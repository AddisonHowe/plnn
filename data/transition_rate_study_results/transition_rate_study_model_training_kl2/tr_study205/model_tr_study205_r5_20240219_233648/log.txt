Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r5', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1470656575

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.89484029613261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.89484029613261 | validation: 12.742669132805645]
	TIME [epoch: 49.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.437020344304395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.437020344304395 | validation: 12.79211174896807]
	TIME [epoch: 10.4 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.693670020402894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.693670020402894 | validation: 12.362724192140947]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 12.701849350377524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.701849350377524 | validation: 12.640761388978262]
	TIME [epoch: 10.4 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.91737230704246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.91737230704246 | validation: 7.299115214587344]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.099231021912114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.099231021912114 | validation: 11.093656176912196]
	TIME [epoch: 10.4 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.094470230217603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.094470230217603 | validation: 10.919964350707989]
	TIME [epoch: 10.4 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.114740207318798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.114740207318798 | validation: 7.796692225203007]
	TIME [epoch: 10.4 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.683260233505232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.683260233505232 | validation: 5.087803895039953]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.336678588888824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.336678588888824 | validation: 4.915036422714892]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.27409532413473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.27409532413473 | validation: 5.001163945188421]
	TIME [epoch: 10.4 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.473987878280807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.473987878280807 | validation: 5.511385351306892]
	TIME [epoch: 10.4 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.07111722599501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.07111722599501 | validation: 4.8038992602817565]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.354610670176292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.354610670176292 | validation: 4.817352647837565]
	TIME [epoch: 10.4 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.29235180996889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.29235180996889 | validation: 4.742410861134467]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.956374608226492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.956374608226492 | validation: 6.838342934682487]
	TIME [epoch: 10.4 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4470771143656425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4470771143656425 | validation: 4.7036203200441244]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.84626614737778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.84626614737778 | validation: 4.957203398950639]
	TIME [epoch: 10.4 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.379406132980809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.379406132980809 | validation: 4.911607840826849]
	TIME [epoch: 10.4 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.218284559010325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.218284559010325 | validation: 5.2084565302062495]
	TIME [epoch: 10.4 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.238071996930576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.238071996930576 | validation: 4.778808203614739]
	TIME [epoch: 10.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.104918726754694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.104918726754694 | validation: 4.7145420037726495]
	TIME [epoch: 10.4 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7793839236332545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7793839236332545 | validation: 4.705502427617422]
	TIME [epoch: 10.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.383153890972517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.383153890972517 | validation: 5.204664082515786]
	TIME [epoch: 10.4 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0941879175513245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0941879175513245 | validation: 4.920053269974907]
	TIME [epoch: 10.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0498664206542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0498664206542 | validation: 4.8158749790866064]
	TIME [epoch: 10.4 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.320865369959627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.320865369959627 | validation: 4.535562196707026]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.981190893311057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.981190893311057 | validation: 4.788215456675562]
	TIME [epoch: 10.4 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.021269959612756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.021269959612756 | validation: 4.742407846577727]
	TIME [epoch: 10.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.769111631426236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.769111631426236 | validation: 5.799109158343815]
	TIME [epoch: 10.4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.135871531202933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.135871531202933 | validation: 4.5090822896001965]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.015956818889864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.015956818889864 | validation: 4.45579802676623]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.567821075320322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.567821075320322 | validation: 5.193832839515318]
	TIME [epoch: 10.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.60028256877376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.60028256877376 | validation: 4.496353667577637]
	TIME [epoch: 10.4 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.910458884984635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.910458884984635 | validation: 4.7911441113318185]
	TIME [epoch: 10.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.854142920006557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.854142920006557 | validation: 4.804093340817819]
	TIME [epoch: 10.4 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8438446309427885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8438446309427885 | validation: 4.520119266336942]
	TIME [epoch: 10.4 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.654013891570309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.654013891570309 | validation: 6.402144653657281]
	TIME [epoch: 10.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.151437989854075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.151437989854075 | validation: 5.968807832802443]
	TIME [epoch: 10.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.199441890035597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.199441890035597 | validation: 4.835101312842316]
	TIME [epoch: 10.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.838197377631762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.838197377631762 | validation: 4.441342175395501]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.666345082414439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.666345082414439 | validation: 5.059122396694895]
	TIME [epoch: 10.4 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.884466295058982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.884466295058982 | validation: 4.436308050364109]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8773479807493905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8773479807493905 | validation: 4.426771413889441]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.651315994931262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.651315994931262 | validation: 4.334130035919162]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.369138708520542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.369138708520542 | validation: 4.367409054778863]
	TIME [epoch: 10.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.211950600348848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.211950600348848 | validation: 4.3316890891702]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.762623675937113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.762623675937113 | validation: 4.235399343985698]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.715496321108299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.715496321108299 | validation: 4.3538846304645205]
	TIME [epoch: 10.4 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.661084947415464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.661084947415464 | validation: 4.506072376939728]
	TIME [epoch: 10.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.644141677003715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.644141677003715 | validation: 4.580233693906513]
	TIME [epoch: 10.4 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.852363287735198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.852363287735198 | validation: 4.23694364216482]
	TIME [epoch: 10.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.806921473731885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.806921473731885 | validation: 5.483842482379074]
	TIME [epoch: 10.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.717596094648892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.717596094648892 | validation: 4.574188629962794]
	TIME [epoch: 10.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.555105224430011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.555105224430011 | validation: 4.62633230484453]
	TIME [epoch: 10.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.79728151063989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.79728151063989 | validation: 4.385214931245454]
	TIME [epoch: 10.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.355473291546089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.355473291546089 | validation: 4.155346744137045]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.846627214956112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.846627214956112 | validation: 4.390766028262785]
	TIME [epoch: 10.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.762394648457568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.762394648457568 | validation: 4.221581006881927]
	TIME [epoch: 10.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.63043694535906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.63043694535906 | validation: 4.264591833357274]
	TIME [epoch: 10.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.633996587361736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.633996587361736 | validation: 4.458961314389927]
	TIME [epoch: 10.4 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.664692264648177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.664692264648177 | validation: 4.266482490595849]
	TIME [epoch: 10.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6363552128399546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6363552128399546 | validation: 4.715363380135604]
	TIME [epoch: 10.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.527020251597542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.527020251597542 | validation: 4.386770535471217]
	TIME [epoch: 10.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.466379375249342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.466379375249342 | validation: 4.837188594848048]
	TIME [epoch: 10.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.57392945629919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.57392945629919 | validation: 4.4096642037442395]
	TIME [epoch: 10.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.549258770581874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.549258770581874 | validation: 4.415641393435083]
	TIME [epoch: 10.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.330631733532016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.330631733532016 | validation: 4.624660405657934]
	TIME [epoch: 10.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.563106616161611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.563106616161611 | validation: 4.876957285462271]
	TIME [epoch: 10.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.585926785224169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.585926785224169 | validation: 4.863956941770105]
	TIME [epoch: 10.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.59013026920894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.59013026920894 | validation: 4.434240910170016]
	TIME [epoch: 10.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.441398113141115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.441398113141115 | validation: 4.640410010925609]
	TIME [epoch: 10.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.736198177908638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.736198177908638 | validation: 5.0512806310713065]
	TIME [epoch: 10.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.567217948321122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.567217948321122 | validation: 4.335894911555264]
	TIME [epoch: 10.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.548554599521784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.548554599521784 | validation: 4.153880048866017]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.301663331409111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.301663331409111 | validation: 4.050687723036905]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.54598868574458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.54598868574458 | validation: 4.183807081027986]
	TIME [epoch: 10.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4849083258806735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4849083258806735 | validation: 4.8948009983545715]
	TIME [epoch: 10.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.490722332577205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.490722332577205 | validation: 4.086442124100609]
	TIME [epoch: 10.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.425840367013794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.425840367013794 | validation: 4.46227886186263]
	TIME [epoch: 10.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.335161094725853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.335161094725853 | validation: 5.6725872686895835]
	TIME [epoch: 10.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.488238512487994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.488238512487994 | validation: 4.128145793779515]
	TIME [epoch: 10.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.376443356409189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.376443356409189 | validation: 4.34214206790337]
	TIME [epoch: 10.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.473392075871147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.473392075871147 | validation: 4.061710480661255]
	TIME [epoch: 10.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.392517353425077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.392517353425077 | validation: 4.413893551725968]
	TIME [epoch: 10.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.456651420037479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.456651420037479 | validation: 4.2161724390736826]
	TIME [epoch: 10.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.451121824715018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.451121824715018 | validation: 4.250552205178208]
	TIME [epoch: 10.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1797235863977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1797235863977 | validation: 5.032704517389515]
	TIME [epoch: 10.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.508137805814926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.508137805814926 | validation: 4.404888861294725]
	TIME [epoch: 10.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.393894031600808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.393894031600808 | validation: 3.9408799738806812]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4050715450849065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4050715450849065 | validation: 4.826037358936684]
	TIME [epoch: 10.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.460513042653528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.460513042653528 | validation: 4.319676337186602]
	TIME [epoch: 10.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.158775911090655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.158775911090655 | validation: 4.089837696460907]
	TIME [epoch: 10.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.385660629448769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.385660629448769 | validation: 4.83878320770725]
	TIME [epoch: 10.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.457411622434362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.457411622434362 | validation: 4.229399810102721]
	TIME [epoch: 10.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.424120859957958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.424120859957958 | validation: 4.2261329862348385]
	TIME [epoch: 10.4 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.307483856809293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.307483856809293 | validation: 4.624276398446495]
	TIME [epoch: 10.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.148342563107141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.148342563107141 | validation: 4.092665746738594]
	TIME [epoch: 10.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.582452475282775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582452475282775 | validation: 3.990975353283212]
	TIME [epoch: 10.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.406887709833855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.406887709833855 | validation: 3.9871128161543323]
	TIME [epoch: 10.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.035725801225683		[learning rate: 0.009971]
	Learning Rate: 0.00997096
	LOSS [training: 4.035725801225683 | validation: 4.077191923874172]
	TIME [epoch: 10.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.566304875217545		[learning rate: 0.0099348]
	Learning Rate: 0.00993477
	LOSS [training: 4.566304875217545 | validation: 4.335852983916438]
	TIME [epoch: 10.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.206554116147795		[learning rate: 0.0098987]
	Learning Rate: 0.00989872
	LOSS [training: 4.206554116147795 | validation: 4.401947769236338]
	TIME [epoch: 10.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.271982854762472		[learning rate: 0.0098628]
	Learning Rate: 0.00986279
	LOSS [training: 4.271982854762472 | validation: 3.949133364747167]
	TIME [epoch: 10.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.336362214602984		[learning rate: 0.009827]
	Learning Rate: 0.009827
	LOSS [training: 4.336362214602984 | validation: 4.043669580066959]
	TIME [epoch: 10.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.148752381807582		[learning rate: 0.0097913]
	Learning Rate: 0.00979134
	LOSS [training: 4.148752381807582 | validation: 3.908138416689603]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.206124259139234		[learning rate: 0.0097558]
	Learning Rate: 0.00975581
	LOSS [training: 4.206124259139234 | validation: 4.242930942872561]
	TIME [epoch: 10.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.406679701972462		[learning rate: 0.0097204]
	Learning Rate: 0.0097204
	LOSS [training: 4.406679701972462 | validation: 4.5432818204674]
	TIME [epoch: 10.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.326430198286301		[learning rate: 0.0096851]
	Learning Rate: 0.00968513
	LOSS [training: 4.326430198286301 | validation: 4.05308404918198]
	TIME [epoch: 10.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.071897727817047		[learning rate: 0.00965]
	Learning Rate: 0.00964998
	LOSS [training: 4.071897727817047 | validation: 4.655896262122232]
	TIME [epoch: 10.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.314944576772859		[learning rate: 0.009615]
	Learning Rate: 0.00961496
	LOSS [training: 4.314944576772859 | validation: 4.206347858211358]
	TIME [epoch: 10.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.109579901824205		[learning rate: 0.0095801]
	Learning Rate: 0.00958006
	LOSS [training: 4.109579901824205 | validation: 3.845272860307224]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.349580590177889		[learning rate: 0.0095453]
	Learning Rate: 0.0095453
	LOSS [training: 4.349580590177889 | validation: 3.8609377637391877]
	TIME [epoch: 10.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.128130533810212		[learning rate: 0.0095107]
	Learning Rate: 0.00951066
	LOSS [training: 4.128130533810212 | validation: 4.072167599620458]
	TIME [epoch: 10.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.158308885687792		[learning rate: 0.0094761]
	Learning Rate: 0.00947614
	LOSS [training: 4.158308885687792 | validation: 3.918486892122365]
	TIME [epoch: 10.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.340434699839937		[learning rate: 0.0094418]
	Learning Rate: 0.00944175
	LOSS [training: 4.340434699839937 | validation: 3.8273216601937783]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.209617396088593		[learning rate: 0.0094075]
	Learning Rate: 0.00940749
	LOSS [training: 4.209617396088593 | validation: 3.798736013288884]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.188172439370904		[learning rate: 0.0093733]
	Learning Rate: 0.00937335
	LOSS [training: 4.188172439370904 | validation: 4.407781445363751]
	TIME [epoch: 10.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.173278096903651		[learning rate: 0.0093393]
	Learning Rate: 0.00933933
	LOSS [training: 4.173278096903651 | validation: 3.891171284780992]
	TIME [epoch: 10.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.140145956626556		[learning rate: 0.0093054]
	Learning Rate: 0.00930544
	LOSS [training: 4.140145956626556 | validation: 3.8422475951758246]
	TIME [epoch: 10.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.146486907249821		[learning rate: 0.0092717]
	Learning Rate: 0.00927167
	LOSS [training: 4.146486907249821 | validation: 3.829952208019546]
	TIME [epoch: 10.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.082948183513738		[learning rate: 0.009238]
	Learning Rate: 0.00923802
	LOSS [training: 4.082948183513738 | validation: 3.7863632289661804]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.00513286797832		[learning rate: 0.0092045]
	Learning Rate: 0.0092045
	LOSS [training: 4.00513286797832 | validation: 3.7439016225265576]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.748272906070055		[learning rate: 0.0091711]
	Learning Rate: 0.00917109
	LOSS [training: 3.748272906070055 | validation: 4.517220652189935]
	TIME [epoch: 10.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.097617657576742		[learning rate: 0.0091378]
	Learning Rate: 0.00913781
	LOSS [training: 4.097617657576742 | validation: 4.032082662218196]
	TIME [epoch: 10.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8946001957547756		[learning rate: 0.0091046]
	Learning Rate: 0.00910465
	LOSS [training: 3.8946001957547756 | validation: 4.346797922153048]
	TIME [epoch: 10.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.023372358327656		[learning rate: 0.0090716]
	Learning Rate: 0.00907161
	LOSS [training: 4.023372358327656 | validation: 3.749948897334304]
	TIME [epoch: 10.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.815571307858616		[learning rate: 0.0090387]
	Learning Rate: 0.00903868
	LOSS [training: 3.815571307858616 | validation: 4.012202974013393]
	TIME [epoch: 10.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.0905831843828135		[learning rate: 0.0090059]
	Learning Rate: 0.00900588
	LOSS [training: 4.0905831843828135 | validation: 3.809815477222428]
	TIME [epoch: 10.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3638540198083016		[learning rate: 0.0089732]
	Learning Rate: 0.0089732
	LOSS [training: 3.3638540198083016 | validation: 3.627502495624362]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7263405136472256		[learning rate: 0.0089406]
	Learning Rate: 0.00894064
	LOSS [training: 3.7263405136472256 | validation: 3.8864585099629694]
	TIME [epoch: 10.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.764768904392048		[learning rate: 0.0089082]
	Learning Rate: 0.00890819
	LOSS [training: 3.764768904392048 | validation: 4.228331030994733]
	TIME [epoch: 10.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.866714487675155		[learning rate: 0.0088759]
	Learning Rate: 0.00887586
	LOSS [training: 3.866714487675155 | validation: 3.667006291687367]
	TIME [epoch: 10.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6172850843757223		[learning rate: 0.0088437]
	Learning Rate: 0.00884365
	LOSS [training: 3.6172850843757223 | validation: 3.595753902753106]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.521503076931869		[learning rate: 0.0088116]
	Learning Rate: 0.00881156
	LOSS [training: 3.521503076931869 | validation: 3.594390852670388]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4985242443530553		[learning rate: 0.0087796]
	Learning Rate: 0.00877958
	LOSS [training: 3.4985242443530553 | validation: 2.796521150832489]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3173292666768455		[learning rate: 0.0087477]
	Learning Rate: 0.00874772
	LOSS [training: 3.3173292666768455 | validation: 3.811351168109275]
	TIME [epoch: 10.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9092875256377937		[learning rate: 0.008716]
	Learning Rate: 0.00871597
	LOSS [training: 3.9092875256377937 | validation: 6.483349680155864]
	TIME [epoch: 10.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.95730273437033		[learning rate: 0.0086843]
	Learning Rate: 0.00868434
	LOSS [training: 4.95730273437033 | validation: 3.141920210061528]
	TIME [epoch: 10.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.269050092405751		[learning rate: 0.0086528]
	Learning Rate: 0.00865282
	LOSS [training: 3.269050092405751 | validation: 3.71516290157776]
	TIME [epoch: 10.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3147260089181834		[learning rate: 0.0086214]
	Learning Rate: 0.00862142
	LOSS [training: 3.3147260089181834 | validation: 3.284077099622982]
	TIME [epoch: 10.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.030376315415637		[learning rate: 0.0085901]
	Learning Rate: 0.00859013
	LOSS [training: 3.030376315415637 | validation: 2.9855863864849685]
	TIME [epoch: 10.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1055343141212597		[learning rate: 0.008559]
	Learning Rate: 0.00855896
	LOSS [training: 3.1055343141212597 | validation: 2.615579782893748]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.157971630034873		[learning rate: 0.0085279]
	Learning Rate: 0.0085279
	LOSS [training: 3.157971630034873 | validation: 3.121475996117425]
	TIME [epoch: 10.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1357391100838106		[learning rate: 0.008497]
	Learning Rate: 0.00849695
	LOSS [training: 3.1357391100838106 | validation: 2.4646559276543014]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0989422323334077		[learning rate: 0.0084661]
	Learning Rate: 0.00846612
	LOSS [training: 3.0989422323334077 | validation: 2.429887906547049]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.466283293242968		[learning rate: 0.0084354]
	Learning Rate: 0.00843539
	LOSS [training: 3.466283293242968 | validation: 3.119617966113052]
	TIME [epoch: 10.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.06955002185373		[learning rate: 0.0084048]
	Learning Rate: 0.00840478
	LOSS [training: 3.06955002185373 | validation: 2.662704737857568]
	TIME [epoch: 10.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.88536345043655		[learning rate: 0.0083743]
	Learning Rate: 0.00837428
	LOSS [training: 2.88536345043655 | validation: 2.7044211131560525]
	TIME [epoch: 10.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.043169781147554		[learning rate: 0.0083439]
	Learning Rate: 0.00834389
	LOSS [training: 3.043169781147554 | validation: 3.83454071628856]
	TIME [epoch: 10.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.954443595734411		[learning rate: 0.0083136]
	Learning Rate: 0.00831361
	LOSS [training: 2.954443595734411 | validation: 2.991050346233537]
	TIME [epoch: 10.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.938950857890075		[learning rate: 0.0082834]
	Learning Rate: 0.00828344
	LOSS [training: 2.938950857890075 | validation: 2.9021744261556974]
	TIME [epoch: 10.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.829973902129803		[learning rate: 0.0082534]
	Learning Rate: 0.00825338
	LOSS [training: 2.829973902129803 | validation: 2.3787428160660893]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.70181142200681		[learning rate: 0.0082234]
	Learning Rate: 0.00822342
	LOSS [training: 2.70181142200681 | validation: 2.2659574819858914]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9441344208733278		[learning rate: 0.0081936]
	Learning Rate: 0.00819358
	LOSS [training: 2.9441344208733278 | validation: 2.5579161308910887]
	TIME [epoch: 10.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.83199794798652		[learning rate: 0.0081638]
	Learning Rate: 0.00816384
	LOSS [training: 2.83199794798652 | validation: 2.329247005999862]
	TIME [epoch: 10.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8789301117825503		[learning rate: 0.0081342]
	Learning Rate: 0.00813422
	LOSS [training: 2.8789301117825503 | validation: 3.035525110390579]
	TIME [epoch: 10.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.689917508540824		[learning rate: 0.0081047]
	Learning Rate: 0.0081047
	LOSS [training: 2.689917508540824 | validation: 2.5707714692983035]
	TIME [epoch: 10.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.737655576279787		[learning rate: 0.0080753]
	Learning Rate: 0.00807529
	LOSS [training: 2.737655576279787 | validation: 2.6099999805582064]
	TIME [epoch: 10.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6598582751423288		[learning rate: 0.008046]
	Learning Rate: 0.00804598
	LOSS [training: 2.6598582751423288 | validation: 2.7268547049199756]
	TIME [epoch: 10.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4834556305422697		[learning rate: 0.0080168]
	Learning Rate: 0.00801678
	LOSS [training: 2.4834556305422697 | validation: 2.207473418064675]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.473936227976729		[learning rate: 0.0079877]
	Learning Rate: 0.00798769
	LOSS [training: 2.473936227976729 | validation: 2.619479573187823]
	TIME [epoch: 10.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5148854891675496		[learning rate: 0.0079587]
	Learning Rate: 0.0079587
	LOSS [training: 2.5148854891675496 | validation: 2.229275816585075]
	TIME [epoch: 10.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5145764063408276		[learning rate: 0.0079298]
	Learning Rate: 0.00792982
	LOSS [training: 2.5145764063408276 | validation: 2.409181340405128]
	TIME [epoch: 10.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3251436134859786		[learning rate: 0.007901]
	Learning Rate: 0.00790104
	LOSS [training: 2.3251436134859786 | validation: 2.386427418060639]
	TIME [epoch: 10.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2343872483031815		[learning rate: 0.0078724]
	Learning Rate: 0.00787237
	LOSS [training: 2.2343872483031815 | validation: 2.868411249628697]
	TIME [epoch: 10.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1850120389659518		[learning rate: 0.0078438]
	Learning Rate: 0.0078438
	LOSS [training: 2.1850120389659518 | validation: 1.6885216725201833]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0549666476742883		[learning rate: 0.0078153]
	Learning Rate: 0.00781533
	LOSS [training: 2.0549666476742883 | validation: 2.4977868616293497]
	TIME [epoch: 10.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9609739474873222		[learning rate: 0.007787]
	Learning Rate: 0.00778697
	LOSS [training: 1.9609739474873222 | validation: 1.8768188957670668]
	TIME [epoch: 10.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7358842062547724		[learning rate: 0.0077587]
	Learning Rate: 0.00775871
	LOSS [training: 1.7358842062547724 | validation: 2.233144016697131]
	TIME [epoch: 10.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.855213053921331		[learning rate: 0.0077306]
	Learning Rate: 0.00773055
	LOSS [training: 1.855213053921331 | validation: 2.2669273494132383]
	TIME [epoch: 10.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8118803310152838		[learning rate: 0.0077025]
	Learning Rate: 0.0077025
	LOSS [training: 1.8118803310152838 | validation: 2.133233874165065]
	TIME [epoch: 10.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0588631991624453		[learning rate: 0.0076745]
	Learning Rate: 0.00767455
	LOSS [training: 2.0588631991624453 | validation: 1.6258645672609162]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9570946170063404		[learning rate: 0.0076467]
	Learning Rate: 0.00764669
	LOSS [training: 1.9570946170063404 | validation: 1.5797039194042224]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7205555192555728		[learning rate: 0.0076189]
	Learning Rate: 0.00761894
	LOSS [training: 1.7205555192555728 | validation: 2.0982094735242787]
	TIME [epoch: 10.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8394869593695062		[learning rate: 0.0075913]
	Learning Rate: 0.00759129
	LOSS [training: 1.8394869593695062 | validation: 1.3741160338030045]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7357965986212538		[learning rate: 0.0075637]
	Learning Rate: 0.00756374
	LOSS [training: 1.7357965986212538 | validation: 1.707603258034586]
	TIME [epoch: 10.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.629324537048582		[learning rate: 0.0075363]
	Learning Rate: 0.00753629
	LOSS [training: 1.629324537048582 | validation: 1.8245486887093672]
	TIME [epoch: 10.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.734844633628261		[learning rate: 0.0075089]
	Learning Rate: 0.00750895
	LOSS [training: 1.734844633628261 | validation: 2.1279489572413217]
	TIME [epoch: 10.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5808578069401968		[learning rate: 0.0074817]
	Learning Rate: 0.00748169
	LOSS [training: 1.5808578069401968 | validation: 1.5305748905414123]
	TIME [epoch: 10.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6586576169257108		[learning rate: 0.0074545]
	Learning Rate: 0.00745454
	LOSS [training: 1.6586576169257108 | validation: 1.7876369844190458]
	TIME [epoch: 10.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4054402838227675		[learning rate: 0.0074275]
	Learning Rate: 0.00742749
	LOSS [training: 1.4054402838227675 | validation: 1.7218358647144383]
	TIME [epoch: 10.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6576502948194762		[learning rate: 0.0074005]
	Learning Rate: 0.00740054
	LOSS [training: 1.6576502948194762 | validation: 2.1092226298895684]
	TIME [epoch: 10.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.681047808374221		[learning rate: 0.0073737]
	Learning Rate: 0.00737368
	LOSS [training: 1.681047808374221 | validation: 1.8891660595917195]
	TIME [epoch: 10.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4808983929545696		[learning rate: 0.0073469]
	Learning Rate: 0.00734692
	LOSS [training: 1.4808983929545696 | validation: 1.9514441102876652]
	TIME [epoch: 10.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5846948423612865		[learning rate: 0.0073203]
	Learning Rate: 0.00732026
	LOSS [training: 1.5846948423612865 | validation: 1.9933108362530008]
	TIME [epoch: 10.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.948394304929248		[learning rate: 0.0072937]
	Learning Rate: 0.00729369
	LOSS [training: 1.948394304929248 | validation: 1.8193664235805125]
	TIME [epoch: 10.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5621683125259351		[learning rate: 0.0072672]
	Learning Rate: 0.00726722
	LOSS [training: 1.5621683125259351 | validation: 1.3413252432872345]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5565722783251978		[learning rate: 0.0072408]
	Learning Rate: 0.00724085
	LOSS [training: 1.5565722783251978 | validation: 1.4265536160145087]
	TIME [epoch: 10.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5704344535077126		[learning rate: 0.0072146]
	Learning Rate: 0.00721457
	LOSS [training: 1.5704344535077126 | validation: 1.9021875498693075]
	TIME [epoch: 10.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.938064519527638		[learning rate: 0.0071884]
	Learning Rate: 0.00718839
	LOSS [training: 1.938064519527638 | validation: 2.6366097592451316]
	TIME [epoch: 10.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8999523237924287		[learning rate: 0.0071623]
	Learning Rate: 0.0071623
	LOSS [training: 1.8999523237924287 | validation: 1.639799284067557]
	TIME [epoch: 10.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5293983865444565		[learning rate: 0.0071363]
	Learning Rate: 0.00713631
	LOSS [training: 1.5293983865444565 | validation: 2.1877519942734107]
	TIME [epoch: 10.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8636488190107443		[learning rate: 0.0071104]
	Learning Rate: 0.00711041
	LOSS [training: 1.8636488190107443 | validation: 5.08036032977186]
	TIME [epoch: 10.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.79436762521789		[learning rate: 0.0070846]
	Learning Rate: 0.00708461
	LOSS [training: 2.79436762521789 | validation: 1.9993163599269588]
	TIME [epoch: 10.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4492494747752889		[learning rate: 0.0070589]
	Learning Rate: 0.0070589
	LOSS [training: 1.4492494747752889 | validation: 2.970162921107647]
	TIME [epoch: 10.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7927074880085363		[learning rate: 0.0070333]
	Learning Rate: 0.00703328
	LOSS [training: 1.7927074880085363 | validation: 1.6171485134187213]
	TIME [epoch: 10.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.565252887775672		[learning rate: 0.0070078]
	Learning Rate: 0.00700776
	LOSS [training: 1.565252887775672 | validation: 1.9048824071437356]
	TIME [epoch: 10.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.655361114050398		[learning rate: 0.0069823]
	Learning Rate: 0.00698232
	LOSS [training: 1.655361114050398 | validation: 1.290824927536437]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5190330466760251		[learning rate: 0.006957]
	Learning Rate: 0.00695698
	LOSS [training: 1.5190330466760251 | validation: 1.4921360027737935]
	TIME [epoch: 10.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4956630517144702		[learning rate: 0.0069317]
	Learning Rate: 0.00693174
	LOSS [training: 1.4956630517144702 | validation: 1.9024919143147652]
	TIME [epoch: 10.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6163220369688673		[learning rate: 0.0069066]
	Learning Rate: 0.00690658
	LOSS [training: 1.6163220369688673 | validation: 1.6717601983212784]
	TIME [epoch: 10.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.653743686807675		[learning rate: 0.0068815]
	Learning Rate: 0.00688152
	LOSS [training: 1.653743686807675 | validation: 1.7452202885319201]
	TIME [epoch: 10.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5257258420355062		[learning rate: 0.0068565]
	Learning Rate: 0.00685654
	LOSS [training: 1.5257258420355062 | validation: 1.299648507139263]
	TIME [epoch: 10.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4240328290633937		[learning rate: 0.0068317]
	Learning Rate: 0.00683166
	LOSS [training: 1.4240328290633937 | validation: 1.5064807082165306]
	TIME [epoch: 10.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.404047301012205		[learning rate: 0.0068069]
	Learning Rate: 0.00680687
	LOSS [training: 1.404047301012205 | validation: 1.3478929929077266]
	TIME [epoch: 10.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4503300579467697		[learning rate: 0.0067822]
	Learning Rate: 0.00678217
	LOSS [training: 1.4503300579467697 | validation: 1.4453883692849159]
	TIME [epoch: 10.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3306720883077883		[learning rate: 0.0067576]
	Learning Rate: 0.00675755
	LOSS [training: 1.3306720883077883 | validation: 1.9285091578982358]
	TIME [epoch: 10.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8601675249149914		[learning rate: 0.006733]
	Learning Rate: 0.00673303
	LOSS [training: 1.8601675249149914 | validation: 1.837802148540846]
	TIME [epoch: 10.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7361847441536729		[learning rate: 0.0067086]
	Learning Rate: 0.00670859
	LOSS [training: 1.7361847441536729 | validation: 1.4630629580709626]
	TIME [epoch: 10.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5091184330837077		[learning rate: 0.0066842]
	Learning Rate: 0.00668425
	LOSS [training: 1.5091184330837077 | validation: 1.502661937665659]
	TIME [epoch: 10.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4723105817844693		[learning rate: 0.00666]
	Learning Rate: 0.00665999
	LOSS [training: 1.4723105817844693 | validation: 1.3029724012961197]
	TIME [epoch: 10.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3650692775427242		[learning rate: 0.0066358]
	Learning Rate: 0.00663582
	LOSS [training: 1.3650692775427242 | validation: 2.127767540320846]
	TIME [epoch: 10.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.469526811518382		[learning rate: 0.0066117]
	Learning Rate: 0.00661174
	LOSS [training: 1.469526811518382 | validation: 1.4826763204770774]
	TIME [epoch: 10.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3134382773016686		[learning rate: 0.0065877]
	Learning Rate: 0.00658775
	LOSS [training: 1.3134382773016686 | validation: 1.2346169969152931]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2669676916379695		[learning rate: 0.0065638]
	Learning Rate: 0.00656384
	LOSS [training: 1.2669676916379695 | validation: 1.6239286347854485]
	TIME [epoch: 10.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.652164504150927		[learning rate: 0.00654]
	Learning Rate: 0.00654002
	LOSS [training: 1.652164504150927 | validation: 2.219833362817265]
	TIME [epoch: 10.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5898511228975476		[learning rate: 0.0065163]
	Learning Rate: 0.00651628
	LOSS [training: 1.5898511228975476 | validation: 2.363360079167355]
	TIME [epoch: 10.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8094630656231814		[learning rate: 0.0064926]
	Learning Rate: 0.00649264
	LOSS [training: 1.8094630656231814 | validation: 1.858808040660926]
	TIME [epoch: 10.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7855626778359828		[learning rate: 0.0064691]
	Learning Rate: 0.00646907
	LOSS [training: 1.7855626778359828 | validation: 2.009200023635363]
	TIME [epoch: 10.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6404254198176145		[learning rate: 0.0064456]
	Learning Rate: 0.0064456
	LOSS [training: 1.6404254198176145 | validation: 1.8816627259238334]
	TIME [epoch: 10.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.497170263522817		[learning rate: 0.0064222]
	Learning Rate: 0.00642221
	LOSS [training: 1.497170263522817 | validation: 1.21716872395734]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2688523804412721		[learning rate: 0.0063989]
	Learning Rate: 0.0063989
	LOSS [training: 1.2688523804412721 | validation: 1.8991674501843332]
	TIME [epoch: 10.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5112384632223415		[learning rate: 0.0063757]
	Learning Rate: 0.00637568
	LOSS [training: 1.5112384632223415 | validation: 1.3920583128495403]
	TIME [epoch: 10.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3417597934920489		[learning rate: 0.0063525]
	Learning Rate: 0.00635254
	LOSS [training: 1.3417597934920489 | validation: 1.647033455376665]
	TIME [epoch: 10.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4475080881298734		[learning rate: 0.0063295]
	Learning Rate: 0.00632949
	LOSS [training: 1.4475080881298734 | validation: 1.4199201902344067]
	TIME [epoch: 10.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3072609398427448		[learning rate: 0.0063065]
	Learning Rate: 0.00630652
	LOSS [training: 1.3072609398427448 | validation: 1.0699555008346178]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3097412843068994		[learning rate: 0.0062836]
	Learning Rate: 0.00628363
	LOSS [training: 1.3097412843068994 | validation: 1.7918503273698798]
	TIME [epoch: 10.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6378773663993722		[learning rate: 0.0062608]
	Learning Rate: 0.00626082
	LOSS [training: 1.6378773663993722 | validation: 1.4571156074193363]
	TIME [epoch: 10.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3387635468638113		[learning rate: 0.0062381]
	Learning Rate: 0.0062381
	LOSS [training: 1.3387635468638113 | validation: 1.3308456207352635]
	TIME [epoch: 10.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3373669510410557		[learning rate: 0.0062155]
	Learning Rate: 0.00621547
	LOSS [training: 1.3373669510410557 | validation: 1.3596121609001282]
	TIME [epoch: 10.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4800499238263451		[learning rate: 0.0061929]
	Learning Rate: 0.00619291
	LOSS [training: 1.4800499238263451 | validation: 1.5482258136912947]
	TIME [epoch: 10.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.361716691713589		[learning rate: 0.0061704]
	Learning Rate: 0.00617043
	LOSS [training: 1.361716691713589 | validation: 1.1578663845309667]
	TIME [epoch: 10.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1614184339911993		[learning rate: 0.006148]
	Learning Rate: 0.00614804
	LOSS [training: 1.1614184339911993 | validation: 1.3871055799354213]
	TIME [epoch: 10.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4406167129775111		[learning rate: 0.0061257]
	Learning Rate: 0.00612573
	LOSS [training: 1.4406167129775111 | validation: 1.6649541653492312]
	TIME [epoch: 10.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3443567442684619		[learning rate: 0.0061035]
	Learning Rate: 0.0061035
	LOSS [training: 1.3443567442684619 | validation: 1.2025758412379262]
	TIME [epoch: 10.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3017504213258557		[learning rate: 0.0060814]
	Learning Rate: 0.00608135
	LOSS [training: 1.3017504213258557 | validation: 1.352430094629747]
	TIME [epoch: 10.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2691773362041514		[learning rate: 0.0060593]
	Learning Rate: 0.00605928
	LOSS [training: 1.2691773362041514 | validation: 1.6970045065555337]
	TIME [epoch: 10.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5462669765923205		[learning rate: 0.0060373]
	Learning Rate: 0.00603729
	LOSS [training: 1.5462669765923205 | validation: 1.1499562961032903]
	TIME [epoch: 10.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2761691660484638		[learning rate: 0.0060154]
	Learning Rate: 0.00601538
	LOSS [training: 1.2761691660484638 | validation: 1.2546099179423966]
	TIME [epoch: 10.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3700089301495972		[learning rate: 0.0059936]
	Learning Rate: 0.00599355
	LOSS [training: 1.3700089301495972 | validation: 1.9032627735803953]
	TIME [epoch: 10.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.597348791142448		[learning rate: 0.0059718]
	Learning Rate: 0.0059718
	LOSS [training: 1.597348791142448 | validation: 1.1895310117968454]
	TIME [epoch: 10.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.124924021815252		[learning rate: 0.0059501]
	Learning Rate: 0.00595013
	LOSS [training: 1.124924021815252 | validation: 1.485200935243775]
	TIME [epoch: 10.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2809653161620884		[learning rate: 0.0059285]
	Learning Rate: 0.00592853
	LOSS [training: 1.2809653161620884 | validation: 1.4329886872866917]
	TIME [epoch: 10.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2080733330799778		[learning rate: 0.005907]
	Learning Rate: 0.00590702
	LOSS [training: 1.2080733330799778 | validation: 1.053174486784208]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5472808023421905		[learning rate: 0.0058856]
	Learning Rate: 0.00588558
	LOSS [training: 1.5472808023421905 | validation: 1.3040411053170362]
	TIME [epoch: 10.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4255566922054315		[learning rate: 0.0058642]
	Learning Rate: 0.00586422
	LOSS [training: 1.4255566922054315 | validation: 1.9772485393765933]
	TIME [epoch: 10.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.427917853188227		[learning rate: 0.0058429]
	Learning Rate: 0.00584294
	LOSS [training: 1.427917853188227 | validation: 1.635283038882215]
	TIME [epoch: 10.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.533186542164153		[learning rate: 0.0058217]
	Learning Rate: 0.00582174
	LOSS [training: 1.533186542164153 | validation: 1.214288269645565]
	TIME [epoch: 10.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.890076060675982		[learning rate: 0.0058006]
	Learning Rate: 0.00580061
	LOSS [training: 1.890076060675982 | validation: 1.508418236221575]
	TIME [epoch: 10.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.511721328860673		[learning rate: 0.0057796]
	Learning Rate: 0.00577956
	LOSS [training: 1.511721328860673 | validation: 1.3734089369047875]
	TIME [epoch: 10.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.102040448632938		[learning rate: 0.0057586]
	Learning Rate: 0.00575859
	LOSS [training: 1.102040448632938 | validation: 1.365166505583633]
	TIME [epoch: 10.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2059503066430166		[learning rate: 0.0057377]
	Learning Rate: 0.00573769
	LOSS [training: 1.2059503066430166 | validation: 1.4840554715560532]
	TIME [epoch: 10.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1954579437995654		[learning rate: 0.0057169]
	Learning Rate: 0.00571686
	LOSS [training: 1.1954579437995654 | validation: 1.3016226728545595]
	TIME [epoch: 10.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4939105796932064		[learning rate: 0.0056961]
	Learning Rate: 0.00569612
	LOSS [training: 1.4939105796932064 | validation: 1.4730986536989665]
	TIME [epoch: 10.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3922165291813404		[learning rate: 0.0056754]
	Learning Rate: 0.00567545
	LOSS [training: 1.3922165291813404 | validation: 1.5166015164495168]
	TIME [epoch: 10.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3132397992318994		[learning rate: 0.0056548]
	Learning Rate: 0.00565485
	LOSS [training: 1.3132397992318994 | validation: 1.0433515535500713]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1513172031390084		[learning rate: 0.0056343]
	Learning Rate: 0.00563433
	LOSS [training: 1.1513172031390084 | validation: 1.5992650382481217]
	TIME [epoch: 10.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3271080357567868		[learning rate: 0.0056139]
	Learning Rate: 0.00561388
	LOSS [training: 1.3271080357567868 | validation: 1.5387659941254908]
	TIME [epoch: 10.4 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.340434600161836		[learning rate: 0.0055935]
	Learning Rate: 0.00559351
	LOSS [training: 1.340434600161836 | validation: 1.0536930654086079]
	TIME [epoch: 10.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.331081633439145		[learning rate: 0.0055732]
	Learning Rate: 0.00557321
	LOSS [training: 1.331081633439145 | validation: 1.246791357298741]
	TIME [epoch: 10.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.224944542136453		[learning rate: 0.005553]
	Learning Rate: 0.00555298
	LOSS [training: 2.224944542136453 | validation: 1.5580623386993342]
	TIME [epoch: 10.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4850327049778012		[learning rate: 0.0055328]
	Learning Rate: 0.00553283
	LOSS [training: 1.4850327049778012 | validation: 1.7249515338022163]
	TIME [epoch: 10.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.795803195906036		[learning rate: 0.0055128]
	Learning Rate: 0.00551275
	LOSS [training: 1.795803195906036 | validation: 1.451203920532958]
	TIME [epoch: 10.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2706793463118653		[learning rate: 0.0054927]
	Learning Rate: 0.00549274
	LOSS [training: 1.2706793463118653 | validation: 1.1131177678489204]
	TIME [epoch: 10.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2683243881243145		[learning rate: 0.0054728]
	Learning Rate: 0.00547281
	LOSS [training: 1.2683243881243145 | validation: 1.2738578452746665]
	TIME [epoch: 10.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2677206898557536		[learning rate: 0.005453]
	Learning Rate: 0.00545295
	LOSS [training: 1.2677206898557536 | validation: 1.3400774647251978]
	TIME [epoch: 10.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1956877955716734		[learning rate: 0.0054332]
	Learning Rate: 0.00543316
	LOSS [training: 1.1956877955716734 | validation: 1.5382283850779965]
	TIME [epoch: 10.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4033252184414855		[learning rate: 0.0054134]
	Learning Rate: 0.00541344
	LOSS [training: 1.4033252184414855 | validation: 1.3483653716684108]
	TIME [epoch: 10.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4077285210183454		[learning rate: 0.0053938]
	Learning Rate: 0.0053938
	LOSS [training: 1.4077285210183454 | validation: 1.181318653057659]
	TIME [epoch: 10.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2872362932587091		[learning rate: 0.0053742]
	Learning Rate: 0.00537422
	LOSS [training: 1.2872362932587091 | validation: 1.1379754944235096]
	TIME [epoch: 10.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.180694676636353		[learning rate: 0.0053547]
	Learning Rate: 0.00535472
	LOSS [training: 1.180694676636353 | validation: 1.448710151226796]
	TIME [epoch: 10.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3134321137322682		[learning rate: 0.0053353]
	Learning Rate: 0.00533529
	LOSS [training: 1.3134321137322682 | validation: 1.8862516031269818]
	TIME [epoch: 10.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.474650536460273		[learning rate: 0.0053159]
	Learning Rate: 0.00531593
	LOSS [training: 2.474650536460273 | validation: 1.5988756693493356]
	TIME [epoch: 10.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5031148975362576		[learning rate: 0.0052966]
	Learning Rate: 0.00529663
	LOSS [training: 1.5031148975362576 | validation: 1.5119112927312506]
	TIME [epoch: 10.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.286474229217577		[learning rate: 0.0052774]
	Learning Rate: 0.00527741
	LOSS [training: 1.286474229217577 | validation: 1.1402914868038532]
	TIME [epoch: 10.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2831395987506338		[learning rate: 0.0052583]
	Learning Rate: 0.00525826
	LOSS [training: 1.2831395987506338 | validation: 1.4226245468512158]
	TIME [epoch: 10.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1989709088097378		[learning rate: 0.0052392]
	Learning Rate: 0.00523918
	LOSS [training: 1.1989709088097378 | validation: 1.2945926540688473]
	TIME [epoch: 10.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2665219968081327		[learning rate: 0.0052202]
	Learning Rate: 0.00522017
	LOSS [training: 1.2665219968081327 | validation: 1.2714753957664862]
	TIME [epoch: 10.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.133027815831534		[learning rate: 0.0052012]
	Learning Rate: 0.00520122
	LOSS [training: 1.133027815831534 | validation: 1.068305140883417]
	TIME [epoch: 10.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1705748233218494		[learning rate: 0.0051823]
	Learning Rate: 0.00518234
	LOSS [training: 1.1705748233218494 | validation: 1.2947485328150654]
	TIME [epoch: 10.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1341796499015058		[learning rate: 0.0051635]
	Learning Rate: 0.00516354
	LOSS [training: 1.1341796499015058 | validation: 1.1525312845763493]
	TIME [epoch: 10.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.301373419669601		[learning rate: 0.0051448]
	Learning Rate: 0.0051448
	LOSS [training: 1.301373419669601 | validation: 1.242310548504708]
	TIME [epoch: 10.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.44584651195976		[learning rate: 0.0051261]
	Learning Rate: 0.00512613
	LOSS [training: 1.44584651195976 | validation: 1.6040078443657186]
	TIME [epoch: 10.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2327767384722672		[learning rate: 0.0051075]
	Learning Rate: 0.00510753
	LOSS [training: 1.2327767384722672 | validation: 1.1901931519059028]
	TIME [epoch: 10.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.21695952658009		[learning rate: 0.005089]
	Learning Rate: 0.00508899
	LOSS [training: 1.21695952658009 | validation: 1.3060719755302956]
	TIME [epoch: 10.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.131643258261906		[learning rate: 0.0050705]
	Learning Rate: 0.00507052
	LOSS [training: 1.131643258261906 | validation: 1.2498764983449733]
	TIME [epoch: 10.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1765814781444677		[learning rate: 0.0050521]
	Learning Rate: 0.00505212
	LOSS [training: 1.1765814781444677 | validation: 1.3419150387975742]
	TIME [epoch: 10.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1197896141608368		[learning rate: 0.0050338]
	Learning Rate: 0.00503379
	LOSS [training: 1.1197896141608368 | validation: 1.4076343714118627]
	TIME [epoch: 10.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2885225132961113		[learning rate: 0.0050155]
	Learning Rate: 0.00501552
	LOSS [training: 1.2885225132961113 | validation: 1.368848624631255]
	TIME [epoch: 10.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2512459323793474		[learning rate: 0.0049973]
	Learning Rate: 0.00499732
	LOSS [training: 1.2512459323793474 | validation: 1.2160837666038091]
	TIME [epoch: 10.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1798410056490245		[learning rate: 0.0049792]
	Learning Rate: 0.00497918
	LOSS [training: 1.1798410056490245 | validation: 1.1405090948125889]
	TIME [epoch: 10.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1128768557345492		[learning rate: 0.0049611]
	Learning Rate: 0.00496111
	LOSS [training: 1.1128768557345492 | validation: 1.0861327978965059]
	TIME [epoch: 10.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1757506085172122		[learning rate: 0.0049431]
	Learning Rate: 0.00494311
	LOSS [training: 1.1757506085172122 | validation: 1.1748938595496465]
	TIME [epoch: 10.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1449637237927721		[learning rate: 0.0049252]
	Learning Rate: 0.00492517
	LOSS [training: 1.1449637237927721 | validation: 1.4603552065913321]
	TIME [epoch: 10.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.213907476471991		[learning rate: 0.0049073]
	Learning Rate: 0.00490729
	LOSS [training: 1.213907476471991 | validation: 1.266680858618488]
	TIME [epoch: 10.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0486124298337594		[learning rate: 0.0048895]
	Learning Rate: 0.00488948
	LOSS [training: 1.0486124298337594 | validation: 1.3774910240406915]
	TIME [epoch: 10.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3012759116458954		[learning rate: 0.0048717]
	Learning Rate: 0.00487174
	LOSS [training: 1.3012759116458954 | validation: 1.281831331895086]
	TIME [epoch: 10.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1133250055451291		[learning rate: 0.0048541]
	Learning Rate: 0.00485406
	LOSS [training: 1.1133250055451291 | validation: 1.0787791473857318]
	TIME [epoch: 10.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2110966451441811		[learning rate: 0.0048364]
	Learning Rate: 0.00483645
	LOSS [training: 1.2110966451441811 | validation: 1.7294021615594575]
	TIME [epoch: 10.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2503031854607127		[learning rate: 0.0048189]
	Learning Rate: 0.00481889
	LOSS [training: 1.2503031854607127 | validation: 1.1311099434204674]
	TIME [epoch: 10.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2351822052721535		[learning rate: 0.0048014]
	Learning Rate: 0.00480141
	LOSS [training: 1.2351822052721535 | validation: 1.2855347376149413]
	TIME [epoch: 10.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2600325916223611		[learning rate: 0.004784]
	Learning Rate: 0.00478398
	LOSS [training: 1.2600325916223611 | validation: 1.2495760136172722]
	TIME [epoch: 10.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2446575433970373		[learning rate: 0.0047666]
	Learning Rate: 0.00476662
	LOSS [training: 1.2446575433970373 | validation: 1.2153604590811136]
	TIME [epoch: 10.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1189689273755734		[learning rate: 0.0047493]
	Learning Rate: 0.00474932
	LOSS [training: 1.1189689273755734 | validation: 1.4787033528586109]
	TIME [epoch: 10.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2123278786241822		[learning rate: 0.0047321]
	Learning Rate: 0.00473209
	LOSS [training: 1.2123278786241822 | validation: 1.2910149269971174]
	TIME [epoch: 10.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.167993331645895		[learning rate: 0.0047149]
	Learning Rate: 0.00471491
	LOSS [training: 1.167993331645895 | validation: 1.2561948392906883]
	TIME [epoch: 10.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1476243703135596		[learning rate: 0.0046978]
	Learning Rate: 0.0046978
	LOSS [training: 1.1476243703135596 | validation: 1.3597798036546647]
	TIME [epoch: 10.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1070447429791468		[learning rate: 0.0046808]
	Learning Rate: 0.00468075
	LOSS [training: 1.1070447429791468 | validation: 1.152507117645878]
	TIME [epoch: 10.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2284899143811863		[learning rate: 0.0046638]
	Learning Rate: 0.00466377
	LOSS [training: 1.2284899143811863 | validation: 1.1376033848789617]
	TIME [epoch: 10.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5362604415024708		[learning rate: 0.0046468]
	Learning Rate: 0.00464684
	LOSS [training: 1.5362604415024708 | validation: 1.6820464697671265]
	TIME [epoch: 10.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.169473067566127		[learning rate: 0.00463]
	Learning Rate: 0.00462998
	LOSS [training: 1.169473067566127 | validation: 1.2166548416252752]
	TIME [epoch: 10.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0927723618498493		[learning rate: 0.0046132]
	Learning Rate: 0.00461318
	LOSS [training: 1.0927723618498493 | validation: 0.9938808444224833]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1040679458562743		[learning rate: 0.0045964]
	Learning Rate: 0.00459643
	LOSS [training: 1.1040679458562743 | validation: 1.6186832766863912]
	TIME [epoch: 10.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2335965768446153		[learning rate: 0.0045798]
	Learning Rate: 0.00457975
	LOSS [training: 1.2335965768446153 | validation: 1.1844758216756262]
	TIME [epoch: 10.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.972498706787231		[learning rate: 0.0045631]
	Learning Rate: 0.00456313
	LOSS [training: 0.972498706787231 | validation: 1.4552131043401706]
	TIME [epoch: 10.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2936952625155422		[learning rate: 0.0045466]
	Learning Rate: 0.00454657
	LOSS [training: 1.2936952625155422 | validation: 1.9677284804754491]
	TIME [epoch: 10.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.367841237618952		[learning rate: 0.0045301]
	Learning Rate: 0.00453007
	LOSS [training: 1.367841237618952 | validation: 1.163746387635421]
	TIME [epoch: 10.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1384834892726001		[learning rate: 0.0045136]
	Learning Rate: 0.00451363
	LOSS [training: 1.1384834892726001 | validation: 0.9790346691713456]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1874896921594338		[learning rate: 0.0044973]
	Learning Rate: 0.00449725
	LOSS [training: 1.1874896921594338 | validation: 1.1872369075970348]
	TIME [epoch: 10.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0616069138751059		[learning rate: 0.0044809]
	Learning Rate: 0.00448093
	LOSS [training: 1.0616069138751059 | validation: 1.2151907393274395]
	TIME [epoch: 10.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1308420175808984		[learning rate: 0.0044647]
	Learning Rate: 0.00446467
	LOSS [training: 1.1308420175808984 | validation: 1.0070913894150613]
	TIME [epoch: 10.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9982440463131355		[learning rate: 0.0044485]
	Learning Rate: 0.00444847
	LOSS [training: 0.9982440463131355 | validation: 1.210485957246526]
	TIME [epoch: 10.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.020680209968015		[learning rate: 0.0044323]
	Learning Rate: 0.00443232
	LOSS [training: 1.020680209968015 | validation: 1.3250548256078278]
	TIME [epoch: 10.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0567336234653404		[learning rate: 0.0044162]
	Learning Rate: 0.00441624
	LOSS [training: 1.0567336234653404 | validation: 1.590552782273228]
	TIME [epoch: 10.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1742141174739713		[learning rate: 0.0044002]
	Learning Rate: 0.00440021
	LOSS [training: 1.1742141174739713 | validation: 1.4145719853597047]
	TIME [epoch: 10.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1089217177422452		[learning rate: 0.0043842]
	Learning Rate: 0.00438424
	LOSS [training: 1.1089217177422452 | validation: 1.4637550289214385]
	TIME [epoch: 10.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1637394344470118		[learning rate: 0.0043683]
	Learning Rate: 0.00436833
	LOSS [training: 1.1637394344470118 | validation: 1.3023412818111706]
	TIME [epoch: 10.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057635832435973		[learning rate: 0.0043525]
	Learning Rate: 0.00435248
	LOSS [training: 1.057635832435973 | validation: 0.99284299009283]
	TIME [epoch: 10.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.02062853016036		[learning rate: 0.0043367]
	Learning Rate: 0.00433668
	LOSS [training: 1.02062853016036 | validation: 1.3435068217992712]
	TIME [epoch: 10.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.30943718712388		[learning rate: 0.0043209]
	Learning Rate: 0.00432095
	LOSS [training: 1.30943718712388 | validation: 1.420015747219391]
	TIME [epoch: 10.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1518631339743939		[learning rate: 0.0043053]
	Learning Rate: 0.00430527
	LOSS [training: 1.1518631339743939 | validation: 1.3214921437077476]
	TIME [epoch: 10.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.107357812028562		[learning rate: 0.0042896]
	Learning Rate: 0.00428964
	LOSS [training: 1.107357812028562 | validation: 1.1889047904868908]
	TIME [epoch: 10.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.037479826906198		[learning rate: 0.0042741]
	Learning Rate: 0.00427407
	LOSS [training: 1.037479826906198 | validation: 1.5906556082905179]
	TIME [epoch: 10.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.287448947249256		[learning rate: 0.0042586]
	Learning Rate: 0.00425856
	LOSS [training: 1.287448947249256 | validation: 1.1719895298306093]
	TIME [epoch: 10.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3427789703625586		[learning rate: 0.0042431]
	Learning Rate: 0.00424311
	LOSS [training: 1.3427789703625586 | validation: 1.653460150071485]
	TIME [epoch: 10.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2901043532561218		[learning rate: 0.0042277]
	Learning Rate: 0.00422771
	LOSS [training: 1.2901043532561218 | validation: 1.1968077375654818]
	TIME [epoch: 10.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2338359075018448		[learning rate: 0.0042124]
	Learning Rate: 0.00421237
	LOSS [training: 1.2338359075018448 | validation: 0.991119297830138]
	TIME [epoch: 10.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0550849224331968		[learning rate: 0.0041971]
	Learning Rate: 0.00419708
	LOSS [training: 1.0550849224331968 | validation: 0.9495369130512716]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0470439129529914		[learning rate: 0.0041818]
	Learning Rate: 0.00418185
	LOSS [training: 1.0470439129529914 | validation: 1.12114855518611]
	TIME [epoch: 10.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0682927165952667		[learning rate: 0.0041667]
	Learning Rate: 0.00416667
	LOSS [training: 1.0682927165952667 | validation: 1.1097638948410722]
	TIME [epoch: 10.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1321209257188216		[learning rate: 0.0041516]
	Learning Rate: 0.00415155
	LOSS [training: 1.1321209257188216 | validation: 1.190146479330348]
	TIME [epoch: 10.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0473224607205098		[learning rate: 0.0041365]
	Learning Rate: 0.00413649
	LOSS [training: 1.0473224607205098 | validation: 1.3809077058022576]
	TIME [epoch: 10.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9599992281020737		[learning rate: 0.0041215]
	Learning Rate: 0.00412147
	LOSS [training: 0.9599992281020737 | validation: 1.0572388480175552]
	TIME [epoch: 10.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.046403436993011		[learning rate: 0.0041065]
	Learning Rate: 0.00410652
	LOSS [training: 1.046403436993011 | validation: 0.9325077113464779]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0622825073523097		[learning rate: 0.0040916]
	Learning Rate: 0.00409161
	LOSS [training: 1.0622825073523097 | validation: 1.1405694091464782]
	TIME [epoch: 10.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0466157898264805		[learning rate: 0.0040768]
	Learning Rate: 0.00407677
	LOSS [training: 1.0466157898264805 | validation: 1.0364147415376923]
	TIME [epoch: 10.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1605109214776965		[learning rate: 0.004062]
	Learning Rate: 0.00406197
	LOSS [training: 1.1605109214776965 | validation: 0.9656798970540368]
	TIME [epoch: 10.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3368724441746098		[learning rate: 0.0040472]
	Learning Rate: 0.00404723
	LOSS [training: 1.3368724441746098 | validation: 1.1200908473533533]
	TIME [epoch: 10.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.166625042090344		[learning rate: 0.0040325]
	Learning Rate: 0.00403254
	LOSS [training: 3.166625042090344 | validation: 0.9614626177854791]
	TIME [epoch: 10.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9868707690017409		[learning rate: 0.0040179]
	Learning Rate: 0.00401791
	LOSS [training: 0.9868707690017409 | validation: 1.0467547022495303]
	TIME [epoch: 10.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9649752393242338		[learning rate: 0.0040033]
	Learning Rate: 0.00400333
	LOSS [training: 0.9649752393242338 | validation: 0.8709803930620323]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9476740685444964		[learning rate: 0.0039888]
	Learning Rate: 0.0039888
	LOSS [training: 0.9476740685444964 | validation: 1.111969367033366]
	TIME [epoch: 10.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0212725258351396		[learning rate: 0.0039743]
	Learning Rate: 0.00397432
	LOSS [training: 1.0212725258351396 | validation: 0.8707326686473386]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0173585275210484		[learning rate: 0.0039599]
	Learning Rate: 0.0039599
	LOSS [training: 1.0173585275210484 | validation: 1.209636051342834]
	TIME [epoch: 10.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9369419066320501		[learning rate: 0.0039455]
	Learning Rate: 0.00394553
	LOSS [training: 0.9369419066320501 | validation: 1.4408508299615108]
	TIME [epoch: 10.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1118001717218005		[learning rate: 0.0039312]
	Learning Rate: 0.00393121
	LOSS [training: 1.1118001717218005 | validation: 0.9977301758522574]
	TIME [epoch: 10.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0953079090744537		[learning rate: 0.0039169]
	Learning Rate: 0.00391694
	LOSS [training: 1.0953079090744537 | validation: 1.0396287090817438]
	TIME [epoch: 10.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.955009110981031		[learning rate: 0.0039027]
	Learning Rate: 0.00390273
	LOSS [training: 0.955009110981031 | validation: 1.4678791442444004]
	TIME [epoch: 10.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0679766127828096		[learning rate: 0.0038886]
	Learning Rate: 0.00388857
	LOSS [training: 1.0679766127828096 | validation: 1.2466908554259981]
	TIME [epoch: 10.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9949181774078731		[learning rate: 0.0038745]
	Learning Rate: 0.00387445
	LOSS [training: 0.9949181774078731 | validation: 1.0916090615974066]
	TIME [epoch: 10.4 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9424221876519534		[learning rate: 0.0038604]
	Learning Rate: 0.00386039
	LOSS [training: 0.9424221876519534 | validation: 0.9053001717828726]
	TIME [epoch: 10.4 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9074646346131361		[learning rate: 0.0038464]
	Learning Rate: 0.00384638
	LOSS [training: 0.9074646346131361 | validation: 1.1073206976163963]
	TIME [epoch: 10.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3129276800255343		[learning rate: 0.0038324]
	Learning Rate: 0.00383242
	LOSS [training: 1.3129276800255343 | validation: 1.34785340598393]
	TIME [epoch: 10.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4215415146803754		[learning rate: 0.0038185]
	Learning Rate: 0.00381852
	LOSS [training: 1.4215415146803754 | validation: 1.2374598013722589]
	TIME [epoch: 10.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9729766790817085		[learning rate: 0.0038047]
	Learning Rate: 0.00380466
	LOSS [training: 0.9729766790817085 | validation: 0.8834537807523298]
	TIME [epoch: 10.4 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8410113625897617		[learning rate: 0.0037909]
	Learning Rate: 0.00379085
	LOSS [training: 0.8410113625897617 | validation: 1.1790193458764358]
	TIME [epoch: 10.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9131954341955163		[learning rate: 0.0037771]
	Learning Rate: 0.00377709
	LOSS [training: 0.9131954341955163 | validation: 1.0961821185191347]
	TIME [epoch: 10.4 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9745695399678682		[learning rate: 0.0037634]
	Learning Rate: 0.00376339
	LOSS [training: 0.9745695399678682 | validation: 0.8732966981110823]
	TIME [epoch: 10.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.970037607922489		[learning rate: 0.0037497]
	Learning Rate: 0.00374973
	LOSS [training: 0.970037607922489 | validation: 1.0882288359454055]
	TIME [epoch: 10.4 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.111511971279118		[learning rate: 0.0037361]
	Learning Rate: 0.00373612
	LOSS [training: 1.111511971279118 | validation: 1.0194132083219434]
	TIME [epoch: 10.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0752226501643385		[learning rate: 0.0037226]
	Learning Rate: 0.00372256
	LOSS [training: 1.0752226501643385 | validation: 1.2384945344572003]
	TIME [epoch: 10.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9227882770357319		[learning rate: 0.0037091]
	Learning Rate: 0.00370905
	LOSS [training: 0.9227882770357319 | validation: 0.9509093292113098]
	TIME [epoch: 10.4 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8682870613484155		[learning rate: 0.0036956]
	Learning Rate: 0.00369559
	LOSS [training: 0.8682870613484155 | validation: 0.9444472001510255]
	TIME [epoch: 10.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8978358382433813		[learning rate: 0.0036822]
	Learning Rate: 0.00368218
	LOSS [training: 0.8978358382433813 | validation: 0.9935995437599034]
	TIME [epoch: 10.4 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0335351013429792		[learning rate: 0.0036688]
	Learning Rate: 0.00366882
	LOSS [training: 1.0335351013429792 | validation: 1.1301986181342105]
	TIME [epoch: 10.4 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.098126558560517		[learning rate: 0.0036555]
	Learning Rate: 0.0036555
	LOSS [training: 1.098126558560517 | validation: 1.1913106895605925]
	TIME [epoch: 10.4 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9196466283140474		[learning rate: 0.0036422]
	Learning Rate: 0.00364224
	LOSS [training: 0.9196466283140474 | validation: 0.7910219010579412]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9028727817491413		[learning rate: 0.003629]
	Learning Rate: 0.00362902
	LOSS [training: 0.9028727817491413 | validation: 1.1011173724891337]
	TIME [epoch: 10.4 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0111902493061866		[learning rate: 0.0036159]
	Learning Rate: 0.00361585
	LOSS [training: 1.0111902493061866 | validation: 0.9845727788545391]
	TIME [epoch: 10.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.895094207223422		[learning rate: 0.0036027]
	Learning Rate: 0.00360273
	LOSS [training: 0.895094207223422 | validation: 1.0181884804948143]
	TIME [epoch: 10.4 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8547893717738086		[learning rate: 0.0035897]
	Learning Rate: 0.00358965
	LOSS [training: 0.8547893717738086 | validation: 0.8115914126654542]
	TIME [epoch: 10.4 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8376431880066659		[learning rate: 0.0035766]
	Learning Rate: 0.00357663
	LOSS [training: 0.8376431880066659 | validation: 1.3311899784571728]
	TIME [epoch: 10.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0533122984316763		[learning rate: 0.0035636]
	Learning Rate: 0.00356365
	LOSS [training: 1.0533122984316763 | validation: 0.8930355583056244]
	TIME [epoch: 10.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8957189310534108		[learning rate: 0.0035507]
	Learning Rate: 0.00355072
	LOSS [training: 0.8957189310534108 | validation: 1.0647727183292517]
	TIME [epoch: 10.4 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9459221124729649		[learning rate: 0.0035378]
	Learning Rate: 0.00353783
	LOSS [training: 0.9459221124729649 | validation: 1.0819498725179362]
	TIME [epoch: 10.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9749663589139985		[learning rate: 0.003525]
	Learning Rate: 0.00352499
	LOSS [training: 0.9749663589139985 | validation: 0.8549535362267194]
	TIME [epoch: 10.4 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9493711977489809		[learning rate: 0.0035122]
	Learning Rate: 0.0035122
	LOSS [training: 0.9493711977489809 | validation: 1.0278797695831154]
	TIME [epoch: 10.4 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.943905442532424		[learning rate: 0.0034995]
	Learning Rate: 0.00349945
	LOSS [training: 0.943905442532424 | validation: 0.9522038897177347]
	TIME [epoch: 10.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.001442443322917		[learning rate: 0.0034868]
	Learning Rate: 0.00348675
	LOSS [training: 1.001442443322917 | validation: 1.2520362181291207]
	TIME [epoch: 10.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.054098691305261		[learning rate: 0.0034741]
	Learning Rate: 0.0034741
	LOSS [training: 1.054098691305261 | validation: 1.1771892548925786]
	TIME [epoch: 10.4 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8832167297652838		[learning rate: 0.0034615]
	Learning Rate: 0.00346149
	LOSS [training: 0.8832167297652838 | validation: 0.9524282048553367]
	TIME [epoch: 10.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7967173310015149		[learning rate: 0.0034489]
	Learning Rate: 0.00344893
	LOSS [training: 0.7967173310015149 | validation: 1.0655494995242238]
	TIME [epoch: 10.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9518244996039602		[learning rate: 0.0034364]
	Learning Rate: 0.00343641
	LOSS [training: 0.9518244996039602 | validation: 1.1478921122386672]
	TIME [epoch: 10.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9437955939649629		[learning rate: 0.0034239]
	Learning Rate: 0.00342394
	LOSS [training: 0.9437955939649629 | validation: 1.0954863264995396]
	TIME [epoch: 10.4 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.052201855418437		[learning rate: 0.0034115]
	Learning Rate: 0.00341152
	LOSS [training: 1.052201855418437 | validation: 0.9173914392920618]
	TIME [epoch: 10.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8868057042204056		[learning rate: 0.0033991]
	Learning Rate: 0.00339914
	LOSS [training: 0.8868057042204056 | validation: 0.8709753300800821]
	TIME [epoch: 10.4 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8120622356124148		[learning rate: 0.0033868]
	Learning Rate: 0.0033868
	LOSS [training: 0.8120622356124148 | validation: 1.0680019051762681]
	TIME [epoch: 10.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9161230611942983		[learning rate: 0.0033745]
	Learning Rate: 0.00337451
	LOSS [training: 0.9161230611942983 | validation: 0.8216380218467589]
	TIME [epoch: 10.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.806955537701518		[learning rate: 0.0033623]
	Learning Rate: 0.00336226
	LOSS [training: 0.806955537701518 | validation: 0.9490440346251782]
	TIME [epoch: 10.4 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9257414179542309		[learning rate: 0.0033501]
	Learning Rate: 0.00335006
	LOSS [training: 0.9257414179542309 | validation: 1.0193017813898941]
	TIME [epoch: 10.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9075344325383569		[learning rate: 0.0033379]
	Learning Rate: 0.0033379
	LOSS [training: 0.9075344325383569 | validation: 1.0957762645259304]
	TIME [epoch: 10.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8919557575729817		[learning rate: 0.0033258]
	Learning Rate: 0.00332579
	LOSS [training: 0.8919557575729817 | validation: 0.9475860297560784]
	TIME [epoch: 10.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9049444944456259		[learning rate: 0.0033137]
	Learning Rate: 0.00331372
	LOSS [training: 0.9049444944456259 | validation: 0.991218679879267]
	TIME [epoch: 10.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8592282788193512		[learning rate: 0.0033017]
	Learning Rate: 0.00330169
	LOSS [training: 0.8592282788193512 | validation: 0.9963321791093874]
	TIME [epoch: 10.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8369839154655931		[learning rate: 0.0032897]
	Learning Rate: 0.00328971
	LOSS [training: 0.8369839154655931 | validation: 1.0052033770214646]
	TIME [epoch: 10.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8396382398602341		[learning rate: 0.0032778]
	Learning Rate: 0.00327777
	LOSS [training: 0.8396382398602341 | validation: 0.7612421620981562]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8659793450075981		[learning rate: 0.0032659]
	Learning Rate: 0.00326588
	LOSS [training: 0.8659793450075981 | validation: 0.8679532722715368]
	TIME [epoch: 10.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9065104939981934		[learning rate: 0.003254]
	Learning Rate: 0.00325403
	LOSS [training: 0.9065104939981934 | validation: 0.8569962787589489]
	TIME [epoch: 10.4 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8270825656324885		[learning rate: 0.0032422]
	Learning Rate: 0.00324222
	LOSS [training: 0.8270825656324885 | validation: 1.3296992619226171]
	TIME [epoch: 10.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7260212453966617		[learning rate: 0.0032305]
	Learning Rate: 0.00323045
	LOSS [training: 1.7260212453966617 | validation: 1.1635361228971004]
	TIME [epoch: 10.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8169413548295384		[learning rate: 0.0032187]
	Learning Rate: 0.00321873
	LOSS [training: 0.8169413548295384 | validation: 1.1851576415006964]
	TIME [epoch: 10.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0254361528418978		[learning rate: 0.003207]
	Learning Rate: 0.00320705
	LOSS [training: 1.0254361528418978 | validation: 1.1125715988959695]
	TIME [epoch: 10.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9219300985835559		[learning rate: 0.0031954]
	Learning Rate: 0.00319541
	LOSS [training: 0.9219300985835559 | validation: 0.8015024685960705]
	TIME [epoch: 10.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8587309082710947		[learning rate: 0.0031838]
	Learning Rate: 0.00318381
	LOSS [training: 0.8587309082710947 | validation: 0.7810055940710369]
	TIME [epoch: 10.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7759686040551148		[learning rate: 0.0031723]
	Learning Rate: 0.00317226
	LOSS [training: 0.7759686040551148 | validation: 0.8197478526269584]
	TIME [epoch: 10.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8133863123687061		[learning rate: 0.0031607]
	Learning Rate: 0.00316075
	LOSS [training: 0.8133863123687061 | validation: 0.7716841826478786]
	TIME [epoch: 10.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9158771793357181		[learning rate: 0.0031493]
	Learning Rate: 0.00314927
	LOSS [training: 0.9158771793357181 | validation: 0.794804132671607]
	TIME [epoch: 10.4 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8350555001549983		[learning rate: 0.0031378]
	Learning Rate: 0.00313785
	LOSS [training: 0.8350555001549983 | validation: 1.4722633228028161]
	TIME [epoch: 10.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0405542238198717		[learning rate: 0.0031265]
	Learning Rate: 0.00312646
	LOSS [training: 1.0405542238198717 | validation: 0.8819020105259537]
	TIME [epoch: 10.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9193044821260287		[learning rate: 0.0031151]
	Learning Rate: 0.00311511
	LOSS [training: 0.9193044821260287 | validation: 0.8189635908819267]
	TIME [epoch: 10.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8236574935322489		[learning rate: 0.0031038]
	Learning Rate: 0.00310381
	LOSS [training: 0.8236574935322489 | validation: 1.4530418763466526]
	TIME [epoch: 10.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9891854263646366		[learning rate: 0.0030925]
	Learning Rate: 0.00309254
	LOSS [training: 0.9891854263646366 | validation: 0.8482959761763234]
	TIME [epoch: 10.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8982782987185859		[learning rate: 0.0030813]
	Learning Rate: 0.00308132
	LOSS [training: 0.8982782987185859 | validation: 0.9078620716252579]
	TIME [epoch: 10.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7122193369886813		[learning rate: 0.0030701]
	Learning Rate: 0.00307014
	LOSS [training: 0.7122193369886813 | validation: 0.6427629334180089]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8730052895006402		[learning rate: 0.003059]
	Learning Rate: 0.003059
	LOSS [training: 0.8730052895006402 | validation: 0.8142182041991586]
	TIME [epoch: 10.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8064115527176468		[learning rate: 0.0030479]
	Learning Rate: 0.0030479
	LOSS [training: 0.8064115527176468 | validation: 0.6434218113411015]
	TIME [epoch: 10.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7955231579987618		[learning rate: 0.0030368]
	Learning Rate: 0.00303683
	LOSS [training: 0.7955231579987618 | validation: 0.99640638476851]
	TIME [epoch: 10.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8562829784086571		[learning rate: 0.0030258]
	Learning Rate: 0.00302581
	LOSS [training: 0.8562829784086571 | validation: 1.075324218339364]
	TIME [epoch: 10.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8910127664504234		[learning rate: 0.0030148]
	Learning Rate: 0.00301483
	LOSS [training: 0.8910127664504234 | validation: 0.6663613393067742]
	TIME [epoch: 10.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8205192105665795		[learning rate: 0.0030039]
	Learning Rate: 0.00300389
	LOSS [training: 0.8205192105665795 | validation: 0.8909218804624024]
	TIME [epoch: 10.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8745113428503976		[learning rate: 0.002993]
	Learning Rate: 0.00299299
	LOSS [training: 0.8745113428503976 | validation: 0.904593033698178]
	TIME [epoch: 10.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9720649058286004		[learning rate: 0.0029821]
	Learning Rate: 0.00298213
	LOSS [training: 0.9720649058286004 | validation: 1.0960957292932028]
	TIME [epoch: 10.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8624722562978195		[learning rate: 0.0029713]
	Learning Rate: 0.00297131
	LOSS [training: 0.8624722562978195 | validation: 0.846798675215526]
	TIME [epoch: 10.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8077509245573014		[learning rate: 0.0029605]
	Learning Rate: 0.00296052
	LOSS [training: 0.8077509245573014 | validation: 0.9361197475426092]
	TIME [epoch: 10.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7661034146020947		[learning rate: 0.0029498]
	Learning Rate: 0.00294978
	LOSS [training: 0.7661034146020947 | validation: 1.1131598541770582]
	TIME [epoch: 10.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7804887005794856		[learning rate: 0.0029391]
	Learning Rate: 0.00293907
	LOSS [training: 0.7804887005794856 | validation: 1.0451371500394349]
	TIME [epoch: 10.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9348598069451437		[learning rate: 0.0029284]
	Learning Rate: 0.00292841
	LOSS [training: 0.9348598069451437 | validation: 1.0859179799475709]
	TIME [epoch: 10.4 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.001868570234318		[learning rate: 0.0029178]
	Learning Rate: 0.00291778
	LOSS [training: 1.001868570234318 | validation: 0.9872722061453607]
	TIME [epoch: 10.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8907976097440431		[learning rate: 0.0029072]
	Learning Rate: 0.00290719
	LOSS [training: 0.8907976097440431 | validation: 1.028528689131335]
	TIME [epoch: 10.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8661581224654682		[learning rate: 0.0028966]
	Learning Rate: 0.00289664
	LOSS [training: 0.8661581224654682 | validation: 0.9173530660669796]
	TIME [epoch: 10.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.905277798959338		[learning rate: 0.0028861]
	Learning Rate: 0.00288613
	LOSS [training: 0.905277798959338 | validation: 0.9772820924598876]
	TIME [epoch: 10.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8933109050687695		[learning rate: 0.0028757]
	Learning Rate: 0.00287566
	LOSS [training: 0.8933109050687695 | validation: 1.011461985628337]
	TIME [epoch: 10.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8720149121630865		[learning rate: 0.0028652]
	Learning Rate: 0.00286522
	LOSS [training: 0.8720149121630865 | validation: 0.8869008534202394]
	TIME [epoch: 10.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.895799988867758		[learning rate: 0.0028548]
	Learning Rate: 0.00285482
	LOSS [training: 0.895799988867758 | validation: 0.9689789007688414]
	TIME [epoch: 10.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7954620328189149		[learning rate: 0.0028445]
	Learning Rate: 0.00284446
	LOSS [training: 0.7954620328189149 | validation: 0.819797500832621]
	TIME [epoch: 10.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8764136085112005		[learning rate: 0.0028341]
	Learning Rate: 0.00283414
	LOSS [training: 0.8764136085112005 | validation: 0.9508850757409687]
	TIME [epoch: 10.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9178872123743961		[learning rate: 0.0028239]
	Learning Rate: 0.00282385
	LOSS [training: 0.9178872123743961 | validation: 0.8095231943881862]
	TIME [epoch: 10.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8964375147856318		[learning rate: 0.0028136]
	Learning Rate: 0.00281361
	LOSS [training: 0.8964375147856318 | validation: 0.8271463360184075]
	TIME [epoch: 10.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.834983270598485		[learning rate: 0.0028034]
	Learning Rate: 0.00280339
	LOSS [training: 0.834983270598485 | validation: 1.0576581228010165]
	TIME [epoch: 10.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8681417153322581		[learning rate: 0.0027932]
	Learning Rate: 0.00279322
	LOSS [training: 0.8681417153322581 | validation: 0.8181217901537104]
	TIME [epoch: 10.4 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8462240456225747		[learning rate: 0.0027831]
	Learning Rate: 0.00278308
	LOSS [training: 0.8462240456225747 | validation: 0.9978578736843744]
	TIME [epoch: 10.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9183417376220004		[learning rate: 0.002773]
	Learning Rate: 0.00277298
	LOSS [training: 0.9183417376220004 | validation: 0.8080872861010172]
	TIME [epoch: 10.4 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8728204461694865		[learning rate: 0.0027629]
	Learning Rate: 0.00276292
	LOSS [training: 0.8728204461694865 | validation: 1.1168406249903624]
	TIME [epoch: 10.4 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.864618906345876		[learning rate: 0.0027529]
	Learning Rate: 0.00275289
	LOSS [training: 0.864618906345876 | validation: 1.2175668690451478]
	TIME [epoch: 10.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9892675573242309		[learning rate: 0.0027429]
	Learning Rate: 0.0027429
	LOSS [training: 0.9892675573242309 | validation: 0.8282387935179754]
	TIME [epoch: 10.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8754262430321168		[learning rate: 0.0027329]
	Learning Rate: 0.00273295
	LOSS [training: 0.8754262430321168 | validation: 1.0146484139218137]
	TIME [epoch: 10.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9568930325072866		[learning rate: 0.002723]
	Learning Rate: 0.00272303
	LOSS [training: 0.9568930325072866 | validation: 1.0891961506874257]
	TIME [epoch: 10.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8345435933114057		[learning rate: 0.0027131]
	Learning Rate: 0.00271315
	LOSS [training: 0.8345435933114057 | validation: 0.8352280532307091]
	TIME [epoch: 10.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7840214411981674		[learning rate: 0.0027033]
	Learning Rate: 0.0027033
	LOSS [training: 0.7840214411981674 | validation: 0.9296562779422435]
	TIME [epoch: 10.4 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8856021106783911		[learning rate: 0.0026935]
	Learning Rate: 0.00269349
	LOSS [training: 0.8856021106783911 | validation: 1.2743449924999934]
	TIME [epoch: 10.4 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8568540667197257		[learning rate: 0.0026837]
	Learning Rate: 0.00268372
	LOSS [training: 0.8568540667197257 | validation: 0.9055179989216908]
	TIME [epoch: 10.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8194605051368683		[learning rate: 0.002674]
	Learning Rate: 0.00267398
	LOSS [training: 0.8194605051368683 | validation: 0.7903604973705385]
	TIME [epoch: 10.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8339160528838778		[learning rate: 0.0026643]
	Learning Rate: 0.00266427
	LOSS [training: 0.8339160528838778 | validation: 0.8905561028943929]
	TIME [epoch: 10.4 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8157184416068807		[learning rate: 0.0026546]
	Learning Rate: 0.00265461
	LOSS [training: 0.8157184416068807 | validation: 0.9391566900060031]
	TIME [epoch: 10.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7940213254663241		[learning rate: 0.002645]
	Learning Rate: 0.00264497
	LOSS [training: 0.7940213254663241 | validation: 0.8843196637995828]
	TIME [epoch: 10.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8357623828126373		[learning rate: 0.0026354]
	Learning Rate: 0.00263537
	LOSS [training: 0.8357623828126373 | validation: 1.017260938169645]
	TIME [epoch: 10.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7954198132631088		[learning rate: 0.0026258]
	Learning Rate: 0.00262581
	LOSS [training: 0.7954198132631088 | validation: 0.8503036474517555]
	TIME [epoch: 10.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8902297366042887		[learning rate: 0.0026163]
	Learning Rate: 0.00261628
	LOSS [training: 0.8902297366042887 | validation: 0.9985967213958895]
	TIME [epoch: 10.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.795375721203083		[learning rate: 0.0026068]
	Learning Rate: 0.00260679
	LOSS [training: 0.795375721203083 | validation: 0.9496455133996036]
	TIME [epoch: 10.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8549450495807227		[learning rate: 0.0025973]
	Learning Rate: 0.00259733
	LOSS [training: 0.8549450495807227 | validation: 0.7432040773207388]
	TIME [epoch: 10.4 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7779539857361929		[learning rate: 0.0025879]
	Learning Rate: 0.0025879
	LOSS [training: 0.7779539857361929 | validation: 0.6645507461490123]
	TIME [epoch: 10.4 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8262652740722782		[learning rate: 0.0025785]
	Learning Rate: 0.00257851
	LOSS [training: 0.8262652740722782 | validation: 0.9012182010246643]
	TIME [epoch: 10.4 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7895180999928755		[learning rate: 0.0025691]
	Learning Rate: 0.00256915
	LOSS [training: 0.7895180999928755 | validation: 0.9906858568390235]
	TIME [epoch: 10.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.811725738024552		[learning rate: 0.0025598]
	Learning Rate: 0.00255983
	LOSS [training: 0.811725738024552 | validation: 0.8348146598840583]
	TIME [epoch: 10.4 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7561699963126921		[learning rate: 0.0025505]
	Learning Rate: 0.00255054
	LOSS [training: 0.7561699963126921 | validation: 0.8013809087120302]
	TIME [epoch: 10.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8144688923562216		[learning rate: 0.0025413]
	Learning Rate: 0.00254128
	LOSS [training: 0.8144688923562216 | validation: 0.9109637669381699]
	TIME [epoch: 10.4 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7451835698048751		[learning rate: 0.0025321]
	Learning Rate: 0.00253206
	LOSS [training: 0.7451835698048751 | validation: 0.9387089693394814]
	TIME [epoch: 10.4 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8916979697223605		[learning rate: 0.0025229]
	Learning Rate: 0.00252287
	LOSS [training: 0.8916979697223605 | validation: 1.025052658221493]
	TIME [epoch: 10.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8198683095780709		[learning rate: 0.0025137]
	Learning Rate: 0.00251371
	LOSS [training: 0.8198683095780709 | validation: 0.8050747628169179]
	TIME [epoch: 10.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707955850178545		[learning rate: 0.0025046]
	Learning Rate: 0.00250459
	LOSS [training: 0.7707955850178545 | validation: 0.8495757228849601]
	TIME [epoch: 10.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7895281001860454		[learning rate: 0.0024955]
	Learning Rate: 0.0024955
	LOSS [training: 0.7895281001860454 | validation: 1.0786437807472167]
	TIME [epoch: 10.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.743894563101755		[learning rate: 0.0024864]
	Learning Rate: 0.00248645
	LOSS [training: 0.743894563101755 | validation: 0.7745008790550835]
	TIME [epoch: 10.4 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8193551032457431		[learning rate: 0.0024774]
	Learning Rate: 0.00247742
	LOSS [training: 0.8193551032457431 | validation: 1.0485000539343399]
	TIME [epoch: 10.4 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8263919515455832		[learning rate: 0.0024684]
	Learning Rate: 0.00246843
	LOSS [training: 0.8263919515455832 | validation: 0.9970090131786437]
	TIME [epoch: 10.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8192952570962889		[learning rate: 0.0024595]
	Learning Rate: 0.00245947
	LOSS [training: 0.8192952570962889 | validation: 0.7267759214607901]
	TIME [epoch: 10.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7599208891192071		[learning rate: 0.0024505]
	Learning Rate: 0.00245055
	LOSS [training: 0.7599208891192071 | validation: 0.8874741960439707]
	TIME [epoch: 10.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7085647456133535		[learning rate: 0.0024417]
	Learning Rate: 0.00244165
	LOSS [training: 0.7085647456133535 | validation: 1.398850425452432]
	TIME [epoch: 10.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8859742559774558		[learning rate: 0.0024328]
	Learning Rate: 0.00243279
	LOSS [training: 0.8859742559774558 | validation: 0.8767552335344706]
	TIME [epoch: 10.4 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7590716319318153		[learning rate: 0.002424]
	Learning Rate: 0.00242396
	LOSS [training: 0.7590716319318153 | validation: 1.0070074426092195]
	TIME [epoch: 10.4 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.855654796399371		[learning rate: 0.0024152]
	Learning Rate: 0.00241517
	LOSS [training: 0.855654796399371 | validation: 0.7639571855318238]
	TIME [epoch: 10.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415703689967291		[learning rate: 0.0024064]
	Learning Rate: 0.0024064
	LOSS [training: 0.7415703689967291 | validation: 0.9406917571479539]
	TIME [epoch: 10.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7021629718109766		[learning rate: 0.0023977]
	Learning Rate: 0.00239767
	LOSS [training: 0.7021629718109766 | validation: 1.1400604771112393]
	TIME [epoch: 10.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7659496715047289		[learning rate: 0.002389]
	Learning Rate: 0.00238897
	LOSS [training: 0.7659496715047289 | validation: 0.7740483099125203]
	TIME [epoch: 10.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.679880199336872		[learning rate: 0.0023803]
	Learning Rate: 0.0023803
	LOSS [training: 0.679880199336872 | validation: 1.22844456023529]
	TIME [epoch: 10.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8299644826192211		[learning rate: 0.0023717]
	Learning Rate: 0.00237166
	LOSS [training: 0.8299644826192211 | validation: 0.9110626160612738]
	TIME [epoch: 10.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8071367656937332		[learning rate: 0.0023631]
	Learning Rate: 0.00236305
	LOSS [training: 0.8071367656937332 | validation: 0.8311547545528589]
	TIME [epoch: 10.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415926777646797		[learning rate: 0.0023545]
	Learning Rate: 0.00235448
	LOSS [training: 0.7415926777646797 | validation: 0.7141287768069409]
	TIME [epoch: 10.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6962349130924474		[learning rate: 0.0023459]
	Learning Rate: 0.00234593
	LOSS [training: 0.6962349130924474 | validation: 1.0705952933255387]
	TIME [epoch: 10.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7948146277970933		[learning rate: 0.0023374]
	Learning Rate: 0.00233742
	LOSS [training: 0.7948146277970933 | validation: 0.8101133624790368]
	TIME [epoch: 10.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6601383471996836		[learning rate: 0.0023289]
	Learning Rate: 0.00232894
	LOSS [training: 0.6601383471996836 | validation: 0.7934887296466895]
	TIME [epoch: 10.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.671289203919612		[learning rate: 0.0023205]
	Learning Rate: 0.00232049
	LOSS [training: 0.671289203919612 | validation: 0.7893219577831978]
	TIME [epoch: 10.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7882957305086322		[learning rate: 0.0023121]
	Learning Rate: 0.00231206
	LOSS [training: 0.7882957305086322 | validation: 0.9579927314972474]
	TIME [epoch: 10.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8670404312915952		[learning rate: 0.0023037]
	Learning Rate: 0.00230367
	LOSS [training: 0.8670404312915952 | validation: 1.0689189881935732]
	TIME [epoch: 10.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7905679850683208		[learning rate: 0.0022953]
	Learning Rate: 0.00229531
	LOSS [training: 0.7905679850683208 | validation: 0.7213330064783604]
	TIME [epoch: 10.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8099358353498932		[learning rate: 0.002287]
	Learning Rate: 0.00228698
	LOSS [training: 0.8099358353498932 | validation: 0.8428062712745444]
	TIME [epoch: 10.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7468424663453579		[learning rate: 0.0022787]
	Learning Rate: 0.00227868
	LOSS [training: 0.7468424663453579 | validation: 0.8219362235247892]
	TIME [epoch: 10.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7846987174769876		[learning rate: 0.0022704]
	Learning Rate: 0.00227042
	LOSS [training: 0.7846987174769876 | validation: 1.0354695747367904]
	TIME [epoch: 10.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7564857871255294		[learning rate: 0.0022622]
	Learning Rate: 0.00226218
	LOSS [training: 0.7564857871255294 | validation: 0.87696265951102]
	TIME [epoch: 10.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025987478121118		[learning rate: 0.002254]
	Learning Rate: 0.00225397
	LOSS [training: 0.7025987478121118 | validation: 0.9638666421803238]
	TIME [epoch: 10.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.806854424691321		[learning rate: 0.0022458]
	Learning Rate: 0.00224579
	LOSS [training: 0.806854424691321 | validation: 0.9131686068242542]
	TIME [epoch: 10.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7510500764477372		[learning rate: 0.0022376]
	Learning Rate: 0.00223764
	LOSS [training: 0.7510500764477372 | validation: 0.8836223717349597]
	TIME [epoch: 10.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6925980784862567		[learning rate: 0.0022295]
	Learning Rate: 0.00222952
	LOSS [training: 0.6925980784862567 | validation: 1.0996704754208668]
	TIME [epoch: 10.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8835013016126844		[learning rate: 0.0022214]
	Learning Rate: 0.00222142
	LOSS [training: 0.8835013016126844 | validation: 0.8501664087722263]
	TIME [epoch: 10.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7243219610540523		[learning rate: 0.0022134]
	Learning Rate: 0.00221336
	LOSS [training: 0.7243219610540523 | validation: 0.9037412477067563]
	TIME [epoch: 10.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7330516961538687		[learning rate: 0.0022053]
	Learning Rate: 0.00220533
	LOSS [training: 0.7330516961538687 | validation: 0.8081777498600385]
	TIME [epoch: 10.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7023435241292713		[learning rate: 0.0021973]
	Learning Rate: 0.00219733
	LOSS [training: 0.7023435241292713 | validation: 0.8599240473667302]
	TIME [epoch: 10.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7127074488853491		[learning rate: 0.0021894]
	Learning Rate: 0.00218935
	LOSS [training: 0.7127074488853491 | validation: 0.808534904230456]
	TIME [epoch: 10.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7170990204629148		[learning rate: 0.0021814]
	Learning Rate: 0.00218141
	LOSS [training: 0.7170990204629148 | validation: 0.8733218744679424]
	TIME [epoch: 10.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7493542512901373		[learning rate: 0.0021735]
	Learning Rate: 0.00217349
	LOSS [training: 0.7493542512901373 | validation: 0.9920168614371477]
	TIME [epoch: 10.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8015243608032598		[learning rate: 0.0021656]
	Learning Rate: 0.0021656
	LOSS [training: 0.8015243608032598 | validation: 0.8639258992403177]
	TIME [epoch: 10.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8012036869105966		[learning rate: 0.0021577]
	Learning Rate: 0.00215774
	LOSS [training: 0.8012036869105966 | validation: 0.9130327268800794]
	TIME [epoch: 10.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8320078170767484		[learning rate: 0.0021499]
	Learning Rate: 0.00214991
	LOSS [training: 0.8320078170767484 | validation: 0.8429795424084702]
	TIME [epoch: 10.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7863664889865831		[learning rate: 0.0021421]
	Learning Rate: 0.00214211
	LOSS [training: 0.7863664889865831 | validation: 0.8936183009944648]
	TIME [epoch: 10.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024522648113509		[learning rate: 0.0021343]
	Learning Rate: 0.00213434
	LOSS [training: 0.7024522648113509 | validation: 0.8561109001267926]
	TIME [epoch: 10.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.714312032720368		[learning rate: 0.0021266]
	Learning Rate: 0.00212659
	LOSS [training: 0.714312032720368 | validation: 0.908744938452225]
	TIME [epoch: 10.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7160738996278828		[learning rate: 0.0021189]
	Learning Rate: 0.00211887
	LOSS [training: 0.7160738996278828 | validation: 0.7374946943104373]
	TIME [epoch: 10.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6812773398818287		[learning rate: 0.0021112]
	Learning Rate: 0.00211119
	LOSS [training: 0.6812773398818287 | validation: 0.799246776049026]
	TIME [epoch: 10.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6996636926828456		[learning rate: 0.0021035]
	Learning Rate: 0.00210352
	LOSS [training: 0.6996636926828456 | validation: 0.7910287768324595]
	TIME [epoch: 10.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8094758298898448		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.8094758298898448 | validation: 0.7469037409090791]
	TIME [epoch: 10.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.748557128321242		[learning rate: 0.0020883]
	Learning Rate: 0.00208828
	LOSS [training: 0.748557128321242 | validation: 0.8615429831815001]
	TIME [epoch: 10.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6644749200746481		[learning rate: 0.0020807]
	Learning Rate: 0.00208071
	LOSS [training: 0.6644749200746481 | validation: 0.7712768884802341]
	TIME [epoch: 10.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6415543776354486		[learning rate: 0.0020732]
	Learning Rate: 0.00207315
	LOSS [training: 0.6415543776354486 | validation: 0.8740900619463152]
	TIME [epoch: 10.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6590948624611258		[learning rate: 0.0020656]
	Learning Rate: 0.00206563
	LOSS [training: 0.6590948624611258 | validation: 0.8276941135052277]
	TIME [epoch: 10.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7078720691553723		[learning rate: 0.0020581]
	Learning Rate: 0.00205813
	LOSS [training: 0.7078720691553723 | validation: 0.8586812130762241]
	TIME [epoch: 10.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7317201119147698		[learning rate: 0.0020507]
	Learning Rate: 0.00205067
	LOSS [training: 0.7317201119147698 | validation: 0.7291646509528914]
	TIME [epoch: 10.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7637716630387649		[learning rate: 0.0020432]
	Learning Rate: 0.00204322
	LOSS [training: 0.7637716630387649 | validation: 0.8233145717214865]
	TIME [epoch: 10.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7521365535709695		[learning rate: 0.0020358]
	Learning Rate: 0.00203581
	LOSS [training: 0.7521365535709695 | validation: 0.892083338061741]
	TIME [epoch: 10.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7489703782283093		[learning rate: 0.0020284]
	Learning Rate: 0.00202842
	LOSS [training: 0.7489703782283093 | validation: 0.8033694491894013]
	TIME [epoch: 10.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.668054647396829		[learning rate: 0.0020211]
	Learning Rate: 0.00202106
	LOSS [training: 0.668054647396829 | validation: 0.8083940260607793]
	TIME [epoch: 10.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6764826746375154		[learning rate: 0.0020137]
	Learning Rate: 0.00201372
	LOSS [training: 0.6764826746375154 | validation: 0.8173949140926107]
	TIME [epoch: 10.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.767619451071171		[learning rate: 0.0020064]
	Learning Rate: 0.00200642
	LOSS [training: 0.767619451071171 | validation: 0.8013129190222026]
	TIME [epoch: 10.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6208789395464589		[learning rate: 0.0019991]
	Learning Rate: 0.00199913
	LOSS [training: 0.6208789395464589 | validation: 0.7294991649057176]
	TIME [epoch: 10.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6877074762099842		[learning rate: 0.0019919]
	Learning Rate: 0.00199188
	LOSS [training: 0.6877074762099842 | validation: 0.7998284923895475]
	TIME [epoch: 10.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6703314365904595		[learning rate: 0.0019847]
	Learning Rate: 0.00198465
	LOSS [training: 0.6703314365904595 | validation: 0.7283098429406363]
	TIME [epoch: 10.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7115255166568023		[learning rate: 0.0019774]
	Learning Rate: 0.00197745
	LOSS [training: 0.7115255166568023 | validation: 0.6123192771257892]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474775512393748		[learning rate: 0.0019703]
	Learning Rate: 0.00197027
	LOSS [training: 0.6474775512393748 | validation: 1.0305118939265956]
	TIME [epoch: 10.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6796761181454574		[learning rate: 0.0019631]
	Learning Rate: 0.00196312
	LOSS [training: 0.6796761181454574 | validation: 0.7721081359011375]
	TIME [epoch: 10.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7712274588792143		[learning rate: 0.001956]
	Learning Rate: 0.001956
	LOSS [training: 0.7712274588792143 | validation: 0.8449830608471937]
	TIME [epoch: 10.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.704878087281757		[learning rate: 0.0019489]
	Learning Rate: 0.0019489
	LOSS [training: 0.704878087281757 | validation: 0.9822782062302747]
	TIME [epoch: 10.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6961798082944469		[learning rate: 0.0019418]
	Learning Rate: 0.00194183
	LOSS [training: 0.6961798082944469 | validation: 0.8506548073652196]
	TIME [epoch: 10.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7360089593892717		[learning rate: 0.0019348]
	Learning Rate: 0.00193478
	LOSS [training: 0.7360089593892717 | validation: 0.6284531763832171]
	TIME [epoch: 10.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6402424948443689		[learning rate: 0.0019278]
	Learning Rate: 0.00192776
	LOSS [training: 0.6402424948443689 | validation: 0.7437467342767242]
	TIME [epoch: 10.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5041317085528507		[learning rate: 0.0019208]
	Learning Rate: 0.00192076
	LOSS [training: 1.5041317085528507 | validation: 3.3375286869350105]
	TIME [epoch: 10.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8349801625128392		[learning rate: 0.0019138]
	Learning Rate: 0.00191379
	LOSS [training: 1.8349801625128392 | validation: 0.6929471617346716]
	TIME [epoch: 10.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7560384440336808		[learning rate: 0.0019068]
	Learning Rate: 0.00190685
	LOSS [training: 0.7560384440336808 | validation: 0.6759647748306903]
	TIME [epoch: 10.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7242252661533516		[learning rate: 0.0018999]
	Learning Rate: 0.00189993
	LOSS [training: 0.7242252661533516 | validation: 0.7971161283371246]
	TIME [epoch: 10.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6928263077082362		[learning rate: 0.001893]
	Learning Rate: 0.00189303
	LOSS [training: 0.6928263077082362 | validation: 0.7796359710332831]
	TIME [epoch: 10.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6437069730099679		[learning rate: 0.0018862]
	Learning Rate: 0.00188616
	LOSS [training: 0.6437069730099679 | validation: 0.5907543279962573]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6784943775667354		[learning rate: 0.0018793]
	Learning Rate: 0.00187932
	LOSS [training: 0.6784943775667354 | validation: 0.7328056936620749]
	TIME [epoch: 10.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7251253116652698		[learning rate: 0.0018725]
	Learning Rate: 0.0018725
	LOSS [training: 0.7251253116652698 | validation: 0.6106812845670295]
	TIME [epoch: 10.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7196981293547913		[learning rate: 0.0018657]
	Learning Rate: 0.0018657
	LOSS [training: 0.7196981293547913 | validation: 0.8134773465114594]
	TIME [epoch: 10.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6368504461616615		[learning rate: 0.0018589]
	Learning Rate: 0.00185893
	LOSS [training: 0.6368504461616615 | validation: 0.6764656053474529]
	TIME [epoch: 10.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578194607862898		[learning rate: 0.0018522]
	Learning Rate: 0.00185218
	LOSS [training: 0.6578194607862898 | validation: 0.6574187255196068]
	TIME [epoch: 10.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7087058670589319		[learning rate: 0.0018455]
	Learning Rate: 0.00184546
	LOSS [training: 0.7087058670589319 | validation: 0.7533087673596179]
	TIME [epoch: 10.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6220257973971375		[learning rate: 0.0018388]
	Learning Rate: 0.00183877
	LOSS [training: 0.6220257973971375 | validation: 0.6896119492395346]
	TIME [epoch: 10.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6880290390833107		[learning rate: 0.0018321]
	Learning Rate: 0.00183209
	LOSS [training: 0.6880290390833107 | validation: 0.7670179224380342]
	TIME [epoch: 10.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.630208470152811		[learning rate: 0.0018254]
	Learning Rate: 0.00182544
	LOSS [training: 0.630208470152811 | validation: 0.8254231753428559]
	TIME [epoch: 10.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7175208934643276		[learning rate: 0.0018188]
	Learning Rate: 0.00181882
	LOSS [training: 0.7175208934643276 | validation: 0.7648222539619838]
	TIME [epoch: 10.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6517157420237158		[learning rate: 0.0018122]
	Learning Rate: 0.00181222
	LOSS [training: 0.6517157420237158 | validation: 0.7108764677310796]
	TIME [epoch: 10.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6543329905074142		[learning rate: 0.0018056]
	Learning Rate: 0.00180564
	LOSS [training: 0.6543329905074142 | validation: 0.8030801704938534]
	TIME [epoch: 10.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6647923158328787		[learning rate: 0.0017991]
	Learning Rate: 0.00179909
	LOSS [training: 0.6647923158328787 | validation: 0.7969386976136855]
	TIME [epoch: 10.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6513420919446602		[learning rate: 0.0017926]
	Learning Rate: 0.00179256
	LOSS [training: 0.6513420919446602 | validation: 0.9011172524260989]
	TIME [epoch: 10.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6271498330311079		[learning rate: 0.0017861]
	Learning Rate: 0.00178605
	LOSS [training: 0.6271498330311079 | validation: 0.7507934119120687]
	TIME [epoch: 10.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7157612480082987		[learning rate: 0.0017796]
	Learning Rate: 0.00177957
	LOSS [training: 0.7157612480082987 | validation: 0.776646813422677]
	TIME [epoch: 10.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6853459403350908		[learning rate: 0.0017731]
	Learning Rate: 0.00177311
	LOSS [training: 0.6853459403350908 | validation: 1.0539241973317692]
	TIME [epoch: 10.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6978162713381904		[learning rate: 0.0017667]
	Learning Rate: 0.00176668
	LOSS [training: 0.6978162713381904 | validation: 0.7574061514231462]
	TIME [epoch: 10.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7163579342619089		[learning rate: 0.0017603]
	Learning Rate: 0.00176027
	LOSS [training: 0.7163579342619089 | validation: 0.8428000350324721]
	TIME [epoch: 10.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6792221033310044		[learning rate: 0.0017539]
	Learning Rate: 0.00175388
	LOSS [training: 0.6792221033310044 | validation: 0.776587599194903]
	TIME [epoch: 10.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398238894707986		[learning rate: 0.0017475]
	Learning Rate: 0.00174752
	LOSS [training: 0.6398238894707986 | validation: 0.787586483826741]
	TIME [epoch: 10.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280321938040482		[learning rate: 0.0017412]
	Learning Rate: 0.00174117
	LOSS [training: 0.6280321938040482 | validation: 0.6424855808468797]
	TIME [epoch: 10.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7190497165056572		[learning rate: 0.0017349]
	Learning Rate: 0.00173486
	LOSS [training: 0.7190497165056572 | validation: 0.7635492879796004]
	TIME [epoch: 10.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6220288214408488		[learning rate: 0.0017286]
	Learning Rate: 0.00172856
	LOSS [training: 0.6220288214408488 | validation: 0.7001714543294868]
	TIME [epoch: 10.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7184446435224421		[learning rate: 0.0017223]
	Learning Rate: 0.00172229
	LOSS [training: 0.7184446435224421 | validation: 0.8082532653030902]
	TIME [epoch: 10.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6584744709087582		[learning rate: 0.001716]
	Learning Rate: 0.00171604
	LOSS [training: 0.6584744709087582 | validation: 0.8270634922147875]
	TIME [epoch: 10.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.688111483183122		[learning rate: 0.0017098]
	Learning Rate: 0.00170981
	LOSS [training: 0.688111483183122 | validation: 1.1606247678221902]
	TIME [epoch: 10.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7534422244391606		[learning rate: 0.0017036]
	Learning Rate: 0.0017036
	LOSS [training: 0.7534422244391606 | validation: 0.7195180996404144]
	TIME [epoch: 10.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6394712857068999		[learning rate: 0.0016974]
	Learning Rate: 0.00169742
	LOSS [training: 0.6394712857068999 | validation: 0.5776985903692454]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245812451830928		[learning rate: 0.0016913]
	Learning Rate: 0.00169126
	LOSS [training: 0.6245812451830928 | validation: 0.7291268113066727]
	TIME [epoch: 10.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6305395267373681		[learning rate: 0.0016851]
	Learning Rate: 0.00168512
	LOSS [training: 0.6305395267373681 | validation: 0.6351002923113387]
	TIME [epoch: 10.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6149978279919174		[learning rate: 0.001679]
	Learning Rate: 0.00167901
	LOSS [training: 0.6149978279919174 | validation: 0.5539763353817204]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.622252354474832		[learning rate: 0.0016729]
	Learning Rate: 0.00167291
	LOSS [training: 0.622252354474832 | validation: 0.6545501077884899]
	TIME [epoch: 10.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6664356402826426		[learning rate: 0.0016668]
	Learning Rate: 0.00166684
	LOSS [training: 0.6664356402826426 | validation: 0.5875803200708902]
	TIME [epoch: 10.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5811980217015174		[learning rate: 0.0016608]
	Learning Rate: 0.00166079
	LOSS [training: 0.5811980217015174 | validation: 0.7816476560815077]
	TIME [epoch: 10.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7225613247557885		[learning rate: 0.0016548]
	Learning Rate: 0.00165477
	LOSS [training: 0.7225613247557885 | validation: 0.734780036396618]
	TIME [epoch: 10.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7086562372645481		[learning rate: 0.0016488]
	Learning Rate: 0.00164876
	LOSS [training: 0.7086562372645481 | validation: 0.7925938968997238]
	TIME [epoch: 10.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6186705809238775		[learning rate: 0.0016428]
	Learning Rate: 0.00164278
	LOSS [training: 0.6186705809238775 | validation: 0.5598570735718589]
	TIME [epoch: 10.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5513729705285457		[learning rate: 0.0016368]
	Learning Rate: 0.00163682
	LOSS [training: 0.5513729705285457 | validation: 0.7631405688463557]
	TIME [epoch: 10.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7059369347046394		[learning rate: 0.0016309]
	Learning Rate: 0.00163088
	LOSS [training: 0.7059369347046394 | validation: 0.7240780262836919]
	TIME [epoch: 10.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6741581247018626		[learning rate: 0.001625]
	Learning Rate: 0.00162496
	LOSS [training: 0.6741581247018626 | validation: 0.5300976363217853]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6145697546430385		[learning rate: 0.0016191]
	Learning Rate: 0.00161906
	LOSS [training: 0.6145697546430385 | validation: 0.6990046997922638]
	TIME [epoch: 10.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6524903134380355		[learning rate: 0.0016132]
	Learning Rate: 0.00161319
	LOSS [training: 0.6524903134380355 | validation: 0.6214991198633874]
	TIME [epoch: 10.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6180763357291565		[learning rate: 0.0016073]
	Learning Rate: 0.00160733
	LOSS [training: 0.6180763357291565 | validation: 0.5835761001024432]
	TIME [epoch: 10.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.683189379789923		[learning rate: 0.0016015]
	Learning Rate: 0.0016015
	LOSS [training: 0.683189379789923 | validation: 0.7178160546610942]
	TIME [epoch: 10.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6167151345569988		[learning rate: 0.0015957]
	Learning Rate: 0.00159569
	LOSS [training: 0.6167151345569988 | validation: 0.8708587543305829]
	TIME [epoch: 10.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6713341168736269		[learning rate: 0.0015899]
	Learning Rate: 0.00158989
	LOSS [training: 0.6713341168736269 | validation: 1.0716387789714943]
	TIME [epoch: 10.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578347969584308		[learning rate: 0.0015841]
	Learning Rate: 0.00158413
	LOSS [training: 0.6578347969584308 | validation: 0.7793023807988589]
	TIME [epoch: 10.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456796721205835		[learning rate: 0.0015784]
	Learning Rate: 0.00157838
	LOSS [training: 0.6456796721205835 | validation: 0.827504190345818]
	TIME [epoch: 10.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6491346305956998		[learning rate: 0.0015726]
	Learning Rate: 0.00157265
	LOSS [training: 0.6491346305956998 | validation: 0.5597495566884182]
	TIME [epoch: 10.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5880405853547483		[learning rate: 0.0015669]
	Learning Rate: 0.00156694
	LOSS [training: 0.5880405853547483 | validation: 0.699330146199067]
	TIME [epoch: 10.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5909997897841667		[learning rate: 0.0015613]
	Learning Rate: 0.00156125
	LOSS [training: 0.5909997897841667 | validation: 0.621407712830124]
	TIME [epoch: 10.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.561879565783322		[learning rate: 0.0015556]
	Learning Rate: 0.00155559
	LOSS [training: 0.561879565783322 | validation: 0.7306020166047273]
	TIME [epoch: 10.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6521152628491926		[learning rate: 0.0015499]
	Learning Rate: 0.00154994
	LOSS [training: 0.6521152628491926 | validation: 0.6238153513830658]
	TIME [epoch: 10.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5889658136736453		[learning rate: 0.0015443]
	Learning Rate: 0.00154432
	LOSS [training: 0.5889658136736453 | validation: 0.541456913017314]
	TIME [epoch: 10.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6179786628144168		[learning rate: 0.0015387]
	Learning Rate: 0.00153871
	LOSS [training: 0.6179786628144168 | validation: 0.6017748145800689]
	TIME [epoch: 10.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6059725103341501		[learning rate: 0.0015331]
	Learning Rate: 0.00153313
	LOSS [training: 0.6059725103341501 | validation: 0.5380950927829063]
	TIME [epoch: 10.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5998477360077458		[learning rate: 0.0015276]
	Learning Rate: 0.00152757
	LOSS [training: 0.5998477360077458 | validation: 0.5610098512795537]
	TIME [epoch: 10.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5970517831403026		[learning rate: 0.001522]
	Learning Rate: 0.00152202
	LOSS [training: 0.5970517831403026 | validation: 0.5557442255209011]
	TIME [epoch: 10.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.592622838628938		[learning rate: 0.0015165]
	Learning Rate: 0.0015165
	LOSS [training: 0.592622838628938 | validation: 0.6726702211042241]
	TIME [epoch: 10.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.569412741793507		[learning rate: 0.001511]
	Learning Rate: 0.001511
	LOSS [training: 0.569412741793507 | validation: 0.6216240546056944]
	TIME [epoch: 10.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5797236558375882		[learning rate: 0.0015055]
	Learning Rate: 0.00150551
	LOSS [training: 0.5797236558375882 | validation: 0.5649364405812441]
	TIME [epoch: 10.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5884215215840587		[learning rate: 0.0015]
	Learning Rate: 0.00150005
	LOSS [training: 0.5884215215840587 | validation: 0.9249200503991974]
	TIME [epoch: 10.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6653684456979174		[learning rate: 0.0014946]
	Learning Rate: 0.0014946
	LOSS [training: 0.6653684456979174 | validation: 0.5795905872903219]
	TIME [epoch: 10.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5957109032397405		[learning rate: 0.0014892]
	Learning Rate: 0.00148918
	LOSS [training: 0.5957109032397405 | validation: 0.5305009913109331]
	TIME [epoch: 10.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5470546399944408		[learning rate: 0.0014838]
	Learning Rate: 0.00148378
	LOSS [training: 0.5470546399944408 | validation: 1.2011124726332267]
	TIME [epoch: 10.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8314974068420291		[learning rate: 0.0014784]
	Learning Rate: 0.00147839
	LOSS [training: 0.8314974068420291 | validation: 0.5125195389938453]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5494953108348002		[learning rate: 0.001473]
	Learning Rate: 0.00147303
	LOSS [training: 0.5494953108348002 | validation: 0.555520050822072]
	TIME [epoch: 10.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159351416617517		[learning rate: 0.0014677]
	Learning Rate: 0.00146768
	LOSS [training: 0.6159351416617517 | validation: 0.6731421835197966]
	TIME [epoch: 10.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6236288412104288		[learning rate: 0.0014624]
	Learning Rate: 0.00146235
	LOSS [training: 0.6236288412104288 | validation: 0.5822752674485537]
	TIME [epoch: 10.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602361493761081		[learning rate: 0.001457]
	Learning Rate: 0.00145705
	LOSS [training: 0.5602361493761081 | validation: 0.7233053070996386]
	TIME [epoch: 10.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7580383970834598		[learning rate: 0.0014518]
	Learning Rate: 0.00145176
	LOSS [training: 0.7580383970834598 | validation: 0.6388797148287023]
	TIME [epoch: 10.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5694530238532824		[learning rate: 0.0014465]
	Learning Rate: 0.00144649
	LOSS [training: 0.5694530238532824 | validation: 0.5762777588395956]
	TIME [epoch: 10.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624044107910038		[learning rate: 0.0014412]
	Learning Rate: 0.00144124
	LOSS [training: 0.5624044107910038 | validation: 0.6856446858422273]
	TIME [epoch: 10.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6752042004546404		[learning rate: 0.001436]
	Learning Rate: 0.00143601
	LOSS [training: 0.6752042004546404 | validation: 0.8307195643517125]
	TIME [epoch: 10.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.628229377673477		[learning rate: 0.0014308]
	Learning Rate: 0.0014308
	LOSS [training: 0.628229377673477 | validation: 0.5507561806326126]
	TIME [epoch: 10.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5802123554813542		[learning rate: 0.0014256]
	Learning Rate: 0.00142561
	LOSS [training: 0.5802123554813542 | validation: 0.8172360273683047]
	TIME [epoch: 10.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6968215372110443		[learning rate: 0.0014204]
	Learning Rate: 0.00142043
	LOSS [training: 0.6968215372110443 | validation: 0.6364925592462913]
	TIME [epoch: 10.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5828814792283883		[learning rate: 0.0014153]
	Learning Rate: 0.00141528
	LOSS [training: 0.5828814792283883 | validation: 0.6618501846347072]
	TIME [epoch: 10.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6023206363519483		[learning rate: 0.0014101]
	Learning Rate: 0.00141014
	LOSS [training: 0.6023206363519483 | validation: 0.7132760369414857]
	TIME [epoch: 10.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6119987505495145		[learning rate: 0.001405]
	Learning Rate: 0.00140503
	LOSS [training: 0.6119987505495145 | validation: 0.5356453616385377]
	TIME [epoch: 10.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260741626267448		[learning rate: 0.0013999]
	Learning Rate: 0.00139993
	LOSS [training: 0.6260741626267448 | validation: 0.7823126521266245]
	TIME [epoch: 10.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6093696554928799		[learning rate: 0.0013948]
	Learning Rate: 0.00139485
	LOSS [training: 0.6093696554928799 | validation: 0.6592457674269053]
	TIME [epoch: 10.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199732501190586		[learning rate: 0.0013898]
	Learning Rate: 0.00138978
	LOSS [training: 0.6199732501190586 | validation: 0.5878841345801716]
	TIME [epoch: 10.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7172381722887291		[learning rate: 0.0013847]
	Learning Rate: 0.00138474
	LOSS [training: 0.7172381722887291 | validation: 0.53889188431993]
	TIME [epoch: 10.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5427586262091927		[learning rate: 0.0013797]
	Learning Rate: 0.00137972
	LOSS [training: 0.5427586262091927 | validation: 0.5774016694659211]
	TIME [epoch: 10.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601284944181119		[learning rate: 0.0013747]
	Learning Rate: 0.00137471
	LOSS [training: 0.5601284944181119 | validation: 0.8712679208834507]
	TIME [epoch: 10.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.565881716843566		[learning rate: 0.0013697]
	Learning Rate: 0.00136972
	LOSS [training: 0.565881716843566 | validation: 0.6102954881618063]
	TIME [epoch: 10.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552533477614025		[learning rate: 0.0013647]
	Learning Rate: 0.00136475
	LOSS [training: 0.6552533477614025 | validation: 0.6021590195861604]
	TIME [epoch: 10.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6749058611961366		[learning rate: 0.0013598]
	Learning Rate: 0.0013598
	LOSS [training: 0.6749058611961366 | validation: 0.5218666812041053]
	TIME [epoch: 10.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5850545853995536		[learning rate: 0.0013549]
	Learning Rate: 0.00135486
	LOSS [training: 0.5850545853995536 | validation: 0.77069039891263]
	TIME [epoch: 10.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5946237113363018		[learning rate: 0.0013499]
	Learning Rate: 0.00134994
	LOSS [training: 0.5946237113363018 | validation: 0.5532824937168145]
	TIME [epoch: 10.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6360815763844714		[learning rate: 0.001345]
	Learning Rate: 0.00134505
	LOSS [training: 0.6360815763844714 | validation: 0.9420581826148879]
	TIME [epoch: 10.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5876392583373704		[learning rate: 0.0013402]
	Learning Rate: 0.00134016
	LOSS [training: 0.5876392583373704 | validation: 0.7539335206302713]
	TIME [epoch: 10.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6073265191820427		[learning rate: 0.0013353]
	Learning Rate: 0.0013353
	LOSS [training: 0.6073265191820427 | validation: 0.6991484191867113]
	TIME [epoch: 10.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5403032738022449		[learning rate: 0.0013305]
	Learning Rate: 0.00133045
	LOSS [training: 0.5403032738022449 | validation: 0.6948373834802056]
	TIME [epoch: 10.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6129084064789364		[learning rate: 0.0013256]
	Learning Rate: 0.00132563
	LOSS [training: 0.6129084064789364 | validation: 0.6253539712980076]
	TIME [epoch: 10.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256981522895872		[learning rate: 0.0013208]
	Learning Rate: 0.00132082
	LOSS [training: 0.5256981522895872 | validation: 0.608819580406298]
	TIME [epoch: 10.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5585262379151295		[learning rate: 0.001316]
	Learning Rate: 0.00131602
	LOSS [training: 0.5585262379151295 | validation: 0.6666591587145696]
	TIME [epoch: 10.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5979633195859784		[learning rate: 0.0013112]
	Learning Rate: 0.00131125
	LOSS [training: 0.5979633195859784 | validation: 0.6290244164304]
	TIME [epoch: 10.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5729533847677063		[learning rate: 0.0013065]
	Learning Rate: 0.00130649
	LOSS [training: 0.5729533847677063 | validation: 0.685840109607633]
	TIME [epoch: 10.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5430486095025981		[learning rate: 0.0013017]
	Learning Rate: 0.00130175
	LOSS [training: 0.5430486095025981 | validation: 0.676929427390794]
	TIME [epoch: 10.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5834282956900494		[learning rate: 0.001297]
	Learning Rate: 0.00129702
	LOSS [training: 0.5834282956900494 | validation: 0.6500922945238352]
	TIME [epoch: 10.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5788782352038405		[learning rate: 0.0012923]
	Learning Rate: 0.00129232
	LOSS [training: 0.5788782352038405 | validation: 0.582457671978373]
	TIME [epoch: 10.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499092145360963		[learning rate: 0.0012876]
	Learning Rate: 0.00128763
	LOSS [training: 0.5499092145360963 | validation: 0.5977406776640907]
	TIME [epoch: 10.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094489558302995		[learning rate: 0.001283]
	Learning Rate: 0.00128295
	LOSS [training: 0.6094489558302995 | validation: 0.5902800289790376]
	TIME [epoch: 10.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.648983952849451		[learning rate: 0.0012783]
	Learning Rate: 0.0012783
	LOSS [training: 0.648983952849451 | validation: 0.5359815955452719]
	TIME [epoch: 10.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5055335024367944		[learning rate: 0.0012737]
	Learning Rate: 0.00127366
	LOSS [training: 0.5055335024367944 | validation: 0.5972190520513273]
	TIME [epoch: 10.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194407291755858		[learning rate: 0.001269]
	Learning Rate: 0.00126904
	LOSS [training: 0.5194407291755858 | validation: 0.6017560270561702]
	TIME [epoch: 10.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6343510544626885		[learning rate: 0.0012644]
	Learning Rate: 0.00126443
	LOSS [training: 0.6343510544626885 | validation: 0.8239480119583842]
	TIME [epoch: 10.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805893680028785		[learning rate: 0.0012598]
	Learning Rate: 0.00125984
	LOSS [training: 0.5805893680028785 | validation: 0.6447666156682295]
	TIME [epoch: 10.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6064194476151178		[learning rate: 0.0012553]
	Learning Rate: 0.00125527
	LOSS [training: 0.6064194476151178 | validation: 0.6654200402975827]
	TIME [epoch: 10.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426056568496359		[learning rate: 0.0012507]
	Learning Rate: 0.00125071
	LOSS [training: 0.5426056568496359 | validation: 0.6071682218593745]
	TIME [epoch: 10.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6182274208776026		[learning rate: 0.0012462]
	Learning Rate: 0.00124617
	LOSS [training: 0.6182274208776026 | validation: 0.5850083992466439]
	TIME [epoch: 10.4 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6110244600146595		[learning rate: 0.0012417]
	Learning Rate: 0.00124165
	LOSS [training: 0.6110244600146595 | validation: 0.5345145262064083]
	TIME [epoch: 10.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5095293698532419		[learning rate: 0.0012371]
	Learning Rate: 0.00123715
	LOSS [training: 0.5095293698532419 | validation: 0.570817048809164]
	TIME [epoch: 10.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5435811602636917		[learning rate: 0.0012327]
	Learning Rate: 0.00123266
	LOSS [training: 0.5435811602636917 | validation: 0.609826809324414]
	TIME [epoch: 10.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270447332485239		[learning rate: 0.0012282]
	Learning Rate: 0.00122818
	LOSS [training: 0.5270447332485239 | validation: 0.6617067364979091]
	TIME [epoch: 10.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5557159782529575		[learning rate: 0.0012237]
	Learning Rate: 0.00122373
	LOSS [training: 0.5557159782529575 | validation: 0.6633338698146115]
	TIME [epoch: 10.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6503638329042821		[learning rate: 0.0012193]
	Learning Rate: 0.00121929
	LOSS [training: 0.6503638329042821 | validation: 0.6387866367047069]
	TIME [epoch: 10.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7267057299139268		[learning rate: 0.0012149]
	Learning Rate: 0.00121486
	LOSS [training: 0.7267057299139268 | validation: 0.5775815930951723]
	TIME [epoch: 10.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5384417807176615		[learning rate: 0.0012105]
	Learning Rate: 0.00121045
	LOSS [training: 0.5384417807176615 | validation: 0.5477061308572609]
	TIME [epoch: 10.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5332928080896838		[learning rate: 0.0012061]
	Learning Rate: 0.00120606
	LOSS [training: 0.5332928080896838 | validation: 0.6058398264098138]
	TIME [epoch: 10.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5118127901208389		[learning rate: 0.0012017]
	Learning Rate: 0.00120168
	LOSS [training: 0.5118127901208389 | validation: 0.4809257811892889]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.486626559057558		[learning rate: 0.0011973]
	Learning Rate: 0.00119732
	LOSS [training: 0.486626559057558 | validation: 0.5481728925620941]
	TIME [epoch: 10.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5030802997723514		[learning rate: 0.001193]
	Learning Rate: 0.00119298
	LOSS [training: 0.5030802997723514 | validation: 0.5923205831944904]
	TIME [epoch: 10.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47153256882065736		[learning rate: 0.0011886]
	Learning Rate: 0.00118865
	LOSS [training: 0.47153256882065736 | validation: 0.48241758931638046]
	TIME [epoch: 10.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315098221272376		[learning rate: 0.0011843]
	Learning Rate: 0.00118433
	LOSS [training: 0.5315098221272376 | validation: 0.5530350679270698]
	TIME [epoch: 10.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6665407420866891		[learning rate: 0.00118]
	Learning Rate: 0.00118003
	LOSS [training: 0.6665407420866891 | validation: 0.568774423729143]
	TIME [epoch: 10.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5249625679310295		[learning rate: 0.0011758]
	Learning Rate: 0.00117575
	LOSS [training: 0.5249625679310295 | validation: 0.4829517605265495]
	TIME [epoch: 10.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230085766748611		[learning rate: 0.0011715]
	Learning Rate: 0.00117149
	LOSS [training: 0.5230085766748611 | validation: 0.5124093330099041]
	TIME [epoch: 10.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5763036053326767		[learning rate: 0.0011672]
	Learning Rate: 0.00116723
	LOSS [training: 0.5763036053326767 | validation: 0.497556932483157]
	TIME [epoch: 10.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6610983055742052		[learning rate: 0.001163]
	Learning Rate: 0.001163
	LOSS [training: 0.6610983055742052 | validation: 0.6395024816980819]
	TIME [epoch: 10.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5437330706776751		[learning rate: 0.0011588]
	Learning Rate: 0.00115878
	LOSS [training: 0.5437330706776751 | validation: 0.6672925879733137]
	TIME [epoch: 10.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5650368385010653		[learning rate: 0.0011546]
	Learning Rate: 0.00115457
	LOSS [training: 0.5650368385010653 | validation: 0.5821604501230032]
	TIME [epoch: 10.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5951265859406352		[learning rate: 0.0011504]
	Learning Rate: 0.00115038
	LOSS [training: 0.5951265859406352 | validation: 0.542355661969976]
	TIME [epoch: 10.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5797383441047439		[learning rate: 0.0011462]
	Learning Rate: 0.00114621
	LOSS [training: 0.5797383441047439 | validation: 0.6735674817112449]
	TIME [epoch: 10.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178719731940866		[learning rate: 0.001142]
	Learning Rate: 0.00114205
	LOSS [training: 0.5178719731940866 | validation: 0.6394005234053798]
	TIME [epoch: 10.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266088591017497		[learning rate: 0.0011379]
	Learning Rate: 0.0011379
	LOSS [training: 0.5266088591017497 | validation: 0.4915492561794991]
	TIME [epoch: 10.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5467803799690254		[learning rate: 0.0011338]
	Learning Rate: 0.00113377
	LOSS [training: 0.5467803799690254 | validation: 0.5477164629585021]
	TIME [epoch: 10.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5755455135067378		[learning rate: 0.0011297]
	Learning Rate: 0.00112966
	LOSS [training: 0.5755455135067378 | validation: 0.5154474026724075]
	TIME [epoch: 10.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4813902640365006		[learning rate: 0.0011256]
	Learning Rate: 0.00112556
	LOSS [training: 0.4813902640365006 | validation: 0.5697409276488307]
	TIME [epoch: 10.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219996895806142		[learning rate: 0.0011215]
	Learning Rate: 0.00112147
	LOSS [training: 0.5219996895806142 | validation: 0.5130638558628347]
	TIME [epoch: 10.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4905071716575085		[learning rate: 0.0011174]
	Learning Rate: 0.0011174
	LOSS [training: 0.4905071716575085 | validation: 0.6153756705804232]
	TIME [epoch: 10.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499116924481544		[learning rate: 0.0011133]
	Learning Rate: 0.00111335
	LOSS [training: 0.5499116924481544 | validation: 0.6114260535784017]
	TIME [epoch: 10.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5107589938310174		[learning rate: 0.0011093]
	Learning Rate: 0.00110931
	LOSS [training: 0.5107589938310174 | validation: 0.5834701809241076]
	TIME [epoch: 10.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5911813917297406		[learning rate: 0.0011053]
	Learning Rate: 0.00110528
	LOSS [training: 0.5911813917297406 | validation: 0.5242387429209108]
	TIME [epoch: 10.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426999321086925		[learning rate: 0.0011013]
	Learning Rate: 0.00110127
	LOSS [training: 0.5426999321086925 | validation: 0.5368652308063371]
	TIME [epoch: 10.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5877789885884308		[learning rate: 0.0010973]
	Learning Rate: 0.00109728
	LOSS [training: 0.5877789885884308 | validation: 0.6075974261447906]
	TIME [epoch: 10.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4926035099959883		[learning rate: 0.0010933]
	Learning Rate: 0.00109329
	LOSS [training: 0.4926035099959883 | validation: 0.4715102631979542]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074593217983886		[learning rate: 0.0010893]
	Learning Rate: 0.00108933
	LOSS [training: 0.5074593217983886 | validation: 0.5254899838647187]
	TIME [epoch: 10.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5522287511879912		[learning rate: 0.0010854]
	Learning Rate: 0.00108537
	LOSS [training: 0.5522287511879912 | validation: 0.573606244891251]
	TIME [epoch: 10.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5670763953541933		[learning rate: 0.0010814]
	Learning Rate: 0.00108143
	LOSS [training: 0.5670763953541933 | validation: 0.7432036656066364]
	TIME [epoch: 10.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4966141307708286		[learning rate: 0.0010775]
	Learning Rate: 0.00107751
	LOSS [training: 0.4966141307708286 | validation: 0.5017757860399447]
	TIME [epoch: 10.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764791335024656		[learning rate: 0.0010736]
	Learning Rate: 0.0010736
	LOSS [training: 0.5764791335024656 | validation: 0.5547200948344838]
	TIME [epoch: 10.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5460016859539258		[learning rate: 0.0010697]
	Learning Rate: 0.0010697
	LOSS [training: 0.5460016859539258 | validation: 0.9170493508904705]
	TIME [epoch: 10.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393575090288254		[learning rate: 0.0010658]
	Learning Rate: 0.00106582
	LOSS [training: 0.6393575090288254 | validation: 0.5761688998923756]
	TIME [epoch: 10.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5160900968906205		[learning rate: 0.001062]
	Learning Rate: 0.00106195
	LOSS [training: 0.5160900968906205 | validation: 0.6435727291921517]
	TIME [epoch: 10.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5155012283579714		[learning rate: 0.0010581]
	Learning Rate: 0.0010581
	LOSS [training: 0.5155012283579714 | validation: 0.5100060244938384]
	TIME [epoch: 10.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5089078907874183		[learning rate: 0.0010543]
	Learning Rate: 0.00105426
	LOSS [training: 0.5089078907874183 | validation: 0.6471264552814391]
	TIME [epoch: 10.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516111043787063		[learning rate: 0.0010504]
	Learning Rate: 0.00105043
	LOSS [training: 0.5516111043787063 | validation: 0.6771821767781994]
	TIME [epoch: 10.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293789727338917		[learning rate: 0.0010466]
	Learning Rate: 0.00104662
	LOSS [training: 0.5293789727338917 | validation: 0.6413960872879038]
	TIME [epoch: 10.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5041849191090725		[learning rate: 0.0010428]
	Learning Rate: 0.00104282
	LOSS [training: 0.5041849191090725 | validation: 0.5526392765199555]
	TIME [epoch: 10.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5248839366138636		[learning rate: 0.001039]
	Learning Rate: 0.00103904
	LOSS [training: 0.5248839366138636 | validation: 0.47464421491273073]
	TIME [epoch: 10.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073055644722151		[learning rate: 0.0010353]
	Learning Rate: 0.00103527
	LOSS [training: 0.5073055644722151 | validation: 0.6016717413402649]
	TIME [epoch: 10.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4944245499584753		[learning rate: 0.0010315]
	Learning Rate: 0.00103151
	LOSS [training: 0.4944245499584753 | validation: 0.5633726940609459]
	TIME [epoch: 10.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5021228134176404		[learning rate: 0.0010278]
	Learning Rate: 0.00102777
	LOSS [training: 0.5021228134176404 | validation: 0.6734385340741312]
	TIME [epoch: 10.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4997166117138012		[learning rate: 0.001024]
	Learning Rate: 0.00102404
	LOSS [training: 0.4997166117138012 | validation: 0.4874157061072096]
	TIME [epoch: 10.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49779984621854395		[learning rate: 0.0010203]
	Learning Rate: 0.00102032
	LOSS [training: 0.49779984621854395 | validation: 0.501839265642698]
	TIME [epoch: 10.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4693171238750934		[learning rate: 0.0010166]
	Learning Rate: 0.00101662
	LOSS [training: 0.4693171238750934 | validation: 0.5695059048705842]
	TIME [epoch: 10.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156553139176733		[learning rate: 0.0010129]
	Learning Rate: 0.00101293
	LOSS [training: 0.5156553139176733 | validation: 0.6490330936891734]
	TIME [epoch: 10.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5584546089714439		[learning rate: 0.0010093]
	Learning Rate: 0.00100925
	LOSS [training: 0.5584546089714439 | validation: 0.5486894387456771]
	TIME [epoch: 10.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48977563603302626		[learning rate: 0.0010056]
	Learning Rate: 0.00100559
	LOSS [training: 0.48977563603302626 | validation: 0.6619225954231059]
	TIME [epoch: 10.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410525138350994		[learning rate: 0.0010019]
	Learning Rate: 0.00100194
	LOSS [training: 0.5410525138350994 | validation: 0.4517320095798808]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4632264101964516		[learning rate: 0.0009983]
	Learning Rate: 0.000998305
	LOSS [training: 0.4632264101964516 | validation: 0.5839241264105046]
	TIME [epoch: 10.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.540300226902565		[learning rate: 0.00099468]
	Learning Rate: 0.000994682
	LOSS [training: 0.540300226902565 | validation: 0.4796477978803704]
	TIME [epoch: 10.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5465208716449974		[learning rate: 0.00099107]
	Learning Rate: 0.000991072
	LOSS [training: 0.5465208716449974 | validation: 0.5346520728270545]
	TIME [epoch: 10.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5617873420465116		[learning rate: 0.00098748]
	Learning Rate: 0.000987475
	LOSS [training: 0.5617873420465116 | validation: 0.5417586871707984]
	TIME [epoch: 10.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5093967204637966		[learning rate: 0.00098389]
	Learning Rate: 0.000983892
	LOSS [training: 0.5093967204637966 | validation: 0.5310852005341419]
	TIME [epoch: 10.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4864998014741819		[learning rate: 0.00098032]
	Learning Rate: 0.000980321
	LOSS [training: 0.4864998014741819 | validation: 0.4987756415394597]
	TIME [epoch: 10.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5169987267655457		[learning rate: 0.00097676]
	Learning Rate: 0.000976764
	LOSS [training: 0.5169987267655457 | validation: 0.501117572193539]
	TIME [epoch: 10.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5012220070125115		[learning rate: 0.00097322]
	Learning Rate: 0.000973219
	LOSS [training: 0.5012220070125115 | validation: 0.5734509207402281]
	TIME [epoch: 10.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5403987610543752		[learning rate: 0.00096969]
	Learning Rate: 0.000969687
	LOSS [training: 0.5403987610543752 | validation: 0.6238483675944732]
	TIME [epoch: 10.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5145556604299312		[learning rate: 0.00096617]
	Learning Rate: 0.000966168
	LOSS [training: 0.5145556604299312 | validation: 0.5140259868388994]
	TIME [epoch: 10.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5062277901266283		[learning rate: 0.00096266]
	Learning Rate: 0.000962662
	LOSS [training: 0.5062277901266283 | validation: 0.5741357419904732]
	TIME [epoch: 10.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5461108589241338		[learning rate: 0.00095917]
	Learning Rate: 0.000959168
	LOSS [training: 0.5461108589241338 | validation: 0.5089819379235186]
	TIME [epoch: 10.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44823529830059716		[learning rate: 0.00095569]
	Learning Rate: 0.000955687
	LOSS [training: 0.44823529830059716 | validation: 0.5394053498563635]
	TIME [epoch: 10.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5101021576789055		[learning rate: 0.00095222]
	Learning Rate: 0.000952219
	LOSS [training: 0.5101021576789055 | validation: 0.4772124517894274]
	TIME [epoch: 10.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5334465724596719		[learning rate: 0.00094876]
	Learning Rate: 0.000948763
	LOSS [training: 0.5334465724596719 | validation: 0.49016819920410953]
	TIME [epoch: 10.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45271104682216323		[learning rate: 0.00094532]
	Learning Rate: 0.00094532
	LOSS [training: 0.45271104682216323 | validation: 0.5584404264841486]
	TIME [epoch: 10.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4634001148215094		[learning rate: 0.00094189]
	Learning Rate: 0.000941889
	LOSS [training: 0.4634001148215094 | validation: 0.5057875457990896]
	TIME [epoch: 10.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5129936317885048		[learning rate: 0.00093847]
	Learning Rate: 0.000938471
	LOSS [training: 0.5129936317885048 | validation: 0.49197376200363147]
	TIME [epoch: 10.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6792747448574215		[learning rate: 0.00093507]
	Learning Rate: 0.000935066
	LOSS [training: 0.6792747448574215 | validation: 0.46986391860343274]
	TIME [epoch: 10.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48434777510382043		[learning rate: 0.00093167]
	Learning Rate: 0.000931672
	LOSS [training: 0.48434777510382043 | validation: 0.4914733848092726]
	TIME [epoch: 10.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43635609733222297		[learning rate: 0.00092829]
	Learning Rate: 0.000928291
	LOSS [training: 0.43635609733222297 | validation: 0.5312833516500836]
	TIME [epoch: 10.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163477808142647		[learning rate: 0.00092492]
	Learning Rate: 0.000924922
	LOSS [training: 0.5163477808142647 | validation: 0.4556569986472886]
	TIME [epoch: 10.4 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4630969509892987		[learning rate: 0.00092157]
	Learning Rate: 0.000921566
	LOSS [training: 0.4630969509892987 | validation: 0.5561892003258841]
	TIME [epoch: 10.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299168114960312		[learning rate: 0.00091822]
	Learning Rate: 0.000918221
	LOSS [training: 0.5299168114960312 | validation: 0.4903401102673348]
	TIME [epoch: 10.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46012686569231553		[learning rate: 0.00091489]
	Learning Rate: 0.000914889
	LOSS [training: 0.46012686569231553 | validation: 0.5855265362629958]
	TIME [epoch: 10.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5001676455739424		[learning rate: 0.00091157]
	Learning Rate: 0.000911569
	LOSS [training: 0.5001676455739424 | validation: 0.5231664590618555]
	TIME [epoch: 10.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.533052215995227		[learning rate: 0.00090826]
	Learning Rate: 0.000908261
	LOSS [training: 0.533052215995227 | validation: 0.5060887158638078]
	TIME [epoch: 10.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48021860084894463		[learning rate: 0.00090496]
	Learning Rate: 0.000904965
	LOSS [training: 0.48021860084894463 | validation: 0.6117839969277322]
	TIME [epoch: 10.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5145728995152572		[learning rate: 0.00090168]
	Learning Rate: 0.00090168
	LOSS [training: 0.5145728995152572 | validation: 0.48490853701605097]
	TIME [epoch: 10.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48709683273992005		[learning rate: 0.00089841]
	Learning Rate: 0.000898408
	LOSS [training: 0.48709683273992005 | validation: 0.5059382576599513]
	TIME [epoch: 10.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4481720994784165		[learning rate: 0.00089515]
	Learning Rate: 0.000895148
	LOSS [training: 0.4481720994784165 | validation: 0.49349118433944883]
	TIME [epoch: 10.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4702591827446379		[learning rate: 0.0008919]
	Learning Rate: 0.000891899
	LOSS [training: 0.4702591827446379 | validation: 0.5128999606501969]
	TIME [epoch: 10.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48479580840353326		[learning rate: 0.00088866]
	Learning Rate: 0.000888663
	LOSS [training: 0.48479580840353326 | validation: 0.5315131989473041]
	TIME [epoch: 10.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46195559549967646		[learning rate: 0.00088544]
	Learning Rate: 0.000885438
	LOSS [training: 0.46195559549967646 | validation: 0.5405413575641415]
	TIME [epoch: 10.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4748434162401224		[learning rate: 0.00088222]
	Learning Rate: 0.000882224
	LOSS [training: 0.4748434162401224 | validation: 0.4669863630972934]
	TIME [epoch: 10.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.512393125070955		[learning rate: 0.00087902]
	Learning Rate: 0.000879022
	LOSS [training: 0.512393125070955 | validation: 0.5676216523347895]
	TIME [epoch: 10.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5364447885703665		[learning rate: 0.00087583]
	Learning Rate: 0.000875833
	LOSS [training: 0.5364447885703665 | validation: 0.6698162572252488]
	TIME [epoch: 10.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409052202774201		[learning rate: 0.00087265]
	Learning Rate: 0.000872654
	LOSS [training: 0.6409052202774201 | validation: 0.6153689525668518]
	TIME [epoch: 10.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5804786180780808		[learning rate: 0.00086949]
	Learning Rate: 0.000869487
	LOSS [training: 0.5804786180780808 | validation: 0.4775165546028957]
	TIME [epoch: 10.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4611717625235805		[learning rate: 0.00086633]
	Learning Rate: 0.000866332
	LOSS [training: 0.4611717625235805 | validation: 0.7177606927658912]
	TIME [epoch: 10.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5300465270375847		[learning rate: 0.00086319]
	Learning Rate: 0.000863188
	LOSS [training: 0.5300465270375847 | validation: 0.5056524616073251]
	TIME [epoch: 10.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46204136305853327		[learning rate: 0.00086006]
	Learning Rate: 0.000860055
	LOSS [training: 0.46204136305853327 | validation: 0.6568798090652217]
	TIME [epoch: 10.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5046393019031611		[learning rate: 0.00085693]
	Learning Rate: 0.000856934
	LOSS [training: 0.5046393019031611 | validation: 0.5677504030737675]
	TIME [epoch: 10.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48417573598500907		[learning rate: 0.00085382]
	Learning Rate: 0.000853824
	LOSS [training: 0.48417573598500907 | validation: 0.4663667418746549]
	TIME [epoch: 10.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4799565186255704		[learning rate: 0.00085073]
	Learning Rate: 0.000850726
	LOSS [training: 0.4799565186255704 | validation: 0.46194202999750117]
	TIME [epoch: 10.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44651404765863817		[learning rate: 0.00084764]
	Learning Rate: 0.000847638
	LOSS [training: 0.44651404765863817 | validation: 0.6787721007220003]
	TIME [epoch: 10.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5766863467611824		[learning rate: 0.00084456]
	Learning Rate: 0.000844562
	LOSS [training: 0.5766863467611824 | validation: 0.44710269660356133]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_780.pth
	Model improved!!!
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306101021252971		[learning rate: 0.0008415]
	Learning Rate: 0.000841497
	LOSS [training: 0.5306101021252971 | validation: 0.5628340622589576]
	TIME [epoch: 10.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4504247507901134		[learning rate: 0.00083844]
	Learning Rate: 0.000838443
	LOSS [training: 0.4504247507901134 | validation: 0.5178946007771242]
	TIME [epoch: 10.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4220548753339794		[learning rate: 0.0008354]
	Learning Rate: 0.000835401
	LOSS [training: 0.4220548753339794 | validation: 0.46850858403836554]
	TIME [epoch: 10.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5392813892730672		[learning rate: 0.00083237]
	Learning Rate: 0.000832369
	LOSS [training: 0.5392813892730672 | validation: 0.43890055251782045]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4445958971798786		[learning rate: 0.00082935]
	Learning Rate: 0.000829348
	LOSS [training: 0.4445958971798786 | validation: 0.4849206040477925]
	TIME [epoch: 10.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182514130417122		[learning rate: 0.00082634]
	Learning Rate: 0.000826338
	LOSS [training: 0.4182514130417122 | validation: 0.46061396849727204]
	TIME [epoch: 10.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5048269026055532		[learning rate: 0.00082334]
	Learning Rate: 0.00082334
	LOSS [training: 0.5048269026055532 | validation: 0.5730311134169793]
	TIME [epoch: 10.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5590487449142657		[learning rate: 0.00082035]
	Learning Rate: 0.000820352
	LOSS [training: 0.5590487449142657 | validation: 0.5790957645349633]
	TIME [epoch: 10.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47890831969575387		[learning rate: 0.00081737]
	Learning Rate: 0.000817375
	LOSS [training: 0.47890831969575387 | validation: 0.582053916835523]
	TIME [epoch: 10.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5152516225021869		[learning rate: 0.00081441]
	Learning Rate: 0.000814408
	LOSS [training: 0.5152516225021869 | validation: 0.5991411084233328]
	TIME [epoch: 10.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5763476548683594		[learning rate: 0.00081145]
	Learning Rate: 0.000811453
	LOSS [training: 0.5763476548683594 | validation: 0.44582234122955444]
	TIME [epoch: 10.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42542583736401174		[learning rate: 0.00080851]
	Learning Rate: 0.000808508
	LOSS [training: 0.42542583736401174 | validation: 0.4126759986946481]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45622523323728065		[learning rate: 0.00080557]
	Learning Rate: 0.000805574
	LOSS [training: 0.45622523323728065 | validation: 0.5782686713762282]
	TIME [epoch: 10.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47650618210816764		[learning rate: 0.00080265]
	Learning Rate: 0.00080265
	LOSS [training: 0.47650618210816764 | validation: 0.4923611631323051]
	TIME [epoch: 10.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4493015137178878		[learning rate: 0.00079974]
	Learning Rate: 0.000799737
	LOSS [training: 0.4493015137178878 | validation: 0.46772558600610015]
	TIME [epoch: 10.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.483415588485578		[learning rate: 0.00079684]
	Learning Rate: 0.000796835
	LOSS [training: 0.483415588485578 | validation: 0.5153697868684599]
	TIME [epoch: 10.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4953199486767633		[learning rate: 0.00079394]
	Learning Rate: 0.000793943
	LOSS [training: 0.4953199486767633 | validation: 0.47179144128612577]
	TIME [epoch: 10.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4863906736737619		[learning rate: 0.00079106]
	Learning Rate: 0.000791062
	LOSS [training: 0.4863906736737619 | validation: 0.4593283637083749]
	TIME [epoch: 10.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43142404758138175		[learning rate: 0.00078819]
	Learning Rate: 0.000788191
	LOSS [training: 0.43142404758138175 | validation: 0.4542410793610678]
	TIME [epoch: 10.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730700539046257		[learning rate: 0.00078533]
	Learning Rate: 0.000785331
	LOSS [training: 0.4730700539046257 | validation: 0.5244776885469372]
	TIME [epoch: 10.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023233558894564		[learning rate: 0.00078248]
	Learning Rate: 0.000782481
	LOSS [training: 0.5023233558894564 | validation: 0.5667019879778148]
	TIME [epoch: 10.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4769592864416835		[learning rate: 0.00077964]
	Learning Rate: 0.000779641
	LOSS [training: 0.4769592864416835 | validation: 0.5110860017963313]
	TIME [epoch: 10.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46575245313440605		[learning rate: 0.00077681]
	Learning Rate: 0.000776812
	LOSS [training: 0.46575245313440605 | validation: 0.4518989598174957]
	TIME [epoch: 10.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4305506059206244		[learning rate: 0.00077399]
	Learning Rate: 0.000773993
	LOSS [training: 0.4305506059206244 | validation: 0.45442554381715233]
	TIME [epoch: 10.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41266451573169743		[learning rate: 0.00077118]
	Learning Rate: 0.000771184
	LOSS [training: 0.41266451573169743 | validation: 0.4824769175606005]
	TIME [epoch: 10.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4930830668088613		[learning rate: 0.00076839]
	Learning Rate: 0.000768385
	LOSS [training: 0.4930830668088613 | validation: 0.6362857301003028]
	TIME [epoch: 10.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5409981628749255		[learning rate: 0.0007656]
	Learning Rate: 0.000765597
	LOSS [training: 0.5409981628749255 | validation: 0.40582602421742536]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_807.pth
	Model improved!!!
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4484779810287593		[learning rate: 0.00076282]
	Learning Rate: 0.000762818
	LOSS [training: 0.4484779810287593 | validation: 0.47510740153777037]
	TIME [epoch: 10.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057342008379301		[learning rate: 0.00076005]
	Learning Rate: 0.00076005
	LOSS [training: 0.5057342008379301 | validation: 0.5075446204788644]
	TIME [epoch: 10.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44999211430961206		[learning rate: 0.00075729]
	Learning Rate: 0.000757292
	LOSS [training: 0.44999211430961206 | validation: 0.5846996385035849]
	TIME [epoch: 10.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4575417866886027		[learning rate: 0.00075454]
	Learning Rate: 0.000754543
	LOSS [training: 0.4575417866886027 | validation: 0.5136010913748826]
	TIME [epoch: 10.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616638665914312		[learning rate: 0.00075181]
	Learning Rate: 0.000751805
	LOSS [training: 0.4616638665914312 | validation: 0.5682400879673722]
	TIME [epoch: 10.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4805734286423073		[learning rate: 0.00074908]
	Learning Rate: 0.000749077
	LOSS [training: 0.4805734286423073 | validation: 0.4694714916582649]
	TIME [epoch: 10.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4436980594879598		[learning rate: 0.00074636]
	Learning Rate: 0.000746358
	LOSS [training: 0.4436980594879598 | validation: 0.4630256541200932]
	TIME [epoch: 10.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40618047220698184		[learning rate: 0.00074365]
	Learning Rate: 0.00074365
	LOSS [training: 0.40618047220698184 | validation: 0.5023599194112205]
	TIME [epoch: 10.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43782074185893327		[learning rate: 0.00074095]
	Learning Rate: 0.000740951
	LOSS [training: 0.43782074185893327 | validation: 0.474824626906599]
	TIME [epoch: 10.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5099019413467036		[learning rate: 0.00073826]
	Learning Rate: 0.000738262
	LOSS [training: 0.5099019413467036 | validation: 0.4646401683126877]
	TIME [epoch: 10.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48330612455205524		[learning rate: 0.00073558]
	Learning Rate: 0.000735583
	LOSS [training: 0.48330612455205524 | validation: 0.5380409321018205]
	TIME [epoch: 10.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45385082067676275		[learning rate: 0.00073291]
	Learning Rate: 0.000732913
	LOSS [training: 0.45385082067676275 | validation: 0.4721329162909639]
	TIME [epoch: 10.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45016532142943805		[learning rate: 0.00073025]
	Learning Rate: 0.000730254
	LOSS [training: 0.45016532142943805 | validation: 0.53213542169121]
	TIME [epoch: 10.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5153690112432182		[learning rate: 0.0007276]
	Learning Rate: 0.000727603
	LOSS [training: 0.5153690112432182 | validation: 0.5805960591754055]
	TIME [epoch: 10.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47763856365583734		[learning rate: 0.00072496]
	Learning Rate: 0.000724963
	LOSS [training: 0.47763856365583734 | validation: 0.5322070076143485]
	TIME [epoch: 10.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45168760795572716		[learning rate: 0.00072233]
	Learning Rate: 0.000722332
	LOSS [training: 0.45168760795572716 | validation: 0.5325964999794826]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43591500612387		[learning rate: 0.00071971]
	Learning Rate: 0.000719711
	LOSS [training: 0.43591500612387 | validation: 0.48850501883079916]
	TIME [epoch: 10.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47722505331232073		[learning rate: 0.0007171]
	Learning Rate: 0.000717099
	LOSS [training: 0.47722505331232073 | validation: 0.46571200003064933]
	TIME [epoch: 10.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3999189596190219		[learning rate: 0.0007145]
	Learning Rate: 0.000714496
	LOSS [training: 0.3999189596190219 | validation: 0.43196535979426026]
	TIME [epoch: 10.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41973284780895914		[learning rate: 0.0007119]
	Learning Rate: 0.000711903
	LOSS [training: 0.41973284780895914 | validation: 0.45288760984069937]
	TIME [epoch: 10.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42443099283769714		[learning rate: 0.00070932]
	Learning Rate: 0.00070932
	LOSS [training: 0.42443099283769714 | validation: 0.48448668596174094]
	TIME [epoch: 10.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4826204168887841		[learning rate: 0.00070675]
	Learning Rate: 0.000706746
	LOSS [training: 0.4826204168887841 | validation: 0.5423761657464783]
	TIME [epoch: 10.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5026965136233457		[learning rate: 0.00070418]
	Learning Rate: 0.000704181
	LOSS [training: 0.5026965136233457 | validation: 0.45391957053167675]
	TIME [epoch: 10.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41365104969763306		[learning rate: 0.00070163]
	Learning Rate: 0.000701625
	LOSS [training: 0.41365104969763306 | validation: 0.5013417939573777]
	TIME [epoch: 10.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48329517703088165		[learning rate: 0.00069908]
	Learning Rate: 0.000699079
	LOSS [training: 0.48329517703088165 | validation: 0.58647722568889]
	TIME [epoch: 10.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47863648431084177		[learning rate: 0.00069654]
	Learning Rate: 0.000696542
	LOSS [training: 0.47863648431084177 | validation: 0.428756496332677]
	TIME [epoch: 10.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4149692773507791		[learning rate: 0.00069401]
	Learning Rate: 0.000694014
	LOSS [training: 0.4149692773507791 | validation: 0.4321481627313726]
	TIME [epoch: 10.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44256319144420353		[learning rate: 0.0006915]
	Learning Rate: 0.000691496
	LOSS [training: 0.44256319144420353 | validation: 0.42038990393797465]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196966191016955		[learning rate: 0.00068899]
	Learning Rate: 0.000688986
	LOSS [training: 0.5196966191016955 | validation: 0.4284575816771121]
	TIME [epoch: 10.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.414343121185056		[learning rate: 0.00068649]
	Learning Rate: 0.000686486
	LOSS [training: 0.414343121185056 | validation: 0.5054365532179412]
	TIME [epoch: 10.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4283631690845004		[learning rate: 0.00068399]
	Learning Rate: 0.000683994
	LOSS [training: 0.4283631690845004 | validation: 0.43261541751338284]
	TIME [epoch: 10.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44910123263703144		[learning rate: 0.00068151]
	Learning Rate: 0.000681512
	LOSS [training: 0.44910123263703144 | validation: 0.43560101290602526]
	TIME [epoch: 10.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46648352849441466		[learning rate: 0.00067904]
	Learning Rate: 0.000679039
	LOSS [training: 0.46648352849441466 | validation: 0.470413975817705]
	TIME [epoch: 10.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4915309575389671		[learning rate: 0.00067657]
	Learning Rate: 0.000676575
	LOSS [training: 0.4915309575389671 | validation: 0.4233662916668682]
	TIME [epoch: 10.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42546707649743787		[learning rate: 0.00067412]
	Learning Rate: 0.00067412
	LOSS [training: 0.42546707649743787 | validation: 0.517741146426202]
	TIME [epoch: 10.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4864840501662996		[learning rate: 0.00067167]
	Learning Rate: 0.000671673
	LOSS [training: 0.4864840501662996 | validation: 0.4388003918853808]
	TIME [epoch: 10.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4243105282896087		[learning rate: 0.00066924]
	Learning Rate: 0.000669235
	LOSS [training: 0.4243105282896087 | validation: 0.49329961545795675]
	TIME [epoch: 10.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4645164408738368		[learning rate: 0.00066681]
	Learning Rate: 0.000666807
	LOSS [training: 0.4645164408738368 | validation: 0.4622188552922339]
	TIME [epoch: 10.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4375375023652987		[learning rate: 0.00066439]
	Learning Rate: 0.000664387
	LOSS [training: 0.4375375023652987 | validation: 0.44515378439207764]
	TIME [epoch: 10.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4427271366167525		[learning rate: 0.00066198]
	Learning Rate: 0.000661976
	LOSS [training: 0.4427271366167525 | validation: 0.42252921648847536]
	TIME [epoch: 10.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38872192789477605		[learning rate: 0.00065957]
	Learning Rate: 0.000659573
	LOSS [training: 0.38872192789477605 | validation: 0.45027057580176455]
	TIME [epoch: 10.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40252624075011434		[learning rate: 0.00065718]
	Learning Rate: 0.00065718
	LOSS [training: 0.40252624075011434 | validation: 0.4353978400280512]
	TIME [epoch: 10.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.388610935179433		[learning rate: 0.00065479]
	Learning Rate: 0.000654795
	LOSS [training: 0.388610935179433 | validation: 0.450842667242803]
	TIME [epoch: 10.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42262508590616754		[learning rate: 0.00065242]
	Learning Rate: 0.000652419
	LOSS [training: 0.42262508590616754 | validation: 0.4459411725474712]
	TIME [epoch: 10.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4186582439222299		[learning rate: 0.00065005]
	Learning Rate: 0.000650051
	LOSS [training: 0.4186582439222299 | validation: 0.529921931299135]
	TIME [epoch: 10.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.443768645336558		[learning rate: 0.00064769]
	Learning Rate: 0.000647692
	LOSS [training: 0.443768645336558 | validation: 0.49677077535112646]
	TIME [epoch: 10.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4612503772125055		[learning rate: 0.00064534]
	Learning Rate: 0.000645341
	LOSS [training: 0.4612503772125055 | validation: 0.6104591110033619]
	TIME [epoch: 10.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46776686522984223		[learning rate: 0.000643]
	Learning Rate: 0.000642999
	LOSS [training: 0.46776686522984223 | validation: 0.5529952656729437]
	TIME [epoch: 10.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41641959491551245		[learning rate: 0.00064067]
	Learning Rate: 0.000640666
	LOSS [training: 0.41641959491551245 | validation: 0.4503583832696025]
	TIME [epoch: 10.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.464625693851805		[learning rate: 0.00063834]
	Learning Rate: 0.000638341
	LOSS [training: 0.464625693851805 | validation: 0.4940519251220135]
	TIME [epoch: 10.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.452918006606892		[learning rate: 0.00063602]
	Learning Rate: 0.000636024
	LOSS [training: 0.452918006606892 | validation: 0.4720482649309094]
	TIME [epoch: 10.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488981168245315		[learning rate: 0.00063372]
	Learning Rate: 0.000633716
	LOSS [training: 0.4488981168245315 | validation: 0.5011075204155654]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46299746190569646		[learning rate: 0.00063142]
	Learning Rate: 0.000631416
	LOSS [training: 0.46299746190569646 | validation: 0.7735479762505013]
	TIME [epoch: 10.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5958231689871599		[learning rate: 0.00062912]
	Learning Rate: 0.000629125
	LOSS [training: 0.5958231689871599 | validation: 0.49900597745625236]
	TIME [epoch: 10.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4630516733288991		[learning rate: 0.00062684]
	Learning Rate: 0.000626842
	LOSS [training: 0.4630516733288991 | validation: 0.4121246681447939]
	TIME [epoch: 10.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42101253762312557		[learning rate: 0.00062457]
	Learning Rate: 0.000624567
	LOSS [training: 0.42101253762312557 | validation: 0.4259821444668884]
	TIME [epoch: 10.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4139259006528956		[learning rate: 0.0006223]
	Learning Rate: 0.0006223
	LOSS [training: 0.4139259006528956 | validation: 0.460475708004114]
	TIME [epoch: 10.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42519127201502355		[learning rate: 0.00062004]
	Learning Rate: 0.000620042
	LOSS [training: 0.42519127201502355 | validation: 0.4973268559640328]
	TIME [epoch: 10.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42084170301777474		[learning rate: 0.00061779]
	Learning Rate: 0.000617792
	LOSS [training: 0.42084170301777474 | validation: 0.49037066713778726]
	TIME [epoch: 10.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42470666315388783		[learning rate: 0.00061555]
	Learning Rate: 0.00061555
	LOSS [training: 0.42470666315388783 | validation: 0.47977689833126425]
	TIME [epoch: 10.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4442482314662118		[learning rate: 0.00061332]
	Learning Rate: 0.000613316
	LOSS [training: 0.4442482314662118 | validation: 0.5820870717449804]
	TIME [epoch: 10.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44960233402276073		[learning rate: 0.00061109]
	Learning Rate: 0.00061109
	LOSS [training: 0.44960233402276073 | validation: 0.45610262207018354]
	TIME [epoch: 10.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4418552384759183		[learning rate: 0.00060887]
	Learning Rate: 0.000608872
	LOSS [training: 0.4418552384759183 | validation: 0.4053835556819131]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4059681308391533		[learning rate: 0.00060666]
	Learning Rate: 0.000606663
	LOSS [training: 0.4059681308391533 | validation: 0.4449623370917243]
	TIME [epoch: 10.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42165986965691216		[learning rate: 0.00060446]
	Learning Rate: 0.000604461
	LOSS [training: 0.42165986965691216 | validation: 0.45034892142830296]
	TIME [epoch: 10.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46793155066593883		[learning rate: 0.00060227]
	Learning Rate: 0.000602268
	LOSS [training: 0.46793155066593883 | validation: 0.5524428553685603]
	TIME [epoch: 10.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4146932128246513		[learning rate: 0.00060008]
	Learning Rate: 0.000600082
	LOSS [training: 0.4146932128246513 | validation: 0.4037032569106683]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_874.pth
	Model improved!!!
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4107456108588366		[learning rate: 0.0005979]
	Learning Rate: 0.000597904
	LOSS [training: 0.4107456108588366 | validation: 0.4475767012177508]
	TIME [epoch: 10.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44985184413499385		[learning rate: 0.00059573]
	Learning Rate: 0.000595734
	LOSS [training: 0.44985184413499385 | validation: 0.49937898495406174]
	TIME [epoch: 10.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4490109979217383		[learning rate: 0.00059357]
	Learning Rate: 0.000593572
	LOSS [training: 0.4490109979217383 | validation: 0.4652136865592546]
	TIME [epoch: 10.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5047672075755483		[learning rate: 0.00059142]
	Learning Rate: 0.000591418
	LOSS [training: 0.5047672075755483 | validation: 0.48001872947465873]
	TIME [epoch: 10.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4262906791132054		[learning rate: 0.00058927]
	Learning Rate: 0.000589272
	LOSS [training: 0.4262906791132054 | validation: 0.45775446995122054]
	TIME [epoch: 10.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41231743207118743		[learning rate: 0.00058713]
	Learning Rate: 0.000587133
	LOSS [training: 0.41231743207118743 | validation: 0.5065485827028964]
	TIME [epoch: 10.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47336024839469665		[learning rate: 0.000585]
	Learning Rate: 0.000585003
	LOSS [training: 0.47336024839469665 | validation: 0.4103028787976784]
	TIME [epoch: 10.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42675575633518276		[learning rate: 0.00058288]
	Learning Rate: 0.00058288
	LOSS [training: 0.42675575633518276 | validation: 0.4653733557562151]
	TIME [epoch: 10.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.408973352792524		[learning rate: 0.00058076]
	Learning Rate: 0.000580764
	LOSS [training: 0.408973352792524 | validation: 0.38993430806486185]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_883.pth
	Model improved!!!
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035324446469346		[learning rate: 0.00057866]
	Learning Rate: 0.000578657
	LOSS [training: 0.4035324446469346 | validation: 0.4438052819071179]
	TIME [epoch: 10.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42835290356186695		[learning rate: 0.00057656]
	Learning Rate: 0.000576557
	LOSS [training: 0.42835290356186695 | validation: 0.44922621728694623]
	TIME [epoch: 10.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42517032185552317		[learning rate: 0.00057446]
	Learning Rate: 0.000574465
	LOSS [training: 0.42517032185552317 | validation: 0.4957551387929509]
	TIME [epoch: 10.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4227563169466265		[learning rate: 0.00057238]
	Learning Rate: 0.00057238
	LOSS [training: 0.4227563169466265 | validation: 0.4480036324834717]
	TIME [epoch: 10.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4256830062122855		[learning rate: 0.0005703]
	Learning Rate: 0.000570303
	LOSS [training: 0.4256830062122855 | validation: 0.45122657627891694]
	TIME [epoch: 10.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4523921857476692		[learning rate: 0.00056823]
	Learning Rate: 0.000568233
	LOSS [training: 0.4523921857476692 | validation: 0.6341978808423597]
	TIME [epoch: 10.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5393335556989969		[learning rate: 0.00056617]
	Learning Rate: 0.000566171
	LOSS [training: 0.5393335556989969 | validation: 0.42151408061074314]
	TIME [epoch: 10.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42450608510543697		[learning rate: 0.00056412]
	Learning Rate: 0.000564116
	LOSS [training: 0.42450608510543697 | validation: 0.41713695800086575]
	TIME [epoch: 10.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43665457205857255		[learning rate: 0.00056207]
	Learning Rate: 0.000562069
	LOSS [training: 0.43665457205857255 | validation: 0.5065623027651247]
	TIME [epoch: 10.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263694131766701		[learning rate: 0.00056003]
	Learning Rate: 0.000560029
	LOSS [training: 0.4263694131766701 | validation: 0.4950354831806864]
	TIME [epoch: 10.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929928325234637		[learning rate: 0.000558]
	Learning Rate: 0.000557997
	LOSS [training: 0.3929928325234637 | validation: 0.4706121558549262]
	TIME [epoch: 10.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4304587509750507		[learning rate: 0.00055597]
	Learning Rate: 0.000555972
	LOSS [training: 0.4304587509750507 | validation: 0.4342117111277939]
	TIME [epoch: 10.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.394837527930131		[learning rate: 0.00055395]
	Learning Rate: 0.000553954
	LOSS [training: 0.394837527930131 | validation: 0.4092478977724322]
	TIME [epoch: 10.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42970128217199255		[learning rate: 0.00055194]
	Learning Rate: 0.000551944
	LOSS [training: 0.42970128217199255 | validation: 0.37436482167705576]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644503718678255		[learning rate: 0.00054994]
	Learning Rate: 0.000549941
	LOSS [training: 0.4644503718678255 | validation: 0.47916557427233436]
	TIME [epoch: 10.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39639433162975063		[learning rate: 0.00054794]
	Learning Rate: 0.000547945
	LOSS [training: 0.39639433162975063 | validation: 0.4197912766713789]
	TIME [epoch: 10.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4066132592096734		[learning rate: 0.00054596]
	Learning Rate: 0.000545956
	LOSS [training: 0.4066132592096734 | validation: 0.4090419970013446]
	TIME [epoch: 10.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38683244053860366		[learning rate: 0.00054397]
	Learning Rate: 0.000543975
	LOSS [training: 0.38683244053860366 | validation: 0.4439942064879525]
	TIME [epoch: 10.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3979124546601862		[learning rate: 0.000542]
	Learning Rate: 0.000542001
	LOSS [training: 0.3979124546601862 | validation: 0.4158081429570657]
	TIME [epoch: 10.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38438011268648276		[learning rate: 0.00054003]
	Learning Rate: 0.000540034
	LOSS [training: 0.38438011268648276 | validation: 0.40740920349021936]
	TIME [epoch: 10.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3862925791549559		[learning rate: 0.00053807]
	Learning Rate: 0.000538074
	LOSS [training: 0.3862925791549559 | validation: 0.4456788791989845]
	TIME [epoch: 10.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39395807598332916		[learning rate: 0.00053612]
	Learning Rate: 0.000536121
	LOSS [training: 0.39395807598332916 | validation: 0.4325509875306139]
	TIME [epoch: 10.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39995738621563764		[learning rate: 0.00053418]
	Learning Rate: 0.000534176
	LOSS [training: 0.39995738621563764 | validation: 0.4660684272889901]
	TIME [epoch: 10.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41740820409961527		[learning rate: 0.00053224]
	Learning Rate: 0.000532237
	LOSS [training: 0.41740820409961527 | validation: 0.4131625226009539]
	TIME [epoch: 10.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43463648797090393		[learning rate: 0.00053031]
	Learning Rate: 0.000530306
	LOSS [training: 0.43463648797090393 | validation: 0.4251752685532791]
	TIME [epoch: 10.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4046276188328187		[learning rate: 0.00052838]
	Learning Rate: 0.000528381
	LOSS [training: 0.4046276188328187 | validation: 0.43978938767737497]
	TIME [epoch: 10.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3840629236800986		[learning rate: 0.00052646]
	Learning Rate: 0.000526464
	LOSS [training: 0.3840629236800986 | validation: 0.48288721660852113]
	TIME [epoch: 10.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122769375392473		[learning rate: 0.00052455]
	Learning Rate: 0.000524553
	LOSS [training: 0.4122769375392473 | validation: 0.49546076612003526]
	TIME [epoch: 10.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4093828221269584		[learning rate: 0.00052265]
	Learning Rate: 0.000522649
	LOSS [training: 0.4093828221269584 | validation: 0.4429736349434036]
	TIME [epoch: 10.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050284312484711		[learning rate: 0.00052075]
	Learning Rate: 0.000520753
	LOSS [training: 0.5050284312484711 | validation: 0.43129107764085073]
	TIME [epoch: 10.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3938805354890774		[learning rate: 0.00051886]
	Learning Rate: 0.000518863
	LOSS [training: 0.3938805354890774 | validation: 0.426195720323716]
	TIME [epoch: 10.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44716232608225626		[learning rate: 0.00051698]
	Learning Rate: 0.00051698
	LOSS [training: 0.44716232608225626 | validation: 0.40497553710215983]
	TIME [epoch: 10.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41912267932388153		[learning rate: 0.0005151]
	Learning Rate: 0.000515104
	LOSS [training: 0.41912267932388153 | validation: 0.4454891303839047]
	TIME [epoch: 10.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3891639233670509		[learning rate: 0.00051323]
	Learning Rate: 0.000513235
	LOSS [training: 0.3891639233670509 | validation: 0.46763669727015567]
	TIME [epoch: 10.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42757658545648436		[learning rate: 0.00051137]
	Learning Rate: 0.000511372
	LOSS [training: 0.42757658545648436 | validation: 0.46104900248470265]
	TIME [epoch: 10.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42251166439019966		[learning rate: 0.00050952]
	Learning Rate: 0.000509516
	LOSS [training: 0.42251166439019966 | validation: 0.5194550284020357]
	TIME [epoch: 10.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4348574189052622		[learning rate: 0.00050767]
	Learning Rate: 0.000507667
	LOSS [training: 0.4348574189052622 | validation: 0.4216071877581984]
	TIME [epoch: 10.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40760853925031204		[learning rate: 0.00050582]
	Learning Rate: 0.000505825
	LOSS [training: 0.40760853925031204 | validation: 0.38718379062039193]
	TIME [epoch: 10.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3675815670514655		[learning rate: 0.00050399]
	Learning Rate: 0.000503989
	LOSS [training: 0.3675815670514655 | validation: 0.522219522970631]
	TIME [epoch: 10.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4605414958593899		[learning rate: 0.00050216]
	Learning Rate: 0.00050216
	LOSS [training: 0.4605414958593899 | validation: 0.4274031185958426]
	TIME [epoch: 10.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38700584455006765		[learning rate: 0.00050034]
	Learning Rate: 0.000500338
	LOSS [training: 0.38700584455006765 | validation: 0.42099948667666676]
	TIME [epoch: 10.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4493109400223519		[learning rate: 0.00049852]
	Learning Rate: 0.000498522
	LOSS [training: 0.4493109400223519 | validation: 0.4790478694855454]
	TIME [epoch: 10.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40996904035101506		[learning rate: 0.00049671]
	Learning Rate: 0.000496713
	LOSS [training: 0.40996904035101506 | validation: 0.4110973459312241]
	TIME [epoch: 10.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41484234813840926		[learning rate: 0.00049491]
	Learning Rate: 0.00049491
	LOSS [training: 0.41484234813840926 | validation: 0.4355850641748255]
	TIME [epoch: 10.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47771568696576894		[learning rate: 0.00049311]
	Learning Rate: 0.000493114
	LOSS [training: 0.47771568696576894 | validation: 0.478467382280801]
	TIME [epoch: 10.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4226885746776722		[learning rate: 0.00049132]
	Learning Rate: 0.000491325
	LOSS [training: 0.4226885746776722 | validation: 0.49216126161231905]
	TIME [epoch: 10.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42947434596955975		[learning rate: 0.00048954]
	Learning Rate: 0.000489542
	LOSS [training: 0.42947434596955975 | validation: 0.44221028968944537]
	TIME [epoch: 10.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4120704476203313		[learning rate: 0.00048776]
	Learning Rate: 0.000487765
	LOSS [training: 0.4120704476203313 | validation: 0.4218563418948824]
	TIME [epoch: 10.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40016948100289956		[learning rate: 0.00048599]
	Learning Rate: 0.000485995
	LOSS [training: 0.40016948100289956 | validation: 0.45231515254424254]
	TIME [epoch: 10.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44443182728923736		[learning rate: 0.00048423]
	Learning Rate: 0.000484231
	LOSS [training: 0.44443182728923736 | validation: 0.4796165111433255]
	TIME [epoch: 10.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41408447613817845		[learning rate: 0.00048247]
	Learning Rate: 0.000482474
	LOSS [training: 0.41408447613817845 | validation: 0.4013507273465033]
	TIME [epoch: 10.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37460336632023683		[learning rate: 0.00048072]
	Learning Rate: 0.000480723
	LOSS [training: 0.37460336632023683 | validation: 0.46862549854744745]
	TIME [epoch: 10.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42962715419649855		[learning rate: 0.00047898]
	Learning Rate: 0.000478978
	LOSS [training: 0.42962715419649855 | validation: 0.4303024430520159]
	TIME [epoch: 10.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4086030456123785		[learning rate: 0.00047724]
	Learning Rate: 0.00047724
	LOSS [training: 0.4086030456123785 | validation: 0.3965572732670655]
	TIME [epoch: 10.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3914975136667909		[learning rate: 0.00047551]
	Learning Rate: 0.000475508
	LOSS [training: 0.3914975136667909 | validation: 0.406273953292663]
	TIME [epoch: 10.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4050808617896119		[learning rate: 0.00047378]
	Learning Rate: 0.000473782
	LOSS [training: 0.4050808617896119 | validation: 0.4110694697529232]
	TIME [epoch: 10.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41850215058069296		[learning rate: 0.00047206]
	Learning Rate: 0.000472063
	LOSS [training: 0.41850215058069296 | validation: 0.5292866620742143]
	TIME [epoch: 10.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4288736092188139		[learning rate: 0.00047035]
	Learning Rate: 0.00047035
	LOSS [training: 0.4288736092188139 | validation: 0.49679383131663574]
	TIME [epoch: 10.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4434956831527675		[learning rate: 0.00046864]
	Learning Rate: 0.000468643
	LOSS [training: 0.4434956831527675 | validation: 0.5958397177663597]
	TIME [epoch: 10.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48378764614872827		[learning rate: 0.00046694]
	Learning Rate: 0.000466942
	LOSS [training: 0.48378764614872827 | validation: 0.48895225193270675]
	TIME [epoch: 10.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40174121204357804		[learning rate: 0.00046525]
	Learning Rate: 0.000465248
	LOSS [training: 0.40174121204357804 | validation: 0.4166928006801313]
	TIME [epoch: 10.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4185848313762537		[learning rate: 0.00046356]
	Learning Rate: 0.000463559
	LOSS [training: 0.4185848313762537 | validation: 0.4892934611827315]
	TIME [epoch: 10.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40920191648348875		[learning rate: 0.00046188]
	Learning Rate: 0.000461877
	LOSS [training: 0.40920191648348875 | validation: 0.4324003018131937]
	TIME [epoch: 10.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40763514728632		[learning rate: 0.0004602]
	Learning Rate: 0.000460201
	LOSS [training: 0.40763514728632 | validation: 0.4055812099997793]
	TIME [epoch: 10.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38356076259931143		[learning rate: 0.00045853]
	Learning Rate: 0.000458531
	LOSS [training: 0.38356076259931143 | validation: 0.4704925384212663]
	TIME [epoch: 10.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38833740691283614		[learning rate: 0.00045687]
	Learning Rate: 0.000456867
	LOSS [training: 0.38833740691283614 | validation: 0.4313876351211803]
	TIME [epoch: 10.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4184461506081196		[learning rate: 0.00045521]
	Learning Rate: 0.000455209
	LOSS [training: 0.4184461506081196 | validation: 0.5091318847843778]
	TIME [epoch: 10.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4787975582507949		[learning rate: 0.00045356]
	Learning Rate: 0.000453557
	LOSS [training: 0.4787975582507949 | validation: 0.3846144092657584]
	TIME [epoch: 10.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176149835288592		[learning rate: 0.00045191]
	Learning Rate: 0.000451911
	LOSS [training: 0.4176149835288592 | validation: 0.42020309125581634]
	TIME [epoch: 10.4 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39847589648390835		[learning rate: 0.00045027]
	Learning Rate: 0.000450271
	LOSS [training: 0.39847589648390835 | validation: 0.46926199140681457]
	TIME [epoch: 10.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40823780661198794		[learning rate: 0.00044864]
	Learning Rate: 0.000448637
	LOSS [training: 0.40823780661198794 | validation: 0.43457140657459653]
	TIME [epoch: 10.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3832030611411169		[learning rate: 0.00044701]
	Learning Rate: 0.000447009
	LOSS [training: 0.3832030611411169 | validation: 0.37650358357889235]
	TIME [epoch: 10.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39082667382089875		[learning rate: 0.00044539]
	Learning Rate: 0.000445386
	LOSS [training: 0.39082667382089875 | validation: 0.38377586771657934]
	TIME [epoch: 10.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3762081787205047		[learning rate: 0.00044377]
	Learning Rate: 0.00044377
	LOSS [training: 0.3762081787205047 | validation: 0.4493294749109283]
	TIME [epoch: 10.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4043878651551527		[learning rate: 0.00044216]
	Learning Rate: 0.00044216
	LOSS [training: 0.4043878651551527 | validation: 0.48769223913662585]
	TIME [epoch: 10.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39202467597142376		[learning rate: 0.00044055]
	Learning Rate: 0.000440555
	LOSS [training: 0.39202467597142376 | validation: 0.41678724077149315]
	TIME [epoch: 10.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38179793667639506		[learning rate: 0.00043896]
	Learning Rate: 0.000438956
	LOSS [training: 0.38179793667639506 | validation: 0.40458424402971466]
	TIME [epoch: 10.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876055871776932		[learning rate: 0.00043736]
	Learning Rate: 0.000437363
	LOSS [training: 0.3876055871776932 | validation: 0.4297071452781184]
	TIME [epoch: 10.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4187893661020605		[learning rate: 0.00043578]
	Learning Rate: 0.000435776
	LOSS [training: 0.4187893661020605 | validation: 0.402386429753352]
	TIME [epoch: 10.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4576541469283072		[learning rate: 0.00043419]
	Learning Rate: 0.000434194
	LOSS [training: 0.4576541469283072 | validation: 0.4021223142215017]
	TIME [epoch: 10.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5206417289418992		[learning rate: 0.00043262]
	Learning Rate: 0.000432619
	LOSS [training: 0.5206417289418992 | validation: 0.38128132548402577]
	TIME [epoch: 10.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4273468580827304		[learning rate: 0.00043105]
	Learning Rate: 0.000431049
	LOSS [training: 0.4273468580827304 | validation: 0.47855735679522715]
	TIME [epoch: 10.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5060979121532612		[learning rate: 0.00042948]
	Learning Rate: 0.000429484
	LOSS [training: 0.5060979121532612 | validation: 0.4539558472836107]
	TIME [epoch: 10.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3803293956229571		[learning rate: 0.00042793]
	Learning Rate: 0.000427926
	LOSS [training: 0.3803293956229571 | validation: 0.45805502603061954]
	TIME [epoch: 10.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40626926163983546		[learning rate: 0.00042637]
	Learning Rate: 0.000426373
	LOSS [training: 0.40626926163983546 | validation: 0.3887890183916428]
	TIME [epoch: 10.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35151983368385276		[learning rate: 0.00042483]
	Learning Rate: 0.000424825
	LOSS [training: 0.35151983368385276 | validation: 0.40495024223110176]
	TIME [epoch: 10.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35876109187829386		[learning rate: 0.00042328]
	Learning Rate: 0.000423284
	LOSS [training: 0.35876109187829386 | validation: 0.4038835128097613]
	TIME [epoch: 10.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742482848842437		[learning rate: 0.00042175]
	Learning Rate: 0.000421748
	LOSS [training: 0.3742482848842437 | validation: 0.4150652246688037]
	TIME [epoch: 10.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41040338422405054		[learning rate: 0.00042022]
	Learning Rate: 0.000420217
	LOSS [training: 0.41040338422405054 | validation: 0.3741694207193146]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_972.pth
	Model improved!!!
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38130651518766906		[learning rate: 0.00041869]
	Learning Rate: 0.000418692
	LOSS [training: 0.38130651518766906 | validation: 0.39037558835311814]
	TIME [epoch: 10.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39354853098873116		[learning rate: 0.00041717]
	Learning Rate: 0.000417173
	LOSS [training: 0.39354853098873116 | validation: 0.3865182050104787]
	TIME [epoch: 10.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3758974222448588		[learning rate: 0.00041566]
	Learning Rate: 0.000415659
	LOSS [training: 0.3758974222448588 | validation: 0.4426767001001039]
	TIME [epoch: 10.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39518661502384417		[learning rate: 0.00041415]
	Learning Rate: 0.00041415
	LOSS [training: 0.39518661502384417 | validation: 0.39369545056424016]
	TIME [epoch: 10.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39240155827423673		[learning rate: 0.00041265]
	Learning Rate: 0.000412647
	LOSS [training: 0.39240155827423673 | validation: 0.40585254550568556]
	TIME [epoch: 10.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4130474490064054		[learning rate: 0.00041115]
	Learning Rate: 0.00041115
	LOSS [training: 0.4130474490064054 | validation: 0.4249952079088024]
	TIME [epoch: 10.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39070425691124366		[learning rate: 0.00040966]
	Learning Rate: 0.000409658
	LOSS [training: 0.39070425691124366 | validation: 0.4768996736343721]
	TIME [epoch: 10.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38484843963396276		[learning rate: 0.00040817]
	Learning Rate: 0.000408171
	LOSS [training: 0.38484843963396276 | validation: 0.4970510792318109]
	TIME [epoch: 10.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909856953395101		[learning rate: 0.00040669]
	Learning Rate: 0.00040669
	LOSS [training: 0.3909856953395101 | validation: 0.4862625002149061]
	TIME [epoch: 10.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37700025215162775		[learning rate: 0.00040521]
	Learning Rate: 0.000405214
	LOSS [training: 0.37700025215162775 | validation: 0.43397103363131323]
	TIME [epoch: 10.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39393532612284987		[learning rate: 0.00040374]
	Learning Rate: 0.000403743
	LOSS [training: 0.39393532612284987 | validation: 0.44040601911821725]
	TIME [epoch: 10.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4021061715196481		[learning rate: 0.00040228]
	Learning Rate: 0.000402278
	LOSS [training: 0.4021061715196481 | validation: 0.39883241444350304]
	TIME [epoch: 10.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.388146105713873		[learning rate: 0.00040082]
	Learning Rate: 0.000400818
	LOSS [training: 0.388146105713873 | validation: 0.40283501460150667]
	TIME [epoch: 10.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37715079511717886		[learning rate: 0.00039936]
	Learning Rate: 0.000399364
	LOSS [training: 0.37715079511717886 | validation: 0.3957555220734888]
	TIME [epoch: 10.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3970709622856413		[learning rate: 0.00039791]
	Learning Rate: 0.000397914
	LOSS [training: 0.3970709622856413 | validation: 0.45311814138980694]
	TIME [epoch: 10.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3603590987168975		[learning rate: 0.00039647]
	Learning Rate: 0.00039647
	LOSS [training: 0.3603590987168975 | validation: 0.4314311784158813]
	TIME [epoch: 10.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3667880773051987		[learning rate: 0.00039503]
	Learning Rate: 0.000395031
	LOSS [training: 0.3667880773051987 | validation: 0.4439260433125006]
	TIME [epoch: 10.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38291994281328556		[learning rate: 0.0003936]
	Learning Rate: 0.000393598
	LOSS [training: 0.38291994281328556 | validation: 0.3929810171303248]
	TIME [epoch: 10.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720299408026685		[learning rate: 0.00039217]
	Learning Rate: 0.000392169
	LOSS [training: 0.3720299408026685 | validation: 0.4423030427765625]
	TIME [epoch: 10.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3978860345190361		[learning rate: 0.00039075]
	Learning Rate: 0.000390746
	LOSS [training: 0.3978860345190361 | validation: 0.4160450970979428]
	TIME [epoch: 10.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36857342260430687		[learning rate: 0.00038933]
	Learning Rate: 0.000389328
	LOSS [training: 0.36857342260430687 | validation: 0.44005526965706104]
	TIME [epoch: 10.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3724365983603801		[learning rate: 0.00038792]
	Learning Rate: 0.000387915
	LOSS [training: 0.3724365983603801 | validation: 0.4171883466821038]
	TIME [epoch: 10.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3824175979428601		[learning rate: 0.00038651]
	Learning Rate: 0.000386508
	LOSS [training: 0.3824175979428601 | validation: 0.4167095132423512]
	TIME [epoch: 10.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37922716524325184		[learning rate: 0.0003851]
	Learning Rate: 0.000385105
	LOSS [training: 0.37922716524325184 | validation: 0.37884611724281647]
	TIME [epoch: 10.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38253055572349354		[learning rate: 0.00038371]
	Learning Rate: 0.000383707
	LOSS [training: 0.38253055572349354 | validation: 0.43587864065431753]
	TIME [epoch: 10.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37195528766596286		[learning rate: 0.00038231]
	Learning Rate: 0.000382315
	LOSS [training: 0.37195528766596286 | validation: 0.43500715218284813]
	TIME [epoch: 10.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3732940386860304		[learning rate: 0.00038093]
	Learning Rate: 0.000380927
	LOSS [training: 0.3732940386860304 | validation: 0.39751585227566866]
	TIME [epoch: 10.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42807244495957003		[learning rate: 0.00037954]
	Learning Rate: 0.000379545
	LOSS [training: 0.42807244495957003 | validation: 0.40485823052422815]
	TIME [epoch: 10.4 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4249251258603093		[learning rate: 0.00037817]
	Learning Rate: 0.000378167
	LOSS [training: 0.4249251258603093 | validation: 0.4386645086580209]
	TIME [epoch: 10.4 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3823784032277747		[learning rate: 0.0003768]
	Learning Rate: 0.000376795
	LOSS [training: 0.3823784032277747 | validation: 0.41299884471266785]
	TIME [epoch: 10.4 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.362403331220387		[learning rate: 0.00037543]
	Learning Rate: 0.000375428
	LOSS [training: 0.362403331220387 | validation: 0.3632197717807196]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1003.pth
	Model improved!!!
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36953280396491683		[learning rate: 0.00037407]
	Learning Rate: 0.000374065
	LOSS [training: 0.36953280396491683 | validation: 0.3959702115859699]
	TIME [epoch: 10.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3602484855968199		[learning rate: 0.00037271]
	Learning Rate: 0.000372708
	LOSS [training: 0.3602484855968199 | validation: 0.3890243399987361]
	TIME [epoch: 10.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3547460698159427		[learning rate: 0.00037136]
	Learning Rate: 0.000371355
	LOSS [training: 0.3547460698159427 | validation: 0.4090556711867867]
	TIME [epoch: 10.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37132711960347486		[learning rate: 0.00037001]
	Learning Rate: 0.000370008
	LOSS [training: 0.37132711960347486 | validation: 0.4140266370322961]
	TIME [epoch: 10.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615405444432658		[learning rate: 0.00036866]
	Learning Rate: 0.000368665
	LOSS [training: 0.3615405444432658 | validation: 0.3842491329532146]
	TIME [epoch: 10.4 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3606088108656754		[learning rate: 0.00036733]
	Learning Rate: 0.000367327
	LOSS [training: 0.3606088108656754 | validation: 0.3804144181897624]
	TIME [epoch: 10.4 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3551678849545937		[learning rate: 0.00036599]
	Learning Rate: 0.000365994
	LOSS [training: 0.3551678849545937 | validation: 0.3699645396638204]
	TIME [epoch: 10.4 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3474847705772551		[learning rate: 0.00036467]
	Learning Rate: 0.000364666
	LOSS [training: 0.3474847705772551 | validation: 0.37566305942859257]
	TIME [epoch: 10.4 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37161500292703786		[learning rate: 0.00036334]
	Learning Rate: 0.000363342
	LOSS [training: 0.37161500292703786 | validation: 0.3926120660122813]
	TIME [epoch: 10.4 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36932851630902175		[learning rate: 0.00036202]
	Learning Rate: 0.000362024
	LOSS [training: 0.36932851630902175 | validation: 0.4044179024874408]
	TIME [epoch: 10.4 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38913080701176705		[learning rate: 0.00036071]
	Learning Rate: 0.00036071
	LOSS [training: 0.38913080701176705 | validation: 0.41499182232756326]
	TIME [epoch: 10.4 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36460947720489684		[learning rate: 0.0003594]
	Learning Rate: 0.000359401
	LOSS [training: 0.36460947720489684 | validation: 0.4126481522366363]
	TIME [epoch: 10.4 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3789665003472123		[learning rate: 0.0003581]
	Learning Rate: 0.000358096
	LOSS [training: 0.3789665003472123 | validation: 0.41664268333411736]
	TIME [epoch: 10.4 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39527870423190625		[learning rate: 0.0003568]
	Learning Rate: 0.000356797
	LOSS [training: 0.39527870423190625 | validation: 0.42902655086008656]
	TIME [epoch: 10.4 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37478304467888424		[learning rate: 0.0003555]
	Learning Rate: 0.000355502
	LOSS [training: 0.37478304467888424 | validation: 0.4052296015612781]
	TIME [epoch: 10.4 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020715999449358		[learning rate: 0.00035421]
	Learning Rate: 0.000354212
	LOSS [training: 0.4020715999449358 | validation: 0.4273246698635515]
	TIME [epoch: 10.4 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37212870379784074		[learning rate: 0.00035293]
	Learning Rate: 0.000352926
	LOSS [training: 0.37212870379784074 | validation: 0.4186757688837468]
	TIME [epoch: 10.4 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37281207486947954		[learning rate: 0.00035165]
	Learning Rate: 0.000351646
	LOSS [training: 0.37281207486947954 | validation: 0.4218154608454719]
	TIME [epoch: 10.4 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38062489963653434		[learning rate: 0.00035037]
	Learning Rate: 0.00035037
	LOSS [training: 0.38062489963653434 | validation: 0.4314553187983533]
	TIME [epoch: 10.4 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3873929521565397		[learning rate: 0.0003491]
	Learning Rate: 0.000349098
	LOSS [training: 0.3873929521565397 | validation: 0.3913843831512597]
	TIME [epoch: 10.4 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40865198079829856		[learning rate: 0.00034783]
	Learning Rate: 0.000347831
	LOSS [training: 0.40865198079829856 | validation: 0.46480007820339325]
	TIME [epoch: 10.4 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35298093295170396		[learning rate: 0.00034657]
	Learning Rate: 0.000346569
	LOSS [training: 0.35298093295170396 | validation: 0.4578745775417929]
	TIME [epoch: 10.4 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38138208766704773		[learning rate: 0.00034531]
	Learning Rate: 0.000345311
	LOSS [training: 0.38138208766704773 | validation: 0.41901716331618977]
	TIME [epoch: 10.4 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39132714188481876		[learning rate: 0.00034406]
	Learning Rate: 0.000344058
	LOSS [training: 0.39132714188481876 | validation: 0.47334925725683075]
	TIME [epoch: 10.4 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.421705150436369		[learning rate: 0.00034281]
	Learning Rate: 0.000342809
	LOSS [training: 0.421705150436369 | validation: 0.45175361150669074]
	TIME [epoch: 10.4 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720927443280041		[learning rate: 0.00034157]
	Learning Rate: 0.000341565
	LOSS [training: 0.3720927443280041 | validation: 0.4450062566850264]
	TIME [epoch: 10.4 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3746450232651196		[learning rate: 0.00034033]
	Learning Rate: 0.000340326
	LOSS [training: 0.3746450232651196 | validation: 0.4046004446802266]
	TIME [epoch: 10.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39703708144448757		[learning rate: 0.00033909]
	Learning Rate: 0.000339091
	LOSS [training: 0.39703708144448757 | validation: 0.4557849923918483]
	TIME [epoch: 10.4 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37958845325543633		[learning rate: 0.00033786]
	Learning Rate: 0.00033786
	LOSS [training: 0.37958845325543633 | validation: 0.38723713625077866]
	TIME [epoch: 10.4 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36588511867207985		[learning rate: 0.00033663]
	Learning Rate: 0.000336634
	LOSS [training: 0.36588511867207985 | validation: 0.44920627019850357]
	TIME [epoch: 10.4 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36398484223341043		[learning rate: 0.00033541]
	Learning Rate: 0.000335412
	LOSS [training: 0.36398484223341043 | validation: 0.4446395445864824]
	TIME [epoch: 10.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36722802756268036		[learning rate: 0.0003342]
	Learning Rate: 0.000334195
	LOSS [training: 0.36722802756268036 | validation: 0.45219264031590134]
	TIME [epoch: 10.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37022209953329355		[learning rate: 0.00033298]
	Learning Rate: 0.000332982
	LOSS [training: 0.37022209953329355 | validation: 0.43081497417624176]
	TIME [epoch: 10.4 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37654297434643724		[learning rate: 0.00033177]
	Learning Rate: 0.000331774
	LOSS [training: 0.37654297434643724 | validation: 0.3924389409854092]
	TIME [epoch: 10.4 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39679590013837884		[learning rate: 0.00033057]
	Learning Rate: 0.00033057
	LOSS [training: 0.39679590013837884 | validation: 0.44541494204185]
	TIME [epoch: 10.4 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4110019683276699		[learning rate: 0.00032937]
	Learning Rate: 0.00032937
	LOSS [training: 0.4110019683276699 | validation: 0.4242484924574887]
	TIME [epoch: 10.4 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3741147016790398		[learning rate: 0.00032817]
	Learning Rate: 0.000328175
	LOSS [training: 0.3741147016790398 | validation: 0.37824370763048476]
	TIME [epoch: 10.4 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3610822371491286		[learning rate: 0.00032698]
	Learning Rate: 0.000326984
	LOSS [training: 0.3610822371491286 | validation: 0.428231780369739]
	TIME [epoch: 10.4 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38803225140846676		[learning rate: 0.0003258]
	Learning Rate: 0.000325797
	LOSS [training: 0.38803225140846676 | validation: 0.4116113183796641]
	TIME [epoch: 10.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3567998705580686		[learning rate: 0.00032461]
	Learning Rate: 0.000324615
	LOSS [training: 0.3567998705580686 | validation: 0.41520573579780384]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36532585424837805		[learning rate: 0.00032344]
	Learning Rate: 0.000323437
	LOSS [training: 0.36532585424837805 | validation: 0.39278368542635905]
	TIME [epoch: 10.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3628274303822591		[learning rate: 0.00032226]
	Learning Rate: 0.000322263
	LOSS [training: 0.3628274303822591 | validation: 0.42465819189758586]
	TIME [epoch: 10.4 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37611931774622503		[learning rate: 0.00032109]
	Learning Rate: 0.000321094
	LOSS [training: 0.37611931774622503 | validation: 0.3931290808726779]
	TIME [epoch: 10.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3620344591441444		[learning rate: 0.00031993]
	Learning Rate: 0.000319928
	LOSS [training: 0.3620344591441444 | validation: 0.40673745581704923]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39947007433761544		[learning rate: 0.00031877]
	Learning Rate: 0.000318767
	LOSS [training: 0.39947007433761544 | validation: 0.44720059831627085]
	TIME [epoch: 10.4 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40333408064857634		[learning rate: 0.00031761]
	Learning Rate: 0.000317611
	LOSS [training: 0.40333408064857634 | validation: 0.3956340601552496]
	TIME [epoch: 10.4 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39619174963702675		[learning rate: 0.00031646]
	Learning Rate: 0.000316458
	LOSS [training: 0.39619174963702675 | validation: 0.45616843115218586]
	TIME [epoch: 10.4 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38824925236233987		[learning rate: 0.00031531]
	Learning Rate: 0.000315309
	LOSS [training: 0.38824925236233987 | validation: 0.43788611202749284]
	TIME [epoch: 10.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626278059740661		[learning rate: 0.00031417]
	Learning Rate: 0.000314165
	LOSS [training: 0.3626278059740661 | validation: 0.39323017073698174]
	TIME [epoch: 10.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38733160152238544		[learning rate: 0.00031302]
	Learning Rate: 0.000313025
	LOSS [training: 0.38733160152238544 | validation: 0.43878346612227304]
	TIME [epoch: 10.4 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4167709874427832		[learning rate: 0.00031189]
	Learning Rate: 0.000311889
	LOSS [training: 0.4167709874427832 | validation: 0.44731235090865823]
	TIME [epoch: 10.4 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3873490270548176		[learning rate: 0.00031076]
	Learning Rate: 0.000310757
	LOSS [training: 0.3873490270548176 | validation: 0.4368721781214964]
	TIME [epoch: 10.4 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3531631918054242		[learning rate: 0.00030963]
	Learning Rate: 0.000309629
	LOSS [training: 0.3531631918054242 | validation: 0.38478826529147797]
	TIME [epoch: 10.4 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38257251742984055		[learning rate: 0.00030851]
	Learning Rate: 0.000308506
	LOSS [training: 0.38257251742984055 | validation: 0.4249157655941813]
	TIME [epoch: 10.4 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3932755610512119		[learning rate: 0.00030739]
	Learning Rate: 0.000307386
	LOSS [training: 0.3932755610512119 | validation: 0.420070830861856]
	TIME [epoch: 10.4 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36015464059707836		[learning rate: 0.00030627]
	Learning Rate: 0.000306271
	LOSS [training: 0.36015464059707836 | validation: 0.4421094931793641]
	TIME [epoch: 10.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36808809621978966		[learning rate: 0.00030516]
	Learning Rate: 0.000305159
	LOSS [training: 0.36808809621978966 | validation: 0.39037156418514535]
	TIME [epoch: 10.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36904157535157384		[learning rate: 0.00030405]
	Learning Rate: 0.000304052
	LOSS [training: 0.36904157535157384 | validation: 0.4531158073523236]
	TIME [epoch: 10.4 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3616001638724902		[learning rate: 0.00030295]
	Learning Rate: 0.000302948
	LOSS [training: 0.3616001638724902 | validation: 0.37381617506871273]
	TIME [epoch: 10.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36243906511174906		[learning rate: 0.00030185]
	Learning Rate: 0.000301849
	LOSS [training: 0.36243906511174906 | validation: 0.40792641197239476]
	TIME [epoch: 10.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3793029990246222		[learning rate: 0.00030075]
	Learning Rate: 0.000300753
	LOSS [training: 0.3793029990246222 | validation: 0.36773093254063793]
	TIME [epoch: 10.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36396254711291737		[learning rate: 0.00029966]
	Learning Rate: 0.000299662
	LOSS [training: 0.36396254711291737 | validation: 0.42077690774004095]
	TIME [epoch: 10.4 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39611778541127085		[learning rate: 0.00029857]
	Learning Rate: 0.000298574
	LOSS [training: 0.39611778541127085 | validation: 0.4520254939216383]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4095382546284574		[learning rate: 0.00029749]
	Learning Rate: 0.000297491
	LOSS [training: 0.4095382546284574 | validation: 0.564641319952]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4378222122180306		[learning rate: 0.00029641]
	Learning Rate: 0.000296411
	LOSS [training: 0.4378222122180306 | validation: 0.4075587447070912]
	TIME [epoch: 10.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3883050750346109		[learning rate: 0.00029534]
	Learning Rate: 0.000295336
	LOSS [training: 0.3883050750346109 | validation: 0.4016831460186475]
	TIME [epoch: 10.4 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36391348479035657		[learning rate: 0.00029426]
	Learning Rate: 0.000294264
	LOSS [training: 0.36391348479035657 | validation: 0.4505739787469331]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4071100055521192		[learning rate: 0.0002932]
	Learning Rate: 0.000293196
	LOSS [training: 0.4071100055521192 | validation: 0.46417228101035934]
	TIME [epoch: 10.4 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39473913853677167		[learning rate: 0.00029213]
	Learning Rate: 0.000292132
	LOSS [training: 0.39473913853677167 | validation: 0.3800693083016101]
	TIME [epoch: 10.4 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3911008188395311		[learning rate: 0.00029107]
	Learning Rate: 0.000291072
	LOSS [training: 0.3911008188395311 | validation: 0.38167534234543604]
	TIME [epoch: 10.4 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35622737089322076		[learning rate: 0.00029002]
	Learning Rate: 0.000290015
	LOSS [training: 0.35622737089322076 | validation: 0.3992607584320021]
	TIME [epoch: 10.4 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3619402870503295		[learning rate: 0.00028896]
	Learning Rate: 0.000288963
	LOSS [training: 0.3619402870503295 | validation: 0.44200126731465605]
	TIME [epoch: 10.4 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3688569878030802		[learning rate: 0.00028791]
	Learning Rate: 0.000287914
	LOSS [training: 0.3688569878030802 | validation: 0.40141824829609446]
	TIME [epoch: 10.4 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37229260069485925		[learning rate: 0.00028687]
	Learning Rate: 0.000286869
	LOSS [training: 0.37229260069485925 | validation: 0.4402531948530882]
	TIME [epoch: 10.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38102740271761076		[learning rate: 0.00028583]
	Learning Rate: 0.000285828
	LOSS [training: 0.38102740271761076 | validation: 0.3772926225609487]
	TIME [epoch: 10.4 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32904036424701544		[learning rate: 0.00028479]
	Learning Rate: 0.000284791
	LOSS [training: 0.32904036424701544 | validation: 0.40354838865805187]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536177160274715		[learning rate: 0.00028376]
	Learning Rate: 0.000283758
	LOSS [training: 0.3536177160274715 | validation: 0.3666025535210286]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36878016560287186		[learning rate: 0.00028273]
	Learning Rate: 0.000282728
	LOSS [training: 0.36878016560287186 | validation: 0.40693820140490133]
	TIME [epoch: 10.4 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3719680980519514		[learning rate: 0.0002817]
	Learning Rate: 0.000281702
	LOSS [training: 0.3719680980519514 | validation: 0.43869851438368707]
	TIME [epoch: 10.4 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.346015788191585		[learning rate: 0.00028068]
	Learning Rate: 0.000280679
	LOSS [training: 0.346015788191585 | validation: 0.389256023671762]
	TIME [epoch: 10.4 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3783444385443535		[learning rate: 0.00027966]
	Learning Rate: 0.000279661
	LOSS [training: 0.3783444385443535 | validation: 0.401450121843253]
	TIME [epoch: 10.4 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3992425741347533		[learning rate: 0.00027865]
	Learning Rate: 0.000278646
	LOSS [training: 0.3992425741347533 | validation: 0.4238365486614478]
	TIME [epoch: 10.4 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38144855224607094		[learning rate: 0.00027763]
	Learning Rate: 0.000277635
	LOSS [training: 0.38144855224607094 | validation: 0.4645115449462252]
	TIME [epoch: 10.4 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3663161597342277		[learning rate: 0.00027663]
	Learning Rate: 0.000276627
	LOSS [training: 0.3663161597342277 | validation: 0.38493781849723396]
	TIME [epoch: 10.4 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35988937014912314		[learning rate: 0.00027562]
	Learning Rate: 0.000275623
	LOSS [training: 0.35988937014912314 | validation: 0.4330110983143448]
	TIME [epoch: 10.4 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3618457374252055		[learning rate: 0.00027462]
	Learning Rate: 0.000274623
	LOSS [training: 0.3618457374252055 | validation: 0.41571302464411075]
	TIME [epoch: 10.4 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.391080853569525		[learning rate: 0.00027363]
	Learning Rate: 0.000273626
	LOSS [training: 0.391080853569525 | validation: 0.45501806879400547]
	TIME [epoch: 10.4 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.342067804465682		[learning rate: 0.00027263]
	Learning Rate: 0.000272633
	LOSS [training: 0.342067804465682 | validation: 0.3547087532880061]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1091.pth
	Model improved!!!
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36400506471187455		[learning rate: 0.00027164]
	Learning Rate: 0.000271644
	LOSS [training: 0.36400506471187455 | validation: 0.4199300966571545]
	TIME [epoch: 10.3 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3640867749193368		[learning rate: 0.00027066]
	Learning Rate: 0.000270658
	LOSS [training: 0.3640867749193368 | validation: 0.35879562145403227]
	TIME [epoch: 10.4 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35982422556117144		[learning rate: 0.00026968]
	Learning Rate: 0.000269676
	LOSS [training: 0.35982422556117144 | validation: 0.35959828790226434]
	TIME [epoch: 10.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3543195466794186		[learning rate: 0.0002687]
	Learning Rate: 0.000268697
	LOSS [training: 0.3543195466794186 | validation: 0.39606636464385836]
	TIME [epoch: 10.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3656429440244954		[learning rate: 0.00026772]
	Learning Rate: 0.000267722
	LOSS [training: 0.3656429440244954 | validation: 0.3479746965857086]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1096.pth
	Model improved!!!
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35343363366177405		[learning rate: 0.00026675]
	Learning Rate: 0.000266751
	LOSS [training: 0.35343363366177405 | validation: 0.4024916389454712]
	TIME [epoch: 10.4 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36830569677871006		[learning rate: 0.00026578]
	Learning Rate: 0.000265782
	LOSS [training: 0.36830569677871006 | validation: 0.4029468176473278]
	TIME [epoch: 10.4 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35621658842480397		[learning rate: 0.00026482]
	Learning Rate: 0.000264818
	LOSS [training: 0.35621658842480397 | validation: 0.3668404487849691]
	TIME [epoch: 10.4 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34850847175544075		[learning rate: 0.00026386]
	Learning Rate: 0.000263857
	LOSS [training: 0.34850847175544075 | validation: 0.35179372510340473]
	TIME [epoch: 10.4 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3417913961731312		[learning rate: 0.0002629]
	Learning Rate: 0.000262899
	LOSS [training: 0.3417913961731312 | validation: 0.37938067838869516]
	TIME [epoch: 10.4 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3383197929511442		[learning rate: 0.00026195]
	Learning Rate: 0.000261945
	LOSS [training: 0.3383197929511442 | validation: 0.37951059815297217]
	TIME [epoch: 10.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739080188956637		[learning rate: 0.00026099]
	Learning Rate: 0.000260995
	LOSS [training: 0.3739080188956637 | validation: 0.36694117448761204]
	TIME [epoch: 10.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3391633891975677		[learning rate: 0.00026005]
	Learning Rate: 0.000260047
	LOSS [training: 0.3391633891975677 | validation: 0.39959037852862817]
	TIME [epoch: 10.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33402523820235325		[learning rate: 0.0002591]
	Learning Rate: 0.000259104
	LOSS [training: 0.33402523820235325 | validation: 0.4145568453383641]
	TIME [epoch: 10.4 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615234790581254		[learning rate: 0.00025816]
	Learning Rate: 0.000258163
	LOSS [training: 0.3615234790581254 | validation: 0.4006646038626245]
	TIME [epoch: 10.4 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36008027648126895		[learning rate: 0.00025723]
	Learning Rate: 0.000257227
	LOSS [training: 0.36008027648126895 | validation: 0.3891983508656548]
	TIME [epoch: 10.4 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3493740022566596		[learning rate: 0.00025629]
	Learning Rate: 0.000256293
	LOSS [training: 0.3493740022566596 | validation: 0.37326266587303736]
	TIME [epoch: 10.4 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423430700436568		[learning rate: 0.00025536]
	Learning Rate: 0.000255363
	LOSS [training: 0.3423430700436568 | validation: 0.39942956415358266]
	TIME [epoch: 10.4 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3529557002402378		[learning rate: 0.00025444]
	Learning Rate: 0.000254436
	LOSS [training: 0.3529557002402378 | validation: 0.404800860543899]
	TIME [epoch: 10.4 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34882038356582185		[learning rate: 0.00025351]
	Learning Rate: 0.000253513
	LOSS [training: 0.34882038356582185 | validation: 0.403654865552232]
	TIME [epoch: 10.4 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3631404894390737		[learning rate: 0.00025259]
	Learning Rate: 0.000252593
	LOSS [training: 0.3631404894390737 | validation: 0.37559822991522696]
	TIME [epoch: 10.4 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3242153013492719		[learning rate: 0.00025168]
	Learning Rate: 0.000251676
	LOSS [training: 0.3242153013492719 | validation: 0.35872849053597605]
	TIME [epoch: 10.4 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3651165328266675		[learning rate: 0.00025076]
	Learning Rate: 0.000250763
	LOSS [training: 0.3651165328266675 | validation: 0.3860422446255437]
	TIME [epoch: 10.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37283445093952644		[learning rate: 0.00024985]
	Learning Rate: 0.000249853
	LOSS [training: 0.37283445093952644 | validation: 0.37624155424686834]
	TIME [epoch: 10.4 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34491406990993473		[learning rate: 0.00024895]
	Learning Rate: 0.000248946
	LOSS [training: 0.34491406990993473 | validation: 0.365915015810716]
	TIME [epoch: 10.4 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35438159074697856		[learning rate: 0.00024804]
	Learning Rate: 0.000248043
	LOSS [training: 0.35438159074697856 | validation: 0.3804945489127623]
	TIME [epoch: 10.4 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3560380692811095		[learning rate: 0.00024714]
	Learning Rate: 0.000247142
	LOSS [training: 0.3560380692811095 | validation: 0.39153867464762876]
	TIME [epoch: 10.4 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38663162321893557		[learning rate: 0.00024625]
	Learning Rate: 0.000246246
	LOSS [training: 0.38663162321893557 | validation: 0.30886261529028664]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1119.pth
	Model improved!!!
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31546131050830767		[learning rate: 0.00024535]
	Learning Rate: 0.000245352
	LOSS [training: 0.31546131050830767 | validation: 0.37436706405493736]
	TIME [epoch: 10.4 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32941714365627084		[learning rate: 0.00024446]
	Learning Rate: 0.000244462
	LOSS [training: 0.32941714365627084 | validation: 0.3850516177698081]
	TIME [epoch: 10.4 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35466038393798116		[learning rate: 0.00024357]
	Learning Rate: 0.000243574
	LOSS [training: 0.35466038393798116 | validation: 0.37300169750280104]
	TIME [epoch: 10.4 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3760039575453057		[learning rate: 0.00024269]
	Learning Rate: 0.00024269
	LOSS [training: 0.3760039575453057 | validation: 0.3729520313178857]
	TIME [epoch: 10.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240977706424074		[learning rate: 0.00024181]
	Learning Rate: 0.00024181
	LOSS [training: 0.4240977706424074 | validation: 0.37354787221663843]
	TIME [epoch: 10.4 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36235238517930474		[learning rate: 0.00024093]
	Learning Rate: 0.000240932
	LOSS [training: 0.36235238517930474 | validation: 0.3738394486188592]
	TIME [epoch: 10.4 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37050944674832936		[learning rate: 0.00024006]
	Learning Rate: 0.000240058
	LOSS [training: 0.37050944674832936 | validation: 0.3887904392804572]
	TIME [epoch: 10.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420224652149835		[learning rate: 0.00023919]
	Learning Rate: 0.000239187
	LOSS [training: 0.3420224652149835 | validation: 0.3555407580006009]
	TIME [epoch: 10.4 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33366145531306746		[learning rate: 0.00023832]
	Learning Rate: 0.000238319
	LOSS [training: 0.33366145531306746 | validation: 0.33892706557169067]
	TIME [epoch: 10.4 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3238787992741763		[learning rate: 0.00023745]
	Learning Rate: 0.000237454
	LOSS [training: 0.3238787992741763 | validation: 0.3524765952018556]
	TIME [epoch: 10.4 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3506312529862886		[learning rate: 0.00023659]
	Learning Rate: 0.000236592
	LOSS [training: 0.3506312529862886 | validation: 0.3983989829249515]
	TIME [epoch: 10.4 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3374228476546262		[learning rate: 0.00023573]
	Learning Rate: 0.000235733
	LOSS [training: 0.3374228476546262 | validation: 0.411328571667095]
	TIME [epoch: 10.4 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3551676273448535		[learning rate: 0.00023488]
	Learning Rate: 0.000234878
	LOSS [training: 0.3551676273448535 | validation: 0.3655652673410319]
	TIME [epoch: 10.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34314666915750647		[learning rate: 0.00023403]
	Learning Rate: 0.000234026
	LOSS [training: 0.34314666915750647 | validation: 0.4059793892116156]
	TIME [epoch: 10.4 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33031868739820525		[learning rate: 0.00023318]
	Learning Rate: 0.000233176
	LOSS [training: 0.33031868739820525 | validation: 0.4041242494131613]
	TIME [epoch: 10.4 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35311956272397566		[learning rate: 0.00023233]
	Learning Rate: 0.00023233
	LOSS [training: 0.35311956272397566 | validation: 0.3695142776805668]
	TIME [epoch: 10.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3438263281431062		[learning rate: 0.00023149]
	Learning Rate: 0.000231487
	LOSS [training: 0.3438263281431062 | validation: 0.358089438768228]
	TIME [epoch: 10.4 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3878636241231673		[learning rate: 0.00023065]
	Learning Rate: 0.000230647
	LOSS [training: 0.3878636241231673 | validation: 0.31477619069601637]
	TIME [epoch: 10.4 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33769857701573736		[learning rate: 0.00022981]
	Learning Rate: 0.00022981
	LOSS [training: 0.33769857701573736 | validation: 0.36864733557220214]
	TIME [epoch: 10.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34778497531179725		[learning rate: 0.00022898]
	Learning Rate: 0.000228976
	LOSS [training: 0.34778497531179725 | validation: 0.3586471427366017]
	TIME [epoch: 10.4 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35980017302802497		[learning rate: 0.00022814]
	Learning Rate: 0.000228145
	LOSS [training: 0.35980017302802497 | validation: 0.3748443436885295]
	TIME [epoch: 10.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.353688285476214		[learning rate: 0.00022732]
	Learning Rate: 0.000227317
	LOSS [training: 0.353688285476214 | validation: 0.35824690659418723]
	TIME [epoch: 10.4 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399769909268558		[learning rate: 0.00022649]
	Learning Rate: 0.000226492
	LOSS [training: 0.3399769909268558 | validation: 0.359985294626641]
	TIME [epoch: 10.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720940910734399		[learning rate: 0.00022567]
	Learning Rate: 0.00022567
	LOSS [training: 0.3720940910734399 | validation: 0.2961144089649558]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1143.pth
	Model improved!!!
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33700018669598264		[learning rate: 0.00022485]
	Learning Rate: 0.000224851
	LOSS [training: 0.33700018669598264 | validation: 0.3697944264628383]
	TIME [epoch: 10.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3359218648934862		[learning rate: 0.00022403]
	Learning Rate: 0.000224035
	LOSS [training: 0.3359218648934862 | validation: 0.35760222365676414]
	TIME [epoch: 10.4 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3450830581144951		[learning rate: 0.00022322]
	Learning Rate: 0.000223222
	LOSS [training: 0.3450830581144951 | validation: 0.3916525009405219]
	TIME [epoch: 10.4 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35517189644496705		[learning rate: 0.00022241]
	Learning Rate: 0.000222412
	LOSS [training: 0.35517189644496705 | validation: 0.42757139231072644]
	TIME [epoch: 10.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432537740586513		[learning rate: 0.0002216]
	Learning Rate: 0.000221605
	LOSS [training: 0.3432537740586513 | validation: 0.37538141901574384]
	TIME [epoch: 10.4 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3291821294900791		[learning rate: 0.0002208]
	Learning Rate: 0.0002208
	LOSS [training: 0.3291821294900791 | validation: 0.42999230616738976]
	TIME [epoch: 10.4 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36584353387827456		[learning rate: 0.00022]
	Learning Rate: 0.000219999
	LOSS [training: 0.36584353387827456 | validation: 0.37144221754098133]
	TIME [epoch: 10.4 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412921694866064		[learning rate: 0.0002192]
	Learning Rate: 0.000219201
	LOSS [training: 0.3412921694866064 | validation: 0.3903416847782759]
	TIME [epoch: 10.4 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3499296431769249		[learning rate: 0.00021841]
	Learning Rate: 0.000218405
	LOSS [training: 0.3499296431769249 | validation: 0.37584542810112626]
	TIME [epoch: 10.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3401034196910813		[learning rate: 0.00021761]
	Learning Rate: 0.000217613
	LOSS [training: 0.3401034196910813 | validation: 0.405590467357969]
	TIME [epoch: 10.4 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3575382816305007		[learning rate: 0.00021682]
	Learning Rate: 0.000216823
	LOSS [training: 0.3575382816305007 | validation: 0.3711099759826537]
	TIME [epoch: 10.4 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3497243089652997		[learning rate: 0.00021604]
	Learning Rate: 0.000216036
	LOSS [training: 0.3497243089652997 | validation: 0.39107359476584036]
	TIME [epoch: 10.4 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35284820117151294		[learning rate: 0.00021525]
	Learning Rate: 0.000215252
	LOSS [training: 0.35284820117151294 | validation: 0.39858202959228833]
	TIME [epoch: 10.4 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3484524871426179		[learning rate: 0.00021447]
	Learning Rate: 0.000214471
	LOSS [training: 0.3484524871426179 | validation: 0.37118799693159427]
	TIME [epoch: 10.4 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35365018385005254		[learning rate: 0.00021369]
	Learning Rate: 0.000213693
	LOSS [training: 0.35365018385005254 | validation: 0.36992243162828486]
	TIME [epoch: 10.4 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3431566577378886		[learning rate: 0.00021292]
	Learning Rate: 0.000212917
	LOSS [training: 0.3431566577378886 | validation: 0.43712873451203343]
	TIME [epoch: 10.4 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3636406779114228		[learning rate: 0.00021214]
	Learning Rate: 0.000212144
	LOSS [training: 0.3636406779114228 | validation: 0.3844589532654373]
	TIME [epoch: 10.4 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3325210441853726		[learning rate: 0.00021137]
	Learning Rate: 0.000211375
	LOSS [training: 0.3325210441853726 | validation: 0.36320900116943317]
	TIME [epoch: 10.4 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3523339877842736		[learning rate: 0.00021061]
	Learning Rate: 0.000210607
	LOSS [training: 0.3523339877842736 | validation: 0.36832448447442445]
	TIME [epoch: 10.4 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33495953544138635		[learning rate: 0.00020984]
	Learning Rate: 0.000209843
	LOSS [training: 0.33495953544138635 | validation: 0.3831854094057414]
	TIME [epoch: 10.4 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3328598236822928		[learning rate: 0.00020908]
	Learning Rate: 0.000209082
	LOSS [training: 0.3328598236822928 | validation: 0.3819258399049872]
	TIME [epoch: 10.4 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3592050300677915		[learning rate: 0.00020832]
	Learning Rate: 0.000208323
	LOSS [training: 0.3592050300677915 | validation: 0.3923865416930677]
	TIME [epoch: 10.4 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33586584929165897		[learning rate: 0.00020757]
	Learning Rate: 0.000207567
	LOSS [training: 0.33586584929165897 | validation: 0.36894823396692167]
	TIME [epoch: 10.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32128064368457177		[learning rate: 0.00020681]
	Learning Rate: 0.000206814
	LOSS [training: 0.32128064368457177 | validation: 0.3612249406591]
	TIME [epoch: 10.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233080691401954		[learning rate: 0.00020606]
	Learning Rate: 0.000206063
	LOSS [training: 0.3233080691401954 | validation: 0.3668441734899245]
	TIME [epoch: 10.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33882427279205496		[learning rate: 0.00020532]
	Learning Rate: 0.000205315
	LOSS [training: 0.33882427279205496 | validation: 0.392808443934199]
	TIME [epoch: 10.4 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33587820083191233		[learning rate: 0.00020457]
	Learning Rate: 0.00020457
	LOSS [training: 0.33587820083191233 | validation: 0.37018485775828497]
	TIME [epoch: 10.4 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34214455835057367		[learning rate: 0.00020383]
	Learning Rate: 0.000203828
	LOSS [training: 0.34214455835057367 | validation: 0.35986985978579045]
	TIME [epoch: 10.4 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3351489921580667		[learning rate: 0.00020309]
	Learning Rate: 0.000203088
	LOSS [training: 0.3351489921580667 | validation: 0.36446733317024577]
	TIME [epoch: 10.4 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3662581451638094		[learning rate: 0.00020235]
	Learning Rate: 0.000202351
	LOSS [training: 0.3662581451638094 | validation: 0.37984058832531425]
	TIME [epoch: 10.4 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3740459920580099		[learning rate: 0.00020162]
	Learning Rate: 0.000201617
	LOSS [training: 0.3740459920580099 | validation: 0.396962181436691]
	TIME [epoch: 10.4 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33448555087052295		[learning rate: 0.00020088]
	Learning Rate: 0.000200885
	LOSS [training: 0.33448555087052295 | validation: 0.40198484864831135]
	TIME [epoch: 10.4 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39755436480769124		[learning rate: 0.00020016]
	Learning Rate: 0.000200156
	LOSS [training: 0.39755436480769124 | validation: 0.42604669472318457]
	TIME [epoch: 10.4 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35967910466617065		[learning rate: 0.00019943]
	Learning Rate: 0.00019943
	LOSS [training: 0.35967910466617065 | validation: 0.36750221064064664]
	TIME [epoch: 10.4 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33594582734896117		[learning rate: 0.00019871]
	Learning Rate: 0.000198706
	LOSS [training: 0.33594582734896117 | validation: 0.3875942110661619]
	TIME [epoch: 10.4 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34595791651130775		[learning rate: 0.00019798]
	Learning Rate: 0.000197985
	LOSS [training: 0.34595791651130775 | validation: 0.36169265981705556]
	TIME [epoch: 10.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3428006535310265		[learning rate: 0.00019727]
	Learning Rate: 0.000197266
	LOSS [training: 0.3428006535310265 | validation: 0.36928315589368843]
	TIME [epoch: 10.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3681088443006885		[learning rate: 0.00019655]
	Learning Rate: 0.00019655
	LOSS [training: 0.3681088443006885 | validation: 0.43953265371972683]
	TIME [epoch: 10.4 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.343276745132104		[learning rate: 0.00019584]
	Learning Rate: 0.000195837
	LOSS [training: 0.343276745132104 | validation: 0.43611121842310546]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3413552932818603		[learning rate: 0.00019513]
	Learning Rate: 0.000195126
	LOSS [training: 0.3413552932818603 | validation: 0.36180344285176014]
	TIME [epoch: 10.4 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32338080039792266		[learning rate: 0.00019442]
	Learning Rate: 0.000194418
	LOSS [training: 0.32338080039792266 | validation: 0.40543227369839785]
	TIME [epoch: 10.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34559454256551814		[learning rate: 0.00019371]
	Learning Rate: 0.000193713
	LOSS [training: 0.34559454256551814 | validation: 0.36765483447908]
	TIME [epoch: 10.4 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34811826370923926		[learning rate: 0.00019301]
	Learning Rate: 0.00019301
	LOSS [training: 0.34811826370923926 | validation: 0.39532495546669133]
	TIME [epoch: 10.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3440521530217465		[learning rate: 0.00019231]
	Learning Rate: 0.000192309
	LOSS [training: 0.3440521530217465 | validation: 0.3688817601761306]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34753451006653785		[learning rate: 0.00019161]
	Learning Rate: 0.000191611
	LOSS [training: 0.34753451006653785 | validation: 0.3799877763424425]
	TIME [epoch: 10.4 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3289306341428974		[learning rate: 0.00019092]
	Learning Rate: 0.000190916
	LOSS [training: 0.3289306341428974 | validation: 0.38554345687746205]
	TIME [epoch: 10.4 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.330183860910067		[learning rate: 0.00019022]
	Learning Rate: 0.000190223
	LOSS [training: 0.330183860910067 | validation: 0.4078598513161193]
	TIME [epoch: 10.4 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3467444873425011		[learning rate: 0.00018953]
	Learning Rate: 0.000189533
	LOSS [training: 0.3467444873425011 | validation: 0.40263849256014284]
	TIME [epoch: 10.4 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32605033847439935		[learning rate: 0.00018884]
	Learning Rate: 0.000188845
	LOSS [training: 0.32605033847439935 | validation: 0.3781264150445563]
	TIME [epoch: 10.4 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34390259871715856		[learning rate: 0.00018816]
	Learning Rate: 0.00018816
	LOSS [training: 0.34390259871715856 | validation: 0.3725625151003974]
	TIME [epoch: 10.4 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33299408245758205		[learning rate: 0.00018748]
	Learning Rate: 0.000187477
	LOSS [training: 0.33299408245758205 | validation: 0.3443386765218997]
	TIME [epoch: 10.4 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34283434577668154		[learning rate: 0.0001868]
	Learning Rate: 0.000186796
	LOSS [training: 0.34283434577668154 | validation: 0.35256121235991017]
	TIME [epoch: 10.4 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3228157574375474		[learning rate: 0.00018612]
	Learning Rate: 0.000186119
	LOSS [training: 0.3228157574375474 | validation: 0.3714283544813166]
	TIME [epoch: 10.4 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3118228223628835		[learning rate: 0.00018544]
	Learning Rate: 0.000185443
	LOSS [training: 0.3118228223628835 | validation: 0.36114539284698566]
	TIME [epoch: 10.4 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274631662877402		[learning rate: 0.00018477]
	Learning Rate: 0.00018477
	LOSS [training: 0.3274631662877402 | validation: 0.394028678062349]
	TIME [epoch: 10.4 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420718328562602		[learning rate: 0.0001841]
	Learning Rate: 0.000184099
	LOSS [training: 0.3420718328562602 | validation: 0.34698508148609153]
	TIME [epoch: 10.4 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32613529757738535		[learning rate: 0.00018343]
	Learning Rate: 0.000183431
	LOSS [training: 0.32613529757738535 | validation: 0.35884268188428453]
	TIME [epoch: 10.4 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34678900834834436		[learning rate: 0.00018277]
	Learning Rate: 0.000182766
	LOSS [training: 0.34678900834834436 | validation: 0.4048960729094195]
	TIME [epoch: 10.4 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3752002063022681		[learning rate: 0.0001821]
	Learning Rate: 0.000182102
	LOSS [training: 0.3752002063022681 | validation: 0.42646560053528676]
	TIME [epoch: 10.4 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35765252574405826		[learning rate: 0.00018144]
	Learning Rate: 0.000181442
	LOSS [training: 0.35765252574405826 | validation: 0.4045694892965346]
	TIME [epoch: 10.4 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36884843819585245		[learning rate: 0.00018078]
	Learning Rate: 0.000180783
	LOSS [training: 0.36884843819585245 | validation: 0.3681240696826818]
	TIME [epoch: 10.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34062885996609354		[learning rate: 0.00018013]
	Learning Rate: 0.000180127
	LOSS [training: 0.34062885996609354 | validation: 0.3923591085930086]
	TIME [epoch: 10.4 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35574193236694024		[learning rate: 0.00017947]
	Learning Rate: 0.000179473
	LOSS [training: 0.35574193236694024 | validation: 0.3606882226779045]
	TIME [epoch: 10.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32924797135401573		[learning rate: 0.00017882]
	Learning Rate: 0.000178822
	LOSS [training: 0.32924797135401573 | validation: 0.38194794718976155]
	TIME [epoch: 10.4 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34040933570866605		[learning rate: 0.00017817]
	Learning Rate: 0.000178173
	LOSS [training: 0.34040933570866605 | validation: 0.39397964651095285]
	TIME [epoch: 10.4 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3539922461578599		[learning rate: 0.00017753]
	Learning Rate: 0.000177526
	LOSS [training: 0.3539922461578599 | validation: 0.35584873091608316]
	TIME [epoch: 10.4 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3506085541927079		[learning rate: 0.00017688]
	Learning Rate: 0.000176882
	LOSS [training: 0.3506085541927079 | validation: 0.43999025714059004]
	TIME [epoch: 10.4 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34806256817661835		[learning rate: 0.00017624]
	Learning Rate: 0.00017624
	LOSS [training: 0.34806256817661835 | validation: 0.34828275571590267]
	TIME [epoch: 10.4 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240952002376869		[learning rate: 0.0001756]
	Learning Rate: 0.000175601
	LOSS [training: 0.3240952002376869 | validation: 0.4136192606323115]
	TIME [epoch: 10.4 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35316858083467123		[learning rate: 0.00017496]
	Learning Rate: 0.000174964
	LOSS [training: 0.35316858083467123 | validation: 0.3949415587279014]
	TIME [epoch: 10.4 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34854619658941116		[learning rate: 0.00017433]
	Learning Rate: 0.000174329
	LOSS [training: 0.34854619658941116 | validation: 0.39560500069766974]
	TIME [epoch: 10.4 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35686003043911435		[learning rate: 0.0001737]
	Learning Rate: 0.000173696
	LOSS [training: 0.35686003043911435 | validation: 0.38470927308695396]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.336665753935726		[learning rate: 0.00017307]
	Learning Rate: 0.000173066
	LOSS [training: 0.336665753935726 | validation: 0.408946979452832]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3544845279847316		[learning rate: 0.00017244]
	Learning Rate: 0.000172437
	LOSS [training: 0.3544845279847316 | validation: 0.37721623409117416]
	TIME [epoch: 10.4 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3352463153984731		[learning rate: 0.00017181]
	Learning Rate: 0.000171812
	LOSS [training: 0.3352463153984731 | validation: 0.3421211602001219]
	TIME [epoch: 10.4 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32566535762889814		[learning rate: 0.00017119]
	Learning Rate: 0.000171188
	LOSS [training: 0.32566535762889814 | validation: 0.3817397626913628]
	TIME [epoch: 10.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3371760505650358		[learning rate: 0.00017057]
	Learning Rate: 0.000170567
	LOSS [training: 0.3371760505650358 | validation: 0.3948134266417271]
	TIME [epoch: 10.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3320337528378937		[learning rate: 0.00016995]
	Learning Rate: 0.000169948
	LOSS [training: 0.3320337528378937 | validation: 0.36381953047452614]
	TIME [epoch: 10.4 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34789916253867126		[learning rate: 0.00016933]
	Learning Rate: 0.000169331
	LOSS [training: 0.34789916253867126 | validation: 0.39431042667268323]
	TIME [epoch: 10.4 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3346958679424346		[learning rate: 0.00016872]
	Learning Rate: 0.000168717
	LOSS [training: 0.3346958679424346 | validation: 0.3354564665466295]
	TIME [epoch: 10.4 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33993560666144623		[learning rate: 0.0001681]
	Learning Rate: 0.000168104
	LOSS [training: 0.33993560666144623 | validation: 0.3554666925456374]
	TIME [epoch: 10.4 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33352896995302095		[learning rate: 0.00016749]
	Learning Rate: 0.000167494
	LOSS [training: 0.33352896995302095 | validation: 0.345143604358757]
	TIME [epoch: 10.4 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.318496381066662		[learning rate: 0.00016689]
	Learning Rate: 0.000166886
	LOSS [training: 0.318496381066662 | validation: 0.3608957110691847]
	TIME [epoch: 10.4 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34886720830601325		[learning rate: 0.00016628]
	Learning Rate: 0.000166281
	LOSS [training: 0.34886720830601325 | validation: 0.37937524186491883]
	TIME [epoch: 10.4 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32191710218695013		[learning rate: 0.00016568]
	Learning Rate: 0.000165677
	LOSS [training: 0.32191710218695013 | validation: 0.3489869844306163]
	TIME [epoch: 10.4 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.331860963947834		[learning rate: 0.00016508]
	Learning Rate: 0.000165076
	LOSS [training: 0.331860963947834 | validation: 0.3573878576078098]
	TIME [epoch: 10.4 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33582308023706353		[learning rate: 0.00016448]
	Learning Rate: 0.000164477
	LOSS [training: 0.33582308023706353 | validation: 0.3650667818306937]
	TIME [epoch: 10.4 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3631347563077775		[learning rate: 0.00016388]
	Learning Rate: 0.00016388
	LOSS [training: 0.3631347563077775 | validation: 0.3677792120519369]
	TIME [epoch: 10.4 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33187566785094125		[learning rate: 0.00016329]
	Learning Rate: 0.000163285
	LOSS [training: 0.33187566785094125 | validation: 0.38029562685131907]
	TIME [epoch: 10.4 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3326491014999989		[learning rate: 0.00016269]
	Learning Rate: 0.000162693
	LOSS [training: 0.3326491014999989 | validation: 0.36478891197586477]
	TIME [epoch: 10.4 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274653618304816		[learning rate: 0.0001621]
	Learning Rate: 0.000162102
	LOSS [training: 0.3274653618304816 | validation: 0.3545900399195343]
	TIME [epoch: 10.4 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34010028444357415		[learning rate: 0.00016151]
	Learning Rate: 0.000161514
	LOSS [training: 0.34010028444357415 | validation: 0.3923886050489031]
	TIME [epoch: 10.4 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432591109740905		[learning rate: 0.00016093]
	Learning Rate: 0.000160928
	LOSS [training: 0.3432591109740905 | validation: 0.4039317414148744]
	TIME [epoch: 10.4 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3585384327317334		[learning rate: 0.00016034]
	Learning Rate: 0.000160344
	LOSS [training: 0.3585384327317334 | validation: 0.39411280998542525]
	TIME [epoch: 10.4 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341452902008481		[learning rate: 0.00015976]
	Learning Rate: 0.000159762
	LOSS [training: 0.3341452902008481 | validation: 0.38205842300303156]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3266899749245408		[learning rate: 0.00015918]
	Learning Rate: 0.000159182
	LOSS [training: 0.3266899749245408 | validation: 0.3493152965267811]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360091832239579		[learning rate: 0.0001586]
	Learning Rate: 0.000158605
	LOSS [training: 0.3360091832239579 | validation: 0.3456509235437491]
	TIME [epoch: 10.4 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34366854652614925		[learning rate: 0.00015803]
	Learning Rate: 0.000158029
	LOSS [training: 0.34366854652614925 | validation: 0.3811550245630393]
	TIME [epoch: 10.4 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3589518339271599		[learning rate: 0.00015746]
	Learning Rate: 0.000157456
	LOSS [training: 0.3589518339271599 | validation: 0.373386989955102]
	TIME [epoch: 10.4 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432795445762607		[learning rate: 0.00015688]
	Learning Rate: 0.000156884
	LOSS [training: 0.3432795445762607 | validation: 0.3556158358085782]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34508954143961207		[learning rate: 0.00015631]
	Learning Rate: 0.000156315
	LOSS [training: 0.34508954143961207 | validation: 0.38091329674683677]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35408233811004086		[learning rate: 0.00015575]
	Learning Rate: 0.000155748
	LOSS [training: 0.35408233811004086 | validation: 0.39321161844663494]
	TIME [epoch: 10.4 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3281294434592939		[learning rate: 0.00015518]
	Learning Rate: 0.000155182
	LOSS [training: 0.3281294434592939 | validation: 0.3841287180024056]
	TIME [epoch: 10.4 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36226838161839314		[learning rate: 0.00015462]
	Learning Rate: 0.000154619
	LOSS [training: 0.36226838161839314 | validation: 0.38490453803878566]
	TIME [epoch: 10.4 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3509552139135728		[learning rate: 0.00015406]
	Learning Rate: 0.000154058
	LOSS [training: 0.3509552139135728 | validation: 0.3797247119120597]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3582850444378922		[learning rate: 0.0001535]
	Learning Rate: 0.000153499
	LOSS [training: 0.3582850444378922 | validation: 0.3732053363620756]
	TIME [epoch: 10.4 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32702430616564826		[learning rate: 0.00015294]
	Learning Rate: 0.000152942
	LOSS [training: 0.32702430616564826 | validation: 0.34655473294864825]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3119787807591421		[learning rate: 0.00015239]
	Learning Rate: 0.000152387
	LOSS [training: 0.3119787807591421 | validation: 0.3558957058073463]
	TIME [epoch: 10.4 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31787566348412105		[learning rate: 0.00015183]
	Learning Rate: 0.000151834
	LOSS [training: 0.31787566348412105 | validation: 0.34576067259775856]
	TIME [epoch: 10.4 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32852064613250903		[learning rate: 0.00015128]
	Learning Rate: 0.000151283
	LOSS [training: 0.32852064613250903 | validation: 0.27388568774108907]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1253.pth
	Model improved!!!
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33183974903235874		[learning rate: 0.00015073]
	Learning Rate: 0.000150734
	LOSS [training: 0.33183974903235874 | validation: 0.3556774803453054]
	TIME [epoch: 10.4 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285054795196499		[learning rate: 0.00015019]
	Learning Rate: 0.000150187
	LOSS [training: 0.3285054795196499 | validation: 0.38787768172451814]
	TIME [epoch: 10.4 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34265432745538815		[learning rate: 0.00014964]
	Learning Rate: 0.000149642
	LOSS [training: 0.34265432745538815 | validation: 0.2955897463967933]
	TIME [epoch: 10.4 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32569834893013083		[learning rate: 0.0001491]
	Learning Rate: 0.000149099
	LOSS [training: 0.32569834893013083 | validation: 0.2645009587233877]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1257.pth
	Model improved!!!
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3333645263464503		[learning rate: 0.00014856]
	Learning Rate: 0.000148558
	LOSS [training: 0.3333645263464503 | validation: 0.3762242253039028]
	TIME [epoch: 10.4 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.343946972457537		[learning rate: 0.00014802]
	Learning Rate: 0.000148018
	LOSS [training: 0.343946972457537 | validation: 0.39557154482534546]
	TIME [epoch: 10.4 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30926573824198134		[learning rate: 0.00014748]
	Learning Rate: 0.000147481
	LOSS [training: 0.30926573824198134 | validation: 0.3380518765596767]
	TIME [epoch: 10.4 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33481515460480377		[learning rate: 0.00014695]
	Learning Rate: 0.000146946
	LOSS [training: 0.33481515460480377 | validation: 0.33817972975386007]
	TIME [epoch: 10.4 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32795700688355545		[learning rate: 0.00014641]
	Learning Rate: 0.000146413
	LOSS [training: 0.32795700688355545 | validation: 0.3674992681999835]
	TIME [epoch: 10.4 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299305984125828		[learning rate: 0.00014588]
	Learning Rate: 0.000145881
	LOSS [training: 0.3299305984125828 | validation: 0.3807547574933001]
	TIME [epoch: 10.4 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33208349712986723		[learning rate: 0.00014535]
	Learning Rate: 0.000145352
	LOSS [training: 0.33208349712986723 | validation: 0.3787312267793398]
	TIME [epoch: 10.4 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33455132017099726		[learning rate: 0.00014482]
	Learning Rate: 0.000144825
	LOSS [training: 0.33455132017099726 | validation: 0.3460116694711984]
	TIME [epoch: 10.4 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432189772775439		[learning rate: 0.0001443]
	Learning Rate: 0.000144299
	LOSS [training: 0.3432189772775439 | validation: 0.3517520546649005]
	TIME [epoch: 10.4 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327277231349278		[learning rate: 0.00014378]
	Learning Rate: 0.000143775
	LOSS [training: 0.327277231349278 | validation: 0.37257842493677296]
	TIME [epoch: 10.4 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3342303835572585		[learning rate: 0.00014325]
	Learning Rate: 0.000143253
	LOSS [training: 0.3342303835572585 | validation: 0.36899591812596283]
	TIME [epoch: 10.4 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3342296879117422		[learning rate: 0.00014273]
	Learning Rate: 0.000142734
	LOSS [training: 0.3342296879117422 | validation: 0.38114269013187213]
	TIME [epoch: 10.4 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3169657910797056		[learning rate: 0.00014222]
	Learning Rate: 0.000142216
	LOSS [training: 0.3169657910797056 | validation: 0.3538951090950085]
	TIME [epoch: 10.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3227595987771309		[learning rate: 0.0001417]
	Learning Rate: 0.0001417
	LOSS [training: 0.3227595987771309 | validation: 0.36104953771710596]
	TIME [epoch: 10.4 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31795004848329766		[learning rate: 0.00014119]
	Learning Rate: 0.000141185
	LOSS [training: 0.31795004848329766 | validation: 0.3451619338915524]
	TIME [epoch: 10.4 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33431653288656615		[learning rate: 0.00014067]
	Learning Rate: 0.000140673
	LOSS [training: 0.33431653288656615 | validation: 0.37589551436628804]
	TIME [epoch: 10.4 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341387845105139		[learning rate: 0.00014016]
	Learning Rate: 0.000140162
	LOSS [training: 0.3341387845105139 | validation: 0.351690756991471]
	TIME [epoch: 10.4 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32807718977744144		[learning rate: 0.00013965]
	Learning Rate: 0.000139654
	LOSS [training: 0.32807718977744144 | validation: 0.3661325955828535]
	TIME [epoch: 10.4 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33285505155120704		[learning rate: 0.00013915]
	Learning Rate: 0.000139147
	LOSS [training: 0.33285505155120704 | validation: 0.35386613504300735]
	TIME [epoch: 10.4 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3474772733581567		[learning rate: 0.00013864]
	Learning Rate: 0.000138642
	LOSS [training: 0.3474772733581567 | validation: 0.3815865666707329]
	TIME [epoch: 10.4 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3267136596121524		[learning rate: 0.00013814]
	Learning Rate: 0.000138139
	LOSS [training: 0.3267136596121524 | validation: 0.4267160546503381]
	TIME [epoch: 10.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39040217368415103		[learning rate: 0.00013764]
	Learning Rate: 0.000137638
	LOSS [training: 0.39040217368415103 | validation: 0.41112944360316456]
	TIME [epoch: 10.4 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3490132401115389		[learning rate: 0.00013714]
	Learning Rate: 0.000137138
	LOSS [training: 0.3490132401115389 | validation: 0.39123727630554217]
	TIME [epoch: 10.4 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33025971157426376		[learning rate: 0.00013664]
	Learning Rate: 0.00013664
	LOSS [training: 0.33025971157426376 | validation: 0.32892117432813367]
	TIME [epoch: 10.4 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285212646339161		[learning rate: 0.00013614]
	Learning Rate: 0.000136144
	LOSS [training: 0.3285212646339161 | validation: 0.38800478613026057]
	TIME [epoch: 10.4 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312564990404913		[learning rate: 0.00013565]
	Learning Rate: 0.00013565
	LOSS [training: 0.3312564990404913 | validation: 0.3741746392782154]
	TIME [epoch: 10.4 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3245910750811118		[learning rate: 0.00013516]
	Learning Rate: 0.000135158
	LOSS [training: 0.3245910750811118 | validation: 0.3852986359116196]
	TIME [epoch: 10.4 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32311487247866816		[learning rate: 0.00013467]
	Learning Rate: 0.000134668
	LOSS [training: 0.32311487247866816 | validation: 0.35725873668525504]
	TIME [epoch: 10.4 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3174328853390419		[learning rate: 0.00013418]
	Learning Rate: 0.000134179
	LOSS [training: 0.3174328853390419 | validation: 0.3477206650146888]
	TIME [epoch: 10.4 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32459633340931615		[learning rate: 0.00013369]
	Learning Rate: 0.000133692
	LOSS [training: 0.32459633340931615 | validation: 0.3786363966567508]
	TIME [epoch: 10.4 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261894280374216		[learning rate: 0.00013321]
	Learning Rate: 0.000133207
	LOSS [training: 0.3261894280374216 | validation: 0.37306604152265466]
	TIME [epoch: 10.4 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3384035604649287		[learning rate: 0.00013272]
	Learning Rate: 0.000132723
	LOSS [training: 0.3384035604649287 | validation: 0.35600893125385014]
	TIME [epoch: 10.4 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33670234430951906		[learning rate: 0.00013224]
	Learning Rate: 0.000132242
	LOSS [training: 0.33670234430951906 | validation: 0.38579065175275373]
	TIME [epoch: 10.4 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3389047699943407		[learning rate: 0.00013176]
	Learning Rate: 0.000131762
	LOSS [training: 0.3389047699943407 | validation: 0.3963477150297996]
	TIME [epoch: 10.4 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34798522199410836		[learning rate: 0.00013128]
	Learning Rate: 0.000131284
	LOSS [training: 0.34798522199410836 | validation: 0.37119217118276737]
	TIME [epoch: 10.4 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33445718912087125		[learning rate: 0.00013081]
	Learning Rate: 0.000130807
	LOSS [training: 0.33445718912087125 | validation: 0.35693796132949623]
	TIME [epoch: 10.4 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3205639105836112		[learning rate: 0.00013033]
	Learning Rate: 0.000130332
	LOSS [training: 0.3205639105836112 | validation: 0.3539921036385815]
	TIME [epoch: 10.4 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31302672693762007		[learning rate: 0.00012986]
	Learning Rate: 0.000129859
	LOSS [training: 0.31302672693762007 | validation: 0.3542370569336234]
	TIME [epoch: 10.4 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32851369833776795		[learning rate: 0.00012939]
	Learning Rate: 0.000129388
	LOSS [training: 0.32851369833776795 | validation: 0.3734306184837267]
	TIME [epoch: 10.4 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32754211946950607		[learning rate: 0.00012892]
	Learning Rate: 0.000128919
	LOSS [training: 0.32754211946950607 | validation: 0.33121918178508064]
	TIME [epoch: 10.4 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3445877138858246		[learning rate: 0.00012845]
	Learning Rate: 0.000128451
	LOSS [training: 0.3445877138858246 | validation: 0.3463582286870274]
	TIME [epoch: 10.4 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088846898202835		[learning rate: 0.00012798]
	Learning Rate: 0.000127985
	LOSS [training: 0.3088846898202835 | validation: 0.3433833880025802]
	TIME [epoch: 10.4 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31236174342904044		[learning rate: 0.00012752]
	Learning Rate: 0.00012752
	LOSS [training: 0.31236174342904044 | validation: 0.3798269768919249]
	TIME [epoch: 10.4 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3236053342646399		[learning rate: 0.00012706]
	Learning Rate: 0.000127057
	LOSS [training: 0.3236053342646399 | validation: 0.3662276411973026]
	TIME [epoch: 10.4 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3314304156182232		[learning rate: 0.0001266]
	Learning Rate: 0.000126596
	LOSS [training: 0.3314304156182232 | validation: 0.3904073954139783]
	TIME [epoch: 10.4 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35694822017864186		[learning rate: 0.00012614]
	Learning Rate: 0.000126137
	LOSS [training: 0.35694822017864186 | validation: 0.38627666904879726]
	TIME [epoch: 10.4 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3362735152024864		[learning rate: 0.00012568]
	Learning Rate: 0.000125679
	LOSS [training: 0.3362735152024864 | validation: 0.4076836453746475]
	TIME [epoch: 10.4 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3286471817915488		[learning rate: 0.00012522]
	Learning Rate: 0.000125223
	LOSS [training: 0.3286471817915488 | validation: 0.2863052626715365]
	TIME [epoch: 10.4 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33285616065009804		[learning rate: 0.00012477]
	Learning Rate: 0.000124769
	LOSS [training: 0.33285616065009804 | validation: 0.3870735967999638]
	TIME [epoch: 10.4 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32437503799757883		[learning rate: 0.00012432]
	Learning Rate: 0.000124316
	LOSS [training: 0.32437503799757883 | validation: 0.344085982834266]
	TIME [epoch: 10.4 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157109788583786		[learning rate: 0.00012386]
	Learning Rate: 0.000123865
	LOSS [training: 0.3157109788583786 | validation: 0.34638702538812705]
	TIME [epoch: 10.4 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32751576358082835		[learning rate: 0.00012342]
	Learning Rate: 0.000123415
	LOSS [training: 0.32751576358082835 | validation: 0.35144149408235215]
	TIME [epoch: 10.4 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31879742032875796		[learning rate: 0.00012297]
	Learning Rate: 0.000122967
	LOSS [training: 0.31879742032875796 | validation: 0.33481935204324254]
	TIME [epoch: 10.4 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31876587326284167		[learning rate: 0.00012252]
	Learning Rate: 0.000122521
	LOSS [training: 0.31876587326284167 | validation: 0.3601845433978447]
	TIME [epoch: 10.4 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3355539617876081		[learning rate: 0.00012208]
	Learning Rate: 0.000122076
	LOSS [training: 0.3355539617876081 | validation: 0.33054889696120016]
	TIME [epoch: 10.4 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3379945344726147		[learning rate: 0.00012163]
	Learning Rate: 0.000121633
	LOSS [training: 0.3379945344726147 | validation: 0.34339640064784815]
	TIME [epoch: 10.4 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3285269162724871		[learning rate: 0.00012119]
	Learning Rate: 0.000121192
	LOSS [training: 0.3285269162724871 | validation: 0.38208460986972614]
	TIME [epoch: 10.4 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30736630177279883		[learning rate: 0.00012075]
	Learning Rate: 0.000120752
	LOSS [training: 0.30736630177279883 | validation: 0.3982777676353254]
	TIME [epoch: 10.4 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3275319558034404		[learning rate: 0.00012031]
	Learning Rate: 0.000120314
	LOSS [training: 0.3275319558034404 | validation: 0.3556188485215755]
	TIME [epoch: 10.4 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152606398907628		[learning rate: 0.00011988]
	Learning Rate: 0.000119877
	LOSS [training: 0.3152606398907628 | validation: 0.3344720380780285]
	TIME [epoch: 10.4 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3245258227935382		[learning rate: 0.00011944]
	Learning Rate: 0.000119442
	LOSS [training: 0.3245258227935382 | validation: 0.3394910039604146]
	TIME [epoch: 10.4 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31630127893077536		[learning rate: 0.00011901]
	Learning Rate: 0.000119009
	LOSS [training: 0.31630127893077536 | validation: 0.3950518188342892]
	TIME [epoch: 10.4 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3265277078224867		[learning rate: 0.00011858]
	Learning Rate: 0.000118577
	LOSS [training: 0.3265277078224867 | validation: 0.3333782883938196]
	TIME [epoch: 10.4 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3277229595669561		[learning rate: 0.00011815]
	Learning Rate: 0.000118147
	LOSS [training: 0.3277229595669561 | validation: 0.38594492031449323]
	TIME [epoch: 10.4 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32483083125488593		[learning rate: 0.00011772]
	Learning Rate: 0.000117718
	LOSS [training: 0.32483083125488593 | validation: 0.36121907503368733]
	TIME [epoch: 10.4 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32966881095421585		[learning rate: 0.00011729]
	Learning Rate: 0.000117291
	LOSS [training: 0.32966881095421585 | validation: 0.3705470975977291]
	TIME [epoch: 10.4 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33565722085538907		[learning rate: 0.00011686]
	Learning Rate: 0.000116865
	LOSS [training: 0.33565722085538907 | validation: 0.3553882623019309]
	TIME [epoch: 10.4 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34167728970615097		[learning rate: 0.00011644]
	Learning Rate: 0.000116441
	LOSS [training: 0.34167728970615097 | validation: 0.3427943801337405]
	TIME [epoch: 10.4 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33270033382782443		[learning rate: 0.00011602]
	Learning Rate: 0.000116018
	LOSS [training: 0.33270033382782443 | validation: 0.3817639365564288]
	TIME [epoch: 10.4 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3441121729280626		[learning rate: 0.0001156]
	Learning Rate: 0.000115597
	LOSS [training: 0.3441121729280626 | validation: 0.35472828199929557]
	TIME [epoch: 10.4 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3089976433056301		[learning rate: 0.00011518]
	Learning Rate: 0.000115178
	LOSS [training: 0.3089976433056301 | validation: 0.35321468359559643]
	TIME [epoch: 10.4 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31213321536185706		[learning rate: 0.00011476]
	Learning Rate: 0.00011476
	LOSS [training: 0.31213321536185706 | validation: 0.3547043852238908]
	TIME [epoch: 10.4 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3333281633664446		[learning rate: 0.00011434]
	Learning Rate: 0.000114343
	LOSS [training: 0.3333281633664446 | validation: 0.3799346838692979]
	TIME [epoch: 10.4 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3203462879195638		[learning rate: 0.00011393]
	Learning Rate: 0.000113928
	LOSS [training: 0.3203462879195638 | validation: 0.3318857829281472]
	TIME [epoch: 10.4 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.328477313781804		[learning rate: 0.00011351]
	Learning Rate: 0.000113515
	LOSS [training: 0.328477313781804 | validation: 0.34071603381707716]
	TIME [epoch: 10.4 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3362602157863057		[learning rate: 0.0001131]
	Learning Rate: 0.000113103
	LOSS [training: 0.3362602157863057 | validation: 0.36899932625693926]
	TIME [epoch: 10.4 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33588109596099053		[learning rate: 0.00011269]
	Learning Rate: 0.000112692
	LOSS [training: 0.33588109596099053 | validation: 0.35615903885999595]
	TIME [epoch: 10.4 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31009351274072267		[learning rate: 0.00011228]
	Learning Rate: 0.000112283
	LOSS [training: 0.31009351274072267 | validation: 0.3669244072335286]
	TIME [epoch: 10.4 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31132985998157975		[learning rate: 0.00011188]
	Learning Rate: 0.000111876
	LOSS [training: 0.31132985998157975 | validation: 0.3596629606604006]
	TIME [epoch: 10.4 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3163788686293526		[learning rate: 0.00011147]
	Learning Rate: 0.00011147
	LOSS [training: 0.3163788686293526 | validation: 0.3584091017105952]
	TIME [epoch: 10.4 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32082098717723917		[learning rate: 0.00011107]
	Learning Rate: 0.000111065
	LOSS [training: 0.32082098717723917 | validation: 0.3303075170288653]
	TIME [epoch: 10.4 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32910017901534805		[learning rate: 0.00011066]
	Learning Rate: 0.000110662
	LOSS [training: 0.32910017901534805 | validation: 0.34465644380038074]
	TIME [epoch: 10.4 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3248861321673524		[learning rate: 0.00011026]
	Learning Rate: 0.000110261
	LOSS [training: 0.3248861321673524 | validation: 0.3406191613579324]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32069002412396846		[learning rate: 0.00010986]
	Learning Rate: 0.000109861
	LOSS [training: 0.32069002412396846 | validation: 0.3354271884370861]
	TIME [epoch: 10.4 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3212296297437723		[learning rate: 0.00010946]
	Learning Rate: 0.000109462
	LOSS [training: 0.3212296297437723 | validation: 0.3631235109141268]
	TIME [epoch: 10.4 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31534972020373997		[learning rate: 0.00010906]
	Learning Rate: 0.000109065
	LOSS [training: 0.31534972020373997 | validation: 0.33537289742400506]
	TIME [epoch: 10.4 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3397118913504774		[learning rate: 0.00010867]
	Learning Rate: 0.000108669
	LOSS [training: 0.3397118913504774 | validation: 0.3511781236924456]
	TIME [epoch: 10.4 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3363663864771316		[learning rate: 0.00010827]
	Learning Rate: 0.000108275
	LOSS [training: 0.3363663864771316 | validation: 0.34889362527310047]
	TIME [epoch: 10.4 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32147523100937503		[learning rate: 0.00010788]
	Learning Rate: 0.000107882
	LOSS [training: 0.32147523100937503 | validation: 0.3534887009449078]
	TIME [epoch: 10.4 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32430779888953853		[learning rate: 0.00010749]
	Learning Rate: 0.00010749
	LOSS [training: 0.32430779888953853 | validation: 0.3524050398589933]
	TIME [epoch: 10.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32037913139474355		[learning rate: 0.0001071]
	Learning Rate: 0.0001071
	LOSS [training: 0.32037913139474355 | validation: 0.3556333275381038]
	TIME [epoch: 10.4 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32812766084367156		[learning rate: 0.00010671]
	Learning Rate: 0.000106711
	LOSS [training: 0.32812766084367156 | validation: 0.3827049917389026]
	TIME [epoch: 10.4 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32483496696773556		[learning rate: 0.00010632]
	Learning Rate: 0.000106324
	LOSS [training: 0.32483496696773556 | validation: 0.3469985732973539]
	TIME [epoch: 10.4 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32946547320903574		[learning rate: 0.00010594]
	Learning Rate: 0.000105938
	LOSS [training: 0.32946547320903574 | validation: 0.41057110825091914]
	TIME [epoch: 10.4 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32439304309508976		[learning rate: 0.00010555]
	Learning Rate: 0.000105554
	LOSS [training: 0.32439304309508976 | validation: 0.3474532020351901]
	TIME [epoch: 10.4 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33614117607208555		[learning rate: 0.00010517]
	Learning Rate: 0.000105171
	LOSS [training: 0.33614117607208555 | validation: 0.3472789729354155]
	TIME [epoch: 10.4 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31634715531156654		[learning rate: 0.00010479]
	Learning Rate: 0.000104789
	LOSS [training: 0.31634715531156654 | validation: 0.3805963165057042]
	TIME [epoch: 10.4 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3101316770462791		[learning rate: 0.00010441]
	Learning Rate: 0.000104409
	LOSS [training: 0.3101316770462791 | validation: 0.3601813133701562]
	TIME [epoch: 10.4 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32297337131553905		[learning rate: 0.00010403]
	Learning Rate: 0.00010403
	LOSS [training: 0.32297337131553905 | validation: 0.37752133760390894]
	TIME [epoch: 10.4 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33252046532404433		[learning rate: 0.00010365]
	Learning Rate: 0.000103652
	LOSS [training: 0.33252046532404433 | validation: 0.3876978482217637]
	TIME [epoch: 10.4 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3377331490266209		[learning rate: 0.00010328]
	Learning Rate: 0.000103276
	LOSS [training: 0.3377331490266209 | validation: 0.38527053989902366]
	TIME [epoch: 10.4 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32469080293533487		[learning rate: 0.0001029]
	Learning Rate: 0.000102901
	LOSS [training: 0.32469080293533487 | validation: 0.36971557694363183]
	TIME [epoch: 10.4 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3348835063318435		[learning rate: 0.00010253]
	Learning Rate: 0.000102528
	LOSS [training: 0.3348835063318435 | validation: 0.37972113827987886]
	TIME [epoch: 10.4 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230580570933422		[learning rate: 0.00010216]
	Learning Rate: 0.000102156
	LOSS [training: 0.3230580570933422 | validation: 0.34722643630648437]
	TIME [epoch: 10.4 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30748693697481794		[learning rate: 0.00010179]
	Learning Rate: 0.000101785
	LOSS [training: 0.30748693697481794 | validation: 0.3777274901128898]
	TIME [epoch: 10.4 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154066509026484		[learning rate: 0.00010142]
	Learning Rate: 0.000101416
	LOSS [training: 0.3154066509026484 | validation: 0.34263331902558863]
	TIME [epoch: 10.4 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3116674521653267		[learning rate: 0.00010105]
	Learning Rate: 0.000101048
	LOSS [training: 0.3116674521653267 | validation: 0.3297730778578377]
	TIME [epoch: 10.4 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3355942779410423		[learning rate: 0.00010068]
	Learning Rate: 0.000100681
	LOSS [training: 0.3355942779410423 | validation: 0.3332266431072331]
	TIME [epoch: 10.4 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3066642351734486		[learning rate: 0.00010032]
	Learning Rate: 0.000100316
	LOSS [training: 0.3066642351734486 | validation: 0.34421973805977646]
	TIME [epoch: 10.4 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3460950232990247		[learning rate: 9.9952e-05]
	Learning Rate: 9.99515e-05
	LOSS [training: 0.3460950232990247 | validation: 0.3597830242623797]
	TIME [epoch: 10.4 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3270640274687592		[learning rate: 9.9589e-05]
	Learning Rate: 9.95888e-05
	LOSS [training: 0.3270640274687592 | validation: 0.3804068737476925]
	TIME [epoch: 10.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3392600358037162		[learning rate: 9.9227e-05]
	Learning Rate: 9.92274e-05
	LOSS [training: 0.3392600358037162 | validation: 0.3498866999007994]
	TIME [epoch: 10.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.323708302773006		[learning rate: 9.8867e-05]
	Learning Rate: 9.88673e-05
	LOSS [training: 0.323708302773006 | validation: 0.33919649859925266]
	TIME [epoch: 10.4 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31372664374059145		[learning rate: 9.8509e-05]
	Learning Rate: 9.85085e-05
	LOSS [training: 0.31372664374059145 | validation: 0.3440388499532323]
	TIME [epoch: 10.4 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075755525071622		[learning rate: 9.8151e-05]
	Learning Rate: 9.8151e-05
	LOSS [training: 0.3075755525071622 | validation: 0.35282773903707887]
	TIME [epoch: 10.4 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3251132857426206		[learning rate: 9.7795e-05]
	Learning Rate: 9.77948e-05
	LOSS [training: 0.3251132857426206 | validation: 0.3649150925158988]
	TIME [epoch: 10.4 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33209221228823055		[learning rate: 9.744e-05]
	Learning Rate: 9.74399e-05
	LOSS [training: 0.33209221228823055 | validation: 0.34809893638698625]
	TIME [epoch: 10.4 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327758050370784		[learning rate: 9.7086e-05]
	Learning Rate: 9.70863e-05
	LOSS [training: 0.327758050370784 | validation: 0.37025200745368936]
	TIME [epoch: 10.4 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416978824068576		[learning rate: 9.6734e-05]
	Learning Rate: 9.6734e-05
	LOSS [training: 0.3416978824068576 | validation: 0.35879226834277844]
	TIME [epoch: 10.4 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33835310232876203		[learning rate: 9.6383e-05]
	Learning Rate: 9.63829e-05
	LOSS [training: 0.33835310232876203 | validation: 0.38101488801437355]
	TIME [epoch: 10.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237298532866826		[learning rate: 9.6033e-05]
	Learning Rate: 9.60331e-05
	LOSS [training: 0.3237298532866826 | validation: 0.36056577786089544]
	TIME [epoch: 10.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32647757419401346		[learning rate: 9.5685e-05]
	Learning Rate: 9.56846e-05
	LOSS [training: 0.32647757419401346 | validation: 0.3430272023271587]
	TIME [epoch: 10.4 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32124068299680075		[learning rate: 9.5337e-05]
	Learning Rate: 9.53374e-05
	LOSS [training: 0.32124068299680075 | validation: 0.35237235986089505]
	TIME [epoch: 10.4 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3163571197255416		[learning rate: 9.4991e-05]
	Learning Rate: 9.49914e-05
	LOSS [training: 0.3163571197255416 | validation: 0.3660717953933034]
	TIME [epoch: 10.4 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274621856285657		[learning rate: 9.4647e-05]
	Learning Rate: 9.46466e-05
	LOSS [training: 0.3274621856285657 | validation: 0.2961858376849873]
	TIME [epoch: 10.4 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32910781250343396		[learning rate: 9.4303e-05]
	Learning Rate: 9.43032e-05
	LOSS [training: 0.32910781250343396 | validation: 0.3639795197278826]
	TIME [epoch: 10.4 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31562155270266945		[learning rate: 9.3961e-05]
	Learning Rate: 9.39609e-05
	LOSS [training: 0.31562155270266945 | validation: 0.35450422102811435]
	TIME [epoch: 10.4 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261706781610789		[learning rate: 9.362e-05]
	Learning Rate: 9.362e-05
	LOSS [training: 0.3261706781610789 | validation: 0.40007192454861346]
	TIME [epoch: 10.4 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3183994060563802		[learning rate: 9.328e-05]
	Learning Rate: 9.32802e-05
	LOSS [training: 0.3183994060563802 | validation: 0.3427824287443911]
	TIME [epoch: 10.4 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3167287801430725		[learning rate: 9.2942e-05]
	Learning Rate: 9.29417e-05
	LOSS [training: 0.3167287801430725 | validation: 0.35221525353826805]
	TIME [epoch: 10.4 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217146511389061		[learning rate: 9.2604e-05]
	Learning Rate: 9.26044e-05
	LOSS [training: 0.3217146511389061 | validation: 0.3691020494421834]
	TIME [epoch: 10.4 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33011218083183025		[learning rate: 9.2268e-05]
	Learning Rate: 9.22683e-05
	LOSS [training: 0.33011218083183025 | validation: 0.36157423973131764]
	TIME [epoch: 10.4 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3375600843659195		[learning rate: 9.1933e-05]
	Learning Rate: 9.19335e-05
	LOSS [training: 0.3375600843659195 | validation: 0.2729675233449122]
	TIME [epoch: 10.4 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3388047690533931		[learning rate: 9.16e-05]
	Learning Rate: 9.15998e-05
	LOSS [training: 0.3388047690533931 | validation: 0.3644489714851837]
	TIME [epoch: 10.4 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.318476450988762		[learning rate: 9.1267e-05]
	Learning Rate: 9.12674e-05
	LOSS [training: 0.318476450988762 | validation: 0.3508224795984928]
	TIME [epoch: 10.4 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3085373346360441		[learning rate: 9.0936e-05]
	Learning Rate: 9.09362e-05
	LOSS [training: 0.3085373346360441 | validation: 0.3909244577768473]
	TIME [epoch: 10.4 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33507615410804276		[learning rate: 9.0606e-05]
	Learning Rate: 9.06062e-05
	LOSS [training: 0.33507615410804276 | validation: 0.33460475554056507]
	TIME [epoch: 10.4 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33923679216554314		[learning rate: 9.0277e-05]
	Learning Rate: 9.02774e-05
	LOSS [training: 0.33923679216554314 | validation: 0.33868560804098835]
	TIME [epoch: 10.4 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186929403886013		[learning rate: 8.995e-05]
	Learning Rate: 8.99498e-05
	LOSS [training: 0.3186929403886013 | validation: 0.3704013922125992]
	TIME [epoch: 10.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3272512980554151		[learning rate: 8.9623e-05]
	Learning Rate: 8.96233e-05
	LOSS [training: 0.3272512980554151 | validation: 0.3514160628218835]
	TIME [epoch: 10.4 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3151636910987717		[learning rate: 8.9298e-05]
	Learning Rate: 8.92981e-05
	LOSS [training: 0.3151636910987717 | validation: 0.36392520804531586]
	TIME [epoch: 10.4 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32247591377262524		[learning rate: 8.8974e-05]
	Learning Rate: 8.8974e-05
	LOSS [training: 0.32247591377262524 | validation: 0.3294308584661439]
	TIME [epoch: 10.4 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32144036362993084		[learning rate: 8.8651e-05]
	Learning Rate: 8.86511e-05
	LOSS [training: 0.32144036362993084 | validation: 0.3694661776716416]
	TIME [epoch: 10.4 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064563738199111		[learning rate: 8.8329e-05]
	Learning Rate: 8.83294e-05
	LOSS [training: 0.3064563738199111 | validation: 0.3743168282657504]
	TIME [epoch: 10.4 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054024521950453		[learning rate: 8.8009e-05]
	Learning Rate: 8.80088e-05
	LOSS [training: 0.3054024521950453 | validation: 0.34258909865458037]
	TIME [epoch: 10.4 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3184031851645152		[learning rate: 8.7689e-05]
	Learning Rate: 8.76895e-05
	LOSS [training: 0.3184031851645152 | validation: 0.36637379323076064]
	TIME [epoch: 10.4 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147278757035608		[learning rate: 8.7371e-05]
	Learning Rate: 8.73712e-05
	LOSS [training: 0.3147278757035608 | validation: 0.36468768402326535]
	TIME [epoch: 10.4 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32464877862933844		[learning rate: 8.7054e-05]
	Learning Rate: 8.70542e-05
	LOSS [training: 0.32464877862933844 | validation: 0.3496329226526334]
	TIME [epoch: 10.4 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3296602368228779		[learning rate: 8.6738e-05]
	Learning Rate: 8.67382e-05
	LOSS [training: 0.3296602368228779 | validation: 0.33384965039902087]
	TIME [epoch: 10.4 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3116118468255933		[learning rate: 8.6423e-05]
	Learning Rate: 8.64235e-05
	LOSS [training: 0.3116118468255933 | validation: 0.3667625487723894]
	TIME [epoch: 10.4 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3271936583738285		[learning rate: 8.611e-05]
	Learning Rate: 8.61098e-05
	LOSS [training: 0.3271936583738285 | validation: 0.3320136360409651]
	TIME [epoch: 10.4 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230599016676122		[learning rate: 8.5797e-05]
	Learning Rate: 8.57973e-05
	LOSS [training: 0.3230599016676122 | validation: 0.37065412971547473]
	TIME [epoch: 10.4 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31959260389676525		[learning rate: 8.5486e-05]
	Learning Rate: 8.54859e-05
	LOSS [training: 0.31959260389676525 | validation: 0.3344750228236682]
	TIME [epoch: 10.4 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32475125881193573		[learning rate: 8.5176e-05]
	Learning Rate: 8.51757e-05
	LOSS [training: 0.32475125881193573 | validation: 0.36365033157595006]
	TIME [epoch: 10.4 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3216478976389304		[learning rate: 8.4867e-05]
	Learning Rate: 8.48666e-05
	LOSS [training: 0.3216478976389304 | validation: 0.3199276521631006]
	TIME [epoch: 10.4 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260706910306319		[learning rate: 8.4559e-05]
	Learning Rate: 8.45586e-05
	LOSS [training: 0.3260706910306319 | validation: 0.32954183009897586]
	TIME [epoch: 10.4 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3481228740786035		[learning rate: 8.4252e-05]
	Learning Rate: 8.42518e-05
	LOSS [training: 0.3481228740786035 | validation: 0.34415538967909165]
	TIME [epoch: 10.4 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35449220577978685		[learning rate: 8.3946e-05]
	Learning Rate: 8.3946e-05
	LOSS [training: 0.35449220577978685 | validation: 0.38779200576400286]
	TIME [epoch: 10.4 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3698939780411089		[learning rate: 8.3641e-05]
	Learning Rate: 8.36414e-05
	LOSS [training: 0.3698939780411089 | validation: 0.360830260120106]
	TIME [epoch: 10.4 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3508821821263983		[learning rate: 8.3338e-05]
	Learning Rate: 8.33378e-05
	LOSS [training: 0.3508821821263983 | validation: 0.3749746368711645]
	TIME [epoch: 10.4 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.341053655818728		[learning rate: 8.3035e-05]
	Learning Rate: 8.30354e-05
	LOSS [training: 0.341053655818728 | validation: 0.34757507440953783]
	TIME [epoch: 10.4 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3185025393982545		[learning rate: 8.2734e-05]
	Learning Rate: 8.2734e-05
	LOSS [training: 0.3185025393982545 | validation: 0.33573460567045343]
	TIME [epoch: 10.4 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33491486266979653		[learning rate: 8.2434e-05]
	Learning Rate: 8.24338e-05
	LOSS [training: 0.33491486266979653 | validation: 0.374217890946684]
	TIME [epoch: 10.4 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.315614000763631		[learning rate: 8.2135e-05]
	Learning Rate: 8.21346e-05
	LOSS [training: 0.315614000763631 | validation: 0.3356138600400809]
	TIME [epoch: 10.4 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3213579405471688		[learning rate: 8.1837e-05]
	Learning Rate: 8.18366e-05
	LOSS [training: 0.3213579405471688 | validation: 0.27513009169647246]
	TIME [epoch: 10.4 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3232740504227939		[learning rate: 8.154e-05]
	Learning Rate: 8.15396e-05
	LOSS [training: 0.3232740504227939 | validation: 0.2466413489712201]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1423.pth
	Model improved!!!
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3090768130481734		[learning rate: 8.1244e-05]
	Learning Rate: 8.12437e-05
	LOSS [training: 0.3090768130481734 | validation: 0.3517940262978189]
	TIME [epoch: 10.4 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3324930223164112		[learning rate: 8.0949e-05]
	Learning Rate: 8.09488e-05
	LOSS [training: 0.3324930223164112 | validation: 0.34286767272945073]
	TIME [epoch: 10.4 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3158485935905435		[learning rate: 8.0655e-05]
	Learning Rate: 8.0655e-05
	LOSS [training: 0.3158485935905435 | validation: 0.33384990805067005]
	TIME [epoch: 10.4 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32549143260237046		[learning rate: 8.0362e-05]
	Learning Rate: 8.03623e-05
	LOSS [training: 0.32549143260237046 | validation: 0.3649332867809444]
	TIME [epoch: 10.4 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3159753074732604		[learning rate: 8.0071e-05]
	Learning Rate: 8.00707e-05
	LOSS [training: 0.3159753074732604 | validation: 0.3699450123239366]
	TIME [epoch: 10.4 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3289937437515714		[learning rate: 7.978e-05]
	Learning Rate: 7.97801e-05
	LOSS [training: 0.3289937437515714 | validation: 0.34207042671820354]
	TIME [epoch: 10.4 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32612502649367847		[learning rate: 7.9491e-05]
	Learning Rate: 7.94906e-05
	LOSS [training: 0.32612502649367847 | validation: 0.33462001359068366]
	TIME [epoch: 10.4 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32646389954432337		[learning rate: 7.9202e-05]
	Learning Rate: 7.92021e-05
	LOSS [training: 0.32646389954432337 | validation: 0.3152003645018898]
	TIME [epoch: 10.4 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31688675139258066		[learning rate: 7.8915e-05]
	Learning Rate: 7.89147e-05
	LOSS [training: 0.31688675139258066 | validation: 0.3693257853989825]
	TIME [epoch: 10.4 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32013657268810763		[learning rate: 7.8628e-05]
	Learning Rate: 7.86283e-05
	LOSS [training: 0.32013657268810763 | validation: 0.38473320908700687]
	TIME [epoch: 10.4 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31119642442967604		[learning rate: 7.8343e-05]
	Learning Rate: 7.8343e-05
	LOSS [training: 0.31119642442967604 | validation: 0.3447090780438051]
	TIME [epoch: 10.4 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3201864261958993		[learning rate: 7.8059e-05]
	Learning Rate: 7.80586e-05
	LOSS [training: 0.3201864261958993 | validation: 0.38552844776463957]
	TIME [epoch: 10.4 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042147948842382		[learning rate: 7.7775e-05]
	Learning Rate: 7.77754e-05
	LOSS [training: 0.3042147948842382 | validation: 0.33880330642897816]
	TIME [epoch: 10.4 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3304088306076454		[learning rate: 7.7493e-05]
	Learning Rate: 7.74931e-05
	LOSS [training: 0.3304088306076454 | validation: 0.36549849290877773]
	TIME [epoch: 10.4 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3239925945269905		[learning rate: 7.7212e-05]
	Learning Rate: 7.72119e-05
	LOSS [training: 0.3239925945269905 | validation: 0.3594764203991105]
	TIME [epoch: 10.4 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33396163009381186		[learning rate: 7.6932e-05]
	Learning Rate: 7.69317e-05
	LOSS [training: 0.33396163009381186 | validation: 0.38107466571484977]
	TIME [epoch: 10.4 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30012859191386126		[learning rate: 7.6653e-05]
	Learning Rate: 7.66525e-05
	LOSS [training: 0.30012859191386126 | validation: 0.34578613575610895]
	TIME [epoch: 10.4 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.307099554081358		[learning rate: 7.6374e-05]
	Learning Rate: 7.63743e-05
	LOSS [training: 0.307099554081358 | validation: 0.3159759926195274]
	TIME [epoch: 10.4 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31991094691604766		[learning rate: 7.6097e-05]
	Learning Rate: 7.60972e-05
	LOSS [training: 0.31991094691604766 | validation: 0.34148362341413446]
	TIME [epoch: 10.4 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165730669922625		[learning rate: 7.5821e-05]
	Learning Rate: 7.5821e-05
	LOSS [training: 0.3165730669922625 | validation: 0.3398745623175414]
	TIME [epoch: 10.4 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252332304278861		[learning rate: 7.5546e-05]
	Learning Rate: 7.55458e-05
	LOSS [training: 0.3252332304278861 | validation: 0.32637163712440015]
	TIME [epoch: 10.4 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086169617172466		[learning rate: 7.5272e-05]
	Learning Rate: 7.52717e-05
	LOSS [training: 0.3086169617172466 | validation: 0.3453273788225272]
	TIME [epoch: 10.4 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3354280685899564		[learning rate: 7.4999e-05]
	Learning Rate: 7.49985e-05
	LOSS [training: 0.3354280685899564 | validation: 0.36708490463297433]
	TIME [epoch: 10.4 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31591530926059563		[learning rate: 7.4726e-05]
	Learning Rate: 7.47263e-05
	LOSS [training: 0.31591530926059563 | validation: 0.33890792624541677]
	TIME [epoch: 10.3 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261687948585194		[learning rate: 7.4455e-05]
	Learning Rate: 7.44552e-05
	LOSS [training: 0.3261687948585194 | validation: 0.35179339814060534]
	TIME [epoch: 10.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3497556484248382		[learning rate: 7.4185e-05]
	Learning Rate: 7.4185e-05
	LOSS [training: 0.3497556484248382 | validation: 0.3479128269220766]
	TIME [epoch: 10.4 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3276016624679214		[learning rate: 7.3916e-05]
	Learning Rate: 7.39157e-05
	LOSS [training: 0.3276016624679214 | validation: 0.32891079086985836]
	TIME [epoch: 10.4 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237354064809243		[learning rate: 7.3647e-05]
	Learning Rate: 7.36475e-05
	LOSS [training: 0.3237354064809243 | validation: 0.32503070549734736]
	TIME [epoch: 10.4 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31806238089338673		[learning rate: 7.338e-05]
	Learning Rate: 7.33802e-05
	LOSS [training: 0.31806238089338673 | validation: 0.34641422052904247]
	TIME [epoch: 10.4 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30854623767422645		[learning rate: 7.3114e-05]
	Learning Rate: 7.31139e-05
	LOSS [training: 0.30854623767422645 | validation: 0.32674083151394306]
	TIME [epoch: 10.4 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32279269417129136		[learning rate: 7.2849e-05]
	Learning Rate: 7.28486e-05
	LOSS [training: 0.32279269417129136 | validation: 0.32748568354598034]
	TIME [epoch: 10.4 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31976762361405175		[learning rate: 7.2584e-05]
	Learning Rate: 7.25842e-05
	LOSS [training: 0.31976762361405175 | validation: 0.3812430364746329]
	TIME [epoch: 10.4 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30932494501483326		[learning rate: 7.2321e-05]
	Learning Rate: 7.23208e-05
	LOSS [training: 0.30932494501483326 | validation: 0.3319353487099261]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30346832490731573		[learning rate: 7.2058e-05]
	Learning Rate: 7.20583e-05
	LOSS [training: 0.30346832490731573 | validation: 0.24513924852818417]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1457.pth
	Model improved!!!
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134842418256461		[learning rate: 7.1797e-05]
	Learning Rate: 7.17968e-05
	LOSS [training: 0.3134842418256461 | validation: 0.33125528235505464]
	TIME [epoch: 10.4 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027718245878192		[learning rate: 7.1536e-05]
	Learning Rate: 7.15363e-05
	LOSS [training: 0.3027718245878192 | validation: 0.3338156587457042]
	TIME [epoch: 10.3 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32264174814482044		[learning rate: 7.1277e-05]
	Learning Rate: 7.12767e-05
	LOSS [training: 0.32264174814482044 | validation: 0.3611161637388861]
	TIME [epoch: 10.4 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3216928143478463		[learning rate: 7.1018e-05]
	Learning Rate: 7.1018e-05
	LOSS [training: 0.3216928143478463 | validation: 0.28866338772276473]
	TIME [epoch: 10.4 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3352911448002912		[learning rate: 7.076e-05]
	Learning Rate: 7.07603e-05
	LOSS [training: 0.3352911448002912 | validation: 0.35955321602856855]
	TIME [epoch: 10.4 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31134237734084474		[learning rate: 7.0503e-05]
	Learning Rate: 7.05035e-05
	LOSS [training: 0.31134237734084474 | validation: 0.35715907077777553]
	TIME [epoch: 10.4 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156105149202398		[learning rate: 7.0248e-05]
	Learning Rate: 7.02476e-05
	LOSS [training: 0.3156105149202398 | validation: 0.33751027229366287]
	TIME [epoch: 10.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.302498301750757		[learning rate: 6.9993e-05]
	Learning Rate: 6.99927e-05
	LOSS [training: 0.302498301750757 | validation: 0.316942502425955]
	TIME [epoch: 10.4 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154343160430425		[learning rate: 6.9739e-05]
	Learning Rate: 6.97387e-05
	LOSS [training: 0.3154343160430425 | validation: 0.3286273001514716]
	TIME [epoch: 10.4 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32291040029057994		[learning rate: 6.9486e-05]
	Learning Rate: 6.94856e-05
	LOSS [training: 0.32291040029057994 | validation: 0.3612682855800501]
	TIME [epoch: 10.4 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221061237353718		[learning rate: 6.9233e-05]
	Learning Rate: 6.92334e-05
	LOSS [training: 0.3221061237353718 | validation: 0.3859372455641341]
	TIME [epoch: 10.4 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3290655261980124		[learning rate: 6.8982e-05]
	Learning Rate: 6.89822e-05
	LOSS [training: 0.3290655261980124 | validation: 0.3376596366181535]
	TIME [epoch: 10.4 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32344403634973184		[learning rate: 6.8732e-05]
	Learning Rate: 6.87318e-05
	LOSS [training: 0.32344403634973184 | validation: 0.3659560570372232]
	TIME [epoch: 10.4 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32303880170617305		[learning rate: 6.8482e-05]
	Learning Rate: 6.84824e-05
	LOSS [training: 0.32303880170617305 | validation: 0.31172630921535294]
	TIME [epoch: 10.4 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31188416581675354		[learning rate: 6.8234e-05]
	Learning Rate: 6.82339e-05
	LOSS [training: 0.31188416581675354 | validation: 0.36861146401561046]
	TIME [epoch: 10.4 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32400799544262765		[learning rate: 6.7986e-05]
	Learning Rate: 6.79862e-05
	LOSS [training: 0.32400799544262765 | validation: 0.3342816106290731]
	TIME [epoch: 10.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.325131363694526		[learning rate: 6.774e-05]
	Learning Rate: 6.77395e-05
	LOSS [training: 0.325131363694526 | validation: 0.33109376700947685]
	TIME [epoch: 10.4 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32744806534002324		[learning rate: 6.7494e-05]
	Learning Rate: 6.74937e-05
	LOSS [training: 0.32744806534002324 | validation: 0.34250963885718383]
	TIME [epoch: 10.4 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105381117070252		[learning rate: 6.7249e-05]
	Learning Rate: 6.72488e-05
	LOSS [training: 0.3105381117070252 | validation: 0.3481705553707225]
	TIME [epoch: 10.4 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168758014592947		[learning rate: 6.7005e-05]
	Learning Rate: 6.70047e-05
	LOSS [training: 0.3168758014592947 | validation: 0.3243713532928544]
	TIME [epoch: 10.4 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31464555743248435		[learning rate: 6.6762e-05]
	Learning Rate: 6.67616e-05
	LOSS [training: 0.31464555743248435 | validation: 0.3290095530988822]
	TIME [epoch: 10.4 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3349215358755397		[learning rate: 6.6519e-05]
	Learning Rate: 6.65192e-05
	LOSS [training: 0.3349215358755397 | validation: 0.3677116059159576]
	TIME [epoch: 10.4 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31401806141391136		[learning rate: 6.6278e-05]
	Learning Rate: 6.62778e-05
	LOSS [training: 0.31401806141391136 | validation: 0.35628369396405274]
	TIME [epoch: 10.4 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3078418830119122		[learning rate: 6.6037e-05]
	Learning Rate: 6.60373e-05
	LOSS [training: 0.3078418830119122 | validation: 0.37018121737974113]
	TIME [epoch: 10.4 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3085027729950573		[learning rate: 6.5798e-05]
	Learning Rate: 6.57977e-05
	LOSS [training: 0.3085027729950573 | validation: 0.319226014572761]
	TIME [epoch: 10.4 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32065274701094804		[learning rate: 6.5559e-05]
	Learning Rate: 6.55589e-05
	LOSS [training: 0.32065274701094804 | validation: 0.3413203654585636]
	TIME [epoch: 10.4 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30889445403888977		[learning rate: 6.5321e-05]
	Learning Rate: 6.5321e-05
	LOSS [training: 0.30889445403888977 | validation: 0.31706968776150296]
	TIME [epoch: 10.4 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31285361948986495		[learning rate: 6.5084e-05]
	Learning Rate: 6.50839e-05
	LOSS [training: 0.31285361948986495 | validation: 0.3447794499603507]
	TIME [epoch: 10.4 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130905315606318		[learning rate: 6.4848e-05]
	Learning Rate: 6.48477e-05
	LOSS [training: 0.3130905315606318 | validation: 0.36543001068811803]
	TIME [epoch: 10.4 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3273864119881123		[learning rate: 6.4612e-05]
	Learning Rate: 6.46124e-05
	LOSS [training: 0.3273864119881123 | validation: 0.3323863704103644]
	TIME [epoch: 10.4 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3188684839201956		[learning rate: 6.4378e-05]
	Learning Rate: 6.43779e-05
	LOSS [training: 0.3188684839201956 | validation: 0.34042105131921035]
	TIME [epoch: 10.4 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3269892501845862		[learning rate: 6.4144e-05]
	Learning Rate: 6.41443e-05
	LOSS [training: 0.3269892501845862 | validation: 0.34570199978690425]
	TIME [epoch: 10.4 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34044873278168897		[learning rate: 6.3911e-05]
	Learning Rate: 6.39115e-05
	LOSS [training: 0.34044873278168897 | validation: 0.3409558192347364]
	TIME [epoch: 10.4 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.331000198615984		[learning rate: 6.368e-05]
	Learning Rate: 6.36795e-05
	LOSS [training: 0.331000198615984 | validation: 0.380641519952128]
	TIME [epoch: 10.4 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32404245589759256		[learning rate: 6.3448e-05]
	Learning Rate: 6.34485e-05
	LOSS [training: 0.32404245589759256 | validation: 0.41256898706893397]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3129166429029811		[learning rate: 6.3218e-05]
	Learning Rate: 6.32182e-05
	LOSS [training: 0.3129166429029811 | validation: 0.37760810159208086]
	TIME [epoch: 10.4 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3319433513736768		[learning rate: 6.2989e-05]
	Learning Rate: 6.29888e-05
	LOSS [training: 0.3319433513736768 | validation: 0.3498534340567083]
	TIME [epoch: 10.4 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31959786394233597		[learning rate: 6.276e-05]
	Learning Rate: 6.27602e-05
	LOSS [training: 0.31959786394233597 | validation: 0.3433565893909045]
	TIME [epoch: 10.4 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3200821438409042		[learning rate: 6.2532e-05]
	Learning Rate: 6.25324e-05
	LOSS [training: 0.3200821438409042 | validation: 0.33583373340378614]
	TIME [epoch: 10.4 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30231847632255426		[learning rate: 6.2305e-05]
	Learning Rate: 6.23055e-05
	LOSS [training: 0.30231847632255426 | validation: 0.3399209444238504]
	TIME [epoch: 10.4 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3180205798462603		[learning rate: 6.2079e-05]
	Learning Rate: 6.20794e-05
	LOSS [training: 0.3180205798462603 | validation: 0.4139029053044135]
	TIME [epoch: 10.4 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32257198869490783		[learning rate: 6.1854e-05]
	Learning Rate: 6.18541e-05
	LOSS [training: 0.32257198869490783 | validation: 0.3528029093699654]
	TIME [epoch: 10.4 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064172202302836		[learning rate: 6.163e-05]
	Learning Rate: 6.16296e-05
	LOSS [training: 0.3064172202302836 | validation: 0.2800251575216097]
	TIME [epoch: 10.4 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32056001189238836		[learning rate: 6.1406e-05]
	Learning Rate: 6.1406e-05
	LOSS [training: 0.32056001189238836 | validation: 0.33432734097886324]
	TIME [epoch: 10.4 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3196983922417546		[learning rate: 6.1183e-05]
	Learning Rate: 6.11831e-05
	LOSS [training: 0.3196983922417546 | validation: 0.33800504629107236]
	TIME [epoch: 10.4 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3128776010473559		[learning rate: 6.0961e-05]
	Learning Rate: 6.09611e-05
	LOSS [training: 0.3128776010473559 | validation: 0.3689252506936333]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3216630341541729		[learning rate: 6.074e-05]
	Learning Rate: 6.07399e-05
	LOSS [training: 0.3216630341541729 | validation: 0.3829605580849062]
	TIME [epoch: 10.4 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283179004163681		[learning rate: 6.0519e-05]
	Learning Rate: 6.05194e-05
	LOSS [training: 0.3283179004163681 | validation: 0.3265838334386661]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221797541336144		[learning rate: 6.03e-05]
	Learning Rate: 6.02998e-05
	LOSS [training: 0.3221797541336144 | validation: 0.36505329301062106]
	TIME [epoch: 10.4 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3187363572607661		[learning rate: 6.0081e-05]
	Learning Rate: 6.0081e-05
	LOSS [training: 0.3187363572607661 | validation: 0.33620549098124386]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3187995665936904		[learning rate: 5.9863e-05]
	Learning Rate: 5.98629e-05
	LOSS [training: 0.3187995665936904 | validation: 0.3540757138011313]
	TIME [epoch: 10.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3196086816187172		[learning rate: 5.9646e-05]
	Learning Rate: 5.96457e-05
	LOSS [training: 0.3196086816187172 | validation: 0.34110435042067905]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31865629126763173		[learning rate: 5.9429e-05]
	Learning Rate: 5.94292e-05
	LOSS [training: 0.31865629126763173 | validation: 0.3403922713108801]
	TIME [epoch: 10.4 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086176524117936		[learning rate: 5.9214e-05]
	Learning Rate: 5.92136e-05
	LOSS [training: 0.3086176524117936 | validation: 0.3818639862950943]
	TIME [epoch: 10.4 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31731755667544753		[learning rate: 5.8999e-05]
	Learning Rate: 5.89987e-05
	LOSS [training: 0.31731755667544753 | validation: 0.3486213533648252]
	TIME [epoch: 10.4 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076573257019874		[learning rate: 5.8785e-05]
	Learning Rate: 5.87846e-05
	LOSS [training: 0.3076573257019874 | validation: 0.3305343421354551]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146078405655422		[learning rate: 5.8571e-05]
	Learning Rate: 5.85712e-05
	LOSS [training: 0.3146078405655422 | validation: 0.3390798043347769]
	TIME [epoch: 10.4 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32480914110096054		[learning rate: 5.8359e-05]
	Learning Rate: 5.83586e-05
	LOSS [training: 0.32480914110096054 | validation: 0.32891092798759647]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068576315179001		[learning rate: 5.8147e-05]
	Learning Rate: 5.81469e-05
	LOSS [training: 0.3068576315179001 | validation: 0.36525243872430635]
	TIME [epoch: 10.4 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32367786322783865		[learning rate: 5.7936e-05]
	Learning Rate: 5.79358e-05
	LOSS [training: 0.32367786322783865 | validation: 0.34441917246467285]
	TIME [epoch: 10.4 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32546597884330863		[learning rate: 5.7726e-05]
	Learning Rate: 5.77256e-05
	LOSS [training: 0.32546597884330863 | validation: 0.343721905576805]
	TIME [epoch: 10.4 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.329888884765498		[learning rate: 5.7516e-05]
	Learning Rate: 5.75161e-05
	LOSS [training: 0.329888884765498 | validation: 0.37147932540731327]
	TIME [epoch: 10.4 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022686418235284		[learning rate: 5.7307e-05]
	Learning Rate: 5.73074e-05
	LOSS [training: 0.3022686418235284 | validation: 0.3394143028497185]
	TIME [epoch: 10.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30420419932648457		[learning rate: 5.7099e-05]
	Learning Rate: 5.70994e-05
	LOSS [training: 0.30420419932648457 | validation: 0.34372656411372343]
	TIME [epoch: 10.4 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31202508280945185		[learning rate: 5.6892e-05]
	Learning Rate: 5.68922e-05
	LOSS [training: 0.31202508280945185 | validation: 0.35072319294995863]
	TIME [epoch: 10.4 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31238126814742456		[learning rate: 5.6686e-05]
	Learning Rate: 5.66857e-05
	LOSS [training: 0.31238126814742456 | validation: 0.3506002007314976]
	TIME [epoch: 10.4 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.311252190661867		[learning rate: 5.648e-05]
	Learning Rate: 5.648e-05
	LOSS [training: 0.311252190661867 | validation: 0.38601156268080056]
	TIME [epoch: 10.4 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30726855043747653		[learning rate: 5.6275e-05]
	Learning Rate: 5.6275e-05
	LOSS [training: 0.30726855043747653 | validation: 0.3446415755889106]
	TIME [epoch: 10.4 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3303196580138987		[learning rate: 5.6071e-05]
	Learning Rate: 5.60708e-05
	LOSS [training: 0.3303196580138987 | validation: 0.3772253370508586]
	TIME [epoch: 10.4 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134152908819263		[learning rate: 5.5867e-05]
	Learning Rate: 5.58673e-05
	LOSS [training: 0.3134152908819263 | validation: 0.33942338041450604]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30805126006125055		[learning rate: 5.5665e-05]
	Learning Rate: 5.56646e-05
	LOSS [training: 0.30805126006125055 | validation: 0.34341266800119685]
	TIME [epoch: 10.3 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3167541315479524		[learning rate: 5.5463e-05]
	Learning Rate: 5.54626e-05
	LOSS [training: 0.3167541315479524 | validation: 0.35566219459293325]
	TIME [epoch: 10.4 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32553558057113696		[learning rate: 5.5261e-05]
	Learning Rate: 5.52613e-05
	LOSS [training: 0.32553558057113696 | validation: 0.3690449749386904]
	TIME [epoch: 10.4 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3230311104707082		[learning rate: 5.5061e-05]
	Learning Rate: 5.50608e-05
	LOSS [training: 0.3230311104707082 | validation: 0.3338511759156852]
	TIME [epoch: 10.4 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3279748612060399		[learning rate: 5.4861e-05]
	Learning Rate: 5.48609e-05
	LOSS [training: 0.3279748612060399 | validation: 0.3384995488258922]
	TIME [epoch: 10.4 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3136740251519701		[learning rate: 5.4662e-05]
	Learning Rate: 5.46618e-05
	LOSS [training: 0.3136740251519701 | validation: 0.33904441669957003]
	TIME [epoch: 10.4 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31336212737903874		[learning rate: 5.4463e-05]
	Learning Rate: 5.44635e-05
	LOSS [training: 0.31336212737903874 | validation: 0.3743198329381016]
	TIME [epoch: 10.4 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31494978111042615		[learning rate: 5.4266e-05]
	Learning Rate: 5.42658e-05
	LOSS [training: 0.31494978111042615 | validation: 0.328322563134761]
	TIME [epoch: 10.4 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3078533709253259		[learning rate: 5.4069e-05]
	Learning Rate: 5.40689e-05
	LOSS [training: 0.3078533709253259 | validation: 0.34265218479316006]
	TIME [epoch: 10.4 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32917871479384087		[learning rate: 5.3873e-05]
	Learning Rate: 5.38727e-05
	LOSS [training: 0.32917871479384087 | validation: 0.3459870363027801]
	TIME [epoch: 10.4 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3215211671798434		[learning rate: 5.3677e-05]
	Learning Rate: 5.36772e-05
	LOSS [training: 0.3215211671798434 | validation: 0.3624234071993051]
	TIME [epoch: 10.4 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3195522670181981		[learning rate: 5.3482e-05]
	Learning Rate: 5.34824e-05
	LOSS [training: 0.3195522670181981 | validation: 0.3724537551602608]
	TIME [epoch: 10.4 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073715748203803		[learning rate: 5.3288e-05]
	Learning Rate: 5.32883e-05
	LOSS [training: 0.3073715748203803 | validation: 0.34376662463925145]
	TIME [epoch: 10.4 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31605443151252144		[learning rate: 5.3095e-05]
	Learning Rate: 5.30949e-05
	LOSS [training: 0.31605443151252144 | validation: 0.33234006457634413]
	TIME [epoch: 10.4 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3206835885676765		[learning rate: 5.2902e-05]
	Learning Rate: 5.29022e-05
	LOSS [training: 0.3206835885676765 | validation: 0.37673016225814354]
	TIME [epoch: 10.4 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32235700289649893		[learning rate: 5.271e-05]
	Learning Rate: 5.27102e-05
	LOSS [training: 0.32235700289649893 | validation: 0.3591240686601093]
	TIME [epoch: 10.4 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31088961316202945		[learning rate: 5.2519e-05]
	Learning Rate: 5.25189e-05
	LOSS [training: 0.31088961316202945 | validation: 0.3699587630969935]
	TIME [epoch: 10.4 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35749989531141835		[learning rate: 5.2328e-05]
	Learning Rate: 5.23283e-05
	LOSS [training: 0.35749989531141835 | validation: 0.3484168670080928]
	TIME [epoch: 10.4 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33561778264111897		[learning rate: 5.2138e-05]
	Learning Rate: 5.21384e-05
	LOSS [training: 0.33561778264111897 | validation: 0.3746138755130099]
	TIME [epoch: 10.4 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30024702957619087		[learning rate: 5.1949e-05]
	Learning Rate: 5.19492e-05
	LOSS [training: 0.30024702957619087 | validation: 0.341691359645192]
	TIME [epoch: 10.4 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32333368139399		[learning rate: 5.1761e-05]
	Learning Rate: 5.17607e-05
	LOSS [training: 0.32333368139399 | validation: 0.36005635675970465]
	TIME [epoch: 10.4 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31692700874471824		[learning rate: 5.1573e-05]
	Learning Rate: 5.15729e-05
	LOSS [training: 0.31692700874471824 | validation: 0.3469362970296724]
	TIME [epoch: 10.4 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3286367053961213		[learning rate: 5.1386e-05]
	Learning Rate: 5.13857e-05
	LOSS [training: 0.3286367053961213 | validation: 0.34090421068406285]
	TIME [epoch: 10.4 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3119600259697549		[learning rate: 5.1199e-05]
	Learning Rate: 5.11992e-05
	LOSS [training: 0.3119600259697549 | validation: 0.3504322191993554]
	TIME [epoch: 10.4 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.318882335387346		[learning rate: 5.1013e-05]
	Learning Rate: 5.10134e-05
	LOSS [training: 0.318882335387346 | validation: 0.33787429563050486]
	TIME [epoch: 10.4 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3206093728791133		[learning rate: 5.0828e-05]
	Learning Rate: 5.08283e-05
	LOSS [training: 0.3206093728791133 | validation: 0.35068908180017466]
	TIME [epoch: 10.4 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31002547203006114		[learning rate: 5.0644e-05]
	Learning Rate: 5.06438e-05
	LOSS [training: 0.31002547203006114 | validation: 0.23975590348285558]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1554.pth
	Model improved!!!
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3195878286988359		[learning rate: 5.046e-05]
	Learning Rate: 5.046e-05
	LOSS [training: 0.3195878286988359 | validation: 0.4008268756501212]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086370478832131		[learning rate: 5.0277e-05]
	Learning Rate: 5.02769e-05
	LOSS [training: 0.3086370478832131 | validation: 0.3391119546195365]
	TIME [epoch: 10.4 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168570644990345		[learning rate: 5.0094e-05]
	Learning Rate: 5.00944e-05
	LOSS [training: 0.3168570644990345 | validation: 0.3312918536003477]
	TIME [epoch: 10.4 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297234545066023		[learning rate: 4.9913e-05]
	Learning Rate: 4.99127e-05
	LOSS [training: 0.297234545066023 | validation: 0.3314277506875876]
	TIME [epoch: 10.4 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3132946392488619		[learning rate: 4.9732e-05]
	Learning Rate: 4.97315e-05
	LOSS [training: 0.3132946392488619 | validation: 0.3510830241954521]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2973332577431826		[learning rate: 4.9551e-05]
	Learning Rate: 4.9551e-05
	LOSS [training: 0.2973332577431826 | validation: 0.34898190315978767]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29813135574206195		[learning rate: 4.9371e-05]
	Learning Rate: 4.93712e-05
	LOSS [training: 0.29813135574206195 | validation: 0.3378111989797331]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31271830464839495		[learning rate: 4.9192e-05]
	Learning Rate: 4.9192e-05
	LOSS [training: 0.31271830464839495 | validation: 0.3570846657138322]
	TIME [epoch: 10.4 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31962428310515667		[learning rate: 4.9014e-05]
	Learning Rate: 4.90135e-05
	LOSS [training: 0.31962428310515667 | validation: 0.37692636219023423]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31412577258237945		[learning rate: 4.8836e-05]
	Learning Rate: 4.88356e-05
	LOSS [training: 0.31412577258237945 | validation: 0.32323410386665496]
	TIME [epoch: 10.4 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075521809324421		[learning rate: 4.8658e-05]
	Learning Rate: 4.86584e-05
	LOSS [training: 0.3075521809324421 | validation: 0.3338683969958891]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127845533280456		[learning rate: 4.8482e-05]
	Learning Rate: 4.84818e-05
	LOSS [training: 0.3127845533280456 | validation: 0.370221319636187]
	TIME [epoch: 10.4 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168877305654412		[learning rate: 4.8306e-05]
	Learning Rate: 4.83059e-05
	LOSS [training: 0.3168877305654412 | validation: 0.3871543059949936]
	TIME [epoch: 10.4 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31865427425742987		[learning rate: 4.8131e-05]
	Learning Rate: 4.81306e-05
	LOSS [training: 0.31865427425742987 | validation: 0.3458931796235025]
	TIME [epoch: 10.4 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221777288602846		[learning rate: 4.7956e-05]
	Learning Rate: 4.79559e-05
	LOSS [training: 0.3221777288602846 | validation: 0.35710087034443916]
	TIME [epoch: 10.4 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3025083597550263		[learning rate: 4.7782e-05]
	Learning Rate: 4.77819e-05
	LOSS [training: 0.3025083597550263 | validation: 0.3442959996175881]
	TIME [epoch: 10.4 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31886090791274424		[learning rate: 4.7608e-05]
	Learning Rate: 4.76085e-05
	LOSS [training: 0.31886090791274424 | validation: 0.3410679307985118]
	TIME [epoch: 10.4 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30425876160690596		[learning rate: 4.7436e-05]
	Learning Rate: 4.74357e-05
	LOSS [training: 0.30425876160690596 | validation: 0.37478890715378627]
	TIME [epoch: 10.4 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29708897734351325		[learning rate: 4.7264e-05]
	Learning Rate: 4.72636e-05
	LOSS [training: 0.29708897734351325 | validation: 0.3288270675865617]
	TIME [epoch: 10.4 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31601534525248703		[learning rate: 4.7092e-05]
	Learning Rate: 4.7092e-05
	LOSS [training: 0.31601534525248703 | validation: 0.333072591909089]
	TIME [epoch: 10.4 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3098048504498524		[learning rate: 4.6921e-05]
	Learning Rate: 4.69211e-05
	LOSS [training: 0.3098048504498524 | validation: 0.34713404127917175]
	TIME [epoch: 10.4 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30992347660398223		[learning rate: 4.6751e-05]
	Learning Rate: 4.67508e-05
	LOSS [training: 0.30992347660398223 | validation: 0.3423436063610441]
	TIME [epoch: 10.4 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32804123411224334		[learning rate: 4.6581e-05]
	Learning Rate: 4.65812e-05
	LOSS [training: 0.32804123411224334 | validation: 0.3400455690304747]
	TIME [epoch: 10.4 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.311483594222351		[learning rate: 4.6412e-05]
	Learning Rate: 4.64121e-05
	LOSS [training: 0.311483594222351 | validation: 0.33172138120982175]
	TIME [epoch: 10.4 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3247941401883402		[learning rate: 4.6244e-05]
	Learning Rate: 4.62437e-05
	LOSS [training: 0.3247941401883402 | validation: 0.3218149242672269]
	TIME [epoch: 10.4 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30543469576698845		[learning rate: 4.6076e-05]
	Learning Rate: 4.60759e-05
	LOSS [training: 0.30543469576698845 | validation: 0.412105021691902]
	TIME [epoch: 10.4 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178010164975361		[learning rate: 4.5909e-05]
	Learning Rate: 4.59087e-05
	LOSS [training: 0.3178010164975361 | validation: 0.36944905984720905]
	TIME [epoch: 10.4 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199359319261056		[learning rate: 4.5742e-05]
	Learning Rate: 4.57421e-05
	LOSS [training: 0.3199359319261056 | validation: 0.33122231932008533]
	TIME [epoch: 10.4 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31525644088418414		[learning rate: 4.5576e-05]
	Learning Rate: 4.55761e-05
	LOSS [training: 0.31525644088418414 | validation: 0.37905639590648454]
	TIME [epoch: 10.4 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32528813579827665		[learning rate: 4.5411e-05]
	Learning Rate: 4.54107e-05
	LOSS [training: 0.32528813579827665 | validation: 0.3440171835084621]
	TIME [epoch: 10.4 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30983250461576844		[learning rate: 4.5246e-05]
	Learning Rate: 4.52459e-05
	LOSS [training: 0.30983250461576844 | validation: 0.3601004552684025]
	TIME [epoch: 10.4 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3023643077121106		[learning rate: 4.5082e-05]
	Learning Rate: 4.50817e-05
	LOSS [training: 0.3023643077121106 | validation: 0.3463961061112717]
	TIME [epoch: 10.4 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.309028624908259		[learning rate: 4.4918e-05]
	Learning Rate: 4.49181e-05
	LOSS [training: 0.309028624908259 | validation: 0.325293984659885]
	TIME [epoch: 10.4 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3170321687536565		[learning rate: 4.4755e-05]
	Learning Rate: 4.47551e-05
	LOSS [training: 0.3170321687536565 | validation: 0.3758330816990163]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31191390708381384		[learning rate: 4.4593e-05]
	Learning Rate: 4.45926e-05
	LOSS [training: 0.31191390708381384 | validation: 0.3297389132861954]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146083781459185		[learning rate: 4.4431e-05]
	Learning Rate: 4.44308e-05
	LOSS [training: 0.3146083781459185 | validation: 0.36935146507390193]
	TIME [epoch: 10.4 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30979056989516424		[learning rate: 4.427e-05]
	Learning Rate: 4.42696e-05
	LOSS [training: 0.30979056989516424 | validation: 0.3918418619608434]
	TIME [epoch: 10.4 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30881070471538974		[learning rate: 4.4109e-05]
	Learning Rate: 4.41089e-05
	LOSS [training: 0.30881070471538974 | validation: 0.3379801343921187]
	TIME [epoch: 10.4 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30429660602094444		[learning rate: 4.3949e-05]
	Learning Rate: 4.39489e-05
	LOSS [training: 0.30429660602094444 | validation: 0.3362835543208222]
	TIME [epoch: 10.4 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29288862337366506		[learning rate: 4.3789e-05]
	Learning Rate: 4.37893e-05
	LOSS [training: 0.29288862337366506 | validation: 0.33432967711329525]
	TIME [epoch: 10.4 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3227716930506543		[learning rate: 4.363e-05]
	Learning Rate: 4.36304e-05
	LOSS [training: 0.3227716930506543 | validation: 0.3456099274198519]
	TIME [epoch: 10.4 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308667235196001		[learning rate: 4.3472e-05]
	Learning Rate: 4.34721e-05
	LOSS [training: 0.308667235196001 | validation: 0.3741610795286517]
	TIME [epoch: 10.4 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003219504637336		[learning rate: 4.3314e-05]
	Learning Rate: 4.33143e-05
	LOSS [training: 0.3003219504637336 | validation: 0.36478578403333245]
	TIME [epoch: 10.4 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31716286461643095		[learning rate: 4.3157e-05]
	Learning Rate: 4.31571e-05
	LOSS [training: 0.31716286461643095 | validation: 0.3508048980652033]
	TIME [epoch: 10.4 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31631618808341233		[learning rate: 4.3001e-05]
	Learning Rate: 4.30005e-05
	LOSS [training: 0.31631618808341233 | validation: 0.3375915597577903]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30907323722295044		[learning rate: 4.2844e-05]
	Learning Rate: 4.28445e-05
	LOSS [training: 0.30907323722295044 | validation: 0.27173134698825335]
	TIME [epoch: 10.4 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156903802762038		[learning rate: 4.2689e-05]
	Learning Rate: 4.2689e-05
	LOSS [training: 0.3156903802762038 | validation: 0.3699647105190567]
	TIME [epoch: 10.4 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981923971517476		[learning rate: 4.2534e-05]
	Learning Rate: 4.25341e-05
	LOSS [training: 0.2981923971517476 | validation: 0.34511682644655056]
	TIME [epoch: 10.4 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144975992603287		[learning rate: 4.238e-05]
	Learning Rate: 4.23797e-05
	LOSS [training: 0.3144975992603287 | validation: 0.35018653273439154]
	TIME [epoch: 10.4 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32903484493161955		[learning rate: 4.2226e-05]
	Learning Rate: 4.22259e-05
	LOSS [training: 0.32903484493161955 | validation: 0.3292661141108274]
	TIME [epoch: 10.4 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974118794295474		[learning rate: 4.2073e-05]
	Learning Rate: 4.20727e-05
	LOSS [training: 0.2974118794295474 | validation: 0.3272787829234362]
	TIME [epoch: 10.4 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32249663016891217		[learning rate: 4.192e-05]
	Learning Rate: 4.192e-05
	LOSS [training: 0.32249663016891217 | validation: 0.3684430959928712]
	TIME [epoch: 10.4 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961158513690932		[learning rate: 4.1768e-05]
	Learning Rate: 4.17679e-05
	LOSS [training: 0.2961158513690932 | validation: 0.3209869096106325]
	TIME [epoch: 10.4 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33072600320707884		[learning rate: 4.1616e-05]
	Learning Rate: 4.16163e-05
	LOSS [training: 0.33072600320707884 | validation: 0.33162649300673624]
	TIME [epoch: 10.4 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30358837502842007		[learning rate: 4.1465e-05]
	Learning Rate: 4.14652e-05
	LOSS [training: 0.30358837502842007 | validation: 0.33467529668530893]
	TIME [epoch: 10.4 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31275345435721225		[learning rate: 4.1315e-05]
	Learning Rate: 4.13148e-05
	LOSS [training: 0.31275345435721225 | validation: 0.31890136563643223]
	TIME [epoch: 10.4 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31218905294708416		[learning rate: 4.1165e-05]
	Learning Rate: 4.11648e-05
	LOSS [training: 0.31218905294708416 | validation: 0.36313034383044107]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076904845090985		[learning rate: 4.1015e-05]
	Learning Rate: 4.10154e-05
	LOSS [training: 0.3076904845090985 | validation: 0.33949366723286106]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31863462603250137		[learning rate: 4.0867e-05]
	Learning Rate: 4.08666e-05
	LOSS [training: 0.31863462603250137 | validation: 0.326134626796359]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31838653234171443		[learning rate: 4.0718e-05]
	Learning Rate: 4.07183e-05
	LOSS [training: 0.31838653234171443 | validation: 0.38485094960107474]
	TIME [epoch: 10.4 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30829569708259075		[learning rate: 4.0571e-05]
	Learning Rate: 4.05705e-05
	LOSS [training: 0.30829569708259075 | validation: 0.33427569967805226]
	TIME [epoch: 10.4 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32685472565686846		[learning rate: 4.0423e-05]
	Learning Rate: 4.04233e-05
	LOSS [training: 0.32685472565686846 | validation: 0.28864000306641574]
	TIME [epoch: 10.4 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29783039381584275		[learning rate: 4.0277e-05]
	Learning Rate: 4.02766e-05
	LOSS [training: 0.29783039381584275 | validation: 0.27381650046105793]
	TIME [epoch: 10.4 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30121416671933404		[learning rate: 4.013e-05]
	Learning Rate: 4.01304e-05
	LOSS [training: 0.30121416671933404 | validation: 0.3685975033997514]
	TIME [epoch: 10.4 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105239643646735		[learning rate: 3.9985e-05]
	Learning Rate: 3.99848e-05
	LOSS [training: 0.3105239643646735 | validation: 0.32913725191976123]
	TIME [epoch: 10.4 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29712306086681717		[learning rate: 3.984e-05]
	Learning Rate: 3.98397e-05
	LOSS [training: 0.29712306086681717 | validation: 0.36070981145361075]
	TIME [epoch: 10.4 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3090848525041272		[learning rate: 3.9695e-05]
	Learning Rate: 3.96951e-05
	LOSS [training: 0.3090848525041272 | validation: 0.32825048492416226]
	TIME [epoch: 10.4 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012910779430168		[learning rate: 3.9551e-05]
	Learning Rate: 3.9551e-05
	LOSS [training: 0.3012910779430168 | validation: 0.33983757118072]
	TIME [epoch: 10.4 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166572934943867		[learning rate: 3.9408e-05]
	Learning Rate: 3.94075e-05
	LOSS [training: 0.3166572934943867 | validation: 0.3739614081420434]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29939492005398655		[learning rate: 3.9264e-05]
	Learning Rate: 3.92645e-05
	LOSS [training: 0.29939492005398655 | validation: 0.33038133053479557]
	TIME [epoch: 10.4 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30911780997569827		[learning rate: 3.9122e-05]
	Learning Rate: 3.9122e-05
	LOSS [training: 0.30911780997569827 | validation: 0.3427792652339058]
	TIME [epoch: 10.4 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30468593975459723		[learning rate: 3.898e-05]
	Learning Rate: 3.898e-05
	LOSS [training: 0.30468593975459723 | validation: 0.34454602877028934]
	TIME [epoch: 10.4 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3181871075044396		[learning rate: 3.8839e-05]
	Learning Rate: 3.88386e-05
	LOSS [training: 0.3181871075044396 | validation: 0.32191900548147107]
	TIME [epoch: 10.4 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3225731571002745		[learning rate: 3.8698e-05]
	Learning Rate: 3.86976e-05
	LOSS [training: 0.3225731571002745 | validation: 0.3681901003014375]
	TIME [epoch: 10.4 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3145538799395315		[learning rate: 3.8557e-05]
	Learning Rate: 3.85572e-05
	LOSS [training: 0.3145538799395315 | validation: 0.3694646260621703]
	TIME [epoch: 10.4 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341304950366827		[learning rate: 3.8417e-05]
	Learning Rate: 3.84173e-05
	LOSS [training: 0.3341304950366827 | validation: 0.321595034536457]
	TIME [epoch: 10.4 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32056483199959324		[learning rate: 3.8278e-05]
	Learning Rate: 3.82778e-05
	LOSS [training: 0.32056483199959324 | validation: 0.35676189175992934]
	TIME [epoch: 10.4 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31707033550172525		[learning rate: 3.8139e-05]
	Learning Rate: 3.81389e-05
	LOSS [training: 0.31707033550172525 | validation: 0.339166543374247]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32728595555519546		[learning rate: 3.8001e-05]
	Learning Rate: 3.80005e-05
	LOSS [training: 0.32728595555519546 | validation: 0.3168341825531175]
	TIME [epoch: 10.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30794078579629464		[learning rate: 3.7863e-05]
	Learning Rate: 3.78626e-05
	LOSS [training: 0.30794078579629464 | validation: 0.34310071099202377]
	TIME [epoch: 10.4 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31236105037717626		[learning rate: 3.7725e-05]
	Learning Rate: 3.77252e-05
	LOSS [training: 0.31236105037717626 | validation: 0.3573339858347389]
	TIME [epoch: 10.4 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32120246916742523		[learning rate: 3.7588e-05]
	Learning Rate: 3.75883e-05
	LOSS [training: 0.32120246916742523 | validation: 0.37663480726124826]
	TIME [epoch: 10.4 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29760575029957076		[learning rate: 3.7452e-05]
	Learning Rate: 3.74519e-05
	LOSS [training: 0.29760575029957076 | validation: 0.360123028250324]
	TIME [epoch: 10.4 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31058405254704247		[learning rate: 3.7316e-05]
	Learning Rate: 3.7316e-05
	LOSS [training: 0.31058405254704247 | validation: 0.32149322453894585]
	TIME [epoch: 10.4 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29632137464945374		[learning rate: 3.7181e-05]
	Learning Rate: 3.71805e-05
	LOSS [training: 0.29632137464945374 | validation: 0.3484594562541767]
	TIME [epoch: 10.4 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977806604397187		[learning rate: 3.7046e-05]
	Learning Rate: 3.70456e-05
	LOSS [training: 0.2977806604397187 | validation: 0.3426499486406911]
	TIME [epoch: 10.4 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31972206233129136		[learning rate: 3.6911e-05]
	Learning Rate: 3.69112e-05
	LOSS [training: 0.31972206233129136 | validation: 0.32922590126163004]
	TIME [epoch: 10.4 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32035480674491695		[learning rate: 3.6777e-05]
	Learning Rate: 3.67772e-05
	LOSS [training: 0.32035480674491695 | validation: 0.31929083348520226]
	TIME [epoch: 10.4 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32250104020258324		[learning rate: 3.6644e-05]
	Learning Rate: 3.66438e-05
	LOSS [training: 0.32250104020258324 | validation: 0.3380879754776157]
	TIME [epoch: 10.4 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31462628975576973		[learning rate: 3.6511e-05]
	Learning Rate: 3.65108e-05
	LOSS [training: 0.31462628975576973 | validation: 0.31340686671960166]
	TIME [epoch: 10.4 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30196032968940095		[learning rate: 3.6378e-05]
	Learning Rate: 3.63783e-05
	LOSS [training: 0.30196032968940095 | validation: 0.3244873456603834]
	TIME [epoch: 10.4 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3155047299744822		[learning rate: 3.6246e-05]
	Learning Rate: 3.62463e-05
	LOSS [training: 0.3155047299744822 | validation: 0.3453146254599273]
	TIME [epoch: 10.4 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144388280305803		[learning rate: 3.6115e-05]
	Learning Rate: 3.61147e-05
	LOSS [training: 0.3144388280305803 | validation: 0.35695169515104985]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.321855070996196		[learning rate: 3.5984e-05]
	Learning Rate: 3.59837e-05
	LOSS [training: 0.321855070996196 | validation: 0.33994794699627945]
	TIME [epoch: 10.4 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32012712503346474		[learning rate: 3.5853e-05]
	Learning Rate: 3.58531e-05
	LOSS [training: 0.32012712503346474 | validation: 0.3451039300888882]
	TIME [epoch: 10.4 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3181566561425641		[learning rate: 3.5723e-05]
	Learning Rate: 3.5723e-05
	LOSS [training: 0.3181566561425641 | validation: 0.3651420624158395]
	TIME [epoch: 10.4 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3106919371521163		[learning rate: 3.5593e-05]
	Learning Rate: 3.55933e-05
	LOSS [training: 0.3106919371521163 | validation: 0.33667167111783997]
	TIME [epoch: 10.4 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3198144300853113		[learning rate: 3.5464e-05]
	Learning Rate: 3.54641e-05
	LOSS [training: 0.3198144300853113 | validation: 0.3365379056859497]
	TIME [epoch: 10.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31681972464540953		[learning rate: 3.5335e-05]
	Learning Rate: 3.53354e-05
	LOSS [training: 0.31681972464540953 | validation: 0.32040426435049313]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3000700232874714		[learning rate: 3.5207e-05]
	Learning Rate: 3.52072e-05
	LOSS [training: 0.3000700232874714 | validation: 0.37967546629769794]
	TIME [epoch: 10.4 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108276239132976		[learning rate: 3.5079e-05]
	Learning Rate: 3.50794e-05
	LOSS [training: 0.3108276239132976 | validation: 0.398327596227755]
	TIME [epoch: 10.4 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30718605046947184		[learning rate: 3.4952e-05]
	Learning Rate: 3.49521e-05
	LOSS [training: 0.30718605046947184 | validation: 0.3241932281422298]
	TIME [epoch: 10.4 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156735699422863		[learning rate: 3.4825e-05]
	Learning Rate: 3.48253e-05
	LOSS [training: 0.3156735699422863 | validation: 0.31601810717571005]
	TIME [epoch: 10.4 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032416437674287		[learning rate: 3.4699e-05]
	Learning Rate: 3.46989e-05
	LOSS [training: 0.3032416437674287 | validation: 0.34445947163878726]
	TIME [epoch: 10.4 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29620392213699953		[learning rate: 3.4573e-05]
	Learning Rate: 3.4573e-05
	LOSS [training: 0.29620392213699953 | validation: 0.32205042203998036]
	TIME [epoch: 10.4 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32278627365579365		[learning rate: 3.4448e-05]
	Learning Rate: 3.44475e-05
	LOSS [training: 0.32278627365579365 | validation: 0.37091508203787543]
	TIME [epoch: 10.4 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075080250255472		[learning rate: 3.4323e-05]
	Learning Rate: 3.43225e-05
	LOSS [training: 0.3075080250255472 | validation: 0.3592898563968429]
	TIME [epoch: 10.4 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31366322377904926		[learning rate: 3.4198e-05]
	Learning Rate: 3.4198e-05
	LOSS [training: 0.31366322377904926 | validation: 0.3411528988604613]
	TIME [epoch: 10.4 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29390190355193324		[learning rate: 3.4074e-05]
	Learning Rate: 3.40738e-05
	LOSS [training: 0.29390190355193324 | validation: 0.338422884510305]
	TIME [epoch: 10.4 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3127981015297288		[learning rate: 3.395e-05]
	Learning Rate: 3.39502e-05
	LOSS [training: 0.3127981015297288 | validation: 0.32351867466105644]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3208015669661079		[learning rate: 3.3827e-05]
	Learning Rate: 3.3827e-05
	LOSS [training: 0.3208015669661079 | validation: 0.3323757110491695]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29744687558819816		[learning rate: 3.3704e-05]
	Learning Rate: 3.37042e-05
	LOSS [training: 0.29744687558819816 | validation: 0.22084832912309313]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r5_20240219_233648/states/model_tr_study205_1666.pth
	Model improved!!!
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31630613503156685		[learning rate: 3.3582e-05]
	Learning Rate: 3.35819e-05
	LOSS [training: 0.31630613503156685 | validation: 0.33834827300618275]
	TIME [epoch: 10.4 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3061381674456303		[learning rate: 3.346e-05]
	Learning Rate: 3.346e-05
	LOSS [training: 0.3061381674456303 | validation: 0.33632270978261836]
	TIME [epoch: 10.4 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3004327648506335		[learning rate: 3.3339e-05]
	Learning Rate: 3.33386e-05
	LOSS [training: 0.3004327648506335 | validation: 0.34674902272513836]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3061476214788684		[learning rate: 3.3218e-05]
	Learning Rate: 3.32176e-05
	LOSS [training: 0.3061476214788684 | validation: 0.3292995402830992]
	TIME [epoch: 10.4 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31574752664610034		[learning rate: 3.3097e-05]
	Learning Rate: 3.30971e-05
	LOSS [training: 0.31574752664610034 | validation: 0.3270084340478197]
	TIME [epoch: 10.4 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3104937804910777		[learning rate: 3.2977e-05]
	Learning Rate: 3.2977e-05
	LOSS [training: 0.3104937804910777 | validation: 0.3339395373233276]
	TIME [epoch: 10.4 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3158838433174833		[learning rate: 3.2857e-05]
	Learning Rate: 3.28573e-05
	LOSS [training: 0.3158838433174833 | validation: 0.3590196881448105]
	TIME [epoch: 10.4 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107285220164728		[learning rate: 3.2738e-05]
	Learning Rate: 3.2738e-05
	LOSS [training: 0.3107285220164728 | validation: 0.3238857602943596]
	TIME [epoch: 10.4 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30647441458479135		[learning rate: 3.2619e-05]
	Learning Rate: 3.26192e-05
	LOSS [training: 0.30647441458479135 | validation: 0.32693863374206034]
	TIME [epoch: 10.4 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3256927013598031		[learning rate: 3.2501e-05]
	Learning Rate: 3.25009e-05
	LOSS [training: 0.3256927013598031 | validation: 0.35635381503857533]
	TIME [epoch: 10.4 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30881157745274257		[learning rate: 3.2383e-05]
	Learning Rate: 3.23829e-05
	LOSS [training: 0.30881157745274257 | validation: 0.3349668863286329]
	TIME [epoch: 10.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111105172741661		[learning rate: 3.2265e-05]
	Learning Rate: 3.22654e-05
	LOSS [training: 0.3111105172741661 | validation: 0.38386822152515826]
	TIME [epoch: 10.4 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29997857838305997		[learning rate: 3.2148e-05]
	Learning Rate: 3.21483e-05
	LOSS [training: 0.29997857838305997 | validation: 0.3331148715798923]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3082319599750497		[learning rate: 3.2032e-05]
	Learning Rate: 3.20316e-05
	LOSS [training: 0.3082319599750497 | validation: 0.3279585016975747]
	TIME [epoch: 10.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32280934128344313		[learning rate: 3.1915e-05]
	Learning Rate: 3.19154e-05
	LOSS [training: 0.32280934128344313 | validation: 0.32172852416743275]
	TIME [epoch: 10.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037488142292808		[learning rate: 3.18e-05]
	Learning Rate: 3.17996e-05
	LOSS [training: 0.3037488142292808 | validation: 0.3717045402903144]
	TIME [epoch: 10.4 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31807605851641335		[learning rate: 3.1684e-05]
	Learning Rate: 3.16842e-05
	LOSS [training: 0.31807605851641335 | validation: 0.3349778575400748]
	TIME [epoch: 10.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30425771077995		[learning rate: 3.1569e-05]
	Learning Rate: 3.15692e-05
	LOSS [training: 0.30425771077995 | validation: 0.37737090013692604]
	TIME [epoch: 10.4 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30006147388663706		[learning rate: 3.1455e-05]
	Learning Rate: 3.14546e-05
	LOSS [training: 0.30006147388663706 | validation: 0.3382620418561006]
	TIME [epoch: 10.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3245349514893653		[learning rate: 3.134e-05]
	Learning Rate: 3.13405e-05
	LOSS [training: 0.3245349514893653 | validation: 0.3375798095060519]
	TIME [epoch: 10.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050359984342556		[learning rate: 3.1227e-05]
	Learning Rate: 3.12267e-05
	LOSS [training: 0.3050359984342556 | validation: 0.38455054556981433]
	TIME [epoch: 10.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29181697436028303		[learning rate: 3.1113e-05]
	Learning Rate: 3.11134e-05
	LOSS [training: 0.29181697436028303 | validation: 0.3163996323150465]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31361020839336057		[learning rate: 3.1e-05]
	Learning Rate: 3.10005e-05
	LOSS [training: 0.31361020839336057 | validation: 0.3660989022142276]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3086670849942246		[learning rate: 3.0888e-05]
	Learning Rate: 3.0888e-05
	LOSS [training: 0.3086670849942246 | validation: 0.33851463850089936]
	TIME [epoch: 10.4 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102833488230655		[learning rate: 3.0776e-05]
	Learning Rate: 3.07759e-05
	LOSS [training: 0.3102833488230655 | validation: 0.3378727916267317]
	TIME [epoch: 10.4 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3044277357328644		[learning rate: 3.0664e-05]
	Learning Rate: 3.06642e-05
	LOSS [training: 0.3044277357328644 | validation: 0.26931736098602826]
	TIME [epoch: 10.3 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3007957941293998		[learning rate: 3.0553e-05]
	Learning Rate: 3.05529e-05
	LOSS [training: 0.3007957941293998 | validation: 0.353564359669634]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113637549076139		[learning rate: 3.0442e-05]
	Learning Rate: 3.0442e-05
	LOSS [training: 0.3113637549076139 | validation: 0.354917140312802]
	TIME [epoch: 10.4 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30724125705599564		[learning rate: 3.0332e-05]
	Learning Rate: 3.03316e-05
	LOSS [training: 0.30724125705599564 | validation: 0.3290868628163933]
	TIME [epoch: 10.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977702885035176		[learning rate: 3.0221e-05]
	Learning Rate: 3.02215e-05
	LOSS [training: 0.2977702885035176 | validation: 0.33392418107454136]
	TIME [epoch: 10.3 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30770217585555815		[learning rate: 3.0112e-05]
	Learning Rate: 3.01118e-05
	LOSS [training: 0.30770217585555815 | validation: 0.3260792288744925]
	TIME [epoch: 10.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30127000860054515		[learning rate: 3.0003e-05]
	Learning Rate: 3.00025e-05
	LOSS [training: 0.30127000860054515 | validation: 0.3302056421133414]
	TIME [epoch: 10.4 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31160449352674735		[learning rate: 2.9894e-05]
	Learning Rate: 2.98936e-05
	LOSS [training: 0.31160449352674735 | validation: 0.33357047161684167]
	TIME [epoch: 10.4 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29888647557933923		[learning rate: 2.9785e-05]
	Learning Rate: 2.97852e-05
	LOSS [training: 0.29888647557933923 | validation: 0.3248248062534211]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3082375595045004		[learning rate: 2.9677e-05]
	Learning Rate: 2.96771e-05
	LOSS [training: 0.3082375595045004 | validation: 0.34227185240008196]
	TIME [epoch: 10.4 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31293239121704		[learning rate: 2.9569e-05]
	Learning Rate: 2.95694e-05
	LOSS [training: 0.31293239121704 | validation: 0.3341117026517525]
	TIME [epoch: 10.4 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30557865321671873		[learning rate: 2.9462e-05]
	Learning Rate: 2.94621e-05
	LOSS [training: 0.30557865321671873 | validation: 0.3468376260783667]
	TIME [epoch: 10.4 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105562750975185		[learning rate: 2.9355e-05]
	Learning Rate: 2.93551e-05
	LOSS [training: 0.3105562750975185 | validation: 0.33679708367734934]
	TIME [epoch: 10.4 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29637421868037905		[learning rate: 2.9249e-05]
	Learning Rate: 2.92486e-05
	LOSS [training: 0.29637421868037905 | validation: 0.34238346535258873]
	TIME [epoch: 10.4 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018563793609027		[learning rate: 2.9142e-05]
	Learning Rate: 2.91425e-05
	LOSS [training: 0.3018563793609027 | validation: 0.3743212850357408]
	TIME [epoch: 10.4 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30241190559515874		[learning rate: 2.9037e-05]
	Learning Rate: 2.90367e-05
	LOSS [training: 0.30241190559515874 | validation: 0.38450574011794286]
	TIME [epoch: 10.4 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30712941245685454		[learning rate: 2.8931e-05]
	Learning Rate: 2.89313e-05
	LOSS [training: 0.30712941245685454 | validation: 0.3662663952487679]
	TIME [epoch: 10.4 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30987158891201316		[learning rate: 2.8826e-05]
	Learning Rate: 2.88263e-05
	LOSS [training: 0.30987158891201316 | validation: 0.3580488508094251]
	TIME [epoch: 10.4 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052657178759662		[learning rate: 2.8722e-05]
	Learning Rate: 2.87217e-05
	LOSS [training: 0.3052657178759662 | validation: 0.33816492479005517]
	TIME [epoch: 10.4 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30884749550804685		[learning rate: 2.8617e-05]
	Learning Rate: 2.86175e-05
	LOSS [training: 0.30884749550804685 | validation: 0.37942190516838076]
	TIME [epoch: 10.4 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2938533711764191		[learning rate: 2.8514e-05]
	Learning Rate: 2.85136e-05
	LOSS [training: 0.2938533711764191 | validation: 0.35200188765916174]
	TIME [epoch: 10.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3117463947968616		[learning rate: 2.841e-05]
	Learning Rate: 2.84102e-05
	LOSS [training: 0.3117463947968616 | validation: 0.3576516260607673]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31362262359254867		[learning rate: 2.8307e-05]
	Learning Rate: 2.83071e-05
	LOSS [training: 0.31362262359254867 | validation: 0.34459049649783363]
	TIME [epoch: 10.4 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30883998451521494		[learning rate: 2.8204e-05]
	Learning Rate: 2.82043e-05
	LOSS [training: 0.30883998451521494 | validation: 0.34468914526960526]
	TIME [epoch: 10.4 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30505392961137134		[learning rate: 2.8102e-05]
	Learning Rate: 2.8102e-05
	LOSS [training: 0.30505392961137134 | validation: 0.33905608870756465]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30736667334002143		[learning rate: 2.8e-05]
	Learning Rate: 2.8e-05
	LOSS [training: 0.30736667334002143 | validation: 0.3283844705491938]
	TIME [epoch: 10.4 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054897616933977		[learning rate: 2.7898e-05]
	Learning Rate: 2.78984e-05
	LOSS [training: 0.3054897616933977 | validation: 0.3276156428872227]
	TIME [epoch: 10.4 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30615293941827737		[learning rate: 2.7797e-05]
	Learning Rate: 2.77971e-05
	LOSS [training: 0.30615293941827737 | validation: 0.3167712083487265]
	TIME [epoch: 10.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3251274027012098		[learning rate: 2.7696e-05]
	Learning Rate: 2.76963e-05
	LOSS [training: 0.3251274027012098 | validation: 0.3381873725340032]
	TIME [epoch: 10.4 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3030349119620039		[learning rate: 2.7596e-05]
	Learning Rate: 2.75957e-05
	LOSS [training: 0.3030349119620039 | validation: 0.32905943876299165]
	TIME [epoch: 10.4 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31109415038476496		[learning rate: 2.7496e-05]
	Learning Rate: 2.74956e-05
	LOSS [training: 0.31109415038476496 | validation: 0.30990141536553883]
	TIME [epoch: 10.4 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967287936664297		[learning rate: 2.7396e-05]
	Learning Rate: 2.73958e-05
	LOSS [training: 0.2967287936664297 | validation: 0.341265396794023]
	TIME [epoch: 10.4 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3345323234377764		[learning rate: 2.7296e-05]
	Learning Rate: 2.72964e-05
	LOSS [training: 0.3345323234377764 | validation: 0.32728949810714014]
	TIME [epoch: 10.4 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142649115615146		[learning rate: 2.7197e-05]
	Learning Rate: 2.71973e-05
	LOSS [training: 0.3142649115615146 | validation: 0.32234090540277555]
	TIME [epoch: 10.4 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30105467711815914		[learning rate: 2.7099e-05]
	Learning Rate: 2.70986e-05
	LOSS [training: 0.30105467711815914 | validation: 0.3309719169291552]
	TIME [epoch: 10.4 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2984470533045463		[learning rate: 2.7e-05]
	Learning Rate: 2.70003e-05
	LOSS [training: 0.2984470533045463 | validation: 0.3281464239107561]
	TIME [epoch: 10.4 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32306206998499715		[learning rate: 2.6902e-05]
	Learning Rate: 2.69023e-05
	LOSS [training: 0.32306206998499715 | validation: 0.33035540058829227]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2992235835763386		[learning rate: 2.6805e-05]
	Learning Rate: 2.68047e-05
	LOSS [training: 0.2992235835763386 | validation: 0.33586143516826383]
	TIME [epoch: 10.4 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31669184357493874		[learning rate: 2.6707e-05]
	Learning Rate: 2.67074e-05
	LOSS [training: 0.31669184357493874 | validation: 0.33812210360453315]
	TIME [epoch: 10.4 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134427847158709		[learning rate: 2.661e-05]
	Learning Rate: 2.66105e-05
	LOSS [training: 0.3134427847158709 | validation: 0.34154723558877337]
	TIME [epoch: 10.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3055999832752218		[learning rate: 2.6514e-05]
	Learning Rate: 2.65139e-05
	LOSS [training: 0.3055999832752218 | validation: 0.3339797232537051]
	TIME [epoch: 10.4 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31239384740225756		[learning rate: 2.6418e-05]
	Learning Rate: 2.64177e-05
	LOSS [training: 0.31239384740225756 | validation: 0.3295957883259243]
	TIME [epoch: 10.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3038556122085956		[learning rate: 2.6322e-05]
	Learning Rate: 2.63218e-05
	LOSS [training: 0.3038556122085956 | validation: 0.37274409396240143]
	TIME [epoch: 10.4 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30630421187425494		[learning rate: 2.6226e-05]
	Learning Rate: 2.62263e-05
	LOSS [training: 0.30630421187425494 | validation: 0.32471048493249877]
	TIME [epoch: 10.4 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088720651416278		[learning rate: 2.6131e-05]
	Learning Rate: 2.61311e-05
	LOSS [training: 0.3088720651416278 | validation: 0.33925982048055914]
	TIME [epoch: 10.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31028028703707045		[learning rate: 2.6036e-05]
	Learning Rate: 2.60363e-05
	LOSS [training: 0.31028028703707045 | validation: 0.3361569433482803]
	TIME [epoch: 10.4 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961220308732054		[learning rate: 2.5942e-05]
	Learning Rate: 2.59418e-05
	LOSS [training: 0.2961220308732054 | validation: 0.3531508099073156]
	TIME [epoch: 10.4 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3215933685417854		[learning rate: 2.5848e-05]
	Learning Rate: 2.58477e-05
	LOSS [training: 0.3215933685417854 | validation: 0.36054774206569845]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977825803086958		[learning rate: 2.5754e-05]
	Learning Rate: 2.57539e-05
	LOSS [training: 0.2977825803086958 | validation: 0.36134431813895995]
	TIME [epoch: 10.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920639436976661		[learning rate: 2.566e-05]
	Learning Rate: 2.56604e-05
	LOSS [training: 0.2920639436976661 | validation: 0.34578140978911603]
	TIME [epoch: 10.4 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3029405391491108		[learning rate: 2.5567e-05]
	Learning Rate: 2.55673e-05
	LOSS [training: 0.3029405391491108 | validation: 0.36698221812932375]
	TIME [epoch: 10.4 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147198324093319		[learning rate: 2.5474e-05]
	Learning Rate: 2.54745e-05
	LOSS [training: 0.3147198324093319 | validation: 0.3386063292088426]
	TIME [epoch: 10.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088317550409078		[learning rate: 2.5382e-05]
	Learning Rate: 2.5382e-05
	LOSS [training: 0.3088317550409078 | validation: 0.32920433257603265]
	TIME [epoch: 10.4 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3045627975301794		[learning rate: 2.529e-05]
	Learning Rate: 2.52899e-05
	LOSS [training: 0.3045627975301794 | validation: 0.34458804596950415]
	TIME [epoch: 10.4 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3094782691401509		[learning rate: 2.5198e-05]
	Learning Rate: 2.51981e-05
	LOSS [training: 0.3094782691401509 | validation: 0.3331260928744456]
	TIME [epoch: 10.4 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31626233881406646		[learning rate: 2.5107e-05]
	Learning Rate: 2.51067e-05
	LOSS [training: 0.31626233881406646 | validation: 0.36931200154235755]
	TIME [epoch: 10.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042296515769102		[learning rate: 2.5016e-05]
	Learning Rate: 2.50156e-05
	LOSS [training: 0.3042296515769102 | validation: 0.32015893102549003]
	TIME [epoch: 10.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3062916524974775		[learning rate: 2.4925e-05]
	Learning Rate: 2.49248e-05
	LOSS [training: 0.3062916524974775 | validation: 0.2628440704600717]
	TIME [epoch: 10.4 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31408364364281854		[learning rate: 2.4834e-05]
	Learning Rate: 2.48343e-05
	LOSS [training: 0.31408364364281854 | validation: 0.3489798479721406]
	TIME [epoch: 10.4 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30254775184791177		[learning rate: 2.4744e-05]
	Learning Rate: 2.47442e-05
	LOSS [training: 0.30254775184791177 | validation: 0.34798453272908414]
	TIME [epoch: 10.4 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2939882456746099		[learning rate: 2.4654e-05]
	Learning Rate: 2.46544e-05
	LOSS [training: 0.2939882456746099 | validation: 0.3215479642961035]
	TIME [epoch: 10.4 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107335930904934		[learning rate: 2.4565e-05]
	Learning Rate: 2.45649e-05
	LOSS [training: 0.3107335930904934 | validation: 0.3224137933836718]
	TIME [epoch: 10.4 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30123113404845975		[learning rate: 2.4476e-05]
	Learning Rate: 2.44758e-05
	LOSS [training: 0.30123113404845975 | validation: 0.355909028123741]
	TIME [epoch: 10.4 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3049438529703416		[learning rate: 2.4387e-05]
	Learning Rate: 2.4387e-05
	LOSS [training: 0.3049438529703416 | validation: 0.34226004370695506]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.314617075552295		[learning rate: 2.4298e-05]
	Learning Rate: 2.42985e-05
	LOSS [training: 0.314617075552295 | validation: 0.3320028356011897]
	TIME [epoch: 10.4 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3006206640871934		[learning rate: 2.421e-05]
	Learning Rate: 2.42103e-05
	LOSS [training: 0.3006206640871934 | validation: 0.326515447064111]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064463479587333		[learning rate: 2.4122e-05]
	Learning Rate: 2.41224e-05
	LOSS [training: 0.3064463479587333 | validation: 0.3648780110743536]
	TIME [epoch: 10.4 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3113294695043927		[learning rate: 2.4035e-05]
	Learning Rate: 2.40349e-05
	LOSS [training: 0.3113294695043927 | validation: 0.31218733402446447]
	TIME [epoch: 10.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084265178830544		[learning rate: 2.3948e-05]
	Learning Rate: 2.39477e-05
	LOSS [training: 0.3084265178830544 | validation: 0.3419956876876668]
	TIME [epoch: 10.4 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29686037498559276		[learning rate: 2.3861e-05]
	Learning Rate: 2.38608e-05
	LOSS [training: 0.29686037498559276 | validation: 0.3368482714373791]
	TIME [epoch: 10.3 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2989570800141427		[learning rate: 2.3774e-05]
	Learning Rate: 2.37742e-05
	LOSS [training: 0.2989570800141427 | validation: 0.36068440646692984]
	TIME [epoch: 10.4 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30521049885230755		[learning rate: 2.3688e-05]
	Learning Rate: 2.36879e-05
	LOSS [training: 0.30521049885230755 | validation: 0.3217797536942316]
	TIME [epoch: 10.4 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30563948040857086		[learning rate: 2.3602e-05]
	Learning Rate: 2.36019e-05
	LOSS [training: 0.30563948040857086 | validation: 0.3680072010326812]
	TIME [epoch: 10.4 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088675813359817		[learning rate: 2.3516e-05]
	Learning Rate: 2.35163e-05
	LOSS [training: 0.3088675813359817 | validation: 0.3636017683987895]
	TIME [epoch: 10.4 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29594550459572566		[learning rate: 2.3431e-05]
	Learning Rate: 2.34309e-05
	LOSS [training: 0.29594550459572566 | validation: 0.35011784399776363]
	TIME [epoch: 10.4 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124858250220398		[learning rate: 2.3346e-05]
	Learning Rate: 2.33459e-05
	LOSS [training: 0.3124858250220398 | validation: 0.34046456902248273]
	TIME [epoch: 10.4 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30170228484404227		[learning rate: 2.3261e-05]
	Learning Rate: 2.32612e-05
	LOSS [training: 0.30170228484404227 | validation: 0.35823144652836797]
	TIME [epoch: 10.4 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32198214569670014		[learning rate: 2.3177e-05]
	Learning Rate: 2.31768e-05
	LOSS [training: 0.32198214569670014 | validation: 0.34812192076540316]
	TIME [epoch: 10.4 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30959190371267814		[learning rate: 2.3093e-05]
	Learning Rate: 2.30926e-05
	LOSS [training: 0.30959190371267814 | validation: 0.35442982427948744]
	TIME [epoch: 10.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31738729546758276		[learning rate: 2.3009e-05]
	Learning Rate: 2.30088e-05
	LOSS [training: 0.31738729546758276 | validation: 0.33115788360496523]
	TIME [epoch: 10.4 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013596012130344		[learning rate: 2.2925e-05]
	Learning Rate: 2.29253e-05
	LOSS [training: 0.3013596012130344 | validation: 0.3585181961693197]
	TIME [epoch: 10.4 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30318985404519		[learning rate: 2.2842e-05]
	Learning Rate: 2.28421e-05
	LOSS [training: 0.30318985404519 | validation: 0.32390253237163896]
	TIME [epoch: 10.4 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3011660081963677		[learning rate: 2.2759e-05]
	Learning Rate: 2.27592e-05
	LOSS [training: 0.3011660081963677 | validation: 0.3300805564913466]
	TIME [epoch: 10.4 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31454110220779224		[learning rate: 2.2677e-05]
	Learning Rate: 2.26767e-05
	LOSS [training: 0.31454110220779224 | validation: 0.36530907616597624]
	TIME [epoch: 10.4 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079214389954452		[learning rate: 2.2594e-05]
	Learning Rate: 2.25944e-05
	LOSS [training: 0.3079214389954452 | validation: 0.36215356349747846]
	TIME [epoch: 10.4 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3099843917160048		[learning rate: 2.2512e-05]
	Learning Rate: 2.25124e-05
	LOSS [training: 0.3099843917160048 | validation: 0.33040233968349475]
	TIME [epoch: 10.4 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3180267308674521		[learning rate: 2.2431e-05]
	Learning Rate: 2.24307e-05
	LOSS [training: 0.3180267308674521 | validation: 0.32108560907960737]
	TIME [epoch: 10.4 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33312796186841115		[learning rate: 2.2349e-05]
	Learning Rate: 2.23493e-05
	LOSS [training: 0.33312796186841115 | validation: 0.3290502013103409]
	TIME [epoch: 10.4 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3057070179637894		[learning rate: 2.2268e-05]
	Learning Rate: 2.22682e-05
	LOSS [training: 0.3057070179637894 | validation: 0.3416637486104123]
	TIME [epoch: 10.4 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29911396787917244		[learning rate: 2.2187e-05]
	Learning Rate: 2.21873e-05
	LOSS [training: 0.29911396787917244 | validation: 0.3363612092006155]
	TIME [epoch: 10.4 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29775541937178834		[learning rate: 2.2107e-05]
	Learning Rate: 2.21068e-05
	LOSS [training: 0.29775541937178834 | validation: 0.23259137242288286]
	TIME [epoch: 10.4 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077085202841213		[learning rate: 2.2027e-05]
	Learning Rate: 2.20266e-05
	LOSS [training: 0.3077085202841213 | validation: 0.3295525191811302]
	TIME [epoch: 10.4 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30482041860455567		[learning rate: 2.1947e-05]
	Learning Rate: 2.19467e-05
	LOSS [training: 0.30482041860455567 | validation: 0.3550773143402839]
	TIME [epoch: 10.4 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30766697137176574		[learning rate: 2.1867e-05]
	Learning Rate: 2.1867e-05
	LOSS [training: 0.30766697137176574 | validation: 0.31688320850745444]
	TIME [epoch: 10.4 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2998326862521234		[learning rate: 2.1788e-05]
	Learning Rate: 2.17877e-05
	LOSS [training: 0.2998326862521234 | validation: 0.33016715033027766]
	TIME [epoch: 10.4 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2966623182895288		[learning rate: 2.1709e-05]
	Learning Rate: 2.17086e-05
	LOSS [training: 0.2966623182895288 | validation: 0.3345719456786949]
	TIME [epoch: 10.4 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3004375762296917		[learning rate: 2.163e-05]
	Learning Rate: 2.16298e-05
	LOSS [training: 0.3004375762296917 | validation: 0.3327950160772678]
	TIME [epoch: 10.4 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30983140505678		[learning rate: 2.1551e-05]
	Learning Rate: 2.15513e-05
	LOSS [training: 0.30983140505678 | validation: 0.3220268028637323]
	TIME [epoch: 10.4 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131375134658419		[learning rate: 2.1473e-05]
	Learning Rate: 2.14731e-05
	LOSS [training: 0.3131375134658419 | validation: 0.323227383759675]
	TIME [epoch: 10.4 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30823749411083545		[learning rate: 2.1395e-05]
	Learning Rate: 2.13952e-05
	LOSS [training: 0.30823749411083545 | validation: 0.3356825996442491]
	TIME [epoch: 10.4 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3080247024629984		[learning rate: 2.1318e-05]
	Learning Rate: 2.13175e-05
	LOSS [training: 0.3080247024629984 | validation: 0.33321850574582174]
	TIME [epoch: 10.4 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32022575979277823		[learning rate: 2.124e-05]
	Learning Rate: 2.12402e-05
	LOSS [training: 0.32022575979277823 | validation: 0.325366417016415]
	TIME [epoch: 10.4 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041831016225453		[learning rate: 2.1163e-05]
	Learning Rate: 2.11631e-05
	LOSS [training: 0.3041831016225453 | validation: 0.3464354686721764]
	TIME [epoch: 10.4 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30676088336346663		[learning rate: 2.1086e-05]
	Learning Rate: 2.10863e-05
	LOSS [training: 0.30676088336346663 | validation: 0.32078271821126103]
	TIME [epoch: 10.4 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3057232588282176		[learning rate: 2.101e-05]
	Learning Rate: 2.10098e-05
	LOSS [training: 0.3057232588282176 | validation: 0.3174868380016413]
	TIME [epoch: 10.4 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30389974585118606		[learning rate: 2.0934e-05]
	Learning Rate: 2.09335e-05
	LOSS [training: 0.30389974585118606 | validation: 0.33987269631140576]
	TIME [epoch: 10.4 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3081359862119667		[learning rate: 2.0858e-05]
	Learning Rate: 2.08575e-05
	LOSS [training: 0.3081359862119667 | validation: 0.34874268467802566]
	TIME [epoch: 10.4 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3015067927604828		[learning rate: 2.0782e-05]
	Learning Rate: 2.07819e-05
	LOSS [training: 0.3015067927604828 | validation: 0.32475875075893984]
	TIME [epoch: 10.4 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308284449158911		[learning rate: 2.0706e-05]
	Learning Rate: 2.07064e-05
	LOSS [training: 0.308284449158911 | validation: 0.3279550786723054]
	TIME [epoch: 10.4 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2938773459267459		[learning rate: 2.0631e-05]
	Learning Rate: 2.06313e-05
	LOSS [training: 0.2938773459267459 | validation: 0.36183066210549947]
	TIME [epoch: 10.4 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957648429913022		[learning rate: 2.0556e-05]
	Learning Rate: 2.05564e-05
	LOSS [training: 0.2957648429913022 | validation: 0.3312232401455512]
	TIME [epoch: 10.4 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30236905585435825		[learning rate: 2.0482e-05]
	Learning Rate: 2.04818e-05
	LOSS [training: 0.30236905585435825 | validation: 0.32814822213530465]
	TIME [epoch: 10.4 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2981266103446499		[learning rate: 2.0407e-05]
	Learning Rate: 2.04075e-05
	LOSS [training: 0.2981266103446499 | validation: 0.3421577319243299]
	TIME [epoch: 10.4 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31314626030152004		[learning rate: 2.0333e-05]
	Learning Rate: 2.03334e-05
	LOSS [training: 0.31314626030152004 | validation: 0.35395058577056754]
	TIME [epoch: 10.4 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3165974726174491		[learning rate: 2.026e-05]
	Learning Rate: 2.02596e-05
	LOSS [training: 0.3165974726174491 | validation: 0.3694111472458672]
	TIME [epoch: 10.4 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063354110047914		[learning rate: 2.0186e-05]
	Learning Rate: 2.01861e-05
	LOSS [training: 0.3063354110047914 | validation: 0.3555961718411417]
	TIME [epoch: 10.4 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3175486577457664		[learning rate: 2.0113e-05]
	Learning Rate: 2.01129e-05
	LOSS [training: 0.3175486577457664 | validation: 0.32496768969757206]
	TIME [epoch: 10.4 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29913008151194337		[learning rate: 2.004e-05]
	Learning Rate: 2.00399e-05
	LOSS [training: 0.29913008151194337 | validation: 0.3229270197274165]
	TIME [epoch: 10.4 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30983827229495514		[learning rate: 1.9967e-05]
	Learning Rate: 1.99671e-05
	LOSS [training: 0.30983827229495514 | validation: 0.33523093223586226]
	TIME [epoch: 10.4 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965935028285405		[learning rate: 1.9895e-05]
	Learning Rate: 1.98947e-05
	LOSS [training: 0.2965935028285405 | validation: 0.3643995101559827]
	TIME [epoch: 10.4 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30587065668699476		[learning rate: 1.9822e-05]
	Learning Rate: 1.98225e-05
	LOSS [training: 0.30587065668699476 | validation: 0.3570169412032251]
	TIME [epoch: 10.4 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020517790279118		[learning rate: 1.9751e-05]
	Learning Rate: 1.97505e-05
	LOSS [training: 0.3020517790279118 | validation: 0.3236651623365978]
	TIME [epoch: 10.4 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31140154302144		[learning rate: 1.9679e-05]
	Learning Rate: 1.96789e-05
	LOSS [training: 0.31140154302144 | validation: 0.3308106897058275]
	TIME [epoch: 10.4 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29552815831772994		[learning rate: 1.9607e-05]
	Learning Rate: 1.96074e-05
	LOSS [training: 0.29552815831772994 | validation: 0.3333516780605267]
	TIME [epoch: 10.4 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3125088545246494		[learning rate: 1.9536e-05]
	Learning Rate: 1.95363e-05
	LOSS [training: 0.3125088545246494 | validation: 0.3783670633200256]
	TIME [epoch: 10.4 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29865476499299176		[learning rate: 1.9465e-05]
	Learning Rate: 1.94654e-05
	LOSS [training: 0.29865476499299176 | validation: 0.36245501848800993]
	TIME [epoch: 10.4 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152584199044348		[learning rate: 1.9395e-05]
	Learning Rate: 1.93948e-05
	LOSS [training: 0.3152584199044348 | validation: 0.34372234320785255]
	TIME [epoch: 10.4 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31446488478515433		[learning rate: 1.9324e-05]
	Learning Rate: 1.93244e-05
	LOSS [training: 0.31446488478515433 | validation: 0.3370516814911014]
	TIME [epoch: 10.4 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3007114329225632		[learning rate: 1.9254e-05]
	Learning Rate: 1.92542e-05
	LOSS [training: 0.3007114329225632 | validation: 0.3398327779870982]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020902783537438		[learning rate: 1.9184e-05]
	Learning Rate: 1.91844e-05
	LOSS [training: 0.3020902783537438 | validation: 0.33275934014607994]
	TIME [epoch: 10.4 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30568129076218237		[learning rate: 1.9115e-05]
	Learning Rate: 1.91147e-05
	LOSS [training: 0.30568129076218237 | validation: 0.3197465068852598]
	TIME [epoch: 10.4 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2994030854301385		[learning rate: 1.9045e-05]
	Learning Rate: 1.90454e-05
	LOSS [training: 0.2994030854301385 | validation: 0.3277303596175063]
	TIME [epoch: 10.4 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3024492380199658		[learning rate: 1.8976e-05]
	Learning Rate: 1.89763e-05
	LOSS [training: 0.3024492380199658 | validation: 0.31934722405048815]
	TIME [epoch: 10.4 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30675545063061105		[learning rate: 1.8907e-05]
	Learning Rate: 1.89074e-05
	LOSS [training: 0.30675545063061105 | validation: 0.3325867647582211]
	TIME [epoch: 10.4 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3053972429385188		[learning rate: 1.8839e-05]
	Learning Rate: 1.88388e-05
	LOSS [training: 0.3053972429385188 | validation: 0.32061026006589444]
	TIME [epoch: 10.4 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30087666354427933		[learning rate: 1.877e-05]
	Learning Rate: 1.87704e-05
	LOSS [training: 0.30087666354427933 | validation: 0.32100668781044467]
	TIME [epoch: 10.4 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2980191606278363		[learning rate: 1.8702e-05]
	Learning Rate: 1.87023e-05
	LOSS [training: 0.2980191606278363 | validation: 0.31820204200659646]
	TIME [epoch: 10.4 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30762989310399635		[learning rate: 1.8634e-05]
	Learning Rate: 1.86344e-05
	LOSS [training: 0.30762989310399635 | validation: 0.3322247495168361]
	TIME [epoch: 10.4 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.310405464978848		[learning rate: 1.8567e-05]
	Learning Rate: 1.85668e-05
	LOSS [training: 0.310405464978848 | validation: 0.3312985161370074]
	TIME [epoch: 10.4 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2918438429694453		[learning rate: 1.8499e-05]
	Learning Rate: 1.84994e-05
	LOSS [training: 0.2918438429694453 | validation: 0.35182693326015274]
	TIME [epoch: 10.4 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2978597359144927		[learning rate: 1.8432e-05]
	Learning Rate: 1.84323e-05
	LOSS [training: 0.2978597359144927 | validation: 0.37799462077567425]
	TIME [epoch: 10.4 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29442581691888925		[learning rate: 1.8365e-05]
	Learning Rate: 1.83654e-05
	LOSS [training: 0.29442581691888925 | validation: 0.324561531947516]
	TIME [epoch: 10.4 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3011818775986486		[learning rate: 1.8299e-05]
	Learning Rate: 1.82987e-05
	LOSS [training: 0.3011818775986486 | validation: 0.36161278633316146]
	TIME [epoch: 10.4 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3140546058154442		[learning rate: 1.8232e-05]
	Learning Rate: 1.82323e-05
	LOSS [training: 0.3140546058154442 | validation: 0.32838250640127215]
	TIME [epoch: 10.4 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29978619683540647		[learning rate: 1.8166e-05]
	Learning Rate: 1.81662e-05
	LOSS [training: 0.29978619683540647 | validation: 0.3215010695216154]
	TIME [epoch: 10.4 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31033547678738005		[learning rate: 1.81e-05]
	Learning Rate: 1.81002e-05
	LOSS [training: 0.31033547678738005 | validation: 0.32004831775804954]
	TIME [epoch: 10.4 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30407325325381895		[learning rate: 1.8035e-05]
	Learning Rate: 1.80346e-05
	LOSS [training: 0.30407325325381895 | validation: 0.3168598860207551]
	TIME [epoch: 10.4 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29031355581368923		[learning rate: 1.7969e-05]
	Learning Rate: 1.79691e-05
	LOSS [training: 0.29031355581368923 | validation: 0.3318637311629632]
	TIME [epoch: 10.4 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30879123189964286		[learning rate: 1.7904e-05]
	Learning Rate: 1.79039e-05
	LOSS [training: 0.30879123189964286 | validation: 0.325253091382567]
	TIME [epoch: 10.4 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31387922325418455		[learning rate: 1.7839e-05]
	Learning Rate: 1.78389e-05
	LOSS [training: 0.31387922325418455 | validation: 0.348648721513966]
	TIME [epoch: 10.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059757838908532		[learning rate: 1.7774e-05]
	Learning Rate: 1.77742e-05
	LOSS [training: 0.3059757838908532 | validation: 0.3451287410761654]
	TIME [epoch: 10.4 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31129787204007464		[learning rate: 1.771e-05]
	Learning Rate: 1.77097e-05
	LOSS [training: 0.31129787204007464 | validation: 0.34418954693484766]
	TIME [epoch: 10.4 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30609922253384253		[learning rate: 1.7645e-05]
	Learning Rate: 1.76454e-05
	LOSS [training: 0.30609922253384253 | validation: 0.2367016182032363]
	TIME [epoch: 10.4 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982510631276609		[learning rate: 1.7581e-05]
	Learning Rate: 1.75814e-05
	LOSS [training: 0.2982510631276609 | validation: 0.3649437760408996]
	TIME [epoch: 10.4 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2977905238488227		[learning rate: 1.7518e-05]
	Learning Rate: 1.75176e-05
	LOSS [training: 0.2977905238488227 | validation: 0.3542390528536937]
	TIME [epoch: 10.4 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31428065521510073		[learning rate: 1.7454e-05]
	Learning Rate: 1.7454e-05
	LOSS [training: 0.31428065521510073 | validation: 0.27119293279623746]
	TIME [epoch: 10.4 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30172241200939226		[learning rate: 1.7391e-05]
	Learning Rate: 1.73907e-05
	LOSS [training: 0.30172241200939226 | validation: 0.33042773735676906]
	TIME [epoch: 10.4 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30851823791808025		[learning rate: 1.7328e-05]
	Learning Rate: 1.73275e-05
	LOSS [training: 0.30851823791808025 | validation: 0.33082889922703135]
	TIME [epoch: 10.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031294163549958		[learning rate: 1.7265e-05]
	Learning Rate: 1.72647e-05
	LOSS [training: 0.3031294163549958 | validation: 0.33073512349574474]
	TIME [epoch: 10.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29777590439547735		[learning rate: 1.7202e-05]
	Learning Rate: 1.7202e-05
	LOSS [training: 0.29777590439547735 | validation: 0.3137885278488208]
	TIME [epoch: 10.4 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3033860851183072		[learning rate: 1.714e-05]
	Learning Rate: 1.71396e-05
	LOSS [training: 0.3033860851183072 | validation: 0.3404582281971409]
	TIME [epoch: 10.4 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076522143940479		[learning rate: 1.7077e-05]
	Learning Rate: 1.70774e-05
	LOSS [training: 0.3076522143940479 | validation: 0.33971328688293084]
	TIME [epoch: 10.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30862366355242477		[learning rate: 1.7015e-05]
	Learning Rate: 1.70154e-05
	LOSS [training: 0.30862366355242477 | validation: 0.3270057785396563]
	TIME [epoch: 10.4 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077229086239913		[learning rate: 1.6954e-05]
	Learning Rate: 1.69537e-05
	LOSS [training: 0.3077229086239913 | validation: 0.3553674810791322]
	TIME [epoch: 10.4 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075665560758004		[learning rate: 1.6892e-05]
	Learning Rate: 1.68921e-05
	LOSS [training: 0.3075665560758004 | validation: 0.3364106622325658]
	TIME [epoch: 10.4 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3034449143164159		[learning rate: 1.6831e-05]
	Learning Rate: 1.68308e-05
	LOSS [training: 0.3034449143164159 | validation: 0.3527413678379132]
	TIME [epoch: 10.4 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31423380555686253		[learning rate: 1.677e-05]
	Learning Rate: 1.67697e-05
	LOSS [training: 0.31423380555686253 | validation: 0.34677042219971915]
	TIME [epoch: 10.4 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30889149297777196		[learning rate: 1.6709e-05]
	Learning Rate: 1.67089e-05
	LOSS [training: 0.30889149297777196 | validation: 0.3268502831024393]
	TIME [epoch: 10.4 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29216984133714435		[learning rate: 1.6648e-05]
	Learning Rate: 1.66482e-05
	LOSS [training: 0.29216984133714435 | validation: 0.30828393785573555]
	TIME [epoch: 10.3 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32848116937241634		[learning rate: 1.6588e-05]
	Learning Rate: 1.65878e-05
	LOSS [training: 0.32848116937241634 | validation: 0.243735826137628]
	TIME [epoch: 10.4 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30571145362916946		[learning rate: 1.6528e-05]
	Learning Rate: 1.65276e-05
	LOSS [training: 0.30571145362916946 | validation: 0.32408502267383443]
	TIME [epoch: 10.4 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3272400382161901		[learning rate: 1.6468e-05]
	Learning Rate: 1.64677e-05
	LOSS [training: 0.3272400382161901 | validation: 0.35648531570219993]
	TIME [epoch: 10.4 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30818932026481194		[learning rate: 1.6408e-05]
	Learning Rate: 1.64079e-05
	LOSS [training: 0.30818932026481194 | validation: 0.3258109134997349]
	TIME [epoch: 10.4 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.301449481487007		[learning rate: 1.6348e-05]
	Learning Rate: 1.63483e-05
	LOSS [training: 0.301449481487007 | validation: 0.3208538688229557]
	TIME [epoch: 10.4 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156089573932762		[learning rate: 1.6289e-05]
	Learning Rate: 1.6289e-05
	LOSS [training: 0.3156089573932762 | validation: 0.35270059764934547]
	TIME [epoch: 10.4 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152343448612488		[learning rate: 1.623e-05]
	Learning Rate: 1.62299e-05
	LOSS [training: 0.3152343448612488 | validation: 0.31346698257592487]
	TIME [epoch: 10.4 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3187491640174199		[learning rate: 1.6171e-05]
	Learning Rate: 1.6171e-05
	LOSS [training: 0.3187491640174199 | validation: 0.36512099805228504]
	TIME [epoch: 10.4 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3193001785715692		[learning rate: 1.6112e-05]
	Learning Rate: 1.61123e-05
	LOSS [training: 0.3193001785715692 | validation: 0.3126229824703246]
	TIME [epoch: 10.4 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29032534232429824		[learning rate: 1.6054e-05]
	Learning Rate: 1.60538e-05
	LOSS [training: 0.29032534232429824 | validation: 0.3211289955654188]
	TIME [epoch: 10.4 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3006975186396398		[learning rate: 1.5996e-05]
	Learning Rate: 1.59956e-05
	LOSS [training: 0.3006975186396398 | validation: 0.3428896952412187]
	TIME [epoch: 10.4 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138141787197085		[learning rate: 1.5938e-05]
	Learning Rate: 1.59375e-05
	LOSS [training: 0.3138141787197085 | validation: 0.31817355140542336]
	TIME [epoch: 10.4 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3085713062758545		[learning rate: 1.588e-05]
	Learning Rate: 1.58797e-05
	LOSS [training: 0.3085713062758545 | validation: 0.3238660752250562]
	TIME [epoch: 10.4 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2986217080946288		[learning rate: 1.5822e-05]
	Learning Rate: 1.58221e-05
	LOSS [training: 0.2986217080946288 | validation: 0.33178764605773664]
	TIME [epoch: 10.4 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3116621272765931		[learning rate: 1.5765e-05]
	Learning Rate: 1.57647e-05
	LOSS [training: 0.3116621272765931 | validation: 0.31337497679850074]
	TIME [epoch: 10.4 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30578333690476767		[learning rate: 1.5707e-05]
	Learning Rate: 1.57074e-05
	LOSS [training: 0.30578333690476767 | validation: 0.3533979937335276]
	TIME [epoch: 10.4 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3141824785456048		[learning rate: 1.565e-05]
	Learning Rate: 1.56504e-05
	LOSS [training: 0.3141824785456048 | validation: 0.34961577151389556]
	TIME [epoch: 10.4 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109762549966325		[learning rate: 1.5594e-05]
	Learning Rate: 1.55936e-05
	LOSS [training: 0.3109762549966325 | validation: 0.3585010571484895]
	TIME [epoch: 10.4 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3016146266488775		[learning rate: 1.5537e-05]
	Learning Rate: 1.5537e-05
	LOSS [training: 0.3016146266488775 | validation: 0.3380366692030903]
	TIME [epoch: 10.4 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31136573432378833		[learning rate: 1.5481e-05]
	Learning Rate: 1.54807e-05
	LOSS [training: 0.31136573432378833 | validation: 0.33661324527723047]
	TIME [epoch: 10.4 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3066981873378758		[learning rate: 1.5424e-05]
	Learning Rate: 1.54245e-05
	LOSS [training: 0.3066981873378758 | validation: 0.32554003507007273]
	TIME [epoch: 10.4 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3137003745075583		[learning rate: 1.5369e-05]
	Learning Rate: 1.53685e-05
	LOSS [training: 0.3137003745075583 | validation: 0.34847696459597244]
	TIME [epoch: 10.4 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3007461412375844		[learning rate: 1.5313e-05]
	Learning Rate: 1.53127e-05
	LOSS [training: 0.3007461412375844 | validation: 0.3716708861488536]
	TIME [epoch: 10.4 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3067868097253555		[learning rate: 1.5257e-05]
	Learning Rate: 1.52572e-05
	LOSS [training: 0.3067868097253555 | validation: 0.33576720920505393]
	TIME [epoch: 10.4 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2982317181961225		[learning rate: 1.5202e-05]
	Learning Rate: 1.52018e-05
	LOSS [training: 0.2982317181961225 | validation: 0.3247421399149424]
	TIME [epoch: 10.4 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2963130579413548		[learning rate: 1.5147e-05]
	Learning Rate: 1.51466e-05
	LOSS [training: 0.2963130579413548 | validation: 0.33501816643046894]
	TIME [epoch: 10.4 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2913144544893316		[learning rate: 1.5092e-05]
	Learning Rate: 1.50917e-05
	LOSS [training: 0.2913144544893316 | validation: 0.33779519108427947]
	TIME [epoch: 10.4 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29645620010023155		[learning rate: 1.5037e-05]
	Learning Rate: 1.50369e-05
	LOSS [training: 0.29645620010023155 | validation: 0.3237591954635539]
	TIME [epoch: 10.4 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3105513348044735		[learning rate: 1.4982e-05]
	Learning Rate: 1.49823e-05
	LOSS [training: 0.3105513348044735 | validation: 0.324945595035194]
	TIME [epoch: 10.4 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29900470760950715		[learning rate: 1.4928e-05]
	Learning Rate: 1.49279e-05
	LOSS [training: 0.29900470760950715 | validation: 0.3308086360491566]
	TIME [epoch: 10.4 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3081199461101369		[learning rate: 1.4874e-05]
	Learning Rate: 1.48738e-05
	LOSS [training: 0.3081199461101369 | validation: 0.3670682924092276]
	TIME [epoch: 10.4 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3171552951450154		[learning rate: 1.482e-05]
	Learning Rate: 1.48198e-05
	LOSS [training: 0.3171552951450154 | validation: 0.35777948501630064]
	TIME [epoch: 10.4 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32462028572328877		[learning rate: 1.4766e-05]
	Learning Rate: 1.4766e-05
	LOSS [training: 0.32462028572328877 | validation: 0.35522833291305944]
	TIME [epoch: 10.4 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999140726297627		[learning rate: 1.4712e-05]
	Learning Rate: 1.47124e-05
	LOSS [training: 0.2999140726297627 | validation: 0.3247923464152755]
	TIME [epoch: 10.4 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29874367822703224		[learning rate: 1.4659e-05]
	Learning Rate: 1.4659e-05
	LOSS [training: 0.29874367822703224 | validation: 0.3603028033413962]
	TIME [epoch: 10.4 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037056010951067		[learning rate: 1.4606e-05]
	Learning Rate: 1.46058e-05
	LOSS [training: 0.3037056010951067 | validation: 0.34850734928685]
	TIME [epoch: 10.4 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31435856716849797		[learning rate: 1.4553e-05]
	Learning Rate: 1.45528e-05
	LOSS [training: 0.31435856716849797 | validation: 0.3428096820391599]
	TIME [epoch: 10.4 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3018510193970682		[learning rate: 1.45e-05]
	Learning Rate: 1.45e-05
	LOSS [training: 0.3018510193970682 | validation: 0.3294374313883905]
	TIME [epoch: 10.4 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108108393170703		[learning rate: 1.4447e-05]
	Learning Rate: 1.44474e-05
	LOSS [training: 0.3108108393170703 | validation: 0.34609561576771014]
	TIME [epoch: 10.4 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3039102718898251		[learning rate: 1.4395e-05]
	Learning Rate: 1.4395e-05
	LOSS [training: 0.3039102718898251 | validation: 0.32040431319612067]
	TIME [epoch: 10.4 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3017863002079657		[learning rate: 1.4343e-05]
	Learning Rate: 1.43427e-05
	LOSS [training: 0.3017863002079657 | validation: 0.34165255697670105]
	TIME [epoch: 10.4 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30850203364350215		[learning rate: 1.4291e-05]
	Learning Rate: 1.42907e-05
	LOSS [training: 0.30850203364350215 | validation: 0.3415592964612837]
	TIME [epoch: 10.4 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32625682870761785		[learning rate: 1.4239e-05]
	Learning Rate: 1.42388e-05
	LOSS [training: 0.32625682870761785 | validation: 0.3341614312270809]
	TIME [epoch: 10.4 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3031693297321587		[learning rate: 1.4187e-05]
	Learning Rate: 1.41871e-05
	LOSS [training: 0.3031693297321587 | validation: 0.32220552388613555]
	TIME [epoch: 10.4 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29603461057288716		[learning rate: 1.4136e-05]
	Learning Rate: 1.41357e-05
	LOSS [training: 0.29603461057288716 | validation: 0.3259599463630843]
	TIME [epoch: 10.4 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068865813845237		[learning rate: 1.4084e-05]
	Learning Rate: 1.40844e-05
	LOSS [training: 0.3068865813845237 | validation: 0.3325307883341931]
	TIME [epoch: 10.4 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30682043755693744		[learning rate: 1.4033e-05]
	Learning Rate: 1.40332e-05
	LOSS [training: 0.30682043755693744 | validation: 0.3635308480466915]
	TIME [epoch: 10.4 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2980863108816367		[learning rate: 1.3982e-05]
	Learning Rate: 1.39823e-05
	LOSS [training: 0.2980863108816367 | validation: 0.3246251887916208]
	TIME [epoch: 10.4 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3069339784085117		[learning rate: 1.3932e-05]
	Learning Rate: 1.39316e-05
	LOSS [training: 0.3069339784085117 | validation: 0.3431882297152823]
	TIME [epoch: 10.4 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2907958902173847		[learning rate: 1.3881e-05]
	Learning Rate: 1.3881e-05
	LOSS [training: 0.2907958902173847 | validation: 0.3194319420027134]
	TIME [epoch: 10.4 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3060495659763675		[learning rate: 1.3831e-05]
	Learning Rate: 1.38306e-05
	LOSS [training: 0.3060495659763675 | validation: 0.3244305402029796]
	TIME [epoch: 10.4 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30870327652290624		[learning rate: 1.378e-05]
	Learning Rate: 1.37804e-05
	LOSS [training: 0.30870327652290624 | validation: 0.37027462151528845]
	TIME [epoch: 10.4 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32028798094070815		[learning rate: 1.373e-05]
	Learning Rate: 1.37304e-05
	LOSS [training: 0.32028798094070815 | validation: 0.3688023918286208]
	TIME [epoch: 10.4 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027951101472519		[learning rate: 1.3681e-05]
	Learning Rate: 1.36806e-05
	LOSS [training: 0.3027951101472519 | validation: 0.3279318330709468]
	TIME [epoch: 10.4 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3119683356249101		[learning rate: 1.3631e-05]
	Learning Rate: 1.3631e-05
	LOSS [training: 0.3119683356249101 | validation: 0.3567258085323066]
	TIME [epoch: 10.4 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068598163652733		[learning rate: 1.3581e-05]
	Learning Rate: 1.35815e-05
	LOSS [training: 0.3068598163652733 | validation: 0.3261308508951426]
	TIME [epoch: 10.4 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142178685812585		[learning rate: 1.3532e-05]
	Learning Rate: 1.35322e-05
	LOSS [training: 0.3142178685812585 | validation: 0.3318863330934155]
	TIME [epoch: 10.4 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3072466808536459		[learning rate: 1.3483e-05]
	Learning Rate: 1.34831e-05
	LOSS [training: 0.3072466808536459 | validation: 0.3499905975199446]
	TIME [epoch: 10.4 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30049312505370696		[learning rate: 1.3434e-05]
	Learning Rate: 1.34342e-05
	LOSS [training: 0.30049312505370696 | validation: 0.3493166084514901]
	TIME [epoch: 10.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29633146266061494		[learning rate: 1.3385e-05]
	Learning Rate: 1.33854e-05
	LOSS [training: 0.29633146266061494 | validation: 0.3315116159345349]
	TIME [epoch: 10.4 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037258571272833		[learning rate: 1.3337e-05]
	Learning Rate: 1.33368e-05
	LOSS [training: 0.3037258571272833 | validation: 0.3722166281630604]
	TIME [epoch: 10.4 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29371879926483146		[learning rate: 1.3288e-05]
	Learning Rate: 1.32884e-05
	LOSS [training: 0.29371879926483146 | validation: 0.3114302732153313]
	TIME [epoch: 10.4 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30374456017811047		[learning rate: 1.324e-05]
	Learning Rate: 1.32402e-05
	LOSS [training: 0.30374456017811047 | validation: 0.3280140660023298]
	TIME [epoch: 10.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3191022263603329		[learning rate: 1.3192e-05]
	Learning Rate: 1.31922e-05
	LOSS [training: 0.3191022263603329 | validation: 0.3307034381857266]
	TIME [epoch: 10.4 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3124303565118229		[learning rate: 1.3144e-05]
	Learning Rate: 1.31443e-05
	LOSS [training: 0.3124303565118229 | validation: 0.3354290479129054]
	TIME [epoch: 10.4 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30901120061318305		[learning rate: 1.3097e-05]
	Learning Rate: 1.30966e-05
	LOSS [training: 0.30901120061318305 | validation: 0.3393605970639409]
	TIME [epoch: 10.4 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30480314376769463		[learning rate: 1.3049e-05]
	Learning Rate: 1.30491e-05
	LOSS [training: 0.30480314376769463 | validation: 0.3682406248320515]
	TIME [epoch: 10.4 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31448363098446264		[learning rate: 1.3002e-05]
	Learning Rate: 1.30017e-05
	LOSS [training: 0.31448363098446264 | validation: 0.3265031768497646]
	TIME [epoch: 10.4 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084591649337791		[learning rate: 1.2955e-05]
	Learning Rate: 1.29545e-05
	LOSS [training: 0.3084591649337791 | validation: 0.32194418873141234]
	TIME [epoch: 10.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3284029656438118		[learning rate: 1.2907e-05]
	Learning Rate: 1.29075e-05
	LOSS [training: 0.3284029656438118 | validation: 0.3618037664317006]
	TIME [epoch: 10.4 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31505654607493416		[learning rate: 1.2861e-05]
	Learning Rate: 1.28607e-05
	LOSS [training: 0.31505654607493416 | validation: 0.3396713766848324]
	TIME [epoch: 10.4 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3040368866791703		[learning rate: 1.2814e-05]
	Learning Rate: 1.2814e-05
	LOSS [training: 0.3040368866791703 | validation: 0.362760279542522]
	TIME [epoch: 10.4 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30624407053772174		[learning rate: 1.2767e-05]
	Learning Rate: 1.27675e-05
	LOSS [training: 0.30624407053772174 | validation: 0.32916980422053477]
	TIME [epoch: 10.4 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2940553389704058		[learning rate: 1.2721e-05]
	Learning Rate: 1.27212e-05
	LOSS [training: 0.2940553389704058 | validation: 0.38110441589216343]
	TIME [epoch: 10.3 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3255679886372402		[learning rate: 1.2675e-05]
	Learning Rate: 1.2675e-05
	LOSS [training: 0.3255679886372402 | validation: 0.35304224476043566]
	TIME [epoch: 10.4 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30473813149443896		[learning rate: 1.2629e-05]
	Learning Rate: 1.2629e-05
	LOSS [training: 0.30473813149443896 | validation: 0.32730154695512553]
	TIME [epoch: 10.4 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2994868294478628		[learning rate: 1.2583e-05]
	Learning Rate: 1.25832e-05
	LOSS [training: 0.2994868294478628 | validation: 0.3603150450938641]
	TIME [epoch: 10.4 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013953090126518		[learning rate: 1.2537e-05]
	Learning Rate: 1.25375e-05
	LOSS [training: 0.3013953090126518 | validation: 0.3462343339496985]
	TIME [epoch: 10.4 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186303860871764		[learning rate: 1.2492e-05]
	Learning Rate: 1.2492e-05
	LOSS [training: 0.3186303860871764 | validation: 0.336995325668376]
	TIME [epoch: 10.4 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073626852815288		[learning rate: 1.2447e-05]
	Learning Rate: 1.24467e-05
	LOSS [training: 0.3073626852815288 | validation: 0.35778908524944286]
	TIME [epoch: 10.4 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138488185681273		[learning rate: 1.2401e-05]
	Learning Rate: 1.24015e-05
	LOSS [training: 0.3138488185681273 | validation: 0.3281907942560558]
	TIME [epoch: 10.4 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3059913787887889		[learning rate: 1.2356e-05]
	Learning Rate: 1.23565e-05
	LOSS [training: 0.3059913787887889 | validation: 0.34352470084713005]
	TIME [epoch: 10.4 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30421574248616967		[learning rate: 1.2312e-05]
	Learning Rate: 1.23116e-05
	LOSS [training: 0.30421574248616967 | validation: 0.36602632298609744]
	TIME [epoch: 10.4 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052519078381927		[learning rate: 1.2267e-05]
	Learning Rate: 1.2267e-05
	LOSS [training: 0.3052519078381927 | validation: 0.3308278835909136]
	TIME [epoch: 10.4 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28940263973016817		[learning rate: 1.2222e-05]
	Learning Rate: 1.22224e-05
	LOSS [training: 0.28940263973016817 | validation: 0.36162131023098154]
	TIME [epoch: 10.4 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31094257398426184		[learning rate: 1.2178e-05]
	Learning Rate: 1.21781e-05
	LOSS [training: 0.31094257398426184 | validation: 0.35627769855774505]
	TIME [epoch: 10.4 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31056870849128054		[learning rate: 1.2134e-05]
	Learning Rate: 1.21339e-05
	LOSS [training: 0.31056870849128054 | validation: 0.36200697810878696]
	TIME [epoch: 10.4 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29993923881189		[learning rate: 1.209e-05]
	Learning Rate: 1.20899e-05
	LOSS [training: 0.29993923881189 | validation: 0.36672517596338344]
	TIME [epoch: 10.4 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2946576789508921		[learning rate: 1.2046e-05]
	Learning Rate: 1.2046e-05
	LOSS [training: 0.2946576789508921 | validation: 0.3256085561101066]
	TIME [epoch: 10.4 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2908749646537792		[learning rate: 1.2002e-05]
	Learning Rate: 1.20023e-05
	LOSS [training: 0.2908749646537792 | validation: 0.3214340956846317]
	TIME [epoch: 10.4 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30243981182359664		[learning rate: 1.1959e-05]
	Learning Rate: 1.19587e-05
	LOSS [training: 0.30243981182359664 | validation: 0.3577393613701497]
	TIME [epoch: 10.4 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30485946745057213		[learning rate: 1.1915e-05]
	Learning Rate: 1.19153e-05
	LOSS [training: 0.30485946745057213 | validation: 0.3242351687353822]
	TIME [epoch: 10.4 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009575359163115		[learning rate: 1.1872e-05]
	Learning Rate: 1.18721e-05
	LOSS [training: 0.3009575359163115 | validation: 0.3215679358825061]
	TIME [epoch: 10.4 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30282223788615464		[learning rate: 1.1829e-05]
	Learning Rate: 1.1829e-05
	LOSS [training: 0.30282223788615464 | validation: 0.2799647276857528]
	TIME [epoch: 10.4 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30514511980005704		[learning rate: 1.1786e-05]
	Learning Rate: 1.17861e-05
	LOSS [training: 0.30514511980005704 | validation: 0.33626841339272145]
	TIME [epoch: 10.4 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31252923287504986		[learning rate: 1.1743e-05]
	Learning Rate: 1.17433e-05
	LOSS [training: 0.31252923287504986 | validation: 0.33915307356046215]
	TIME [epoch: 10.4 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3069396481479946		[learning rate: 1.1701e-05]
	Learning Rate: 1.17007e-05
	LOSS [training: 0.3069396481479946 | validation: 0.3224153102493152]
	TIME [epoch: 10.4 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965102122653958		[learning rate: 1.1658e-05]
	Learning Rate: 1.16582e-05
	LOSS [training: 0.2965102122653958 | validation: 0.3329673123006331]
	TIME [epoch: 10.4 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022103000774234		[learning rate: 1.1616e-05]
	Learning Rate: 1.16159e-05
	LOSS [training: 0.3022103000774234 | validation: 0.34923232786392716]
	TIME [epoch: 10.4 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3045608244970391		[learning rate: 1.1574e-05]
	Learning Rate: 1.15737e-05
	LOSS [training: 0.3045608244970391 | validation: 0.32025412321014235]
	TIME [epoch: 10.4 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29464683277113435		[learning rate: 1.1532e-05]
	Learning Rate: 1.15317e-05
	LOSS [training: 0.29464683277113435 | validation: 0.3238559052305112]
	TIME [epoch: 10.4 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29498873136485815		[learning rate: 1.149e-05]
	Learning Rate: 1.14899e-05
	LOSS [training: 0.29498873136485815 | validation: 0.35901893841791493]
	TIME [epoch: 10.4 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.301586902057022		[learning rate: 1.1448e-05]
	Learning Rate: 1.14482e-05
	LOSS [training: 0.301586902057022 | validation: 0.2267098490956069]
	TIME [epoch: 10.4 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967407898083061		[learning rate: 1.1407e-05]
	Learning Rate: 1.14066e-05
	LOSS [training: 0.2967407898083061 | validation: 0.36855379986206]
	TIME [epoch: 10.4 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30479011420762914		[learning rate: 1.1365e-05]
	Learning Rate: 1.13652e-05
	LOSS [training: 0.30479011420762914 | validation: 0.33361141125504545]
	TIME [epoch: 10.4 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2990775447140712		[learning rate: 1.1324e-05]
	Learning Rate: 1.1324e-05
	LOSS [training: 0.2990775447140712 | validation: 0.3542776830944564]
	TIME [epoch: 10.4 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30765429364571334		[learning rate: 1.1283e-05]
	Learning Rate: 1.12829e-05
	LOSS [training: 0.30765429364571334 | validation: 0.31969980020916977]
	TIME [epoch: 10.4 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30785676421027475		[learning rate: 1.1242e-05]
	Learning Rate: 1.1242e-05
	LOSS [training: 0.30785676421027475 | validation: 0.3218555307133842]
	TIME [epoch: 10.4 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2997927731668966		[learning rate: 1.1201e-05]
	Learning Rate: 1.12012e-05
	LOSS [training: 0.2997927731668966 | validation: 0.3542683644408732]
	TIME [epoch: 10.4 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30763535182041385		[learning rate: 1.1161e-05]
	Learning Rate: 1.11605e-05
	LOSS [training: 0.30763535182041385 | validation: 0.3261829334850378]
	TIME [epoch: 10.4 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29703029639517986		[learning rate: 1.112e-05]
	Learning Rate: 1.112e-05
	LOSS [training: 0.29703029639517986 | validation: 0.3314960886955426]
	TIME [epoch: 10.4 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31462652330709723		[learning rate: 1.108e-05]
	Learning Rate: 1.10797e-05
	LOSS [training: 0.31462652330709723 | validation: 0.3578980842692958]
	TIME [epoch: 10.4 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003061084690789		[learning rate: 1.1039e-05]
	Learning Rate: 1.10394e-05
	LOSS [training: 0.3003061084690789 | validation: 0.3456195155549386]
	TIME [epoch: 10.4 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2972452290502177		[learning rate: 1.0999e-05]
	Learning Rate: 1.09994e-05
	LOSS [training: 0.2972452290502177 | validation: 0.33365830723214646]
	TIME [epoch: 10.4 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2911348028513697		[learning rate: 1.0959e-05]
	Learning Rate: 1.09595e-05
	LOSS [training: 0.2911348028513697 | validation: 0.3563915954547022]
	TIME [epoch: 10.4 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30302071653001444		[learning rate: 1.092e-05]
	Learning Rate: 1.09197e-05
	LOSS [training: 0.30302071653001444 | validation: 0.32858916315939873]
	TIME [epoch: 10.4 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32729155608765537		[learning rate: 1.088e-05]
	Learning Rate: 1.08801e-05
	LOSS [training: 0.32729155608765537 | validation: 0.34146875770177476]
	TIME [epoch: 10.4 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30639541907420853		[learning rate: 1.0841e-05]
	Learning Rate: 1.08406e-05
	LOSS [training: 0.30639541907420853 | validation: 0.36806571060675036]
	TIME [epoch: 10.4 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30375961728551426		[learning rate: 1.0801e-05]
	Learning Rate: 1.08012e-05
	LOSS [training: 0.30375961728551426 | validation: 0.36605378691237506]
	TIME [epoch: 10.4 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3099471843700715		[learning rate: 1.0762e-05]
	Learning Rate: 1.0762e-05
	LOSS [training: 0.3099471843700715 | validation: 0.34141907614883127]
	TIME [epoch: 10.3 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221789816205364		[learning rate: 1.0723e-05]
	Learning Rate: 1.0723e-05
	LOSS [training: 0.3221789816205364 | validation: 0.30825853992180624]
	TIME [epoch: 10.4 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3103738010175944		[learning rate: 1.0684e-05]
	Learning Rate: 1.06841e-05
	LOSS [training: 0.3103738010175944 | validation: 0.3692556499467072]
	TIME [epoch: 10.4 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29250093140930744		[learning rate: 1.0645e-05]
	Learning Rate: 1.06453e-05
	LOSS [training: 0.29250093140930744 | validation: 0.3124373774944184]
	TIME [epoch: 10.4 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3066455771124587		[learning rate: 1.0607e-05]
	Learning Rate: 1.06067e-05
	LOSS [training: 0.3066455771124587 | validation: 0.3094596925195817]
	TIME [epoch: 10.4 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31407507203738594		[learning rate: 1.0568e-05]
	Learning Rate: 1.05682e-05
	LOSS [training: 0.31407507203738594 | validation: 0.3377467958749378]
	TIME [epoch: 10.4 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079992810023528		[learning rate: 1.053e-05]
	Learning Rate: 1.05298e-05
	LOSS [training: 0.3079992810023528 | validation: 0.30594747998432853]
	TIME [epoch: 10.4 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30899482724752564		[learning rate: 1.0492e-05]
	Learning Rate: 1.04916e-05
	LOSS [training: 0.30899482724752564 | validation: 0.3131222619015978]
	TIME [epoch: 10.4 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967390254100262		[learning rate: 1.0454e-05]
	Learning Rate: 1.04535e-05
	LOSS [training: 0.2967390254100262 | validation: 0.36365507660746843]
	TIME [epoch: 10.4 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3015804820755134		[learning rate: 1.0416e-05]
	Learning Rate: 1.04156e-05
	LOSS [training: 0.3015804820755134 | validation: 0.33842441687951286]
	TIME [epoch: 10.4 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32190517480462494		[learning rate: 1.0378e-05]
	Learning Rate: 1.03778e-05
	LOSS [training: 0.32190517480462494 | validation: 0.3550996867503882]
	TIME [epoch: 10.4 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2913684160876147		[learning rate: 1.034e-05]
	Learning Rate: 1.03401e-05
	LOSS [training: 0.2913684160876147 | validation: 0.3264600912221507]
	TIME [epoch: 10.4 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2964687773939237		[learning rate: 1.0303e-05]
	Learning Rate: 1.03026e-05
	LOSS [training: 0.2964687773939237 | validation: 0.3308690235305958]
	TIME [epoch: 10.4 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3132475848237942		[learning rate: 1.0265e-05]
	Learning Rate: 1.02652e-05
	LOSS [training: 0.3132475848237942 | validation: 0.3755975814018903]
	TIME [epoch: 10.4 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3189484200946853		[learning rate: 1.0228e-05]
	Learning Rate: 1.0228e-05
	LOSS [training: 0.3189484200946853 | validation: 0.3650656751200512]
	TIME [epoch: 10.4 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30986800230020767		[learning rate: 1.0191e-05]
	Learning Rate: 1.01909e-05
	LOSS [training: 0.30986800230020767 | validation: 0.3345533874555467]
	TIME [epoch: 10.4 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29478265809289494		[learning rate: 1.0154e-05]
	Learning Rate: 1.01539e-05
	LOSS [training: 0.29478265809289494 | validation: 0.32675155805493317]
	TIME [epoch: 10.4 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29460223148470066		[learning rate: 1.0117e-05]
	Learning Rate: 1.0117e-05
	LOSS [training: 0.29460223148470066 | validation: 0.34139607829641266]
	TIME [epoch: 10.4 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29594746015182966		[learning rate: 1.008e-05]
	Learning Rate: 1.00803e-05
	LOSS [training: 0.29594746015182966 | validation: 0.3571148083749799]
	TIME [epoch: 10.4 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054838131525144		[learning rate: 1.0044e-05]
	Learning Rate: 1.00437e-05
	LOSS [training: 0.3054838131525144 | validation: 0.34682637377228226]
	TIME [epoch: 10.4 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30696246498528545		[learning rate: 1.0007e-05]
	Learning Rate: 1.00073e-05
	LOSS [training: 0.30696246498528545 | validation: 0.33801629265800714]
	TIME [epoch: 10.4 sec]
Finished training in 20892.206 seconds.
