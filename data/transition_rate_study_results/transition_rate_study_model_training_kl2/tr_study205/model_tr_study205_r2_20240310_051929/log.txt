Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r2', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2571944594

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.570125131646856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.570125131646856 | validation: 11.722961862834346]
	TIME [epoch: 111 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.642674996815261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.642674996815261 | validation: 11.906702900320829]
	TIME [epoch: 24.9 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.591719981151858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.591719981151858 | validation: 9.941189972123562]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.242882694370028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.242882694370028 | validation: 8.788887119042919]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.94072036206085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.94072036206085 | validation: 10.450789842319276]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.644282466303498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.644282466303498 | validation: 6.815516296338717]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.188070711523922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.188070711523922 | validation: 6.40108136720423]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.734984679186737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.734984679186737 | validation: 5.687980722446404]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.188658691418286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.188658691418286 | validation: 5.546271989035351]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.245652665472605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.245652665472605 | validation: 5.701132535356761]
	TIME [epoch: 24.8 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9764012348511315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9764012348511315 | validation: 5.6735176638827856]
	TIME [epoch: 24.8 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6701649998924495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6701649998924495 | validation: 5.491177569195412]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.008112205965421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.008112205965421 | validation: 5.616295569090304]
	TIME [epoch: 24.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8361395178217474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8361395178217474 | validation: 5.664048177827174]
	TIME [epoch: 24.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.486666988773947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.486666988773947 | validation: 5.371474001775962]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.00541264779084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.00541264779084 | validation: 5.3108216186749075]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.859443992516649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.859443992516649 | validation: 5.544247047496287]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5554099883845325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5554099883845325 | validation: 5.744388920230813]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.901610289134068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.901610289134068 | validation: 5.150402536721623]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.752728733630625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.752728733630625 | validation: 5.582513050847549]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.404674657294918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.404674657294918 | validation: 5.440987894727539]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.492582947090785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.492582947090785 | validation: 5.146175399935983]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534694872209916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.534694872209916 | validation: 5.19861408623087]
	TIME [epoch: 24.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.44376249005335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.44376249005335 | validation: 5.114760880689058]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.202165165438923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.202165165438923 | validation: 4.955250567940403]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.615705409870966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.615705409870966 | validation: 5.078446382739787]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.106145459032572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.106145459032572 | validation: 5.734070910696219]
	TIME [epoch: 24.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.351013187974551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.351013187974551 | validation: 5.5081883686523305]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.135274097994644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.135274097994644 | validation: 4.914718049416599]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.927779285668975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.927779285668975 | validation: 6.131083062901675]
	TIME [epoch: 24.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4830857299713465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4830857299713465 | validation: 5.636847647709247]
	TIME [epoch: 24.9 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.189858569631337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.189858569631337 | validation: 5.330032356989034]
	TIME [epoch: 24.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.068604742738995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.068604742738995 | validation: 6.277709861670457]
	TIME [epoch: 24.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.200340426406137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.200340426406137 | validation: 4.671143230183634]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.222309202192534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.222309202192534 | validation: 5.347523456279689]
	TIME [epoch: 24.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0948045569951255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0948045569951255 | validation: 5.071089522892364]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037467904064316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.037467904064316 | validation: 5.009419264126165]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.040389904799949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.040389904799949 | validation: 5.538831316580083]
	TIME [epoch: 24.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.070728022297367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.070728022297367 | validation: 4.579930520448098]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.115002183818905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.115002183818905 | validation: 4.643501899290729]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.928969587764599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.928969587764599 | validation: 4.944822217101118]
	TIME [epoch: 24.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.919840053695818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.919840053695818 | validation: 4.896077639085544]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.81037480850227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.81037480850227 | validation: 5.313870346127681]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9997867737063544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9997867737063544 | validation: 4.742086377370774]
	TIME [epoch: 24.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7360206150278734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7360206150278734 | validation: 6.046730813356665]
	TIME [epoch: 24.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0877992571853605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0877992571853605 | validation: 5.093009689154287]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084136994462644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.084136994462644 | validation: 4.97142644881126]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.028344756576646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.028344756576646 | validation: 4.699386664428134]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.948100443335404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.948100443335404 | validation: 4.928736016074798]
	TIME [epoch: 24.9 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.851708251165907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.851708251165907 | validation: 5.064612423222184]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.88855964865735		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.88855964865735 | validation: 4.756916427346757]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.848989009124315		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.848989009124315 | validation: 4.613755628750671]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9871126298627226		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.9871126298627226 | validation: 4.893946474972045]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9862288556822714		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.9862288556822714 | validation: 4.821837263998967]
	TIME [epoch: 24.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8100995439595895		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.8100995439595895 | validation: 4.500777061973937]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.776357555037857		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.776357555037857 | validation: 4.764708698730848]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7782571895833925		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.7782571895833925 | validation: 4.828142467432685]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7830345256388873		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.7830345256388873 | validation: 4.806835785126944]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.783211494923131		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.783211494923131 | validation: 4.51751525957038]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5829330965728623		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.5829330965728623 | validation: 4.5336904796761655]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0374316819683465		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.0374316819683465 | validation: 4.55527127060431]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6505322016638027		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.6505322016638027 | validation: 4.594432230748046]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.802941115166842		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.802941115166842 | validation: 4.771108128871218]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6808079902495807		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.6808079902495807 | validation: 5.0557053597191635]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6262940004125404		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.6262940004125404 | validation: 5.46575919624609]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.389682917880784		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.389682917880784 | validation: 5.23390133892805]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8654394079504195		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.8654394079504195 | validation: 4.657790259902054]
	TIME [epoch: 24.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.707962053793192		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.707962053793192 | validation: 4.473621290921555]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6185180246478175		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.6185180246478175 | validation: 4.5022305560300815]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.812001605307361		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.812001605307361 | validation: 5.054834226409321]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6492795913976694		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.6492795913976694 | validation: 4.582275580876035]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7667209114415434		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.7667209114415434 | validation: 4.4674870641057725]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.631943018116175		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.631943018116175 | validation: 4.564580474017533]
	TIME [epoch: 24.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.69225975966034		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.69225975966034 | validation: 4.658529229047068]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.491291200505169		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.491291200505169 | validation: 4.664142713665793]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.789373129389147		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.789373129389147 | validation: 4.6037291168826435]
	TIME [epoch: 24.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6288335332705577		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.6288335332705577 | validation: 4.387103626038034]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6600965338957416		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6600965338957416 | validation: 4.838204992778857]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.595450879367617		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.595450879367617 | validation: 4.442115794582568]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3785262920324324		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.3785262920324324 | validation: 4.774455756074764]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.95449298804421		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.95449298804421 | validation: 5.48169290788167]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6571621514308967		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.6571621514308967 | validation: 4.622760263004426]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5429579166266914		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.5429579166266914 | validation: 4.6250440303189295]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6849288240973523		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.6849288240973523 | validation: 4.3794557448757905]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.477232716527932		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.477232716527932 | validation: 4.849260852756924]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.422356079485704		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.422356079485704 | validation: 4.3578311769299445]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5004936312292796		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.5004936312292796 | validation: 4.668199193718785]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.54306632403733		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.54306632403733 | validation: 4.517118269218111]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.646865453686183		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.646865453686183 | validation: 4.389894571706936]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3018306583043895		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.3018306583043895 | validation: 5.304346172338719]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6605341070618502		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.6605341070618502 | validation: 4.40230400886832]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.59868511271115		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.59868511271115 | validation: 4.4604041028192345]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.425346433248246		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.425346433248246 | validation: 4.293233840711662]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381139280523533		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.381139280523533 | validation: 4.284950886866088]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.79176590381093		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.79176590381093 | validation: 5.229089881017091]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5901664710235175		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.5901664710235175 | validation: 4.4203490985391545]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3624111047783805		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.3624111047783805 | validation: 4.143227447057289]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3512931027016934		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.3512931027016934 | validation: 4.692542643650827]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.460587394249397		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.460587394249397 | validation: 4.446232531861476]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3946290319157617		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.3946290319157617 | validation: 4.862963366084688]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377678355515015		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.377678355515015 | validation: 4.099088772759684]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.443034821123194		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.443034821123194 | validation: 4.096278892032406]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.326732567146556		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.326732567146556 | validation: 4.271460397173064]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4761992647635527		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.4761992647635527 | validation: 4.19979436788103]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4997085930117606		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.4997085930117606 | validation: 4.086251825576566]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3590055396224385		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.3590055396224385 | validation: 4.272586538747625]
	TIME [epoch: 24.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2815763706337027		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.2815763706337027 | validation: 4.216721598550178]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.327127448495657		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.327127448495657 | validation: 4.542942861359803]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4196897498535215		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.4196897498535215 | validation: 4.436628557806625]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2968859462711433		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.2968859462711433 | validation: 4.299049710628224]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2013883291837164		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.2013883291837164 | validation: 4.185063518348435]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302120342870362		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.302120342870362 | validation: 4.031383249890088]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.292441641139023		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.292441641139023 | validation: 4.254195505455332]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2313235163079645		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.2313235163079645 | validation: 4.228552268172104]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3451077736307173		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3451077736307173 | validation: 4.029681557570715]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3315923858853345		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.3315923858853345 | validation: 5.33627532508413]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6570560003134247		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.6570560003134247 | validation: 4.0974159644378965]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2095763840437286		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.2095763840437286 | validation: 4.098591130410843]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.071711781783651		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.071711781783651 | validation: 4.6629522466861095]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2616423226796925		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.2616423226796925 | validation: 4.445863380976322]
	TIME [epoch: 24.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.202530168694952		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.202530168694952 | validation: 4.922218914242489]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4463699916830244		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.4463699916830244 | validation: 4.344047248366053]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3043189398472883		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.3043189398472883 | validation: 4.244847723491045]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.277738016361191		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.277738016361191 | validation: 4.3916204165018815]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102687983670157		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.2102687983670157 | validation: 4.062952112141221]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2212545446209067		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.2212545446209067 | validation: 3.9983841882227265]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233898369501803		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.233898369501803 | validation: 4.174804941743516]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.144783931323921		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.144783931323921 | validation: 4.14543444831991]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2301978053015894		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.2301978053015894 | validation: 4.071836290424873]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0837560795382633		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.0837560795382633 | validation: 4.065411737306579]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2325287133662517		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.2325287133662517 | validation: 4.113786947690063]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1139917796701324		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.1139917796701324 | validation: 3.9733559081961505]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7079987301936628		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.7079987301936628 | validation: 4.154171656920528]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.027923630423612		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.027923630423612 | validation: 4.045886372209997]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1345730659796294		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.1345730659796294 | validation: 4.114463586003796]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0516606636943555		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.0516606636943555 | validation: 4.599799095809184]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.161469064658934		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.161469064658934 | validation: 3.9482916336909764]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0568770274706214		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.0568770274706214 | validation: 4.18852695821997]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3927568721513013		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.3927568721513013 | validation: 4.1987360254625505]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.128142807024844		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.128142807024844 | validation: 5.332461936145937]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4413844028430187		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.4413844028430187 | validation: 4.366214316252346]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.291000149426464		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.291000149426464 | validation: 4.036218587993138]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.097924918031608		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.097924918031608 | validation: 4.058571450008136]
	TIME [epoch: 24.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.109010909272201		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.109010909272201 | validation: 4.006863604025026]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0726180229913185		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.0726180229913185 | validation: 4.028479503033486]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1355294428849607		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.1355294428849607 | validation: 4.036245049219851]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135508976526238		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.135508976526238 | validation: 4.14477007729689]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2975858997676784		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.2975858997676784 | validation: 4.22301622393179]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0916252086811697		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.0916252086811697 | validation: 3.9663279411821404]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2033899786496636		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.2033899786496636 | validation: 3.9835973839923864]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1009724679345565		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.1009724679345565 | validation: 3.963562908600125]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1540746646499636		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.1540746646499636 | validation: 3.9826997422447192]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0214511562710493		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.0214511562710493 | validation: 4.6538830040391455]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1912459003543825		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.1912459003543825 | validation: 4.586005704145564]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2637506213074357		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.2637506213074357 | validation: 3.9453977942267753]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9689024517425078		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.9689024517425078 | validation: 4.416422989867445]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.107268613690832		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.107268613690832 | validation: 4.263634486644901]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28218472708926		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.28218472708926 | validation: 3.966119455925892]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05829992407127		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.05829992407127 | validation: 4.12659209484684]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.153365751510677		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.153365751510677 | validation: 4.393491486683107]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2282820934781737		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.2282820934781737 | validation: 4.0253934028665315]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3652948620766487		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.3652948620766487 | validation: 4.289968328467419]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3185148685267754		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.3185148685267754 | validation: 4.105701493814391]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0645605056145464		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.0645605056145464 | validation: 3.9092440148031153]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.084772997397654		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.084772997397654 | validation: 4.265604486197957]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.30798013525044		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.30798013525044 | validation: 4.025203525376869]
	TIME [epoch: 24.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.141964696212442		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.141964696212442 | validation: 4.362302128403256]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236160623027032		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.236160623027032 | validation: 4.074391982120103]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0169283570756207		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.0169283570756207 | validation: 4.2211471992586596]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.961210992398974		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 2.961210992398974 | validation: 4.241598453406793]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0992726231267325		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.0992726231267325 | validation: 4.165668129160166]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8493741535582267		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.8493741535582267 | validation: 5.101004978301623]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373686225842515		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.373686225842515 | validation: 4.16065345989738]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9606452169525115		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.9606452169525115 | validation: 3.999785544370787]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.921304803908046		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 2.921304803908046 | validation: 4.069839060019377]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9305656113483103		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.9305656113483103 | validation: 3.91964472301401]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.88740202430916		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.88740202430916 | validation: 4.055327885431283]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.865111884869808		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.865111884869808 | validation: 3.817332201811067]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.459065531292042		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.459065531292042 | validation: 3.8174067227746713]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.880776652077227		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.880776652077227 | validation: 4.254654347409526]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2727050119009204		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.2727050119009204 | validation: 3.997820384811713]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9256854964065706		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.9256854964065706 | validation: 3.8838804078955116]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9479904411428914		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.9479904411428914 | validation: 5.47809939632994]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8387267889390397		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.8387267889390397 | validation: 4.355141035829425]
	TIME [epoch: 24.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0476282294947503		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.0476282294947503 | validation: 3.9090725425345396]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0830285775458486		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.0830285775458486 | validation: 4.097603487902699]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.93107142346637		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 2.93107142346637 | validation: 4.177185074034307]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.07247492872537		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.07247492872537 | validation: 4.313985196495532]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1757894320130706		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.1757894320130706 | validation: 3.8457421383353325]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0021729974353004		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.0021729974353004 | validation: 3.882103211917906]
	TIME [epoch: 24.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.186045912766982		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.186045912766982 | validation: 3.8530891831515293]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.951289203463255		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.951289203463255 | validation: 4.083361696786009]
	TIME [epoch: 24.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.992518815794411		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 2.992518815794411 | validation: 3.790299931332549]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.887782288839837		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.887782288839837 | validation: 4.061646753950626]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.205128203066732		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.205128203066732 | validation: 3.835097139833509]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9199495082503124		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.9199495082503124 | validation: 4.462536199246121]
	TIME [epoch: 24.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0212107886349115		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.0212107886349115 | validation: 5.025174808060718]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.321340927987518		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.321340927987518 | validation: 4.446652007856407]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.098244872317937		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.098244872317937 | validation: 3.926025910549393]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.846686277863739		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.846686277863739 | validation: 3.8081502191169]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9113056428943596		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.9113056428943596 | validation: 3.7769410798030605]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.068376374160332		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.068376374160332 | validation: 3.7682742013645787]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9459063431030716		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.9459063431030716 | validation: 3.7608669744395002]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0448426375246584		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.0448426375246584 | validation: 3.9275118499243997]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.905093163161197		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.905093163161197 | validation: 3.754284551180366]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799444442802691		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.799444442802691 | validation: 3.868595938606284]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.783665678028803		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.783665678028803 | validation: 4.5972279393478415]
	TIME [epoch: 24.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9746000013343443		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.9746000013343443 | validation: 3.7975420628743466]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7760229306666138		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.7760229306666138 | validation: 4.034259828715981]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.940858546118903		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.940858546118903 | validation: 4.423365669800948]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.032177360127606		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.032177360127606 | validation: 4.0517935155193365]
	TIME [epoch: 24.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.934645342317762		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.934645342317762 | validation: 4.170258556980602]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.987295910670616		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.987295910670616 | validation: 3.834624506176886]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7713686720491553		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.7713686720491553 | validation: 4.089316164662005]
	TIME [epoch: 24.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.058274731701828		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.058274731701828 | validation: 3.9551488944386164]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8690483911627		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.8690483911627 | validation: 3.847463412198531]
	TIME [epoch: 24.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.774874508276847		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.774874508276847 | validation: 4.204186829978993]
	TIME [epoch: 24.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.913029747600368		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.913029747600368 | validation: 4.282953528268584]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296965306179241		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.296965306179241 | validation: 4.307825022379108]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9721632332007593		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.9721632332007593 | validation: 4.451050444715141]
	TIME [epoch: 24.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.051677951994199		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.051677951994199 | validation: 4.0158513221445755]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817697261570202		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.817697261570202 | validation: 3.8229319400195756]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.896639825824768		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.896639825824768 | validation: 3.9252858255327308]
	TIME [epoch: 24.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8140885863591367		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.8140885863591367 | validation: 4.139754906080126]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.039485564727623		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.039485564727623 | validation: 4.028206264430245]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.849254301910811		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.849254301910811 | validation: 3.7476557891947953]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7552665327676826		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.7552665327676826 | validation: 4.181256592809666]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.866787876266344		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.866787876266344 | validation: 4.126756834599693]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8489706471451766		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.8489706471451766 | validation: 3.795151675466248]
	TIME [epoch: 24.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.839574666533685		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.839574666533685 | validation: 3.790900441579653]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8497736563462164		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.8497736563462164 | validation: 3.696905313565185]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7728341281241033		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.7728341281241033 | validation: 3.7902572110234267]
	TIME [epoch: 24.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6659640329242054		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.6659640329242054 | validation: 3.7307195606279313]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7154197655827277		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.7154197655827277 | validation: 3.8164827379867807]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7425497492654705		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.7425497492654705 | validation: 3.8068572923088015]
	TIME [epoch: 24.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7075522150943607		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.7075522150943607 | validation: 3.866885106618677]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.942577131148447		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.942577131148447 | validation: 3.719212814109556]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9163645867632546		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.9163645867632546 | validation: 3.843185818759599]
	TIME [epoch: 24.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8863680147743382		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.8863680147743382 | validation: 3.6823314492705057]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9181988666584537		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.9181988666584537 | validation: 3.7403973928769503]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9580157147521926		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.9580157147521926 | validation: 4.1385249403848245]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9366559913886627		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.9366559913886627 | validation: 4.186527576966371]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.872723072428321		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.872723072428321 | validation: 3.872465131941051]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.721863279615816		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.721863279615816 | validation: 3.7137359601891826]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.675343529327807		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.675343529327807 | validation: 3.7441056125358507]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7171490828578806		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.7171490828578806 | validation: 3.8024717979246767]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.651999228755499		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.651999228755499 | validation: 3.8785990875222973]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.732952345528318		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.732952345528318 | validation: 3.7200760604352503]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0649023465419503		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.0649023465419503 | validation: 3.8378133332589064]
	TIME [epoch: 24.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9765614083100482		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.9765614083100482 | validation: 3.744899254667678]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.800607495782864		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.800607495782864 | validation: 3.70409973961086]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6180048129730418		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.6180048129730418 | validation: 3.6555518578856927]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6841847659804516		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.6841847659804516 | validation: 4.003553285606623]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8008484213356577		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.8008484213356577 | validation: 3.868630937918049]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.810332369034252		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.810332369034252 | validation: 3.6955162472029297]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8361265157706104		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.8361265157706104 | validation: 3.7156862699942628]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724921077682533		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.724921077682533 | validation: 3.6371372505611577]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7663324539131415		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.7663324539131415 | validation: 3.8474759973509247]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7999634200721863		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.7999634200721863 | validation: 3.6910670272148933]
	TIME [epoch: 24.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.778970250423311		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.778970250423311 | validation: 3.709143414241962]
	TIME [epoch: 24.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.974952731537596		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.974952731537596 | validation: 3.8391593722109456]
	TIME [epoch: 24.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8302538311948786		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.8302538311948786 | validation: 4.02421179366945]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8744463693509306		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.8744463693509306 | validation: 4.024526053868883]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818942264653835		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.818942264653835 | validation: 4.1528480593133725]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0187404941664804		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.0187404941664804 | validation: 3.7028183869325404]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.640976177776839		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.640976177776839 | validation: 3.95449841455136]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7317978812558836		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.7317978812558836 | validation: 3.8489617008556922]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.736026588507631		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.736026588507631 | validation: 4.035311505915241]
	TIME [epoch: 24.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776778020414614		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.776778020414614 | validation: 3.945570961079411]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7073756469638384		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.7073756469638384 | validation: 3.734652854689418]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8227096809100374		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.8227096809100374 | validation: 3.834416957337104]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724250606660453		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.724250606660453 | validation: 3.6761071216276906]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75188858931438		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.75188858931438 | validation: 3.9744503796348067]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7131828693375697		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.7131828693375697 | validation: 3.65185267323396]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.765546641037637		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.765546641037637 | validation: 3.825079026142148]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.676947577062938		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.676947577062938 | validation: 3.9253025821069127]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6880866503631538		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.6880866503631538 | validation: 3.7499662830784493]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.710495753441333		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.710495753441333 | validation: 3.9121374799934565]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7836068719077125		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.7836068719077125 | validation: 3.875900377511824]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.73059789108636		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.73059789108636 | validation: 3.7379351663166434]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.840436289360856		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.840436289360856 | validation: 3.9034746689816644]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6837750999078716		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.6837750999078716 | validation: 4.320954222227935]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8208995251416766		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.8208995251416766 | validation: 3.806312705380473]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677493906340333		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.6677493906340333 | validation: 3.8637277484041364]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.683020554107363		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.683020554107363 | validation: 3.9540755474675597]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7025711038481837		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.7025711038481837 | validation: 3.689122933772511]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7255828000335347		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.7255828000335347 | validation: 3.66480164917699]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.71306727980828		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.71306727980828 | validation: 3.7749162824855005]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6287510026413266		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.6287510026413266 | validation: 3.62529059238225]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6076017980204593		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.6076017980204593 | validation: 3.8451053678234497]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.70820366167132		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.70820366167132 | validation: 3.9562597537614552]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.735401806889605		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.735401806889605 | validation: 3.9726100281850503]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.792737723074224		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.792737723074224 | validation: 3.745907976391423]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.618843825982778		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.618843825982778 | validation: 3.964817298436867]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7057036466887037		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.7057036466887037 | validation: 4.144772560886519]
	TIME [epoch: 24.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.737788360223603		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.737788360223603 | validation: 3.988738575101895]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780573044301958		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.780573044301958 | validation: 4.21973290613429]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8343880780276294		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.8343880780276294 | validation: 3.8835165031747363]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6259688256208293		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.6259688256208293 | validation: 3.645790655014152]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.700400714323259		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.700400714323259 | validation: 3.6829486102491513]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6708082765043377		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.6708082765043377 | validation: 3.674284438296327]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6279325002310734		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.6279325002310734 | validation: 3.7004061575069342]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.687991239448466		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.687991239448466 | validation: 3.703599927672257]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6520662429782003		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.6520662429782003 | validation: 3.6937269771714503]
	TIME [epoch: 24.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6216855846468627		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.6216855846468627 | validation: 4.170175651154683]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.721875705496082		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.721875705496082 | validation: 3.781431484192747]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.822360521876381		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.822360521876381 | validation: 3.870034450259578]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8601389041578402		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.8601389041578402 | validation: 3.882950111810577]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7042997925477095		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.7042997925477095 | validation: 3.6249852728187153]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.01714998010787		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 3.01714998010787 | validation: 3.876540224949431]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8681570061038575		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.8681570061038575 | validation: 4.224283443998336]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801854240765787		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.801854240765787 | validation: 3.991908733146322]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6727281091543573		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.6727281091543573 | validation: 3.8356444391881483]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6416147355603474		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.6416147355603474 | validation: 3.6849070702926467]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.580742734258382		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.580742734258382 | validation: 3.6690470833131528]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6951494786468437		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.6951494786468437 | validation: 3.646695984162593]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.703953773594651		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.703953773594651 | validation: 3.756542696430171]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6067541240145617		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.6067541240145617 | validation: 3.652589226514913]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6760694537004337		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.6760694537004337 | validation: 3.65332200733494]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7036871861788567		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.7036871861788567 | validation: 3.8201425219829384]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6368758801624104		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.6368758801624104 | validation: 3.657397980329025]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6825380216537607		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.6825380216537607 | validation: 3.9084070528030646]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.724669149020425		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.724669149020425 | validation: 3.7102942752749044]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.602143353743217		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.602143353743217 | validation: 3.7713967126597]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6215299447981866		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.6215299447981866 | validation: 3.7738411546504627]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6264255379411		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.6264255379411 | validation: 3.645513171969111]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7611506934923282		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.7611506934923282 | validation: 4.242017114109249]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.742891843047241		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.742891843047241 | validation: 3.884116767132275]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6510687684238303		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.6510687684238303 | validation: 3.7301480377669396]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.62625763896472		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.62625763896472 | validation: 3.756991641783042]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5942608968128056		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.5942608968128056 | validation: 3.624050282211015]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.607773560343652		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.607773560343652 | validation: 3.737853326480737]
	TIME [epoch: 24.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6357669291665595		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.6357669291665595 | validation: 3.6786610546247847]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.57593822889019		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.57593822889019 | validation: 3.99294938018838]
	TIME [epoch: 24.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7067321207328607		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.7067321207328607 | validation: 3.6424943082835637]
	TIME [epoch: 24.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5836346755485713		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.5836346755485713 | validation: 3.6218690806733735]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6864087031668804		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.6864087031668804 | validation: 3.8296349751847165]
	TIME [epoch: 24.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6724753704770796		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.6724753704770796 | validation: 3.6525249259886468]
	TIME [epoch: 24.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.67350978348252		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.67350978348252 | validation: 3.6229794855273934]
	TIME [epoch: 24.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.674632605769479		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.674632605769479 | validation: 3.7096992788587637]
	TIME [epoch: 24.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7671982912340187		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.7671982912340187 | validation: 4.006912009694139]
	TIME [epoch: 24.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7378180631339992		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.7378180631339992 | validation: 3.7963730408323006]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.662238443727265		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.662238443727265 | validation: 3.7500652454870784]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5951365361177237		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.5951365361177237 | validation: 3.6686905637398293]
	TIME [epoch: 24.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5509700951295127		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.5509700951295127 | validation: 4.102323126443991]
	TIME [epoch: 24.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6888703138455665		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.6888703138455665 | validation: 4.065844770348798]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7747157865582275		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.7747157865582275 | validation: 3.962422193346849]
	TIME [epoch: 24.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.70077768574001		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.70077768574001 | validation: 3.931637544831385]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.675904252804238		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.675904252804238 | validation: 3.692558152310975]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64193272098617		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.64193272098617 | validation: 3.6702504457317224]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6221447911949984		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.6221447911949984 | validation: 3.6222255282239146]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6576118086646168		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.6576118086646168 | validation: 3.6215620852850443]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.751740990024149		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.751740990024149 | validation: 3.753405108499027]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6475359529537057		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.6475359529537057 | validation: 3.7839155750246354]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6009151301544264		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.6009151301544264 | validation: 3.793643177067031]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5887855334028274		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.5887855334028274 | validation: 3.6587036012685066]
	TIME [epoch: 24.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.703719933440753		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.703719933440753 | validation: 3.9751329783590728]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6880373629015657		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.6880373629015657 | validation: 3.756971490936843]
	TIME [epoch: 24.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6140940154454335		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.6140940154454335 | validation: 3.6225588458907034]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589113867470814		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.589113867470814 | validation: 3.965159989587383]
	TIME [epoch: 24.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6896967352219034		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.6896967352219034 | validation: 3.6613832381945772]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6846476822084253		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.6846476822084253 | validation: 3.7694318274224496]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.550407192097443		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.550407192097443 | validation: 3.70909414065757]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6399579443201113		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.6399579443201113 | validation: 3.7067405353994545]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6373553386622		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.6373553386622 | validation: 3.6689574418443978]
	TIME [epoch: 24.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.585353629291328		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.585353629291328 | validation: 3.6560493483125147]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.560076434032055		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.560076434032055 | validation: 3.844919779579158]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5981819585462995		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.5981819585462995 | validation: 3.823413167196997]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.687217016279375		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.687217016279375 | validation: 3.612283438453191]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.529188471888544		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.529188471888544 | validation: 3.852327147474041]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6027260306098285		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.6027260306098285 | validation: 3.6154716016417603]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.710634275680525		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.710634275680525 | validation: 3.927678210245728]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.634677333651527		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.634677333651527 | validation: 3.664546510651271]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.596153627996322		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.596153627996322 | validation: 3.6874218639329515]
	TIME [epoch: 24.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5866683600239107		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.5866683600239107 | validation: 3.6488789202189413]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6046852948692596		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.6046852948692596 | validation: 3.638033619675367]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6824714787649593		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.6824714787649593 | validation: 3.64396729938219]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.660718216499667		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.660718216499667 | validation: 3.8248558519329037]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.623596153179876		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.623596153179876 | validation: 3.6669841731052544]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5964967870862017		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.5964967870862017 | validation: 3.593674726895267]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.675324359438242		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.675324359438242 | validation: 3.596772761544719]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6011027175713006		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.6011027175713006 | validation: 3.727567043064488]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7578734840428454		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.7578734840428454 | validation: 3.631050039735844]
	TIME [epoch: 24.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5220968593695003		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.5220968593695003 | validation: 3.8113961270590404]
	TIME [epoch: 24.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6157768997397577		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.6157768997397577 | validation: 3.654124677137142]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.598898899684439		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.598898899684439 | validation: 3.6912288519191834]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6004750274487476		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.6004750274487476 | validation: 3.763202700624898]
	TIME [epoch: 24.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7455115941440202		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.7455115941440202 | validation: 3.8127744332564575]
	TIME [epoch: 24.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6011208663411107		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.6011208663411107 | validation: 3.6110905973087823]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6029278044769484		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.6029278044769484 | validation: 3.7090614742654777]
	TIME [epoch: 24.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.75398892896537		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.75398892896537 | validation: 3.943404880242474]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6545629584623813		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.6545629584623813 | validation: 3.6429293861779026]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.635409972342645		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.635409972342645 | validation: 4.051687282167749]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6448597185936693		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.6448597185936693 | validation: 3.7957942025847355]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577676034412006		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.577676034412006 | validation: 3.759331695434429]
	TIME [epoch: 24.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6768482160243074		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.6768482160243074 | validation: 3.6932486915782805]
	TIME [epoch: 24.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.552048533816847		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.552048533816847 | validation: 3.762949453193527]
	TIME [epoch: 24.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.643865547379198		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.643865547379198 | validation: 3.7134719869341337]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.587838758683681		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.587838758683681 | validation: 3.583707382616583]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5450737902226868		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.5450737902226868 | validation: 3.6326646895376156]
	TIME [epoch: 24.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5524265241138018		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.5524265241138018 | validation: 3.5953550900647144]
	TIME [epoch: 24.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8151055896307873		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.8151055896307873 | validation: 3.6453315795151036]
	TIME [epoch: 24.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6246526606792715		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.6246526606792715 | validation: 3.6750881342512947]
	TIME [epoch: 24.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5289921207817625		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.5289921207817625 | validation: 3.6224969084085092]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.599191343914169		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.599191343914169 | validation: 3.6205005726887873]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.641533347128001		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.641533347128001 | validation: 3.6398364931505984]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.682924757048509		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.682924757048509 | validation: 3.751267453891045]
	TIME [epoch: 24.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6852854228745824		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.6852854228745824 | validation: 3.806243114552517]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5689080734187963		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.5689080734187963 | validation: 3.6683283192223293]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.565121267193037		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.565121267193037 | validation: 3.9276043304421653]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5606903828154812		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.5606903828154812 | validation: 3.7147227994722973]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5420031972963355		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.5420031972963355 | validation: 3.5710788647079794]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509809796057442		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.509809796057442 | validation: 3.6995422748889086]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5595825510270567		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.5595825510270567 | validation: 3.5794709628571106]
	TIME [epoch: 24.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.56527831230314		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.56527831230314 | validation: 3.799029826640129]
	TIME [epoch: 24.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.53573275720957		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.53573275720957 | validation: 3.593378525729528]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4905420590544765		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.4905420590544765 | validation: 3.8806846919580282]
	TIME [epoch: 24.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.631215441037266		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.631215441037266 | validation: 4.016540851641739]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7147716092959113		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.7147716092959113 | validation: 3.6307616769780124]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5199093509726227		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.5199093509726227 | validation: 3.617569034068348]
	TIME [epoch: 24.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.534333803420658		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.534333803420658 | validation: 3.594930148251066]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4904381621100944		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.4904381621100944 | validation: 3.794637481652076]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5336673398696345		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.5336673398696345 | validation: 3.8992421717820664]
	TIME [epoch: 24.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5672363118458623		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.5672363118458623 | validation: 3.6390656947872935]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5267353972528603		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.5267353972528603 | validation: 3.5634383132576164]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7006276134755103		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.7006276134755103 | validation: 3.5998162190292446]
	TIME [epoch: 24.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5218802519042214		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.5218802519042214 | validation: 3.647179271202786]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.694207497679497		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.694207497679497 | validation: 3.8478170366634776]
	TIME [epoch: 24.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.576930100115948		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.576930100115948 | validation: 3.604641409198709]
	TIME [epoch: 24.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4600717023562884		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.4600717023562884 | validation: 3.578074826888923]
	TIME [epoch: 24.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4753091172493193		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.4753091172493193 | validation: 3.7351009046089145]
	TIME [epoch: 24.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5225606515724275		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.5225606515724275 | validation: 3.546845598451171]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4774657566575264		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.4774657566575264 | validation: 3.543758981937076]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5147126244909104		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.5147126244909104 | validation: 3.65798687582936]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.586567688566914		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.586567688566914 | validation: 3.5688289322511126]
	TIME [epoch: 24.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.853616858385905		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.853616858385905 | validation: 3.643488846333995]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5050585889048333		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.5050585889048333 | validation: 3.5850133249242755]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570976205541124		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.570976205541124 | validation: 3.6636607450683916]
	TIME [epoch: 24.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4769623682221376		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.4769623682221376 | validation: 3.5545989884732045]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461523006507522		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.461523006507522 | validation: 3.687244896930355]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5468126851607766		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.5468126851607766 | validation: 3.5391757820136367]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471848136196998		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.471848136196998 | validation: 3.707684366849013]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.478679828127725		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.478679828127725 | validation: 3.5708130767274486]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449186020563206		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.449186020563206 | validation: 3.5910021647786494]
	TIME [epoch: 24.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4196917373729843		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.4196917373729843 | validation: 3.681506660543316]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50919483274205		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.50919483274205 | validation: 3.532548958946218]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48956387785015		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.48956387785015 | validation: 3.5653917350282733]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4983002517734416		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.4983002517734416 | validation: 3.552304992815583]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459679402508021		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.459679402508021 | validation: 3.6444488638746497]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5930160056353886		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.5930160056353886 | validation: 3.6013688780903492]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.481815232003582		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.481815232003582 | validation: 3.527644426891211]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.448531616918142		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.448531616918142 | validation: 3.6088465926891553]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4527278713451857		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.4527278713451857 | validation: 3.5432869875659048]
	TIME [epoch: 24.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5394971924491507		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.5394971924491507 | validation: 3.954611168669909]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558671696283177		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.558671696283177 | validation: 3.599540060650623]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4692579325184916		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.4692579325184916 | validation: 3.6234934375380368]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4837700225969135		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.4837700225969135 | validation: 3.542451554860934]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5295355160145085		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.5295355160145085 | validation: 3.7556767207284043]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.588433292847844		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.588433292847844 | validation: 3.579681612647746]
	TIME [epoch: 24.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5468923292427768		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.5468923292427768 | validation: 3.665400159581244]
	TIME [epoch: 24.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5476701923318865		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.5476701923318865 | validation: 3.619722156961909]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6054419244724025		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.6054419244724025 | validation: 3.710510963081988]
	TIME [epoch: 24.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5592513055922783		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.5592513055922783 | validation: 3.627489546347614]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7732883376628292		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.7732883376628292 | validation: 3.6102542059545484]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.481356775308799		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.481356775308799 | validation: 3.7173199660349967]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5210172593202875		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.5210172593202875 | validation: 3.5734139578483384]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5654114958003724		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.5654114958003724 | validation: 3.5785308577137]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.445371707938747		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.445371707938747 | validation: 3.6413489412545195]
	TIME [epoch: 24.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4921797677743736		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.4921797677743736 | validation: 3.528831881930921]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4697128213782884		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.4697128213782884 | validation: 3.5548472458414295]
	TIME [epoch: 24.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471220849086139		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.471220849086139 | validation: 3.571344870379129]
	TIME [epoch: 24.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.479124799492081		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.479124799492081 | validation: 3.5224576760660558]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4554788450768887		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.4554788450768887 | validation: 3.534427265699403]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416628713948158		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.416628713948158 | validation: 3.5487636519768184]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4595314444482272		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.4595314444482272 | validation: 3.5475110773897662]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5125581551135587		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.5125581551135587 | validation: 3.5343014199821448]
	TIME [epoch: 24.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5330727791296885		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.5330727791296885 | validation: 3.6542965276172006]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.515158832136297		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.515158832136297 | validation: 3.5969700259676087]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4085598362969467		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.4085598362969467 | validation: 3.569607380498575]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5906229503799554		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.5906229503799554 | validation: 3.570592493125224]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4634913287553215		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.4634913287553215 | validation: 3.609367294912289]
	TIME [epoch: 24.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452684696912378		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.452684696912378 | validation: 3.6632966844675936]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4841308872801413		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.4841308872801413 | validation: 3.5736657903823117]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4332032472693452		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.4332032472693452 | validation: 3.538153641216806]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.550655167255046		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.550655167255046 | validation: 3.629105079700793]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4975381720522827		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.4975381720522827 | validation: 3.608509386924913]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.68353563618468		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.68353563618468 | validation: 3.5158767127345563]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5071048537209855		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.5071048537209855 | validation: 3.9800959294152687]
	TIME [epoch: 24.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.605405468415706		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.605405468415706 | validation: 3.53349906578404]
	TIME [epoch: 24.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4373806378576957		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.4373806378576957 | validation: 3.5339633316798564]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4094386126392413		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.4094386126392413 | validation: 3.775068047622402]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7126739147987555		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.7126739147987555 | validation: 3.67807571807684]
	TIME [epoch: 24.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4571508072873334		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.4571508072873334 | validation: 3.5548993314294894]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4031045005659193		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.4031045005659193 | validation: 3.54381767428291]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6407861012523464		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.6407861012523464 | validation: 3.5004258654240887]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3740607464326664		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.3740607464326664 | validation: 3.9010934188038178]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.548267813644001		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.548267813644001 | validation: 3.5130772300848783]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4562821006058546		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.4562821006058546 | validation: 3.558276145699855]
	TIME [epoch: 24.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5092375063051597		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.5092375063051597 | validation: 3.503845950468132]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4120102250317323		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.4120102250317323 | validation: 3.7551815559368715]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4846550129660074		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.4846550129660074 | validation: 3.6472769944850474]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.457155284959483		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.457155284959483 | validation: 3.738908883105229]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.498943532248644		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.498943532248644 | validation: 3.611608769240821]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5400862980334145		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.5400862980334145 | validation: 3.5064514303669068]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5857973004359955		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.5857973004359955 | validation: 3.54588588600882]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.440356887452436		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.440356887452436 | validation: 3.721714701191971]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473298214203493		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.473298214203493 | validation: 3.5114311903193105]
	TIME [epoch: 24.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.401359091576657		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.401359091576657 | validation: 3.6504196004299097]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471059586812207		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.471059586812207 | validation: 3.5180294771164986]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3874391213065462		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.3874391213065462 | validation: 3.5328506082021716]
	TIME [epoch: 24.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3940490107999692		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.3940490107999692 | validation: 3.5537219600009866]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.429116773556508		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.429116773556508 | validation: 3.7114886111036527]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4765014999951833		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.4765014999951833 | validation: 3.5751327082657127]
	TIME [epoch: 24.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4143855737558457		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.4143855737558457 | validation: 3.5382098898952274]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4383707906786096		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.4383707906786096 | validation: 3.6725515401287794]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4118737905299783		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.4118737905299783 | validation: 3.6775298614584884]
	TIME [epoch: 24.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4654786363838204		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.4654786363838204 | validation: 3.536567074387375]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3920684931954432		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.3920684931954432 | validation: 3.534343964466135]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3829361704362344		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.3829361704362344 | validation: 3.5182384265356643]
	TIME [epoch: 24.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4645810107037405		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.4645810107037405 | validation: 3.5958774756309944]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3986260071489873		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.3986260071489873 | validation: 3.511317500556363]
	TIME [epoch: 24.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482708917755623		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.482708917755623 | validation: 3.52188976786095]
	TIME [epoch: 24.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.508230623246063		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.508230623246063 | validation: 3.667018275131848]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438690002131498		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.438690002131498 | validation: 3.5765750237989744]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4615863703783742		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.4615863703783742 | validation: 3.5290204630600295]
	TIME [epoch: 24.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3858854350292322		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.3858854350292322 | validation: 3.5217394959096104]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391862811648833		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.391862811648833 | validation: 3.5213114637647385]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3733500749777523		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.3733500749777523 | validation: 3.575108617017368]
	TIME [epoch: 24.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4013609204737483		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.4013609204737483 | validation: 3.68250294658141]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.507522367117397		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.507522367117397 | validation: 3.619651961485656]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5008013488277037		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.5008013488277037 | validation: 3.534023465309734]
	TIME [epoch: 24.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3934494229462904		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.3934494229462904 | validation: 3.5534671679257803]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.439237886704011		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.439237886704011 | validation: 3.5332284848065614]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379405044722957		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.379405044722957 | validation: 3.5153651939117556]
	TIME [epoch: 24.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5221323264242272		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.5221323264242272 | validation: 3.675363803934571]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5221378436586326		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.5221378436586326 | validation: 3.6091530923177153]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460815969096605		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.460815969096605 | validation: 3.5701473321739705]
	TIME [epoch: 24.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450285731972754		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.450285731972754 | validation: 3.6760726999993656]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.562111235893487		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.562111235893487 | validation: 3.8109869643851813]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50684758927251		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.50684758927251 | validation: 3.5237523403737385]
	TIME [epoch: 24.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4175896723174537		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.4175896723174537 | validation: 3.5619581321262297]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.402661710060429		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.402661710060429 | validation: 3.524992738850969]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384318261704532		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.384318261704532 | validation: 3.525726660161638]
	TIME [epoch: 24.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.436272654443904		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.436272654443904 | validation: 3.6184871061327044]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4150736769408994		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.4150736769408994 | validation: 3.5445562009457228]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4725642205512086		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.4725642205512086 | validation: 3.566217383237394]
	TIME [epoch: 24.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4597407859314897		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.4597407859314897 | validation: 3.6273041963495185]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.475275603802335		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.475275603802335 | validation: 3.5203910123023343]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4183147551323523		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.4183147551323523 | validation: 3.710611087030553]
	TIME [epoch: 24.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4744946618456782		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.4744946618456782 | validation: 3.6050056151604695]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3972245934268743		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.3972245934268743 | validation: 3.504609489515358]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4107931161180147		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.4107931161180147 | validation: 3.564545708854231]
	TIME [epoch: 24.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4149589516115952		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.4149589516115952 | validation: 3.518213859245867]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4045526491200677		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.4045526491200677 | validation: 3.5799807700355206]
	TIME [epoch: 24.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4448276854681583		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.4448276854681583 | validation: 3.5908806482067654]
	TIME [epoch: 24.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468396630488882		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.468396630488882 | validation: 3.5464222118420405]
	TIME [epoch: 24.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409352289892817		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.409352289892817 | validation: 3.5800748532973796]
	TIME [epoch: 24.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424764514484585		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.424764514484585 | validation: 3.5501069386951447]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4255102289075094		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.4255102289075094 | validation: 3.569975284057972]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.434181872487146		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.434181872487146 | validation: 3.6024644363556058]
	TIME [epoch: 24.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4293111840942885		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.4293111840942885 | validation: 3.504591863639735]
	TIME [epoch: 24.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4082423163485913		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.4082423163485913 | validation: 3.644527716658704]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4223836649503228		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.4223836649503228 | validation: 3.5839961844193295]
	TIME [epoch: 24.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4427989759555953		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.4427989759555953 | validation: 3.502294002797471]
	TIME [epoch: 24.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4186345565986684		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.4186345565986684 | validation: 3.5412591095576555]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435982798434677		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.435982798434677 | validation: 3.5944007449120354]
	TIME [epoch: 24.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4563690203141464		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.4563690203141464 | validation: 3.6762188613305153]
	TIME [epoch: 24.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.441761150871399		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.441761150871399 | validation: 3.6363890610724714]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4260131062553185		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.4260131062553185 | validation: 3.563568576046073]
	TIME [epoch: 24.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415825250853483		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.415825250853483 | validation: 3.5045001149799426]
	TIME [epoch: 24.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4208228762788457		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.4208228762788457 | validation: 3.65260400778362]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.439703483365901		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.439703483365901 | validation: 3.532890832482383]
	TIME [epoch: 24.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4075761207859974		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.4075761207859974 | validation: 3.6117207218113356]
	TIME [epoch: 24.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4366676992968626		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.4366676992968626 | validation: 3.545196401964797]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3968653102769957		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.3968653102769957 | validation: 3.549560724503609]
	TIME [epoch: 24.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4334312754610496		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.4334312754610496 | validation: 3.9833259392723988]
	TIME [epoch: 24.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6216165291157103		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.6216165291157103 | validation: 3.598753851364809]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4264722236261904		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.4264722236261904 | validation: 3.5645691244529476]
	TIME [epoch: 24.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3926803612620335		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.3926803612620335 | validation: 3.5489259005013087]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3909579172675186		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.3909579172675186 | validation: 3.5779711660272846]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435748824377709		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.435748824377709 | validation: 3.7752977543473794]
	TIME [epoch: 24.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5076059398517514		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.5076059398517514 | validation: 3.5282358318151514]
	TIME [epoch: 24.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410511188124776		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.410511188124776 | validation: 3.65569786906271]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4492043991845973		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.4492043991845973 | validation: 3.5140374626046484]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4199719911999296		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.4199719911999296 | validation: 3.512776535260093]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43225922399305		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.43225922399305 | validation: 3.522521282755696]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.434513286576275		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.434513286576275 | validation: 3.501064432174838]
	TIME [epoch: 24.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.456693950436828		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.456693950436828 | validation: 3.6451369118392503]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4720605143552836		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.4720605143552836 | validation: 3.6152403163783915]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.546144699935399		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.546144699935399 | validation: 3.5703639546815737]
	TIME [epoch: 24.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.393900130478818		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.393900130478818 | validation: 3.5259817070570283]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3921585546274327		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.3921585546274327 | validation: 3.5351194394524614]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398286451457337		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.398286451457337 | validation: 3.5179795301489456]
	TIME [epoch: 24.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4311370406644968		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.4311370406644968 | validation: 3.511028156238579]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4376648078273995		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.4376648078273995 | validation: 3.515498974177482]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3993125062548684		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.3993125062548684 | validation: 3.535234979373556]
	TIME [epoch: 24.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3960191105794464		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.3960191105794464 | validation: 3.508746352939186]
	TIME [epoch: 24.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4400849616823836		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.4400849616823836 | validation: 3.6840544023699007]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5470256715475186		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.5470256715475186 | validation: 3.5385191631035724]
	TIME [epoch: 24.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395492067829559		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.395492067829559 | validation: 3.5424243824679764]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3915505614018073		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.3915505614018073 | validation: 3.528106196773307]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.390708971313399		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.390708971313399 | validation: 3.5540405102187584]
	TIME [epoch: 24.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.476016001200157		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.476016001200157 | validation: 3.6250747574315647]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4672004434944306		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.4672004434944306 | validation: 3.5853776386153577]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4981609905339086		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.4981609905339086 | validation: 3.684603042809948]
	TIME [epoch: 24.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4134353531551316		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.4134353531551316 | validation: 3.549185724156813]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4048403646058807		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.4048403646058807 | validation: 3.522345488809981]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.389431481909296		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.389431481909296 | validation: 3.569124041069472]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460318947834042		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.460318947834042 | validation: 3.547258468372653]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4111021540777005		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.4111021540777005 | validation: 3.5147453200424073]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369835721108956		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.369835721108956 | validation: 3.565661311039111]
	TIME [epoch: 24.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3930523159361248		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.3930523159361248 | validation: 3.5313805455627265]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4401813136663817		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.4401813136663817 | validation: 3.5690997757276497]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.399302198608196		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.399302198608196 | validation: 3.6097406446706986]
	TIME [epoch: 24.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4653998688003873		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.4653998688003873 | validation: 3.527861282738898]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383639563933246		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.383639563933246 | validation: 3.561370438607781]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.392264081647201		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.392264081647201 | validation: 3.6134470142349437]
	TIME [epoch: 24.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409764770977339		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.409764770977339 | validation: 3.542051420229685]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385699907062226		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.385699907062226 | validation: 3.545707409801851]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430557169511506		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.430557169511506 | validation: 3.535117650986311]
	TIME [epoch: 24.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.429179327240922		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.429179327240922 | validation: 3.5358105665255124]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3961206168609888		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.3961206168609888 | validation: 3.504321901747444]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459897300078121		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.459897300078121 | validation: 3.5330406978795557]
	TIME [epoch: 24.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377055648519688		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.377055648519688 | validation: 3.5332284425351363]
	TIME [epoch: 24.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4455261435535087		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.4455261435535087 | validation: 3.810541715548375]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5217717648807514		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.5217717648807514 | validation: 3.657764990777707]
	TIME [epoch: 24.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4031473344954217		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.4031473344954217 | validation: 3.674556693246385]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5037049698853426		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.5037049698853426 | validation: 3.5657701984370185]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3886349533097335		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.3886349533097335 | validation: 3.5230495699577626]
	TIME [epoch: 24.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4002798345389316		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.4002798345389316 | validation: 3.5607322349562422]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4022975191455362		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.4022975191455362 | validation: 3.4950685522798417]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397383545063248		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.397383545063248 | validation: 3.6691101155525696]
	TIME [epoch: 24.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4743427016265036		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.4743427016265036 | validation: 3.742619910577905]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4982668680672964		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.4982668680672964 | validation: 3.5364679433619632]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430652325125486		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.430652325125486 | validation: 3.550418624358191]
	TIME [epoch: 24.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414707395145613		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.414707395145613 | validation: 3.505182021193424]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379683723617771		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.379683723617771 | validation: 3.4933036802325024]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.422500078453073		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.422500078453073 | validation: 3.4957471792977617]
	TIME [epoch: 24.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.526524385556978		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.526524385556978 | validation: 3.670007779795773]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446611223501943		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.446611223501943 | validation: 3.4945505206465852]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.407191193113393		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.407191193113393 | validation: 3.534588548185448]
	TIME [epoch: 24.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3946497490587637		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.3946497490587637 | validation: 3.5136752950677876]
	TIME [epoch: 24.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368509710006962		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.368509710006962 | validation: 3.5506239297201168]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3772403508957516		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.3772403508957516 | validation: 3.60214967955748]
	TIME [epoch: 24.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4266980744771365		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.4266980744771365 | validation: 3.5619714517527257]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4029923261942847		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.4029923261942847 | validation: 3.509232184228705]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3745912916602023		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.3745912916602023 | validation: 3.5693540399238857]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405876224144209		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.405876224144209 | validation: 3.5161654542063956]
	TIME [epoch: 24.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410940616154157		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.410940616154157 | validation: 3.5177469561564014]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4162988883002408		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.4162988883002408 | validation: 3.5084872039501955]
	TIME [epoch: 24.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3659656258542907		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.3659656258542907 | validation: 3.5165348964337877]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386855402849479		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.386855402849479 | validation: 3.6543944168493665]
	TIME [epoch: 24.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4088026942603196		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.4088026942603196 | validation: 3.5416989961473866]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3757712083875813		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.3757712083875813 | validation: 3.658801801139036]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.421948966068414		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.421948966068414 | validation: 3.632736513102161]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4349670493155546		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.4349670493155546 | validation: 3.755169722401537]
	TIME [epoch: 24.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.459003866842866		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.459003866842866 | validation: 3.490747816419327]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_657.pth
	Model improved!!!
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3798911825062388		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.3798911825062388 | validation: 3.4967495809964886]
	TIME [epoch: 24.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3941240958063696		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.3941240958063696 | validation: 3.6356106355782423]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3982144642995813		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.3982144642995813 | validation: 3.4802714159922723]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_660.pth
	Model improved!!!
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3768940166532175		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.3768940166532175 | validation: 3.5104835091239046]
	TIME [epoch: 24.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3665825437754533		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.3665825437754533 | validation: 3.488921272120641]
	TIME [epoch: 24.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4005412139098707		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.4005412139098707 | validation: 3.6324848826977525]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4129507633339164		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.4129507633339164 | validation: 3.487294287928129]
	TIME [epoch: 24.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.406578496131625		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.406578496131625 | validation: 3.5318384552049737]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3885876180303685		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.3885876180303685 | validation: 3.488519982148285]
	TIME [epoch: 24.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4310101640608295		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.4310101640608295 | validation: 3.483135385020125]
	TIME [epoch: 24.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.35998066526058		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.35998066526058 | validation: 3.664246368817044]
	TIME [epoch: 24.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4550524249825325		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.4550524249825325 | validation: 3.4909257935131133]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398231933258961		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.398231933258961 | validation: 3.5464551197330354]
	TIME [epoch: 24.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.403326886058516		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.403326886058516 | validation: 3.49414111757357]
	TIME [epoch: 24.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.352382593948237		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.352382593948237 | validation: 3.577371344275552]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3941275257642465		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.3941275257642465 | validation: 3.5695712374371835]
	TIME [epoch: 24.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.404083765415356		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.404083765415356 | validation: 3.5274185044899147]
	TIME [epoch: 24.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4065429197200077		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.4065429197200077 | validation: 3.496039129516798]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.389016337864633		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.389016337864633 | validation: 3.526561678206947]
	TIME [epoch: 24.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3903413365748394		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.3903413365748394 | validation: 3.51491671589692]
	TIME [epoch: 24.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3570846281102433		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.3570846281102433 | validation: 3.4819778991437964]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3653271093853867		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.3653271093853867 | validation: 3.5623065047087312]
	TIME [epoch: 24.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4144963887324344		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.4144963887324344 | validation: 3.4923160293138826]
	TIME [epoch: 24.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369544846614574		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.369544846614574 | validation: 3.5456254617792324]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.38508354232715		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.38508354232715 | validation: 3.616696879386657]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4185130717365126		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.4185130717365126 | validation: 3.47771373209531]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3563259292577756		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.3563259292577756 | validation: 3.5086470209337093]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.374042413014548		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.374042413014548 | validation: 3.506941488800549]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3616437206983965		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.3616437206983965 | validation: 3.4908689923606335]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368390716424359		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.368390716424359 | validation: 3.738477350249506]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4703026752613706		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.4703026752613706 | validation: 3.4915979189507618]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384948003925217		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.384948003925217 | validation: 3.4907921675033413]
	TIME [epoch: 24.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359238754060641		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.359238754060641 | validation: 3.551227905184153]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380707727273407		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.380707727273407 | validation: 3.484902918352257]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4154813899328405		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.4154813899328405 | validation: 3.4806486377958197]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3497536544561317		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.3497536544561317 | validation: 3.565953089936461]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420392762213678		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.420392762213678 | validation: 3.615360392717297]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408040955116557		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.408040955116557 | validation: 3.5701983223134666]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364767911573456		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.364767911573456 | validation: 3.5911021649302315]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3929938560241832		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.3929938560241832 | validation: 3.479703912532217]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358058123618643		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.358058123618643 | validation: 3.565587417222171]
	TIME [epoch: 24.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4004053123796245		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.4004053123796245 | validation: 3.612995836929248]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.406054324620525		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.406054324620525 | validation: 3.5042028152721634]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41194623687876		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.41194623687876 | validation: 3.494610909740442]
	TIME [epoch: 24.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3592884907766822		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.3592884907766822 | validation: 3.498306171569675]
	TIME [epoch: 24.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3546058197806574		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.3546058197806574 | validation: 3.4864299426823164]
	TIME [epoch: 24.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366329313106281		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.366329313106281 | validation: 3.4940660135508232]
	TIME [epoch: 24.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408512181969438		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.408512181969438 | validation: 3.5704303131340276]
	TIME [epoch: 24.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377386183287349		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.377386183287349 | validation: 3.5028270740793466]
	TIME [epoch: 24.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355508037366144		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.355508037366144 | validation: 3.535919845834564]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365553758716533		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.365553758716533 | validation: 3.583997435168438]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3820846927968136		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.3820846927968136 | validation: 3.5940069699317694]
	TIME [epoch: 24.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3930992466769214		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.3930992466769214 | validation: 3.5069224295058166]
	TIME [epoch: 24.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361867025439221		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.361867025439221 | validation: 3.5016250310306725]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4435673903394		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.4435673903394 | validation: 3.4861789373266374]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3507672563585515		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.3507672563585515 | validation: 3.504416692130533]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341570309279732		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.341570309279732 | validation: 3.5546122197882006]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3851915003533226		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.3851915003533226 | validation: 3.506543735351853]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360125187759306		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.360125187759306 | validation: 3.4882041625028637]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3575873913215935		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.3575873913215935 | validation: 3.534398608495028]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345413421862557		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.345413421862557 | validation: 3.5254993293869816]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3895885783465842		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.3895885783465842 | validation: 3.5293627255633]
	TIME [epoch: 24.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365644074247788		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.365644074247788 | validation: 3.495159203451146]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3818952169170613		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.3818952169170613 | validation: 3.5384233146549704]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396427857010894		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.396427857010894 | validation: 3.4864713706872856]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375808235205336		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.375808235205336 | validation: 3.5196760434966405]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4315011900796897		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.4315011900796897 | validation: 3.464812953726119]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4240770339181097		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.4240770339181097 | validation: 3.487153845933434]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395165942515115		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.395165942515115 | validation: 3.4771919225086036]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3426465310663933		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.3426465310663933 | validation: 3.529250246449998]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369047451304204		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.369047451304204 | validation: 3.485657787698543]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375691465374067		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.375691465374067 | validation: 3.5147903826343767]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3728940910982512		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.3728940910982512 | validation: 3.486815879255902]
	TIME [epoch: 24.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3403761815239443		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.3403761815239443 | validation: 3.485979257565619]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3642841280386127		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.3642841280386127 | validation: 3.569578806541714]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3807279793811102		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.3807279793811102 | validation: 3.513279514216587]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366687287308992		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.366687287308992 | validation: 3.5303559680175396]
	TIME [epoch: 24.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3603802952470785		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.3603802952470785 | validation: 3.5019977004537033]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3623770885089526		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.3623770885089526 | validation: 3.5083811440573416]
	TIME [epoch: 24.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343375884649105		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.343375884649105 | validation: 3.5792095128262007]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3867839812685383		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.3867839812685383 | validation: 3.521953754946212]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.371717371774256		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.371717371774256 | validation: 3.475874845446553]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3679925437904417		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.3679925437904417 | validation: 3.5027125180974417]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3490485802580956		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.3490485802580956 | validation: 3.480572549934767]
	TIME [epoch: 24.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3460086778013887		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.3460086778013887 | validation: 3.468521308692075]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3510956062994226		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.3510956062994226 | validation: 3.5382801904955272]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382405256103346		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.382405256103346 | validation: 3.57372006105136]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397867181918822		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.397867181918822 | validation: 3.6037443555279634]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4144112139227567		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.4144112139227567 | validation: 3.507052025384238]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3485963281459097		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.3485963281459097 | validation: 3.4874107490252952]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3791464841014838		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.3791464841014838 | validation: 3.5299124411280407]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343967534322588		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.343967534322588 | validation: 3.4849634222808983]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3401583601454945		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.3401583601454945 | validation: 3.4883272492077366]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395960945601966		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.395960945601966 | validation: 3.5190334412868918]
	TIME [epoch: 24.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3643507221010216		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.3643507221010216 | validation: 3.516936356046904]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3608287192745125		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.3608287192745125 | validation: 3.485428744136318]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418677879055888		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.418677879055888 | validation: 3.6266408850548406]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.415655167484782		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.415655167484782 | validation: 3.5343038202222896]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355429556674446		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.355429556674446 | validation: 3.48026456807553]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338185478037741		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.338185478037741 | validation: 3.4809668613466545]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33368711159214		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.33368711159214 | validation: 3.4741246477292664]
	TIME [epoch: 24.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341562629730128		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.341562629730128 | validation: 3.484108002232809]
	TIME [epoch: 24.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420464458474444		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.420464458474444 | validation: 3.4799555215134768]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3534804132121536		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.3534804132121536 | validation: 3.530319767398849]
	TIME [epoch: 24.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367108027076435		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.367108027076435 | validation: 3.47272348861733]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.356292295357652		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.356292295357652 | validation: 3.4932012087977906]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3441113275407672		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.3441113275407672 | validation: 3.491480263384621]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3992062490447794		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.3992062490447794 | validation: 3.466646544192691]
	TIME [epoch: 24.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3294207909604787		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.3294207909604787 | validation: 3.481944764912537]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345023076926603		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.345023076926603 | validation: 3.492772017805529]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3482983230714565		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.3482983230714565 | validation: 3.485675080113534]
	TIME [epoch: 24.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3801203468031837		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.3801203468031837 | validation: 3.4713753232757347]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344722635941164		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.344722635941164 | validation: 3.5106336982038577]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3427901700312264		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.3427901700312264 | validation: 3.493094290434947]
	TIME [epoch: 24.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3509535914455		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.3509535914455 | validation: 3.48926322755476]
	TIME [epoch: 24.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4273771462337836		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.4273771462337836 | validation: 3.494669811347386]
	TIME [epoch: 24.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337513357223859		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.337513357223859 | validation: 3.4801024990442033]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3260544391919873		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.3260544391919873 | validation: 3.4748264669615425]
	TIME [epoch: 24.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3372632976518726		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.3372632976518726 | validation: 3.491613486658673]
	TIME [epoch: 24.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3612559476005233		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.3612559476005233 | validation: 3.4831046283230704]
	TIME [epoch: 24.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361256423150708		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.361256423150708 | validation: 3.5664391897607612]
	TIME [epoch: 24.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450357181919977		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.450357181919977 | validation: 3.481539432557817]
	TIME [epoch: 24.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3259561544033778		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.3259561544033778 | validation: 3.4994494525707727]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.387406275642883		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.387406275642883 | validation: 3.5714017483577094]
	TIME [epoch: 24.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3874844668084108		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.3874844668084108 | validation: 3.481980660195959]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332944634690872		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.332944634690872 | validation: 3.511820785000017]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3497431042112242		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.3497431042112242 | validation: 3.6423424494492984]
	TIME [epoch: 24.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4651181293206315		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.4651181293206315 | validation: 3.490595897780733]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.339807313727368		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.339807313727368 | validation: 3.496976955471017]
	TIME [epoch: 24.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336762052951933		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.336762052951933 | validation: 3.478190154434231]
	TIME [epoch: 24.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3354469651687904		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.3354469651687904 | validation: 3.4952413937961757]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.339886718902134		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.339886718902134 | validation: 3.479770772776927]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346985776625674		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.346985776625674 | validation: 3.5819638855150004]
	TIME [epoch: 24.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359527715882816		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.359527715882816 | validation: 3.4867808260925877]
	TIME [epoch: 24.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337356147171031		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.337356147171031 | validation: 3.4724065467757566]
	TIME [epoch: 24.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335215605250201		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.335215605250201 | validation: 3.489400072182907]
	TIME [epoch: 24.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3366592764428415		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.3366592764428415 | validation: 3.4730131756689935]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3597885503449127		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.3597885503449127 | validation: 3.4962865220008195]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3499182614598357		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.3499182614598357 | validation: 3.4760994781197043]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3344260776900154		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.3344260776900154 | validation: 3.477498643017829]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328193071226763		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.328193071226763 | validation: 3.4694829361291206]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.352973684825421		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.352973684825421 | validation: 3.487932815345664]
	TIME [epoch: 24.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3575776784687625		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.3575776784687625 | validation: 3.6223277119045294]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.400394184701866		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.400394184701866 | validation: 3.501966703681726]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33898406747495		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.33898406747495 | validation: 3.476298189660349]
	TIME [epoch: 24.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334481374981836		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.334481374981836 | validation: 3.4842009862579255]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4131393699477766		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.4131393699477766 | validation: 3.51657979290158]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348718827141167		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.348718827141167 | validation: 3.4978216012771237]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3383058284654403		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.3383058284654403 | validation: 3.4786991926002915]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3315384177409455		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.3315384177409455 | validation: 3.4797881347262765]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3567244890464667		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.3567244890464667 | validation: 3.507249486151271]
	TIME [epoch: 24.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3494056376669112		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.3494056376669112 | validation: 3.5156623686249167]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.370519744685061		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.370519744685061 | validation: 3.4778179173066945]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.339742044427507		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.339742044427507 | validation: 3.4824938736585684]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337285819478255		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.337285819478255 | validation: 3.4838873310764185]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381451155514599		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.381451155514599 | validation: 3.5131908931974154]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354564097060498		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.354564097060498 | validation: 3.4786137764545946]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3427810440083916		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.3427810440083916 | validation: 3.476263543232302]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338444082900572		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.338444082900572 | validation: 3.513440997191422]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358801354850493		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.358801354850493 | validation: 3.4838829995068252]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37938529273335		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.37938529273335 | validation: 3.4707953485153054]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354890752117847		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.354890752117847 | validation: 3.466575946201229]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3434464675475852		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.3434464675475852 | validation: 3.4832133624134]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3383329949522484		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.3383329949522484 | validation: 3.4774647417378173]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3635106085750124		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.3635106085750124 | validation: 3.5217764952485293]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342923025924235		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.342923025924235 | validation: 3.468759030184137]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333101896997434		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.333101896997434 | validation: 3.4581909127065757]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332066390815495		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.332066390815495 | validation: 3.5292232718648915]
	TIME [epoch: 24.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3525356817610814		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.3525356817610814 | validation: 3.5821265859519555]
	TIME [epoch: 24.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4052544156882707		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.4052544156882707 | validation: 3.489672619583732]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3564017521983955		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.3564017521983955 | validation: 3.513851888711965]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3904986585840957		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.3904986585840957 | validation: 3.5226873230344586]
	TIME [epoch: 24.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362333147530108		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.362333147530108 | validation: 3.4942487376515157]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3462537766217206		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.3462537766217206 | validation: 3.5447841491018925]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373739326965786		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.373739326965786 | validation: 3.4804899492035783]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3290728579604068		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.3290728579604068 | validation: 3.505071799479639]
	TIME [epoch: 24.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3561021907089255		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.3561021907089255 | validation: 3.478474909434658]
	TIME [epoch: 24.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337520903789198		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.337520903789198 | validation: 3.4708261127045636]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3335911231459456		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.3335911231459456 | validation: 3.4686940599189455]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345699582878342		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.345699582878342 | validation: 3.499165566962189]
	TIME [epoch: 24.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330042219291899		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.330042219291899 | validation: 3.485780299722343]
	TIME [epoch: 24.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334985240500998		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.334985240500998 | validation: 3.547903123145481]
	TIME [epoch: 24.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391740129529462		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.391740129529462 | validation: 3.477452430460666]
	TIME [epoch: 24.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3336264485533436		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.3336264485533436 | validation: 3.4677080197354972]
	TIME [epoch: 24.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3570334410267852		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.3570334410267852 | validation: 3.577608052481216]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367408166674202		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.367408166674202 | validation: 3.48328726240996]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323331478679208		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.323331478679208 | validation: 3.492278892266701]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33369370429809		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.33369370429809 | validation: 3.475398164328593]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3419880798493873		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.3419880798493873 | validation: 3.4687686586972517]
	TIME [epoch: 24.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3172755046592233		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.3172755046592233 | validation: 3.5006481407568146]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3523468584334233		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.3523468584334233 | validation: 3.4665850714276143]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3375181767723596		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.3375181767723596 | validation: 3.4753820836284515]
	TIME [epoch: 24.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3209327552910324		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.3209327552910324 | validation: 3.483311001736786]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347215152129863		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.347215152129863 | validation: 3.5111666545140183]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32904889151314		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.32904889151314 | validation: 3.4985141696520974]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345851936182642		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.345851936182642 | validation: 3.4966676219309853]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3513539357967432		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.3513539357967432 | validation: 3.5969830318487754]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409629005644079		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.409629005644079 | validation: 3.4617367258382217]
	TIME [epoch: 24.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3151592359797775		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.3151592359797775 | validation: 3.516381698872357]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3400056088704164		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.3400056088704164 | validation: 3.4733317695930244]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329742817838313		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.329742817838313 | validation: 3.476189902258815]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3162962820091986		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.3162962820091986 | validation: 3.4942517433388414]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333846210048472		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.333846210048472 | validation: 3.4781770036827107]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327465040371949		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.327465040371949 | validation: 3.482315529275657]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3296437000366		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.3296437000366 | validation: 3.6757526997923096]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41338845105638		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.41338845105638 | validation: 3.5506888315157683]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369737610000612		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.369737610000612 | validation: 3.5073089307868726]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33766069676504		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.33766069676504 | validation: 3.476237805833313]
	TIME [epoch: 24.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3350579502605715		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.3350579502605715 | validation: 3.4965135762063886]
	TIME [epoch: 24.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3481319917342782		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.3481319917342782 | validation: 3.477308708810547]
	TIME [epoch: 24.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3223916995828295		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.3223916995828295 | validation: 3.463562869493323]
	TIME [epoch: 24.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340330620696955		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.340330620696955 | validation: 3.5226604492168905]
	TIME [epoch: 24.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3460556212990578		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.3460556212990578 | validation: 3.4801467441195726]
	TIME [epoch: 24.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337414136835282		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.337414136835282 | validation: 3.5561346203875845]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3683635121462014		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.3683635121462014 | validation: 3.468962218806326]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3180804557232255		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.3180804557232255 | validation: 3.4854824994309763]
	TIME [epoch: 24.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.35447554334615		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.35447554334615 | validation: 3.5243459462380757]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33672545613453		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.33672545613453 | validation: 3.4783113014894607]
	TIME [epoch: 24.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3592404970760033		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.3592404970760033 | validation: 3.4648922686725587]
	TIME [epoch: 24.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31814806806217		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.31814806806217 | validation: 3.4640571881496305]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3316267585309536		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.3316267585309536 | validation: 3.5173109404926777]
	TIME [epoch: 24.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.33573258442823		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.33573258442823 | validation: 3.4494705507470727]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3222499655159394		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.3222499655159394 | validation: 3.472028877039168]
	TIME [epoch: 24.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31573511689864		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.31573511689864 | validation: 3.519605874563074]
	TIME [epoch: 24.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.351097992899391		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.351097992899391 | validation: 3.487718135475623]
	TIME [epoch: 24.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3293559254311447		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.3293559254311447 | validation: 3.4798029927285747]
	TIME [epoch: 24.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350418925634588		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.350418925634588 | validation: 3.4824099163770312]
	TIME [epoch: 24.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3228927451219317		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.3228927451219317 | validation: 3.4814328852388754]
	TIME [epoch: 24.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3239455460833742		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.3239455460833742 | validation: 3.463376144071162]
	TIME [epoch: 24.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3429386446819263		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.3429386446819263 | validation: 3.4748267027027544]
	TIME [epoch: 24.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3200083357527523		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.3200083357527523 | validation: 3.4638561007584623]
	TIME [epoch: 24.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3358582392078526		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.3358582392078526 | validation: 3.466306995746487]
	TIME [epoch: 24.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348903686467314		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.348903686467314 | validation: 3.4686897245647867]
	TIME [epoch: 24.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3347768042523227		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.3347768042523227 | validation: 3.488474335258714]
	TIME [epoch: 24.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350234169535367		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.350234169535367 | validation: 3.4652829948070845]
	TIME [epoch: 24.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3170559383744473		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.3170559383744473 | validation: 3.467847477684312]
	TIME [epoch: 24.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309136218123432		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.309136218123432 | validation: 3.4694169938200363]
	TIME [epoch: 24.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317773972568685		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.317773972568685 | validation: 3.5084335519649357]
	TIME [epoch: 24.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3439921612648282		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.3439921612648282 | validation: 3.4647049453702516]
	TIME [epoch: 24.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347876293200275		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.347876293200275 | validation: 3.4649752790383257]
	TIME [epoch: 24.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3131764419246585		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.3131764419246585 | validation: 3.4668437770937137]
	TIME [epoch: 24.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.348907688740803		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.348907688740803 | validation: 3.475191035401661]
	TIME [epoch: 24.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336612731010886		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.336612731010886 | validation: 3.5005534950402524]
	TIME [epoch: 24.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3375589760549227		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.3375589760549227 | validation: 3.4649273018004543]
	TIME [epoch: 24.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.323077127479058		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.323077127479058 | validation: 3.4857452545630565]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340897915691715		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.340897915691715 | validation: 3.4722247334541168]
	TIME [epoch: 24.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332104926409049		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.332104926409049 | validation: 3.4888231739449247]
	TIME [epoch: 24.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3293715478821233		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.3293715478821233 | validation: 3.509715195895383]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3616263478632913		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.3616263478632913 | validation: 3.4679733630465397]
	TIME [epoch: 24.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3256875228819753		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.3256875228819753 | validation: 3.4779807766426076]
	TIME [epoch: 24.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320442715303003		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.320442715303003 | validation: 3.468601560042309]
	TIME [epoch: 24.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3312675821559607		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.3312675821559607 | validation: 3.479135884409268]
	TIME [epoch: 24.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3302947786791806		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.3302947786791806 | validation: 3.462562760543457]
	TIME [epoch: 24.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330294797773461		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.330294797773461 | validation: 3.552841066582478]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3395152390758165		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.3395152390758165 | validation: 3.450340152520843]
	TIME [epoch: 24.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368495316598397		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.368495316598397 | validation: 3.5468856230931562]
	TIME [epoch: 24.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.338447539869634		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.338447539869634 | validation: 3.475435221739799]
	TIME [epoch: 24.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3309991721015706		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.3309991721015706 | validation: 3.4681803366861574]
	TIME [epoch: 24.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335558104404864		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.335558104404864 | validation: 3.4599758247363925]
	TIME [epoch: 24.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3160353460969354		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.3160353460969354 | validation: 3.4660284164891877]
	TIME [epoch: 24.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313223868829416		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.313223868829416 | validation: 3.453858775338955]
	TIME [epoch: 24.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3134583908401347		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.3134583908401347 | validation: 3.466310301568991]
	TIME [epoch: 24.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318033901063961		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.318033901063961 | validation: 3.4770012833767168]
	TIME [epoch: 24.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318179513108805		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.318179513108805 | validation: 3.6084715039575013]
	TIME [epoch: 24.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.390856988155372		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.390856988155372 | validation: 3.4874780308443114]
	TIME [epoch: 24.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3231198774144284		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.3231198774144284 | validation: 3.482188504829155]
	TIME [epoch: 24.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308064722971553		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.308064722971553 | validation: 3.4691019387879227]
	TIME [epoch: 24.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.370862580252207		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.370862580252207 | validation: 3.4577761953241772]
	TIME [epoch: 24.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3397055355641543		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.3397055355641543 | validation: 3.482679897023246]
	TIME [epoch: 24.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3178411449574297		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.3178411449574297 | validation: 3.4850274329868456]
	TIME [epoch: 24.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3202257014252385		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.3202257014252385 | validation: 3.506694758055982]
	TIME [epoch: 24.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32748360476827		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.32748360476827 | validation: 3.4891878026113488]
	TIME [epoch: 24.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322889338744604		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.322889338744604 | validation: 3.4639712846207638]
	TIME [epoch: 24.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319090321400445		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.319090321400445 | validation: 3.4595774584653145]
	TIME [epoch: 24.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3072073641114508		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.3072073641114508 | validation: 3.4643644943574716]
	TIME [epoch: 24.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3084973501272628		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.3084973501272628 | validation: 3.4830640883680872]
	TIME [epoch: 24.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313322381297459		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.313322381297459 | validation: 3.4752504132497837]
	TIME [epoch: 24.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3201411805950594		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.3201411805950594 | validation: 3.5613719020972066]
	TIME [epoch: 24.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3691429362679557		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.3691429362679557 | validation: 3.4841305366750994]
	TIME [epoch: 24.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3277492964513566		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.3277492964513566 | validation: 3.4544624569533475]
	TIME [epoch: 24.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314293828239979		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.314293828239979 | validation: 3.4889611521975086]
	TIME [epoch: 24.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321627318823226		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.321627318823226 | validation: 3.460088733290768]
	TIME [epoch: 24.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3233461117843492		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.3233461117843492 | validation: 3.4740581311185026]
	TIME [epoch: 24.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332310060491556		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.332310060491556 | validation: 3.486448450384265]
	TIME [epoch: 24.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3305238975684714		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.3305238975684714 | validation: 3.4720023821441477]
	TIME [epoch: 24.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315097617027475		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.315097617027475 | validation: 3.475531037513438]
	TIME [epoch: 24.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3163727634954383		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.3163727634954383 | validation: 3.480819130873191]
	TIME [epoch: 24.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.337507570102905		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.337507570102905 | validation: 3.4869773536333004]
	TIME [epoch: 24.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3310115747712725		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.3310115747712725 | validation: 3.455265322210792]
	TIME [epoch: 24.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3085127709665394		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.3085127709665394 | validation: 3.463718212253448]
	TIME [epoch: 24.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308567382973768		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.308567382973768 | validation: 3.45455173824384]
	TIME [epoch: 24.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311332558253111		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.311332558253111 | validation: 3.464511468842057]
	TIME [epoch: 24.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3191604831869794		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.3191604831869794 | validation: 3.493390754384037]
	TIME [epoch: 24.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3245363700372845		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.3245363700372845 | validation: 3.4570091653396737]
	TIME [epoch: 24.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3096061963027186		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.3096061963027186 | validation: 3.4895450229547156]
	TIME [epoch: 24.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3482301693786996		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.3482301693786996 | validation: 3.4634707021167026]
	TIME [epoch: 24.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3011446949280554		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.3011446949280554 | validation: 3.4724929499786494]
	TIME [epoch: 24.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3095855910347045		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.3095855910347045 | validation: 3.4636701425713246]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3099326845641723		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.3099326845641723 | validation: 3.4655361787755896]
	TIME [epoch: 24.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319358561645736		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.319358561645736 | validation: 3.4801001177451885]
	TIME [epoch: 24.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306565176655448		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.306565176655448 | validation: 3.4843819329124575]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330891095831984		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.330891095831984 | validation: 3.477534100737517]
	TIME [epoch: 24.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3091302304345858		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.3091302304345858 | validation: 3.492626251045911]
	TIME [epoch: 24.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315381327788465		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.315381327788465 | validation: 3.4820043933196088]
	TIME [epoch: 24.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3155320411157487		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.3155320411157487 | validation: 3.4658112741036735]
	TIME [epoch: 24.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302446521425216		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.302446521425216 | validation: 3.486327758162742]
	TIME [epoch: 24.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3487586356645185		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.3487586356645185 | validation: 3.518417871657285]
	TIME [epoch: 24.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3408028851772844		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.3408028851772844 | validation: 3.51041144314014]
	TIME [epoch: 24.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3312378329090437		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.3312378329090437 | validation: 3.459387321014925]
	TIME [epoch: 24.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3040407206510807		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.3040407206510807 | validation: 3.4613691651776413]
	TIME [epoch: 24.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331865918513954		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.331865918513954 | validation: 3.4658520955095127]
	TIME [epoch: 24.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314747850615363		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.314747850615363 | validation: 3.521059272632996]
	TIME [epoch: 24.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3445334973494405		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.3445334973494405 | validation: 3.4618029622980595]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3305587686183555		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.3305587686183555 | validation: 3.4677664984558634]
	TIME [epoch: 24.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3297364220752814		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.3297364220752814 | validation: 3.5316843539112743]
	TIME [epoch: 24.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32592146611394		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.32592146611394 | validation: 3.4526420898083523]
	TIME [epoch: 24.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304618663305099		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.304618663305099 | validation: 3.4545213933449372]
	TIME [epoch: 24.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314607900319759		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.314607900319759 | validation: 3.478620542502765]
	TIME [epoch: 24.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31206468564839		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.31206468564839 | validation: 3.462523540092017]
	TIME [epoch: 24.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309689089154199		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.309689089154199 | validation: 3.4545153913996836]
	TIME [epoch: 24.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310794306788009		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.310794306788009 | validation: 3.453540969632349]
	TIME [epoch: 24.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305015553014165		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.305015553014165 | validation: 3.4577224366497625]
	TIME [epoch: 24.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3012119363323946		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.3012119363323946 | validation: 3.4532956305416445]
	TIME [epoch: 24.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3077410182379965		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.3077410182379965 | validation: 3.483637073860882]
	TIME [epoch: 24.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3151485361126016		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.3151485361126016 | validation: 3.4596979585972436]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305234705519463		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.305234705519463 | validation: 3.4553296966662703]
	TIME [epoch: 24.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3131934156924814		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.3131934156924814 | validation: 3.459592343944194]
	TIME [epoch: 24.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344380505275928		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.344380505275928 | validation: 3.5198607765696908]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3313952022752		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.3313952022752 | validation: 3.4654632775508025]
	TIME [epoch: 24.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319675766790499		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.319675766790499 | validation: 3.4591398887962503]
	TIME [epoch: 24.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301436000549484		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.301436000549484 | validation: 3.4609045418617486]
	TIME [epoch: 24.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.352650360564527		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.352650360564527 | validation: 3.640095540007262]
	TIME [epoch: 24.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.409392395622405		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.409392395622405 | validation: 3.4742421074225622]
	TIME [epoch: 24.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3309979452614122		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.3309979452614122 | validation: 3.4600359569920096]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3051134402978546		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.3051134402978546 | validation: 3.464092577059049]
	TIME [epoch: 24.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3159728293540027		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.3159728293540027 | validation: 3.4615968363684364]
	TIME [epoch: 24.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311634690927419		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.311634690927419 | validation: 3.4589004451798457]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3018906343279224		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.3018906343279224 | validation: 3.487089948833022]
	TIME [epoch: 24.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3199876933048724		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.3199876933048724 | validation: 3.4720025919148454]
	TIME [epoch: 24.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3116214948534575		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.3116214948534575 | validation: 3.475505736052656]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3091718477857754		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.3091718477857754 | validation: 3.4585848769684886]
	TIME [epoch: 24.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30321520214289		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.30321520214289 | validation: 3.51810725675535]
	TIME [epoch: 24.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3645509539961		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.3645509539961 | validation: 3.455969682964932]
	TIME [epoch: 24.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3614560302455643		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.3614560302455643 | validation: 3.4974302185356896]
	TIME [epoch: 24.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3143016823429026		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.3143016823429026 | validation: 3.4553747738807505]
	TIME [epoch: 24.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3141568005857067		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.3141568005857067 | validation: 3.4747644794349806]
	TIME [epoch: 24.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3087063466419595		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.3087063466419595 | validation: 3.457183761431332]
	TIME [epoch: 24.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3510997031067475		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.3510997031067475 | validation: 3.47210547811649]
	TIME [epoch: 24.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3178551065943473		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.3178551065943473 | validation: 3.4599855292556176]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316040849218512		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.316040849218512 | validation: 3.4630315422010565]
	TIME [epoch: 24.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308013388978029		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.308013388978029 | validation: 3.459897079756044]
	TIME [epoch: 24.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299051717119447		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.299051717119447 | validation: 3.457670318689898]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306322287848512		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.306322287848512 | validation: 3.4534028925290703]
	TIME [epoch: 24.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297275842524069		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.297275842524069 | validation: 3.450433770925455]
	TIME [epoch: 24.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3070357496318556		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.3070357496318556 | validation: 3.471257470317529]
	TIME [epoch: 24.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3201770425749526		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.3201770425749526 | validation: 3.487822260295199]
	TIME [epoch: 24.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314908632832512		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.314908632832512 | validation: 3.449559441166357]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3252781646111433		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.3252781646111433 | validation: 3.521995022318821]
	TIME [epoch: 24.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391594001134454		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.391594001134454 | validation: 3.4849735497934224]
	TIME [epoch: 24.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313442243870907		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.313442243870907 | validation: 3.4559865898300943]
	TIME [epoch: 24.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3027001582540376		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.3027001582540376 | validation: 3.4550768381267343]
	TIME [epoch: 24.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3006728056597585		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.3006728056597585 | validation: 3.4591569995046214]
	TIME [epoch: 24.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321261950340666		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.321261950340666 | validation: 3.469096520241667]
	TIME [epoch: 24.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3093351323246982		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.3093351323246982 | validation: 3.4597530134816497]
	TIME [epoch: 24.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307303622754582		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.307303622754582 | validation: 3.461865754438991]
	TIME [epoch: 24.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314408727635836		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.314408727635836 | validation: 3.4553779315475452]
	TIME [epoch: 24.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3121433829208486		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.3121433829208486 | validation: 3.478303480765851]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321932022890022		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.321932022890022 | validation: 3.463314920136942]
	TIME [epoch: 24.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3084617619048124		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.3084617619048124 | validation: 3.460444807047989]
	TIME [epoch: 24.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301924063632188		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.301924063632188 | validation: 3.4815063087063995]
	TIME [epoch: 24.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3560322581311506		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.3560322581311506 | validation: 3.4652780666817256]
	TIME [epoch: 24.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299629815102524		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.299629815102524 | validation: 3.4465881888382697]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_1029.pth
	Model improved!!!
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296036443356057		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.296036443356057 | validation: 3.449213493794605]
	TIME [epoch: 24.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313570583939125		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.313570583939125 | validation: 3.473286052744004]
	TIME [epoch: 24.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2981312796868583		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.2981312796868583 | validation: 3.442196393761847]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_1032.pth
	Model improved!!!
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3023380471253496		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.3023380471253496 | validation: 3.4499521587270894]
	TIME [epoch: 24.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3086302061016077		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.3086302061016077 | validation: 3.4815407356040384]
	TIME [epoch: 24.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3020199370876817		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.3020199370876817 | validation: 3.4782629545494026]
	TIME [epoch: 24.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318049448497158		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.318049448497158 | validation: 3.4761100991761373]
	TIME [epoch: 24.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301668048550254		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.301668048550254 | validation: 3.449585776438703]
	TIME [epoch: 24.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3037587789046037		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.3037587789046037 | validation: 3.4479392717655144]
	TIME [epoch: 24.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3058263760068387		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.3058263760068387 | validation: 3.501181872730803]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3131159472120837		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.3131159472120837 | validation: 3.4489105752002183]
	TIME [epoch: 24.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3139849687991845		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.3139849687991845 | validation: 3.464658168174605]
	TIME [epoch: 24.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300735555962385		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.300735555962385 | validation: 3.454863678118591]
	TIME [epoch: 24.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3014967005473164		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.3014967005473164 | validation: 3.4915115008034254]
	TIME [epoch: 24.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3459802235498306		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.3459802235498306 | validation: 3.4560794538811592]
	TIME [epoch: 24.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317452758657522		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.317452758657522 | validation: 3.4594592365097725]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296184874473126		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.296184874473126 | validation: 3.4904915582424696]
	TIME [epoch: 24.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3115024170221026		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.3115024170221026 | validation: 3.4567657956800986]
	TIME [epoch: 24.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31309058453049		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.31309058453049 | validation: 3.468724013538618]
	TIME [epoch: 24.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3536359561506623		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.3536359561506623 | validation: 3.547949843141995]
	TIME [epoch: 24.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3246503824381555		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.3246503824381555 | validation: 3.4598266637966173]
	TIME [epoch: 24.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2941144195268017		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.2941144195268017 | validation: 3.462470241509269]
	TIME [epoch: 24.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2972671207021746		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.2972671207021746 | validation: 3.4540994176360282]
	TIME [epoch: 24.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3082461673607613		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.3082461673607613 | validation: 3.459820646168363]
	TIME [epoch: 24.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305597223603502		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.305597223603502 | validation: 3.4458783517583673]
	TIME [epoch: 24.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2978024339413805		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.2978024339413805 | validation: 3.4450677123256623]
	TIME [epoch: 24.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.300899316611622		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.300899316611622 | validation: 3.451631288572003]
	TIME [epoch: 24.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303008409816313		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.303008409816313 | validation: 3.4451627690748454]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2898682049643573		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.2898682049643573 | validation: 3.4641087282092986]
	TIME [epoch: 24.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2916394836451235		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.2916394836451235 | validation: 3.450378510297799]
	TIME [epoch: 24.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2970994617360008		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.2970994617360008 | validation: 3.4562960910125065]
	TIME [epoch: 24.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298110946630091		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.298110946630091 | validation: 3.448758254103667]
	TIME [epoch: 24.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2968585308086378		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.2968585308086378 | validation: 3.458573664064957]
	TIME [epoch: 24.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296590665384607		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.296590665384607 | validation: 3.448109644313584]
	TIME [epoch: 24.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2942889723113646		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.2942889723113646 | validation: 3.4517555110101057]
	TIME [epoch: 24.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3037056963660723		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.3037056963660723 | validation: 3.4449653643049976]
	TIME [epoch: 24.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3122372857565443		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.3122372857565443 | validation: 3.459081966406368]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3106914641907332		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.3106914641907332 | validation: 3.478828918779799]
	TIME [epoch: 24.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312233317715916		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.312233317715916 | validation: 3.4516447571653135]
	TIME [epoch: 24.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294516788232669		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.294516788232669 | validation: 3.463052533086199]
	TIME [epoch: 24.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3037333060210643		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.3037333060210643 | validation: 3.449278220529761]
	TIME [epoch: 24.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2973098725364074		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.2973098725364074 | validation: 3.460166581079964]
	TIME [epoch: 24.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3080744160386097		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.3080744160386097 | validation: 3.466269278913361]
	TIME [epoch: 24.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298471255873495		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.298471255873495 | validation: 3.444495492375493]
	TIME [epoch: 24.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2958593734938435		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.2958593734938435 | validation: 3.4583829771999195]
	TIME [epoch: 24.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001496308599148		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.3001496308599148 | validation: 3.4451173869083163]
	TIME [epoch: 24.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314844817961514		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.314844817961514 | validation: 3.494555484930092]
	TIME [epoch: 24.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3286949777364776		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.3286949777364776 | validation: 3.447996247324562]
	TIME [epoch: 24.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291841988354608		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.291841988354608 | validation: 3.453181301478029]
	TIME [epoch: 24.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3075728751881974		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.3075728751881974 | validation: 3.44911960671481]
	TIME [epoch: 24.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2953701833712303		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.2953701833712303 | validation: 3.4531058042713303]
	TIME [epoch: 24.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2943849869184207		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.2943849869184207 | validation: 3.4504897152371603]
	TIME [epoch: 24.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929317992633815		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.2929317992633815 | validation: 3.4577407008549397]
	TIME [epoch: 24.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3009076823113883		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.3009076823113883 | validation: 3.45617743975645]
	TIME [epoch: 24.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308505434067552		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.308505434067552 | validation: 3.453274518974581]
	TIME [epoch: 24.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298103996343849		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.298103996343849 | validation: 3.4494723823374502]
	TIME [epoch: 24.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2900078142008917		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.2900078142008917 | validation: 3.4600104625041515]
	TIME [epoch: 24.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297771271339765		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.297771271339765 | validation: 3.4707157772194024]
	TIME [epoch: 24.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296053111392851		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.296053111392851 | validation: 3.450432173942942]
	TIME [epoch: 24.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2978108918500944		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.2978108918500944 | validation: 3.4475324169699544]
	TIME [epoch: 24.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303315606696133		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.303315606696133 | validation: 3.448885480015962]
	TIME [epoch: 24.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292740458808909		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.292740458808909 | validation: 3.4572020446346774]
	TIME [epoch: 24.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2985921755101386		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.2985921755101386 | validation: 3.4566207432681213]
	TIME [epoch: 24.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3052220382113897		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.3052220382113897 | validation: 3.4582458186496945]
	TIME [epoch: 24.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3249866681489193		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.3249866681489193 | validation: 3.4646463936438243]
	TIME [epoch: 24.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3001059420435386		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.3001059420435386 | validation: 3.4512442563916537]
	TIME [epoch: 24.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3006414170303877		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.3006414170303877 | validation: 3.4569351251478917]
	TIME [epoch: 24.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2941455945539024		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.2941455945539024 | validation: 3.4435098788946754]
	TIME [epoch: 24.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288405987635896		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.288405987635896 | validation: 3.4517617514569485]
	TIME [epoch: 24.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3022052809541353		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.3022052809541353 | validation: 3.4472839199690943]
	TIME [epoch: 24.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288152482616878		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.288152482616878 | validation: 3.4543071664135194]
	TIME [epoch: 24.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2971154131663205		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.2971154131663205 | validation: 3.4618853133252503]
	TIME [epoch: 24.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293152714845024		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.293152714845024 | validation: 3.4615026479698754]
	TIME [epoch: 24.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2959414456626956		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.2959414456626956 | validation: 3.462774243679862]
	TIME [epoch: 24.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301474598045995		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.301474598045995 | validation: 3.462192578081873]
	TIME [epoch: 24.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30009146893569		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.30009146893569 | validation: 3.456873292920436]
	TIME [epoch: 24.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3004419620395895		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.3004419620395895 | validation: 3.446199672889219]
	TIME [epoch: 24.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3106347909997695		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.3106347909997695 | validation: 3.4564974508577633]
	TIME [epoch: 24.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318482008461368		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.318482008461368 | validation: 3.5189451535770546]
	TIME [epoch: 24.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326689292228163		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.326689292228163 | validation: 3.4535725505190067]
	TIME [epoch: 24.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2934976149343873		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.2934976149343873 | validation: 3.446701298343814]
	TIME [epoch: 24.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2899942590397213		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.2899942590397213 | validation: 3.4598765853161924]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292969266487127		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.292969266487127 | validation: 3.4515893473840893]
	TIME [epoch: 24.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2932349553625353		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.2932349553625353 | validation: 3.4548533931439107]
	TIME [epoch: 24.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287933308328785		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.287933308328785 | validation: 3.446028789843169]
	TIME [epoch: 24.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294730143252615		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.294730143252615 | validation: 3.4455809233237393]
	TIME [epoch: 24.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29405782211309		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.29405782211309 | validation: 3.449806944338466]
	TIME [epoch: 24.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293400046427276		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.293400046427276 | validation: 3.466637283333371]
	TIME [epoch: 24.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2980698458632025		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.2980698458632025 | validation: 3.450671843090713]
	TIME [epoch: 24.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297601029732033		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.297601029732033 | validation: 3.4578402828492267]
	TIME [epoch: 24.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2997279033395435		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.2997279033395435 | validation: 3.4443785697359175]
	TIME [epoch: 24.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2915689641719372		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.2915689641719372 | validation: 3.457203348785747]
	TIME [epoch: 24.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2974123248237244		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.2974123248237244 | validation: 3.451254017831165]
	TIME [epoch: 24.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2959235605839203		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.2959235605839203 | validation: 3.462593086995546]
	TIME [epoch: 24.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2991113131315055		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.2991113131315055 | validation: 3.4555711316656947]
	TIME [epoch: 24.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2945562016439824		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.2945562016439824 | validation: 3.450531736664932]
	TIME [epoch: 24.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2996477890256397		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.2996477890256397 | validation: 3.4517433372017754]
	TIME [epoch: 24.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2942277120995684		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.2942277120995684 | validation: 3.4464769343403407]
	TIME [epoch: 24.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298434423590197		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.298434423590197 | validation: 3.4741664293989594]
	TIME [epoch: 24.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310172764388879		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.310172764388879 | validation: 3.447634344320547]
	TIME [epoch: 24.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3038166768683572		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.3038166768683572 | validation: 3.465099481709609]
	TIME [epoch: 24.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909741547139237		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.2909741547139237 | validation: 3.4729681460106883]
	TIME [epoch: 24.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2999228198598356		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.2999228198598356 | validation: 3.4515829676998226]
	TIME [epoch: 24.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306418571297529		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.306418571297529 | validation: 3.4520019949875915]
	TIME [epoch: 24.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2944816169236426		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.2944816169236426 | validation: 3.4616956197795306]
	TIME [epoch: 24.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306523029173592		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.306523029173592 | validation: 3.4548437485002994]
	TIME [epoch: 24.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2878102639004547		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.2878102639004547 | validation: 3.4554743143336437]
	TIME [epoch: 24.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297448862672323		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.297448862672323 | validation: 3.435514594207567]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_1137.pth
	Model improved!!!
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2888120656532305		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.2888120656532305 | validation: 3.455264980552251]
	TIME [epoch: 24.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287866790154495		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.287866790154495 | validation: 3.4496742157213793]
	TIME [epoch: 24.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2920495806208696		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.2920495806208696 | validation: 3.4473060041591794]
	TIME [epoch: 24.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2938681548980746		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.2938681548980746 | validation: 3.453108335435217]
	TIME [epoch: 24.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2887033175274256		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.2887033175274256 | validation: 3.4424228545807694]
	TIME [epoch: 24.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290997622910221		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.290997622910221 | validation: 3.454190940463444]
	TIME [epoch: 24.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290342690241645		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.290342690241645 | validation: 3.456358442142024]
	TIME [epoch: 24.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2928069073035124		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.2928069073035124 | validation: 3.4639736461074895]
	TIME [epoch: 24.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2998641122815853		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.2998641122815853 | validation: 3.453050171324221]
	TIME [epoch: 24.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2916319016397666		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.2916319016397666 | validation: 3.4621810315194295]
	TIME [epoch: 24.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2911763656154447		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.2911763656154447 | validation: 3.4555866884990434]
	TIME [epoch: 24.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2890347538244202		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.2890347538244202 | validation: 3.445094389375711]
	TIME [epoch: 24.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862086397278065		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.2862086397278065 | validation: 3.4473115206086824]
	TIME [epoch: 24.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2918525292042893		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.2918525292042893 | validation: 3.4750096578117944]
	TIME [epoch: 24.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30683903853571		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.30683903853571 | validation: 3.4478621380136283]
	TIME [epoch: 24.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28659045896243		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.28659045896243 | validation: 3.4583360476878813]
	TIME [epoch: 24.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2921122606023028		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.2921122606023028 | validation: 3.4758856409697882]
	TIME [epoch: 24.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305894324701681		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.305894324701681 | validation: 3.461817025096298]
	TIME [epoch: 24.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310348374769229		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.310348374769229 | validation: 3.451286918178849]
	TIME [epoch: 24.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2998116997871283		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.2998116997871283 | validation: 3.4451866704921175]
	TIME [epoch: 24.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2935439943987634		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.2935439943987634 | validation: 3.4524264179740327]
	TIME [epoch: 24.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288776735178733		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.288776735178733 | validation: 3.456662762183818]
	TIME [epoch: 24.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2952754346097333		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.2952754346097333 | validation: 3.456099563813016]
	TIME [epoch: 24.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293203030198429		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.293203030198429 | validation: 3.449024504323097]
	TIME [epoch: 24.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2971133346135577		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.2971133346135577 | validation: 3.452772596049418]
	TIME [epoch: 24.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2903630101668897		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.2903630101668897 | validation: 3.4580483779503863]
	TIME [epoch: 24.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2912834133205413		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.2912834133205413 | validation: 3.4545431711282406]
	TIME [epoch: 24.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2932471591478416		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.2932471591478416 | validation: 3.451041797302614]
	TIME [epoch: 24.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3029618805656207		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.3029618805656207 | validation: 3.4606058285303276]
	TIME [epoch: 24.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2934732732942082		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.2934732732942082 | validation: 3.4434096633923184]
	TIME [epoch: 24.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2991537670973647		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.2991537670973647 | validation: 3.489216849709477]
	TIME [epoch: 24.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2999862622896963		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 2.2999862622896963 | validation: 3.458130715578983]
	TIME [epoch: 24.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312094051800229		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 2.312094051800229 | validation: 3.448868612946398]
	TIME [epoch: 24.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2831471689240233		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 2.2831471689240233 | validation: 3.448111916320972]
	TIME [epoch: 24.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2942647954442568		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 2.2942647954442568 | validation: 3.444113539654805]
	TIME [epoch: 24.8 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2950003085379884		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 2.2950003085379884 | validation: 3.4490035629093727]
	TIME [epoch: 24.8 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2809043833067473		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 2.2809043833067473 | validation: 3.457644210283096]
	TIME [epoch: 24.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2881429413894487		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 2.2881429413894487 | validation: 3.4482048845929656]
	TIME [epoch: 24.8 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3035890223772757		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 2.3035890223772757 | validation: 3.458222183394902]
	TIME [epoch: 24.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317428549755316		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 2.317428549755316 | validation: 3.5012073444719425]
	TIME [epoch: 24.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325174493280985		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 2.325174493280985 | validation: 3.452153632199181]
	TIME [epoch: 24.8 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288217229881866		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 2.288217229881866 | validation: 3.446813259686329]
	TIME [epoch: 24.8 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291213426140546		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 2.291213426140546 | validation: 3.451173472322546]
	TIME [epoch: 24.8 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2874009929440065		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 2.2874009929440065 | validation: 3.445616559997626]
	TIME [epoch: 24.8 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282461936914678		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 2.282461936914678 | validation: 3.445691751496846]
	TIME [epoch: 25.2 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287930361430227		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 2.287930361430227 | validation: 3.4684469906095194]
	TIME [epoch: 24.8 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2896803344244323		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 2.2896803344244323 | validation: 3.4424059138262124]
	TIME [epoch: 24.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286177214365188		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 2.286177214365188 | validation: 3.4412581744990502]
	TIME [epoch: 24.8 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2809906228025025		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 2.2809906228025025 | validation: 3.446918265773555]
	TIME [epoch: 24.8 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292102117401602		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 2.292102117401602 | validation: 3.4603286728735725]
	TIME [epoch: 24.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2927636223999315		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 2.2927636223999315 | validation: 3.4532430088903165]
	TIME [epoch: 24.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288789826858893		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 2.288789826858893 | validation: 3.4650236830911245]
	TIME [epoch: 24.8 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2986501625915214		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 2.2986501625915214 | validation: 3.4426346028432024]
	TIME [epoch: 24.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3013513123155973		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 2.3013513123155973 | validation: 3.4540734703088414]
	TIME [epoch: 24.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2897703941864265		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 2.2897703941864265 | validation: 3.454020921011902]
	TIME [epoch: 24.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289862598077387		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 2.289862598077387 | validation: 3.463869587062069]
	TIME [epoch: 24.8 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2926485325678043		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 2.2926485325678043 | validation: 3.447843501544306]
	TIME [epoch: 24.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2887549403269536		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 2.2887549403269536 | validation: 3.441537305086807]
	TIME [epoch: 24.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287851700022488		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 2.287851700022488 | validation: 3.4474381701622896]
	TIME [epoch: 24.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287290847123281		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 2.287290847123281 | validation: 3.4495041649347185]
	TIME [epoch: 24.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29430509092614		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 2.29430509092614 | validation: 3.457031446114378]
	TIME [epoch: 24.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2977925192358617		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 2.2977925192358617 | validation: 3.4418719817752335]
	TIME [epoch: 24.8 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286279776391786		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 2.286279776391786 | validation: 3.4563722679402407]
	TIME [epoch: 24.8 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2982187721748972		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 2.2982187721748972 | validation: 3.4654804729328896]
	TIME [epoch: 24.8 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2966843671149713		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 2.2966843671149713 | validation: 3.4483883896306087]
	TIME [epoch: 24.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2975794163080625		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 2.2975794163080625 | validation: 3.4630306567746714]
	TIME [epoch: 24.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29876359128953		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 2.29876359128953 | validation: 3.449164643914678]
	TIME [epoch: 24.8 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3067953057580786		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 2.3067953057580786 | validation: 3.454749548014461]
	TIME [epoch: 24.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294550251475828		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 2.294550251475828 | validation: 3.456676539992411]
	TIME [epoch: 24.8 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862595832217645		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 2.2862595832217645 | validation: 3.452133413446382]
	TIME [epoch: 24.8 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287660117118722		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 2.287660117118722 | validation: 3.4466149689431065]
	TIME [epoch: 24.8 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282728510784999		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 2.282728510784999 | validation: 3.44244067569838]
	TIME [epoch: 24.8 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2870927368847562		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 2.2870927368847562 | validation: 3.463675657807609]
	TIME [epoch: 24.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29444926463		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 2.29444926463 | validation: 3.4417250913727457]
	TIME [epoch: 24.8 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2867987261613894		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 2.2867987261613894 | validation: 3.4451265257276122]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288661411948655		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 2.288661411948655 | validation: 3.438611241325441]
	TIME [epoch: 24.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307152796601011		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 2.307152796601011 | validation: 3.4792672588434734]
	TIME [epoch: 24.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321882449362157		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 2.321882449362157 | validation: 3.445932718150964]
	TIME [epoch: 24.8 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2915547057871173		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 2.2915547057871173 | validation: 3.471534384112802]
	TIME [epoch: 24.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307089742904444		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 2.307089742904444 | validation: 3.4683734577067797]
	TIME [epoch: 24.8 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2960525000308105		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 2.2960525000308105 | validation: 3.447815559965946]
	TIME [epoch: 24.8 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2859024480714805		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 2.2859024480714805 | validation: 3.447948185404674]
	TIME [epoch: 24.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2924721857390136		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 2.2924721857390136 | validation: 3.4438227616673673]
	TIME [epoch: 24.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2828866595756683		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 2.2828866595756683 | validation: 3.450389791892839]
	TIME [epoch: 24.8 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287015323866904		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 2.287015323866904 | validation: 3.4442773811780865]
	TIME [epoch: 24.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2939432234806043		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 2.2939432234806043 | validation: 3.4519765294036784]
	TIME [epoch: 24.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2961858023088855		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 2.2961858023088855 | validation: 3.445477986918015]
	TIME [epoch: 24.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2872056930611926		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 2.2872056930611926 | validation: 3.44267485506345]
	TIME [epoch: 24.8 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2910083788574718		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 2.2910083788574718 | validation: 3.4497422465476295]
	TIME [epoch: 24.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929629112711334		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 2.2929629112711334 | validation: 3.4449634321597524]
	TIME [epoch: 24.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2838424451314077		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 2.2838424451314077 | validation: 3.446263369873346]
	TIME [epoch: 24.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2886384824073627		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 2.2886384824073627 | validation: 3.445604983207969]
	TIME [epoch: 24.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294098260251297		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 2.294098260251297 | validation: 3.4669207645543305]
	TIME [epoch: 24.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909200172926782		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 2.2909200172926782 | validation: 3.444730942985939]
	TIME [epoch: 24.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294043031051426		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 2.294043031051426 | validation: 3.436054386614561]
	TIME [epoch: 24.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3017241271307105		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 2.3017241271307105 | validation: 3.4574060156879045]
	TIME [epoch: 24.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2957909212106546		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 2.2957909212106546 | validation: 3.444289626595014]
	TIME [epoch: 24.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286322414180453		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 2.286322414180453 | validation: 3.4381264347349396]
	TIME [epoch: 24.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289161959366125		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 2.289161959366125 | validation: 3.4477620916866285]
	TIME [epoch: 24.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2917069263881613		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 2.2917069263881613 | validation: 3.441676342374435]
	TIME [epoch: 24.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293608060136022		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 2.293608060136022 | validation: 3.4548691757966368]
	TIME [epoch: 24.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3031940912288764		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 2.3031940912288764 | validation: 3.475800934526753]
	TIME [epoch: 24.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3090329868464052		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 2.3090329868464052 | validation: 3.4619828239955956]
	TIME [epoch: 24.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2955930186590088		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 2.2955930186590088 | validation: 3.451695095274082]
	TIME [epoch: 24.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286193002928215		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 2.286193002928215 | validation: 3.4461961406149966]
	TIME [epoch: 24.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287434673759749		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 2.287434673759749 | validation: 3.454855071161355]
	TIME [epoch: 24.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2881210608085674		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 2.2881210608085674 | validation: 3.459024182378305]
	TIME [epoch: 24.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286511777783817		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 2.286511777783817 | validation: 3.4486791034429896]
	TIME [epoch: 24.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2872210724952957		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 2.2872210724952957 | validation: 3.4426916069186615]
	TIME [epoch: 24.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282334960018036		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 2.282334960018036 | validation: 3.4399301989679745]
	TIME [epoch: 24.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2893883495783425		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 2.2893883495783425 | validation: 3.4589560279941316]
	TIME [epoch: 24.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3009231398882743		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 2.3009231398882743 | validation: 3.4437532411404095]
	TIME [epoch: 24.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286476016913766		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 2.286476016913766 | validation: 3.4474876129069583]
	TIME [epoch: 24.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28622312050134		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 2.28622312050134 | validation: 3.4472617933509966]
	TIME [epoch: 24.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289905265777892		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 2.289905265777892 | validation: 3.4469847496388217]
	TIME [epoch: 24.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2974702311595983		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 2.2974702311595983 | validation: 3.4509820817835943]
	TIME [epoch: 24.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2877277093005346		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 2.2877277093005346 | validation: 3.444003655478076]
	TIME [epoch: 24.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2827903206039233		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 2.2827903206039233 | validation: 3.451191955906895]
	TIME [epoch: 24.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282766559549731		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 2.282766559549731 | validation: 3.438976620111153]
	TIME [epoch: 24.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2767768876824643		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 2.2767768876824643 | validation: 3.431950046540582]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r2_20240310_051929/states/model_tr_study205_1257.pth
	Model improved!!!
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295049712682234		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 2.295049712682234 | validation: 3.4534766916004473]
	TIME [epoch: 24.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29620387720312		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 2.29620387720312 | validation: 3.438867216831527]
	TIME [epoch: 24.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280435919366836		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 2.280435919366836 | validation: 3.4391610208050807]
	TIME [epoch: 24.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2801016069967095		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 2.2801016069967095 | validation: 3.4324171144758857]
	TIME [epoch: 24.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282656246529354		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 2.282656246529354 | validation: 3.4484325093667216]
	TIME [epoch: 24.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291400278429038		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 2.291400278429038 | validation: 3.4433605061258845]
	TIME [epoch: 24.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2859128486955136		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 2.2859128486955136 | validation: 3.4401192438299475]
	TIME [epoch: 24.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2802360981720264		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 2.2802360981720264 | validation: 3.43692754541967]
	TIME [epoch: 24.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2788816494178668		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 2.2788816494178668 | validation: 3.4417289068770907]
	TIME [epoch: 24.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28296578882683		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 2.28296578882683 | validation: 3.438695184025188]
	TIME [epoch: 24.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287551814983249		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 2.287551814983249 | validation: 3.475548097466267]
	TIME [epoch: 24.8 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3021244275132045		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 2.3021244275132045 | validation: 3.4533150956486667]
	TIME [epoch: 24.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289483901629665		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 2.289483901629665 | validation: 3.438152486871711]
	TIME [epoch: 24.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2834598346972292		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 2.2834598346972292 | validation: 3.4510547851849065]
	TIME [epoch: 24.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2851719677959235		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 2.2851719677959235 | validation: 3.440912963071237]
	TIME [epoch: 24.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281529641838271		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 2.281529641838271 | validation: 3.4411746110767547]
	TIME [epoch: 24.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2833857046241115		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 2.2833857046241115 | validation: 3.4347379740590998]
	TIME [epoch: 24.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.280504813761678		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 2.280504813761678 | validation: 3.4465695291206715]
	TIME [epoch: 24.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2860536267304252		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 2.2860536267304252 | validation: 3.4431089556261965]
	TIME [epoch: 24.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2974690201444194		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 2.2974690201444194 | validation: 3.4433800428129935]
	TIME [epoch: 24.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279684649051909		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 2.279684649051909 | validation: 3.4468753015322875]
	TIME [epoch: 24.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2940632645561765		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 2.2940632645561765 | validation: 3.461555124075902]
	TIME [epoch: 24.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2856731265502743		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 2.2856731265502743 | validation: 3.4409134529830427]
	TIME [epoch: 24.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299672075891584		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 2.299672075891584 | validation: 3.4828810172507403]
	TIME [epoch: 24.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311481527959704		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 2.311481527959704 | validation: 3.4466542392596757]
	TIME [epoch: 24.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2917330984518696		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 2.2917330984518696 | validation: 3.4406794797938036]
	TIME [epoch: 24.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281942802774058		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 2.281942802774058 | validation: 3.4500182086914464]
	TIME [epoch: 24.8 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2810791269452695		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 2.2810791269452695 | validation: 3.440614369590752]
	TIME [epoch: 24.7 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2796971391603127		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 2.2796971391603127 | validation: 3.4469335055401236]
	TIME [epoch: 24.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2793297117238485		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 2.2793297117238485 | validation: 3.442530625775956]
	TIME [epoch: 24.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3012784112551135		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 2.3012784112551135 | validation: 3.4610892174088645]
	TIME [epoch: 24.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2907486801439205		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 2.2907486801439205 | validation: 3.447222196522728]
	TIME [epoch: 24.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285495121078604		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 2.285495121078604 | validation: 3.451850677324417]
	TIME [epoch: 24.8 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2856678897662266		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 2.2856678897662266 | validation: 3.443151349413997]
	TIME [epoch: 24.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2908359195062284		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 2.2908359195062284 | validation: 3.4493097578875416]
	TIME [epoch: 24.8 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3041700219161085		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 2.3041700219161085 | validation: 3.4615168393967237]
	TIME [epoch: 24.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288323948372463		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 2.288323948372463 | validation: 3.444842312491672]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2841280812817404		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 2.2841280812817404 | validation: 3.447495115740113]
	TIME [epoch: 24.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286355253273745		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 2.286355253273745 | validation: 3.4389428538257882]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.28040051997011		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 2.28040051997011 | validation: 3.4428201305942325]
	TIME [epoch: 24.8 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.278410265987831		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 2.278410265987831 | validation: 3.4485024249286687]
	TIME [epoch: 24.8 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.283525480792675		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 2.283525480792675 | validation: 3.439722138472518]
	TIME [epoch: 24.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2816571718865544		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 2.2816571718865544 | validation: 3.4467635109475228]
	TIME [epoch: 24.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2819528252545696		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 2.2819528252545696 | validation: 3.4452989950836743]
	TIME [epoch: 24.8 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2805329533398364		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 2.2805329533398364 | validation: 3.438798732391431]
	TIME [epoch: 24.8 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.277171785719352		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 2.277171785719352 | validation: 3.4435021722876593]
	TIME [epoch: 24.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2903614408949835		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 2.2903614408949835 | validation: 3.4425507096404577]
	TIME [epoch: 24.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281114642301221		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 2.281114642301221 | validation: 3.443693092726326]
	TIME [epoch: 24.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293243209087016		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 2.293243209087016 | validation: 3.4531912363425885]
	TIME [epoch: 24.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288917964878786		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 2.288917964878786 | validation: 3.439877047621603]
	TIME [epoch: 24.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2840133280236565		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 2.2840133280236565 | validation: 3.4391502066728084]
	TIME [epoch: 24.8 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286208552449749		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 2.286208552449749 | validation: 3.4510836847764144]
	TIME [epoch: 24.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288242273107232		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 2.288242273107232 | validation: 3.446459831274168]
	TIME [epoch: 24.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2835311959868396		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 2.2835311959868396 | validation: 3.4403857636748216]
	TIME [epoch: 24.8 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2876914326539675		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 2.2876914326539675 | validation: 3.442882209606097]
	TIME [epoch: 24.7 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2748530421679454		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 2.2748530421679454 | validation: 3.4466015052582533]
	TIME [epoch: 24.8 sec]
EPOCH 1314/2000:
	Training over batches...
