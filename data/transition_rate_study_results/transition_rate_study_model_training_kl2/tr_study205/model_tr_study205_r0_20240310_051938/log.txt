Args:
Namespace(name='model_tr_study205', outdir='out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0', training_data='data/transition_rate_studies/tr_study205/tr_study205_training/r0', validation_data='data/transition_rate_studies/tr_study205/tr_study205_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4121847019

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.68540154832262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.68540154832262 | validation: 11.41638957772215]
	TIME [epoch: 118 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.203242294325982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.203242294325982 | validation: 11.881160427897731]
	TIME [epoch: 28.2 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.136827081902858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.136827081902858 | validation: 10.882519187240518]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.856361211212825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.856361211212825 | validation: 9.816729244578235]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.37228499151792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.37228499151792 | validation: 9.830123402447684]
	TIME [epoch: 28.1 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.789275988316215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.789275988316215 | validation: 8.516031955305893]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.954003449537281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.954003449537281 | validation: 7.974656945554227]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.463093101483051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.463093101483051 | validation: 7.37698621314059]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.198529435513594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.198529435513594 | validation: 9.048113237397441]
	TIME [epoch: 28.1 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.4005372685805035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4005372685805035 | validation: 7.01612774397193]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.100734839445765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.100734839445765 | validation: 7.3381562564507385]
	TIME [epoch: 28.1 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.125904293312324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.125904293312324 | validation: 7.298460883917175]
	TIME [epoch: 28.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.03899668088303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.03899668088303 | validation: 6.669727070582509]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.808138815039899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.808138815039899 | validation: 6.426806369992635]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894741995348473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.894741995348473 | validation: 6.3162122378419125]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830318409975398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.830318409975398 | validation: 6.120913663845565]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.547528104724985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.547528104724985 | validation: 6.171028789387281]
	TIME [epoch: 28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.524543070464004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.524543070464004 | validation: 6.031963787263431]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.380622964984622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.380622964984622 | validation: 7.028728606519027]
	TIME [epoch: 28 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.434375888565064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.434375888565064 | validation: 6.536648841690833]
	TIME [epoch: 28.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.531861633541681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.531861633541681 | validation: 6.116455785234932]
	TIME [epoch: 28.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.538522134077198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.538522134077198 | validation: 5.945988787984395]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.07459446688624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.07459446688624 | validation: 5.743499624265106]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.255326663041924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.255326663041924 | validation: 6.106126083717961]
	TIME [epoch: 28 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.139298283702511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.139298283702511 | validation: 6.160242526100237]
	TIME [epoch: 28.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.96991094146978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.96991094146978 | validation: 5.750739477855509]
	TIME [epoch: 28 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172309703516947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.172309703516947 | validation: 6.094002909131348]
	TIME [epoch: 28 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.957090386798779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.957090386798779 | validation: 5.488062505760008]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.253993655076578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.253993655076578 | validation: 5.445684629325537]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9487053347659185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9487053347659185 | validation: 5.753296050337856]
	TIME [epoch: 28 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.837866549834348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.837866549834348 | validation: 6.234849993607022]
	TIME [epoch: 28 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.874466279994637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.874466279994637 | validation: 6.224409889204767]
	TIME [epoch: 28.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.822118649658897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.822118649658897 | validation: 5.388319925415924]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.993255769696581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.993255769696581 | validation: 5.454970896265859]
	TIME [epoch: 28.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.883433725608306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.883433725608306 | validation: 5.595573936516135]
	TIME [epoch: 28 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.77682725844657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.77682725844657 | validation: 5.464042615452506]
	TIME [epoch: 28.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.605544209046072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.605544209046072 | validation: 5.538197547980154]
	TIME [epoch: 28.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.613775623337016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.613775623337016 | validation: 5.493803415572813]
	TIME [epoch: 28.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552242633426292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.552242633426292 | validation: 6.340682318414036]
	TIME [epoch: 28.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.675331583480615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.675331583480615 | validation: 5.806805665845543]
	TIME [epoch: 28 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7959670276145125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7959670276145125 | validation: 5.341684959087753]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.71668883835357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.71668883835357 | validation: 5.195548107923671]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.596427663052823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596427663052823 | validation: 5.292010124088486]
	TIME [epoch: 28.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463516781780784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.463516781780784 | validation: 5.058133989621249]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.558234268539652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.558234268539652 | validation: 5.275567115559259]
	TIME [epoch: 28 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.527958489612833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.527958489612833 | validation: 5.285027779960053]
	TIME [epoch: 28.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.341917569041241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.341917569041241 | validation: 5.129960302188987]
	TIME [epoch: 28 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.378968001384619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.378968001384619 | validation: 5.190833226506945]
	TIME [epoch: 28.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481772760649376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.481772760649376 | validation: 5.930701705290093]
	TIME [epoch: 28.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544381085013528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.544381085013528 | validation: 5.32645886329025]
	TIME [epoch: 28.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.258037540717026		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.258037540717026 | validation: 5.221716584097319]
	TIME [epoch: 28 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.100099644490145		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.100099644490145 | validation: 5.090084430983281]
	TIME [epoch: 28 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476858828040068		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.476858828040068 | validation: 5.072029215904845]
	TIME [epoch: 28.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.285510007639818		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.285510007639818 | validation: 5.5856218473674435]
	TIME [epoch: 28.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083731923670348		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.083731923670348 | validation: 5.545494617275842]
	TIME [epoch: 28 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.241353889861075		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.241353889861075 | validation: 4.901757602900536]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.137795501530905		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.137795501530905 | validation: 5.182313442120777]
	TIME [epoch: 28 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.069175383623772		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.069175383623772 | validation: 5.415513667536092]
	TIME [epoch: 28.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.230171841428065		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.230171841428065 | validation: 5.056465330202637]
	TIME [epoch: 28 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.251027412756963		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.251027412756963 | validation: 4.82370345057756]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023960585953944		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.023960585953944 | validation: 5.025918440640904]
	TIME [epoch: 28 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.029648567345184		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.029648567345184 | validation: 4.723621869919797]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.125390666479519		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.125390666479519 | validation: 4.948356291086289]
	TIME [epoch: 28 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0368297872942644		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.0368297872942644 | validation: 4.791202968317271]
	TIME [epoch: 28 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03373999638885		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.03373999638885 | validation: 5.137223565095907]
	TIME [epoch: 28 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9734025951613807		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.9734025951613807 | validation: 5.076400864145791]
	TIME [epoch: 28 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.985030433280532		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.985030433280532 | validation: 4.706677268567141]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9904724821686672		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.9904724821686672 | validation: 4.658729249321537]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6742852269299293		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.6742852269299293 | validation: 5.158056202375646]
	TIME [epoch: 28 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.154546870750286		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.154546870750286 | validation: 4.813050368481815]
	TIME [epoch: 28 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.849354455854797		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.849354455854797 | validation: 5.094782661517822]
	TIME [epoch: 28 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9643573600040014		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.9643573600040014 | validation: 4.656295845750288]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9987697577799586		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.9987697577799586 | validation: 4.561532081787326]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.746497719547637		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.746497719547637 | validation: 5.357145021954647]
	TIME [epoch: 28 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.939397368868889		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.939397368868889 | validation: 5.116682822318489]
	TIME [epoch: 28 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7305463348951022		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.7305463348951022 | validation: 4.826066620683571]
	TIME [epoch: 28 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9189182461477197		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.9189182461477197 | validation: 4.541658029026353]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.95337716196519		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.95337716196519 | validation: 4.538106230317165]
	TIME [epoch: 28.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7827028418895625		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.7827028418895625 | validation: 4.571270421950854]
	TIME [epoch: 28.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7960463397465896		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.7960463397465896 | validation: 4.774998419483945]
	TIME [epoch: 28.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6789983732368663		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.6789983732368663 | validation: 4.447367916167462]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7131393683490286		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.7131393683490286 | validation: 5.079873809188221]
	TIME [epoch: 28.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6980020149311197		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.6980020149311197 | validation: 4.963806998439295]
	TIME [epoch: 28 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.686501367864772		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.686501367864772 | validation: 4.8387038182639195]
	TIME [epoch: 28.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7685885853623464		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.7685885853623464 | validation: 4.829903139492617]
	TIME [epoch: 28.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7453998011447434		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.7453998011447434 | validation: 4.6675393240025915]
	TIME [epoch: 28.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6383226163811964		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.6383226163811964 | validation: 4.508370214708396]
	TIME [epoch: 28 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7839488378167614		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.7839488378167614 | validation: 4.588873848395887]
	TIME [epoch: 28 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6320469514168994		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.6320469514168994 | validation: 4.378364493205054]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5960528642587204		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.5960528642587204 | validation: 4.560688233205199]
	TIME [epoch: 28.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.738917566025806		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.738917566025806 | validation: 4.896106132182593]
	TIME [epoch: 28 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7445674076479865		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.7445674076479865 | validation: 4.437935635556173]
	TIME [epoch: 28 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5529904883274517		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.5529904883274517 | validation: 4.727933070008281]
	TIME [epoch: 28.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5093168559456145		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.5093168559456145 | validation: 4.701421236872286]
	TIME [epoch: 28.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5454224185385685		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.5454224185385685 | validation: 4.27652141843514]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.544299853225314		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.544299853225314 | validation: 4.522207003145312]
	TIME [epoch: 28 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.509615409574595		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.509615409574595 | validation: 4.446330804866746]
	TIME [epoch: 28 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4659097469520947		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.4659097469520947 | validation: 4.469806998808326]
	TIME [epoch: 28 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386548352748601		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.386548352748601 | validation: 4.4337824607211545]
	TIME [epoch: 28 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.454505755429979		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.454505755429979 | validation: 4.409038152814757]
	TIME [epoch: 28 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4495239101787076		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.4495239101787076 | validation: 4.358769788970833]
	TIME [epoch: 28 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369907167221954		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.369907167221954 | validation: 5.142451573111405]
	TIME [epoch: 28 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.527643419579503		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.527643419579503 | validation: 4.733851333828527]
	TIME [epoch: 28 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7409724711338725		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.7409724711338725 | validation: 4.856730237369093]
	TIME [epoch: 28 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4725798656641773		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.4725798656641773 | validation: 4.188730472313011]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389471409769118		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.389471409769118 | validation: 4.256324219325951]
	TIME [epoch: 28 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4084198708903934		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.4084198708903934 | validation: 4.507163206245217]
	TIME [epoch: 28.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.25453991393111		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.25453991393111 | validation: 4.526920825882266]
	TIME [epoch: 28 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26487441134947		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.26487441134947 | validation: 5.427703180765866]
	TIME [epoch: 28 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4734738567641137		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.4734738567641137 | validation: 4.701331976967355]
	TIME [epoch: 28.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3529501632751026		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.3529501632751026 | validation: 4.100922100492331]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4321715288903865		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.4321715288903865 | validation: 4.333715557897888]
	TIME [epoch: 28 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3777269931154663		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.3777269931154663 | validation: 4.399528347893839]
	TIME [epoch: 28 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5086829805402684		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.5086829805402684 | validation: 4.1889943238968685]
	TIME [epoch: 28 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2904126394027484		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.2904126394027484 | validation: 4.3650821118214065]
	TIME [epoch: 28.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.347783156804878		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.347783156804878 | validation: 4.630511676549852]
	TIME [epoch: 28 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231061424402372		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.231061424402372 | validation: 4.331841988456912]
	TIME [epoch: 28 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4781956882905773		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.4781956882905773 | validation: 4.24520133746118]
	TIME [epoch: 28 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2315485683352514		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.2315485683352514 | validation: 4.42394816743169]
	TIME [epoch: 28 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5592525476407095		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.5592525476407095 | validation: 4.937069525129663]
	TIME [epoch: 28 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.601922672834157		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.601922672834157 | validation: 4.132120016851591]
	TIME [epoch: 28 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2337213189203893		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.2337213189203893 | validation: 4.056097304311874]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1998925030873377		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.1998925030873377 | validation: 4.132684957543573]
	TIME [epoch: 28 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408804515687671		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.408804515687671 | validation: 4.31375062889142]
	TIME [epoch: 28 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.140553762768802		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.140553762768802 | validation: 4.50796124867131]
	TIME [epoch: 28 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.506463346287265		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.506463346287265 | validation: 4.6642448401192205]
	TIME [epoch: 28 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.440542024683023		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.440542024683023 | validation: 4.132313852287673]
	TIME [epoch: 28 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227121726846141		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.227121726846141 | validation: 4.2019598924665775]
	TIME [epoch: 28 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.262328198344825		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.262328198344825 | validation: 4.418981680920788]
	TIME [epoch: 28 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3062087262510857		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.3062087262510857 | validation: 4.28690610362629]
	TIME [epoch: 28 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.364936522278698		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.364936522278698 | validation: 4.46198829181601]
	TIME [epoch: 28 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405318542427844		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.405318542427844 | validation: 4.081885720535277]
	TIME [epoch: 28 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213226120055646		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.213226120055646 | validation: 4.363618196001981]
	TIME [epoch: 28 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226607922226261		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.226607922226261 | validation: 4.404163392225304]
	TIME [epoch: 28.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3735033503868124		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.3735033503868124 | validation: 4.46683596546286]
	TIME [epoch: 28 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258046634747262		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.258046634747262 | validation: 4.350920101326551]
	TIME [epoch: 28 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.196250280075555		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.196250280075555 | validation: 4.359655755768641]
	TIME [epoch: 28 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2077019344803936		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.2077019344803936 | validation: 4.328147947212102]
	TIME [epoch: 28 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236375893299198		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.236375893299198 | validation: 4.460247870608852]
	TIME [epoch: 28 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.143841333544561		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.143841333544561 | validation: 4.563936437479086]
	TIME [epoch: 28 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223042811210347		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.223042811210347 | validation: 4.318711257390354]
	TIME [epoch: 28 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1655808838928214		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.1655808838928214 | validation: 4.292358463743569]
	TIME [epoch: 28 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2057602844085498		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.2057602844085498 | validation: 4.135091811622945]
	TIME [epoch: 28 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.108271486481346		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.108271486481346 | validation: 4.157164068692193]
	TIME [epoch: 28 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2060903601294415		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.2060903601294415 | validation: 4.121809421159244]
	TIME [epoch: 28 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.149361489035262		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.149361489035262 | validation: 3.96940552679578]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2024192254952766		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.2024192254952766 | validation: 3.9830865879863535]
	TIME [epoch: 28 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3184539598093807		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.3184539598093807 | validation: 4.244426393502418]
	TIME [epoch: 28 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2255496386222946		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.2255496386222946 | validation: 4.272836578339438]
	TIME [epoch: 28 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.146013016377665		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.146013016377665 | validation: 4.343022325526404]
	TIME [epoch: 28 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3343950391772124		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.3343950391772124 | validation: 4.0747065701134]
	TIME [epoch: 28 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1885518976625127		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.1885518976625127 | validation: 4.091050957045737]
	TIME [epoch: 28 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.957279283818125		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.957279283818125 | validation: 3.9937521383555317]
	TIME [epoch: 28 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250719258749136		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.250719258749136 | validation: 4.1785007955646165]
	TIME [epoch: 28 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226525088731036		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.226525088731036 | validation: 4.154011793925692]
	TIME [epoch: 28.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1615132793718765		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.1615132793718765 | validation: 4.1116390460175065]
	TIME [epoch: 28.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.143752973668327		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.143752973668327 | validation: 4.0841687040692625]
	TIME [epoch: 28.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4291054648546044		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.4291054648546044 | validation: 3.952976095717009]
	TIME [epoch: 28.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9482414543919035		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.9482414543919035 | validation: 4.490189014465011]
	TIME [epoch: 28 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.257144783736707		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.257144783736707 | validation: 4.294216210984932]
	TIME [epoch: 27.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126876596052756		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.126876596052756 | validation: 4.277219208061907]
	TIME [epoch: 27.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.127463669534103		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.127463669534103 | validation: 4.2744916939972875]
	TIME [epoch: 27.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.018727371949848		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.018727371949848 | validation: 4.381892630424489]
	TIME [epoch: 27.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3015873104085167		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.3015873104085167 | validation: 3.9947054289090707]
	TIME [epoch: 27.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.091877819590171		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.091877819590171 | validation: 4.0951192919855]
	TIME [epoch: 27.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0036694628277774		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.0036694628277774 | validation: 4.084574747609951]
	TIME [epoch: 27.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9609238795273884		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 2.9609238795273884 | validation: 4.2507677605038605]
	TIME [epoch: 27.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0590642135344384		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.0590642135344384 | validation: 4.04906886776893]
	TIME [epoch: 27.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.868762796332777		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.868762796332777 | validation: 4.410121604275266]
	TIME [epoch: 27.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0715063671775997		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.0715063671775997 | validation: 4.155716201814596]
	TIME [epoch: 27.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.011590168028265		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.011590168028265 | validation: 3.980010630606137]
	TIME [epoch: 27.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.062558228402388		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.062558228402388 | validation: 3.9430471988347358]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.019241197593016		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.019241197593016 | validation: 4.016864876726508]
	TIME [epoch: 27.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9621278005098217		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.9621278005098217 | validation: 3.9097171124653345]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1013161922630896		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.1013161922630896 | validation: 3.9014227548827263]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9761837752244436		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.9761837752244436 | validation: 3.9089934590180544]
	TIME [epoch: 27.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.007787970532164		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.007787970532164 | validation: 3.995871820940154]
	TIME [epoch: 27.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.085467498832829		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.085467498832829 | validation: 3.884359092858746]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.947202215412336		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.947202215412336 | validation: 3.911000432282504]
	TIME [epoch: 27.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918235314908344		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.918235314908344 | validation: 4.0558912070311655]
	TIME [epoch: 27.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0697277107596728		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.0697277107596728 | validation: 4.050294092087003]
	TIME [epoch: 27.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9325419117992837		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.9325419117992837 | validation: 3.9774155405733405]
	TIME [epoch: 27.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879478761034531		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.879478761034531 | validation: 4.13853613694464]
	TIME [epoch: 27.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1244868179956082		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.1244868179956082 | validation: 4.3757549728099345]
	TIME [epoch: 27.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.004665343618306		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.004665343618306 | validation: 4.096834139353751]
	TIME [epoch: 27.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9125023776850916		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 2.9125023776850916 | validation: 4.154433789268478]
	TIME [epoch: 27.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.04819476927902		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.04819476927902 | validation: 4.122144032323668]
	TIME [epoch: 27.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9578419622300722		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 2.9578419622300722 | validation: 4.016302992635155]
	TIME [epoch: 27.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9231555805254708		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.9231555805254708 | validation: 4.090230391765921]
	TIME [epoch: 27.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0693338087441853		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.0693338087441853 | validation: 3.9912200325021367]
	TIME [epoch: 27.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5264500907396203		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.5264500907396203 | validation: 3.9335184067504487]
	TIME [epoch: 27.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126143364904821		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.126143364904821 | validation: 3.9372857991909953]
	TIME [epoch: 27.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0768886843009025		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.0768886843009025 | validation: 4.105482468637181]
	TIME [epoch: 27.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9272962017351314		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.9272962017351314 | validation: 4.26655343741386]
	TIME [epoch: 27.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.985199149845617		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.985199149845617 | validation: 4.187719076493806]
	TIME [epoch: 27.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9010545904741782		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.9010545904741782 | validation: 3.865483288725467]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7560974775090066		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.7560974775090066 | validation: 3.9181891959800668]
	TIME [epoch: 27.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1472137676951744		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.1472137676951744 | validation: 4.0914216602385185]
	TIME [epoch: 27.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9691258182616984		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.9691258182616984 | validation: 4.633555571980196]
	TIME [epoch: 27.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.017538765101575		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.017538765101575 | validation: 3.9534803612923612]
	TIME [epoch: 27.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7661099385352728		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.7661099385352728 | validation: 4.638028427206495]
	TIME [epoch: 27.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0383896900077194		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.0383896900077194 | validation: 4.3366323598258445]
	TIME [epoch: 27.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.956191805290377		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 2.956191805290377 | validation: 3.9901214161845187]
	TIME [epoch: 27.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.910022457760032		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.910022457760032 | validation: 4.0497342966674115]
	TIME [epoch: 27.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7984023269388665		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.7984023269388665 | validation: 4.148694180432314]
	TIME [epoch: 27.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.049955175049139		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.049955175049139 | validation: 3.9596179563552356]
	TIME [epoch: 27.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8109974044041532		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.8109974044041532 | validation: 3.9549158434918237]
	TIME [epoch: 27.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9106435174662235		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.9106435174662235 | validation: 4.226635937551335]
	TIME [epoch: 27.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9263463236501197		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.9263463236501197 | validation: 3.9729417275070755]
	TIME [epoch: 27.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.854515411189531		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 2.854515411189531 | validation: 4.011389832768246]
	TIME [epoch: 27.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.798219095827121		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 2.798219095827121 | validation: 3.902146514489111]
	TIME [epoch: 27.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0263696121009085		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.0263696121009085 | validation: 3.947639914126488]
	TIME [epoch: 27.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8291097774088776		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.8291097774088776 | validation: 3.9202599215300875]
	TIME [epoch: 27.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8415901923974785		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 2.8415901923974785 | validation: 4.1236735473043495]
	TIME [epoch: 27.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8550559203137134		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.8550559203137134 | validation: 4.073409059246572]
	TIME [epoch: 27.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.847713373896442		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.847713373896442 | validation: 3.9604030478372216]
	TIME [epoch: 27.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.899231460542218		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 2.899231460542218 | validation: 4.008316419810703]
	TIME [epoch: 27.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7974822802734924		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.7974822802734924 | validation: 4.13217941668212]
	TIME [epoch: 27.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.133232703330136		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.133232703330136 | validation: 4.122852877502923]
	TIME [epoch: 27.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8374439468785173		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 2.8374439468785173 | validation: 3.833498271507344]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.818427394686795		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 2.818427394686795 | validation: 3.857393230148408]
	TIME [epoch: 27.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8919149701570874		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.8919149701570874 | validation: 3.9367645815343453]
	TIME [epoch: 27.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.918346090281948		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.918346090281948 | validation: 3.801859216496522]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8181722342201176		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.8181722342201176 | validation: 4.02549837118041]
	TIME [epoch: 27.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8359195019895456		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.8359195019895456 | validation: 3.822167877463796]
	TIME [epoch: 27.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.750773035725758		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.750773035725758 | validation: 3.8658497362685864]
	TIME [epoch: 27.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0013705252419194		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.0013705252419194 | validation: 3.9517355158632563]
	TIME [epoch: 27.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7561286343907963		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.7561286343907963 | validation: 3.788297987378975]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8007449890383764		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.8007449890383764 | validation: 3.8646603911509096]
	TIME [epoch: 27.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8228255907350945		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.8228255907350945 | validation: 4.0973825166923294]
	TIME [epoch: 27.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8901065944286684		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 2.8901065944286684 | validation: 3.857338672784653]
	TIME [epoch: 27.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.969436004977839		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.969436004977839 | validation: 3.8024753346741322]
	TIME [epoch: 27.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8983201308206072		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 2.8983201308206072 | validation: 3.962255318551525]
	TIME [epoch: 27.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9049490845562267		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 2.9049490845562267 | validation: 3.9583617303924963]
	TIME [epoch: 27.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.77790670835477		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.77790670835477 | validation: 3.8539274736208706]
	TIME [epoch: 27.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7609972967320653		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 2.7609972967320653 | validation: 3.80657900560134]
	TIME [epoch: 27.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7651577975514385		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.7651577975514385 | validation: 4.00853440635944]
	TIME [epoch: 27.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9849305766903758		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.9849305766903758 | validation: 3.759432302192291]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8039911851085186		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.8039911851085186 | validation: 3.902233384431685]
	TIME [epoch: 27.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8359445541545343		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.8359445541545343 | validation: 4.163322028452112]
	TIME [epoch: 27.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8743367754154354		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.8743367754154354 | validation: 3.855659547828815]
	TIME [epoch: 27.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6327062840967006		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.6327062840967006 | validation: 3.9693244332832207]
	TIME [epoch: 27.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8640707793584164		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.8640707793584164 | validation: 3.8484317433411945]
	TIME [epoch: 27.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.953264628817591		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.953264628817591 | validation: 4.51725642004907]
	TIME [epoch: 27.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9770840833472043		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.9770840833472043 | validation: 3.838030361279529]
	TIME [epoch: 27.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.512433006933681		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.512433006933681 | validation: 5.223100083891297]
	TIME [epoch: 27.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.079925283571442		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.079925283571442 | validation: 4.331254534226847]
	TIME [epoch: 27.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9554311348315894		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.9554311348315894 | validation: 3.7552101893838485]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9163107197709133		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 2.9163107197709133 | validation: 4.010256108788114]
	TIME [epoch: 27.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.884509483430981		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.884509483430981 | validation: 3.8499724001912647]
	TIME [epoch: 27.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8146275473185476		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.8146275473185476 | validation: 3.8683819150207945]
	TIME [epoch: 27.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9410230090141534		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 2.9410230090141534 | validation: 3.792534046947654]
	TIME [epoch: 27.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9063202818625307		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.9063202818625307 | validation: 4.238975307126642]
	TIME [epoch: 27.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8648920271419525		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.8648920271419525 | validation: 3.978613838863199]
	TIME [epoch: 27.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.795027187140573		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.795027187140573 | validation: 3.8832636899031736]
	TIME [epoch: 27.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7107333934173434		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.7107333934173434 | validation: 3.8701653441259074]
	TIME [epoch: 27.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.763260747773195		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 2.763260747773195 | validation: 3.967699583506348]
	TIME [epoch: 27.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7056821991425952		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.7056821991425952 | validation: 3.964299799297062]
	TIME [epoch: 27.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7493128809182963		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.7493128809182963 | validation: 3.903450258090487]
	TIME [epoch: 27.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.718235606504321		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.718235606504321 | validation: 3.8704089258651853]
	TIME [epoch: 27.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7615501298697565		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.7615501298697565 | validation: 4.07591729844747]
	TIME [epoch: 27.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.759862748933364		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 2.759862748933364 | validation: 3.910043125224687]
	TIME [epoch: 27.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7273669703789447		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 2.7273669703789447 | validation: 3.7262791040134653]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7358526411957005		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 2.7358526411957005 | validation: 3.8685054073801872]
	TIME [epoch: 27.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6870319856873692		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.6870319856873692 | validation: 3.8098878753993564]
	TIME [epoch: 27.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801002004085907		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 2.801002004085907 | validation: 3.745573060891165]
	TIME [epoch: 27.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7016819302872843		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.7016819302872843 | validation: 3.7573375503149373]
	TIME [epoch: 27.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6930748548406296		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.6930748548406296 | validation: 3.834440848054008]
	TIME [epoch: 27.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7535414781716296		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.7535414781716296 | validation: 3.7488065385026585]
	TIME [epoch: 27.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.745049910166521		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.745049910166521 | validation: 3.877970393438332]
	TIME [epoch: 27.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6848741084051664		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.6848741084051664 | validation: 4.129731328239826]
	TIME [epoch: 27.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9332190049394358		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.9332190049394358 | validation: 3.8369129213692634]
	TIME [epoch: 27.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.597085973430223		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.597085973430223 | validation: 4.136796872443989]
	TIME [epoch: 27.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7958073196258226		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.7958073196258226 | validation: 3.892823296116782]
	TIME [epoch: 27.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.664893254626875		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.664893254626875 | validation: 4.160314936475102]
	TIME [epoch: 27.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9415488590627934		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.9415488590627934 | validation: 3.9334762217268575]
	TIME [epoch: 27.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6667875624535244		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.6667875624535244 | validation: 4.13132226784717]
	TIME [epoch: 27.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.664628065091823		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.664628065091823 | validation: 3.992540793859306]
	TIME [epoch: 27.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.772027122496282		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.772027122496282 | validation: 4.272499205674255]
	TIME [epoch: 27.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0912798767124063		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.0912798767124063 | validation: 4.807541099124243]
	TIME [epoch: 27.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1998070309078805		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.1998070309078805 | validation: 4.176042508626304]
	TIME [epoch: 27.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.883576784879694		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 2.883576784879694 | validation: 3.909422925846052]
	TIME [epoch: 27.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802285959699859		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.802285959699859 | validation: 3.7666200170453226]
	TIME [epoch: 27.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6701439281004946		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.6701439281004946 | validation: 3.7652072660555964]
	TIME [epoch: 27.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6681466725560323		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.6681466725560323 | validation: 3.9002368503287563]
	TIME [epoch: 27.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6905203146873102		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.6905203146873102 | validation: 4.255703233423613]
	TIME [epoch: 27.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8435507958674835		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.8435507958674835 | validation: 3.8936576642684053]
	TIME [epoch: 27.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6778397058052414		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.6778397058052414 | validation: 3.869867789204666]
	TIME [epoch: 27.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.80223051332444		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.80223051332444 | validation: 3.96812073982941]
	TIME [epoch: 27.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7454344407151163		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.7454344407151163 | validation: 3.791246815008256]
	TIME [epoch: 27.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7431269568612326		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.7431269568612326 | validation: 3.7997905390621227]
	TIME [epoch: 27.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7521270837930443		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.7521270837930443 | validation: 4.383216797081866]
	TIME [epoch: 27.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.850715072869176		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.850715072869176 | validation: 3.864257443702966]
	TIME [epoch: 27.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6736134095232065		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.6736134095232065 | validation: 3.7206559981336627]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7159574764791694		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.7159574764791694 | validation: 3.8782734143492177]
	TIME [epoch: 27.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.702852308314133		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.702852308314133 | validation: 3.7487480572018024]
	TIME [epoch: 27.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6923053419426934		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.6923053419426934 | validation: 3.7593839951511185]
	TIME [epoch: 27.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.607071648871534		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.607071648871534 | validation: 3.8344192269767827]
	TIME [epoch: 27.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7267824844227544		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.7267824844227544 | validation: 3.7123207540609533]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6545115125853727		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.6545115125853727 | validation: 3.788761534077192]
	TIME [epoch: 27.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6713791248813425		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.6713791248813425 | validation: 3.782315691036033]
	TIME [epoch: 27.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.708048132996529		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.708048132996529 | validation: 3.6949884840259304]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6419048458851426		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.6419048458851426 | validation: 3.959623680934661]
	TIME [epoch: 27.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7645624201169423		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.7645624201169423 | validation: 3.748257340597974]
	TIME [epoch: 27.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8717873319938776		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.8717873319938776 | validation: 4.472645603788618]
	TIME [epoch: 27.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.030986980675231		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.030986980675231 | validation: 4.119680230741158]
	TIME [epoch: 27.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6926145950607205		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.6926145950607205 | validation: 3.769786347075917]
	TIME [epoch: 27.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805272967133706		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.805272967133706 | validation: 4.038879199946183]
	TIME [epoch: 27.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7354649843306897		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.7354649843306897 | validation: 3.8063447251195046]
	TIME [epoch: 27.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.752254451230571		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.752254451230571 | validation: 3.7694275905530827]
	TIME [epoch: 27.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7642191451783145		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.7642191451783145 | validation: 3.926700620433851]
	TIME [epoch: 27.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7784147324482933		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.7784147324482933 | validation: 3.7673758415633483]
	TIME [epoch: 27.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6947203640141453		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.6947203640141453 | validation: 3.892259740506288]
	TIME [epoch: 27.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7405074111588257		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.7405074111588257 | validation: 3.7018257428588863]
	TIME [epoch: 27.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.61519682885129		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.61519682885129 | validation: 3.810310457286868]
	TIME [epoch: 27.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6286201650992065		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.6286201650992065 | validation: 3.9804835267193477]
	TIME [epoch: 27.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6222419570607367		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.6222419570607367 | validation: 3.976755924686429]
	TIME [epoch: 27.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.599773450205752		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.599773450205752 | validation: 3.857269479722366]
	TIME [epoch: 27.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7190635062876747		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.7190635062876747 | validation: 3.6872789487056314]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6548477515466553		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.6548477515466553 | validation: 3.6945613193815916]
	TIME [epoch: 27.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.047648922736581		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 3.047648922736581 | validation: 3.8602956818886236]
	TIME [epoch: 27.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7522151959890935		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.7522151959890935 | validation: 4.287107453791427]
	TIME [epoch: 27.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6982678675776093		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.6982678675776093 | validation: 3.9218608932897143]
	TIME [epoch: 27.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6447989250118935		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.6447989250118935 | validation: 3.743969371315363]
	TIME [epoch: 27.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.776197450268566		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.776197450268566 | validation: 3.854224062326305]
	TIME [epoch: 27.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.624482509218435		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.624482509218435 | validation: 3.7291464324501544]
	TIME [epoch: 27.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7178131299943042		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.7178131299943042 | validation: 3.793527558602696]
	TIME [epoch: 27.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.632526572553342		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.632526572553342 | validation: 3.744771662098393]
	TIME [epoch: 27.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.580586667780749		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.580586667780749 | validation: 3.8338632618393267]
	TIME [epoch: 27.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5985581367939017		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.5985581367939017 | validation: 3.8042316685434656]
	TIME [epoch: 27.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.88548900814233		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.88548900814233 | validation: 3.859145505412965]
	TIME [epoch: 27.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9387873818156605		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.9387873818156605 | validation: 3.731296241933144]
	TIME [epoch: 27.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6376437474505896		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.6376437474505896 | validation: 3.749461143537136]
	TIME [epoch: 27.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6008106587528257		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.6008106587528257 | validation: 3.807816946079247]
	TIME [epoch: 27.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.612610083016376		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.612610083016376 | validation: 3.900027697281538]
	TIME [epoch: 27.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.641729204861847		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.641729204861847 | validation: 4.032251411486303]
	TIME [epoch: 27.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7353632117367015		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.7353632117367015 | validation: 3.7399333412655937]
	TIME [epoch: 27.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.627202031830591		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 2.627202031830591 | validation: 3.9532301935072747]
	TIME [epoch: 27.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64198602281313		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.64198602281313 | validation: 3.7247973158167564]
	TIME [epoch: 27.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6042510379450134		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.6042510379450134 | validation: 3.7486512866739816]
	TIME [epoch: 27.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.605364970201952		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.605364970201952 | validation: 3.752071052042245]
	TIME [epoch: 27.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5943111223083877		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.5943111223083877 | validation: 3.8065741711549084]
	TIME [epoch: 27.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.591111668700823		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.591111668700823 | validation: 3.6896030756895115]
	TIME [epoch: 27.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6958240895199204		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.6958240895199204 | validation: 3.925024195838263]
	TIME [epoch: 27.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.56756739963195		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.56756739963195 | validation: 3.701291498000385]
	TIME [epoch: 27.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.614820446422948		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.614820446422948 | validation: 3.711610548742441]
	TIME [epoch: 27.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6362389872336567		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.6362389872336567 | validation: 3.867750948944554]
	TIME [epoch: 27.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.600917607228337		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 2.600917607228337 | validation: 3.961087159790308]
	TIME [epoch: 27.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8074411030911053		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 2.8074411030911053 | validation: 3.6850270386436246]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6108588005610844		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.6108588005610844 | validation: 3.6674621575879316]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.571953588787199		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 2.571953588787199 | validation: 3.664983518862978]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549943965326985		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 2.549943965326985 | validation: 3.704044901375507]
	TIME [epoch: 27.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6166354740817934		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.6166354740817934 | validation: 3.749717206699671]
	TIME [epoch: 27.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6989043927615683		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.6989043927615683 | validation: 4.257745074711451]
	TIME [epoch: 27.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9061629885777007		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.9061629885777007 | validation: 4.0403321492828965]
	TIME [epoch: 27.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6438292009638924		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.6438292009638924 | validation: 3.872761736503097]
	TIME [epoch: 27.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6165815408469193		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.6165815408469193 | validation: 3.6745320204897234]
	TIME [epoch: 27.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5809239851006898		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.5809239851006898 | validation: 3.6899611216737687]
	TIME [epoch: 27.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.545473431212567		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.545473431212567 | validation: 3.737770630758148]
	TIME [epoch: 27.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5494535916166416		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.5494535916166416 | validation: 3.8844035001218415]
	TIME [epoch: 27.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.589598256113673		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.589598256113673 | validation: 4.033291321909631]
	TIME [epoch: 27.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677953676250032		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 2.6677953676250032 | validation: 3.6818658984790025]
	TIME [epoch: 27.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5536053446994993		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.5536053446994993 | validation: 3.7872197186528718]
	TIME [epoch: 27.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5475497716179367		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.5475497716179367 | validation: 3.696504681058747]
	TIME [epoch: 27.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6620308008171807		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.6620308008171807 | validation: 4.094190521268122]
	TIME [epoch: 27.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.783486499622909		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 2.783486499622909 | validation: 3.6692857441482922]
	TIME [epoch: 27.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5712389799233937		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.5712389799233937 | validation: 3.7469200126798325]
	TIME [epoch: 27.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.60551632891844		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 2.60551632891844 | validation: 3.747568603762705]
	TIME [epoch: 27.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5565075285313177		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 2.5565075285313177 | validation: 3.932100362663232]
	TIME [epoch: 27.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.630715651724504		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 2.630715651724504 | validation: 3.7672706092516672]
	TIME [epoch: 27.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.548932691699397		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.548932691699397 | validation: 3.9986669125164314]
	TIME [epoch: 27.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5925609035900505		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 2.5925609035900505 | validation: 3.745370431091098]
	TIME [epoch: 27.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.564898133644641		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 2.564898133644641 | validation: 3.7647591441556405]
	TIME [epoch: 27.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.64042335493079		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 2.64042335493079 | validation: 3.6997395733280873]
	TIME [epoch: 27.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7267954379377923		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 2.7267954379377923 | validation: 3.7044745879536602]
	TIME [epoch: 27.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536276280040282		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 2.536276280040282 | validation: 3.7481278148183903]
	TIME [epoch: 27.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.623247171023295		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 2.623247171023295 | validation: 3.6819373015187367]
	TIME [epoch: 27.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5493079202382454		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 2.5493079202382454 | validation: 3.739078542140811]
	TIME [epoch: 27.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5619207007672986		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 2.5619207007672986 | validation: 4.005301877234366]
	TIME [epoch: 27.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5939902200845237		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 2.5939902200845237 | validation: 3.686542085554297]
	TIME [epoch: 27.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.584178743590784		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 2.584178743590784 | validation: 3.6907651548565448]
	TIME [epoch: 27.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.516505821233289		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 2.516505821233289 | validation: 3.7995994677112326]
	TIME [epoch: 27.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.569183007787122		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.569183007787122 | validation: 3.7364070442411466]
	TIME [epoch: 27.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.552957924764648		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 2.552957924764648 | validation: 3.6378743753068132]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5334009041010823		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 2.5334009041010823 | validation: 3.73803564929202]
	TIME [epoch: 27.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5681830467355544		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.5681830467355544 | validation: 3.6996670503990776]
	TIME [epoch: 27.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5407201785652793		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.5407201785652793 | validation: 3.7220038763915815]
	TIME [epoch: 27.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4957425849551624		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 2.4957425849551624 | validation: 3.6785070401468154]
	TIME [epoch: 27.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6167896374921336		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 2.6167896374921336 | validation: 3.737861330990254]
	TIME [epoch: 27.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.721200921607895		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 2.721200921607895 | validation: 4.2380650218957046]
	TIME [epoch: 27.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8149280407756523		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 2.8149280407756523 | validation: 3.974078206692732]
	TIME [epoch: 27.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6291374050867673		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 2.6291374050867673 | validation: 3.7237319670502256]
	TIME [epoch: 27.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509664704040295		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 2.509664704040295 | validation: 3.642523650511197]
	TIME [epoch: 27.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.55847762078265		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 2.55847762078265 | validation: 3.9656930301866864]
	TIME [epoch: 27.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5739069214428287		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.5739069214428287 | validation: 4.121634428734499]
	TIME [epoch: 27.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6684074955879535		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 2.6684074955879535 | validation: 3.82881961112604]
	TIME [epoch: 27.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.566443930817271		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 2.566443930817271 | validation: 3.708197629162182]
	TIME [epoch: 27.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4967599427430214		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 2.4967599427430214 | validation: 3.708344782472192]
	TIME [epoch: 27.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6734789964813643		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 2.6734789964813643 | validation: 3.807455990921545]
	TIME [epoch: 27.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6575977158035857		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 2.6575977158035857 | validation: 3.7137267802825558]
	TIME [epoch: 27.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7324420184034786		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 2.7324420184034786 | validation: 4.461414907672658]
	TIME [epoch: 27.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.845908563409966		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 2.845908563409966 | validation: 3.919284508485635]
	TIME [epoch: 27.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570753239725776		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 2.570753239725776 | validation: 3.674874802903578]
	TIME [epoch: 27.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625833179428744		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 2.625833179428744 | validation: 3.9084405702587017]
	TIME [epoch: 27.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.596133789888021		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.596133789888021 | validation: 3.6506883103760197]
	TIME [epoch: 27.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.586376895373986		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 2.586376895373986 | validation: 3.8622457082383947]
	TIME [epoch: 27.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.555108463627989		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 2.555108463627989 | validation: 3.641308107968432]
	TIME [epoch: 27.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5773744523026556		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 2.5773744523026556 | validation: 3.6309064932639523]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5425422554875885		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 2.5425422554875885 | validation: 3.689454400889689]
	TIME [epoch: 27.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5338304836673213		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 2.5338304836673213 | validation: 3.7850872832772176]
	TIME [epoch: 27.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5220345968508475		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 2.5220345968508475 | validation: 3.740938433104117]
	TIME [epoch: 27.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.557660735039062		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 2.557660735039062 | validation: 3.7536777844513027]
	TIME [epoch: 27.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.591050318512516		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 2.591050318512516 | validation: 3.9000151389330266]
	TIME [epoch: 27.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.571552892661095		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 2.571552892661095 | validation: 3.664341722904155]
	TIME [epoch: 27.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4957277014345274		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 2.4957277014345274 | validation: 3.687007331046619]
	TIME [epoch: 27.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625123509049461		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 2.625123509049461 | validation: 3.676697016718827]
	TIME [epoch: 27.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5362462993790973		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 2.5362462993790973 | validation: 3.677880042953638]
	TIME [epoch: 27.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.517160607264117		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 2.517160607264117 | validation: 3.8932187071359863]
	TIME [epoch: 27.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6090715442158032		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 2.6090715442158032 | validation: 3.666653984553399]
	TIME [epoch: 27.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.516268930694147		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 2.516268930694147 | validation: 3.696799130308083]
	TIME [epoch: 27.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.502934392476126		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 2.502934392476126 | validation: 3.805077146731637]
	TIME [epoch: 27.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.668490356696285		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.668490356696285 | validation: 3.8321554293513866]
	TIME [epoch: 27.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5985987042851066		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 2.5985987042851066 | validation: 3.6546282460145574]
	TIME [epoch: 27.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.575642232624842		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 2.575642232624842 | validation: 3.8475657738587916]
	TIME [epoch: 27.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5302690891009476		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.5302690891009476 | validation: 3.791414664108345]
	TIME [epoch: 27.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5311531350335255		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.5311531350335255 | validation: 3.6577436671834245]
	TIME [epoch: 27.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6075458312652815		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 2.6075458312652815 | validation: 3.6701289294127823]
	TIME [epoch: 27.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549711248087368		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 2.549711248087368 | validation: 3.703819691205579]
	TIME [epoch: 27.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5037765943095964		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 2.5037765943095964 | validation: 3.715912427182642]
	TIME [epoch: 27.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5339534354046664		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.5339534354046664 | validation: 3.6773197061164553]
	TIME [epoch: 27.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5578105424875837		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.5578105424875837 | validation: 4.29601992667865]
	TIME [epoch: 27.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6501254485541974		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.6501254485541974 | validation: 3.824471935307465]
	TIME [epoch: 27.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5380671354252464		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 2.5380671354252464 | validation: 3.753514301477588]
	TIME [epoch: 27.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.511907368969548		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.511907368969548 | validation: 3.7533977851218117]
	TIME [epoch: 27.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.546292755670029		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.546292755670029 | validation: 3.6338405796678637]
	TIME [epoch: 27.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4877986061589974		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 2.4877986061589974 | validation: 3.7435796142459026]
	TIME [epoch: 27.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.484887380100902		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 2.484887380100902 | validation: 3.7667393103135756]
	TIME [epoch: 27.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50911965774771		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.50911965774771 | validation: 3.6958606382604478]
	TIME [epoch: 27.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5989478689040193		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.5989478689040193 | validation: 3.6196401417041946]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514582350534087		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.514582350534087 | validation: 3.717794758215789]
	TIME [epoch: 27.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5193373876001046		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.5193373876001046 | validation: 3.6987076521993782]
	TIME [epoch: 27.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.495116938563124		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.495116938563124 | validation: 3.611164873717226]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.528684077502022		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.528684077502022 | validation: 3.816302940540915]
	TIME [epoch: 27.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.534475560649542		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.534475560649542 | validation: 3.6620194533911]
	TIME [epoch: 27.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5849158468502544		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 2.5849158468502544 | validation: 3.6278598457325577]
	TIME [epoch: 27.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7681901818356596		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 2.7681901818356596 | validation: 3.6210766899311024]
	TIME [epoch: 27.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.545464736389121		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 2.545464736389121 | validation: 3.776586102759178]
	TIME [epoch: 27.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.549930195826458		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 2.549930195826458 | validation: 4.258488395361459]
	TIME [epoch: 27.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7518432107148603		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 2.7518432107148603 | validation: 3.687701254804842]
	TIME [epoch: 27.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4984172280686927		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 2.4984172280686927 | validation: 3.641678609097054]
	TIME [epoch: 27.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6200978799401184		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.6200978799401184 | validation: 3.6810974636704414]
	TIME [epoch: 27.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.570299028129949		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 2.570299028129949 | validation: 3.6713394462927784]
	TIME [epoch: 27.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512959254037082		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 2.512959254037082 | validation: 3.660685232261626]
	TIME [epoch: 27.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4546480608003325		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 2.4546480608003325 | validation: 3.6602076310707945]
	TIME [epoch: 27.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.492234023221394		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 2.492234023221394 | validation: 3.7237648632289244]
	TIME [epoch: 27.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4751407841737403		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 2.4751407841737403 | validation: 3.8498187173020892]
	TIME [epoch: 27.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4851055422762807		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 2.4851055422762807 | validation: 3.6469678077342587]
	TIME [epoch: 27.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5093044686068477		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.5093044686068477 | validation: 3.5993969277642406]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50822536623875		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 2.50822536623875 | validation: 3.672939869669225]
	TIME [epoch: 27.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5035660681489853		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 2.5035660681489853 | validation: 3.6283096203472156]
	TIME [epoch: 27.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5338657678682814		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 2.5338657678682814 | validation: 3.6663600954362146]
	TIME [epoch: 27.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6388966914474365		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 2.6388966914474365 | validation: 3.647464450490072]
	TIME [epoch: 27.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6147296953747614		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 2.6147296953747614 | validation: 3.7066037481063336]
	TIME [epoch: 27.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5615329608634543		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 2.5615329608634543 | validation: 3.7760220481558515]
	TIME [epoch: 27.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4736930397129018		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 2.4736930397129018 | validation: 3.6350019412795356]
	TIME [epoch: 27.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4929712709735603		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 2.4929712709735603 | validation: 3.665958219084847]
	TIME [epoch: 27.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4862382415939654		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 2.4862382415939654 | validation: 3.662468958502527]
	TIME [epoch: 27.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.496189533543246		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 2.496189533543246 | validation: 3.7289074658072456]
	TIME [epoch: 27.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4982893054002213		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 2.4982893054002213 | validation: 3.7783964758123263]
	TIME [epoch: 27.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.498156583415774		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.498156583415774 | validation: 3.9056532580884964]
	TIME [epoch: 27.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.586915815480616		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 2.586915815480616 | validation: 3.8148490672610342]
	TIME [epoch: 27.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.610102122243144		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 2.610102122243144 | validation: 3.6740885966912002]
	TIME [epoch: 27.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460845517028548		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 2.460845517028548 | validation: 3.637154444236045]
	TIME [epoch: 27.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.451392757395243		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 2.451392757395243 | validation: 3.5998048997270895]
	TIME [epoch: 27.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4330955188964043		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 2.4330955188964043 | validation: 4.050287853044856]
	TIME [epoch: 27.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6116474771173426		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 2.6116474771173426 | validation: 3.6032701564826928]
	TIME [epoch: 27.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4436888519190574		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 2.4436888519190574 | validation: 3.744760544349497]
	TIME [epoch: 27.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4783133836540796		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 2.4783133836540796 | validation: 3.755871994729674]
	TIME [epoch: 27.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5949996831433806		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 2.5949996831433806 | validation: 3.6297838977167602]
	TIME [epoch: 27.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4953805475507034		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 2.4953805475507034 | validation: 3.595576569894657]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4382739038468992		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 2.4382739038468992 | validation: 3.889216791769742]
	TIME [epoch: 27.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5739949969763405		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 2.5739949969763405 | validation: 3.6366468188910552]
	TIME [epoch: 27.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.480593942137639		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 2.480593942137639 | validation: 3.894611755475826]
	TIME [epoch: 27.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5529517420340313		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 2.5529517420340313 | validation: 3.746221109646699]
	TIME [epoch: 28 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5544322042370706		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.5544322042370706 | validation: 3.6383900849235102]
	TIME [epoch: 27.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.534589821154106		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 2.534589821154106 | validation: 3.637004586002382]
	TIME [epoch: 27.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.437874831410822		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 2.437874831410822 | validation: 3.7327069352763416]
	TIME [epoch: 27.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4907033125286837		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 2.4907033125286837 | validation: 3.664649201479291]
	TIME [epoch: 27.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4577578639860587		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 2.4577578639860587 | validation: 3.7273447871679672]
	TIME [epoch: 27.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5173789970483584		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 2.5173789970483584 | validation: 3.647545814441397]
	TIME [epoch: 28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4776930736694522		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 2.4776930736694522 | validation: 3.672899804357312]
	TIME [epoch: 27.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6281661893677724		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 2.6281661893677724 | validation: 3.7665549026405687]
	TIME [epoch: 28 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4631677957708598		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 2.4631677957708598 | validation: 3.6257825810947253]
	TIME [epoch: 27.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4739092983128086		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 2.4739092983128086 | validation: 3.717347649843522]
	TIME [epoch: 27.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4506772337020557		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 2.4506772337020557 | validation: 3.6961795027585294]
	TIME [epoch: 27.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.461155191252149		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 2.461155191252149 | validation: 3.7400412866322164]
	TIME [epoch: 27.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.583487376422371		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 2.583487376422371 | validation: 3.7357421137192963]
	TIME [epoch: 27.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5543753245426646		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 2.5543753245426646 | validation: 3.7061645677251374]
	TIME [epoch: 27.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504753199263624		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 2.504753199263624 | validation: 3.99207292472904]
	TIME [epoch: 28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.593966629110332		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.593966629110332 | validation: 3.694578356026533]
	TIME [epoch: 28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4658156966321556		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 2.4658156966321556 | validation: 3.926675709888058]
	TIME [epoch: 27.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639019776655547		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 2.639019776655547 | validation: 3.6927271553194645]
	TIME [epoch: 28 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.504608040506192		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 2.504608040506192 | validation: 3.6779879514996283]
	TIME [epoch: 27.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.509463971020719		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 2.509463971020719 | validation: 3.6533817312854877]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.518837524040094		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 2.518837524040094 | validation: 3.778607719627036]
	TIME [epoch: 28 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467285923661561		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 2.467285923661561 | validation: 3.8783916854359486]
	TIME [epoch: 27.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5402952747615384		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 2.5402952747615384 | validation: 3.6241352757131007]
	TIME [epoch: 27.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471786697556272		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 2.471786697556272 | validation: 3.6578675584991225]
	TIME [epoch: 27.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4461434229028542		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.4461434229028542 | validation: 3.6780164458626157]
	TIME [epoch: 28 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5057427927421076		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.5057427927421076 | validation: 3.79432490611772]
	TIME [epoch: 28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.529616557203166		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.529616557203166 | validation: 3.6728449019791305]
	TIME [epoch: 27.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450840117079742		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 2.450840117079742 | validation: 3.620610654465295]
	TIME [epoch: 28 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4454585580203725		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 2.4454585580203725 | validation: 4.246873265405636]
	TIME [epoch: 27.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6359612863729374		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 2.6359612863729374 | validation: 3.909173815024376]
	TIME [epoch: 28 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.514948044025669		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 2.514948044025669 | validation: 3.6713632860353362]
	TIME [epoch: 28 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.435013851562797		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 2.435013851562797 | validation: 3.65370194494071]
	TIME [epoch: 27.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4673861846805503		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 2.4673861846805503 | validation: 3.6434902117641492]
	TIME [epoch: 28 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.448989023044407		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 2.448989023044407 | validation: 3.6289611304930713]
	TIME [epoch: 27.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.428431435031188		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 2.428431435031188 | validation: 3.596470259813847]
	TIME [epoch: 28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4213677165608094		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.4213677165608094 | validation: 3.9521812093054165]
	TIME [epoch: 28 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.561297681158357		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 2.561297681158357 | validation: 3.6274724580731594]
	TIME [epoch: 27.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4265924762024844		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 2.4265924762024844 | validation: 3.6998777239006775]
	TIME [epoch: 28 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5497333444828705		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 2.5497333444828705 | validation: 3.870226112672913]
	TIME [epoch: 27.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5179373256663546		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 2.5179373256663546 | validation: 3.6968144106340732]
	TIME [epoch: 28 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.516994387184572		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 2.516994387184572 | validation: 3.63762639001007]
	TIME [epoch: 27.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4376326438643794		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 2.4376326438643794 | validation: 3.641530489466338]
	TIME [epoch: 27.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4399592300264783		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 2.4399592300264783 | validation: 3.6778635001812985]
	TIME [epoch: 27.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4731114861512498		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 2.4731114861512498 | validation: 3.753233224858527]
	TIME [epoch: 27.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577994835990583		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 2.577994835990583 | validation: 3.6190586574089516]
	TIME [epoch: 27.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5484743212604624		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 2.5484743212604624 | validation: 3.8264943062704875]
	TIME [epoch: 27.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5770841297537865		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 2.5770841297537865 | validation: 3.7055440111976874]
	TIME [epoch: 27.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4812688415859947		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 2.4812688415859947 | validation: 3.586477941624258]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452996192437058		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 2.452996192437058 | validation: 3.590768780942668]
	TIME [epoch: 27.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4236421465222744		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 2.4236421465222744 | validation: 3.6775576743561063]
	TIME [epoch: 27.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.454689478001708		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 2.454689478001708 | validation: 3.6094149956511776]
	TIME [epoch: 27.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4564006160855945		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 2.4564006160855945 | validation: 3.5751262196223226]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4471507264396593		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 2.4471507264396593 | validation: 3.8139466515928415]
	TIME [epoch: 27.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.460358009859502		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 2.460358009859502 | validation: 3.5891793563013277]
	TIME [epoch: 27.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.41289671260432		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 2.41289671260432 | validation: 3.7967622128024607]
	TIME [epoch: 27.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.528232817592956		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 2.528232817592956 | validation: 3.5778602150733714]
	TIME [epoch: 27.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4718882671389695		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 2.4718882671389695 | validation: 3.599387843083784]
	TIME [epoch: 27.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.487302588786775		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 2.487302588786775 | validation: 3.873045807422179]
	TIME [epoch: 27.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.537754832232943		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 2.537754832232943 | validation: 3.6203637049687614]
	TIME [epoch: 27.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.482019700922674		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 2.482019700922674 | validation: 3.839297262394849]
	TIME [epoch: 27.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5462522034831676		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 2.5462522034831676 | validation: 3.7454604889044063]
	TIME [epoch: 27.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.473479108170088		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 2.473479108170088 | validation: 3.6017575014894487]
	TIME [epoch: 27.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4143484692633055		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 2.4143484692633055 | validation: 3.6209316179461855]
	TIME [epoch: 27.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.470889060941372		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 2.470889060941372 | validation: 3.762163545093945]
	TIME [epoch: 27.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.503780386152631		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 2.503780386152631 | validation: 3.6469141270428658]
	TIME [epoch: 27.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4305564672670577		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 2.4305564672670577 | validation: 3.698655110476183]
	TIME [epoch: 27.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.469656076905057		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 2.469656076905057 | validation: 3.5964099338296007]
	TIME [epoch: 27.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4092122144818893		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 2.4092122144818893 | validation: 3.6083375208331394]
	TIME [epoch: 27.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5000066586944456		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 2.5000066586944456 | validation: 3.5967193554747614]
	TIME [epoch: 27.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4144505933781604		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 2.4144505933781604 | validation: 3.588695887614323]
	TIME [epoch: 27.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.427853016581181		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 2.427853016581181 | validation: 3.6423617923346057]
	TIME [epoch: 27.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4223382401261415		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 2.4223382401261415 | validation: 3.7563380639159614]
	TIME [epoch: 27.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4724972954559914		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 2.4724972954559914 | validation: 3.6641712244569646]
	TIME [epoch: 27.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4637501948172473		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 2.4637501948172473 | validation: 3.643945124019308]
	TIME [epoch: 27.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4173802876348844		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 2.4173802876348844 | validation: 3.615709197897553]
	TIME [epoch: 27.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468746174309223		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 2.468746174309223 | validation: 3.580762260000619]
	TIME [epoch: 27.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3936203352489267		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.3936203352489267 | validation: 3.564488240331778]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_561.pth
	Model improved!!!
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.457750280973894		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 2.457750280973894 | validation: 3.794447802122188]
	TIME [epoch: 27.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491800617502753		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 2.491800617502753 | validation: 3.6788981229403817]
	TIME [epoch: 27.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458345424808651		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 2.458345424808651 | validation: 3.591384145609385]
	TIME [epoch: 27.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4091436168893874		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 2.4091436168893874 | validation: 3.5933257160652294]
	TIME [epoch: 27.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3810751036094793		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.3810751036094793 | validation: 3.5966582592514813]
	TIME [epoch: 27.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4197627899037384		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 2.4197627899037384 | validation: 3.77495489133069]
	TIME [epoch: 27.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4488663475751316		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 2.4488663475751316 | validation: 3.8066849496137984]
	TIME [epoch: 27.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.47631409187859		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 2.47631409187859 | validation: 3.811673684108438]
	TIME [epoch: 27.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.508348933086099		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 2.508348933086099 | validation: 3.602098967708033]
	TIME [epoch: 27.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.392546776202464		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 2.392546776202464 | validation: 3.634067065688125]
	TIME [epoch: 27.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.42732971631985		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 2.42732971631985 | validation: 3.5919998091319916]
	TIME [epoch: 27.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4505779753272705		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 2.4505779753272705 | validation: 3.5584859159181357]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4650620008867747		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.4650620008867747 | validation: 3.5693890748154864]
	TIME [epoch: 28 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48208979497692		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 2.48208979497692 | validation: 3.637056890731693]
	TIME [epoch: 27.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.521624118528816		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 2.521624118528816 | validation: 3.569343393145981]
	TIME [epoch: 27.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4873484522288662		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 2.4873484522288662 | validation: 3.7339023750303286]
	TIME [epoch: 27.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4478159745057404		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 2.4478159745057404 | validation: 3.632641842064219]
	TIME [epoch: 27.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4473335295887892		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 2.4473335295887892 | validation: 3.621006473270958]
	TIME [epoch: 27.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3812055961334493		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 2.3812055961334493 | validation: 3.592044944869433]
	TIME [epoch: 27.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4569179380580994		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 2.4569179380580994 | validation: 3.562487935948933]
	TIME [epoch: 27.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43199342621325		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 2.43199342621325 | validation: 3.5582508755857805]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4142938647826346		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 2.4142938647826346 | validation: 3.5650969008647873]
	TIME [epoch: 27.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391181207742456		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 2.391181207742456 | validation: 3.627963527340644]
	TIME [epoch: 27.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4226583731056155		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 2.4226583731056155 | validation: 3.5724292961089215]
	TIME [epoch: 27.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5068282977208884		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 2.5068282977208884 | validation: 3.621907130412577]
	TIME [epoch: 27.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.454979676284984		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.454979676284984 | validation: 3.6497479686214795]
	TIME [epoch: 27.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.469193485562072		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 2.469193485562072 | validation: 3.5782961287309485]
	TIME [epoch: 27.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.387318106113383		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 2.387318106113383 | validation: 3.7771837259831464]
	TIME [epoch: 27.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4490033684461006		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 2.4490033684461006 | validation: 3.6166032139166866]
	TIME [epoch: 27.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4358965636140093		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 2.4358965636140093 | validation: 3.566983478650781]
	TIME [epoch: 27.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4129585897863235		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 2.4129585897863235 | validation: 3.794907492039404]
	TIME [epoch: 27.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.479072372510725		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 2.479072372510725 | validation: 3.5963028286886374]
	TIME [epoch: 27.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.44463233375885		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 2.44463233375885 | validation: 3.6337509741169187]
	TIME [epoch: 27.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4072950057873514		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 2.4072950057873514 | validation: 3.6191208490499585]
	TIME [epoch: 27.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4325868988568327		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 2.4325868988568327 | validation: 3.722297838645626]
	TIME [epoch: 27.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468179828841552		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.468179828841552 | validation: 3.5678752674323513]
	TIME [epoch: 27.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3998278125937027		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 2.3998278125937027 | validation: 3.594997281994762]
	TIME [epoch: 27.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4146285222243677		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 2.4146285222243677 | validation: 3.629983825956821]
	TIME [epoch: 27.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.430114978797929		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 2.430114978797929 | validation: 3.679014227417574]
	TIME [epoch: 27.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4000364314353773		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 2.4000364314353773 | validation: 3.624625977660338]
	TIME [epoch: 27.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.412352520523935		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 2.412352520523935 | validation: 3.5663269889372056]
	TIME [epoch: 27.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3971530919680712		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 2.3971530919680712 | validation: 3.5988895006831605]
	TIME [epoch: 27.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.404943837565141		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 2.404943837565141 | validation: 3.705830462927719]
	TIME [epoch: 27.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450434605882797		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 2.450434605882797 | validation: 3.6716407379437066]
	TIME [epoch: 27.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.530608593455896		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 2.530608593455896 | validation: 3.8666603154487316]
	TIME [epoch: 27.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45685082209465		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 2.45685082209465 | validation: 3.645713544135349]
	TIME [epoch: 27.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4595885115461824		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 2.4595885115461824 | validation: 3.5907979030816954]
	TIME [epoch: 27.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3850039683230495		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 2.3850039683230495 | validation: 3.554356337217516]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_609.pth
	Model improved!!!
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3745800477988417		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 2.3745800477988417 | validation: 3.563093897561823]
	TIME [epoch: 27.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364571130377386		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.364571130377386 | validation: 3.6251985380637417]
	TIME [epoch: 27.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3929618131662536		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 2.3929618131662536 | validation: 3.5725486041268333]
	TIME [epoch: 27.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.414258111233768		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 2.414258111233768 | validation: 3.570750016596307]
	TIME [epoch: 27.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4368103307841977		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 2.4368103307841977 | validation: 3.713568190921451]
	TIME [epoch: 27.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4558232281868744		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 2.4558232281868744 | validation: 3.623768805942839]
	TIME [epoch: 27.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408716458403635		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 2.408716458403635 | validation: 3.615656549206526]
	TIME [epoch: 27.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4003281617132552		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 2.4003281617132552 | validation: 3.6275635117916334]
	TIME [epoch: 27.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418491277412569		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 2.418491277412569 | validation: 3.580696280684299]
	TIME [epoch: 27.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3966728696274386		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 2.3966728696274386 | validation: 3.68545955514323]
	TIME [epoch: 27.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4354866021280897		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 2.4354866021280897 | validation: 3.591029383777607]
	TIME [epoch: 27.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3993655912471277		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 2.3993655912471277 | validation: 3.5815700642917716]
	TIME [epoch: 27.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.499217548923089		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 2.499217548923089 | validation: 3.6077448203650553]
	TIME [epoch: 27.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.422648685078584		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 2.422648685078584 | validation: 3.6427497883452076]
	TIME [epoch: 27.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.416027760749987		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 2.416027760749987 | validation: 3.574216987450027]
	TIME [epoch: 27.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3855673849018744		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 2.3855673849018744 | validation: 3.572275771995992]
	TIME [epoch: 27.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3971579250654176		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 2.3971579250654176 | validation: 3.582977478964119]
	TIME [epoch: 27.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3999129843964226		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.3999129843964226 | validation: 3.5490496543780927]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4236843512159707		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 2.4236843512159707 | validation: 3.663834041592237]
	TIME [epoch: 27.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4184003944034242		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 2.4184003944034242 | validation: 3.5626717034904187]
	TIME [epoch: 27.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4215720140952888		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 2.4215720140952888 | validation: 3.6695901685793038]
	TIME [epoch: 27.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3972064717724066		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 2.3972064717724066 | validation: 3.671291889699403]
	TIME [epoch: 27.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5002434178093713		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.5002434178093713 | validation: 3.6103060126533633]
	TIME [epoch: 27.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.444256804089943		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 2.444256804089943 | validation: 3.541994126595109]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_633.pth
	Model improved!!!
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391557399408253		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 2.391557399408253 | validation: 3.62054404346227]
	TIME [epoch: 27.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.501546355328354		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 2.501546355328354 | validation: 3.6205345410979137]
	TIME [epoch: 27.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4492588096509333		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 2.4492588096509333 | validation: 3.5835545577953867]
	TIME [epoch: 27.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3827494567684466		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 2.3827494567684466 | validation: 3.678330452715118]
	TIME [epoch: 27.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.418359617278233		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 2.418359617278233 | validation: 3.562447462798946]
	TIME [epoch: 27.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4085332804111994		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 2.4085332804111994 | validation: 3.568853283056939]
	TIME [epoch: 27.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.422521155349304		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 2.422521155349304 | validation: 3.566925413494663]
	TIME [epoch: 27.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3668775579886905		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 2.3668775579886905 | validation: 3.6032115502371664]
	TIME [epoch: 27.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.391636708794127		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 2.391636708794127 | validation: 3.5698401390857613]
	TIME [epoch: 27.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4129693932126157		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 2.4129693932126157 | validation: 3.606104679651285]
	TIME [epoch: 27.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3852274388661545		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 2.3852274388661545 | validation: 3.5879479370749965]
	TIME [epoch: 27.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3964900389139037		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 2.3964900389139037 | validation: 3.6009810017472934]
	TIME [epoch: 27.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.392506269093832		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 2.392506269093832 | validation: 3.5510710436461808]
	TIME [epoch: 27.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386738114600956		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 2.386738114600956 | validation: 3.5617302527279384]
	TIME [epoch: 27.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3868436704799674		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 2.3868436704799674 | validation: 3.5629625577305295]
	TIME [epoch: 27.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368809511642005		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 2.368809511642005 | validation: 3.593943537145625]
	TIME [epoch: 27.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.394494689283917		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 2.394494689283917 | validation: 3.674175180369128]
	TIME [epoch: 27.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4180236782399107		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 2.4180236782399107 | validation: 3.5703979471950538]
	TIME [epoch: 27.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450796080751969		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 2.450796080751969 | validation: 3.5649482946157365]
	TIME [epoch: 27.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364866445760662		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 2.364866445760662 | validation: 3.5968378318389815]
	TIME [epoch: 27.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4073522407830814		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 2.4073522407830814 | validation: 3.6067634965844038]
	TIME [epoch: 27.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3777525268589206		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 2.3777525268589206 | validation: 3.564987284182471]
	TIME [epoch: 27.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4830429371796665		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 2.4830429371796665 | validation: 3.7047511014044074]
	TIME [epoch: 27.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4372113263788235		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 2.4372113263788235 | validation: 3.5569140074037278]
	TIME [epoch: 27.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4192346183974687		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 2.4192346183974687 | validation: 3.533208918920853]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383849816947792		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 2.383849816947792 | validation: 3.5597345643533482]
	TIME [epoch: 27.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3853132491107845		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 2.3853132491107845 | validation: 3.607068765110975]
	TIME [epoch: 27.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4024550610536424		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 2.4024550610536424 | validation: 3.580703748339272]
	TIME [epoch: 27.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37926657794342		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 2.37926657794342 | validation: 3.5495568818016556]
	TIME [epoch: 27.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381972957711814		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.381972957711814 | validation: 3.5986086051661936]
	TIME [epoch: 27.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4432237903749536		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 2.4432237903749536 | validation: 3.5668269022023686]
	TIME [epoch: 27.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.366298722977217		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 2.366298722977217 | validation: 3.5225170200536264]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367715244882622		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 2.367715244882622 | validation: 3.584892676782999]
	TIME [epoch: 27.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37965637754965		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 2.37965637754965 | validation: 3.537386972049451]
	TIME [epoch: 27.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.367685234020738		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 2.367685234020738 | validation: 3.5740988494331565]
	TIME [epoch: 27.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3779446207931594		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 2.3779446207931594 | validation: 3.6738814053755893]
	TIME [epoch: 27.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443872534837002		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 2.443872534837002 | validation: 3.5403206289371294]
	TIME [epoch: 27.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360332871333315		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 2.360332871333315 | validation: 3.590749431856258]
	TIME [epoch: 27.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.390443323699289		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 2.390443323699289 | validation: 3.5322609388516684]
	TIME [epoch: 27.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358199621343136		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 2.358199621343136 | validation: 3.5562466021251806]
	TIME [epoch: 27.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3803852358144875		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 2.3803852358144875 | validation: 3.5415749058355437]
	TIME [epoch: 27.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4304247011009266		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 2.4304247011009266 | validation: 3.6870664824874364]
	TIME [epoch: 27.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4371693084621784		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 2.4371693084621784 | validation: 3.6227684048692517]
	TIME [epoch: 27.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3619893689771634		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 2.3619893689771634 | validation: 3.5593348368027415]
	TIME [epoch: 27.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4137383387743325		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 2.4137383387743325 | validation: 3.691237950512574]
	TIME [epoch: 27.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39073856862863		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 2.39073856862863 | validation: 3.5740601303415667]
	TIME [epoch: 27.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3592043275274373		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 2.3592043275274373 | validation: 3.6923872702054172]
	TIME [epoch: 27.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43357040455341		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 2.43357040455341 | validation: 3.588677210457408]
	TIME [epoch: 27.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4798804187651693		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 2.4798804187651693 | validation: 3.6130598457590906]
	TIME [epoch: 27.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4030687154449413		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 2.4030687154449413 | validation: 3.5715433345097245]
	TIME [epoch: 27.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.353151742459894		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 2.353151742459894 | validation: 3.5558274915336607]
	TIME [epoch: 27.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9568391912443044		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 2.9568391912443044 | validation: 3.775497433020752]
	TIME [epoch: 27.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4699345014333725		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 2.4699345014333725 | validation: 3.626190247865725]
	TIME [epoch: 27.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4257415123353328		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 2.4257415123353328 | validation: 3.539316597128421]
	TIME [epoch: 27.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.407703262811271		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 2.407703262811271 | validation: 3.6385852636067852]
	TIME [epoch: 27.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4331537340584126		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 2.4331537340584126 | validation: 3.5588423549076005]
	TIME [epoch: 27.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3712080717350634		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 2.3712080717350634 | validation: 3.5701016819071034]
	TIME [epoch: 27.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3434424540912517		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 2.3434424540912517 | validation: 3.538014497590038]
	TIME [epoch: 27.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3777559927939182		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 2.3777559927939182 | validation: 3.546178834711509]
	TIME [epoch: 27.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361870181373283		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 2.361870181373283 | validation: 3.578090410014262]
	TIME [epoch: 27.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358616898410034		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 2.358616898410034 | validation: 3.5553221829984594]
	TIME [epoch: 27.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4205289337085576		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 2.4205289337085576 | validation: 3.6053358801008857]
	TIME [epoch: 27.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3683011306557225		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 2.3683011306557225 | validation: 3.5583019385394277]
	TIME [epoch: 27.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.347923779586466		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 2.347923779586466 | validation: 3.6411864270646532]
	TIME [epoch: 27.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3761709166532086		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 2.3761709166532086 | validation: 3.552995941676609]
	TIME [epoch: 27.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355531236466954		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 2.355531236466954 | validation: 3.5389573536967043]
	TIME [epoch: 27.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343500131873194		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 2.343500131873194 | validation: 3.5777616683452447]
	TIME [epoch: 27.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386997403149106		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.386997403149106 | validation: 3.543103129957716]
	TIME [epoch: 27.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3948254873250034		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 2.3948254873250034 | validation: 3.61953823425435]
	TIME [epoch: 27.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4562546471317726		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 2.4562546471317726 | validation: 3.7327569762295174]
	TIME [epoch: 27.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4784902459961557		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 2.4784902459961557 | validation: 3.5475116305042134]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45802150367781		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 2.45802150367781 | validation: 3.5406532316031987]
	TIME [epoch: 27.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3689325032400146		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 2.3689325032400146 | validation: 3.557590501802234]
	TIME [epoch: 27.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380892990037769		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 2.380892990037769 | validation: 3.5811648633468565]
	TIME [epoch: 27.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3554590300378013		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 2.3554590300378013 | validation: 3.537904780844483]
	TIME [epoch: 27.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4042102057829906		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 2.4042102057829906 | validation: 3.5365521814385437]
	TIME [epoch: 27.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3567563047218596		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 2.3567563047218596 | validation: 3.5371319228564335]
	TIME [epoch: 27.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345397243846984		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 2.345397243846984 | validation: 3.575943070335213]
	TIME [epoch: 27.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.341210324389925		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 2.341210324389925 | validation: 3.6386172423405005]
	TIME [epoch: 27.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3615819992683966		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 2.3615819992683966 | validation: 3.531091618352906]
	TIME [epoch: 27.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4041609389630283		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 2.4041609389630283 | validation: 3.6094752310529907]
	TIME [epoch: 27.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3710350757026766		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 2.3710350757026766 | validation: 3.5344873941207835]
	TIME [epoch: 27.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3762021881721607		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 2.3762021881721607 | validation: 3.5453479981792193]
	TIME [epoch: 27.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385816500357657		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 2.385816500357657 | validation: 3.5693777317041895]
	TIME [epoch: 27.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3489450919678565		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 2.3489450919678565 | validation: 3.528308111982982]
	TIME [epoch: 27.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3601163014378184		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 2.3601163014378184 | validation: 3.5286330460810444]
	TIME [epoch: 27.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342275909515399		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 2.342275909515399 | validation: 3.5607065042439308]
	TIME [epoch: 27.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3620987116174406		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 2.3620987116174406 | validation: 3.544025065455169]
	TIME [epoch: 27.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.381760734084904		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 2.381760734084904 | validation: 3.53725656693184]
	TIME [epoch: 27.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375220562185861		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 2.375220562185861 | validation: 3.528901677565076]
	TIME [epoch: 27.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3475812074495908		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 2.3475812074495908 | validation: 3.5261441623646093]
	TIME [epoch: 27.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3741267683233582		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 2.3741267683233582 | validation: 3.5283523524954057]
	TIME [epoch: 27.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346403882476955		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 2.346403882476955 | validation: 3.5665200341654746]
	TIME [epoch: 27.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340674297844014		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 2.340674297844014 | validation: 3.6944933417116195]
	TIME [epoch: 27.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4200987424438534		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 2.4200987424438534 | validation: 3.606080356726682]
	TIME [epoch: 27.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4122800147802277		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 2.4122800147802277 | validation: 3.5642889654935472]
	TIME [epoch: 27.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3554402824658185		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 2.3554402824658185 | validation: 3.52777777971294]
	TIME [epoch: 27.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3997760135998707		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 2.3997760135998707 | validation: 3.5249533172623]
	TIME [epoch: 27.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3922136457425296		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 2.3922136457425296 | validation: 3.546786525011232]
	TIME [epoch: 27.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360998940029629		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 2.360998940029629 | validation: 3.7260506908796245]
	TIME [epoch: 27.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4471813750397713		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 2.4471813750397713 | validation: 3.7294238569566307]
	TIME [epoch: 27.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4111702837301845		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 2.4111702837301845 | validation: 3.543348833623858]
	TIME [epoch: 27.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3469776926927617		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 2.3469776926927617 | validation: 3.566247516688435]
	TIME [epoch: 27.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3561776356523847		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 2.3561776356523847 | validation: 3.5297310823034627]
	TIME [epoch: 27.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385243532432144		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 2.385243532432144 | validation: 3.5840329289775115]
	TIME [epoch: 27.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3565739436605875		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 2.3565739436605875 | validation: 3.541939363561003]
	TIME [epoch: 27.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3577927596098758		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 2.3577927596098758 | validation: 3.593106281535004]
	TIME [epoch: 27.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4056118428029483		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 2.4056118428029483 | validation: 3.5602667667312593]
	TIME [epoch: 27.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3545537741282616		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 2.3545537741282616 | validation: 3.538493996188291]
	TIME [epoch: 27.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3585801997879967		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 2.3585801997879967 | validation: 3.6184696842663953]
	TIME [epoch: 27.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3608902503077127		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 2.3608902503077127 | validation: 3.577370478038664]
	TIME [epoch: 27.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3799080934651857		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 2.3799080934651857 | validation: 3.5948652001737167]
	TIME [epoch: 27.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.34412121477575		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 2.34412121477575 | validation: 3.534635988988995]
	TIME [epoch: 27.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357314556106761		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 2.357314556106761 | validation: 3.521312914264129]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_747.pth
	Model improved!!!
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382253766735864		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 2.382253766735864 | validation: 3.591988950656976]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3829543075108015		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 2.3829543075108015 | validation: 3.5450683712179103]
	TIME [epoch: 27.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3691421389835683		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 2.3691421389835683 | validation: 3.5403955538043763]
	TIME [epoch: 27.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3393732286777853		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 2.3393732286777853 | validation: 3.588722419121723]
	TIME [epoch: 27.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3853581868413967		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 2.3853581868413967 | validation: 3.5795117735782833]
	TIME [epoch: 27.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3453966163499045		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 2.3453966163499045 | validation: 3.525050444173828]
	TIME [epoch: 27.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4032096849356916		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 2.4032096849356916 | validation: 3.5275833693435943]
	TIME [epoch: 27.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3531262808661575		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 2.3531262808661575 | validation: 3.5637343808472735]
	TIME [epoch: 27.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.405045948242073		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 2.405045948242073 | validation: 3.5355330620213388]
	TIME [epoch: 27.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3966488284737197		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 2.3966488284737197 | validation: 3.5312618282031925]
	TIME [epoch: 27.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.353770193513953		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 2.353770193513953 | validation: 3.5329538491587846]
	TIME [epoch: 27.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3329958320307838		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 2.3329958320307838 | validation: 3.5041646500175556]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_759.pth
	Model improved!!!
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350633372675031		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 2.350633372675031 | validation: 3.5379575967431904]
	TIME [epoch: 27.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.379485850451068		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 2.379485850451068 | validation: 3.517975646285149]
	TIME [epoch: 27.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3437081473132784		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 2.3437081473132784 | validation: 3.513914550543782]
	TIME [epoch: 27.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4177899679969084		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 2.4177899679969084 | validation: 3.6877510789651167]
	TIME [epoch: 27.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384066613010907		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 2.384066613010907 | validation: 3.516223331333969]
	TIME [epoch: 27.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.357751086578987		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 2.357751086578987 | validation: 3.5205068128895536]
	TIME [epoch: 27.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3552777033252603		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 2.3552777033252603 | validation: 3.554292491758057]
	TIME [epoch: 27.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3676395434383815		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 2.3676395434383815 | validation: 3.5619330853995796]
	TIME [epoch: 27.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3475944454474575		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 2.3475944454474575 | validation: 3.54941409461886]
	TIME [epoch: 27.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3586382083897814		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 2.3586382083897814 | validation: 3.827374607549779]
	TIME [epoch: 27.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4990111133769726		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 2.4990111133769726 | validation: 3.5276606217738413]
	TIME [epoch: 27.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3505533134950527		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 2.3505533134950527 | validation: 3.5462144410449468]
	TIME [epoch: 27.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.345654389097106		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 2.345654389097106 | validation: 3.539406167658517]
	TIME [epoch: 27.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326256829354735		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 2.326256829354735 | validation: 3.5772833045918673]
	TIME [epoch: 27.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3538603285536794		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 2.3538603285536794 | validation: 3.5391286411716]
	TIME [epoch: 27.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344994150460331		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 2.344994150460331 | validation: 3.528925498357611]
	TIME [epoch: 27.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333904657752452		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 2.333904657752452 | validation: 3.5671874408746995]
	TIME [epoch: 27.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3788053360307333		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 2.3788053360307333 | validation: 3.542967405578636]
	TIME [epoch: 27.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3380438470360265		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 2.3380438470360265 | validation: 3.521530304346632]
	TIME [epoch: 27.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3334149724934394		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 2.3334149724934394 | validation: 3.5431493644765357]
	TIME [epoch: 27.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383101352711237		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 2.383101352711237 | validation: 3.5259579383507322]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.329889621876646		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 2.329889621876646 | validation: 3.5710278806473297]
	TIME [epoch: 27.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343447976468521		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 2.343447976468521 | validation: 3.5285914397467835]
	TIME [epoch: 27.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3411539986860355		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 2.3411539986860355 | validation: 3.5240495427061407]
	TIME [epoch: 27.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330031747633724		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 2.330031747633724 | validation: 3.5352308110797663]
	TIME [epoch: 27.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395506170136354		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 2.395506170136354 | validation: 3.5338650350787026]
	TIME [epoch: 27.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.362997648741765		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 2.362997648741765 | validation: 3.5617573344292626]
	TIME [epoch: 27.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327704229316938		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 2.327704229316938 | validation: 3.545605873756621]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3665626726979343		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 2.3665626726979343 | validation: 3.543766682184618]
	TIME [epoch: 27.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37384823425824		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 2.37384823425824 | validation: 3.5845971018557647]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3557683155320874		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 2.3557683155320874 | validation: 3.5981621563709876]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.360024674669546		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 2.360024674669546 | validation: 3.524800714734187]
	TIME [epoch: 27.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.361274671879262		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 2.361274671879262 | validation: 3.5300280536792266]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3441521784095074		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 2.3441521784095074 | validation: 3.5119482414081813]
	TIME [epoch: 27.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3391937003112977		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 2.3391937003112977 | validation: 3.5514149818393013]
	TIME [epoch: 27.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3664429169465557		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 2.3664429169465557 | validation: 3.5665260120976274]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3416551245067736		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 2.3416551245067736 | validation: 3.6133367854138965]
	TIME [epoch: 27.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354681038961559		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 2.354681038961559 | validation: 3.5536415549812994]
	TIME [epoch: 27.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3318346454008285		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 2.3318346454008285 | validation: 3.5341058616953878]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3612180842801624		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 2.3612180842801624 | validation: 3.589838072683634]
	TIME [epoch: 27.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3661046227153277		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 2.3661046227153277 | validation: 3.5436744299394003]
	TIME [epoch: 27.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3488285169931604		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 2.3488285169931604 | validation: 3.7675702679796905]
	TIME [epoch: 27.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446868953841021		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 2.446868953841021 | validation: 3.555100631644165]
	TIME [epoch: 27.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330738318298418		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 2.330738318298418 | validation: 3.559875721399241]
	TIME [epoch: 27.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3243847807034848		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 2.3243847807034848 | validation: 3.541289736878476]
	TIME [epoch: 27.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.333966211571189		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 2.333966211571189 | validation: 3.5376037406717433]
	TIME [epoch: 27.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3284115448314866		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 2.3284115448314866 | validation: 3.556915237263015]
	TIME [epoch: 27.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3391249137113252		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 2.3391249137113252 | validation: 3.537007102136139]
	TIME [epoch: 27.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3369071958084238		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 2.3369071958084238 | validation: 3.5433439031124863]
	TIME [epoch: 27.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3404237603040903		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 2.3404237603040903 | validation: 3.5338017093030234]
	TIME [epoch: 27.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3345770067909233		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 2.3345770067909233 | validation: 3.5570894010355882]
	TIME [epoch: 27.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3914839179347958		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 2.3914839179347958 | validation: 3.64342439066746]
	TIME [epoch: 27.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.355211120649477		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 2.355211120649477 | validation: 3.5366407964456625]
	TIME [epoch: 27.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3421532263056486		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 2.3421532263056486 | validation: 3.543314656419035]
	TIME [epoch: 27.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3482184970690376		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 2.3482184970690376 | validation: 3.5513669483374306]
	TIME [epoch: 27.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.358817560170895		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 2.358817560170895 | validation: 3.5451880500630395]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3370351062712453		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 2.3370351062712453 | validation: 3.542004691365217]
	TIME [epoch: 27.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3482850969449163		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 2.3482850969449163 | validation: 3.5288916770379126]
	TIME [epoch: 27.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3336961091377835		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 2.3336961091377835 | validation: 3.5375359751003805]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3487072674838254		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 2.3487072674838254 | validation: 3.589628042791153]
	TIME [epoch: 27.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328717776388367		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 2.328717776388367 | validation: 3.520673724494107]
	TIME [epoch: 27.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3151985637970482		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 2.3151985637970482 | validation: 3.6217379411703967]
	TIME [epoch: 27.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373642456611327		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 2.373642456611327 | validation: 3.5755536856060757]
	TIME [epoch: 27.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3464987535054		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 2.3464987535054 | validation: 3.5287193965203394]
	TIME [epoch: 27.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3180019672248147		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 2.3180019672248147 | validation: 3.5216829857991696]
	TIME [epoch: 27.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31711743179832		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 2.31711743179832 | validation: 3.506275355772758]
	TIME [epoch: 27.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3407304468551016		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 2.3407304468551016 | validation: 3.5743973649489544]
	TIME [epoch: 27.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3470550394973135		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 2.3470550394973135 | validation: 3.5265383769022027]
	TIME [epoch: 27.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313939245905197		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 2.313939245905197 | validation: 3.557121343567504]
	TIME [epoch: 27.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3374282911176527		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 2.3374282911176527 | validation: 3.527386329423372]
	TIME [epoch: 27.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.395931105737064		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 2.395931105737064 | validation: 3.61922038079098]
	TIME [epoch: 27.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3839742587514943		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 2.3839742587514943 | validation: 3.5151528576477675]
	TIME [epoch: 27.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3151780879081327		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 2.3151780879081327 | validation: 3.5727046774149063]
	TIME [epoch: 27.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3435681803002995		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 2.3435681803002995 | validation: 3.538194403665695]
	TIME [epoch: 27.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.335877086001871		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 2.335877086001871 | validation: 3.5153924362983093]
	TIME [epoch: 27.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325359433165493		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 2.325359433165493 | validation: 3.581544039335962]
	TIME [epoch: 27.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3480325270612377		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 2.3480325270612377 | validation: 3.524114642583648]
	TIME [epoch: 27.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3231526138409153		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 2.3231526138409153 | validation: 3.5173745661273914]
	TIME [epoch: 27.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325476830307415		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 2.325476830307415 | validation: 3.5126618834983176]
	TIME [epoch: 27.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326768805956265		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 2.326768805956265 | validation: 3.616110830198482]
	TIME [epoch: 27.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3600443945610508		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 2.3600443945610508 | validation: 3.5229267253682988]
	TIME [epoch: 27.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3161801091812806		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 2.3161801091812806 | validation: 3.568372263806176]
	TIME [epoch: 27.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328374176641522		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 2.328374176641522 | validation: 3.5393607902109343]
	TIME [epoch: 27.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3246575647052037		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 2.3246575647052037 | validation: 3.545653661469868]
	TIME [epoch: 27.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330369419461573		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 2.330369419461573 | validation: 3.5179662369140887]
	TIME [epoch: 27.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336754398725631		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 2.336754398725631 | validation: 3.5211193357003943]
	TIME [epoch: 27.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354461098793416		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 2.354461098793416 | validation: 3.5498046709844]
	TIME [epoch: 27.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.336791051749925		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 2.336791051749925 | validation: 3.5209780774653234]
	TIME [epoch: 27.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3436219865659726		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 2.3436219865659726 | validation: 3.514181984890435]
	TIME [epoch: 27.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328342067427375		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 2.328342067427375 | validation: 3.6149435765233795]
	TIME [epoch: 27.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.36585904859511		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 2.36585904859511 | validation: 3.545956966990906]
	TIME [epoch: 27.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343302748859137		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 2.343302748859137 | validation: 3.5477228129678977]
	TIME [epoch: 27.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3452167345723636		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 2.3452167345723636 | validation: 3.542784790749131]
	TIME [epoch: 27.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326265168002842		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 2.326265168002842 | validation: 3.519642450028209]
	TIME [epoch: 27.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3692532254128746		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 2.3692532254128746 | validation: 3.5668037059565165]
	TIME [epoch: 27.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3563890220494614		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 2.3563890220494614 | validation: 3.524633739023754]
	TIME [epoch: 27.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3467043937769017		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 2.3467043937769017 | validation: 3.5084913452967097]
	TIME [epoch: 27.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3270391038207525		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 2.3270391038207525 | validation: 3.527662348474306]
	TIME [epoch: 27.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3176852641618924		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 2.3176852641618924 | validation: 3.5432352566734404]
	TIME [epoch: 27.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32649116313199		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 2.32649116313199 | validation: 3.5676137594756474]
	TIME [epoch: 27.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3698883930104095		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 2.3698883930104095 | validation: 3.5303555262298576]
	TIME [epoch: 27.7 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331950345452605		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 2.331950345452605 | validation: 3.526775470733744]
	TIME [epoch: 27.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320445185918639		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 2.320445185918639 | validation: 3.533949680244998]
	TIME [epoch: 27.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3112749573642213		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 2.3112749573642213 | validation: 3.5174402647870777]
	TIME [epoch: 27.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315334198225779		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 2.315334198225779 | validation: 3.514963912861556]
	TIME [epoch: 27.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3231293813018086		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 2.3231293813018086 | validation: 3.5096733944885057]
	TIME [epoch: 27.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340142082472477		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 2.340142082472477 | validation: 3.5603581848221615]
	TIME [epoch: 27.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.326198614259927		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 2.326198614259927 | validation: 3.5338818435399073]
	TIME [epoch: 27.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350950082724613		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 2.350950082724613 | validation: 3.5123926081856225]
	TIME [epoch: 27.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3439466433374054		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 2.3439466433374054 | validation: 3.5457045211659035]
	TIME [epoch: 27.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3369767584318124		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 2.3369767584318124 | validation: 3.5373130356712568]
	TIME [epoch: 27.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32272692958213		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 2.32272692958213 | validation: 3.5107202945771916]
	TIME [epoch: 27.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32043246561307		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 2.32043246561307 | validation: 3.5246974746070987]
	TIME [epoch: 27.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322188686598959		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 2.322188686598959 | validation: 3.5395621512754167]
	TIME [epoch: 27.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316345954960606		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 2.316345954960606 | validation: 3.525237602943072]
	TIME [epoch: 27.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3080297491690636		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 2.3080297491690636 | validation: 3.525030203837582]
	TIME [epoch: 27.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3071528402841146		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 2.3071528402841146 | validation: 3.5066875357421132]
	TIME [epoch: 27.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3114906052908237		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 2.3114906052908237 | validation: 3.6165471314916364]
	TIME [epoch: 27.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3355830881393995		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 2.3355830881393995 | validation: 3.512731356761382]
	TIME [epoch: 27.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342765594821795		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 2.342765594821795 | validation: 3.4993291879773727]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373505615505953		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 2.373505615505953 | validation: 3.710593781225333]
	TIME [epoch: 27.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3717497175350166		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 2.3717497175350166 | validation: 3.5120772115564445]
	TIME [epoch: 27.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.365143755534801		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 2.365143755534801 | validation: 3.520402598573753]
	TIME [epoch: 27.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.363773915497072		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 2.363773915497072 | validation: 3.565810135102371]
	TIME [epoch: 27.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3259069929406686		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 2.3259069929406686 | validation: 3.5142314575101286]
	TIME [epoch: 27.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305028733961718		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 2.305028733961718 | validation: 3.5720222297615125]
	TIME [epoch: 27.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3261673099509355		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 2.3261673099509355 | validation: 3.5089269774555594]
	TIME [epoch: 27.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3082356675693463		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 2.3082356675693463 | validation: 3.531514517486177]
	TIME [epoch: 27.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.340574298283345		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 2.340574298283345 | validation: 3.5108149978611802]
	TIME [epoch: 27.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3188626071526226		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 2.3188626071526226 | validation: 3.5233396963909986]
	TIME [epoch: 27.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.373733093387701		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 2.373733093387701 | validation: 3.516658156036399]
	TIME [epoch: 27.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3287154662915137		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 2.3287154662915137 | validation: 3.5256824128084925]
	TIME [epoch: 27.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321067558551977		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 2.321067558551977 | validation: 3.520280918383032]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312808182615459		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 2.312808182615459 | validation: 3.519551094587583]
	TIME [epoch: 27.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3101523186490573		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 2.3101523186490573 | validation: 3.495268059199996]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_894.pth
	Model improved!!!
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3138482363178987		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 2.3138482363178987 | validation: 3.55016434664003]
	TIME [epoch: 27.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3137976336100867		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 2.3137976336100867 | validation: 3.535408421822841]
	TIME [epoch: 27.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354639611137661		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 2.354639611137661 | validation: 3.535615353057086]
	TIME [epoch: 27.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3348214121346826		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 2.3348214121346826 | validation: 3.573514407903857]
	TIME [epoch: 27.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332073738939549		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 2.332073738939549 | validation: 3.513834978979093]
	TIME [epoch: 27.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3113401852365056		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 2.3113401852365056 | validation: 3.5340483277258334]
	TIME [epoch: 27.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3163377345441374		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 2.3163377345441374 | validation: 3.5219827858804615]
	TIME [epoch: 27.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3135828404716556		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 2.3135828404716556 | validation: 3.5252213489231763]
	TIME [epoch: 27.7 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3282148385852572		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 2.3282148385852572 | validation: 3.5257728674900206]
	TIME [epoch: 27.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303268525926178		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 2.303268525926178 | validation: 3.5114123350710216]
	TIME [epoch: 27.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3044412545161816		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 2.3044412545161816 | validation: 3.5236621327848865]
	TIME [epoch: 27.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3182646772489077		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 2.3182646772489077 | validation: 3.5772464903367656]
	TIME [epoch: 27.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3396153511946256		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 2.3396153511946256 | validation: 3.54482550808731]
	TIME [epoch: 27.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313993401273789		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 2.313993401273789 | validation: 3.510179145106392]
	TIME [epoch: 28.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.368793326864312		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 2.368793326864312 | validation: 3.5207400449200996]
	TIME [epoch: 27.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317772395386506		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 2.317772395386506 | validation: 3.523528507589272]
	TIME [epoch: 27.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3127112801420857		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 2.3127112801420857 | validation: 3.5100412452280803]
	TIME [epoch: 27.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305680246057214		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 2.305680246057214 | validation: 3.5238145697282572]
	TIME [epoch: 27.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3215040309268358		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 2.3215040309268358 | validation: 3.5503702421801724]
	TIME [epoch: 27.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3205134988902025		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 2.3205134988902025 | validation: 3.526821374897366]
	TIME [epoch: 27.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3030204275413584		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 2.3030204275413584 | validation: 3.51234965823867]
	TIME [epoch: 27.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3111392135274316		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 2.3111392135274316 | validation: 3.5033606164615203]
	TIME [epoch: 27.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311678756460133		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 2.311678756460133 | validation: 3.515715745266304]
	TIME [epoch: 27.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3098281642764777		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 2.3098281642764777 | validation: 3.4950106352196997]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_918.pth
	Model improved!!!
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.350194005035373		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 2.350194005035373 | validation: 3.503617116150086]
	TIME [epoch: 27.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299177826739408		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 2.299177826739408 | validation: 3.526773440293606]
	TIME [epoch: 27.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3313455925304867		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 2.3313455925304867 | validation: 3.509344919308251]
	TIME [epoch: 27.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334750644137891		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 2.334750644137891 | validation: 3.5050339413194087]
	TIME [epoch: 27.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3243640700293886		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 2.3243640700293886 | validation: 3.517397587753487]
	TIME [epoch: 27.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3088186234548185		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 2.3088186234548185 | validation: 3.509945483508309]
	TIME [epoch: 27.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306924520745331		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 2.306924520745331 | validation: 3.509276346333933]
	TIME [epoch: 27.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.316819964783353		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 2.316819964783353 | validation: 3.5197339183065406]
	TIME [epoch: 27.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3054475560410985		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 2.3054475560410985 | validation: 3.497087765285178]
	TIME [epoch: 27.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3049887649348935		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 2.3049887649348935 | validation: 3.515508232109903]
	TIME [epoch: 27.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3065362644887273		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 2.3065362644887273 | validation: 3.5322990812296884]
	TIME [epoch: 27.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.324991426829267		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 2.324991426829267 | validation: 3.516407002521485]
	TIME [epoch: 27.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3071852978530263		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 2.3071852978530263 | validation: 3.499712501755526]
	TIME [epoch: 27.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.305559998855007		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 2.305559998855007 | validation: 3.5217310182063035]
	TIME [epoch: 27.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319919733736577		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 2.319919733736577 | validation: 3.554244974164687]
	TIME [epoch: 27.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31383610507563		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 2.31383610507563 | validation: 3.541450119007131]
	TIME [epoch: 27.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308050066907201		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 2.308050066907201 | validation: 3.5419674217795465]
	TIME [epoch: 27.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3240391183518287		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 2.3240391183518287 | validation: 3.5122037366128036]
	TIME [epoch: 27.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310778412208031		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 2.310778412208031 | validation: 3.577584301195007]
	TIME [epoch: 27.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343657291309505		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 2.343657291309505 | validation: 3.5754248848212513]
	TIME [epoch: 27.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3430758627195782		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 2.3430758627195782 | validation: 3.5087477312030706]
	TIME [epoch: 27.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311208709537958		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 2.311208709537958 | validation: 3.51467633957322]
	TIME [epoch: 27.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325857294190433		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 2.325857294190433 | validation: 3.5027073784727283]
	TIME [epoch: 27.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3120263650084816		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 2.3120263650084816 | validation: 3.522863069131856]
	TIME [epoch: 27.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3088265281670686		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 2.3088265281670686 | validation: 3.5000346363046084]
	TIME [epoch: 27.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325004846285251		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 2.325004846285251 | validation: 3.488875753578897]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_944.pth
	Model improved!!!
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311457258184304		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 2.311457258184304 | validation: 3.5139866135024818]
	TIME [epoch: 27.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31661035892399		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 2.31661035892399 | validation: 3.5209972058166263]
	TIME [epoch: 27.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3108014036522073		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 2.3108014036522073 | validation: 3.5039064615198177]
	TIME [epoch: 27.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29820528179009		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 2.29820528179009 | validation: 3.523080211047915]
	TIME [epoch: 27.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3360832538202123		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 2.3360832538202123 | validation: 3.504205935400403]
	TIME [epoch: 27.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310795522624805		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 2.310795522624805 | validation: 3.5088036057597423]
	TIME [epoch: 27.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3289339825191706		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 2.3289339825191706 | validation: 3.487006025653743]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_951.pth
	Model improved!!!
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318291129606296		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 2.318291129606296 | validation: 3.494566174168219]
	TIME [epoch: 27.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311489645430503		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 2.311489645430503 | validation: 3.501951873722868]
	TIME [epoch: 27.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309747922305448		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 2.309747922305448 | validation: 3.532140782177404]
	TIME [epoch: 27.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3222361141196903		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 2.3222361141196903 | validation: 3.572782386012475]
	TIME [epoch: 27.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.364590760352724		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 2.364590760352724 | validation: 3.500609964139709]
	TIME [epoch: 27.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2989098768466145		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 2.2989098768466145 | validation: 3.5083201345191]
	TIME [epoch: 27.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3125789175222864		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 2.3125789175222864 | validation: 3.5140099243643506]
	TIME [epoch: 27.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3241525399243965		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 2.3241525399243965 | validation: 3.501084867310027]
	TIME [epoch: 27.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308354337241548		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 2.308354337241548 | validation: 3.5011398949157546]
	TIME [epoch: 27.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3396819536965814		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 2.3396819536965814 | validation: 3.5607046599402143]
	TIME [epoch: 27.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3271487127849912		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 2.3271487127849912 | validation: 3.5002186807315594]
	TIME [epoch: 27.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320765276414775		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 2.320765276414775 | validation: 3.5398878051698626]
	TIME [epoch: 27.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317503436587823		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 2.317503436587823 | validation: 3.5068785219463887]
	TIME [epoch: 27.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3026178748413075		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 2.3026178748413075 | validation: 3.5251871957847727]
	TIME [epoch: 27.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3143805364742867		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 2.3143805364742867 | validation: 3.507368388387504]
	TIME [epoch: 27.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.332808935133574		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 2.332808935133574 | validation: 3.512020485280136]
	TIME [epoch: 27.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315981029564652		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 2.315981029564652 | validation: 3.5003191505079987]
	TIME [epoch: 27.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3131397864981538		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 2.3131397864981538 | validation: 3.515504475019434]
	TIME [epoch: 27.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318660482703262		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 2.318660482703262 | validation: 3.5029438655653906]
	TIME [epoch: 27.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3016004558673093		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 2.3016004558673093 | validation: 3.5056891911620625]
	TIME [epoch: 27.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304078764939545		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 2.304078764939545 | validation: 3.5456423415447795]
	TIME [epoch: 27.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3276970257754983		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 2.3276970257754983 | validation: 3.501309605623195]
	TIME [epoch: 27.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3178846336123913		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 2.3178846336123913 | validation: 3.5018298338574745]
	TIME [epoch: 27.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313783657787728		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 2.313783657787728 | validation: 3.512867194590274]
	TIME [epoch: 27.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.377721250319238		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 2.377721250319238 | validation: 3.512143292279877]
	TIME [epoch: 27.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3352882197115292		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 2.3352882197115292 | validation: 3.577999565478484]
	TIME [epoch: 27.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3281000678655754		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 2.3281000678655754 | validation: 3.522256318378353]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.311190543858145		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 2.311190543858145 | validation: 3.5629574213943114]
	TIME [epoch: 27.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.321415950411229		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 2.321415950411229 | validation: 3.5270894417150345]
	TIME [epoch: 27.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3274328520090144		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 2.3274328520090144 | validation: 3.5233889881849705]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2952809168236095		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 2.2952809168236095 | validation: 3.5192530320776547]
	TIME [epoch: 27.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3152975474774724		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 2.3152975474774724 | validation: 3.5088250491116173]
	TIME [epoch: 27.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.37867882025229		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 2.37867882025229 | validation: 3.5670249330421377]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317976449462977		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 2.317976449462977 | validation: 3.500120761505109]
	TIME [epoch: 27.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2939165897049123		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 2.2939165897049123 | validation: 3.4991345284974353]
	TIME [epoch: 27.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3172627080078834		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 2.3172627080078834 | validation: 3.502973393460186]
	TIME [epoch: 27.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.322049187064506		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 2.322049187064506 | validation: 3.521298786608775]
	TIME [epoch: 27.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.315624797090482		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 2.315624797090482 | validation: 3.511588635578322]
	TIME [epoch: 27.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328565549306079		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 2.328565549306079 | validation: 3.5102399231813672]
	TIME [epoch: 27.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3086344084690698		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 2.3086344084690698 | validation: 3.511604429378717]
	TIME [epoch: 27.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.310462403726267		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 2.310462403726267 | validation: 3.5201449102756466]
	TIME [epoch: 27.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309744257469388		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 2.309744257469388 | validation: 3.5112998890282734]
	TIME [epoch: 27.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308138775480123		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 2.308138775480123 | validation: 3.500639359511512]
	TIME [epoch: 27.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2975848927921456		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 2.2975848927921456 | validation: 3.502783493848887]
	TIME [epoch: 27.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3146632312754134		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 2.3146632312754134 | validation: 3.5342503295482204]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313577554914281		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 2.313577554914281 | validation: 3.5121731906428515]
	TIME [epoch: 27.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3545207228531004		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 2.3545207228531004 | validation: 3.521717587290086]
	TIME [epoch: 27.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306624244511858		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 2.306624244511858 | validation: 3.492057171858927]
	TIME [epoch: 27.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3040713912103605		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 2.3040713912103605 | validation: 3.4885531772379283]
	TIME [epoch: 27.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.317921602750851		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 2.317921602750851 | validation: 3.501348723123134]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304674385915905		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 2.304674385915905 | validation: 3.505876207484507]
	TIME [epoch: 27.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306427906525843		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 2.306427906525843 | validation: 3.4928657505209664]
	TIME [epoch: 27.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309228966072811		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 2.309228966072811 | validation: 3.5091581160216925]
	TIME [epoch: 27.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3035038525631366		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 2.3035038525631366 | validation: 3.4987069364577996]
	TIME [epoch: 27.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296442188499222		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 2.296442188499222 | validation: 3.4910359442495587]
	TIME [epoch: 27.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302413672085054		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 2.302413672085054 | validation: 3.507957310382888]
	TIME [epoch: 27.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3130083550956035		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 2.3130083550956035 | validation: 3.500752676545334]
	TIME [epoch: 27.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2993339351196096		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 2.2993339351196096 | validation: 3.4994960055852022]
	TIME [epoch: 27.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3156261384798285		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 2.3156261384798285 | validation: 3.530822490692383]
	TIME [epoch: 27.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3381056050506928		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 2.3381056050506928 | validation: 3.527315258019964]
	TIME [epoch: 27.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3074158472462747		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 2.3074158472462747 | validation: 3.5024077417935713]
	TIME [epoch: 27.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3052905163130335		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 2.3052905163130335 | validation: 3.4990007952587674]
	TIME [epoch: 27.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2914419700938335		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 2.2914419700938335 | validation: 3.4997763470109646]
	TIME [epoch: 27.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295407013943542		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 2.295407013943542 | validation: 3.514080729689383]
	TIME [epoch: 27.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301210681299333		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 2.301210681299333 | validation: 3.4956587371513557]
	TIME [epoch: 27.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3146738078335862		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 2.3146738078335862 | validation: 3.515028463986622]
	TIME [epoch: 27.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3109770076138227		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 2.3109770076138227 | validation: 3.502357592317535]
	TIME [epoch: 27.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307928935319789		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 2.307928935319789 | validation: 3.492811538245991]
	TIME [epoch: 27.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3101366489950284		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 2.3101366489950284 | validation: 3.5451852133841433]
	TIME [epoch: 27.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.313929090066882		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 2.313929090066882 | validation: 3.503373587373336]
	TIME [epoch: 27.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3006925320269045		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 2.3006925320269045 | validation: 3.5069711084124764]
	TIME [epoch: 27.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2960961065871417		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 2.2960961065871417 | validation: 3.50819421104684]
	TIME [epoch: 27.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2948054250769787		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 2.2948054250769787 | validation: 3.5108982042603003]
	TIME [epoch: 27.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3106627084432882		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 2.3106627084432882 | validation: 3.504079979365034]
	TIME [epoch: 27.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301265385431889		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 2.301265385431889 | validation: 3.5347362107617353]
	TIME [epoch: 27.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3085680811190215		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 2.3085680811190215 | validation: 3.5026022493666926]
	TIME [epoch: 27.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909677637180654		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 2.2909677637180654 | validation: 3.4984765327305865]
	TIME [epoch: 27.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297563958778607		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 2.297563958778607 | validation: 3.528190393144324]
	TIME [epoch: 27.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3075856477456282		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 2.3075856477456282 | validation: 3.5032312056283472]
	TIME [epoch: 27.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2932542496078834		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 2.2932542496078834 | validation: 3.5024743633401885]
	TIME [epoch: 27.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3099854549754775		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 2.3099854549754775 | validation: 3.5136761629389954]
	TIME [epoch: 27.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307965270443044		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 2.307965270443044 | validation: 3.50481625339703]
	TIME [epoch: 27.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2962141336308455		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 2.2962141336308455 | validation: 3.530165649993354]
	TIME [epoch: 27.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303524594086237		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 2.303524594086237 | validation: 3.5005489431447065]
	TIME [epoch: 27.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291085666265678		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 2.291085666265678 | validation: 3.4864274223406353]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3017727105912678		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 2.3017727105912678 | validation: 3.5210578511609927]
	TIME [epoch: 27.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.319231188280318		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 2.319231188280318 | validation: 3.615477537291958]
	TIME [epoch: 27.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3417873177608204		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 2.3417873177608204 | validation: 3.5297660171472405]
	TIME [epoch: 27.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3080905527390954		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 2.3080905527390954 | validation: 3.4963822861201734]
	TIME [epoch: 27.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290730388456388		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 2.290730388456388 | validation: 3.4953484662413588]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3100015223215298		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 2.3100015223215298 | validation: 3.5141014296485293]
	TIME [epoch: 27.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3129608237551946		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 2.3129608237551946 | validation: 3.5113117064451105]
	TIME [epoch: 27.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302885514933739		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 2.302885514933739 | validation: 3.4908558157739096]
	TIME [epoch: 27.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2960006892615135		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 2.2960006892615135 | validation: 3.49241887797222]
	TIME [epoch: 27.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2942296705794387		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 2.2942296705794387 | validation: 3.4887635834964414]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309556737819289		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 2.309556737819289 | validation: 3.4997930622070004]
	TIME [epoch: 27.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296673314019399		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 2.296673314019399 | validation: 3.4990866816997097]
	TIME [epoch: 27.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299266506025022		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 2.299266506025022 | validation: 3.491775400533627]
	TIME [epoch: 27.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.320286819425217		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 2.320286819425217 | validation: 3.4903183205598283]
	TIME [epoch: 27.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2921178308136665		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 2.2921178308136665 | validation: 3.520214420051044]
	TIME [epoch: 27.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32836083200196		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 2.32836083200196 | validation: 3.528983068670803]
	TIME [epoch: 27.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299436229083646		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 2.299436229083646 | validation: 3.492132485659685]
	TIME [epoch: 27.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328709920630599		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 2.328709920630599 | validation: 3.4956531406053855]
	TIME [epoch: 27.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302750177195476		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 2.302750177195476 | validation: 3.538204133535137]
	TIME [epoch: 27.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296799166038021		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 2.296799166038021 | validation: 3.495140473854955]
	TIME [epoch: 27.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2981343653577575		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 2.2981343653577575 | validation: 3.519857487282112]
	TIME [epoch: 27.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2976545673343036		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 2.2976545673343036 | validation: 3.509608727844335]
	TIME [epoch: 27.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295867975240874		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 2.295867975240874 | validation: 3.4862089785847616]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_1059.pth
	Model improved!!!
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3106753255720047		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 2.3106753255720047 | validation: 3.4923221664122743]
	TIME [epoch: 27.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3068199896625674		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 2.3068199896625674 | validation: 3.4955507412010935]
	TIME [epoch: 27.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3066203461925436		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 2.3066203461925436 | validation: 3.4928035185553346]
	TIME [epoch: 27.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3010567228879433		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 2.3010567228879433 | validation: 3.4990893008674555]
	TIME [epoch: 27.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301010997169479		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 2.301010997169479 | validation: 3.533641304694921]
	TIME [epoch: 27.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3159231397944025		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 2.3159231397944025 | validation: 3.500400982155783]
	TIME [epoch: 27.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2998609380395987		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 2.2998609380395987 | validation: 3.518389830036483]
	TIME [epoch: 27.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.309721537453835		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 2.309721537453835 | validation: 3.5025481671127356]
	TIME [epoch: 27.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299225232571847		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 2.299225232571847 | validation: 3.478275832220033]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study205/model_tr_study205_r0_20240310_051938/states/model_tr_study205_1068.pth
	Model improved!!!
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2929255998589504		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 2.2929255998589504 | validation: 3.497048632158045]
	TIME [epoch: 27.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302345749055073		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 2.302345749055073 | validation: 3.5324632871741812]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3111754474601898		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 2.3111754474601898 | validation: 3.502470308478341]
	TIME [epoch: 27.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299861786866384		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 2.299861786866384 | validation: 3.4989168098548045]
	TIME [epoch: 27.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2942506806687093		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 2.2942506806687093 | validation: 3.486754413603953]
	TIME [epoch: 27.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2889435101259084		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 2.2889435101259084 | validation: 3.4922314017359315]
	TIME [epoch: 27.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.295958592142113		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 2.295958592142113 | validation: 3.4925262963334274]
	TIME [epoch: 27.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.325459453663853		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 2.325459453663853 | validation: 3.4974445934590292]
	TIME [epoch: 27.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296333393163065		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 2.296333393163065 | validation: 3.497123124154052]
	TIME [epoch: 27.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2936230731081806		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 2.2936230731081806 | validation: 3.5224343644476317]
	TIME [epoch: 27.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3395695235715097		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 2.3395695235715097 | validation: 3.4943558692428303]
	TIME [epoch: 27.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2960841608466604		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 2.2960841608466604 | validation: 3.4980640322353724]
	TIME [epoch: 27.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2906050975421604		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 2.2906050975421604 | validation: 3.4936436308182]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284874131760853		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 2.284874131760853 | validation: 3.492509161707125]
	TIME [epoch: 27.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2969758612038644		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 2.2969758612038644 | validation: 3.5130334346740675]
	TIME [epoch: 27.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296618555544069		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 2.296618555544069 | validation: 3.4905840727734123]
	TIME [epoch: 27.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2935611626766788		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 2.2935611626766788 | validation: 3.5110003627401456]
	TIME [epoch: 27.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314183040533522		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 2.314183040533522 | validation: 3.5007272219161623]
	TIME [epoch: 27.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.318040530190756		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 2.318040530190756 | validation: 3.51499685099731]
	TIME [epoch: 27.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294218728497945		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 2.294218728497945 | validation: 3.4793355575153058]
	TIME [epoch: 27.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862288479383275		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 2.2862288479383275 | validation: 3.4926680660156997]
	TIME [epoch: 27.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30118388816046		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 2.30118388816046 | validation: 3.491410779565286]
	TIME [epoch: 27.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298712492326691		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 2.298712492326691 | validation: 3.4901382021863663]
	TIME [epoch: 27.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2878608962405576		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 2.2878608962405576 | validation: 3.4958799219694616]
	TIME [epoch: 27.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2996033876641566		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 2.2996033876641566 | validation: 3.5106516041911178]
	TIME [epoch: 27.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3079170014703694		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 2.3079170014703694 | validation: 3.527696098029524]
	TIME [epoch: 27.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331865158531282		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 2.331865158531282 | validation: 3.546878614411205]
	TIME [epoch: 27.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312026180170109		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 2.312026180170109 | validation: 3.495378529907889]
	TIME [epoch: 27.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298938391278079		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 2.298938391278079 | validation: 3.500777890102589]
	TIME [epoch: 27.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2944843281868597		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 2.2944843281868597 | validation: 3.4801676328601774]
	TIME [epoch: 27.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290289254182325		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 2.290289254182325 | validation: 3.5005688419025267]
	TIME [epoch: 27.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2916681856419023		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 2.2916681856419023 | validation: 3.494498409405088]
	TIME [epoch: 27.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2930386022766838		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 2.2930386022766838 | validation: 3.500459980890811]
	TIME [epoch: 27.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3050546243765186		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 2.3050546243765186 | validation: 3.49545536291866]
	TIME [epoch: 27.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296874996245438		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 2.296874996245438 | validation: 3.499802825027272]
	TIME [epoch: 27.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2964210935652685		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 2.2964210935652685 | validation: 3.508557351107476]
	TIME [epoch: 27.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2934898549369125		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 2.2934898549369125 | validation: 3.492521448309063]
	TIME [epoch: 27.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290086773247318		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 2.290086773247318 | validation: 3.4893568375257904]
	TIME [epoch: 27.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2907829764465575		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 2.2907829764465575 | validation: 3.5018352644416497]
	TIME [epoch: 27.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289341420155289		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 2.289341420155289 | validation: 3.497842879041587]
	TIME [epoch: 27.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3011660178930295		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 2.3011660178930295 | validation: 3.5040524453021193]
	TIME [epoch: 27.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3075522805431317		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 2.3075522805431317 | validation: 3.5238618381237883]
	TIME [epoch: 27.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3290716574874684		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 2.3290716574874684 | validation: 3.5376899634721113]
	TIME [epoch: 27.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2985800057829846		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 2.2985800057829846 | validation: 3.4790384885058416]
	TIME [epoch: 27.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296404373044984		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 2.296404373044984 | validation: 3.4824193607101606]
	TIME [epoch: 27.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292274460782448		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 2.292274460782448 | validation: 3.5069434940920963]
	TIME [epoch: 27.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3169690091850814		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 2.3169690091850814 | validation: 3.5237047291791725]
	TIME [epoch: 27.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3051018307985376		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 2.3051018307985376 | validation: 3.4919804630572897]
	TIME [epoch: 27.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.289578467903313		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 2.289578467903313 | validation: 3.496025932370283]
	TIME [epoch: 27.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2897935493916073		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 2.2897935493916073 | validation: 3.484306469599677]
	TIME [epoch: 27.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290988983419873		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 2.290988983419873 | validation: 3.4813573497554193]
	TIME [epoch: 27.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.312111242361278		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 2.312111242361278 | validation: 3.4910829565805312]
	TIME [epoch: 27.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307575795636063		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 2.307575795636063 | validation: 3.503474772215302]
	TIME [epoch: 27.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2933206828584627		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 2.2933206828584627 | validation: 3.47846932222826]
	TIME [epoch: 27.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3119282384283153		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 2.3119282384283153 | validation: 3.4887509526163423]
	TIME [epoch: 27.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.302274206405474		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 2.302274206405474 | validation: 3.525333544338862]
	TIME [epoch: 27.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.299904744366816		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 2.299904744366816 | validation: 3.484415231898554]
	TIME [epoch: 27.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3017737585609943		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 2.3017737585609943 | validation: 3.5164780622252914]
	TIME [epoch: 27.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3119428122857606		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 2.3119428122857606 | validation: 3.5070980910680585]
	TIME [epoch: 27.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294155098234594		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 2.294155098234594 | validation: 3.5024532358914477]
	TIME [epoch: 27.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286729026852779		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 2.286729026852779 | validation: 3.4918930906152164]
	TIME [epoch: 27.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293987573819786		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 2.293987573819786 | validation: 3.483748919583278]
	TIME [epoch: 27.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291700669414348		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 2.291700669414348 | validation: 3.489107714453023]
	TIME [epoch: 27.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292764354634399		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 2.292764354634399 | validation: 3.4853520831916853]
	TIME [epoch: 27.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2927091034935105		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 2.2927091034935105 | validation: 3.5005930665773715]
	TIME [epoch: 27.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291961315747187		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 2.291961315747187 | validation: 3.484791991975505]
	TIME [epoch: 27.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2895193201532305		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 2.2895193201532305 | validation: 3.4936742847257154]
	TIME [epoch: 27.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2902929254793065		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 2.2902929254793065 | validation: 3.500096572449302]
	TIME [epoch: 27.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.29786875236444		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 2.29786875236444 | validation: 3.503941003343466]
	TIME [epoch: 27.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.301887349632674		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 2.301887349632674 | validation: 3.5219980087121643]
	TIME [epoch: 27.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.314373821786896		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 2.314373821786896 | validation: 3.5012401619922002]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297509129890922		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 2.297509129890922 | validation: 3.5011376746021243]
	TIME [epoch: 27.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2915420699717144		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 2.2915420699717144 | validation: 3.5066478975823965]
	TIME [epoch: 27.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2903863325187297		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 2.2903863325187297 | validation: 3.48935976529149]
	TIME [epoch: 27.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.287174616168207		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 2.287174616168207 | validation: 3.5060403102981095]
	TIME [epoch: 27.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2970824537793373		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 2.2970824537793373 | validation: 3.505217961361874]
	TIME [epoch: 27.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297439375373611		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 2.297439375373611 | validation: 3.50305600806315]
	TIME [epoch: 27.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2878160091917494		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 2.2878160091917494 | validation: 3.5095895376747133]
	TIME [epoch: 27.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2931034848835488		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 2.2931034848835488 | validation: 3.487027883789656]
	TIME [epoch: 27.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292017056299578		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 2.292017056299578 | validation: 3.4934156379984134]
	TIME [epoch: 27.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2938722474537863		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 2.2938722474537863 | validation: 3.4902042113388134]
	TIME [epoch: 27.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.288266953839545		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 2.288266953839545 | validation: 3.5110074118022796]
	TIME [epoch: 27.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.297601880173978		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 2.297601880173978 | validation: 3.5022835528959604]
	TIME [epoch: 27.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.290797623924175		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 2.290797623924175 | validation: 3.4947090526075733]
	TIME [epoch: 27.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304968749704303		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 2.304968749704303 | validation: 3.502956994454852]
	TIME [epoch: 27.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.32039211933172		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 2.32039211933172 | validation: 3.487445316725772]
	TIME [epoch: 27.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291718472052428		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 2.291718472052428 | validation: 3.501967849120433]
	TIME [epoch: 27.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2912217933930603		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 2.2912217933930603 | validation: 3.494557068958783]
	TIME [epoch: 27.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296763356249305		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 2.296763356249305 | validation: 3.4831132550202755]
	TIME [epoch: 27.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2949218489149312		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 2.2949218489149312 | validation: 3.486278535607175]
	TIME [epoch: 27.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2930444990693806		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 2.2930444990693806 | validation: 3.48411028379022]
	TIME [epoch: 27.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.292305800923487		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 2.292305800923487 | validation: 3.4871290857683834]
	TIME [epoch: 27.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.303431594383101		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 2.303431594383101 | validation: 3.5282018618844266]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3118302840878084		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 2.3118302840878084 | validation: 3.5049806786693374]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2968645544032684		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 2.2968645544032684 | validation: 3.4909149641201873]
	TIME [epoch: 27.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2861193266194686		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 2.2861193266194686 | validation: 3.483789400903942]
	TIME [epoch: 27.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.286654571823465		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 2.286654571823465 | validation: 3.4950926158954]
	TIME [epoch: 27.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.298118138803942		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 2.298118138803942 | validation: 3.494516864051418]
	TIME [epoch: 27.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3002339608886255		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 2.3002339608886255 | validation: 3.5107605587898396]
	TIME [epoch: 27.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2880090117950553		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 2.2880090117950553 | validation: 3.494906954855409]
	TIME [epoch: 27.7 sec]
EPOCH 1169/2000:
	Training over batches...
