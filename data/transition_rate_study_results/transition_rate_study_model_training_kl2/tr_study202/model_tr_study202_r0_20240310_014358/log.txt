Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r0', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3801621249

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.655837519178371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.655837519178371 | validation: 9.215287343402768]
	TIME [epoch: 92.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.787417624650498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.787417624650498 | validation: 10.936126635921598]
	TIME [epoch: 5.75 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.763105419289749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.763105419289749 | validation: 10.489992711032464]
	TIME [epoch: 5.74 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.21372316447831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.21372316447831 | validation: 6.444896470008818]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.076869680167281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.076869680167281 | validation: 6.28626539287244]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.27419859089596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.27419859089596 | validation: 5.838898320523949]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.937429291400186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.937429291400186 | validation: 5.6104406271831975]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.026862670347375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.026862670347375 | validation: 5.473689373223497]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.801491340456421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.801491340456421 | validation: 5.388806296976334]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9659958210908055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9659958210908055 | validation: 5.09789503029758]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.129325559565084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.129325559565084 | validation: 4.617309788518026]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.910549068844352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.910549068844352 | validation: 4.408479698549885]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.933953904270936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.933953904270936 | validation: 4.417815243368221]
	TIME [epoch: 5.72 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.906979908614421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.906979908614421 | validation: 5.139999696220682]
	TIME [epoch: 5.71 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.203349668882044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.203349668882044 | validation: 4.277604163200042]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.982306189255599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.982306189255599 | validation: 4.315746016513104]
	TIME [epoch: 5.75 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.830111792467929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.830111792467929 | validation: 3.994876143071706]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.910575083786517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.910575083786517 | validation: 4.193186162032446]
	TIME [epoch: 5.71 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.83476176678497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.83476176678497 | validation: 3.995812261887242]
	TIME [epoch: 5.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6935637228880753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6935637228880753 | validation: 3.9476641020003114]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.647456623094654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.647456623094654 | validation: 3.7218879021176208]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.610659806921085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.610659806921085 | validation: 3.7577031676907815]
	TIME [epoch: 5.72 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4799247773538333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4799247773538333 | validation: 3.7536046609394362]
	TIME [epoch: 5.73 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.401668243738083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.401668243738083 | validation: 4.169165233873665]
	TIME [epoch: 5.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5116150972457114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5116150972457114 | validation: 3.2069977924536235]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2682906578864683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2682906578864683 | validation: 3.0401540872393573]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9305103551210685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9305103551210685 | validation: 4.7231937326820495]
	TIME [epoch: 5.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2975766029561653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2975766029561653 | validation: 3.001819824164684]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.613823530225678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.613823530225678 | validation: 3.251168058038885]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7134460578862254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7134460578862254 | validation: 2.6404163456702103]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4704527245236956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4704527245236956 | validation: 2.2622526406487733]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.542054097121281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.542054097121281 | validation: 2.300211623908746]
	TIME [epoch: 5.72 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1752949131965815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1752949131965815 | validation: 3.158412978846796]
	TIME [epoch: 5.72 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.746169290812719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.746169290812719 | validation: 3.1582612355402135]
	TIME [epoch: 5.72 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2798822205618188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2798822205618188 | validation: 2.214802807800734]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4477432825009773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4477432825009773 | validation: 2.01854768193661]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3381189544623804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3381189544623804 | validation: 2.0105692526467225]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124005209862341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.124005209862341 | validation: 1.8050495182625204]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.944996391219811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.944996391219811 | validation: 2.3482258156527327]
	TIME [epoch: 5.72 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.94105202576585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.94105202576585 | validation: 1.9289447236943056]
	TIME [epoch: 5.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9935635595833243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9935635595833243 | validation: 2.018127892578844]
	TIME [epoch: 5.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8515863294514858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8515863294514858 | validation: 3.8022872367926426]
	TIME [epoch: 5.75 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0636294049040003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0636294049040003 | validation: 3.1343532310759703]
	TIME [epoch: 5.72 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0326779781513413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0326779781513413 | validation: 1.7194536627387746]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6746945203026016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6746945203026016 | validation: 1.6658979510379575]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0725069820757014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0725069820757014 | validation: 1.8299133887032761]
	TIME [epoch: 5.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.961313458401355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.961313458401355 | validation: 1.9340562229779437]
	TIME [epoch: 5.72 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7485775719938648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7485775719938648 | validation: 1.2870585021678471]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6834905962845073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6834905962845073 | validation: 1.3869991492779303]
	TIME [epoch: 5.73 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.693134963226478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.693134963226478 | validation: 1.3924256313621723]
	TIME [epoch: 5.71 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.610393184524749		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.610393184524749 | validation: 1.8630957350340882]
	TIME [epoch: 5.71 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5402793679147888		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.5402793679147888 | validation: 1.3325106475534]
	TIME [epoch: 5.71 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4017388077263535		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.4017388077263535 | validation: 1.606454710034637]
	TIME [epoch: 5.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5204004243098244		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.5204004243098244 | validation: 1.6553904346299513]
	TIME [epoch: 5.72 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.512204635404288		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.512204635404288 | validation: 2.553608346238182]
	TIME [epoch: 5.76 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9589136893195018		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.9589136893195018 | validation: 1.8539367554854238]
	TIME [epoch: 5.72 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4358672156111902		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.4358672156111902 | validation: 1.602815644297877]
	TIME [epoch: 5.72 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.448747899186225		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.448747899186225 | validation: 1.1594488731288626]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294996537883933		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.294996537883933 | validation: 1.947913905238173]
	TIME [epoch: 5.72 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6212263501760504		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.6212263501760504 | validation: 1.7759441682914865]
	TIME [epoch: 5.71 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.608840308673492		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.608840308673492 | validation: 1.1561450529804218]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.34780929166567		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.34780929166567 | validation: 1.0905784943526229]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2499832062899312		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.2499832062899312 | validation: 1.294471731875462]
	TIME [epoch: 5.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302194731695622		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.302194731695622 | validation: 1.1121209401732919]
	TIME [epoch: 5.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1957632677773051		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.1957632677773051 | validation: 1.0929499823997053]
	TIME [epoch: 5.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4363175676955278		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.4363175676955278 | validation: 1.3057458373802746]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.413211390809184		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.413211390809184 | validation: 3.157686855769508]
	TIME [epoch: 5.72 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9262943877222487		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.9262943877222487 | validation: 1.929138116748771]
	TIME [epoch: 5.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3713584385392312		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.3713584385392312 | validation: 1.1524067000460492]
	TIME [epoch: 5.71 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2052866212433775		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.2052866212433775 | validation: 1.2669909743249372]
	TIME [epoch: 5.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302389995617057		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.302389995617057 | validation: 1.9982731018134257]
	TIME [epoch: 5.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323907352870617		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.323907352870617 | validation: 1.2583104633853264]
	TIME [epoch: 5.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3700400605099994		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.3700400605099994 | validation: 1.2075248989753389]
	TIME [epoch: 5.71 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0807506751954536		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.0807506751954536 | validation: 1.3239574857324243]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1473342495497303		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.1473342495497303 | validation: 1.024234481346798]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2846372464098557		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.2846372464098557 | validation: 1.0918366989578214]
	TIME [epoch: 5.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3393874365126919		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.3393874365126919 | validation: 0.9282620288615298]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2210630446363835		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.2210630446363835 | validation: 0.8750358119452404]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039320370229412		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.039320370229412 | validation: 1.2811053524814031]
	TIME [epoch: 5.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0422671097987994		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.0422671097987994 | validation: 1.7985175809702492]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806773090306098		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.2806773090306098 | validation: 1.8675190500253593]
	TIME [epoch: 5.71 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.288683760522762		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.288683760522762 | validation: 0.8978658976948205]
	TIME [epoch: 5.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.830585993564482		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.830585993564482 | validation: 1.3664752631333033]
	TIME [epoch: 5.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2617504487227156		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.2617504487227156 | validation: 0.8326746575531919]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9620281491750048		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.9620281491750048 | validation: 2.2578353853432596]
	TIME [epoch: 5.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.423391156978532		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.423391156978532 | validation: 0.8018334747930284]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.969695214991271		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.969695214991271 | validation: 0.7964275433088247]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174962023446309		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.8174962023446309 | validation: 0.8555200409698442]
	TIME [epoch: 5.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037418967862443		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.8037418967862443 | validation: 1.0272277311796745]
	TIME [epoch: 5.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3255674887180255		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.3255674887180255 | validation: 0.8838996373081954]
	TIME [epoch: 5.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9857040183445912		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.9857040183445912 | validation: 0.643697843454014]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9136467838513512		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.9136467838513512 | validation: 1.115802379231747]
	TIME [epoch: 5.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0582424875916094		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.0582424875916094 | validation: 0.7483359113889171]
	TIME [epoch: 5.74 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1166425731279441		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.1166425731279441 | validation: 0.8568872080862877]
	TIME [epoch: 5.71 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.93301317066237		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.93301317066237 | validation: 0.7755456344230518]
	TIME [epoch: 5.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0885985414041004		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.0885985414041004 | validation: 0.9815482323497111]
	TIME [epoch: 5.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9437363739177141		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.9437363739177141 | validation: 0.6910810672389889]
	TIME [epoch: 5.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8697202397096357		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.8697202397096357 | validation: 1.360324654212168]
	TIME [epoch: 5.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9897204083938571		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.9897204083938571 | validation: 1.465134923840093]
	TIME [epoch: 5.71 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120618939027458		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.120618939027458 | validation: 0.7977755641440417]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9968979596744134		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.9968979596744134 | validation: 0.7819422601216477]
	TIME [epoch: 5.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2098133070116148		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.2098133070116148 | validation: 0.785199823972961]
	TIME [epoch: 5.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9635223850503766		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.9635223850503766 | validation: 0.6927854246841005]
	TIME [epoch: 5.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8997498829936627		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.8997498829936627 | validation: 0.6901116883367577]
	TIME [epoch: 5.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8157338044994922		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.8157338044994922 | validation: 1.4825072484442263]
	TIME [epoch: 5.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0783442887549897		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0783442887549897 | validation: 1.3751929398605212]
	TIME [epoch: 5.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874768217437247		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.874768217437247 | validation: 1.3077436280936514]
	TIME [epoch: 5.71 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9667078987056505		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.9667078987056505 | validation: 0.6519878663170645]
	TIME [epoch: 5.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717822225470131		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.717822225470131 | validation: 0.6862730751918342]
	TIME [epoch: 5.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8294485227419635		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.8294485227419635 | validation: 0.6855514167374741]
	TIME [epoch: 5.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700258391288416		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.7700258391288416 | validation: 0.6689055302556253]
	TIME [epoch: 5.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8098913112273451		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.8098913112273451 | validation: 0.5957361701435473]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7995226911791633		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.7995226911791633 | validation: 0.6231812884380686]
	TIME [epoch: 5.73 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826221037289627		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.7826221037289627 | validation: 0.9128515208050624]
	TIME [epoch: 5.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0377420915874098		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.0377420915874098 | validation: 1.553424080918768]
	TIME [epoch: 5.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.896347756448069		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.896347756448069 | validation: 0.5635424427090037]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400529325510183		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.8400529325510183 | validation: 0.7967501404136141]
	TIME [epoch: 5.71 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8007286975518397		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8007286975518397 | validation: 0.796963194098891]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7362853527826351		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.7362853527826351 | validation: 0.8835657824242183]
	TIME [epoch: 5.74 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8767308473172588		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.8767308473172588 | validation: 0.7486296767698744]
	TIME [epoch: 5.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239760915098513		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.7239760915098513 | validation: 0.6663807937805509]
	TIME [epoch: 5.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6460978169881967		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6460978169881967 | validation: 0.5456605997774527]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095357851022406		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7095357851022406 | validation: 1.5755672876987716]
	TIME [epoch: 5.71 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8522804212279388		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.8522804212279388 | validation: 1.0827821995603075]
	TIME [epoch: 5.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8551952251517512		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.8551952251517512 | validation: 0.5506240621249157]
	TIME [epoch: 5.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257784834495806		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.7257784834495806 | validation: 0.5837166212171067]
	TIME [epoch: 5.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108678410341849		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7108678410341849 | validation: 0.6879919548937314]
	TIME [epoch: 5.71 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5954880444299742		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.5954880444299742 | validation: 1.4598317081658068]
	TIME [epoch: 5.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9047166866624268		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.9047166866624268 | validation: 0.6440655294319799]
	TIME [epoch: 5.71 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684120894030338		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7684120894030338 | validation: 0.5654496239256774]
	TIME [epoch: 5.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033781084926656		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.5033781084926656 | validation: 0.6948414608513808]
	TIME [epoch: 5.72 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694244036344182		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.694244036344182 | validation: 0.9113427821288624]
	TIME [epoch: 5.74 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6732068676520777		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.6732068676520777 | validation: 0.6280049841232648]
	TIME [epoch: 5.72 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650285933605864		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.6650285933605864 | validation: 0.5101027985744093]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6146850911710211		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.6146850911710211 | validation: 0.6406717833764007]
	TIME [epoch: 5.71 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951749661404292		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.6951749661404292 | validation: 0.7416102110953352]
	TIME [epoch: 5.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086237422708536		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.7086237422708536 | validation: 0.6027146887893161]
	TIME [epoch: 5.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819142769993304		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5819142769993304 | validation: 0.4615613629329352]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651045366974209		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.651045366974209 | validation: 0.6575728950107604]
	TIME [epoch: 5.72 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057808214326877		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.7057808214326877 | validation: 0.6808018351039351]
	TIME [epoch: 5.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424650024431592		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.6424650024431592 | validation: 0.5216044133877142]
	TIME [epoch: 5.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603350142216851		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.603350142216851 | validation: 0.9298686626050205]
	TIME [epoch: 5.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508595540011352		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.7508595540011352 | validation: 0.5592418675480051]
	TIME [epoch: 5.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5373855055159644		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.5373855055159644 | validation: 0.48220891067617644]
	TIME [epoch: 5.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604417140647851		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.6604417140647851 | validation: 0.6255523213497375]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6294768932641712		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.6294768932641712 | validation: 1.0582349945405296]
	TIME [epoch: 5.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8907190863148652		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8907190863148652 | validation: 1.569567813777233]
	TIME [epoch: 5.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0747532773504425		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0747532773504425 | validation: 0.9778054843290916]
	TIME [epoch: 5.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6915339737179808		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.6915339737179808 | validation: 0.5246442154323314]
	TIME [epoch: 5.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756433184966072		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5756433184966072 | validation: 0.6356828899033709]
	TIME [epoch: 5.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543199166789565		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6543199166789565 | validation: 0.5253938153192208]
	TIME [epoch: 5.73 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5412434315504386		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.5412434315504386 | validation: 0.6046238050429584]
	TIME [epoch: 5.72 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247001752533413		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.7247001752533413 | validation: 0.4793078852838475]
	TIME [epoch: 5.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6732787529569041		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.6732787529569041 | validation: 0.7896051008102362]
	TIME [epoch: 5.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206540196196034		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.6206540196196034 | validation: 0.9400985850260379]
	TIME [epoch: 5.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112892347573857		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.6112892347573857 | validation: 0.49734900482194067]
	TIME [epoch: 5.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529953706387012		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.6529953706387012 | validation: 0.44491089055532373]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6743291269296892		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6743291269296892 | validation: 0.6886628788224476]
	TIME [epoch: 5.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823643023892709		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.6823643023892709 | validation: 0.527548351532283]
	TIME [epoch: 5.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5781987852431612		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.5781987852431612 | validation: 1.071225880175003]
	TIME [epoch: 5.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.671524399305861		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.671524399305861 | validation: 0.8700589492221207]
	TIME [epoch: 5.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7114704518120485		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.7114704518120485 | validation: 0.4074266540424796]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664220599660521		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.4664220599660521 | validation: 0.4511090873309078]
	TIME [epoch: 5.71 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809866639224086		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5809866639224086 | validation: 0.4767420352966372]
	TIME [epoch: 5.75 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333022699376738		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.5333022699376738 | validation: 0.6675547006688451]
	TIME [epoch: 5.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6601430457178608		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.6601430457178608 | validation: 0.4464084397711958]
	TIME [epoch: 5.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4225551879251829		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.4225551879251829 | validation: 0.6770026375436642]
	TIME [epoch: 5.71 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5956423991229123		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5956423991229123 | validation: 0.532806215115662]
	TIME [epoch: 5.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5899253317068106		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.5899253317068106 | validation: 0.4045957890817215]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716711782700442		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.5716711782700442 | validation: 1.3967455747782294]
	TIME [epoch: 5.72 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845287640469074		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.7845287640469074 | validation: 0.4096751920862212]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167226104050404		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5167226104050404 | validation: 0.5455775254036577]
	TIME [epoch: 5.71 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534412279214025		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.5534412279214025 | validation: 0.4866059575670961]
	TIME [epoch: 5.71 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871940254948136		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5871940254948136 | validation: 0.5549447280558383]
	TIME [epoch: 5.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44383508207195305		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.44383508207195305 | validation: 2.3928463555151733]
	TIME [epoch: 5.71 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2821965215165847		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.2821965215165847 | validation: 0.5113149729127897]
	TIME [epoch: 5.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651003657435273		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.4651003657435273 | validation: 0.8053602372807717]
	TIME [epoch: 5.74 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507572546718222		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5507572546718222 | validation: 1.0130253010516501]
	TIME [epoch: 5.72 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438043976651716		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6438043976651716 | validation: 0.5452069545621943]
	TIME [epoch: 5.71 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5457318810757387		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.5457318810757387 | validation: 0.4758093669678402]
	TIME [epoch: 5.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895741380409053		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4895741380409053 | validation: 0.5393398423464478]
	TIME [epoch: 5.71 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651329434494407		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.5651329434494407 | validation: 0.38317615585372133]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514849322122898		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.514849322122898 | validation: 0.5698362213630367]
	TIME [epoch: 5.72 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771823143417948		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.4771823143417948 | validation: 0.6807314184285811]
	TIME [epoch: 5.75 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761632969467045		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.5761632969467045 | validation: 0.46709547564468223]
	TIME [epoch: 5.71 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414704289808521		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.5414704289808521 | validation: 0.6020418040440518]
	TIME [epoch: 5.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42666153268637175		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.42666153268637175 | validation: 0.9009059079001588]
	TIME [epoch: 5.71 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960291375145212		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5960291375145212 | validation: 1.035741696809298]
	TIME [epoch: 5.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190040728104056		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6190040728104056 | validation: 0.7416537306818105]
	TIME [epoch: 5.71 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5823447714627418		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5823447714627418 | validation: 0.4588588983782168]
	TIME [epoch: 5.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708441382855687		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.5708441382855687 | validation: 0.45924151468741514]
	TIME [epoch: 5.71 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696158227759499		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.5696158227759499 | validation: 0.37928028258231067]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619905737892392		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.619905737892392 | validation: 0.5944186442297218]
	TIME [epoch: 5.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6427339303953625		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.6427339303953625 | validation: 0.49752983872118256]
	TIME [epoch: 5.72 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.643141744140153		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.643141744140153 | validation: 0.5101707764199562]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644391174755365		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.5644391174755365 | validation: 0.46543912367242996]
	TIME [epoch: 5.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43831115942880805		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.43831115942880805 | validation: 0.5881001439349697]
	TIME [epoch: 5.74 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015551996490759		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.5015551996490759 | validation: 0.4687398245044615]
	TIME [epoch: 5.72 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5391257667541268		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.5391257667541268 | validation: 0.39755063730801227]
	TIME [epoch: 5.71 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612950242261121		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.5612950242261121 | validation: 0.44777911837750667]
	TIME [epoch: 5.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4063306352541537		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4063306352541537 | validation: 0.4318122567141007]
	TIME [epoch: 5.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579741597903194		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.5579741597903194 | validation: 0.9774737918441645]
	TIME [epoch: 5.72 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117586081990281		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.5117586081990281 | validation: 0.4682858850523431]
	TIME [epoch: 5.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5693088703003596		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.5693088703003596 | validation: 0.41386266880009054]
	TIME [epoch: 5.72 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55523459576604		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.55523459576604 | validation: 0.3943578678649635]
	TIME [epoch: 5.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48497147122652473		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.48497147122652473 | validation: 0.5350502886434556]
	TIME [epoch: 5.72 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663831359519056		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.5663831359519056 | validation: 1.0960175540583637]
	TIME [epoch: 5.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6718884090443373		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6718884090443373 | validation: 0.38014714033028685]
	TIME [epoch: 5.72 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584297348737738		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.584297348737738 | validation: 0.4754916424050646]
	TIME [epoch: 5.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4399639779665605		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.4399639779665605 | validation: 0.5571834875767026]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45773263709946643		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.45773263709946643 | validation: 0.40525011997682414]
	TIME [epoch: 5.71 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42135884940483775		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.42135884940483775 | validation: 0.5165349429583124]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4846945058280734		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.4846945058280734 | validation: 0.42976879723023587]
	TIME [epoch: 5.71 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47326196166128		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.47326196166128 | validation: 0.45936255564111733]
	TIME [epoch: 5.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236071476842963		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5236071476842963 | validation: 0.7420610477075629]
	TIME [epoch: 5.71 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095887402245944		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.5095887402245944 | validation: 0.36205716959653794]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674295399827926		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.4674295399827926 | validation: 1.1676731745114675]
	TIME [epoch: 5.72 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532623852810632		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7532623852810632 | validation: 0.9049142461057901]
	TIME [epoch: 5.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4027749458607015		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.4027749458607015 | validation: 0.6688622839987031]
	TIME [epoch: 5.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093965590782537		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.5093965590782537 | validation: 0.6596941849975315]
	TIME [epoch: 5.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47258368628353575		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.47258368628353575 | validation: 1.1551054565691008]
	TIME [epoch: 5.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722331708667471		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7722331708667471 | validation: 0.749235469750563]
	TIME [epoch: 5.72 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589519256315478		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5589519256315478 | validation: 0.39622227854932]
	TIME [epoch: 5.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43444622857569004		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.43444622857569004 | validation: 0.3813619091604759]
	TIME [epoch: 5.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3452230705806767		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.3452230705806767 | validation: 0.41076292418350746]
	TIME [epoch: 5.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4270138620443611		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.4270138620443611 | validation: 0.4500632774928276]
	TIME [epoch: 5.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5090904014111379		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.5090904014111379 | validation: 0.7436354562395922]
	TIME [epoch: 5.71 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899487736858605		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.4899487736858605 | validation: 1.2736531414182437]
	TIME [epoch: 5.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199921333762227		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6199921333762227 | validation: 0.7423318477004502]
	TIME [epoch: 5.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193398284961578		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.5193398284961578 | validation: 0.39411197496591277]
	TIME [epoch: 5.71 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44066545457049777		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.44066545457049777 | validation: 0.3475996512644104]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4997419287463665		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.4997419287463665 | validation: 0.3445334971742668]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277842483086705		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.5277842483086705 | validation: 0.5429473786256335]
	TIME [epoch: 5.72 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5259917918696382		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.5259917918696382 | validation: 0.3351174825724698]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39444227721934866		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.39444227721934866 | validation: 0.3900652411688793]
	TIME [epoch: 5.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093834378565717		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.5093834378565717 | validation: 0.6031821605253456]
	TIME [epoch: 5.72 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030803577068896		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.5030803577068896 | validation: 0.5902677994821761]
	TIME [epoch: 5.71 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4401402640837839		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.4401402640837839 | validation: 0.4304241703606755]
	TIME [epoch: 5.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46152930235396383		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.46152930235396383 | validation: 0.368667204843392]
	TIME [epoch: 5.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569725408063524		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.4569725408063524 | validation: 0.4559675475205729]
	TIME [epoch: 5.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37523302659085234		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.37523302659085234 | validation: 0.4375317404770381]
	TIME [epoch: 5.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47383880711198806		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.47383880711198806 | validation: 0.4007168727516885]
	TIME [epoch: 5.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488052098815674		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5488052098815674 | validation: 0.4272136380781677]
	TIME [epoch: 5.71 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3624110077413574		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.3624110077413574 | validation: 0.4873484918724482]
	TIME [epoch: 5.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.538707803645327		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.538707803645327 | validation: 0.5988676207883836]
	TIME [epoch: 5.71 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49308942423958985		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.49308942423958985 | validation: 0.3407742551880703]
	TIME [epoch: 5.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619371133696205		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5619371133696205 | validation: 0.45013400119412056]
	TIME [epoch: 5.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562173253461065		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.5562173253461065 | validation: 0.36959981989612645]
	TIME [epoch: 5.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348468402165924		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7348468402165924 | validation: 0.36916813910935276]
	TIME [epoch: 5.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642540762442906		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5642540762442906 | validation: 0.3774973931522162]
	TIME [epoch: 5.71 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644828643237172		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3644828643237172 | validation: 0.6147890645505699]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42892636014968605		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.42892636014968605 | validation: 0.47622371105314826]
	TIME [epoch: 5.71 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39618093625785195		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.39618093625785195 | validation: 1.3097122696986878]
	TIME [epoch: 5.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7513899994281055		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.7513899994281055 | validation: 0.760331581302442]
	TIME [epoch: 5.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314453928735827		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.5314453928735827 | validation: 0.4466742443087553]
	TIME [epoch: 5.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700631392420161		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.4700631392420161 | validation: 0.3602458222794172]
	TIME [epoch: 5.71 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6710684770182391		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6710684770182391 | validation: 0.4498062676179723]
	TIME [epoch: 5.71 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43349978904584524		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.43349978904584524 | validation: 0.3961413462759117]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395761229250416		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.4395761229250416 | validation: 0.4935588458136846]
	TIME [epoch: 5.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748255676719773		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3748255676719773 | validation: 0.9699532459997066]
	TIME [epoch: 5.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5192031219699511		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5192031219699511 | validation: 0.3472141866764079]
	TIME [epoch: 5.72 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299811690382939		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.4299811690382939 | validation: 0.9735842699019115]
	TIME [epoch: 5.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6446058100436076		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6446058100436076 | validation: 0.8562150903516428]
	TIME [epoch: 5.71 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523037151063057		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.523037151063057 | validation: 0.8053180115660162]
	TIME [epoch: 5.71 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094053716889393		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5094053716889393 | validation: 0.3375099390886574]
	TIME [epoch: 5.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43417716788029814		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.43417716788029814 | validation: 0.3970084771597948]
	TIME [epoch: 5.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.384199240392464		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.384199240392464 | validation: 0.3836464762976087]
	TIME [epoch: 5.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35716294935490545		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.35716294935490545 | validation: 0.49719300203899003]
	TIME [epoch: 5.74 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4814539729562399		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4814539729562399 | validation: 0.41274332623266113]
	TIME [epoch: 5.71 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173844700160505		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.4173844700160505 | validation: 0.41387206576540664]
	TIME [epoch: 5.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3751899049355262		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3751899049355262 | validation: 0.3661930001226246]
	TIME [epoch: 5.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205204624498353		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.4205204624498353 | validation: 0.42631418496631035]
	TIME [epoch: 5.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509344662983188		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.4509344662983188 | validation: 0.3530754466242713]
	TIME [epoch: 5.71 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35828292480481944		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.35828292480481944 | validation: 0.31839462282485625]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42345634408600014		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.42345634408600014 | validation: 0.6676521571243629]
	TIME [epoch: 5.74 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297289413478024		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5297289413478024 | validation: 0.39805181625557057]
	TIME [epoch: 5.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43282126689870365		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.43282126689870365 | validation: 0.4034028679395756]
	TIME [epoch: 5.71 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40198032096496267		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.40198032096496267 | validation: 0.36325398423070254]
	TIME [epoch: 5.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561158455985767		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.3561158455985767 | validation: 0.36668178805425156]
	TIME [epoch: 5.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44734655623793784		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.44734655623793784 | validation: 0.7862687497739961]
	TIME [epoch: 5.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131866642929497		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6131866642929497 | validation: 0.8205643042631227]
	TIME [epoch: 5.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641994303653344		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.5641994303653344 | validation: 0.5231340260402306]
	TIME [epoch: 5.72 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40448097791791404		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.40448097791791404 | validation: 0.41831351408292594]
	TIME [epoch: 5.71 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742602904029623		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.3742602904029623 | validation: 0.4193134632670728]
	TIME [epoch: 5.72 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44591706624216054		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.44591706624216054 | validation: 0.30129497381519743]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4197518938129806		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.4197518938129806 | validation: 0.6186114410565887]
	TIME [epoch: 5.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4247482716866053		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.4247482716866053 | validation: 0.9024420892446899]
	TIME [epoch: 5.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730614308263257		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5730614308263257 | validation: 0.679820858636564]
	TIME [epoch: 5.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39608459978130317		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.39608459978130317 | validation: 0.3134981494438339]
	TIME [epoch: 5.71 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37382414159144095		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.37382414159144095 | validation: 0.38443331033405787]
	TIME [epoch: 5.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40249802978646954		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.40249802978646954 | validation: 0.3776656619752242]
	TIME [epoch: 5.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38602813498509586		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.38602813498509586 | validation: 0.3143605453768911]
	TIME [epoch: 5.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455429273089574		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5455429273089574 | validation: 0.32106578438463096]
	TIME [epoch: 5.71 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677909457410737		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.4677909457410737 | validation: 0.37362275603096723]
	TIME [epoch: 5.75 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450187821193026		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.3450187821193026 | validation: 0.3670168030822205]
	TIME [epoch: 5.72 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745098602127602		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.3745098602127602 | validation: 0.31567053426742475]
	TIME [epoch: 5.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3907648990494148		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.3907648990494148 | validation: 0.35297478040742275]
	TIME [epoch: 5.72 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40277369112005784		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.40277369112005784 | validation: 0.44232473448448034]
	TIME [epoch: 5.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37031645644894096		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.37031645644894096 | validation: 0.6167077278806743]
	TIME [epoch: 5.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43227416400440066		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.43227416400440066 | validation: 0.32705968708691124]
	TIME [epoch: 5.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6271868837314194		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6271868837314194 | validation: 0.41049498933156015]
	TIME [epoch: 5.72 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38729185715621317		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.38729185715621317 | validation: 0.4147426435481242]
	TIME [epoch: 5.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43467133746658954		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.43467133746658954 | validation: 0.906815911997079]
	TIME [epoch: 5.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177354686715292		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5177354686715292 | validation: 0.5254743655305465]
	TIME [epoch: 5.72 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38969200517880287		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.38969200517880287 | validation: 0.37826349101746476]
	TIME [epoch: 5.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39716044466711864		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.39716044466711864 | validation: 0.4338004637619258]
	TIME [epoch: 5.72 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4576618012148352		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.4576618012148352 | validation: 0.44732260825606773]
	TIME [epoch: 5.75 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344329409141984		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3344329409141984 | validation: 0.40135001947213417]
	TIME [epoch: 5.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082298698458841		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.5082298698458841 | validation: 0.38224105698503413]
	TIME [epoch: 5.71 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239866930772151		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.3239866930772151 | validation: 0.4790542155147993]
	TIME [epoch: 5.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36678913112875694		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.36678913112875694 | validation: 0.33822488945468593]
	TIME [epoch: 5.71 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443131844910118		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3443131844910118 | validation: 0.4618004627797644]
	TIME [epoch: 5.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4319578666180442		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.4319578666180442 | validation: 0.46861303115368]
	TIME [epoch: 5.71 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4115159175754754		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.4115159175754754 | validation: 0.7210752905836378]
	TIME [epoch: 5.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200340394661401		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5200340394661401 | validation: 0.6924963018469261]
	TIME [epoch: 5.71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4032736273368748		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.4032736273368748 | validation: 0.301987089650554]
	TIME [epoch: 5.71 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720681130025946		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.720681130025946 | validation: 0.4843252801572266]
	TIME [epoch: 5.71 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867982497280368		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3867982497280368 | validation: 0.3562934579049942]
	TIME [epoch: 5.71 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44692977857145566		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.44692977857145566 | validation: 0.28809931123107696]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36276213234410537		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.36276213234410537 | validation: 0.30915105780782254]
	TIME [epoch: 5.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3335872740690367		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3335872740690367 | validation: 0.3557473171084442]
	TIME [epoch: 5.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33792010499404573		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.33792010499404573 | validation: 0.3582911262907422]
	TIME [epoch: 5.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326638671664486		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3326638671664486 | validation: 0.288603077493184]
	TIME [epoch: 5.71 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3355372982438972		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.3355372982438972 | validation: 0.3352490670757085]
	TIME [epoch: 5.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3682514432845705		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.3682514432845705 | validation: 0.2701288989386152]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116219929178541		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3116219929178541 | validation: 0.33002416486193137]
	TIME [epoch: 5.74 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921412297512649		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3921412297512649 | validation: 2.1819515219931325]
	TIME [epoch: 5.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06714083836434		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.06714083836434 | validation: 0.34085833374736413]
	TIME [epoch: 5.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308020399313761		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3308020399313761 | validation: 0.34286163778164225]
	TIME [epoch: 5.72 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947194033284021		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.2947194033284021 | validation: 0.60045867402261]
	TIME [epoch: 5.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44892264327118286		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.44892264327118286 | validation: 0.4989534088002684]
	TIME [epoch: 5.72 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42334777615790337		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.42334777615790337 | validation: 0.5307506816331388]
	TIME [epoch: 5.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49205269773713245		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.49205269773713245 | validation: 0.6588934021980267]
	TIME [epoch: 5.75 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662267836414049		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4662267836414049 | validation: 0.3281809369073406]
	TIME [epoch: 5.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972660201293066		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.3972660201293066 | validation: 0.5749266316849587]
	TIME [epoch: 5.72 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336776451001478		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.4336776451001478 | validation: 0.4494369846646626]
	TIME [epoch: 5.72 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49179823258831523		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.49179823258831523 | validation: 0.40430910552768184]
	TIME [epoch: 5.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3644286440833393		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3644286440833393 | validation: 0.2789299993626304]
	TIME [epoch: 5.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309816528586671		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3309816528586671 | validation: 0.3880995100623399]
	TIME [epoch: 5.73 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34935366841320203		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.34935366841320203 | validation: 0.32588202742858385]
	TIME [epoch: 5.73 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30127016939153534		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.30127016939153534 | validation: 0.2938663113776416]
	TIME [epoch: 5.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27997821746073676		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.27997821746073676 | validation: 0.38177518645398195]
	TIME [epoch: 5.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913952276682179		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2913952276682179 | validation: 0.3271513573094251]
	TIME [epoch: 5.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33261641161282973		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.33261641161282973 | validation: 0.37330314749382665]
	TIME [epoch: 5.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980792709315097		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.2980792709315097 | validation: 0.4431014370044627]
	TIME [epoch: 5.72 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33631348298419594		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.33631348298419594 | validation: 0.35831010123930823]
	TIME [epoch: 5.76 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979631522061616		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2979631522061616 | validation: 0.33475246398992925]
	TIME [epoch: 5.71 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34260948668131974		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.34260948668131974 | validation: 0.2901050152295728]
	TIME [epoch: 5.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3683770171224906		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.3683770171224906 | validation: 0.42857681285574567]
	TIME [epoch: 5.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34556153453344807		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.34556153453344807 | validation: 0.2845646649702635]
	TIME [epoch: 5.72 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941922690192355		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.2941922690192355 | validation: 0.4146073395706506]
	TIME [epoch: 5.72 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3202682063694775		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.3202682063694775 | validation: 0.2735924586363243]
	TIME [epoch: 5.74 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48988741089753757		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.48988741089753757 | validation: 0.30005914103563736]
	TIME [epoch: 5.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28038892238552937		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.28038892238552937 | validation: 0.3697092163367165]
	TIME [epoch: 5.72 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2963617692136715		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2963617692136715 | validation: 0.3183967683640563]
	TIME [epoch: 5.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3154009164632582		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.3154009164632582 | validation: 0.2800620990381259]
	TIME [epoch: 5.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280210891041501		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.280210891041501 | validation: 0.34668297832684025]
	TIME [epoch: 5.71 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32754091548293973		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.32754091548293973 | validation: 0.39357368672339915]
	TIME [epoch: 5.72 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3524492389439649		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3524492389439649 | validation: 0.8434681041525915]
	TIME [epoch: 5.75 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964492961069712		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5964492961069712 | validation: 0.4196224308606456]
	TIME [epoch: 5.72 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194645114362177		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.3194645114362177 | validation: 0.46089314452069685]
	TIME [epoch: 5.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3441359650220481		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3441359650220481 | validation: 0.6527524423173027]
	TIME [epoch: 5.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3912665719830814		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.3912665719830814 | validation: 0.2699464213823361]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37368677446458		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.37368677446458 | validation: 0.42804398985557285]
	TIME [epoch: 5.72 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229993554837291		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.3229993554837291 | validation: 0.3991564562343396]
	TIME [epoch: 5.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34341882400593104		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.34341882400593104 | validation: 0.30374686836581183]
	TIME [epoch: 5.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48808955287108013		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.48808955287108013 | validation: 0.3214598655837193]
	TIME [epoch: 5.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093568200903558		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3093568200903558 | validation: 0.5924390593762902]
	TIME [epoch: 5.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297996736308334		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.4297996736308334 | validation: 0.2956293248944371]
	TIME [epoch: 5.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3467760332070871		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3467760332070871 | validation: 0.3979939627410613]
	TIME [epoch: 5.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413783989297666		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3413783989297666 | validation: 0.26783810645419126]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27789231483701826		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.27789231483701826 | validation: 0.3053514821956699]
	TIME [epoch: 5.75 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133921256537554		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.3133921256537554 | validation: 0.2502864250349145]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34613252849020254		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.34613252849020254 | validation: 0.29374926942380586]
	TIME [epoch: 5.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306522536216047		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.306522536216047 | validation: 0.30256251016633395]
	TIME [epoch: 5.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33344070573360673		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.33344070573360673 | validation: 0.37858203436130694]
	TIME [epoch: 5.71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28452703490612735		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.28452703490612735 | validation: 0.25333533323201757]
	TIME [epoch: 5.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26407126217721544		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.26407126217721544 | validation: 0.2571522371219427]
	TIME [epoch: 5.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25340656280893925		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.25340656280893925 | validation: 0.36487937333117293]
	TIME [epoch: 5.72 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282394423812375		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.3282394423812375 | validation: 0.26883773785496073]
	TIME [epoch: 5.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5472653471350037		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5472653471350037 | validation: 0.35476155707001483]
	TIME [epoch: 5.71 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36409047405049844		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.36409047405049844 | validation: 0.265357030923458]
	TIME [epoch: 5.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35806879391312585		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.35806879391312585 | validation: 0.3260326529129317]
	TIME [epoch: 5.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299928418218117		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.3299928418218117 | validation: 0.2499065884337439]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30258591987134076		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.30258591987134076 | validation: 0.3992044552557394]
	TIME [epoch: 5.75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31502402651650774		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.31502402651650774 | validation: 0.35198888991640054]
	TIME [epoch: 5.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26667520658124994		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.26667520658124994 | validation: 0.29843422056452107]
	TIME [epoch: 5.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2567311215828682		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.2567311215828682 | validation: 0.4856756132435173]
	TIME [epoch: 5.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42132006098836394		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.42132006098836394 | validation: 0.5169461545754074]
	TIME [epoch: 5.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411293795475475		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3411293795475475 | validation: 0.3833613586950778]
	TIME [epoch: 5.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2787227104686968		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.2787227104686968 | validation: 0.251533964176515]
	TIME [epoch: 5.75 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28725561613977224		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.28725561613977224 | validation: 0.24647914052522585]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608089228644061		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.2608089228644061 | validation: 0.27309534290252746]
	TIME [epoch: 5.71 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29714101360405926		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.29714101360405926 | validation: 0.28785427329221586]
	TIME [epoch: 5.72 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746914589535078		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2746914589535078 | validation: 0.41483599673825305]
	TIME [epoch: 5.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29392878218318913		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.29392878218318913 | validation: 0.34379208565675634]
	TIME [epoch: 5.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39594099850870346		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.39594099850870346 | validation: 0.2360394252680866]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3612604651684018		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.3612604651684018 | validation: 0.25370456587657636]
	TIME [epoch: 6.01 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29286896702735254		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.29286896702735254 | validation: 0.4543704354497814]
	TIME [epoch: 5.72 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28145732631821807		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.28145732631821807 | validation: 0.5567777962418085]
	TIME [epoch: 5.72 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38640995450350185		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.38640995450350185 | validation: 0.2838782867887681]
	TIME [epoch: 5.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26832666931271504		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.26832666931271504 | validation: 0.21408096418690853]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447346637288818		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.22447346637288818 | validation: 0.24320644508723674]
	TIME [epoch: 5.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23630390280851743		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23630390280851743 | validation: 0.23903603041858362]
	TIME [epoch: 5.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3963907605708693		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.3963907605708693 | validation: 0.49979958714716555]
	TIME [epoch: 5.72 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37615155880004997		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.37615155880004997 | validation: 0.3505139535546435]
	TIME [epoch: 5.72 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746896482394938		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2746896482394938 | validation: 0.2935141077056507]
	TIME [epoch: 5.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23608565976781806		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.23608565976781806 | validation: 0.28118097609810105]
	TIME [epoch: 5.72 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3952868154824931		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.3952868154824931 | validation: 0.3704333747121732]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3531787422839422		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3531787422839422 | validation: 0.24586718559032797]
	TIME [epoch: 5.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450148910844266		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3450148910844266 | validation: 0.42890090208114456]
	TIME [epoch: 5.73 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36857258285013306		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.36857258285013306 | validation: 0.3113436812764978]
	TIME [epoch: 5.72 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26325048555754904		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.26325048555754904 | validation: 0.2502510499736922]
	TIME [epoch: 5.72 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32217089202730576		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.32217089202730576 | validation: 0.33951807815445284]
	TIME [epoch: 5.72 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858800811479459		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2858800811479459 | validation: 0.4094148357748149]
	TIME [epoch: 5.72 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359915273845961		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.359915273845961 | validation: 0.4547302942046224]
	TIME [epoch: 5.72 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31923380946356394		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.31923380946356394 | validation: 0.5447728728768496]
	TIME [epoch: 5.76 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.352237648979195		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.352237648979195 | validation: 0.33493746131373864]
	TIME [epoch: 5.72 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750582249335095		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2750582249335095 | validation: 0.3305750974339991]
	TIME [epoch: 5.72 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2969010086639621		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2969010086639621 | validation: 0.2981351331906288]
	TIME [epoch: 5.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772245897715789		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.2772245897715789 | validation: 0.22355931827086287]
	TIME [epoch: 5.72 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27760505450450645		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.27760505450450645 | validation: 0.26768492929485194]
	TIME [epoch: 5.72 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3187740311714491		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3187740311714491 | validation: 0.4259713245519188]
	TIME [epoch: 5.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219561187056923		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.3219561187056923 | validation: 0.25180694558233974]
	TIME [epoch: 5.73 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2376772436414678		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2376772436414678 | validation: 0.2545522861662348]
	TIME [epoch: 5.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29432911708775156		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.29432911708775156 | validation: 1.2069527426633464]
	TIME [epoch: 5.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6611346793089581		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6611346793089581 | validation: 0.3115402534846543]
	TIME [epoch: 5.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844894102751909		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.2844894102751909 | validation: 0.23549379637667794]
	TIME [epoch: 5.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27194540814189994		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.27194540814189994 | validation: 0.42697498658495975]
	TIME [epoch: 5.72 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285071517586711		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3285071517586711 | validation: 0.39191460753257923]
	TIME [epoch: 5.76 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28744455225212745		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.28744455225212745 | validation: 0.3120159350576463]
	TIME [epoch: 5.72 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25291970915641265		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.25291970915641265 | validation: 0.4301706153599908]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3422146208795473		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3422146208795473 | validation: 0.24992577853093306]
	TIME [epoch: 5.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2143715402911961		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2143715402911961 | validation: 0.2953918019642437]
	TIME [epoch: 5.72 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718958573568947		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2718958573568947 | validation: 0.344444305404502]
	TIME [epoch: 5.72 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3292483461830852		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3292483461830852 | validation: 0.23432945821044712]
	TIME [epoch: 5.75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342082506641511		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.342082506641511 | validation: 0.3831173119679913]
	TIME [epoch: 5.73 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30361348218217227		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.30361348218217227 | validation: 0.2361378563298651]
	TIME [epoch: 5.72 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.362342108356429		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.362342108356429 | validation: 0.29436023151396923]
	TIME [epoch: 5.72 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581695616861763		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.2581695616861763 | validation: 0.27797763658106833]
	TIME [epoch: 5.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28623543842758503		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.28623543842758503 | validation: 0.2568629892920097]
	TIME [epoch: 5.72 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25871573051189556		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.25871573051189556 | validation: 0.21848680603372125]
	TIME [epoch: 5.72 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664762333960896		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.2664762333960896 | validation: 0.22070279643767288]
	TIME [epoch: 5.76 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26350033177641025		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.26350033177641025 | validation: 0.247676248492958]
	TIME [epoch: 5.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24215605649166194		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.24215605649166194 | validation: 0.21961626306479784]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22552506124222896		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.22552506124222896 | validation: 0.4250896534138389]
	TIME [epoch: 5.72 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783765923442836		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.3783765923442836 | validation: 0.3468802590582842]
	TIME [epoch: 5.72 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38199599717183663		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.38199599717183663 | validation: 0.21409357016623723]
	TIME [epoch: 5.72 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23767778065283107		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.23767778065283107 | validation: 0.40072078545473305]
	TIME [epoch: 5.75 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729804228913972		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3729804228913972 | validation: 0.24922741178764943]
	TIME [epoch: 5.73 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24313401289261666		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.24313401289261666 | validation: 0.3098249380076416]
	TIME [epoch: 5.72 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260274632123731		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.260274632123731 | validation: 0.2268695380535626]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31470136537800864		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.31470136537800864 | validation: 0.24703855188177962]
	TIME [epoch: 5.72 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40678188973121726		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.40678188973121726 | validation: 0.2621547813872022]
	TIME [epoch: 5.72 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784318698852297		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3784318698852297 | validation: 0.26190406671899524]
	TIME [epoch: 5.72 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22330912361891647		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.22330912361891647 | validation: 0.2468794631916851]
	TIME [epoch: 5.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23088646895793974		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.23088646895793974 | validation: 0.28329956664534184]
	TIME [epoch: 5.72 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785731440744627		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2785731440744627 | validation: 0.35412604820836424]
	TIME [epoch: 5.72 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27423574790175387		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.27423574790175387 | validation: 0.4665968888187346]
	TIME [epoch: 5.72 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35761273865028476		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.35761273865028476 | validation: 0.29720133008088756]
	TIME [epoch: 5.72 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532537159934669		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2532537159934669 | validation: 0.22365566777314833]
	TIME [epoch: 5.72 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33423013656887945		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.33423013656887945 | validation: 0.26307379750712195]
	TIME [epoch: 5.75 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2271627305559665		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.2271627305559665 | validation: 0.26063435036102334]
	TIME [epoch: 5.73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22932539864033977		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.22932539864033977 | validation: 0.20739917268618882]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3231635762270916		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3231635762270916 | validation: 0.3414604699227178]
	TIME [epoch: 5.72 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572860101397801		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2572860101397801 | validation: 0.27488146209608855]
	TIME [epoch: 5.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041512112626642		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.3041512112626642 | validation: 0.2873323152444656]
	TIME [epoch: 5.72 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24636489967676822		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.24636489967676822 | validation: 0.2809337878776262]
	TIME [epoch: 5.72 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829910040671945		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2829910040671945 | validation: 0.2996747471521005]
	TIME [epoch: 5.76 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713433452444357		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.2713433452444357 | validation: 0.22959209215388204]
	TIME [epoch: 5.72 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24669246942448442		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.24669246942448442 | validation: 0.20636736005607115]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113704755742547		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.2113704755742547 | validation: 0.42769042579649097]
	TIME [epoch: 5.72 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36046007321509305		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.36046007321509305 | validation: 0.24519452556967047]
	TIME [epoch: 5.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23568897389869056		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.23568897389869056 | validation: 0.3633738938847239]
	TIME [epoch: 5.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31478490125325126		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.31478490125325126 | validation: 0.2877224564990426]
	TIME [epoch: 5.74 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505681770799115		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2505681770799115 | validation: 0.29640746240512333]
	TIME [epoch: 5.72 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2218153034881259		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2218153034881259 | validation: 0.19502924846306413]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534900199011102		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.3534900199011102 | validation: 0.2786641029051963]
	TIME [epoch: 5.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2314965732763395		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.2314965732763395 | validation: 0.20288366529086652]
	TIME [epoch: 5.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19894571008548623		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.19894571008548623 | validation: 0.2214233613793357]
	TIME [epoch: 5.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788931677436736		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2788931677436736 | validation: 0.22400782968234392]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214884485878746		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.2214884485878746 | validation: 0.1986671208826622]
	TIME [epoch: 5.74 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582744014735916		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2582744014735916 | validation: 0.25452411325625146]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088751686166641		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2088751686166641 | validation: 0.198742607154293]
	TIME [epoch: 5.72 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283249028308701		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2283249028308701 | validation: 0.18849390662703117]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33082538199347766		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.33082538199347766 | validation: 0.28160401987049627]
	TIME [epoch: 5.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23972164816117877		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.23972164816117877 | validation: 0.21171886622434066]
	TIME [epoch: 5.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26341420265466		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.26341420265466 | validation: 0.2126232095328852]
	TIME [epoch: 5.75 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434265460203045		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2434265460203045 | validation: 0.19840774052446258]
	TIME [epoch: 5.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38749632418764085		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.38749632418764085 | validation: 0.24456922690214328]
	TIME [epoch: 5.71 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23706371495342382		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.23706371495342382 | validation: 0.25528903444434653]
	TIME [epoch: 5.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2464086812476157		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.2464086812476157 | validation: 0.17890921202008384]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24311927442490486		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.24311927442490486 | validation: 0.21785220929764415]
	TIME [epoch: 5.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19291695612610738		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.19291695612610738 | validation: 0.23886549151369132]
	TIME [epoch: 5.73 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27053698777908464		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.27053698777908464 | validation: 0.22276408307846257]
	TIME [epoch: 5.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226425466059912		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.2226425466059912 | validation: 0.25050470213244]
	TIME [epoch: 5.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21781285610620293		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.21781285610620293 | validation: 0.18904507708480459]
	TIME [epoch: 5.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21119311308786212		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.21119311308786212 | validation: 0.36481893185011516]
	TIME [epoch: 5.72 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44211321155010525		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.44211321155010525 | validation: 0.2079352012325204]
	TIME [epoch: 5.71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28338059384652475		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.28338059384652475 | validation: 0.18230774949267256]
	TIME [epoch: 5.72 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117002622510311		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2117002622510311 | validation: 0.22353065574272793]
	TIME [epoch: 5.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20679480543021597		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.20679480543021597 | validation: 0.2556012945417256]
	TIME [epoch: 5.71 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22554649862265133		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.22554649862265133 | validation: 0.1831122737659554]
	TIME [epoch: 5.72 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25441832497423755		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.25441832497423755 | validation: 0.2174651873721673]
	TIME [epoch: 5.72 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25837534966794173		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.25837534966794173 | validation: 0.22591129258522966]
	TIME [epoch: 5.71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688495505823395		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2688495505823395 | validation: 0.20713489194927617]
	TIME [epoch: 5.71 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24264009849964505		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.24264009849964505 | validation: 0.23251830763965028]
	TIME [epoch: 5.72 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2400514868040476		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2400514868040476 | validation: 0.19408726638387172]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23169204757095682		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.23169204757095682 | validation: 0.18730855212173297]
	TIME [epoch: 5.72 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23173848532364602		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.23173848532364602 | validation: 0.20744760695010145]
	TIME [epoch: 5.72 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32617762972538855		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.32617762972538855 | validation: 0.22393409736755923]
	TIME [epoch: 5.71 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19711337341041424		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.19711337341041424 | validation: 0.2665929551871832]
	TIME [epoch: 5.72 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26830148500026774		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.26830148500026774 | validation: 0.2405235595937421]
	TIME [epoch: 5.71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173227592391543		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.2173227592391543 | validation: 0.21837881157474975]
	TIME [epoch: 5.76 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22937361419689187		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.22937361419689187 | validation: 0.41185127521057496]
	TIME [epoch: 5.71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37501411530484385		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.37501411530484385 | validation: 0.21796223669475068]
	TIME [epoch: 5.71 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21223983688214998		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.21223983688214998 | validation: 0.18608287452330433]
	TIME [epoch: 5.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802745989714502		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2802745989714502 | validation: 0.22243037674398575]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2281303268040587		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2281303268040587 | validation: 0.19947344071529355]
	TIME [epoch: 5.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20768185115125345		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.20768185115125345 | validation: 0.23730600340243108]
	TIME [epoch: 5.72 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600666461975554		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2600666461975554 | validation: 0.18593655334806658]
	TIME [epoch: 5.73 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2246960522346414		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2246960522346414 | validation: 0.21469256365689218]
	TIME [epoch: 5.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18531917892294358		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.18531917892294358 | validation: 0.19260053710131025]
	TIME [epoch: 5.71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21419682512117624		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.21419682512117624 | validation: 0.3771165219448659]
	TIME [epoch: 5.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129808557579813		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3129808557579813 | validation: 0.2251383217009095]
	TIME [epoch: 5.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19472327209979137		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.19472327209979137 | validation: 0.18097351731491873]
	TIME [epoch: 5.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18418851353120197		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.18418851353120197 | validation: 0.16754826871964526]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19148915801463126		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.19148915801463126 | validation: 0.17133988133312364]
	TIME [epoch: 5.72 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22035111621232936		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.22035111621232936 | validation: 0.2698149367975918]
	TIME [epoch: 5.72 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251944789441262		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.2251944789441262 | validation: 0.2126694294865736]
	TIME [epoch: 5.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175480940496844		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2175480940496844 | validation: 0.19048368896973855]
	TIME [epoch: 5.72 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19688872134911095		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.19688872134911095 | validation: 0.329358743705742]
	TIME [epoch: 5.72 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25334952041820213		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.25334952041820213 | validation: 0.15850196324365742]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18450116541689468		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.18450116541689468 | validation: 0.15977665907083102]
	TIME [epoch: 5.75 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3127885681739647		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3127885681739647 | validation: 0.7132141329666805]
	TIME [epoch: 5.71 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636402991393291		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5636402991393291 | validation: 0.5865354740059227]
	TIME [epoch: 5.72 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3788539620162492		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3788539620162492 | validation: 0.17452395102732715]
	TIME [epoch: 5.72 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23027720952071906		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.23027720952071906 | validation: 0.25005492653190475]
	TIME [epoch: 5.72 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23091146047317454		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23091146047317454 | validation: 0.19613083447338583]
	TIME [epoch: 5.71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19633089535719875		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.19633089535719875 | validation: 0.28799684727427166]
	TIME [epoch: 5.75 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545567458383633		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2545567458383633 | validation: 0.21906118082821274]
	TIME [epoch: 5.73 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20357771479285108		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.20357771479285108 | validation: 0.41212365280026647]
	TIME [epoch: 5.72 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27520374919621104		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.27520374919621104 | validation: 0.2064937827155758]
	TIME [epoch: 5.71 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2008435373447096		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2008435373447096 | validation: 0.18832872627872704]
	TIME [epoch: 5.71 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063165611325562		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2063165611325562 | validation: 0.182587121288157]
	TIME [epoch: 5.71 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2310736033934123		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2310736033934123 | validation: 0.21409435962192574]
	TIME [epoch: 5.72 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200291096308133		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.200291096308133 | validation: 0.30840715615074304]
	TIME [epoch: 5.74 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29712154673955665		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.29712154673955665 | validation: 0.24534873471681834]
	TIME [epoch: 5.71 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312394004669987		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.2312394004669987 | validation: 0.2106974599918386]
	TIME [epoch: 5.71 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23518793684378103		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.23518793684378103 | validation: 0.18587771396380184]
	TIME [epoch: 5.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866551085962452		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.2866551085962452 | validation: 0.39315810499196807]
	TIME [epoch: 5.71 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597128537343857		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2597128537343857 | validation: 0.22053022992499435]
	TIME [epoch: 5.72 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18415211281403943		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.18415211281403943 | validation: 0.18337718236456027]
	TIME [epoch: 5.75 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992211221317451		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.1992211221317451 | validation: 0.17335780519635774]
	TIME [epoch: 5.71 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801931096494269		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3801931096494269 | validation: 0.24288384789117998]
	TIME [epoch: 5.71 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21100979483989646		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.21100979483989646 | validation: 0.30973404190092046]
	TIME [epoch: 5.71 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2333778360129916		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2333778360129916 | validation: 0.5426344883693295]
	TIME [epoch: 5.71 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3850669218058283		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.3850669218058283 | validation: 0.27602780754181877]
	TIME [epoch: 5.72 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725660378587803		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2725660378587803 | validation: 0.23325166042290235]
	TIME [epoch: 5.72 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1974676163550836		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1974676163550836 | validation: 0.19180237847648243]
	TIME [epoch: 5.74 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17956481890301923		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.17956481890301923 | validation: 0.1800781657383698]
	TIME [epoch: 5.71 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687485499665858		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.19687485499665858 | validation: 0.2600713713713646]
	TIME [epoch: 5.71 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21917019869461704		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.21917019869461704 | validation: 0.16148054118736752]
	TIME [epoch: 5.71 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368115223753718		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2368115223753718 | validation: 0.2370943318689794]
	TIME [epoch: 5.71 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283133668948643		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.2283133668948643 | validation: 0.3470280139910538]
	TIME [epoch: 5.71 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24221471454513793		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.24221471454513793 | validation: 0.2762604534309436]
	TIME [epoch: 5.76 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22022475061108251		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.22022475061108251 | validation: 0.1731379321346442]
	TIME [epoch: 5.72 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17727376493320537		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.17727376493320537 | validation: 0.21775109618906846]
	TIME [epoch: 5.71 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22851748140990363		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.22851748140990363 | validation: 0.1830070849938147]
	TIME [epoch: 5.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20149296293772934		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.20149296293772934 | validation: 0.15838966421957967]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1807456811363983		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1807456811363983 | validation: 0.15931811340816673]
	TIME [epoch: 5.72 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21724534046363841		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.21724534046363841 | validation: 0.2715175527409303]
	TIME [epoch: 5.73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21929482173953077		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.21929482173953077 | validation: 0.43256052895054964]
	TIME [epoch: 5.74 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685066345387245		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.2685066345387245 | validation: 0.19360576445340344]
	TIME [epoch: 5.72 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22898932220582463		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.22898932220582463 | validation: 0.30205003268458464]
	TIME [epoch: 5.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22487727004532965		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.22487727004532965 | validation: 0.17078352754807363]
	TIME [epoch: 5.72 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22636523163911998		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.22636523163911998 | validation: 0.21573002957280796]
	TIME [epoch: 5.72 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24393539480576143		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.24393539480576143 | validation: 0.220738791166069]
	TIME [epoch: 5.72 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101953304467255		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.2101953304467255 | validation: 0.17188290003653123]
	TIME [epoch: 5.75 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17444511358915898		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.17444511358915898 | validation: 0.20828696180099543]
	TIME [epoch: 5.73 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843098644312707		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.1843098644312707 | validation: 0.21565908949600832]
	TIME [epoch: 5.72 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196491526195311		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2196491526195311 | validation: 0.1743702318373446]
	TIME [epoch: 5.72 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221193180120357		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.221193180120357 | validation: 0.38657909904650956]
	TIME [epoch: 5.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23334254601054838		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.23334254601054838 | validation: 0.1667736120911097]
	TIME [epoch: 5.72 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17109720057959815		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.17109720057959815 | validation: 0.172556301894937]
	TIME [epoch: 5.74 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20350036034546598		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.20350036034546598 | validation: 0.1885485682521287]
	TIME [epoch: 5.75 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19899298481805794		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.19899298481805794 | validation: 0.2109170226648815]
	TIME [epoch: 5.72 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18563370898814513		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.18563370898814513 | validation: 0.16594484950993102]
	TIME [epoch: 5.72 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670171764362257		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.1670171764362257 | validation: 0.1863109723066139]
	TIME [epoch: 5.72 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19037992239577137		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.19037992239577137 | validation: 0.21343337317241953]
	TIME [epoch: 5.72 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25190423194213063		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.25190423194213063 | validation: 0.20234217373208438]
	TIME [epoch: 5.72 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2863712013198687		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2863712013198687 | validation: 0.19736295595881181]
	TIME [epoch: 5.76 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896297707614842		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.1896297707614842 | validation: 0.25146562260870303]
	TIME [epoch: 5.72 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21043925699647925		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.21043925699647925 | validation: 0.1547025190866534]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17795197483805436		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.17795197483805436 | validation: 0.20649727589188416]
	TIME [epoch: 5.71 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645463084506428		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1645463084506428 | validation: 0.1593991133530623]
	TIME [epoch: 5.71 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27319424133395553		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.27319424133395553 | validation: 0.2368061690858725]
	TIME [epoch: 5.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944862801711977		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1944862801711977 | validation: 0.40315102577890805]
	TIME [epoch: 5.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2994137512156049		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.2994137512156049 | validation: 0.24680120579951267]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1923807002914306		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1923807002914306 | validation: 0.1673803019269269]
	TIME [epoch: 5.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22762724696406422		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.22762724696406422 | validation: 0.3699078542918543]
	TIME [epoch: 5.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21665985955647313		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.21665985955647313 | validation: 0.18204964246954242]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17698047016564425		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.17698047016564425 | validation: 0.18912164859602848]
	TIME [epoch: 5.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18157650101401324		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.18157650101401324 | validation: 0.22449092043851926]
	TIME [epoch: 5.71 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19781357928150192		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.19781357928150192 | validation: 0.29878256204948317]
	TIME [epoch: 5.75 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680248445728143		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.2680248445728143 | validation: 0.18513290460001913]
	TIME [epoch: 5.71 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18361192729915962		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.18361192729915962 | validation: 0.18126555611707548]
	TIME [epoch: 5.71 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640033627999971		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.1640033627999971 | validation: 0.20009944162005006]
	TIME [epoch: 5.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16781476414391644		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.16781476414391644 | validation: 0.212372626414285]
	TIME [epoch: 5.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20603150233184256		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.20603150233184256 | validation: 0.18816756310284086]
	TIME [epoch: 5.71 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17401999311648655		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.17401999311648655 | validation: 0.16501442910415925]
	TIME [epoch: 5.73 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15677430685788657		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.15677430685788657 | validation: 0.20726499067196055]
	TIME [epoch: 5.73 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18842038324591673		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.18842038324591673 | validation: 0.17077973692763365]
	TIME [epoch: 5.72 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22150660901896788		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.22150660901896788 | validation: 0.26869053378111096]
	TIME [epoch: 5.71 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306800755326164		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.19306800755326164 | validation: 0.1655349149271983]
	TIME [epoch: 5.71 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16797123122204782		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.16797123122204782 | validation: 0.14768083519294437]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603782251211878		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.1603782251211878 | validation: 0.1638547904487958]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222704079909415		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2222704079909415 | validation: 0.1962965491912187]
	TIME [epoch: 5.76 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1761943905593753		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1761943905593753 | validation: 0.17440136425346217]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16088378774181378		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.16088378774181378 | validation: 0.21946414414651969]
	TIME [epoch: 5.72 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638923157789477		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.1638923157789477 | validation: 0.351745322876705]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195960508861711		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.2195960508861711 | validation: 0.16384983855427723]
	TIME [epoch: 5.72 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15812712519793826		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.15812712519793826 | validation: 0.16360333248630007]
	TIME [epoch: 5.72 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16946011382425724		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.16946011382425724 | validation: 0.16381323064578163]
	TIME [epoch: 5.75 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18235006824068314		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.18235006824068314 | validation: 0.17424186382273768]
	TIME [epoch: 5.74 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1846020733050868		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1846020733050868 | validation: 0.15070330429470266]
	TIME [epoch: 5.72 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.175209218808658		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.175209218808658 | validation: 0.16500477694768342]
	TIME [epoch: 5.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2482584466746664		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.2482584466746664 | validation: 0.2581940503220326]
	TIME [epoch: 5.72 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22178149114004136		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.22178149114004136 | validation: 0.1878523725455116]
	TIME [epoch: 5.72 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634545010845801		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1634545010845801 | validation: 0.1407123394321813]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759924012052945		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1759924012052945 | validation: 0.18789147189788594]
	TIME [epoch: 5.76 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155284403923369		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.155284403923369 | validation: 0.18976712428431275]
	TIME [epoch: 5.72 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18983956646963246		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.18983956646963246 | validation: 0.18110418323657804]
	TIME [epoch: 5.72 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16598220234153127		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.16598220234153127 | validation: 0.293145471381296]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892277529767428		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1892277529767428 | validation: 0.16048636560580787]
	TIME [epoch: 5.72 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535207798929043		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.1535207798929043 | validation: 0.17166842332397822]
	TIME [epoch: 5.72 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088339301388215		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.2088339301388215 | validation: 0.20790359030703143]
	TIME [epoch: 5.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18620954122395034		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.18620954122395034 | validation: 0.1768184902825587]
	TIME [epoch: 5.73 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16814893428474026		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.16814893428474026 | validation: 0.19153815969662405]
	TIME [epoch: 5.72 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756955119439757		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.1756955119439757 | validation: 0.16027530167648757]
	TIME [epoch: 5.72 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1779344727325041		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.1779344727325041 | validation: 0.15320522346561066]
	TIME [epoch: 5.72 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485590181531425		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.1485590181531425 | validation: 0.15413482438902218]
	TIME [epoch: 5.72 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615053247779939		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.1615053247779939 | validation: 0.16799447506967471]
	TIME [epoch: 5.72 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15462624869747055		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.15462624869747055 | validation: 0.3151806755728974]
	TIME [epoch: 5.76 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951034681146537		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1951034681146537 | validation: 0.19606530088915491]
	TIME [epoch: 5.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16398963754572973		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.16398963754572973 | validation: 0.19565913187141662]
	TIME [epoch: 5.72 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17315027229717922		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.17315027229717922 | validation: 0.18222532344986953]
	TIME [epoch: 5.72 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17009711456733193		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.17009711456733193 | validation: 0.2177321644067325]
	TIME [epoch: 5.72 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15928693463893634		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.15928693463893634 | validation: 0.14006581543604005]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18986336862489442		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.18986336862489442 | validation: 0.16151950607714244]
	TIME [epoch: 5.76 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085164370665827		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.18085164370665827 | validation: 0.22473040555893042]
	TIME [epoch: 5.72 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19642923834303525		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.19642923834303525 | validation: 0.15339870807039357]
	TIME [epoch: 5.72 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15789956039527203		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.15789956039527203 | validation: 0.16753188143609576]
	TIME [epoch: 5.72 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16268562501782252		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.16268562501782252 | validation: 0.14309937395849934]
	TIME [epoch: 5.72 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15522993039246286		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15522993039246286 | validation: 0.16657887793077442]
	TIME [epoch: 5.72 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16843317930534177		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.16843317930534177 | validation: 0.1629267420419729]
	TIME [epoch: 5.73 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18994747977654114		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.18994747977654114 | validation: 0.16339097977750217]
	TIME [epoch: 5.75 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17788271357818863		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.17788271357818863 | validation: 0.21322561316302718]
	TIME [epoch: 5.72 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15558421197943129		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.15558421197943129 | validation: 0.15971162846240897]
	TIME [epoch: 5.72 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044309465465056		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.2044309465465056 | validation: 0.18908587527259027]
	TIME [epoch: 5.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618127105368522		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1618127105368522 | validation: 0.23008965187902725]
	TIME [epoch: 5.72 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16470899982821618		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.16470899982821618 | validation: 0.21268702863837774]
	TIME [epoch: 5.72 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19191499271396317		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.19191499271396317 | validation: 0.16105003611684096]
	TIME [epoch: 5.76 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14774479629825638		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.14774479629825638 | validation: 0.14181776410984615]
	TIME [epoch: 5.73 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1745401207021528		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1745401207021528 | validation: 0.2249416302881152]
	TIME [epoch: 5.72 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21740516059146808		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.21740516059146808 | validation: 0.19313237547440415]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17095873274067208		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.17095873274067208 | validation: 0.21467944429400823]
	TIME [epoch: 5.72 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16363769136494277		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.16363769136494277 | validation: 0.18494208243030413]
	TIME [epoch: 5.72 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751341605780744		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.18751341605780744 | validation: 0.17915716026720582]
	TIME [epoch: 5.73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22559439109447602		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.22559439109447602 | validation: 0.15613832126164492]
	TIME [epoch: 5.75 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20114684387557677		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.20114684387557677 | validation: 0.22929096089393433]
	TIME [epoch: 5.73 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16832009716597374		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.16832009716597374 | validation: 0.1580834752390119]
	TIME [epoch: 5.72 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734009517067468		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1734009517067468 | validation: 0.15397707848743625]
	TIME [epoch: 5.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22966751684848996		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.22966751684848996 | validation: 0.2537403001540991]
	TIME [epoch: 5.72 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20579790990438895		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.20579790990438895 | validation: 0.1373279161872378]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24467723090465984		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.24467723090465984 | validation: 0.1701431928801683]
	TIME [epoch: 5.75 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084881786230727		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.20084881786230727 | validation: 0.19821007829898407]
	TIME [epoch: 5.72 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16759474349340944		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.16759474349340944 | validation: 0.16997334902495453]
	TIME [epoch: 5.71 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16261630663711588		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.16261630663711588 | validation: 0.14550583327279945]
	TIME [epoch: 5.72 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18989891264356848		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.18989891264356848 | validation: 0.1831316361914661]
	TIME [epoch: 5.71 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708651866431933		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.1708651866431933 | validation: 0.15937578059426744]
	TIME [epoch: 5.72 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730000215410064		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1730000215410064 | validation: 0.15531888439188268]
	TIME [epoch: 5.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16905019945582728		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16905019945582728 | validation: 0.16439177599402846]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15063880193188434		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.15063880193188434 | validation: 0.16584730681173304]
	TIME [epoch: 5.71 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396890485978586		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1396890485978586 | validation: 0.1396028120579418]
	TIME [epoch: 5.72 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619924060455433		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1619924060455433 | validation: 0.21414890775399115]
	TIME [epoch: 5.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525019810803423		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.19525019810803423 | validation: 0.22003462107213523]
	TIME [epoch: 5.72 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18813470769963775		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.18813470769963775 | validation: 0.24392598830184406]
	TIME [epoch: 5.72 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26142627318272305		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.26142627318272305 | validation: 0.16008654778236506]
	TIME [epoch: 5.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14773512747556933		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.14773512747556933 | validation: 0.28589754709172566]
	TIME [epoch: 5.72 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23754722758744268		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.23754722758744268 | validation: 0.21095256376064794]
	TIME [epoch: 5.72 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15347997161802301		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15347997161802301 | validation: 0.1499316427249324]
	TIME [epoch: 5.72 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15237749258292976		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.15237749258292976 | validation: 0.18279189592031528]
	TIME [epoch: 5.72 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23258578127137944		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.23258578127137944 | validation: 0.16520965324208894]
	TIME [epoch: 5.72 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19916065913020248		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.19916065913020248 | validation: 0.1541971759652529]
	TIME [epoch: 5.73 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554328673916309		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1554328673916309 | validation: 0.152922834343028]
	TIME [epoch: 5.74 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714234729579875		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.1714234729579875 | validation: 0.18542589814819574]
	TIME [epoch: 5.72 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18106651776661595		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.18106651776661595 | validation: 0.19253847359182313]
	TIME [epoch: 5.72 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576217174854142		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.1576217174854142 | validation: 0.2016237809099435]
	TIME [epoch: 5.72 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16902439009472697		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.16902439009472697 | validation: 0.21971391751197422]
	TIME [epoch: 5.72 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17559160554998154		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.17559160554998154 | validation: 0.14927471673166706]
	TIME [epoch: 5.72 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14604442286292663		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.14604442286292663 | validation: 0.15263413386506042]
	TIME [epoch: 5.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14423355112107733		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.14423355112107733 | validation: 0.27182518695167446]
	TIME [epoch: 5.72 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21088491895520223		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.21088491895520223 | validation: 0.2323724330155583]
	TIME [epoch: 5.72 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18251926591431467		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.18251926591431467 | validation: 0.15919939991964757]
	TIME [epoch: 5.72 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14436394105432712		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.14436394105432712 | validation: 0.16331857803664915]
	TIME [epoch: 5.72 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14869045259304414		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.14869045259304414 | validation: 0.13302525362229728]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962949523157459		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.13962949523157459 | validation: 0.18707281941907672]
	TIME [epoch: 5.72 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17144031504442883		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.17144031504442883 | validation: 0.1845465538394817]
	TIME [epoch: 5.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18405174461143253		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.18405174461143253 | validation: 0.1316664626595618]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17416628046873323		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.17416628046873323 | validation: 0.16435715548214597]
	TIME [epoch: 5.72 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15800865486790666		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.15800865486790666 | validation: 0.15929810441021597]
	TIME [epoch: 5.72 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20509561092769035		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.20509561092769035 | validation: 0.13920782637139664]
	TIME [epoch: 5.72 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312645172357447		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.1312645172357447 | validation: 0.14300081159378553]
	TIME [epoch: 5.72 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16304731844860884		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.16304731844860884 | validation: 0.15576767755677462]
	TIME [epoch: 5.76 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703047016080697		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.1703047016080697 | validation: 0.3118632643385913]
	TIME [epoch: 5.72 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055358633119638		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.20055358633119638 | validation: 0.28194061383995334]
	TIME [epoch: 5.72 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18695404583156622		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.18695404583156622 | validation: 0.1779577214531232]
	TIME [epoch: 5.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420016770455784		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1420016770455784 | validation: 0.14123905257195773]
	TIME [epoch: 5.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13071449390662548		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.13071449390662548 | validation: 0.14279050871906976]
	TIME [epoch: 5.71 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15076755526596772		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.15076755526596772 | validation: 0.1407903533193228]
	TIME [epoch: 5.73 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18315818157710284		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.18315818157710284 | validation: 0.13677435938807525]
	TIME [epoch: 5.73 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15080680992946208		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.15080680992946208 | validation: 0.14456106053729456]
	TIME [epoch: 5.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515992777780409		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1515992777780409 | validation: 0.5297100843527344]
	TIME [epoch: 5.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33136298013386584		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.33136298013386584 | validation: 0.15636756300172636]
	TIME [epoch: 5.71 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20103697772077994		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.20103697772077994 | validation: 0.22726774527469915]
	TIME [epoch: 5.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15143583655065293		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.15143583655065293 | validation: 0.15086166330394302]
	TIME [epoch: 5.72 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371980599280792		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1371980599280792 | validation: 0.17225932625418802]
	TIME [epoch: 5.76 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15933808835435687		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.15933808835435687 | validation: 0.21449188143567877]
	TIME [epoch: 5.72 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678679946224625		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1678679946224625 | validation: 0.15325034371011462]
	TIME [epoch: 5.72 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18136074790504983		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.18136074790504983 | validation: 0.2834972413987212]
	TIME [epoch: 5.72 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19838119867865225		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.19838119867865225 | validation: 0.18909257353085857]
	TIME [epoch: 5.72 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15872861648165568		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.15872861648165568 | validation: 0.14648794826874362]
	TIME [epoch: 5.72 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14614930068750734		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.14614930068750734 | validation: 0.16573581204073926]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14165936110410018		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14165936110410018 | validation: 0.1515978703875383]
	TIME [epoch: 5.74 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13964425913687303		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.13964425913687303 | validation: 0.18298915732589652]
	TIME [epoch: 5.71 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983246213564016		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.1983246213564016 | validation: 0.14442012148290292]
	TIME [epoch: 5.72 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15571075372749926		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.15571075372749926 | validation: 0.2019303987902399]
	TIME [epoch: 5.71 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17187938564563066		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.17187938564563066 | validation: 0.13646129597580442]
	TIME [epoch: 5.71 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14418515219917952		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.14418515219917952 | validation: 0.16608132816003]
	TIME [epoch: 5.71 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1772338556514108		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1772338556514108 | validation: 0.12871535978860288]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_741.pth
	Model improved!!!
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562293890348681		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1562293890348681 | validation: 0.13440994952729438]
	TIME [epoch: 5.71 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232205212290405		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.14232205212290405 | validation: 0.17429387166473015]
	TIME [epoch: 5.72 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17748119397588963		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.17748119397588963 | validation: 0.15782082672473194]
	TIME [epoch: 5.71 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13936798940211703		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.13936798940211703 | validation: 0.20412749761105936]
	TIME [epoch: 5.71 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550168085422178		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1550168085422178 | validation: 0.25245107811436696]
	TIME [epoch: 5.71 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18178347590147378		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.18178347590147378 | validation: 0.1516042199985449]
	TIME [epoch: 5.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14559782467892277		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.14559782467892277 | validation: 0.13194196701889563]
	TIME [epoch: 5.73 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13663193538449328		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.13663193538449328 | validation: 0.15971842549007362]
	TIME [epoch: 5.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16145441032273572		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.16145441032273572 | validation: 0.1418125665053099]
	TIME [epoch: 5.71 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15742357160945605		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.15742357160945605 | validation: 0.13558175449325077]
	TIME [epoch: 5.71 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15476889240415792		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.15476889240415792 | validation: 0.14031619450453758]
	TIME [epoch: 5.71 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15508894018333746		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.15508894018333746 | validation: 0.15149824629162464]
	TIME [epoch: 5.71 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14168043017120563		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.14168043017120563 | validation: 0.17740943860157926]
	TIME [epoch: 5.76 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14824919049997198		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14824919049997198 | validation: 0.14832139555098584]
	TIME [epoch: 5.71 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369268664535192		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1369268664535192 | validation: 0.19257417207458297]
	TIME [epoch: 5.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16145833239441762		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.16145833239441762 | validation: 0.1406635322397888]
	TIME [epoch: 5.71 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20099588095478624		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.20099588095478624 | validation: 0.16629883324261524]
	TIME [epoch: 5.72 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19528718778609777		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.19528718778609777 | validation: 0.2064253982981355]
	TIME [epoch: 5.69 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14854900331923238		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14854900331923238 | validation: 0.14685235290000756]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737938280775416		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.13737938280775416 | validation: 0.16492897810993534]
	TIME [epoch: 5.73 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13679504963734715		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.13679504963734715 | validation: 0.1446519851566693]
	TIME [epoch: 5.72 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13955376586110263		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.13955376586110263 | validation: 0.1574665602051454]
	TIME [epoch: 5.71 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198583335671393		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.13198583335671393 | validation: 0.13552969690065017]
	TIME [epoch: 5.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518981595167922		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.1518981595167922 | validation: 0.16529958021808694]
	TIME [epoch: 5.72 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17318193279111846		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.17318193279111846 | validation: 0.1668329707181223]
	TIME [epoch: 5.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620659379924893		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.1620659379924893 | validation: 0.19305481969325797]
	TIME [epoch: 5.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17595452880968593		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.17595452880968593 | validation: 0.16280787577462774]
	TIME [epoch: 5.71 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14632493228198593		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.14632493228198593 | validation: 0.14216823415890645]
	TIME [epoch: 5.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14635211873754767		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.14635211873754767 | validation: 0.1470974899746221]
	TIME [epoch: 5.71 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575124798990398		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.13575124798990398 | validation: 0.1402783620338042]
	TIME [epoch: 5.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16761660376592447		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.16761660376592447 | validation: 0.20156935585657756]
	TIME [epoch: 5.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733264241863527		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1733264241863527 | validation: 0.17116060073798642]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14687205504245682		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.14687205504245682 | validation: 0.14816744756210284]
	TIME [epoch: 5.72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13625850686229288		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.13625850686229288 | validation: 0.13989568157211912]
	TIME [epoch: 5.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21827943052656854		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.21827943052656854 | validation: 0.14806036396746972]
	TIME [epoch: 5.71 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16527681400355693		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.16527681400355693 | validation: 0.1769732333667455]
	TIME [epoch: 5.71 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14978305868926836		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.14978305868926836 | validation: 0.1806392738475362]
	TIME [epoch: 5.71 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2421300689698977		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2421300689698977 | validation: 0.14785369911295498]
	TIME [epoch: 5.71 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689154146070678		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13689154146070678 | validation: 0.13805701815489194]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14376742701469153		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.14376742701469153 | validation: 0.24005840719121962]
	TIME [epoch: 5.71 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635916036909788		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.1635916036909788 | validation: 0.1602808470703872]
	TIME [epoch: 5.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13406686090508488		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.13406686090508488 | validation: 0.21729442915540162]
	TIME [epoch: 5.71 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14164458213128933		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.14164458213128933 | validation: 0.20479046982861618]
	TIME [epoch: 5.71 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17763450958930554		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.17763450958930554 | validation: 0.17204864791904634]
	TIME [epoch: 5.71 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14417589974348607		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.14417589974348607 | validation: 0.13473432040541897]
	TIME [epoch: 5.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851615243675733		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.13851615243675733 | validation: 0.2165091224086739]
	TIME [epoch: 5.72 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579101135256289		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1579101135256289 | validation: 0.17270529654217506]
	TIME [epoch: 5.71 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136730225574678		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.136730225574678 | validation: 0.13779385986152862]
	TIME [epoch: 5.71 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13217304063367244		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.13217304063367244 | validation: 0.1278667010112667]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16259132426912282		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.16259132426912282 | validation: 0.16702717636592435]
	TIME [epoch: 5.71 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14690288241781657		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.14690288241781657 | validation: 0.13917659932508014]
	TIME [epoch: 5.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13582334584268524		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.13582334584268524 | validation: 0.13704545733659929]
	TIME [epoch: 5.73 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087126787686204		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.13087126787686204 | validation: 0.1688439949095722]
	TIME [epoch: 5.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482751961438218		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1482751961438218 | validation: 0.19491865144191978]
	TIME [epoch: 5.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16304032900934007		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.16304032900934007 | validation: 0.17558185999703807]
	TIME [epoch: 5.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13098581633722342		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.13098581633722342 | validation: 0.1379136199453153]
	TIME [epoch: 5.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13478349908898432		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.13478349908898432 | validation: 0.17048413069404705]
	TIME [epoch: 5.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1857127767940517		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1857127767940517 | validation: 0.173499114718916]
	TIME [epoch: 5.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631003370201578		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.14631003370201578 | validation: 0.15835388611861864]
	TIME [epoch: 5.72 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15563090641579994		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.15563090641579994 | validation: 0.17674159003752646]
	TIME [epoch: 5.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14927575637838514		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.14927575637838514 | validation: 0.15644862097535786]
	TIME [epoch: 5.71 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989244080694568		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.13989244080694568 | validation: 0.16108939449610601]
	TIME [epoch: 5.71 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644368455039542		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1644368455039542 | validation: 0.1461324795441251]
	TIME [epoch: 5.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14422141975058023		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.14422141975058023 | validation: 0.133182490430409]
	TIME [epoch: 5.72 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012211632878679		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.13012211632878679 | validation: 0.16358603594132087]
	TIME [epoch: 5.76 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241114597216735		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.13241114597216735 | validation: 0.13620160359673092]
	TIME [epoch: 5.72 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13352210892085392		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.13352210892085392 | validation: 0.1880899448764092]
	TIME [epoch: 5.72 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15742217823437832		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.15742217823437832 | validation: 0.13434353169726387]
	TIME [epoch: 5.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15210827903194424		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.15210827903194424 | validation: 0.1568251224999439]
	TIME [epoch: 5.71 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331028870841507		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.1331028870841507 | validation: 0.20565499908585586]
	TIME [epoch: 5.71 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1578015651193546		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1578015651193546 | validation: 0.12170753267850831]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14756538091044025		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.14756538091044025 | validation: 0.17041344473461423]
	TIME [epoch: 5.71 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695896234391877		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.1695896234391877 | validation: 0.13157222847340033]
	TIME [epoch: 5.71 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316879288004323		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1316879288004323 | validation: 0.1238555894471488]
	TIME [epoch: 5.71 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13371425576621931		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.13371425576621931 | validation: 0.12898467575203276]
	TIME [epoch: 5.71 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13034195132802714		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.13034195132802714 | validation: 0.16141526789701413]
	TIME [epoch: 5.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194395330499925		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.13194395330499925 | validation: 0.11202658303535945]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425383154011256		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.12425383154011256 | validation: 0.11805836305792224]
	TIME [epoch: 5.76 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753927042024172		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.13753927042024172 | validation: 0.1771797926365398]
	TIME [epoch: 5.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1858366552503629		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1858366552503629 | validation: 0.19983789164429921]
	TIME [epoch: 5.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15388354449265335		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.15388354449265335 | validation: 0.1349457725753298]
	TIME [epoch: 5.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14125788101208825		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.14125788101208825 | validation: 0.15834076606695344]
	TIME [epoch: 5.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14770588927976527		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.14770588927976527 | validation: 0.18161106568713734]
	TIME [epoch: 5.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378060164902129		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1378060164902129 | validation: 0.1450039911516778]
	TIME [epoch: 5.73 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15382069840431928		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.15382069840431928 | validation: 0.1452725465140018]
	TIME [epoch: 5.71 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14325918565770532		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.14325918565770532 | validation: 0.14645960542236652]
	TIME [epoch: 5.71 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965841048379403		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.15965841048379403 | validation: 0.17555733205849106]
	TIME [epoch: 5.71 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108029084665273		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.15108029084665273 | validation: 0.15238044696132888]
	TIME [epoch: 5.71 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14548425698082498		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14548425698082498 | validation: 0.16638104766722317]
	TIME [epoch: 5.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563454083252563		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.1563454083252563 | validation: 0.16267400875621904]
	TIME [epoch: 5.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307945726914053		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.1307945726914053 | validation: 0.12890046110503459]
	TIME [epoch: 5.74 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13324221405897047		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.13324221405897047 | validation: 0.1402682357757939]
	TIME [epoch: 5.72 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19621390913171663		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.19621390913171663 | validation: 0.14762642619591707]
	TIME [epoch: 5.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280924254123134		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1280924254123134 | validation: 0.15691858559909816]
	TIME [epoch: 5.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12385075992065164		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.12385075992065164 | validation: 0.16230765177666304]
	TIME [epoch: 5.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13877020127026793		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.13877020127026793 | validation: 0.14355171713255577]
	TIME [epoch: 5.71 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339828729300343		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1339828729300343 | validation: 0.13875493835109534]
	TIME [epoch: 5.73 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14935523778853163		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.14935523778853163 | validation: 0.14120967418223532]
	TIME [epoch: 5.72 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13941852538819033		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.13941852538819033 | validation: 0.3179741212474354]
	TIME [epoch: 5.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21226670171866704		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.21226670171866704 | validation: 0.18539974937926315]
	TIME [epoch: 5.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16053466748014975		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.16053466748014975 | validation: 0.14297549191016462]
	TIME [epoch: 5.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447652338089079		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.1447652338089079 | validation: 0.14812929628513144]
	TIME [epoch: 5.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13116880917610704		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.13116880917610704 | validation: 0.11794104268421457]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573379713495666		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14573379713495666 | validation: 0.19429060478165874]
	TIME [epoch: 5.75 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15432993830987835		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.15432993830987835 | validation: 0.14941286151190433]
	TIME [epoch: 5.72 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12398347884072025		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.12398347884072025 | validation: 0.15965980616727468]
	TIME [epoch: 5.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12822637356008604		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.12822637356008604 | validation: 0.15400761003816438]
	TIME [epoch: 5.71 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702975318909583		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.13702975318909583 | validation: 0.15512712902801254]
	TIME [epoch: 5.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13661418492053404		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.13661418492053404 | validation: 0.1442276794764528]
	TIME [epoch: 5.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13881562785818993		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.13881562785818993 | validation: 0.1593045509261428]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369722836406827		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.1369722836406827 | validation: 0.1480653130419597]
	TIME [epoch: 5.73 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653761693671337		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.13653761693671337 | validation: 0.1843345987695819]
	TIME [epoch: 5.71 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17463801367852927		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.17463801367852927 | validation: 0.24467475331233698]
	TIME [epoch: 5.71 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558035931368482		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1558035931368482 | validation: 0.13637512409137162]
	TIME [epoch: 5.71 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737750931696293		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.12737750931696293 | validation: 0.1338803748595831]
	TIME [epoch: 5.71 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12441283060984125		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.12441283060984125 | validation: 0.15275223481802822]
	TIME [epoch: 5.71 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13062499978333453		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.13062499978333453 | validation: 0.14964608133861654]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290213465336848		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.1290213465336848 | validation: 0.1533967596861278]
	TIME [epoch: 5.71 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13804757089248837		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.13804757089248837 | validation: 0.17109110064210303]
	TIME [epoch: 5.71 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443131169501809		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.1443131169501809 | validation: 0.14635858989099765]
	TIME [epoch: 5.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14987424595987064		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.14987424595987064 | validation: 0.13473565853837724]
	TIME [epoch: 5.71 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13084225527915302		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.13084225527915302 | validation: 0.1325947648023341]
	TIME [epoch: 5.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15243498281561568		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.15243498281561568 | validation: 0.13673555360082756]
	TIME [epoch: 5.73 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148361678189524		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.148361678189524 | validation: 0.12647863629812126]
	TIME [epoch: 5.73 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331055319684833		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.1331055319684833 | validation: 0.11836081464460639]
	TIME [epoch: 5.71 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377486686549262		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.1377486686549262 | validation: 0.12949322720099793]
	TIME [epoch: 5.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13270242245926492		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.13270242245926492 | validation: 0.13229501139636152]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313095785963962		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.1313095785963962 | validation: 0.19683755515706966]
	TIME [epoch: 5.71 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999008125479391		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.15999008125479391 | validation: 0.13724018207134067]
	TIME [epoch: 5.72 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301285218378467		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.13301285218378467 | validation: 0.12491705364837931]
	TIME [epoch: 5.76 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060158649765222		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.13060158649765222 | validation: 0.122836129866841]
	TIME [epoch: 5.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370373630038851		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.1370373630038851 | validation: 0.1575595240026948]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13845930598086914		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.13845930598086914 | validation: 0.16275422132055853]
	TIME [epoch: 5.71 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15358140843723633		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.15358140843723633 | validation: 0.1974619761624011]
	TIME [epoch: 5.71 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495644664510043		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.1495644664510043 | validation: 0.14463479350022876]
	TIME [epoch: 5.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14389808797077178		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.14389808797077178 | validation: 0.15866926120201683]
	TIME [epoch: 5.73 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14272099044117076		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.14272099044117076 | validation: 0.16838496050917948]
	TIME [epoch: 5.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713724102274588		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.13713724102274588 | validation: 0.17391448486704283]
	TIME [epoch: 5.71 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17618126872232523		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.17618126872232523 | validation: 0.2009421594243169]
	TIME [epoch: 5.71 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14679521210954768		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.14679521210954768 | validation: 0.14273506216396517]
	TIME [epoch: 5.71 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13982639222668605		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.13982639222668605 | validation: 0.14162221565053698]
	TIME [epoch: 5.71 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327025890809852		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.13327025890809852 | validation: 0.15177574885327044]
	TIME [epoch: 5.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13777033004695702		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.13777033004695702 | validation: 0.1363041308314983]
	TIME [epoch: 5.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13438929018559476		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.13438929018559476 | validation: 0.14149827146057578]
	TIME [epoch: 5.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15194829613535135		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.15194829613535135 | validation: 0.16463424426632145]
	TIME [epoch: 5.71 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273732332772344		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1273732332772344 | validation: 0.1207849948713621]
	TIME [epoch: 5.71 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13751691052918		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.13751691052918 | validation: 0.14650774764635782]
	TIME [epoch: 5.71 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255331196290023		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.1255331196290023 | validation: 0.13288069491972132]
	TIME [epoch: 5.71 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316797242246686		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13316797242246686 | validation: 0.13714331462488796]
	TIME [epoch: 5.74 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575929370226027		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.12575929370226027 | validation: 0.12711938482369362]
	TIME [epoch: 5.72 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693880302572712		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.14693880302572712 | validation: 0.16898206054508236]
	TIME [epoch: 5.71 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15344293505981335		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.15344293505981335 | validation: 0.14209964330378594]
	TIME [epoch: 5.71 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14138253288724031		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.14138253288724031 | validation: 0.123044422197712]
	TIME [epoch: 5.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14639219099161363		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.14639219099161363 | validation: 0.13984200707809583]
	TIME [epoch: 5.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869523246202678		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.11869523246202678 | validation: 0.1526378173681722]
	TIME [epoch: 5.71 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275900091890021		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.1275900091890021 | validation: 0.1477781392851208]
	TIME [epoch: 5.74 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15006073688389415		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.15006073688389415 | validation: 0.155375697213151]
	TIME [epoch: 5.71 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515862827112935		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1515862827112935 | validation: 0.12445744882580677]
	TIME [epoch: 5.71 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12904695587774362		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.12904695587774362 | validation: 0.14911499415252258]
	TIME [epoch: 5.71 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131621350922643		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.131621350922643 | validation: 0.12643894935877578]
	TIME [epoch: 5.71 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13971152358625932		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.13971152358625932 | validation: 0.17165782213972475]
	TIME [epoch: 5.71 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139214927700989		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.139214927700989 | validation: 0.12767767229232274]
	TIME [epoch: 5.73 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456141617198269		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.1456141617198269 | validation: 0.13956000336505345]
	TIME [epoch: 5.72 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507892287064304		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1507892287064304 | validation: 0.14353809584911575]
	TIME [epoch: 5.71 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13069754154017543		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.13069754154017543 | validation: 0.16558669220807373]
	TIME [epoch: 5.71 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394632539829702		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.1394632539829702 | validation: 0.14559392894606354]
	TIME [epoch: 5.71 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273388327823955		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.1273388327823955 | validation: 0.13555120973725956]
	TIME [epoch: 5.71 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14492971922309664		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.14492971922309664 | validation: 0.15562692614015397]
	TIME [epoch: 5.71 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115568518303004		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.14115568518303004 | validation: 0.12181683408767502]
	TIME [epoch: 5.75 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280046581843914		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1280046581843914 | validation: 0.12171302858559266]
	TIME [epoch: 5.71 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920653444940064		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.12920653444940064 | validation: 0.13148651134470518]
	TIME [epoch: 5.71 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14257524248348039		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.14257524248348039 | validation: 0.13957048188664575]
	TIME [epoch: 5.71 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14531820587193164		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.14531820587193164 | validation: 0.12156577712133163]
	TIME [epoch: 5.71 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741180474431774		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.11741180474431774 | validation: 0.13804582253278208]
	TIME [epoch: 5.71 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259977472834541		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.1259977472834541 | validation: 0.13025438069099343]
	TIME [epoch: 5.73 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522943107683238		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.12522943107683238 | validation: 0.12531364841176465]
	TIME [epoch: 5.72 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12454033149890725		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.12454033149890725 | validation: 0.1614864433958988]
	TIME [epoch: 5.71 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636026894515172		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.1636026894515172 | validation: 0.13169260249755227]
	TIME [epoch: 5.71 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12747163727416214		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.12747163727416214 | validation: 0.14834329303587848]
	TIME [epoch: 5.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143044526735907		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.143044526735907 | validation: 0.11856507704993981]
	TIME [epoch: 5.71 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355196688893372		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.12355196688893372 | validation: 0.12209518265127656]
	TIME [epoch: 5.71 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11887446454090253		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.11887446454090253 | validation: 0.14223260777549435]
	TIME [epoch: 5.75 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12244693043303037		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.12244693043303037 | validation: 0.14538149675483256]
	TIME [epoch: 5.71 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532110610107422		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.12532110610107422 | validation: 0.1793891147823357]
	TIME [epoch: 5.71 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14104572070205504		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.14104572070205504 | validation: 0.13840240434156967]
	TIME [epoch: 5.71 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13933627090843728		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.13933627090843728 | validation: 0.1481540180274447]
	TIME [epoch: 5.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090507535620044		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.13090507535620044 | validation: 0.1285202456799783]
	TIME [epoch: 5.71 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11948951470582354		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.11948951470582354 | validation: 0.11990279750420768]
	TIME [epoch: 5.73 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247381827726267		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.11247381827726267 | validation: 0.13949082382847666]
	TIME [epoch: 5.72 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310742866439445		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.1310742866439445 | validation: 0.13432314970843093]
	TIME [epoch: 5.71 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278244476999319		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.1278244476999319 | validation: 0.14130135572260727]
	TIME [epoch: 5.71 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14715710268348028		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.14715710268348028 | validation: 0.11981069898601408]
	TIME [epoch: 5.71 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12445034357458683		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12445034357458683 | validation: 0.13181850407610418]
	TIME [epoch: 5.71 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169609391324532		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.1169609391324532 | validation: 0.18270110591723449]
	TIME [epoch: 5.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13473147567760824		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.13473147567760824 | validation: 0.12443771339597909]
	TIME [epoch: 5.74 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494458275459042		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.12494458275459042 | validation: 0.11875505196154773]
	TIME [epoch: 5.71 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336082808057137		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.1336082808057137 | validation: 0.12446364746003837]
	TIME [epoch: 5.71 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349016900826851		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1349016900826851 | validation: 0.15323635606508876]
	TIME [epoch: 5.71 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14371938188016176		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14371938188016176 | validation: 0.15392088375499952]
	TIME [epoch: 5.71 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12501220181515565		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.12501220181515565 | validation: 0.14668014849814437]
	TIME [epoch: 5.71 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12330145063734997		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.12330145063734997 | validation: 0.14462071073470553]
	TIME [epoch: 5.73 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336891986114589		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.1336891986114589 | validation: 0.13603947423342366]
	TIME [epoch: 5.72 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14406731307732773		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.14406731307732773 | validation: 0.11217255329524138]
	TIME [epoch: 5.71 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11807861171570994		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.11807861171570994 | validation: 0.1390339962844523]
	TIME [epoch: 5.71 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13259926942978387		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.13259926942978387 | validation: 0.12237648915112359]
	TIME [epoch: 5.71 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13709441186313906		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.13709441186313906 | validation: 0.12140706262013078]
	TIME [epoch: 5.71 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12032734651386992		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.12032734651386992 | validation: 0.1477090808838247]
	TIME [epoch: 5.71 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12812142743390154		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12812142743390154 | validation: 0.1296992981679829]
	TIME [epoch: 5.74 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353899140124267		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.13353899140124267 | validation: 0.11584621056004203]
	TIME [epoch: 5.71 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14921268757238734		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.14921268757238734 | validation: 0.1762117267091697]
	TIME [epoch: 5.71 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14536793418365826		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.14536793418365826 | validation: 0.1221333630068434]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307015221898346		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1307015221898346 | validation: 0.15795747742966068]
	TIME [epoch: 5.71 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296119056752696		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.1296119056752696 | validation: 0.11849293670224281]
	TIME [epoch: 5.71 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757248011766022		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.11757248011766022 | validation: 0.13127562245897326]
	TIME [epoch: 5.72 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12044391537493		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.12044391537493 | validation: 0.12112554211265797]
	TIME [epoch: 5.74 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559278134830743		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.13559278134830743 | validation: 0.22696343234298522]
	TIME [epoch: 5.71 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1649535091947127		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.1649535091947127 | validation: 0.1337827535524235]
	TIME [epoch: 5.71 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294686345391984		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.11294686345391984 | validation: 0.12065484112214626]
	TIME [epoch: 5.71 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252999095740913		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.1252999095740913 | validation: 0.14405481819786917]
	TIME [epoch: 5.71 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024987126678854		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.12024987126678854 | validation: 0.14378788965072797]
	TIME [epoch: 5.71 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11907582049235058		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.11907582049235058 | validation: 0.135644703418902]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12221069320254468		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.12221069320254468 | validation: 0.13819949506364887]
	TIME [epoch: 5.71 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14298182463312875		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.14298182463312875 | validation: 0.11668252719722519]
	TIME [epoch: 5.71 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1165327852605906		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1165327852605906 | validation: 0.11611706226309707]
	TIME [epoch: 5.71 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433349184911255		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.12433349184911255 | validation: 0.15551330534522023]
	TIME [epoch: 5.71 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824876101383432		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.13824876101383432 | validation: 0.11318300200408586]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11940938380443154		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.11940938380443154 | validation: 0.13327926323134218]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263033255454673		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.1263033255454673 | validation: 0.17517445906943205]
	TIME [epoch: 5.73 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341604185246806		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1341604185246806 | validation: 0.12822994086093795]
	TIME [epoch: 5.71 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498294374003492		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.12498294374003492 | validation: 0.1315709016597365]
	TIME [epoch: 5.71 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13568813264702087		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.13568813264702087 | validation: 0.12977850678746974]
	TIME [epoch: 5.71 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248383293669701		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.12248383293669701 | validation: 0.15363565235141724]
	TIME [epoch: 5.71 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259438688099128		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.1259438688099128 | validation: 0.19201403599885644]
	TIME [epoch: 5.71 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14909318660948923		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.14909318660948923 | validation: 0.17021651800062632]
	TIME [epoch: 5.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13505425252090317		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.13505425252090317 | validation: 0.16617549856460045]
	TIME [epoch: 5.71 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14148626420640786		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.14148626420640786 | validation: 0.13664915071240066]
	TIME [epoch: 5.71 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231954411902341		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.1231954411902341 | validation: 0.12798460272905132]
	TIME [epoch: 5.71 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12106067224324535		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.12106067224324535 | validation: 0.12363977814647217]
	TIME [epoch: 5.71 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13251619221154348		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.13251619221154348 | validation: 0.12793802552925887]
	TIME [epoch: 5.71 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910098772526333		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.11910098772526333 | validation: 0.18079374692899572]
	TIME [epoch: 5.72 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13084316812388938		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.13084316812388938 | validation: 0.12055646273265386]
	TIME [epoch: 5.73 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13062610114391388		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.13062610114391388 | validation: 0.13845396275987823]
	TIME [epoch: 5.71 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541282192599482		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.1541282192599482 | validation: 0.13613804924820935]
	TIME [epoch: 5.71 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13358305579166496		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.13358305579166496 | validation: 0.12122688587663699]
	TIME [epoch: 5.71 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783333288794982		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.11783333288794982 | validation: 0.11348236568375195]
	TIME [epoch: 5.71 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930189089571203		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.11930189089571203 | validation: 0.15003299315983412]
	TIME [epoch: 5.71 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13337627515647016		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.13337627515647016 | validation: 0.12985875701737185]
	TIME [epoch: 5.74 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179208337877921		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.1179208337877921 | validation: 0.12548791895626893]
	TIME [epoch: 5.71 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560317075636772		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.11560317075636772 | validation: 0.12873439291558975]
	TIME [epoch: 5.71 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11870266270804011		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.11870266270804011 | validation: 0.13741875924703814]
	TIME [epoch: 5.71 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989492227491505		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.11989492227491505 | validation: 0.1048176713301348]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_992.pth
	Model improved!!!
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11609904404136498		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.11609904404136498 | validation: 0.1306055665461108]
	TIME [epoch: 5.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280366836041765		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.1280366836041765 | validation: 0.11988613361768487]
	TIME [epoch: 5.73 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12023100511280198		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.12023100511280198 | validation: 0.10845126842064538]
	TIME [epoch: 5.71 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13919713288012375		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.13919713288012375 | validation: 0.12297534636162272]
	TIME [epoch: 5.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550560182023016		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.11550560182023016 | validation: 0.1140098243725254]
	TIME [epoch: 5.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016587124417477		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.12016587124417477 | validation: 0.11633560194394937]
	TIME [epoch: 5.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12827318198248927		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.12827318198248927 | validation: 0.13045378684393805]
	TIME [epoch: 5.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426314141803523		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.12426314141803523 | validation: 0.16840813876632765]
	TIME [epoch: 5.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366307675555722		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.1366307675555722 | validation: 0.11000296542206633]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11314689422400316		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.11314689422400316 | validation: 0.12082427255010351]
	TIME [epoch: 5.71 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11722390860183046		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.11722390860183046 | validation: 0.1265685616929377]
	TIME [epoch: 5.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136086564376263		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.136086564376263 | validation: 0.1127207333309368]
	TIME [epoch: 5.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11929478321108078		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.11929478321108078 | validation: 0.12439267574778025]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11889559860880111		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.11889559860880111 | validation: 0.11713913489072802]
	TIME [epoch: 5.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11299524975014458		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.11299524975014458 | validation: 0.12304317360521858]
	TIME [epoch: 5.73 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13281031546906163		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.13281031546906163 | validation: 0.1320210862849151]
	TIME [epoch: 5.72 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326764745966571		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1326764745966571 | validation: 0.1327746102209681]
	TIME [epoch: 5.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11801409276826161		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.11801409276826161 | validation: 0.11322420104382222]
	TIME [epoch: 5.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890151031741392		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11890151031741392 | validation: 0.12617999004110192]
	TIME [epoch: 5.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454504080876678		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.13454504080876678 | validation: 0.12133751534313411]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359451204826328		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.11359451204826328 | validation: 0.13680140349537503]
	TIME [epoch: 5.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300364742156658		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.12300364742156658 | validation: 0.11969630387012994]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960554648844338		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.11960554648844338 | validation: 0.11403962486054837]
	TIME [epoch: 5.71 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075010017179616		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.11075010017179616 | validation: 0.10766990994408301]
	TIME [epoch: 5.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211645676844502		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1211645676844502 | validation: 0.14661253858456486]
	TIME [epoch: 5.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12968586526813927		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.12968586526813927 | validation: 0.11810111604439646]
	TIME [epoch: 5.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13636059339808287		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.13636059339808287 | validation: 0.12245486705943766]
	TIME [epoch: 5.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079166767890574		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.13079166767890574 | validation: 0.11701189621980616]
	TIME [epoch: 5.73 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12501743159044632		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.12501743159044632 | validation: 0.1471061586623378]
	TIME [epoch: 5.72 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13499587829032456		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.13499587829032456 | validation: 0.12598493109857475]
	TIME [epoch: 5.71 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12124030721024592		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.12124030721024592 | validation: 0.13224953854261]
	TIME [epoch: 5.71 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855225893968677		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.11855225893968677 | validation: 0.13697756916924703]
	TIME [epoch: 5.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11669491829746835		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.11669491829746835 | validation: 0.12192305265456874]
	TIME [epoch: 5.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11787364338243433		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.11787364338243433 | validation: 0.13011117485446552]
	TIME [epoch: 5.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1175264473292008		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.1175264473292008 | validation: 0.1268432767899274]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12952856718352276		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.12952856718352276 | validation: 0.12785827232156954]
	TIME [epoch: 5.71 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798799142200182		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.15798799142200182 | validation: 0.13843847236687587]
	TIME [epoch: 5.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11755537455980947		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.11755537455980947 | validation: 0.10822005373510374]
	TIME [epoch: 5.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11120916819058708		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.11120916819058708 | validation: 0.1189629934401556]
	TIME [epoch: 5.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12060131278690223		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.12060131278690223 | validation: 0.1359023323744548]
	TIME [epoch: 5.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836588812509985		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11836588812509985 | validation: 0.15227315769275207]
	TIME [epoch: 5.71 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854849409722997		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.13854849409722997 | validation: 0.11660798332795508]
	TIME [epoch: 5.73 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405771000239548		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.11405771000239548 | validation: 0.1255651065508644]
	TIME [epoch: 5.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232800166790905		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1232800166790905 | validation: 0.12701522284321656]
	TIME [epoch: 5.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255457728132667		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.11255457728132667 | validation: 0.11261273950992685]
	TIME [epoch: 5.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273427970135931		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.11273427970135931 | validation: 0.13364904203407904]
	TIME [epoch: 5.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243263178970851		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.1243263178970851 | validation: 0.13449424264254625]
	TIME [epoch: 5.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11687589952101785		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.11687589952101785 | validation: 0.1279466105162042]
	TIME [epoch: 5.74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068167664301337		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.11068167664301337 | validation: 0.1140281333085433]
	TIME [epoch: 5.71 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11010398054827623		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.11010398054827623 | validation: 0.1582047059080113]
	TIME [epoch: 5.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13374843200409914		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.13374843200409914 | validation: 0.13032334845815136]
	TIME [epoch: 5.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11743059855189786		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.11743059855189786 | validation: 0.13252672290009185]
	TIME [epoch: 5.71 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11509409014579391		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.11509409014579391 | validation: 0.12057562275992675]
	TIME [epoch: 5.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13920727682518697		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.13920727682518697 | validation: 0.17136311122355882]
	TIME [epoch: 5.71 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240298711666992		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1240298711666992 | validation: 0.11586770008830204]
	TIME [epoch: 5.73 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159457627580256		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.12159457627580256 | validation: 0.13671655994919113]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349697111101974		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1349697111101974 | validation: 0.12014629867043983]
	TIME [epoch: 5.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12338815476625092		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.12338815476625092 | validation: 0.14085628993115346]
	TIME [epoch: 5.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466227757754808		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.1466227757754808 | validation: 0.11054027367819068]
	TIME [epoch: 5.71 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11752479751041799		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.11752479751041799 | validation: 0.13919002137722078]
	TIME [epoch: 5.71 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12762236584163314		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.12762236584163314 | validation: 0.12482979450949472]
	TIME [epoch: 5.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127225058683361		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1127225058683361 | validation: 0.11255477566648725]
	TIME [epoch: 5.71 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11454275421515643		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.11454275421515643 | validation: 0.1151863143578424]
	TIME [epoch: 5.71 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688014075844513		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.11688014075844513 | validation: 0.11340912017667826]
	TIME [epoch: 5.71 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11943384278008583		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.11943384278008583 | validation: 0.14513840805402706]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129564118238574		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.129564118238574 | validation: 0.12053081968066387]
	TIME [epoch: 5.71 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312049150650036		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.11312049150650036 | validation: 0.1199371811860865]
	TIME [epoch: 5.72 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298861699813458		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.1298861699813458 | validation: 0.10304105749364723]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1060.pth
	Model improved!!!
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426457614608085		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.11426457614608085 | validation: 0.10665287430069441]
	TIME [epoch: 5.71 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11326009476968278		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.11326009476968278 | validation: 0.11433528953667567]
	TIME [epoch: 5.72 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11363983301058156		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.11363983301058156 | validation: 0.10838885648444194]
	TIME [epoch: 5.71 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10995737876334816		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.10995737876334816 | validation: 0.12443007058927599]
	TIME [epoch: 5.71 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942981271492769		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.10942981271492769 | validation: 0.13012338718039765]
	TIME [epoch: 5.72 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230334839957579		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1230334839957579 | validation: 0.1148093838942891]
	TIME [epoch: 5.76 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11600924850784933		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.11600924850784933 | validation: 0.14055233476621262]
	TIME [epoch: 5.71 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238052199345603		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.12238052199345603 | validation: 0.11268910749784158]
	TIME [epoch: 5.72 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097231263364396		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.11097231263364396 | validation: 0.12260506072494746]
	TIME [epoch: 5.71 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242254305661445		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.11242254305661445 | validation: 0.1250587355527131]
	TIME [epoch: 5.72 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11455359144312557		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.11455359144312557 | validation: 0.10446578167645608]
	TIME [epoch: 5.71 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11362571680962495		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.11362571680962495 | validation: 0.12421446368374295]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383586336405646		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.11383586336405646 | validation: 0.12202735793720948]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12406624601848057		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.12406624601848057 | validation: 0.13080519166160703]
	TIME [epoch: 5.71 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11343713335330136		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.11343713335330136 | validation: 0.12614233290857219]
	TIME [epoch: 5.72 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982878764162488		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.10982878764162488 | validation: 0.12357493025762685]
	TIME [epoch: 5.71 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909072319389343		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.10909072319389343 | validation: 0.11820916018155238]
	TIME [epoch: 5.72 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11023259739090736		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.11023259739090736 | validation: 0.11467798758954655]
	TIME [epoch: 5.71 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12628046892396738		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.12628046892396738 | validation: 0.12271031034077026]
	TIME [epoch: 5.75 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182606989629992		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.12182606989629992 | validation: 0.129141121142351]
	TIME [epoch: 5.71 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759839442447399		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.11759839442447399 | validation: 0.10952311336156118]
	TIME [epoch: 5.71 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090672665056049		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.1090672665056049 | validation: 0.12030095956147797]
	TIME [epoch: 5.71 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294183348365139		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.11294183348365139 | validation: 0.13260222894269041]
	TIME [epoch: 5.71 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12380145967017925		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.12380145967017925 | validation: 0.13508377330099144]
	TIME [epoch: 5.71 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11723305981666177		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.11723305981666177 | validation: 0.1218537291454836]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11673867604064761		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.11673867604064761 | validation: 0.10896645297255582]
	TIME [epoch: 5.72 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135375529685416		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.12135375529685416 | validation: 0.15686125165836362]
	TIME [epoch: 5.71 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278994544817046		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.1278994544817046 | validation: 0.10118960940703665]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1088.pth
	Model improved!!!
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077348954764103		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.1077348954764103 | validation: 0.11118515034580305]
	TIME [epoch: 5.71 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259367808011367		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.1259367808011367 | validation: 0.1125890815836065]
	TIME [epoch: 5.72 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154355914751766		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.1154355914751766 | validation: 0.11295466858571976]
	TIME [epoch: 5.71 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365338481778912		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.11365338481778912 | validation: 0.1252857113124158]
	TIME [epoch: 5.76 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1158142915352649		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1158142915352649 | validation: 0.16195178872466315]
	TIME [epoch: 5.72 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498423416575727		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.12498423416575727 | validation: 0.1174343331464402]
	TIME [epoch: 5.72 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10680709578570283		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.10680709578570283 | validation: 0.11401156376713686]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113441207270998		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.11113441207270998 | validation: 0.1293336929144565]
	TIME [epoch: 5.71 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16355695098266065		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.16355695098266065 | validation: 0.15286782972127422]
	TIME [epoch: 5.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13240432723657714		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.13240432723657714 | validation: 0.1280796018097977]
	TIME [epoch: 5.74 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231092865953018		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11231092865953018 | validation: 0.11603429046920932]
	TIME [epoch: 5.72 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791919350284138		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10791919350284138 | validation: 0.13229377684852178]
	TIME [epoch: 5.72 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11417073583218089		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.11417073583218089 | validation: 0.10839920155706124]
	TIME [epoch: 5.71 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416723543532021		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10416723543532021 | validation: 0.10752418715162451]
	TIME [epoch: 5.71 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108847557375743		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.1108847557375743 | validation: 0.1325256246751043]
	TIME [epoch: 5.71 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469914008842082		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.11469914008842082 | validation: 0.11228861441154443]
	TIME [epoch: 5.71 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115120777224964		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.115120777224964 | validation: 0.119833850851313]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11116768020300594		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.11116768020300594 | validation: 0.10936995830518248]
	TIME [epoch: 5.71 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933890911658344		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.10933890911658344 | validation: 0.12981426284979236]
	TIME [epoch: 5.71 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11831689848842838		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.11831689848842838 | validation: 0.11996842964756375]
	TIME [epoch: 5.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11598677645864156		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.11598677645864156 | validation: 0.13025122764678038]
	TIME [epoch: 5.71 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415769390204093		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.12415769390204093 | validation: 0.1233020331135223]
	TIME [epoch: 5.71 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438917306487656		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.10438917306487656 | validation: 0.11508110870688543]
	TIME [epoch: 5.73 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218412758589533		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.11218412758589533 | validation: 0.12675899847567806]
	TIME [epoch: 5.73 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1151791179347291		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.1151791179347291 | validation: 0.11247208454971905]
	TIME [epoch: 5.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11491290091003115		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.11491290091003115 | validation: 0.12011462621979069]
	TIME [epoch: 5.71 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14091837891433084		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.14091837891433084 | validation: 0.11573669532155213]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12908861816321507		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.12908861816321507 | validation: 0.11925078846433206]
	TIME [epoch: 5.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12768472202897307		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.12768472202897307 | validation: 0.12198774668293562]
	TIME [epoch: 5.71 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1130974774569614		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.1130974774569614 | validation: 0.10775013165219102]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189636336436078		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.11189636336436078 | validation: 0.10775646971006736]
	TIME [epoch: 5.71 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918296232743359		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.10918296232743359 | validation: 0.10635693008764702]
	TIME [epoch: 5.71 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019684090329293		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.1019684090329293 | validation: 0.11486284343041642]
	TIME [epoch: 5.71 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12594140226417766		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.12594140226417766 | validation: 0.1417144812934323]
	TIME [epoch: 5.72 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12327710196466479		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.12327710196466479 | validation: 0.12250541217329859]
	TIME [epoch: 5.71 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11652507637315909		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.11652507637315909 | validation: 0.12973957834317587]
	TIME [epoch: 5.73 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11736690470263172		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.11736690470263172 | validation: 0.11718315330930047]
	TIME [epoch: 5.72 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421530246529127		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.11421530246529127 | validation: 0.13324871703676242]
	TIME [epoch: 5.72 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870903622648959		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.10870903622648959 | validation: 0.12724346344426404]
	TIME [epoch: 5.71 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280645628020836		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.12280645628020836 | validation: 0.11550713163176088]
	TIME [epoch: 5.71 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12584470323622665		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.12584470323622665 | validation: 0.12123402766051125]
	TIME [epoch: 5.71 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022292463886599		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.11022292463886599 | validation: 0.12011770260074947]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12715199822315154		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.12715199822315154 | validation: 0.11985017203100912]
	TIME [epoch: 5.76 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11732997940111023		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.11732997940111023 | validation: 0.09972657595486764]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1132.pth
	Model improved!!!
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044898194260336		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.11044898194260336 | validation: 0.10773484375518062]
	TIME [epoch: 5.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230849983777294		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.11230849983777294 | validation: 0.11527588651808988]
	TIME [epoch: 5.71 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12033620715363434		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.12033620715363434 | validation: 0.1087187913641953]
	TIME [epoch: 5.71 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11400912505749065		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.11400912505749065 | validation: 0.11912234741911865]
	TIME [epoch: 5.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427600529044075		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.11427600529044075 | validation: 0.12275334268427239]
	TIME [epoch: 5.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12816901470997757		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.12816901470997757 | validation: 0.10761971088084998]
	TIME [epoch: 5.73 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566393661490418		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.10566393661490418 | validation: 0.11521700947839658]
	TIME [epoch: 5.72 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11568220955479348		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.11568220955479348 | validation: 0.10810544275521938]
	TIME [epoch: 5.71 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147940850344884		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.1147940850344884 | validation: 0.11674537100892192]
	TIME [epoch: 5.72 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11566402628513434		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.11566402628513434 | validation: 0.10458404688706117]
	TIME [epoch: 5.71 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252743569557073		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.11252743569557073 | validation: 0.10595081011666505]
	TIME [epoch: 5.72 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209243666402668		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.11209243666402668 | validation: 0.09834355406004655]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11188716328761035		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.11188716328761035 | validation: 0.10409987580176826]
	TIME [epoch: 5.72 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654872476692312		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.10654872476692312 | validation: 0.10005508218366771]
	TIME [epoch: 5.71 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10783864547758973		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.10783864547758973 | validation: 0.10325846956096933]
	TIME [epoch: 5.71 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058194494818877		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.1058194494818877 | validation: 0.10980507789070433]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12021873055100969		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.12021873055100969 | validation: 0.10548961808800254]
	TIME [epoch: 5.71 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13279906136024178		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.13279906136024178 | validation: 0.15881719892000123]
	TIME [epoch: 5.75 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12982892569548093		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.12982892569548093 | validation: 0.11216361311903171]
	TIME [epoch: 5.72 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300439402814917		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.11300439402814917 | validation: 0.10146137402682158]
	TIME [epoch: 5.71 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647960830767905		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.10647960830767905 | validation: 0.10161971991752396]
	TIME [epoch: 5.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525339610676479		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.10525339610676479 | validation: 0.10705968808985876]
	TIME [epoch: 5.71 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255407321629746		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.1255407321629746 | validation: 0.13181442381946912]
	TIME [epoch: 5.71 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11409512111854224		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.11409512111854224 | validation: 0.10963468273825491]
	TIME [epoch: 5.72 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017897747333201		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.11017897747333201 | validation: 0.09812501773598531]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1157.pth
	Model improved!!!
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039318588121519		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.11039318588121519 | validation: 0.12173137965518528]
	TIME [epoch: 5.72 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182325012734598		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.12182325012734598 | validation: 0.11634567591992166]
	TIME [epoch: 5.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998127623065307		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.10998127623065307 | validation: 0.1169364787471761]
	TIME [epoch: 5.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578083964434681		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.10578083964434681 | validation: 0.10796507076708864]
	TIME [epoch: 5.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900502913430363		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.10900502913430363 | validation: 0.12675482044772174]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113026441654711		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.113026441654711 | validation: 0.14444484478191477]
	TIME [epoch: 5.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135917770930138		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1135917770930138 | validation: 0.1378676278944773]
	TIME [epoch: 5.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11215185887895378		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.11215185887895378 | validation: 0.12569575007902312]
	TIME [epoch: 5.71 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178431076055868		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.1178431076055868 | validation: 0.15044245421241675]
	TIME [epoch: 5.69 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115679906143829		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.115679906143829 | validation: 0.12955606747026555]
	TIME [epoch: 5.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11889279504620087		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.11889279504620087 | validation: 0.1100280663033558]
	TIME [epoch: 5.69 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438711052083703		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.10438711052083703 | validation: 0.12019135530096656]
	TIME [epoch: 5.72 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11564729066960405		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.11564729066960405 | validation: 0.1317526271980268]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454355701023342		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.10454355701023342 | validation: 0.11271272594763866]
	TIME [epoch: 5.71 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857865652475921		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.11857865652475921 | validation: 0.11203305489224182]
	TIME [epoch: 5.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1156423445704783		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.1156423445704783 | validation: 0.1246492038727003]
	TIME [epoch: 5.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.116041650263764		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.116041650263764 | validation: 0.11091474365448586]
	TIME [epoch: 5.69 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165317533743145		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.11165317533743145 | validation: 0.10748166202871591]
	TIME [epoch: 5.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274733520650058		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.11274733520650058 | validation: 0.10271521427681311]
	TIME [epoch: 5.74 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705751978415955		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.10705751978415955 | validation: 0.10834585085564005]
	TIME [epoch: 5.71 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663016484873646		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.10663016484873646 | validation: 0.11216629991140803]
	TIME [epoch: 5.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10972183186047745		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.10972183186047745 | validation: 0.11047227334847914]
	TIME [epoch: 5.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11112952281879702		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.11112952281879702 | validation: 0.12109119239243268]
	TIME [epoch: 5.69 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12193539439947351		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.12193539439947351 | validation: 0.151088851034771]
	TIME [epoch: 5.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300164991765149		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.12300164991765149 | validation: 0.11617180570796624]
	TIME [epoch: 5.71 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11055959944573296		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.11055959944573296 | validation: 0.11438351366912303]
	TIME [epoch: 5.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064691613569111		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.11064691613569111 | validation: 0.1046639556250572]
	TIME [epoch: 5.71 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10740843496348418		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.10740843496348418 | validation: 0.1028341331629053]
	TIME [epoch: 5.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100422902907706		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.1100422902907706 | validation: 0.1062535408198735]
	TIME [epoch: 5.71 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401979277423629		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.12401979277423629 | validation: 0.10384474994350798]
	TIME [epoch: 5.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1057744573307264		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.1057744573307264 | validation: 0.10450763854349301]
	TIME [epoch: 5.72 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10271131545012345		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.10271131545012345 | validation: 0.10531833745836755]
	TIME [epoch: 5.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10352670529346752		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.10352670529346752 | validation: 0.12487397786234793]
	TIME [epoch: 5.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10843290491371987		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.10843290491371987 | validation: 0.13159538033324555]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656692068526693		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.12656692068526693 | validation: 0.12418334525372793]
	TIME [epoch: 5.72 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11132206168253693		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.11132206168253693 | validation: 0.09967391006160053]
	TIME [epoch: 5.71 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341025853982328		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.11341025853982328 | validation: 0.10811791808733702]
	TIME [epoch: 5.71 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795568682830593		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.11795568682830593 | validation: 0.10674404747533921]
	TIME [epoch: 5.72 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10561732978635738		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10561732978635738 | validation: 0.11313636817924458]
	TIME [epoch: 5.72 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638895522402292		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.10638895522402292 | validation: 0.10769097502795717]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12086934270227606		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.12086934270227606 | validation: 0.11408802611532419]
	TIME [epoch: 5.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951219899644227		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.10951219899644227 | validation: 0.1037318950156965]
	TIME [epoch: 5.71 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10535715843036919		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.10535715843036919 | validation: 0.12871019140630197]
	TIME [epoch: 5.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790215314903824		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.11790215314903824 | validation: 0.11713431264138265]
	TIME [epoch: 5.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10514476569846692		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.10514476569846692 | validation: 0.1110603791228305]
	TIME [epoch: 5.75 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898456366727642		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.10898456366727642 | validation: 0.1308207578796909]
	TIME [epoch: 5.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652076142577316		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.10652076142577316 | validation: 0.12148463912771736]
	TIME [epoch: 5.71 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163306792058315		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1163306792058315 | validation: 0.10583721617447933]
	TIME [epoch: 5.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10372396479368269		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.10372396479368269 | validation: 0.1209106256680111]
	TIME [epoch: 5.71 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10703601097152579		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.10703601097152579 | validation: 0.11609168416165322]
	TIME [epoch: 5.71 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024445815610214		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.1024445815610214 | validation: 0.11262891981574685]
	TIME [epoch: 5.73 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369321112430256		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.10369321112430256 | validation: 0.10974770447230953]
	TIME [epoch: 5.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477409289231582		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.10477409289231582 | validation: 0.11979810324495363]
	TIME [epoch: 5.72 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11310876794411195		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.11310876794411195 | validation: 0.10271122503680646]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426513604444292		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.10426513604444292 | validation: 0.09815744406652757]
	TIME [epoch: 5.71 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690527183130057		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.10690527183130057 | validation: 0.10532117049962009]
	TIME [epoch: 5.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621516232741858		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.10621516232741858 | validation: 0.10241998846056002]
	TIME [epoch: 5.72 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403482331812583		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.10403482331812583 | validation: 0.10551477693285528]
	TIME [epoch: 5.75 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204850971326758		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.10204850971326758 | validation: 0.09900590390016648]
	TIME [epoch: 5.72 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706573859470635		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.10706573859470635 | validation: 0.09848642474281302]
	TIME [epoch: 5.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11026451053458244		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.11026451053458244 | validation: 0.10859254119383836]
	TIME [epoch: 5.71 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10475315457999708		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.10475315457999708 | validation: 0.10380137898487486]
	TIME [epoch: 5.71 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10947506312376112		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.10947506312376112 | validation: 0.11054709410633003]
	TIME [epoch: 5.71 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855480431750722		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.10855480431750722 | validation: 0.10462654629408633]
	TIME [epoch: 5.72 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182868642897903		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.1182868642897903 | validation: 0.1128073939768631]
	TIME [epoch: 5.72 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10787859476292125		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.10787859476292125 | validation: 0.10061894700113128]
	TIME [epoch: 5.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084442265595908		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.1084442265595908 | validation: 0.11240687954398791]
	TIME [epoch: 5.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616568922761593		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.10616568922761593 | validation: 0.11650578580277249]
	TIME [epoch: 5.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015518925295097		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.11015518925295097 | validation: 0.1187106096849329]
	TIME [epoch: 5.71 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825533969958768		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.11825533969958768 | validation: 0.11225507107571293]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10897946465630476		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.10897946465630476 | validation: 0.11290335241760645]
	TIME [epoch: 5.75 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562354668916289		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.10562354668916289 | validation: 0.10738763770944797]
	TIME [epoch: 5.71 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866607558687907		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.10866607558687907 | validation: 0.12370085768867893]
	TIME [epoch: 5.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065585487800246		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1065585487800246 | validation: 0.11065931634830452]
	TIME [epoch: 5.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112545822713227		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.1112545822713227 | validation: 0.11369804178270718]
	TIME [epoch: 5.72 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069280495270901		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.11069280495270901 | validation: 0.11755265024866943]
	TIME [epoch: 5.71 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10684589847036864		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10684589847036864 | validation: 0.11052199137167122]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887566210689578		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.10887566210689578 | validation: 0.13363474189689462]
	TIME [epoch: 5.72 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11424659064375829		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.11424659064375829 | validation: 0.1185590758878511]
	TIME [epoch: 5.71 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478579320865808		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.10478579320865808 | validation: 0.11519108485941612]
	TIME [epoch: 5.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793603464548938		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.10793603464548938 | validation: 0.11310702256982336]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10667294375669747		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.10667294375669747 | validation: 0.11893945914601346]
	TIME [epoch: 5.71 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921864520916849		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.10921864520916849 | validation: 0.11499682769751246]
	TIME [epoch: 5.71 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647291086006302		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.10647291086006302 | validation: 0.10956084216236939]
	TIME [epoch: 5.74 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730655505288775		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.10730655505288775 | validation: 0.11200749393473836]
	TIME [epoch: 5.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10496058019175074		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.10496058019175074 | validation: 0.13398162253146295]
	TIME [epoch: 5.71 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354760613322398		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.1354760613322398 | validation: 0.12168943795734782]
	TIME [epoch: 5.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154619128155601		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.1154619128155601 | validation: 0.12218780963717522]
	TIME [epoch: 5.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910697284711827		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.10910697284711827 | validation: 0.11460972345009801]
	TIME [epoch: 5.71 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10958662561030517		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.10958662561030517 | validation: 0.11842402185823621]
	TIME [epoch: 5.72 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087555920661241		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.1087555920661241 | validation: 0.10801193328409665]
	TIME [epoch: 5.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10807430261543713		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.10807430261543713 | validation: 0.1066059036219776]
	TIME [epoch: 5.71 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049672609663514		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.1049672609663514 | validation: 0.10545391082623097]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10617847998432275		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.10617847998432275 | validation: 0.111443479201483]
	TIME [epoch: 5.71 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187430238502008		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.11187430238502008 | validation: 0.11229528227060316]
	TIME [epoch: 5.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261126818919777		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.11261126818919777 | validation: 0.1110980216217713]
	TIME [epoch: 5.71 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299629421489		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.10299629421489 | validation: 0.11055939597233]
	TIME [epoch: 5.74 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060426261033759		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.1060426261033759 | validation: 0.1156301171871982]
	TIME [epoch: 5.71 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246392913459835		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.11246392913459835 | validation: 0.11456390029590868]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261209720713358		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.1261209720713358 | validation: 0.11356379295338456]
	TIME [epoch: 5.71 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887516437294828		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.10887516437294828 | validation: 0.10287465922341171]
	TIME [epoch: 5.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227517648954434		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.10227517648954434 | validation: 0.11251596774778534]
	TIME [epoch: 5.71 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531344493472802		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.10531344493472802 | validation: 0.11058975888359053]
	TIME [epoch: 5.71 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659617317100911		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.10659617317100911 | validation: 0.10661721320444362]
	TIME [epoch: 5.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049470365017241		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.1049470365017241 | validation: 0.10378301393446954]
	TIME [epoch: 5.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10991947041401207		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.10991947041401207 | validation: 0.10887389568516569]
	TIME [epoch: 5.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474681926238763		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.10474681926238763 | validation: 0.10390481331625537]
	TIME [epoch: 5.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10754126467878451		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.10754126467878451 | validation: 0.10675851816959449]
	TIME [epoch: 5.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10781445682733679		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.10781445682733679 | validation: 0.11409210181162319]
	TIME [epoch: 5.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101403269952189		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.1101403269952189 | validation: 0.11266335835365641]
	TIME [epoch: 5.74 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10643277145528575		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.10643277145528575 | validation: 0.10283012827343269]
	TIME [epoch: 5.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10979225197810956		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.10979225197810956 | validation: 0.10279167862466554]
	TIME [epoch: 5.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10538258798722125		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.10538258798722125 | validation: 0.11300053827837488]
	TIME [epoch: 5.71 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508360754172802		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.10508360754172802 | validation: 0.1068690831307693]
	TIME [epoch: 5.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163084386608546		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.11163084386608546 | validation: 0.108044099552833]
	TIME [epoch: 5.69 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10517232236231		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.10517232236231 | validation: 0.11101336991907551]
	TIME [epoch: 5.71 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10157679290929211		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.10157679290929211 | validation: 0.10646839317460874]
	TIME [epoch: 5.72 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216948823858443		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.11216948823858443 | validation: 0.1257610975788279]
	TIME [epoch: 5.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11344410143321736		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.11344410143321736 | validation: 0.1235597143529375]
	TIME [epoch: 5.71 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11327999794655111		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.11327999794655111 | validation: 0.1305830972820651]
	TIME [epoch: 5.71 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950098180428988		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.10950098180428988 | validation: 0.12183897275180605]
	TIME [epoch: 5.71 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061307064462455		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.1061307064462455 | validation: 0.11460189790420866]
	TIME [epoch: 5.71 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062681409837862		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.1062681409837862 | validation: 0.1085964477571854]
	TIME [epoch: 5.73 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10772821617335993		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.10772821617335993 | validation: 0.10563097178132648]
	TIME [epoch: 5.71 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10081946082925995		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.10081946082925995 | validation: 0.11699347638924178]
	TIME [epoch: 5.69 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825802503722902		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.10825802503722902 | validation: 0.10782413189582787]
	TIME [epoch: 5.71 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10389839079156415		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.10389839079156415 | validation: 0.11469147620593423]
	TIME [epoch: 5.69 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241068173044246		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.10241068173044246 | validation: 0.12233221333601128]
	TIME [epoch: 5.71 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11812651848778545		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.11812651848778545 | validation: 0.11951388930572421]
	TIME [epoch: 5.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11373244009296068		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.11373244009296068 | validation: 0.11023955677704964]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11540176053087803		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.11540176053087803 | validation: 0.10157058277044886]
	TIME [epoch: 5.69 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258987036095207		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.10258987036095207 | validation: 0.11126224867554495]
	TIME [epoch: 5.71 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10875156299210542		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.10875156299210542 | validation: 0.09767356529170311]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1290.pth
	Model improved!!!
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058897936376634		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.1058897936376634 | validation: 0.1062484118696972]
	TIME [epoch: 5.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11155002052675786		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.11155002052675786 | validation: 0.10781024490870406]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548346302095465		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.10548346302095465 | validation: 0.10632059336286206]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728262247283618		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.10728262247283618 | validation: 0.10066915337377892]
	TIME [epoch: 5.71 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11280835376136232		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.11280835376136232 | validation: 0.12524845417009647]
	TIME [epoch: 5.71 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10653515979366553		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.10653515979366553 | validation: 0.11192761826525235]
	TIME [epoch: 5.71 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10388120264315952		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.10388120264315952 | validation: 0.10703496787449611]
	TIME [epoch: 5.69 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221112866169633		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.10221112866169633 | validation: 0.10358879975550549]
	TIME [epoch: 5.71 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442491117704095		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10442491117704095 | validation: 0.10451196162336919]
	TIME [epoch: 5.71 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042256965170418		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.1042256965170418 | validation: 0.11468463057749446]
	TIME [epoch: 5.72 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857861167603118		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.10857861167603118 | validation: 0.10696073087667106]
	TIME [epoch: 5.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009211521717908		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.1009211521717908 | validation: 0.1081586412751458]
	TIME [epoch: 5.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10076544501029232		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.10076544501029232 | validation: 0.11175654852683309]
	TIME [epoch: 5.69 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274174553508574		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.11274174553508574 | validation: 0.11844563684413421]
	TIME [epoch: 5.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096699779019165		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.11096699779019165 | validation: 0.1042541068916556]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029422909394943		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.1029422909394943 | validation: 0.11525376842748583]
	TIME [epoch: 5.75 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10673715417220211		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.10673715417220211 | validation: 0.10840990945054156]
	TIME [epoch: 5.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039313251027721		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.1039313251027721 | validation: 0.10684918050364733]
	TIME [epoch: 5.71 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10895190748863959		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.10895190748863959 | validation: 0.10510476151234635]
	TIME [epoch: 5.72 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10643882207373569		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.10643882207373569 | validation: 0.10426657030632004]
	TIME [epoch: 5.72 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10419821490271865		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.10419821490271865 | validation: 0.11654074035077785]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10372979391779134		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.10372979391779134 | validation: 0.10475488658540894]
	TIME [epoch: 5.72 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097182823927564		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.10097182823927564 | validation: 0.10286161619458714]
	TIME [epoch: 5.72 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544813944474161		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.10544813944474161 | validation: 0.10846096184824891]
	TIME [epoch: 5.71 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259105065513285		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.10259105065513285 | validation: 0.11078916060261758]
	TIME [epoch: 5.7 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011091169748498		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.1011091169748498 | validation: 0.10961315063870496]
	TIME [epoch: 5.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10475883417913529		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.10475883417913529 | validation: 0.11210662963333708]
	TIME [epoch: 5.71 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10537423394795045		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.10537423394795045 | validation: 0.11239015284080615]
	TIME [epoch: 5.71 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10530572271843959		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.10530572271843959 | validation: 0.11092467289786892]
	TIME [epoch: 5.75 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071191373652262		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1071191373652262 | validation: 0.11535568657731177]
	TIME [epoch: 5.72 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773923242642962		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.10773923242642962 | validation: 0.10196694489846472]
	TIME [epoch: 5.71 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10468866014400038		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.10468866014400038 | validation: 0.11203124545565948]
	TIME [epoch: 5.71 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005247403426647		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.1005247403426647 | validation: 0.11191388746858894]
	TIME [epoch: 5.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269096078459097		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.10269096078459097 | validation: 0.11107002519117497]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036027167430154		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.1036027167430154 | validation: 0.10837673384614352]
	TIME [epoch: 5.73 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727277572434633		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.10727277572434633 | validation: 0.11617906578214993]
	TIME [epoch: 5.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274667140087129		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.10274667140087129 | validation: 0.11574075070709175]
	TIME [epoch: 5.71 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431615594249355		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.10431615594249355 | validation: 0.10280485683031972]
	TIME [epoch: 5.7 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197730475184486		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.11197730475184486 | validation: 0.121467175031772]
	TIME [epoch: 5.71 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575786032543226		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.10575786032543226 | validation: 0.12502019093879058]
	TIME [epoch: 5.7 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12357894208231936		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.12357894208231936 | validation: 0.1388988419492527]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274168876254273		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.11274168876254273 | validation: 0.10144484393839254]
	TIME [epoch: 5.75 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10885157472390038		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.10885157472390038 | validation: 0.10726288726639098]
	TIME [epoch: 5.71 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795327689473831		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.11795327689473831 | validation: 0.10496239706841497]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113623211135035		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.11113623211135035 | validation: 0.115230442022902]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570079725144258		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.11570079725144258 | validation: 0.10634750944665039]
	TIME [epoch: 5.7 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062046978818699		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.1062046978818699 | validation: 0.10205808123240573]
	TIME [epoch: 5.7 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10634231053953741		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.10634231053953741 | validation: 0.10376442453477915]
	TIME [epoch: 5.73 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072919559066007		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.10072919559066007 | validation: 0.11184821103127232]
	TIME [epoch: 5.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507233174920581		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.10507233174920581 | validation: 0.10255130073267499]
	TIME [epoch: 5.71 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153665429635428		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.10153665429635428 | validation: 0.11054928856369492]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10518326163495302		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.10518326163495302 | validation: 0.1058668985141406]
	TIME [epoch: 5.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1088898553311293		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.1088898553311293 | validation: 0.10964817444119468]
	TIME [epoch: 5.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695826632103077		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.10695826632103077 | validation: 0.11150353505261648]
	TIME [epoch: 5.69 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10550133343908455		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.10550133343908455 | validation: 0.11006260114448031]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004475455787457		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.11004475455787457 | validation: 0.10997949201915137]
	TIME [epoch: 5.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10337593049837375		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.10337593049837375 | validation: 0.11303433464502118]
	TIME [epoch: 5.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431554840571641		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.10431554840571641 | validation: 0.10549003470240638]
	TIME [epoch: 5.71 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097154717015668		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.10097154717015668 | validation: 0.10210143212548634]
	TIME [epoch: 5.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996264739497004		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.09996264739497004 | validation: 0.10693675182841289]
	TIME [epoch: 5.71 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10283511279770496		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.10283511279770496 | validation: 0.11386341249041687]
	TIME [epoch: 5.71 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705149700374714		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.10705149700374714 | validation: 0.12211697130330197]
	TIME [epoch: 5.71 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489689112585404		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.10489689112585404 | validation: 0.11650163122596308]
	TIME [epoch: 5.7 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147751176476176		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.1147751176476176 | validation: 0.12017644968749877]
	TIME [epoch: 5.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686186432046552		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.10686186432046552 | validation: 0.11222756577244301]
	TIME [epoch: 5.69 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469587800033038		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.10469587800033038 | validation: 0.11308520473910853]
	TIME [epoch: 5.71 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562947955948705		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.10562947955948705 | validation: 0.11073186357618404]
	TIME [epoch: 5.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956633577873328		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.09956633577873328 | validation: 0.10794659739592638]
	TIME [epoch: 5.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575438962087447		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.10575438962087447 | validation: 0.10270094463253633]
	TIME [epoch: 5.71 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370025360732484		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.10370025360732484 | validation: 0.10187257749208606]
	TIME [epoch: 5.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556451679625473		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.10556451679625473 | validation: 0.09167854097006141]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1361.pth
	Model improved!!!
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262051281014233		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.10262051281014233 | validation: 0.10888287185771157]
	TIME [epoch: 5.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021022573686236		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.1021022573686236 | validation: 0.1081450100003526]
	TIME [epoch: 5.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357306100905442		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.10357306100905442 | validation: 0.1010127418497473]
	TIME [epoch: 5.71 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489696638607332		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.10489696638607332 | validation: 0.10589694682406708]
	TIME [epoch: 5.73 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302500311576335		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.10302500311576335 | validation: 0.10436946272740326]
	TIME [epoch: 5.71 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241909239627066		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.10241909239627066 | validation: 0.11830332648632315]
	TIME [epoch: 5.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10432818907083613		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.10432818907083613 | validation: 0.10057851819928304]
	TIME [epoch: 5.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544654416208839		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.10544654416208839 | validation: 0.1161517609278476]
	TIME [epoch: 5.71 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10518761098453014		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.10518761098453014 | validation: 0.10916617192382692]
	TIME [epoch: 5.71 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628862185439723		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.10628862185439723 | validation: 0.10973062099053024]
	TIME [epoch: 5.74 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10492413722916316		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.10492413722916316 | validation: 0.11680274857389897]
	TIME [epoch: 5.71 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10348860573761315		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.10348860573761315 | validation: 0.10488921871335997]
	TIME [epoch: 5.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10765956813202068		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.10765956813202068 | validation: 0.1121560496879512]
	TIME [epoch: 5.71 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11173673385939346		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.11173673385939346 | validation: 0.12484176684780657]
	TIME [epoch: 5.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114312201768545		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.1114312201768545 | validation: 0.10841705983810623]
	TIME [epoch: 5.71 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10597371679911913		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.10597371679911913 | validation: 0.09739321893576346]
	TIME [epoch: 5.71 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629833198408559		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.10629833198408559 | validation: 0.10975967833869894]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581370063612935		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.10581370063612935 | validation: 0.10086271263488555]
	TIME [epoch: 5.71 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11215717021563001		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.11215717021563001 | validation: 0.11870104700113046]
	TIME [epoch: 5.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511812982521945		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.11511812982521945 | validation: 0.10919834206188543]
	TIME [epoch: 5.71 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070942053762208		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.1070942053762208 | validation: 0.10412559140361548]
	TIME [epoch: 5.71 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10273802145257327		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.10273802145257327 | validation: 0.09643583092552255]
	TIME [epoch: 5.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329466443353871		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.10329466443353871 | validation: 0.10022527492380434]
	TIME [epoch: 5.75 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10733415211033864		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.10733415211033864 | validation: 0.10688552468135548]
	TIME [epoch: 5.72 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10914832476608657		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.10914832476608657 | validation: 0.10973578215468312]
	TIME [epoch: 5.71 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11128142832076793		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.11128142832076793 | validation: 0.11117879279687863]
	TIME [epoch: 5.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10978779634101166		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.10978779634101166 | validation: 0.11844688282636008]
	TIME [epoch: 5.71 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12479870562060409		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.12479870562060409 | validation: 0.11786978511226025]
	TIME [epoch: 5.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11254725286285841		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.11254725286285841 | validation: 0.12817541086479586]
	TIME [epoch: 5.71 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12236193900495479		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.12236193900495479 | validation: 0.1188207972158591]
	TIME [epoch: 5.74 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11839910226651071		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.11839910226651071 | validation: 0.11685045256432605]
	TIME [epoch: 5.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019061278743631		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.1019061278743631 | validation: 0.1110538253708462]
	TIME [epoch: 5.71 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041732260207399		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.10041732260207399 | validation: 0.1210634764087712]
	TIME [epoch: 5.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294094144589903		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.11294094144589903 | validation: 0.10462308470841956]
	TIME [epoch: 5.71 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10253437086599508		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.10253437086599508 | validation: 0.10518598893959084]
	TIME [epoch: 5.71 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10074305610549442		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.10074305610549442 | validation: 0.10828495735359474]
	TIME [epoch: 5.74 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1048419058975899		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.1048419058975899 | validation: 0.11305402181309476]
	TIME [epoch: 5.72 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218549089029957		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.11218549089029957 | validation: 0.11353664403678874]
	TIME [epoch: 5.71 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736458785597766		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.10736458785597766 | validation: 0.10202628487548614]
	TIME [epoch: 5.71 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020586119890169		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.1020586119890169 | validation: 0.09717577895719817]
	TIME [epoch: 5.7 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379058413547212		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.10379058413547212 | validation: 0.10083139819145]
	TIME [epoch: 5.71 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10774990699412636		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.10774990699412636 | validation: 0.11202099840592313]
	TIME [epoch: 5.72 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10242377954671086		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.10242377954671086 | validation: 0.10679222677137261]
	TIME [epoch: 5.72 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1041567495746143		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.1041567495746143 | validation: 0.10462190104995117]
	TIME [epoch: 5.7 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10279589063933978		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.10279589063933978 | validation: 0.10592792321564379]
	TIME [epoch: 5.69 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10138394274242128		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.10138394274242128 | validation: 0.10531872417895885]
	TIME [epoch: 5.71 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10321507715929504		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.10321507715929504 | validation: 0.0928218318355685]
	TIME [epoch: 5.71 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10218881994859952		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.10218881994859952 | validation: 0.10512871093438779]
	TIME [epoch: 5.7 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09873452306865528		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.09873452306865528 | validation: 0.10748121278562056]
	TIME [epoch: 5.74 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10327042444418062		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.10327042444418062 | validation: 0.10494046110134138]
	TIME [epoch: 5.71 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10779140166737239		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.10779140166737239 | validation: 0.10543943483011113]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347953824304139		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.10347953824304139 | validation: 0.1110890823841986]
	TIME [epoch: 5.7 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11419591059251898		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.11419591059251898 | validation: 0.11369883579040796]
	TIME [epoch: 5.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11023120455165482		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.11023120455165482 | validation: 0.10719747354229554]
	TIME [epoch: 5.71 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290988345456059		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.10290988345456059 | validation: 0.10312880806253646]
	TIME [epoch: 5.71 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10577668647780995		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.10577668647780995 | validation: 0.10316625824869767]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127329704587934		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.10127329704587934 | validation: 0.10167232362058]
	TIME [epoch: 5.71 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874856510379149		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.09874856510379149 | validation: 0.10481239528997872]
	TIME [epoch: 5.71 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490120968359508		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.10490120968359508 | validation: 0.0969927444138653]
	TIME [epoch: 5.71 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350002169776273		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.10350002169776273 | validation: 0.1078429009862618]
	TIME [epoch: 5.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10516070583769832		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.10516070583769832 | validation: 0.10808240938617207]
	TIME [epoch: 5.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702661493543024		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.10702661493543024 | validation: 0.10831869434321321]
	TIME [epoch: 5.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584755229308973		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.10584755229308973 | validation: 0.110272595414791]
	TIME [epoch: 5.72 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024900123514674		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.10024900123514674 | validation: 0.11391153768799449]
	TIME [epoch: 5.71 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608336785641329		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.10608336785641329 | validation: 0.10937448518221451]
	TIME [epoch: 5.7 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992072591156459		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.09992072591156459 | validation: 0.10866731845587033]
	TIME [epoch: 5.71 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10537590120571333		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.10537590120571333 | validation: 0.10049210672560882]
	TIME [epoch: 5.7 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10594360954351054		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.10594360954351054 | validation: 0.10047519981390206]
	TIME [epoch: 5.71 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036020901014303		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.1036020901014303 | validation: 0.10848708859311845]
	TIME [epoch: 5.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10483663613730106		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.10483663613730106 | validation: 0.10570727078519226]
	TIME [epoch: 5.71 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198105120928477		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.11198105120928477 | validation: 0.11807752456404046]
	TIME [epoch: 5.7 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11472726811502001		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.11472726811502001 | validation: 0.1180092678506709]
	TIME [epoch: 5.7 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11677982557291446		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.11677982557291446 | validation: 0.11898316751250786]
	TIME [epoch: 5.7 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718029077983073		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.12718029077983073 | validation: 0.117311902725452]
	TIME [epoch: 5.71 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285793747765993		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.11285793747765993 | validation: 0.10601476748195474]
	TIME [epoch: 5.73 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10437607203277458		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.10437607203277458 | validation: 0.11191172327908643]
	TIME [epoch: 5.71 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1046536543352302		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.1046536543352302 | validation: 0.11358423964371887]
	TIME [epoch: 5.69 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10511123937806863		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.10511123937806863 | validation: 0.10634716417345505]
	TIME [epoch: 5.71 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10387285955491632		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.10387285955491632 | validation: 0.10417083129133602]
	TIME [epoch: 5.7 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10618109894148085		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.10618109894148085 | validation: 0.10624023470138207]
	TIME [epoch: 5.71 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10306398350184305		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.10306398350184305 | validation: 0.10624512259060914]
	TIME [epoch: 5.71 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10328080057339367		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.10328080057339367 | validation: 0.1068924383532003]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077363783467912		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.1077363783467912 | validation: 0.1120665631703924]
	TIME [epoch: 5.71 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016286122947016		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.10016286122947016 | validation: 0.10450871289830162]
	TIME [epoch: 5.71 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10124864601453792		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.10124864601453792 | validation: 0.10902563760108148]
	TIME [epoch: 5.71 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509325139552425		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.10509325139552425 | validation: 0.09652811342570679]
	TIME [epoch: 5.7 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038600683479442		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.1038600683479442 | validation: 0.10499719984821823]
	TIME [epoch: 5.7 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030576476410843		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.10030576476410843 | validation: 0.11005766806211882]
	TIME [epoch: 5.74 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10634155204367775		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.10634155204367775 | validation: 0.10933794598835755]
	TIME [epoch: 5.72 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113601718391316		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.1113601718391316 | validation: 0.10709579179504428]
	TIME [epoch: 5.71 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567812839902523		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.10567812839902523 | validation: 0.10288888861861979]
	TIME [epoch: 5.71 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167141745336761		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.10167141745336761 | validation: 0.10815767675518828]
	TIME [epoch: 5.71 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10096314814861136		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.10096314814861136 | validation: 0.11424337801641665]
	TIME [epoch: 5.71 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107771876430219		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.10107771876430219 | validation: 0.10352133492390066]
	TIME [epoch: 5.72 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078138177267101		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.10078138177267101 | validation: 0.10685851813468014]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011748940000259		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.10011748940000259 | validation: 0.10246822923873]
	TIME [epoch: 5.71 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111620116415253		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.10111620116415253 | validation: 0.10802385849118082]
	TIME [epoch: 5.71 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384262170958787		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.10384262170958787 | validation: 0.10627003105528005]
	TIME [epoch: 5.7 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890674435731998		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.10890674435731998 | validation: 0.10250822203025632]
	TIME [epoch: 5.71 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10708814047294014		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.10708814047294014 | validation: 0.09444998062486341]
	TIME [epoch: 5.71 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556331160701399		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.10556331160701399 | validation: 0.10492684159942173]
	TIME [epoch: 5.75 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347199313930402		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.10347199313930402 | validation: 0.10779529714440696]
	TIME [epoch: 5.7 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507043488226932		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.10507043488226932 | validation: 0.11223028169664687]
	TIME [epoch: 5.7 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10924096684746758		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.10924096684746758 | validation: 0.10739114388185143]
	TIME [epoch: 5.71 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10822620967109885		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.10822620967109885 | validation: 0.11748289044440018]
	TIME [epoch: 5.71 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105488003299596		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.1105488003299596 | validation: 0.11157478340299434]
	TIME [epoch: 5.7 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10609340927720456		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.10609340927720456 | validation: 0.10892481270437657]
	TIME [epoch: 5.72 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854667697351858		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.10854667697351858 | validation: 0.10156940604003595]
	TIME [epoch: 5.73 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103395132149643		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.103395132149643 | validation: 0.11560837956225647]
	TIME [epoch: 5.71 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529485408553843		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.10529485408553843 | validation: 0.1096164272770179]
	TIME [epoch: 5.71 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982609764228526		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.09982609764228526 | validation: 0.1125890410966915]
	TIME [epoch: 5.69 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131026798515606		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.11131026798515606 | validation: 0.11026110088861915]
	TIME [epoch: 5.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363535073941758		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.10363535073941758 | validation: 0.10160959266089614]
	TIME [epoch: 5.7 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221058671383942		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.10221058671383942 | validation: 0.11192314055767291]
	TIME [epoch: 5.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10304414545441405		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.10304414545441405 | validation: 0.10679236304579189]
	TIME [epoch: 5.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052967206288652		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.10052967206288652 | validation: 0.11750834404975452]
	TIME [epoch: 5.7 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474243773790226		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.10474243773790226 | validation: 0.11210823936982837]
	TIME [epoch: 5.7 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10990464051629142		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.10990464051629142 | validation: 0.11513288910280753]
	TIME [epoch: 5.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10213488789540034		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.10213488789540034 | validation: 0.10508328567622113]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10361939410134241		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.10361939410134241 | validation: 0.11072845280570767]
	TIME [epoch: 5.71 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1068441925370072		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.1068441925370072 | validation: 0.1122412929018115]
	TIME [epoch: 5.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10667973232927108		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.10667973232927108 | validation: 0.113048960572584]
	TIME [epoch: 5.71 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10201311278881402		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.10201311278881402 | validation: 0.10880326821344888]
	TIME [epoch: 5.7 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10324299150395508		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.10324299150395508 | validation: 0.10753684844020106]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495225901779456		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.10495225901779456 | validation: 0.10736933867967252]
	TIME [epoch: 5.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10447270243852375		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.10447270243852375 | validation: 0.10799999136727298]
	TIME [epoch: 5.72 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400976691580037		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.10400976691580037 | validation: 0.10794684588126463]
	TIME [epoch: 5.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10610925700736756		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.10610925700736756 | validation: 0.09980482065071083]
	TIME [epoch: 5.71 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293449381785028		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.10293449381785028 | validation: 0.10676830380251685]
	TIME [epoch: 5.7 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10387986883194024		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.10387986883194024 | validation: 0.10153915652305663]
	TIME [epoch: 5.7 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079009055764737		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1079009055764737 | validation: 0.10733721023588269]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148115735002305		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.10148115735002305 | validation: 0.09519813032091883]
	TIME [epoch: 5.7 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292613433647897		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.10292613433647897 | validation: 0.10636169691129459]
	TIME [epoch: 5.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573734655408995		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.10573734655408995 | validation: 0.11155766487841179]
	TIME [epoch: 5.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008375754909881		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.1008375754909881 | validation: 0.10730046626756995]
	TIME [epoch: 5.7 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653487026100979		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.09653487026100979 | validation: 0.11477582226932011]
	TIME [epoch: 5.7 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038060815788597		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.1038060815788597 | validation: 0.10621186623958398]
	TIME [epoch: 5.7 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10606689071139784		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.10606689071139784 | validation: 0.10347064335204884]
	TIME [epoch: 5.71 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069806737889724		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.10069806737889724 | validation: 0.10427570811596173]
	TIME [epoch: 5.69 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024052906693635		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.10024052906693635 | validation: 0.09826204794724759]
	TIME [epoch: 5.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070510822173631		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.10070510822173631 | validation: 0.117394012953486]
	TIME [epoch: 5.7 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10421999466598819		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.10421999466598819 | validation: 0.11088506148771121]
	TIME [epoch: 5.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09895355114408806		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09895355114408806 | validation: 0.10454092621400624]
	TIME [epoch: 5.7 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063804215049219		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.10063804215049219 | validation: 0.10142707325506894]
	TIME [epoch: 5.7 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10292968267163967		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.10292968267163967 | validation: 0.11189394815310542]
	TIME [epoch: 5.7 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462914183888862		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.10462914183888862 | validation: 0.10483204436874045]
	TIME [epoch: 5.71 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10838630205538148		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.10838630205538148 | validation: 0.10470642441095336]
	TIME [epoch: 5.72 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317597270420965		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.10317597270420965 | validation: 0.10816991447292931]
	TIME [epoch: 5.71 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329453507264641		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.10329453507264641 | validation: 0.10456966687485812]
	TIME [epoch: 5.7 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344160693169654		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.10344160693169654 | validation: 0.10359791697908691]
	TIME [epoch: 5.7 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248838838627183		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.10248838838627183 | validation: 0.09973270678361272]
	TIME [epoch: 5.7 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10589201127257536		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.10589201127257536 | validation: 0.10677668664807236]
	TIME [epoch: 5.7 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0997148966290042		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.0997148966290042 | validation: 0.11469801034976884]
	TIME [epoch: 5.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100792369389268		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.100792369389268 | validation: 0.10472613313994547]
	TIME [epoch: 5.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403853697398502		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.10403853697398502 | validation: 0.11519451813225937]
	TIME [epoch: 5.7 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10373217094396839		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.10373217094396839 | validation: 0.10865188370993928]
	TIME [epoch: 5.71 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660098354266392		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.10660098354266392 | validation: 0.12072610551208125]
	TIME [epoch: 5.7 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195255555080715		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.10195255555080715 | validation: 0.10862799702170885]
	TIME [epoch: 5.71 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543972229404855		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.10543972229404855 | validation: 0.10396274054293007]
	TIME [epoch: 5.71 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857905489344098		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.10857905489344098 | validation: 0.1084188693354018]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10405135065193846		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.10405135065193846 | validation: 0.11187634975279272]
	TIME [epoch: 5.7 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10784170472697953		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.10784170472697953 | validation: 0.11080726715918729]
	TIME [epoch: 5.71 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183509996699616		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.10183509996699616 | validation: 0.11208275695015857]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09946715524104621		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.09946715524104621 | validation: 0.10767897109526951]
	TIME [epoch: 5.7 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10026812599495472		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.10026812599495472 | validation: 0.11277664306574661]
	TIME [epoch: 5.7 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101517699365888		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.101517699365888 | validation: 0.11188865705182029]
	TIME [epoch: 5.75 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09989686528431052		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.09989686528431052 | validation: 0.09924233522825103]
	TIME [epoch: 5.71 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433132973166287		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.10433132973166287 | validation: 0.11001420343376189]
	TIME [epoch: 5.7 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291181983110745		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.10291181983110745 | validation: 0.10665391333558955]
	TIME [epoch: 5.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055390582470794		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.10055390582470794 | validation: 0.10487096292170225]
	TIME [epoch: 5.7 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10436102328276972		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.10436102328276972 | validation: 0.10082927204379771]
	TIME [epoch: 5.7 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10099040852906951		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.10099040852906951 | validation: 0.09947639945513802]
	TIME [epoch: 5.71 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10398658823251657		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.10398658823251657 | validation: 0.11070502821675163]
	TIME [epoch: 5.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066813643000447		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.1066813643000447 | validation: 0.11633569242419825]
	TIME [epoch: 5.7 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168529887167102		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.11168529887167102 | validation: 0.09870599447479986]
	TIME [epoch: 5.71 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542918593171209		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.10542918593171209 | validation: 0.10379552732724812]
	TIME [epoch: 5.71 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044029328109837		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.10044029328109837 | validation: 0.11304025787616422]
	TIME [epoch: 5.7 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984182608114434		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.09984182608114434 | validation: 0.1065616980775673]
	TIME [epoch: 5.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114570207634907		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.10114570207634907 | validation: 0.11572504913919947]
	TIME [epoch: 5.75 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10463596396014033		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.10463596396014033 | validation: 0.10441413158214861]
	TIME [epoch: 5.71 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878802785060853		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09878802785060853 | validation: 0.10500581895072976]
	TIME [epoch: 5.7 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855353927197866		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.09855353927197866 | validation: 0.10329323886665506]
	TIME [epoch: 5.71 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10284641436668951		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.10284641436668951 | validation: 0.10947696046790213]
	TIME [epoch: 5.71 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176141041742277		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.10176141041742277 | validation: 0.10569501197777782]
	TIME [epoch: 5.7 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10371050090811702		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.10371050090811702 | validation: 0.10957680063223457]
	TIME [epoch: 5.72 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095340310227718		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.1095340310227718 | validation: 0.11447075619620697]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486610127772793		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.10486610127772793 | validation: 0.10043249681061286]
	TIME [epoch: 5.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548876546800148		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.10548876546800148 | validation: 0.10180623304341875]
	TIME [epoch: 5.71 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833285962815559		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.10833285962815559 | validation: 0.11286883066223276]
	TIME [epoch: 5.7 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101125760733914		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.101125760733914 | validation: 0.10340370678725012]
	TIME [epoch: 5.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10084296939132875		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.10084296939132875 | validation: 0.0978990351952702]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029498757086344		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.1029498757086344 | validation: 0.10444521242041965]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10467072421249424		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.10467072421249424 | validation: 0.10514544783387812]
	TIME [epoch: 5.71 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008068130077324		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1008068130077324 | validation: 0.10073832405614834]
	TIME [epoch: 5.7 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10154710369441045		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.10154710369441045 | validation: 0.10358272631900714]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109681890421042		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.10109681890421042 | validation: 0.10686567005937331]
	TIME [epoch: 5.69 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10268173301240834		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.10268173301240834 | validation: 0.1070605389834254]
	TIME [epoch: 5.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023669850283214		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.1023669850283214 | validation: 0.09914215014162783]
	TIME [epoch: 5.71 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09737318488849098		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.09737318488849098 | validation: 0.11193968802359541]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299953079695563		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.10299953079695563 | validation: 0.1028010980226104]
	TIME [epoch: 5.7 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247799196592201		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.10247799196592201 | validation: 0.11372787050048441]
	TIME [epoch: 5.7 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10346069914053552		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.10346069914053552 | validation: 0.10366178411459466]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342150208829107		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.10342150208829107 | validation: 0.1101945551268147]
	TIME [epoch: 5.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833004807082783		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.10833004807082783 | validation: 0.10161354241973915]
	TIME [epoch: 5.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092847872508244		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.10092847872508244 | validation: 0.1067039584761529]
	TIME [epoch: 5.75 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364296379888986		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.10364296379888986 | validation: 0.10653939027528957]
	TIME [epoch: 5.7 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316512144927903		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.10316512144927903 | validation: 0.10063571265306155]
	TIME [epoch: 5.7 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314377310808516		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.10314377310808516 | validation: 0.10121305103652879]
	TIME [epoch: 5.7 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460205783862468		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.10460205783862468 | validation: 0.11978704686815121]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685526232575082		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.10685526232575082 | validation: 0.10657357669879967]
	TIME [epoch: 5.7 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10703170290356606		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.10703170290356606 | validation: 0.11103443822546137]
	TIME [epoch: 5.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350556143538464		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.10350556143538464 | validation: 0.10927439153596939]
	TIME [epoch: 5.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10402043737988986		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.10402043737988986 | validation: 0.10519952552423079]
	TIME [epoch: 5.71 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223725867504158		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.10223725867504158 | validation: 0.11293808042356325]
	TIME [epoch: 5.71 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10064452320797002		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.10064452320797002 | validation: 0.10703652897628736]
	TIME [epoch: 5.7 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638879545280283		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.10638879545280283 | validation: 0.10454384433759181]
	TIME [epoch: 5.71 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034335489899612		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.10034335489899612 | validation: 0.10927977525317097]
	TIME [epoch: 5.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10250574852913054		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.10250574852913054 | validation: 0.10112068843741734]
	TIME [epoch: 5.75 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09895477268544678		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.09895477268544678 | validation: 0.11417989616446765]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10382401137396396		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.10382401137396396 | validation: 0.10680106917128832]
	TIME [epoch: 5.7 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052920371917848		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.10052920371917848 | validation: 0.0961237938494389]
	TIME [epoch: 5.7 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211246556055627		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.10211246556055627 | validation: 0.11153929326563365]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10137553377830566		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.10137553377830566 | validation: 0.10896988344894147]
	TIME [epoch: 5.71 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435194107403062		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.10435194107403062 | validation: 0.10931229457327359]
	TIME [epoch: 5.73 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016647525931097		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.10016647525931097 | validation: 0.10856166696676978]
	TIME [epoch: 5.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10189042737305198		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.10189042737305198 | validation: 0.0965202069902606]
	TIME [epoch: 5.71 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10547278604279356		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.10547278604279356 | validation: 0.10547429085272902]
	TIME [epoch: 5.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10495087808299201		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.10495087808299201 | validation: 0.10584212453692025]
	TIME [epoch: 5.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073599086491865		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.1073599086491865 | validation: 0.11331140177552489]
	TIME [epoch: 5.71 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11317441236393327		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.11317441236393327 | validation: 0.11542906120548473]
	TIME [epoch: 5.7 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568599700652634		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.10568599700652634 | validation: 0.10889626668698249]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214996179449654		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.10214996179449654 | validation: 0.10165095929158462]
	TIME [epoch: 5.7 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09995297574465538		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.09995297574465538 | validation: 0.10088513085923072]
	TIME [epoch: 5.71 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102248339934784		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.102248339934784 | validation: 0.10352017599549161]
	TIME [epoch: 5.71 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10418213673581364		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.10418213673581364 | validation: 0.10178534177942672]
	TIME [epoch: 5.69 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624442421113336		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.10624442421113336 | validation: 0.10728349185231999]
	TIME [epoch: 5.71 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009861612495535		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.1009861612495535 | validation: 0.1051778328972054]
	TIME [epoch: 5.72 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10174606456279944		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.10174606456279944 | validation: 0.10133070032578974]
	TIME [epoch: 5.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145083420768673		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.10145083420768673 | validation: 0.09479607050466644]
	TIME [epoch: 5.69 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024939649988735		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.1024939649988735 | validation: 0.09976366998456905]
	TIME [epoch: 5.7 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369499936215701		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.10369499936215701 | validation: 0.0961145848667393]
	TIME [epoch: 5.71 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097771648526806		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.10097771648526806 | validation: 0.10496169178000304]
	TIME [epoch: 5.71 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277521677346221		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.10277521677346221 | validation: 0.09494036254584617]
	TIME [epoch: 5.7 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139417460495746		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.10139417460495746 | validation: 0.10056476948567816]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10634834264622339		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.10634834264622339 | validation: 0.10011197036532035]
	TIME [epoch: 5.7 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624298615872611		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.10624298615872611 | validation: 0.09968439759742097]
	TIME [epoch: 5.71 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017616139276357		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.11017616139276357 | validation: 0.09998092866041218]
	TIME [epoch: 5.71 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900691410295564		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.10900691410295564 | validation: 0.09782194839330678]
	TIME [epoch: 5.7 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10166702204754899		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.10166702204754899 | validation: 0.10301594310529151]
	TIME [epoch: 5.7 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10377057316908023		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.10377057316908023 | validation: 0.10009560003447195]
	TIME [epoch: 5.72 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10229599544344699		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.10229599544344699 | validation: 0.10433766594392753]
	TIME [epoch: 5.72 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747995616035429		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.10747995616035429 | validation: 0.11143161842315757]
	TIME [epoch: 5.7 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103638183919444		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.103638183919444 | validation: 0.11048544307102917]
	TIME [epoch: 5.7 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322121586734662		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.10322121586734662 | validation: 0.10974719342627448]
	TIME [epoch: 5.71 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104546961058996		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.104546961058996 | validation: 0.10633870671453276]
	TIME [epoch: 5.7 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993982188050744		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.09993982188050744 | validation: 0.1053842496858248]
	TIME [epoch: 5.7 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089084988385207		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.10089084988385207 | validation: 0.09940143280052506]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10402141880616211		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.10402141880616211 | validation: 0.10154826678960331]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173912702620526		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.10173912702620526 | validation: 0.09601086886583655]
	TIME [epoch: 5.7 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964880881920242		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.09964880881920242 | validation: 0.10688604800823527]
	TIME [epoch: 5.7 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002904414086171		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.1002904414086171 | validation: 0.09783986606036518]
	TIME [epoch: 5.7 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10440661024817885		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.10440661024817885 | validation: 0.10356100411320578]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332225136594442		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.10332225136594442 | validation: 0.09638102109682432]
	TIME [epoch: 5.72 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10684192090985575		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.10684192090985575 | validation: 0.10527398231169341]
	TIME [epoch: 5.72 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.101190948115671		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.101190948115671 | validation: 0.09931869807409331]
	TIME [epoch: 5.71 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294625231227711		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.10294625231227711 | validation: 0.11789691392458262]
	TIME [epoch: 5.71 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10132365193191195		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.10132365193191195 | validation: 0.10552738875407006]
	TIME [epoch: 5.7 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323363601397376		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.10323363601397376 | validation: 0.10925371271837878]
	TIME [epoch: 5.7 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256760489447313		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.10256760489447313 | validation: 0.10498110356714911]
	TIME [epoch: 5.69 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917674655073452		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.09917674655073452 | validation: 0.1107947712135039]
	TIME [epoch: 5.74 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019983928258024		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.10019983928258024 | validation: 0.10727653133151761]
	TIME [epoch: 5.7 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10201244788498975		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.10201244788498975 | validation: 0.1057802220965088]
	TIME [epoch: 5.7 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153305503473734		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.10153305503473734 | validation: 0.10774001913971368]
	TIME [epoch: 5.7 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10315586599216195		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.10315586599216195 | validation: 0.09928822790884574]
	TIME [epoch: 5.7 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09971857496061426		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.09971857496061426 | validation: 0.1016797909567567]
	TIME [epoch: 5.71 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011509365133119		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.1011509365133119 | validation: 0.10517385114913168]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10169963539783526		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.10169963539783526 | validation: 0.104950533597154]
	TIME [epoch: 5.72 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10366011360370474		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.10366011360370474 | validation: 0.10814639647136376]
	TIME [epoch: 5.7 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336847803743665		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.10336847803743665 | validation: 0.10484154213714597]
	TIME [epoch: 5.7 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011302149038166		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.10011302149038166 | validation: 0.1102937653274838]
	TIME [epoch: 5.69 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258678115486106		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.10258678115486106 | validation: 0.1039944676325986]
	TIME [epoch: 5.7 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912486137617038		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.09912486137617038 | validation: 0.0947784344988771]
	TIME [epoch: 5.71 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981730429510946		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.09981730429510946 | validation: 0.1043200589002097]
	TIME [epoch: 5.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09707968248411897		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.09707968248411897 | validation: 0.09718869858051847]
	TIME [epoch: 5.7 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079007052661317		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.10079007052661317 | validation: 0.10781127080384227]
	TIME [epoch: 5.7 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381856851366036		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.10381856851366036 | validation: 0.10647098562907419]
	TIME [epoch: 5.7 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10217307060860377		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.10217307060860377 | validation: 0.11038228584255987]
	TIME [epoch: 5.71 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09930405188769495		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.09930405188769495 | validation: 0.10239129329436006]
	TIME [epoch: 5.7 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145408346621965		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.10145408346621965 | validation: 0.10657004608912576]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793956983975484		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.09793956983975484 | validation: 0.10771452812146923]
	TIME [epoch: 5.72 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131235226344029		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.10131235226344029 | validation: 0.11029511915020995]
	TIME [epoch: 5.7 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261258804624826		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.10261258804624826 | validation: 0.10336038372229026]
	TIME [epoch: 5.71 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09883954920245736		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.09883954920245736 | validation: 0.11014111011869293]
	TIME [epoch: 5.71 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039785474585637		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.10039785474585637 | validation: 0.10706265423436792]
	TIME [epoch: 5.7 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115248997412651		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.10115248997412651 | validation: 0.10444934184768677]
	TIME [epoch: 5.7 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207263293774832		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.10207263293774832 | validation: 0.10832192525673712]
	TIME [epoch: 5.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09902799454649441		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.09902799454649441 | validation: 0.09598983455386922]
	TIME [epoch: 5.69 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679654276486727		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.09679654276486727 | validation: 0.1030598300513597]
	TIME [epoch: 5.69 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909713111222258		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.09909713111222258 | validation: 0.10513460632171252]
	TIME [epoch: 5.69 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917681000962733		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.09917681000962733 | validation: 0.10941802048032408]
	TIME [epoch: 5.7 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882783336499158		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.09882783336499158 | validation: 0.09555813299603357]
	TIME [epoch: 5.7 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10007282776453282		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.10007282776453282 | validation: 0.10579419594911116]
	TIME [epoch: 5.72 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329600422060375		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.10329600422060375 | validation: 0.09871608842280502]
	TIME [epoch: 5.72 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09979499318592547		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.09979499318592547 | validation: 0.099528404208835]
	TIME [epoch: 5.7 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117619098471564		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.10117619098471564 | validation: 0.11325950514439317]
	TIME [epoch: 5.7 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290731219079759		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.10290731219079759 | validation: 0.10348768055004252]
	TIME [epoch: 5.7 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783207675318713		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.09783207675318713 | validation: 0.10072524677788541]
	TIME [epoch: 5.7 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296296790681345		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.10296296790681345 | validation: 0.09821000508072984]
	TIME [epoch: 5.7 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050578953059347		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.10050578953059347 | validation: 0.09998117389120893]
	TIME [epoch: 5.74 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09957093749389309		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.09957093749389309 | validation: 0.09917047475451404]
	TIME [epoch: 5.7 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844657769138787		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.09844657769138787 | validation: 0.10091585565910888]
	TIME [epoch: 5.71 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226712137057764		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.10226712137057764 | validation: 0.095020152656856]
	TIME [epoch: 5.7 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10140008233334934		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.10140008233334934 | validation: 0.10351510528003141]
	TIME [epoch: 5.7 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376193279115617		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.10376193279115617 | validation: 0.10157438945034769]
	TIME [epoch: 5.7 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1028141780308312		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.1028141780308312 | validation: 0.10383805729638222]
	TIME [epoch: 5.72 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439944856953633		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.10439944856953633 | validation: 0.10172831792692129]
	TIME [epoch: 5.72 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112465485951164		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.10112465485951164 | validation: 0.09725008172651022]
	TIME [epoch: 5.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900729275857637		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.09900729275857637 | validation: 0.10036713727984928]
	TIME [epoch: 5.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305972480462633		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.10305972480462633 | validation: 0.10964224607344282]
	TIME [epoch: 5.7 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008948818061169		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.1008948818061169 | validation: 0.10791250247826663]
	TIME [epoch: 5.7 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203066283978494		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.10203066283978494 | validation: 0.10962993374179857]
	TIME [epoch: 5.7 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754640685003865		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.09754640685003865 | validation: 0.10117134619415814]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867522472185274		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.09867522472185274 | validation: 0.10241951038302478]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775637189530995		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.09775637189530995 | validation: 0.10061948610789039]
	TIME [epoch: 5.7 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710259525384429		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.09710259525384429 | validation: 0.10856978534650029]
	TIME [epoch: 5.7 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10371575881848341		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.10371575881848341 | validation: 0.10379929904789963]
	TIME [epoch: 5.7 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867564118707911		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.09867564118707911 | validation: 0.1015368945766272]
	TIME [epoch: 5.7 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037624199801329		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.10037624199801329 | validation: 0.10025330237301067]
	TIME [epoch: 5.72 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09929050084999255		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.09929050084999255 | validation: 0.0948038987335703]
	TIME [epoch: 5.72 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752386971265659		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.09752386971265659 | validation: 0.09877420951106208]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09949320215738594		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.09949320215738594 | validation: 0.1011614873362145]
	TIME [epoch: 5.69 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439333597613593		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.10439333597613593 | validation: 0.10689795493301386]
	TIME [epoch: 5.7 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255210225432859		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.10255210225432859 | validation: 0.10004601355432176]
	TIME [epoch: 5.69 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336432910523619		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.10336432910523619 | validation: 0.09832213189376557]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874404944521603		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.09874404944521603 | validation: 0.10228908393331917]
	TIME [epoch: 5.74 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987264997753317		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.0987264997753317 | validation: 0.09751758252953703]
	TIME [epoch: 5.7 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10021803713713182		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.10021803713713182 | validation: 0.09817774712482663]
	TIME [epoch: 5.7 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116754246478137		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.10116754246478137 | validation: 0.10281074862706803]
	TIME [epoch: 5.69 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905910518522418		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.09905910518522418 | validation: 0.10198624856202694]
	TIME [epoch: 5.7 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002955132053248		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.10002955132053248 | validation: 0.09644010771798024]
	TIME [epoch: 5.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892135807825449		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.09892135807825449 | validation: 0.10634206531505068]
	TIME [epoch: 5.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09814759819252913		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.09814759819252913 | validation: 0.1092594349290551]
	TIME [epoch: 5.71 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090737121674473		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.10090737121674473 | validation: 0.10368523144849884]
	TIME [epoch: 5.71 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10622250243387156		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.10622250243387156 | validation: 0.10335001626206959]
	TIME [epoch: 5.7 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10552817644512838		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.10552817644512838 | validation: 0.11043828135618608]
	TIME [epoch: 5.71 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018512305235384		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.1018512305235384 | validation: 0.10765074334335875]
	TIME [epoch: 5.7 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310935349548678		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.10310935349548678 | validation: 0.10022260106389133]
	TIME [epoch: 5.7 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411168418215891		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.10411168418215891 | validation: 0.10578113651435478]
	TIME [epoch: 5.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993219745739535		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.0993219745739535 | validation: 0.1075980920011709]
	TIME [epoch: 5.7 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164471340243122		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.10164471340243122 | validation: 0.10422443272259095]
	TIME [epoch: 5.71 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006617216231088		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.1006617216231088 | validation: 0.10366698836849203]
	TIME [epoch: 5.71 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10147217564386099		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.10147217564386099 | validation: 0.10596698953097836]
	TIME [epoch: 5.71 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09943706618104627		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.09943706618104627 | validation: 0.09390914397162371]
	TIME [epoch: 5.71 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116600750223065		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.10116600750223065 | validation: 0.11024095512426417]
	TIME [epoch: 5.71 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141806553915506		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.10141806553915506 | validation: 0.10127197977354616]
	TIME [epoch: 5.72 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009497016634949		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.1009497016634949 | validation: 0.10660865340806475]
	TIME [epoch: 5.69 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207155675291675		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.10207155675291675 | validation: 0.10644266509815233]
	TIME [epoch: 5.7 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10161227274980072		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.10161227274980072 | validation: 0.0986148866116409]
	TIME [epoch: 5.69 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841549594300922		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.09841549594300922 | validation: 0.09689324215854817]
	TIME [epoch: 5.69 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738087476873404		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.09738087476873404 | validation: 0.101988613503107]
	TIME [epoch: 5.69 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844172995161302		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.09844172995161302 | validation: 0.10736257269658625]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999899627230996		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.0999899627230996 | validation: 0.10659879026158939]
	TIME [epoch: 5.7 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09997817592938865		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.09997817592938865 | validation: 0.10261934107430534]
	TIME [epoch: 5.7 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988153847254159		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.0988153847254159 | validation: 0.10140170488702194]
	TIME [epoch: 5.69 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676572898146973		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.10676572898146973 | validation: 0.10048112395328997]
	TIME [epoch: 5.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10150710741089465		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.10150710741089465 | validation: 0.09115570984440954]
	TIME [epoch: 5.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1727.pth
	Model improved!!!
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09957022969330619		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.09957022969330619 | validation: 0.10655299155355447]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017567935998702		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.1017567935998702 | validation: 0.10168968818762376]
	TIME [epoch: 5.72 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09834225113702903		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.09834225113702903 | validation: 0.09440192775612358]
	TIME [epoch: 5.7 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996761063883158		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.09996761063883158 | validation: 0.1017498543524959]
	TIME [epoch: 5.71 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914688820502662		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.09914688820502662 | validation: 0.09311967836766115]
	TIME [epoch: 5.7 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10418562377443975		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.10418562377443975 | validation: 0.09560133124588237]
	TIME [epoch: 5.71 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09517011689031371		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.09517011689031371 | validation: 0.10825314824693306]
	TIME [epoch: 5.69 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09797474581646037		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.09797474581646037 | validation: 0.10437531598668724]
	TIME [epoch: 5.75 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544162604535734		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.10544162604535734 | validation: 0.10858624934419236]
	TIME [epoch: 5.71 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259032538008918		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.10259032538008918 | validation: 0.10404148059290817]
	TIME [epoch: 5.71 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001569757847006		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.1001569757847006 | validation: 0.09928116996001402]
	TIME [epoch: 5.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09847021265364508		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.09847021265364508 | validation: 0.09661291271703042]
	TIME [epoch: 5.69 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982888593069866		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.09982888593069866 | validation: 0.10310131048957172]
	TIME [epoch: 5.69 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051361218292351		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.1051361218292351 | validation: 0.1003255180353438]
	TIME [epoch: 5.72 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10153332810114457		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.10153332810114457 | validation: 0.09746984282680572]
	TIME [epoch: 5.71 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09780259511535896		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.09780259511535896 | validation: 0.0992892311302089]
	TIME [epoch: 5.69 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673368549906484		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.09673368549906484 | validation: 0.09890828334234791]
	TIME [epoch: 5.69 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004411853690286		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.10004411853690286 | validation: 0.10147284883994502]
	TIME [epoch: 5.69 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709592779131243		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.09709592779131243 | validation: 0.0958056669738648]
	TIME [epoch: 5.69 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013701118590924		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.1013701118590924 | validation: 0.10717440247357007]
	TIME [epoch: 5.69 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10224844682227444		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.10224844682227444 | validation: 0.09596055601691125]
	TIME [epoch: 5.74 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942422985346894		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.09942422985346894 | validation: 0.10122702727564557]
	TIME [epoch: 5.69 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09930957790789632		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.09930957790789632 | validation: 0.10558221975230737]
	TIME [epoch: 5.69 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705314561581695		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.09705314561581695 | validation: 0.1046167029891695]
	TIME [epoch: 5.69 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385812387688756		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.10385812387688756 | validation: 0.10178710908424289]
	TIME [epoch: 5.69 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10419808687209693		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.10419808687209693 | validation: 0.11313551543080845]
	TIME [epoch: 5.69 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10417622007631741		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.10417622007631741 | validation: 0.11082942484138719]
	TIME [epoch: 5.71 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163107903916249		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.10163107903916249 | validation: 0.10275198403914634]
	TIME [epoch: 5.7 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168347342511765		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.10168347342511765 | validation: 0.10032578316293662]
	TIME [epoch: 5.69 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09931672817754325		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.09931672817754325 | validation: 0.10200710790365712]
	TIME [epoch: 5.69 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09755906142916618		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.09755906142916618 | validation: 0.1070443500034622]
	TIME [epoch: 5.69 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993852509234015		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.09993852509234015 | validation: 0.10606064079668644]
	TIME [epoch: 5.69 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889625743739613		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.09889625743739613 | validation: 0.10886633741497363]
	TIME [epoch: 5.69 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413282838146402		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.10413282838146402 | validation: 0.10746742580649533]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09858988560962136		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.09858988560962136 | validation: 0.100161887408836]
	TIME [epoch: 5.69 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110517887777605		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.10110517887777605 | validation: 0.10114330703818322]
	TIME [epoch: 5.69 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975017542452337		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.09975017542452337 | validation: 0.09925634877547028]
	TIME [epoch: 5.69 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10179354727751277		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.10179354727751277 | validation: 0.10203522625375872]
	TIME [epoch: 5.69 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964493073525754		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.09964493073525754 | validation: 0.10309800522498144]
	TIME [epoch: 5.7 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10076882606144714		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.10076882606144714 | validation: 0.10183721396682809]
	TIME [epoch: 5.71 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020924703476851		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.1020924703476851 | validation: 0.1013021814074177]
	TIME [epoch: 5.72 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089984088227184		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.10089984088227184 | validation: 0.10903989985413585]
	TIME [epoch: 5.69 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867588554794492		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.09867588554794492 | validation: 0.09592676022218932]
	TIME [epoch: 5.69 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758365820561281		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.09758365820561281 | validation: 0.1039603930336212]
	TIME [epoch: 5.69 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10242669353704639		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.10242669353704639 | validation: 0.09426305640190012]
	TIME [epoch: 5.69 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10039697733924277		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.10039697733924277 | validation: 0.10242220646987811]
	TIME [epoch: 5.69 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0998314465319353		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.0998314465319353 | validation: 0.10393771424484607]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911123532042704		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.09911123532042704 | validation: 0.10935012995953276]
	TIME [epoch: 5.69 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09832851811724003		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.09832851811724003 | validation: 0.0972525037410528]
	TIME [epoch: 5.69 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10398014389287927		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.10398014389287927 | validation: 0.10566041372372129]
	TIME [epoch: 5.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10434556262697668		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.10434556262697668 | validation: 0.09752163990028738]
	TIME [epoch: 5.69 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090394245991617		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.10090394245991617 | validation: 0.10473733323462263]
	TIME [epoch: 5.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09860262862955686		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.09860262862955686 | validation: 0.11260997984495617]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057227036088559		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.10057227036088559 | validation: 0.10045746588034984]
	TIME [epoch: 5.71 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320684788450189		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.10320684788450189 | validation: 0.10664989036665984]
	TIME [epoch: 5.71 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033251306428276		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.10033251306428276 | validation: 0.10154029715838413]
	TIME [epoch: 5.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462268656876218		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.10462268656876218 | validation: 0.0980136041728096]
	TIME [epoch: 5.71 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10545942782765581		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.10545942782765581 | validation: 0.10130583465487521]
	TIME [epoch: 5.71 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087321960889618		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.10087321960889618 | validation: 0.10476184803907453]
	TIME [epoch: 5.7 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10527573366737622		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.10527573366737622 | validation: 0.09776049275472655]
	TIME [epoch: 5.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237714548994845		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.10237714548994845 | validation: 0.10325018065967329]
	TIME [epoch: 5.71 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10018348865504834		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.10018348865504834 | validation: 0.10315416620870617]
	TIME [epoch: 5.69 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214943990873476		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.10214943990873476 | validation: 0.1074117951246097]
	TIME [epoch: 5.7 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048887244005325		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.10048887244005325 | validation: 0.11200191195464725]
	TIME [epoch: 5.7 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09949556494769221		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.09949556494769221 | validation: 0.09751784907503398]
	TIME [epoch: 5.7 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09806096148696034		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.09806096148696034 | validation: 0.1015456399503647]
	TIME [epoch: 5.72 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09814619327463661		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.09814619327463661 | validation: 0.10052324252635185]
	TIME [epoch: 5.71 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984034974636034		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.09984034974636034 | validation: 0.10243818179302054]
	TIME [epoch: 5.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656364296446994		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.09656364296446994 | validation: 0.10700466891427489]
	TIME [epoch: 5.7 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281865471728063		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.10281865471728063 | validation: 0.10047712234555649]
	TIME [epoch: 5.69 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1041969546203784		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.1041969546203784 | validation: 0.1090400580110147]
	TIME [epoch: 5.7 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897726422396297		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.09897726422396297 | validation: 0.10580454139767004]
	TIME [epoch: 5.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281590778200757		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.10281590778200757 | validation: 0.11022411660765748]
	TIME [epoch: 5.75 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220103970352931		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.10220103970352931 | validation: 0.10778063890542847]
	TIME [epoch: 5.71 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641647325193589		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.09641647325193589 | validation: 0.10236143394723556]
	TIME [epoch: 5.71 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564225583018532		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.09564225583018532 | validation: 0.10576494964924972]
	TIME [epoch: 5.71 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711197244878152		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.09711197244878152 | validation: 0.09219267757178733]
	TIME [epoch: 5.71 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011521958659236		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.10011521958659236 | validation: 0.10655095594150128]
	TIME [epoch: 5.71 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102683519797997		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.102683519797997 | validation: 0.10572400928269861]
	TIME [epoch: 5.73 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09687602722860203		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.09687602722860203 | validation: 0.11128598667109026]
	TIME [epoch: 5.72 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09856160093218683		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.09856160093218683 | validation: 0.09770753002487938]
	TIME [epoch: 5.71 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09833723497670223		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.09833723497670223 | validation: 0.10549334782184659]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872787678342551		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.09872787678342551 | validation: 0.10661346194363049]
	TIME [epoch: 5.71 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961917408321899		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.09961917408321899 | validation: 0.10382726959880972]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09781633998396319		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.09781633998396319 | validation: 0.10349895054346105]
	TIME [epoch: 5.71 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302168910317197		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.10302168910317197 | validation: 0.10144588615402043]
	TIME [epoch: 5.75 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100495918346101		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.100495918346101 | validation: 0.10835629778863043]
	TIME [epoch: 5.71 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057268835593794		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.10057268835593794 | validation: 0.10177825561757896]
	TIME [epoch: 5.71 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09988286043889522		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.09988286043889522 | validation: 0.09766545864818196]
	TIME [epoch: 5.7 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890032952570885		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.09890032952570885 | validation: 0.0978972245291844]
	TIME [epoch: 5.71 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10303154549811352		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.10303154549811352 | validation: 0.0990433051870858]
	TIME [epoch: 5.71 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912333208092142		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.09912333208092142 | validation: 0.10170084855323012]
	TIME [epoch: 5.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10267147056395551		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.10267147056395551 | validation: 0.09082860886017713]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r0_20240310_014358/states/model_tr_study202_1820.pth
	Model improved!!!
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10001730327264113		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.10001730327264113 | validation: 0.10566892326397043]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986591574519523		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0986591574519523 | validation: 0.09649900851021524]
	TIME [epoch: 5.69 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100152000029851		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.100152000029851 | validation: 0.10490628794324382]
	TIME [epoch: 5.69 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149785671032671		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.10149785671032671 | validation: 0.09921205356858413]
	TIME [epoch: 5.69 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127964201299879		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.10127964201299879 | validation: 0.10665097230710101]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198354364487577		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.10198354364487577 | validation: 0.099325323629045]
	TIME [epoch: 5.72 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226601536543793		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.10226601536543793 | validation: 0.10355628245739489]
	TIME [epoch: 5.69 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0982892549549686		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0982892549549686 | validation: 0.1062582390550335]
	TIME [epoch: 5.69 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09825886937625747		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.09825886937625747 | validation: 0.09789841509535997]
	TIME [epoch: 5.69 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10170251991710086		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.10170251991710086 | validation: 0.1052419892627439]
	TIME [epoch: 5.69 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839731074598829		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.09839731074598829 | validation: 0.10735691431174173]
	TIME [epoch: 5.69 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09697321510038097		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.09697321510038097 | validation: 0.09823252475512247]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051787878447319		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.10051787878447319 | validation: 0.0913653234264788]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09830408070770424		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.09830408070770424 | validation: 0.09564370580200045]
	TIME [epoch: 5.69 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991719632166555		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.0991719632166555 | validation: 0.1017670798475954]
	TIME [epoch: 5.69 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10010786835240577		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.10010786835240577 | validation: 0.10259512523081085]
	TIME [epoch: 5.7 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006959313295827		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.1006959313295827 | validation: 0.10121219720904719]
	TIME [epoch: 5.69 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841582442476189		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.09841582442476189 | validation: 0.10811846272092837]
	TIME [epoch: 5.71 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709534941787275		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.09709534941787275 | validation: 0.09413311207376318]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09860557602308333		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.09860557602308333 | validation: 0.09848204598338801]
	TIME [epoch: 5.7 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122984607151932		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.10122984607151932 | validation: 0.09926900498438145]
	TIME [epoch: 5.7 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09741172105121954		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.09741172105121954 | validation: 0.0972393680791216]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974102066101038		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.09974102066101038 | validation: 0.09692211863799859]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993497710757994		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.0993497710757994 | validation: 0.10034579591263387]
	TIME [epoch: 5.7 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112727284256415		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.10112727284256415 | validation: 0.10982407935807026]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966216827594196		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.09966216827594196 | validation: 0.11103451561514517]
	TIME [epoch: 5.7 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331572401841829		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.10331572401841829 | validation: 0.10757167592457602]
	TIME [epoch: 5.7 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199708398087737		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.10199708398087737 | validation: 0.10474744885536484]
	TIME [epoch: 5.7 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118806914614714		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.10118806914614714 | validation: 0.09448909411611638]
	TIME [epoch: 5.7 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09697207653162918		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.09697207653162918 | validation: 0.10731715042508705]
	TIME [epoch: 5.7 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009305853549087		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.1009305853549087 | validation: 0.10384672178897336]
	TIME [epoch: 5.71 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10005225530705893		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.10005225530705893 | validation: 0.10153674454563408]
	TIME [epoch: 5.72 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912735487070504		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.09912735487070504 | validation: 0.10266458659615556]
	TIME [epoch: 5.7 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09801579626812756		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.09801579626812756 | validation: 0.09762450494137262]
	TIME [epoch: 5.7 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10147609033015152		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.10147609033015152 | validation: 0.10414273109525063]
	TIME [epoch: 5.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069419814318017		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.10069419814318017 | validation: 0.09358559093365915]
	TIME [epoch: 5.7 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090022527499264		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.10090022527499264 | validation: 0.10600646364811794]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09973278104640909		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.09973278104640909 | validation: 0.1114831874578166]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171081738061666		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.10171081738061666 | validation: 0.09657667095547744]
	TIME [epoch: 5.7 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036376373550236		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.10036376373550236 | validation: 0.0963753287228478]
	TIME [epoch: 5.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09864779941832465		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.09864779941832465 | validation: 0.09325053741518857]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752490353793022		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.09752490353793022 | validation: 0.10131295822927644]
	TIME [epoch: 5.7 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049243705759719		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.1049243705759719 | validation: 0.1064808316860285]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870893387866522		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.09870893387866522 | validation: 0.10232872931461053]
	TIME [epoch: 5.71 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145038704614534		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.10145038704614534 | validation: 0.10251524110341631]
	TIME [epoch: 5.73 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219219953108125		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.10219219953108125 | validation: 0.10585333099357819]
	TIME [epoch: 5.7 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10182533641288198		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.10182533641288198 | validation: 0.10630549489877518]
	TIME [epoch: 5.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920970023687184		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.09920970023687184 | validation: 0.1015580110455068]
	TIME [epoch: 5.7 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031774815424786		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.10031774815424786 | validation: 0.10772647783287317]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996365127440468		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.09996365127440468 | validation: 0.10777521535222301]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09696732900833296		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.09696732900833296 | validation: 0.1048689553968941]
	TIME [epoch: 5.73 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165950083648496		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.10165950083648496 | validation: 0.09723656837846772]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117744606151016		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.10117744606151016 | validation: 0.10594458735450005]
	TIME [epoch: 5.7 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038645746377023		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.10038645746377023 | validation: 0.10816785935309942]
	TIME [epoch: 5.7 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080847901161648		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.10080847901161648 | validation: 0.10485774451796352]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000178563188626		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.1000178563188626 | validation: 0.09317457407001349]
	TIME [epoch: 5.7 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175691896765465		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.10175691896765465 | validation: 0.10780682677188566]
	TIME [epoch: 5.71 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035425122388789		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.10035425122388789 | validation: 0.1014312600000514]
	TIME [epoch: 5.72 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09920751208260623		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.09920751208260623 | validation: 0.0972639770636993]
	TIME [epoch: 5.7 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09901623091419888		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.09901623091419888 | validation: 0.10737017643200054]
	TIME [epoch: 5.7 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09726342369674726		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.09726342369674726 | validation: 0.1033915360079698]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10084132689220825		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.10084132689220825 | validation: 0.10836732125715148]
	TIME [epoch: 5.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561687576494347		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.09561687576494347 | validation: 0.10627309310870214]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176179323461126		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.10176179323461126 | validation: 0.10613948340435539]
	TIME [epoch: 5.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10121115376048596		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.10121115376048596 | validation: 0.10624721264266417]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893029728690919		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.09893029728690919 | validation: 0.1065719067025196]
	TIME [epoch: 5.7 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09792264722372164		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.09792264722372164 | validation: 0.10733239746652685]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09723639150109095		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.09723639150109095 | validation: 0.10057561282614608]
	TIME [epoch: 5.7 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09619610208071369		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.09619610208071369 | validation: 0.10549012949626704]
	TIME [epoch: 5.7 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046511891180562		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.10046511891180562 | validation: 0.10962065556570696]
	TIME [epoch: 5.71 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09882750470597225		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.09882750470597225 | validation: 0.1031633290306246]
	TIME [epoch: 5.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800274058994811		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.09800274058994811 | validation: 0.10689095548886765]
	TIME [epoch: 5.71 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10078608081056248		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.10078608081056248 | validation: 0.11507431756494431]
	TIME [epoch: 5.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009431097150051		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.1009431097150051 | validation: 0.10569476894451629]
	TIME [epoch: 5.69 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09726341023024852		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.09726341023024852 | validation: 0.10875304491295747]
	TIME [epoch: 5.71 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09582268221595966		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.09582268221595966 | validation: 0.10234173314726959]
	TIME [epoch: 5.7 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175439622855029		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.10175439622855029 | validation: 0.10924887389828002]
	TIME [epoch: 5.73 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907900609649722		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.09907900609649722 | validation: 0.09961872535472412]
	TIME [epoch: 5.7 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933270995696161		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.09933270995696161 | validation: 0.1023834430669454]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251674962165411		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.10251674962165411 | validation: 0.10106178142624886]
	TIME [epoch: 5.71 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156948717734687		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.10156948717734687 | validation: 0.09909275385107202]
	TIME [epoch: 5.7 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302615133631571		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.10302615133631571 | validation: 0.10089295074945154]
	TIME [epoch: 5.69 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10343199125474524		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.10343199125474524 | validation: 0.10425140330581827]
	TIME [epoch: 5.71 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149161019628512		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.10149161019628512 | validation: 0.1056453407480075]
	TIME [epoch: 5.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10132267321193948		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.10132267321193948 | validation: 0.10723194219885673]
	TIME [epoch: 5.7 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09989674907483112		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.09989674907483112 | validation: 0.10198468318635807]
	TIME [epoch: 5.7 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008392910358297		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.1008392910358297 | validation: 0.11012979877347256]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09964418484272627		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.09964418484272627 | validation: 0.09638285968635459]
	TIME [epoch: 5.71 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045825235385406		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.10045825235385406 | validation: 0.1104231251933598]
	TIME [epoch: 5.71 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966463460473347		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.09966463460473347 | validation: 0.10315059914133042]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911404455811998		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.09911404455811998 | validation: 0.1067612193010194]
	TIME [epoch: 5.71 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0993004568698624		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.0993004568698624 | validation: 0.1068775152074461]
	TIME [epoch: 5.71 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10047139253231942		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.10047139253231942 | validation: 0.1091829202500661]
	TIME [epoch: 5.7 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667684037702588		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.09667684037702588 | validation: 0.10982122403794495]
	TIME [epoch: 5.69 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259681519837932		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.10259681519837932 | validation: 0.10628053092961928]
	TIME [epoch: 5.69 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09891254798047097		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.09891254798047097 | validation: 0.10782846380784833]
	TIME [epoch: 5.71 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10325223681010014		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.10325223681010014 | validation: 0.10921457836475877]
	TIME [epoch: 5.72 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221246973730061		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.10221246973730061 | validation: 0.10660874576090847]
	TIME [epoch: 5.71 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115641078270875		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.10115641078270875 | validation: 0.09915692646736954]
	TIME [epoch: 5.7 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298315520458465		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.10298315520458465 | validation: 0.10362666920923921]
	TIME [epoch: 5.7 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211486781011435		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.10211486781011435 | validation: 0.10405798681466957]
	TIME [epoch: 5.7 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109494475754133		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.10109494475754133 | validation: 0.1053107863013921]
	TIME [epoch: 5.7 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10027805616279055		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.10027805616279055 | validation: 0.10756208041655654]
	TIME [epoch: 5.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640234707839352		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.10640234707839352 | validation: 0.10836216890814879]
	TIME [epoch: 5.7 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400157267978667		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.10400157267978667 | validation: 0.1030724174555562]
	TIME [epoch: 5.7 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09846553811423472		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.09846553811423472 | validation: 0.1031501946684632]
	TIME [epoch: 5.69 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009225173814263		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.1009225173814263 | validation: 0.1029305026493248]
	TIME [epoch: 5.71 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939268058866672		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.0939268058866672 | validation: 0.1116273392910945]
	TIME [epoch: 5.7 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09959359529516223		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.09959359529516223 | validation: 0.10880753947634521]
	TIME [epoch: 5.72 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10169678205719243		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.10169678205719243 | validation: 0.10684344504336307]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09945455678325156		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.09945455678325156 | validation: 0.10772729661711544]
	TIME [epoch: 5.71 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958212581783348		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.09958212581783348 | validation: 0.09888049399091597]
	TIME [epoch: 5.71 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984813654962875		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.09984813654962875 | validation: 0.09784219002505345]
	TIME [epoch: 5.71 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048807702002453		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.10048807702002453 | validation: 0.10593426753078312]
	TIME [epoch: 5.71 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986221799381154		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.0986221799381154 | validation: 0.1026134439956713]
	TIME [epoch: 5.71 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013216027079703		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.1013216027079703 | validation: 0.10409599384702876]
	TIME [epoch: 5.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09832956413140315		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.09832956413140315 | validation: 0.10183181171960122]
	TIME [epoch: 5.71 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678423005469527		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.09678423005469527 | validation: 0.10654082800063935]
	TIME [epoch: 5.7 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09760228378629277		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.09760228378629277 | validation: 0.10366118145248152]
	TIME [epoch: 5.71 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000812075024058		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.1000812075024058 | validation: 0.09912585128054989]
	TIME [epoch: 5.71 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999300472816537		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.0999300472816537 | validation: 0.10790291517720806]
	TIME [epoch: 5.71 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090341881532662		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.10090341881532662 | validation: 0.10758421252237232]
	TIME [epoch: 5.71 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10001978692645123		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.10001978692645123 | validation: 0.1008489471998032]
	TIME [epoch: 5.73 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09808145181062916		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.09808145181062916 | validation: 0.09945519449094761]
	TIME [epoch: 5.7 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09745375679076854		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.09745375679076854 | validation: 0.09778572931171355]
	TIME [epoch: 5.71 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006415407906876		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.1006415407906876 | validation: 0.1066224287343309]
	TIME [epoch: 5.69 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370801932825768		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.10370801932825768 | validation: 0.10528588021684035]
	TIME [epoch: 5.72 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777163285752527		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.09777163285752527 | validation: 0.10687615705535315]
	TIME [epoch: 5.72 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10100193539807908		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.10100193539807908 | validation: 0.10720491330129055]
	TIME [epoch: 5.74 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09699933678908224		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.09699933678908224 | validation: 0.09482279145442452]
	TIME [epoch: 5.71 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961237948242525		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.09961237948242525 | validation: 0.11044326262365588]
	TIME [epoch: 5.71 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705483379359371		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.09705483379359371 | validation: 0.10516109999203542]
	TIME [epoch: 5.7 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051445481227587		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.10051445481227587 | validation: 0.09654635932283835]
	TIME [epoch: 5.71 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188550620826398		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.10188550620826398 | validation: 0.10284379502636508]
	TIME [epoch: 5.71 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09978161603284799		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.09978161603284799 | validation: 0.10075023757066907]
	TIME [epoch: 5.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878812829189695		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.09878812829189695 | validation: 0.10263793959534617]
	TIME [epoch: 5.72 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989963245041912		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.0989963245041912 | validation: 0.10503619523517464]
	TIME [epoch: 5.71 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927976069609765		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.09927976069609765 | validation: 0.10094259241558831]
	TIME [epoch: 5.71 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090578110733829		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.10090578110733829 | validation: 0.10129118718714568]
	TIME [epoch: 5.71 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994092512751782		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.09994092512751782 | validation: 0.10757240182352121]
	TIME [epoch: 5.7 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985011284280282		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.09985011284280282 | validation: 0.10758187120829785]
	TIME [epoch: 5.71 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080657380512692		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.10080657380512692 | validation: 0.1066888577709625]
	TIME [epoch: 5.75 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09771223377469192		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.09771223377469192 | validation: 0.10827960493577768]
	TIME [epoch: 5.71 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914813353995056		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.09914813353995056 | validation: 0.1070393685317983]
	TIME [epoch: 5.7 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631956912347693		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.09631956912347693 | validation: 0.1012359564414479]
	TIME [epoch: 5.71 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160315624845404		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.10160315624845404 | validation: 0.10141842422000696]
	TIME [epoch: 5.7 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09901746325531349		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.09901746325531349 | validation: 0.09553186386255946]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172142133560862		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.10172142133560862 | validation: 0.11758672109778409]
	TIME [epoch: 5.72 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007524672872494		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.1007524672872494 | validation: 0.10637257919303489]
	TIME [epoch: 5.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037326686798896		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.10037326686798896 | validation: 0.10841511944213839]
	TIME [epoch: 5.7 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676888594777727		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.09676888594777727 | validation: 0.09789243660992898]
	TIME [epoch: 5.71 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904853284502924		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.09904853284502924 | validation: 0.10680591804195949]
	TIME [epoch: 5.7 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653823806871632		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.09653823806871632 | validation: 0.09559397436244325]
	TIME [epoch: 5.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323622880475401		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.10323622880475401 | validation: 0.10707783766889517]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226693731634501		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.10226693731634501 | validation: 0.09549802900984172]
	TIME [epoch: 5.74 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970100400255484		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.0970100400255484 | validation: 0.092050449909272]
	TIME [epoch: 5.71 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861153727802333		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.09861153727802333 | validation: 0.11051735838696089]
	TIME [epoch: 5.7 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10297984816636999		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.10297984816636999 | validation: 0.09932364535983006]
	TIME [epoch: 5.72 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992849762151519		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.09992849762151519 | validation: 0.10304435246900916]
	TIME [epoch: 5.71 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888677386128453		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.09888677386128453 | validation: 0.10399206009100948]
	TIME [epoch: 5.71 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09723352109901995		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.09723352109901995 | validation: 0.09656337510540434]
	TIME [epoch: 5.74 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10007783294338435		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.10007783294338435 | validation: 0.09912224385980128]
	TIME [epoch: 5.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09600254103780576		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.09600254103780576 | validation: 0.09508206022285003]
	TIME [epoch: 5.7 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09938068372915836		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.09938068372915836 | validation: 0.10062225532795167]
	TIME [epoch: 5.71 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596870689812388		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.10596870689812388 | validation: 0.10594471103991233]
	TIME [epoch: 5.71 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09968975300079869		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.09968975300079869 | validation: 0.10096745109660903]
	TIME [epoch: 5.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09525919833593965		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.09525919833593965 | validation: 0.102387930440064]
	TIME [epoch: 5.69 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173783662160528		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.10173783662160528 | validation: 0.10135103349343794]
	TIME [epoch: 5.74 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09822404406390917		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.09822404406390917 | validation: 0.1064110086974808]
	TIME [epoch: 5.72 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09877936575290679		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.09877936575290679 | validation: 0.09766613614942732]
	TIME [epoch: 5.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236359303531176		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.10236359303531176 | validation: 0.10390113539981112]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258179616499663		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.10258179616499663 | validation: 0.10018257747205278]
	TIME [epoch: 5.71 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09870831721251394		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.09870831721251394 | validation: 0.1015926715574888]
	TIME [epoch: 5.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251339895834963		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.10251339895834963 | validation: 0.09980262579662931]
	TIME [epoch: 5.73 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09809871109972698		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.09809871109972698 | validation: 0.10176824477625034]
	TIME [epoch: 5.73 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070627540270746		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.10070627540270746 | validation: 0.09863177016178125]
	TIME [epoch: 5.71 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0997237962783879		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.0997237962783879 | validation: 0.1081268767491586]
	TIME [epoch: 5.7 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989802472119041		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.0989802472119041 | validation: 0.10078682901784017]
	TIME [epoch: 5.69 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295080688386311		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.10295080688386311 | validation: 0.09983324310029856]
	TIME [epoch: 5.72 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705378652769472		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.09705378652769472 | validation: 0.09798045791105775]
	TIME [epoch: 5.71 sec]
Finished training in 11657.000 seconds.
