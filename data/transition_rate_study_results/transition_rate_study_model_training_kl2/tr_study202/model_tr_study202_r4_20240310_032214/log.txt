Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r4', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3632110252

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.299059138142937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.299059138142937 | validation: 11.68632216182215]
	TIME [epoch: 91.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.858216840366516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.858216840366516 | validation: 12.465315484817548]
	TIME [epoch: 5.77 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.571079320970133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.571079320970133 | validation: 12.11384742435377]
	TIME [epoch: 5.72 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.854904640363618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.854904640363618 | validation: 11.296817975948702]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.824084171357308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.824084171357308 | validation: 11.04248205361451]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.630755680378929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.630755680378929 | validation: 10.8332338756912]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.240169261932841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.240169261932841 | validation: 10.33711082964069]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.686096119724384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.686096119724384 | validation: 9.402237712658707]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.62045792595689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.62045792595689 | validation: 8.052114539498524]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.916348909474358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.916348909474358 | validation: 8.115881876647052]
	TIME [epoch: 5.71 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.589819378427555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.589819378427555 | validation: 7.470978933510761]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.117188819205852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.117188819205852 | validation: 6.443141752030645]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.423231692409996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.423231692409996 | validation: 5.90516119823799]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.310321720983874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.310321720983874 | validation: 5.420331530343694]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9085278675286865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9085278675286865 | validation: 5.650667440585872]
	TIME [epoch: 5.72 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.960918243806942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.960918243806942 | validation: 5.570884696007401]
	TIME [epoch: 5.72 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.066108725081678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.066108725081678 | validation: 4.7136262797060855]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.478737327477387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.478737327477387 | validation: 4.609680936756953]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.531988136413107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.531988136413107 | validation: 4.6789239499285165]
	TIME [epoch: 5.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.423109259725936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.423109259725936 | validation: 4.474804917256897]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.220828755468189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220828755468189 | validation: 4.684332406561111]
	TIME [epoch: 5.71 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.324877640517991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.324877640517991 | validation: 5.838484018206503]
	TIME [epoch: 5.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.285994983065179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.285994983065179 | validation: 5.226640157453639]
	TIME [epoch: 5.71 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.993677842790825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.993677842790825 | validation: 5.001527786372239]
	TIME [epoch: 5.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.898062451956189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.898062451956189 | validation: 4.902066120950854]
	TIME [epoch: 5.71 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78142592331835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.78142592331835 | validation: 4.699592125954245]
	TIME [epoch: 5.74 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.568003913867271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.568003913867271 | validation: 4.3605861873722755]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.375842955559905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.375842955559905 | validation: 4.318404061314963]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.227933121408644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.227933121408644 | validation: 4.824743753003765]
	TIME [epoch: 5.72 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.224873985719877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.224873985719877 | validation: 3.649915300041645]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.937062305395684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.937062305395684 | validation: 3.596899911345131]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.963583785242083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.963583785242083 | validation: 3.4495559407803467]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.633568753074664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.633568753074664 | validation: 3.2315584433330224]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811167207707433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.811167207707433 | validation: 3.147590114784025]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.740407267389971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.740407267389971 | validation: 3.2946492704531303]
	TIME [epoch: 5.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.816817745487246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.816817745487246 | validation: 4.2134498058921785]
	TIME [epoch: 5.71 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.737063244830868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.737063244830868 | validation: 3.145928339147448]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.429650586636347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.429650586636347 | validation: 3.2621550768622085]
	TIME [epoch: 5.74 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3866185682747085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3866185682747085 | validation: 3.000140561858346]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582671112234655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.582671112234655 | validation: 2.888605983912799]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.573047415501954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.573047415501954 | validation: 2.9890557462652474]
	TIME [epoch: 5.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.355894160754742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.355894160754742 | validation: 2.761141152226459]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.357540767372505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.357540767372505 | validation: 2.7728472049173645]
	TIME [epoch: 5.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.468082819783453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.468082819783453 | validation: 3.1014191181741824]
	TIME [epoch: 5.75 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.430941821764106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.430941821764106 | validation: 2.9629896998867276]
	TIME [epoch: 5.73 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.306340307119288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.306340307119288 | validation: 3.5441394009410714]
	TIME [epoch: 5.72 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475066028057267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.475066028057267 | validation: 2.7313810425110474]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475873033610827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.475873033610827 | validation: 3.0153960869012724]
	TIME [epoch: 5.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.248384365188371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.248384365188371 | validation: 2.7179071455749635]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2623792728050685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2623792728050685 | validation: 2.722223618458075]
	TIME [epoch: 5.75 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.403260690757099		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.403260690757099 | validation: 2.784313555475252]
	TIME [epoch: 5.72 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.20947975930085		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.20947975930085 | validation: 2.9451397276124807]
	TIME [epoch: 5.71 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.346948092790344		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.346948092790344 | validation: 2.801919588337429]
	TIME [epoch: 5.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083605655174883		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.083605655174883 | validation: 2.8496361066417557]
	TIME [epoch: 5.71 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.144627942991773		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.144627942991773 | validation: 2.744513461338841]
	TIME [epoch: 5.71 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.222333029079295		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.222333029079295 | validation: 2.614309116019601]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.321294805869747		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.321294805869747 | validation: 2.6690450711207827]
	TIME [epoch: 5.73 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.179274090249095		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.179274090249095 | validation: 2.7294825636393476]
	TIME [epoch: 5.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.08849857377011		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.08849857377011 | validation: 2.871151033498261]
	TIME [epoch: 5.71 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3121239817280665		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.3121239817280665 | validation: 2.793618544211814]
	TIME [epoch: 5.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.175661996213129		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.175661996213129 | validation: 2.7530522874861276]
	TIME [epoch: 5.71 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076493980270104		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.076493980270104 | validation: 2.583278097803302]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.170087633468171		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.170087633468171 | validation: 2.7229093071525803]
	TIME [epoch: 5.72 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0451767445951505		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.0451767445951505 | validation: 2.6260004950904854]
	TIME [epoch: 5.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.153076790024276		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.153076790024276 | validation: 2.664498293690709]
	TIME [epoch: 5.71 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.024692390631314		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.024692390631314 | validation: 3.26473283929118]
	TIME [epoch: 5.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.235787452897026		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.235787452897026 | validation: 2.5214456599355346]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.155499968768118		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.155499968768118 | validation: 2.517389245673025]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.128124126582798		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.128124126582798 | validation: 2.7244513542988025]
	TIME [epoch: 5.71 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.148268202867502		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.148268202867502 | validation: 2.9760873562160493]
	TIME [epoch: 5.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.09464264933648		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.09464264933648 | validation: 2.896811602191128]
	TIME [epoch: 5.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0573754861825275		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.0573754861825275 | validation: 2.85481238951133]
	TIME [epoch: 5.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089941126148204		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.089941126148204 | validation: 2.5014791163759553]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.054594618705494		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.054594618705494 | validation: 2.7196095331860763]
	TIME [epoch: 5.75 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019665684257952		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.019665684257952 | validation: 2.5206153763234687]
	TIME [epoch: 5.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.031269152766822		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.031269152766822 | validation: 2.4364939261753555]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.078167672616351		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.078167672616351 | validation: 2.4865279680313486]
	TIME [epoch: 5.71 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062853291876068		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.062853291876068 | validation: 2.584095974692742]
	TIME [epoch: 5.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9563281094948293		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.9563281094948293 | validation: 2.669185493862034]
	TIME [epoch: 5.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9863804714569566		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.9863804714569566 | validation: 2.6393076516524885]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.046754541934494		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.046754541934494 | validation: 2.5886956875244858]
	TIME [epoch: 5.71 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.896615132652563		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.896615132652563 | validation: 3.2371291845760357]
	TIME [epoch: 5.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.125388166171792		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.125388166171792 | validation: 3.0049509001868784]
	TIME [epoch: 5.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.051357109844977		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.051357109844977 | validation: 2.486595497555515]
	TIME [epoch: 5.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13277158145366		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.13277158145366 | validation: 2.4471187112839337]
	TIME [epoch: 5.72 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0206488227129045		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.0206488227129045 | validation: 2.4566400701447675]
	TIME [epoch: 5.74 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.226645077440937		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.226645077440937 | validation: 2.488881007074971]
	TIME [epoch: 5.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.926316016537365		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.926316016537365 | validation: 2.3979665310669023]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8778908296386523		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.8778908296386523 | validation: 3.135520045353378]
	TIME [epoch: 5.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.080071744365607		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.080071744365607 | validation: 2.429808665618894]
	TIME [epoch: 5.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8149791960344914		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.8149791960344914 | validation: 2.379351206273241]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037297032950103		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.037297032950103 | validation: 2.553854435666323]
	TIME [epoch: 5.74 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9446173245927216		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.9446173245927216 | validation: 2.4124483394113083]
	TIME [epoch: 5.72 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9029058233895886		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.9029058233895886 | validation: 2.600449848324107]
	TIME [epoch: 5.71 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.963644336462508		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.963644336462508 | validation: 2.384755828655145]
	TIME [epoch: 5.71 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.976070155488898		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.976070155488898 | validation: 2.6174267820577315]
	TIME [epoch: 5.71 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.067533782969166		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.067533782969166 | validation: 2.356310462865009]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.800555103431286		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.800555103431286 | validation: 2.3047410569795512]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8400504825024306		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.8400504825024306 | validation: 2.3328704842009595]
	TIME [epoch: 5.71 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8927394853090567		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.8927394853090567 | validation: 2.770373801576661]
	TIME [epoch: 5.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9192309773440304		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.9192309773440304 | validation: 2.289523960693032]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8284675158077985		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.8284675158077985 | validation: 2.255718580476837]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.801138149515699		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.801138149515699 | validation: 2.281848556501588]
	TIME [epoch: 5.75 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.734311242580701		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.734311242580701 | validation: 2.610001375165582]
	TIME [epoch: 5.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8311497687724394		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.8311497687724394 | validation: 2.5127476690927852]
	TIME [epoch: 5.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.937313892453364		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.937313892453364 | validation: 2.207242495698158]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8657006253938393		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.8657006253938393 | validation: 2.279319157315209]
	TIME [epoch: 5.71 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.912789806857052		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.912789806857052 | validation: 2.2148808426906386]
	TIME [epoch: 5.71 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7725987037907065		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.7725987037907065 | validation: 3.0614056541399766]
	TIME [epoch: 5.74 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.969518928331947		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.969518928331947 | validation: 2.3492725421596363]
	TIME [epoch: 5.71 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.72107044604725		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.72107044604725 | validation: 2.3680222709042362]
	TIME [epoch: 5.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.731529090649981		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.731529090649981 | validation: 2.415490848320173]
	TIME [epoch: 5.72 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8996160037671266		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.8996160037671266 | validation: 2.229643671138572]
	TIME [epoch: 5.71 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.786942571859745		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.786942571859745 | validation: 2.2865363644151775]
	TIME [epoch: 5.71 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8604360551713586		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.8604360551713586 | validation: 2.3590908093886602]
	TIME [epoch: 5.75 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8067936087286194		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.8067936087286194 | validation: 2.2696807608781366]
	TIME [epoch: 5.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7043875366851973		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.7043875366851973 | validation: 2.2399318581356007]
	TIME [epoch: 5.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.835912292454549		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.835912292454549 | validation: 2.301495064287292]
	TIME [epoch: 5.71 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.075544941522558		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.075544941522558 | validation: 2.3027281199671785]
	TIME [epoch: 5.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8141454688601995		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.8141454688601995 | validation: 2.297604215023117]
	TIME [epoch: 5.72 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.686484157377694		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.686484157377694 | validation: 2.2674254942474863]
	TIME [epoch: 5.75 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.784451085757606		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.784451085757606 | validation: 2.5348880106055423]
	TIME [epoch: 5.73 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8636463980948323		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.8636463980948323 | validation: 2.2833462142967558]
	TIME [epoch: 5.71 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7664469536380625		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.7664469536380625 | validation: 2.4895939174855077]
	TIME [epoch: 5.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7603532044284256		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.7603532044284256 | validation: 2.2018053722012114]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7228136571066637		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.7228136571066637 | validation: 2.191020437284246]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.700177255648473		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.700177255648473 | validation: 2.4739581292588935]
	TIME [epoch: 5.74 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7765542580524794		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.7765542580524794 | validation: 2.131089149482686]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.783277490715167		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.783277490715167 | validation: 2.4448452352597587]
	TIME [epoch: 5.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7128506774548202		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.7128506774548202 | validation: 2.831356315896213]
	TIME [epoch: 5.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8105441623736294		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.8105441623736294 | validation: 2.2066131902555775]
	TIME [epoch: 5.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.669254074290907		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.669254074290907 | validation: 2.1000124643296147]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7064241520718144		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.7064241520718144 | validation: 2.119861915257616]
	TIME [epoch: 5.74 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.619589489668134		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.619589489668134 | validation: 2.313912259020253]
	TIME [epoch: 5.71 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7160935227011582		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.7160935227011582 | validation: 2.2198285060545495]
	TIME [epoch: 5.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6581006147498965		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.6581006147498965 | validation: 2.2632032262159036]
	TIME [epoch: 5.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6988627733850157		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.6988627733850157 | validation: 2.277242641111921]
	TIME [epoch: 5.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.634017226766262		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.634017226766262 | validation: 2.2236888752056734]
	TIME [epoch: 5.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7913895071364094		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.7913895071364094 | validation: 2.0480195212139063]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7089533809151427		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.7089533809151427 | validation: 2.114205915322438]
	TIME [epoch: 5.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6588724408309767		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.6588724408309767 | validation: 2.197557366019035]
	TIME [epoch: 5.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.591710058648983		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.591710058648983 | validation: 2.1135809386190743]
	TIME [epoch: 5.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.662551178982696		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.662551178982696 | validation: 2.17431044508475]
	TIME [epoch: 5.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6800148600943565		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.6800148600943565 | validation: 2.1039562594629166]
	TIME [epoch: 5.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.68475584300697		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.68475584300697 | validation: 2.357469306224073]
	TIME [epoch: 5.73 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7555117931368587		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.7555117931368587 | validation: 2.1214754009497465]
	TIME [epoch: 5.71 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6979000328342977		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.6979000328342977 | validation: 2.183481063061835]
	TIME [epoch: 5.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.639027592759486		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.639027592759486 | validation: 2.057381082814996]
	TIME [epoch: 5.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.594009373152978		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.594009373152978 | validation: 2.3601914197625344]
	TIME [epoch: 5.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6578274247581044		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.6578274247581044 | validation: 2.0178417365989967]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.568702003938184		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.568702003938184 | validation: 1.9987502625501135]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.564863400318548		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.564863400318548 | validation: 1.9863523219966863]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6201186829108947		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.6201186829108947 | validation: 2.003132564104519]
	TIME [epoch: 5.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.63417954170672		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.63417954170672 | validation: 2.059364155559187]
	TIME [epoch: 5.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.60738295469958		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.60738295469958 | validation: 2.215105262927611]
	TIME [epoch: 5.71 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6272012920668035		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.6272012920668035 | validation: 2.442164002258554]
	TIME [epoch: 5.71 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.613938292540261		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.613938292540261 | validation: 2.099289872825155]
	TIME [epoch: 5.75 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.595038021705378		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.595038021705378 | validation: 2.0221339253897446]
	TIME [epoch: 5.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5963252917933493		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.5963252917933493 | validation: 2.1466754577503435]
	TIME [epoch: 5.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6205865166862656		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.6205865166862656 | validation: 2.088237419759662]
	TIME [epoch: 5.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516003511576648		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.516003511576648 | validation: 2.3532061485606666]
	TIME [epoch: 5.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.651753415215408		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.651753415215408 | validation: 2.058213344450702]
	TIME [epoch: 5.71 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5687357779640507		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.5687357779640507 | validation: 2.310759968200383]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6423855589843943		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.6423855589843943 | validation: 2.043636051690938]
	TIME [epoch: 5.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.506949623379056		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.506949623379056 | validation: 2.0572860163610027]
	TIME [epoch: 5.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5500229665217726		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.5500229665217726 | validation: 1.9928328059088798]
	TIME [epoch: 5.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5421585419220873		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.5421585419220873 | validation: 2.0433308724939576]
	TIME [epoch: 5.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5142663028918726		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.5142663028918726 | validation: 2.0387188650632173]
	TIME [epoch: 5.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5794598650295706		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.5794598650295706 | validation: 2.1042167965866714]
	TIME [epoch: 5.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7724292089580365		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.7724292089580365 | validation: 2.0455760265932246]
	TIME [epoch: 5.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5885581213787545		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.5885581213787545 | validation: 2.060414653022673]
	TIME [epoch: 5.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5350233019996606		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.5350233019996606 | validation: 1.9936177237785109]
	TIME [epoch: 5.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.471901875558518		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.471901875558518 | validation: 2.19969352308359]
	TIME [epoch: 5.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5554138563781352		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.5554138563781352 | validation: 2.1619200086452195]
	TIME [epoch: 5.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5441300658897275		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.5441300658897275 | validation: 1.9031658665905071]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6729248206269114		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.6729248206269114 | validation: 1.9187929518226745]
	TIME [epoch: 5.71 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616507729758766		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.616507729758766 | validation: 2.021261533880212]
	TIME [epoch: 5.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515019036585207		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.515019036585207 | validation: 2.161500513817559]
	TIME [epoch: 5.71 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.495753427231206		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.495753427231206 | validation: 1.888521166115769]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5140847614506496		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.5140847614506496 | validation: 2.22786646552749]
	TIME [epoch: 5.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.581170290908086		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.581170290908086 | validation: 2.1272409755399804]
	TIME [epoch: 5.76 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5933906255852		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.5933906255852 | validation: 2.2333133093555286]
	TIME [epoch: 5.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5293620165281974		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.5293620165281974 | validation: 2.119774742265805]
	TIME [epoch: 5.71 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.545566607842446		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.545566607842446 | validation: 1.9801064684732241]
	TIME [epoch: 5.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.499629991939954		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.499629991939954 | validation: 2.0035970482458447]
	TIME [epoch: 5.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6057016402763318		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.6057016402763318 | validation: 1.9188463841922132]
	TIME [epoch: 5.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4338438799191486		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.4338438799191486 | validation: 2.007463205056101]
	TIME [epoch: 5.75 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4892199629607656		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.4892199629607656 | validation: 2.3548808406936454]
	TIME [epoch: 5.73 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.547639405644068		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.547639405644068 | validation: 1.8874794995450668]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4382941566488583		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.4382941566488583 | validation: 1.9617438905427964]
	TIME [epoch: 5.71 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.417498870398485		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.417498870398485 | validation: 1.8707053507996358]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.453959504507504		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.453959504507504 | validation: 1.9320298373861147]
	TIME [epoch: 5.72 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4873330310742423		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.4873330310742423 | validation: 1.8964973803495206]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.465287654081162		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.465287654081162 | validation: 1.828318615850169]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.344044086714624		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.344044086714624 | validation: 1.9438694761750432]
	TIME [epoch: 5.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4462020714664123		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.4462020714664123 | validation: 1.8632666248422123]
	TIME [epoch: 5.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.438532681072937		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.438532681072937 | validation: 2.0867368156654487]
	TIME [epoch: 5.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4856006214822655		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.4856006214822655 | validation: 1.878809966986569]
	TIME [epoch: 5.72 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.42805249848047		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.42805249848047 | validation: 1.8547537038671993]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3776881130441057		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.3776881130441057 | validation: 2.0398598535435166]
	TIME [epoch: 5.71 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4633301323773655		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.4633301323773655 | validation: 2.3564670690696317]
	TIME [epoch: 5.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5255110134038836		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.5255110134038836 | validation: 2.070204857320562]
	TIME [epoch: 5.71 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45922624695985		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.45922624695985 | validation: 2.262788608770714]
	TIME [epoch: 5.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5203691588519033		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.5203691588519033 | validation: 1.83740646842942]
	TIME [epoch: 5.72 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4718112714480722		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.4718112714480722 | validation: 1.8725836937520837]
	TIME [epoch: 5.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4407128679906815		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.4407128679906815 | validation: 1.847787619756532]
	TIME [epoch: 5.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3789552547988815		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.3789552547988815 | validation: 2.2848884072434616]
	TIME [epoch: 5.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5211447230266604		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 3.5211447230266604 | validation: 2.0417914803494206]
	TIME [epoch: 5.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4036978040945316		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.4036978040945316 | validation: 1.9570386371838475]
	TIME [epoch: 5.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371898622731053		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.371898622731053 | validation: 1.8628423545231476]
	TIME [epoch: 5.72 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.372184437431606		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.372184437431606 | validation: 1.8031829855854238]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.305397821206024		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.305397821206024 | validation: 2.0493560828938264]
	TIME [epoch: 5.71 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.532503700247061		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.532503700247061 | validation: 1.7777159975677683]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4690051833905464		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.4690051833905464 | validation: 1.8268172455552107]
	TIME [epoch: 5.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.415070342052635		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.415070342052635 | validation: 1.7702889474100305]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368417069730767		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.368417069730767 | validation: 1.8863680525742534]
	TIME [epoch: 5.74 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3532753087376466		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.3532753087376466 | validation: 2.1653339680668706]
	TIME [epoch: 5.72 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3994315638802464		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.3994315638802464 | validation: 1.7752241132617297]
	TIME [epoch: 5.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.529480059492142		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.529480059492142 | validation: 1.9316150135288552]
	TIME [epoch: 5.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4770879037986058		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.4770879037986058 | validation: 1.8326537442181263]
	TIME [epoch: 5.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3210075926639213		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.3210075926639213 | validation: 1.9948362264195385]
	TIME [epoch: 5.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.330320797042641		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.330320797042641 | validation: 1.8801907032566396]
	TIME [epoch: 5.74 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3674078075302996		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.3674078075302996 | validation: 2.063296077310773]
	TIME [epoch: 5.72 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5571013665688134		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.5571013665688134 | validation: 1.9615958820627748]
	TIME [epoch: 5.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.373848147630518		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.373848147630518 | validation: 1.8800537535535853]
	TIME [epoch: 5.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3366655933314195		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.3366655933314195 | validation: 1.8949875345393923]
	TIME [epoch: 5.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3940822701403124		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.3940822701403124 | validation: 1.7828881152475604]
	TIME [epoch: 5.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.399275364526398		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.399275364526398 | validation: 2.119027585020116]
	TIME [epoch: 5.72 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4180623268437627		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.4180623268437627 | validation: 1.7403070222141488]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3380236427278303		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 3.3380236427278303 | validation: 1.8205398558176473]
	TIME [epoch: 5.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4326527667699085		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.4326527667699085 | validation: 1.8040653291545323]
	TIME [epoch: 5.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.551115632477093		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.551115632477093 | validation: 1.9116408865144678]
	TIME [epoch: 5.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.350304159154314		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.350304159154314 | validation: 1.851700774525967]
	TIME [epoch: 5.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.307513002099409		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.307513002099409 | validation: 1.7836406882442901]
	TIME [epoch: 5.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5402755809864326		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.5402755809864326 | validation: 1.9360739546880243]
	TIME [epoch: 5.73 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366555865527179		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 3.366555865527179 | validation: 2.1721771516289246]
	TIME [epoch: 5.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.530224419714886		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 3.530224419714886 | validation: 1.9867581759108806]
	TIME [epoch: 5.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3697905545642337		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.3697905545642337 | validation: 1.760076734717795]
	TIME [epoch: 5.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3356630232015787		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 3.3356630232015787 | validation: 1.797253710723747]
	TIME [epoch: 5.72 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2991619440967397		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.2991619440967397 | validation: 1.9241302773131588]
	TIME [epoch: 5.73 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.362499101663711		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.362499101663711 | validation: 1.893138969527242]
	TIME [epoch: 5.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3238886605310487		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.3238886605310487 | validation: 1.8082188878713341]
	TIME [epoch: 5.72 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.491153337237879		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.491153337237879 | validation: 1.8062039275630855]
	TIME [epoch: 5.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.363483696587118		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 3.363483696587118 | validation: 2.088499434833944]
	TIME [epoch: 5.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4357010011111617		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.4357010011111617 | validation: 1.881345706633565]
	TIME [epoch: 5.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.343150645741126		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.343150645741126 | validation: 1.8548693326028387]
	TIME [epoch: 5.72 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.341243391564755		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.341243391564755 | validation: 1.776495106799483]
	TIME [epoch: 5.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.558029412274156		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 3.558029412274156 | validation: 2.0396147103474047]
	TIME [epoch: 5.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3710924840925123		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.3710924840925123 | validation: 2.0417150129044424]
	TIME [epoch: 5.71 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3773978345959046		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 3.3773978345959046 | validation: 1.9192691062154665]
	TIME [epoch: 5.71 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3750175389759387		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.3750175389759387 | validation: 1.8622785604569232]
	TIME [epoch: 5.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310292101235084		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.310292101235084 | validation: 1.9207541152387342]
	TIME [epoch: 5.73 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.390029483020721		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 3.390029483020721 | validation: 1.7908663364065243]
	TIME [epoch: 5.74 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3541969943981456		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 3.3541969943981456 | validation: 1.7587524159964005]
	TIME [epoch: 5.72 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.331175536209713		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 3.331175536209713 | validation: 1.8090753661145136]
	TIME [epoch: 5.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3381347962715746		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 3.3381347962715746 | validation: 2.2030558319357683]
	TIME [epoch: 5.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4568920503058163		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.4568920503058163 | validation: 2.0110368780291874]
	TIME [epoch: 5.71 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4462724059541654		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 3.4462724059541654 | validation: 2.0421361266005555]
	TIME [epoch: 5.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3699660077156404		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 3.3699660077156404 | validation: 1.8144028479386458]
	TIME [epoch: 5.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2848669408295104		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 3.2848669408295104 | validation: 1.7441337765714735]
	TIME [epoch: 5.72 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382857563204967		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.382857563204967 | validation: 1.7579795363335722]
	TIME [epoch: 5.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.262912110920429		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.262912110920429 | validation: 1.7620517068814534]
	TIME [epoch: 5.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310008443854034		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.310008443854034 | validation: 1.7801589600259808]
	TIME [epoch: 5.71 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2542365538873814		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.2542365538873814 | validation: 1.7629510567875144]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2946782051283043		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.2946782051283043 | validation: 1.7589456683663753]
	TIME [epoch: 5.75 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253242226222076		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.253242226222076 | validation: 2.1434590171588095]
	TIME [epoch: 5.72 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.354703236685596		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.354703236685596 | validation: 1.7452485484556264]
	TIME [epoch: 5.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2658595111838826		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.2658595111838826 | validation: 1.8347551824350643]
	TIME [epoch: 5.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3323990327113373		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.3323990327113373 | validation: 1.7092833450016554]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253195335864485		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.253195335864485 | validation: 1.6987662089633373]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.318399340206861		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.318399340206861 | validation: 1.69921071439397]
	TIME [epoch: 5.75 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.290839346035987		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.290839346035987 | validation: 1.9488543941350294]
	TIME [epoch: 5.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.345614886940614		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.345614886940614 | validation: 1.8958274517561169]
	TIME [epoch: 5.71 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4337463481109394		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.4337463481109394 | validation: 1.8617423289702533]
	TIME [epoch: 5.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3142746721984233		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.3142746721984233 | validation: 1.7088235537316536]
	TIME [epoch: 5.71 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3417945915152214		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.3417945915152214 | validation: 1.7886097926297038]
	TIME [epoch: 5.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2517422914317544		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.2517422914317544 | validation: 1.7613104165078783]
	TIME [epoch: 5.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391921127143708		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.391921127143708 | validation: 2.054031204659338]
	TIME [epoch: 5.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.396566921805439		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.396566921805439 | validation: 1.7554984034364998]
	TIME [epoch: 5.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.238630120047503		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.238630120047503 | validation: 1.7295991051700828]
	TIME [epoch: 5.72 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2489521168502082		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.2489521168502082 | validation: 1.8847720644832464]
	TIME [epoch: 5.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3873653136116713		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.3873653136116713 | validation: 1.9671043365217484]
	TIME [epoch: 5.73 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.274859725706954		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.274859725706954 | validation: 2.7248317221189478]
	TIME [epoch: 5.75 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7095314523973895		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.7095314523973895 | validation: 2.036942946819473]
	TIME [epoch: 5.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.400265589858466		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.400265589858466 | validation: 1.809374961796419]
	TIME [epoch: 5.72 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270459844980745		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.270459844980745 | validation: 1.7267722100559824]
	TIME [epoch: 5.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2396114066347224		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.2396114066347224 | validation: 1.8987678082830821]
	TIME [epoch: 5.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2414373621287917		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.2414373621287917 | validation: 1.8938914588323348]
	TIME [epoch: 5.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.333666561390265		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.333666561390265 | validation: 1.6949113971441454]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2773321252970433		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.2773321252970433 | validation: 1.722213123155249]
	TIME [epoch: 5.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227467335198017		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.227467335198017 | validation: 1.766879927374938]
	TIME [epoch: 5.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2855949717950566		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.2855949717950566 | validation: 2.6096084749896717]
	TIME [epoch: 5.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.478259330575741		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.478259330575741 | validation: 1.8946400506050374]
	TIME [epoch: 5.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3926859613211877		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.3926859613211877 | validation: 1.7394248340733516]
	TIME [epoch: 5.71 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2677856772028973		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.2677856772028973 | validation: 1.8130487783331097]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2844416897191264		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.2844416897191264 | validation: 1.7176588231190453]
	TIME [epoch: 5.72 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2423914092124195		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.2423914092124195 | validation: 1.675444011675029]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2647890467983447		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 3.2647890467983447 | validation: 1.685607840459507]
	TIME [epoch: 5.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2652563852083496		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.2652563852083496 | validation: 1.7326723591207451]
	TIME [epoch: 5.72 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3047417643152026		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.3047417643152026 | validation: 2.1179984734215513]
	TIME [epoch: 5.71 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3530867726210705		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.3530867726210705 | validation: 1.7928717305628283]
	TIME [epoch: 5.74 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2759871441780124		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.2759871441780124 | validation: 1.7109811787036353]
	TIME [epoch: 5.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2900945546918505		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 3.2900945546918505 | validation: 1.773639053822319]
	TIME [epoch: 5.71 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2545401046047235		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 3.2545401046047235 | validation: 1.8056824994607588]
	TIME [epoch: 5.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.263362365541007		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.263362365541007 | validation: 1.7153556937089542]
	TIME [epoch: 5.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2379582566037923		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.2379582566037923 | validation: 1.9582976934681582]
	TIME [epoch: 5.73 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2994280335599195		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 3.2994280335599195 | validation: 1.6910249617220394]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2250846722771938		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 3.2250846722771938 | validation: 1.7182188900597073]
	TIME [epoch: 5.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2696471023325975		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 3.2696471023325975 | validation: 1.9306293357857311]
	TIME [epoch: 5.72 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2914360920642425		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 3.2914360920642425 | validation: 2.2192385665705974]
	TIME [epoch: 5.72 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.339971671170712		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 3.339971671170712 | validation: 1.7682364591512365]
	TIME [epoch: 5.72 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2792619233780673		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 3.2792619233780673 | validation: 1.8602009650368074]
	TIME [epoch: 5.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2778837669843934		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 3.2778837669843934 | validation: 1.8840515809889267]
	TIME [epoch: 5.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2739876948243505		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.2739876948243505 | validation: 1.756317758956582]
	TIME [epoch: 5.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256864026196284		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 3.256864026196284 | validation: 1.6654993520125545]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.188902267951665		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 3.188902267951665 | validation: 1.662449983943283]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1705155032261647		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 3.1705155032261647 | validation: 1.7822152606780366]
	TIME [epoch: 5.72 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2840406799490482		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 3.2840406799490482 | validation: 1.7068453114682354]
	TIME [epoch: 5.75 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.348562409760026		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 3.348562409760026 | validation: 2.05950672677159]
	TIME [epoch: 5.73 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3054091219964308		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 3.3054091219964308 | validation: 1.8279109653177457]
	TIME [epoch: 5.72 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2936422765291753		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 3.2936422765291753 | validation: 1.7743128617776254]
	TIME [epoch: 5.72 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253211807936365		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 3.253211807936365 | validation: 1.8187510980655879]
	TIME [epoch: 5.72 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246369979073255		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 3.246369979073255 | validation: 1.670757475773558]
	TIME [epoch: 5.72 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2188851339565003		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 3.2188851339565003 | validation: 1.778709315781122]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3303365249634163		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 3.3303365249634163 | validation: 1.6694131692660674]
	TIME [epoch: 5.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2158385996253944		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 3.2158385996253944 | validation: 1.7278892946898492]
	TIME [epoch: 5.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228141615649244		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 3.228141615649244 | validation: 1.6607755500047756]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3016012653001985		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.3016012653001985 | validation: 1.7560718860047855]
	TIME [epoch: 5.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227122996446108		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 3.227122996446108 | validation: 1.6536548264995259]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2333498668095		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 3.2333498668095 | validation: 1.9584594774264361]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258477930301285		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 3.258477930301285 | validation: 1.6545854120887413]
	TIME [epoch: 5.73 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219200129101748		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 3.219200129101748 | validation: 1.8156245707568457]
	TIME [epoch: 5.72 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230720945264401		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 3.230720945264401 | validation: 1.6825704822834637]
	TIME [epoch: 5.72 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256065522133531		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 3.256065522133531 | validation: 1.6991005430899557]
	TIME [epoch: 5.72 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296766334874545		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 3.296766334874545 | validation: 1.7139358421047213]
	TIME [epoch: 5.72 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166575921372741		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 3.166575921372741 | validation: 1.6858838410681203]
	TIME [epoch: 5.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276462159472265		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 3.276462159472265 | validation: 1.6813842377485346]
	TIME [epoch: 5.73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2242595073697355		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 3.2242595073697355 | validation: 1.6531577485011164]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.170891105306656		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 3.170891105306656 | validation: 1.7115039308793076]
	TIME [epoch: 5.72 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296244772575416		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 3.296244772575416 | validation: 2.237722078803352]
	TIME [epoch: 5.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3329568793411433		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 3.3329568793411433 | validation: 1.7178460215640954]
	TIME [epoch: 5.71 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1780811109587006		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 3.1780811109587006 | validation: 1.6289206591709686]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2153231258299244		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 3.2153231258299244 | validation: 1.6591074581895071]
	TIME [epoch: 5.73 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1931824592576326		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 3.1931824592576326 | validation: 1.6379856168538056]
	TIME [epoch: 5.72 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2348143513889047		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 3.2348143513889047 | validation: 1.7339801851635377]
	TIME [epoch: 5.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1320060885034597		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 3.1320060885034597 | validation: 1.7038628968538103]
	TIME [epoch: 5.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1149316028502003		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 3.1149316028502003 | validation: 1.5993940884763493]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.110746915354233		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 3.110746915354233 | validation: 1.730693456787372]
	TIME [epoch: 5.74 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.096745354713377		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 3.096745354713377 | validation: 1.9468918722695363]
	TIME [epoch: 5.72 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.171805306384326		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 3.171805306384326 | validation: 1.587907910866503]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1021933459987014		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 3.1021933459987014 | validation: 1.581489541134851]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.04629259553632		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 3.04629259553632 | validation: 1.5811253840249213]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.024178632324235		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 3.024178632324235 | validation: 1.621455754513591]
	TIME [epoch: 5.71 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0712178583175014		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 3.0712178583175014 | validation: 1.610528153843618]
	TIME [epoch: 5.76 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9989998886591627		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 2.9989998886591627 | validation: 1.5501208244121716]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9450547759511307		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.9450547759511307 | validation: 1.516072571066857]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8198698781084235		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 2.8198698781084235 | validation: 1.3975031397566369]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.497145904779204		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 2.497145904779204 | validation: 1.2879894915537011]
	TIME [epoch: 5.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3551368211493116		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.3551368211493116 | validation: 1.3222048059358857]
	TIME [epoch: 5.76 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9616037151462686		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.9616037151462686 | validation: 1.0454708141872782]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4172099761409571		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.4172099761409571 | validation: 0.6419147886113429]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0893614816122195		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.0893614816122195 | validation: 0.5441897687807228]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9231433753225705		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.9231433753225705 | validation: 0.7709103604974016]
	TIME [epoch: 5.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084010735907776		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.084010735907776 | validation: 0.5881894828909414]
	TIME [epoch: 5.72 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.410890657736037		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.410890657736037 | validation: 0.4407570401446895]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1902164253119265		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.1902164253119265 | validation: 0.71410841590572]
	TIME [epoch: 5.71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178239064875579		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.178239064875579 | validation: 0.7348075332579522]
	TIME [epoch: 5.72 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.863660742838347		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.863660742838347 | validation: 1.0999994064797052]
	TIME [epoch: 5.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0824768193266874		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.0824768193266874 | validation: 0.8391684198279389]
	TIME [epoch: 5.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0517289217047794		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.0517289217047794 | validation: 0.7524319216468536]
	TIME [epoch: 5.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8157747415267211		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8157747415267211 | validation: 0.9773981157227806]
	TIME [epoch: 5.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022174929986915		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.022174929986915 | validation: 0.8439202416781906]
	TIME [epoch: 5.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8850120539371744		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.8850120539371744 | validation: 0.5111010821230673]
	TIME [epoch: 5.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060307105685422		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7060307105685422 | validation: 0.5731548961272457]
	TIME [epoch: 5.72 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6196265333118285		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.6196265333118285 | validation: 0.9622830203112748]
	TIME [epoch: 5.72 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7850213041065803		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7850213041065803 | validation: 0.4805577862765618]
	TIME [epoch: 5.72 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814016854520918		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5814016854520918 | validation: 0.8374721460784664]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112361166220925		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7112361166220925 | validation: 0.3982811030721689]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319543625681645		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5319543625681645 | validation: 0.48159366763709544]
	TIME [epoch: 5.72 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473601819654196		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5473601819654196 | validation: 0.46331629294421717]
	TIME [epoch: 5.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49882034757774496		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.49882034757774496 | validation: 0.6209370781877934]
	TIME [epoch: 5.72 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888296966109847		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5888296966109847 | validation: 0.4144811740242345]
	TIME [epoch: 5.72 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331438705985195		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5331438705985195 | validation: 0.6267461053863757]
	TIME [epoch: 5.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756596141092374		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.5756596141092374 | validation: 0.3568692205893486]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641241512054439		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5641241512054439 | validation: 0.4163483377797821]
	TIME [epoch: 5.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46666230286959354		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.46666230286959354 | validation: 0.4769360279742055]
	TIME [epoch: 5.72 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511740405503354		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.511740405503354 | validation: 0.4225877285756644]
	TIME [epoch: 5.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520971368977904		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6520971368977904 | validation: 0.358078284827773]
	TIME [epoch: 5.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506301740975833		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.4506301740975833 | validation: 0.32488958609473306]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49051585800588515		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.49051585800588515 | validation: 0.26739856491448427]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42973012213503414		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.42973012213503414 | validation: 0.39469208257139343]
	TIME [epoch: 5.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508526277750379		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5508526277750379 | validation: 0.3468393110916671]
	TIME [epoch: 5.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5160241898391147		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5160241898391147 | validation: 0.5075427381300831]
	TIME [epoch: 5.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681693458482853		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4681693458482853 | validation: 0.47614468033614105]
	TIME [epoch: 5.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40066357646692674		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.40066357646692674 | validation: 0.4424990371416243]
	TIME [epoch: 5.74 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4123243616218875		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4123243616218875 | validation: 0.40305352445712006]
	TIME [epoch: 5.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44251647786153686		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.44251647786153686 | validation: 0.4823150840134947]
	TIME [epoch: 5.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736213160673285		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.4736213160673285 | validation: 0.2971407552244998]
	TIME [epoch: 5.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43325945663830495		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.43325945663830495 | validation: 0.33014197874196544]
	TIME [epoch: 5.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37909326284685174		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.37909326284685174 | validation: 0.31879029649106827]
	TIME [epoch: 5.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4433216129753928		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4433216129753928 | validation: 0.42176318044058436]
	TIME [epoch: 5.76 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139073434907133		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.4139073434907133 | validation: 0.4253685430510539]
	TIME [epoch: 5.73 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343917064926358		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.4343917064926358 | validation: 0.35512258894286997]
	TIME [epoch: 5.72 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41606915016086354		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.41606915016086354 | validation: 0.5844318490153395]
	TIME [epoch: 5.72 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5618873558173421		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5618873558173421 | validation: 0.36589372369550405]
	TIME [epoch: 5.72 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732554239015041		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3732554239015041 | validation: 0.46941199286440893]
	TIME [epoch: 5.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472346695955414		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.472346695955414 | validation: 0.29761576821273095]
	TIME [epoch: 5.76 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933543175883846		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3933543175883846 | validation: 0.4537167911408622]
	TIME [epoch: 5.73 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6115069849460006		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.6115069849460006 | validation: 0.550154890689066]
	TIME [epoch: 5.72 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645155835662552		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5645155835662552 | validation: 0.3976913675268689]
	TIME [epoch: 5.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057498164682555		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5057498164682555 | validation: 0.29268367148009333]
	TIME [epoch: 5.72 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4142819879427453		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.4142819879427453 | validation: 0.275994055098457]
	TIME [epoch: 5.72 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4149457779897076		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.4149457779897076 | validation: 0.5005103394829484]
	TIME [epoch: 5.76 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629973660565494		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4629973660565494 | validation: 0.2656116823870127]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4786961643933447		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4786961643933447 | validation: 0.3142286987469123]
	TIME [epoch: 5.72 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820618249693574		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.4820618249693574 | validation: 0.3304271556449794]
	TIME [epoch: 5.72 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489105140464267		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.4489105140464267 | validation: 0.42351384571419914]
	TIME [epoch: 5.72 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542041526603319		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.542041526603319 | validation: 0.3996648529525523]
	TIME [epoch: 5.72 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4110778925076366		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4110778925076366 | validation: 0.3139733608335926]
	TIME [epoch: 5.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372587872354532		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5372587872354532 | validation: 0.2813866535359628]
	TIME [epoch: 5.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37675643262597375		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.37675643262597375 | validation: 0.357937847595487]
	TIME [epoch: 5.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880127026097393		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3880127026097393 | validation: 0.32587158650263065]
	TIME [epoch: 5.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37690837440640756		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.37690837440640756 | validation: 0.5424040501498886]
	TIME [epoch: 5.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565463067571318		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4565463067571318 | validation: 0.26061466712167297]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056457520540436		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.3056457520540436 | validation: 0.24760738117375625]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743492622721236		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3743492622721236 | validation: 0.45006435604073713]
	TIME [epoch: 5.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375986986659044		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4375986986659044 | validation: 0.3917476763958264]
	TIME [epoch: 5.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44589515303980576		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.44589515303980576 | validation: 0.42737275380825224]
	TIME [epoch: 5.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39004038976058764		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.39004038976058764 | validation: 0.23589965457950776]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36799159008201976		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.36799159008201976 | validation: 0.31080868094078934]
	TIME [epoch: 5.73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30774808163270134		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.30774808163270134 | validation: 0.3044367769192354]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552933216356143		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.3552933216356143 | validation: 0.3611761919138574]
	TIME [epoch: 5.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31261320532804393		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.31261320532804393 | validation: 0.4188806039916529]
	TIME [epoch: 5.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4228903634864923		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.4228903634864923 | validation: 0.4216785157648906]
	TIME [epoch: 5.72 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34809442684879965		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.34809442684879965 | validation: 0.4192445177666578]
	TIME [epoch: 5.72 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978898906444014		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3978898906444014 | validation: 0.3427619500535186]
	TIME [epoch: 5.73 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676500957536655		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3676500957536655 | validation: 0.3423278020083867]
	TIME [epoch: 5.75 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094451070254741		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4094451070254741 | validation: 0.2764848440769834]
	TIME [epoch: 5.72 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32640359208281133		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.32640359208281133 | validation: 0.3877258485544286]
	TIME [epoch: 5.72 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326053218455335		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.326053218455335 | validation: 0.35809576789086595]
	TIME [epoch: 5.72 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38308373585438227		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.38308373585438227 | validation: 0.36861093148472457]
	TIME [epoch: 5.72 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228331106519514		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.3228331106519514 | validation: 0.2541092935869705]
	TIME [epoch: 5.73 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312397736263919		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3312397736263919 | validation: 0.29936832543037345]
	TIME [epoch: 5.75 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39790004379017163		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.39790004379017163 | validation: 0.2913283889384156]
	TIME [epoch: 5.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354461818584462		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.354461818584462 | validation: 0.26239394420308026]
	TIME [epoch: 5.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215807862603358		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3215807862603358 | validation: 0.32459306735224525]
	TIME [epoch: 5.72 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41171301324088605		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.41171301324088605 | validation: 0.3948397974334013]
	TIME [epoch: 5.72 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088605989952698		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3088605989952698 | validation: 0.25550505846912364]
	TIME [epoch: 5.73 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3004028163049025		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3004028163049025 | validation: 0.3073401090513846]
	TIME [epoch: 5.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2702656778150231		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.2702656778150231 | validation: 0.2887250972331483]
	TIME [epoch: 5.73 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31559107400749203		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.31559107400749203 | validation: 0.26937149513314895]
	TIME [epoch: 5.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3325348724245956		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3325348724245956 | validation: 0.32871752809460375]
	TIME [epoch: 5.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850422846415393		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6850422846415393 | validation: 0.8109433646971684]
	TIME [epoch: 5.72 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298154432981715		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4298154432981715 | validation: 0.2361970571257703]
	TIME [epoch: 5.72 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093659690156497		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3093659690156497 | validation: 0.5905235831025855]
	TIME [epoch: 5.75 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44075355094737106		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.44075355094737106 | validation: 0.1936764938881241]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24229184744831878		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.24229184744831878 | validation: 0.22279544458966805]
	TIME [epoch: 5.72 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26146048391802534		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.26146048391802534 | validation: 0.17085056324528075]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826157203024503		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.2826157203024503 | validation: 0.2274882920754414]
	TIME [epoch: 5.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689887130804304		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.2689887130804304 | validation: 0.25044741811322374]
	TIME [epoch: 5.72 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33568093725364323		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.33568093725364323 | validation: 0.1956842931191949]
	TIME [epoch: 5.73 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28844221449019924		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.28844221449019924 | validation: 0.206623467546578]
	TIME [epoch: 5.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408839374922339		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.2408839374922339 | validation: 0.2591667329092603]
	TIME [epoch: 5.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38164656184389745		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.38164656184389745 | validation: 0.3540777100774213]
	TIME [epoch: 5.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501559446347889		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3501559446347889 | validation: 0.23724568758375725]
	TIME [epoch: 5.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857888195193314		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2857888195193314 | validation: 0.1942677385330488]
	TIME [epoch: 5.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29452358565340886		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.29452358565340886 | validation: 0.18915580569445056]
	TIME [epoch: 5.73 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2617016949738293		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.2617016949738293 | validation: 0.26456803625589986]
	TIME [epoch: 5.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21564723295514468		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.21564723295514468 | validation: 0.3044870278393745]
	TIME [epoch: 5.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26825475503040586		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.26825475503040586 | validation: 0.2614179384518005]
	TIME [epoch: 5.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25958484473992177		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.25958484473992177 | validation: 0.6496143211927722]
	TIME [epoch: 5.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497308022401525		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.497308022401525 | validation: 0.5781673322566586]
	TIME [epoch: 5.72 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38604858286875926		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.38604858286875926 | validation: 0.22403261915924375]
	TIME [epoch: 5.73 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26860999694237764		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.26860999694237764 | validation: 0.3204343876182096]
	TIME [epoch: 5.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939902424767882		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2939902424767882 | validation: 0.18917074344862328]
	TIME [epoch: 5.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253595781318333		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.253595781318333 | validation: 0.17252290501029727]
	TIME [epoch: 5.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846501672675005		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2846501672675005 | validation: 0.15475889651133895]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23926844003849235		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.23926844003849235 | validation: 0.25582469201394276]
	TIME [epoch: 5.72 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167266708652483		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6167266708652483 | validation: 1.0356134441921703]
	TIME [epoch: 5.73 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45117315805775293		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.45117315805775293 | validation: 0.203683797072659]
	TIME [epoch: 5.72 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658849149738597		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2658849149738597 | validation: 0.48005988838243696]
	TIME [epoch: 5.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4030278275136279		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4030278275136279 | validation: 0.2607144589649523]
	TIME [epoch: 5.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24744127771337188		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.24744127771337188 | validation: 0.3203341007939403]
	TIME [epoch: 5.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26105244202042277		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.26105244202042277 | validation: 0.19612684396576613]
	TIME [epoch: 5.71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23729479257178085		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.23729479257178085 | validation: 0.2578359475654658]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23287656359892317		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.23287656359892317 | validation: 0.23563342845178564]
	TIME [epoch: 5.72 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34820571731305316		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.34820571731305316 | validation: 0.2228282620013868]
	TIME [epoch: 5.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24994610523710514		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.24994610523710514 | validation: 0.2564837265438643]
	TIME [epoch: 5.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29564149974024223		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.29564149974024223 | validation: 0.18057945266925327]
	TIME [epoch: 5.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22922660531064543		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.22922660531064543 | validation: 0.20517464339018482]
	TIME [epoch: 5.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24189998906059612		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.24189998906059612 | validation: 0.2616907576670046]
	TIME [epoch: 5.73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21973996288791722		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.21973996288791722 | validation: 0.21418943644125996]
	TIME [epoch: 5.72 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20198866001732219		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.20198866001732219 | validation: 0.31520229980047065]
	TIME [epoch: 5.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22221731161725322		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.22221731161725322 | validation: 0.17420856656489378]
	TIME [epoch: 5.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20246595289838254		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.20246595289838254 | validation: 0.39875205683032755]
	TIME [epoch: 5.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29408048872198345		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.29408048872198345 | validation: 0.3222058006666218]
	TIME [epoch: 5.71 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077411104643838		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.2077411104643838 | validation: 0.14950370737457322]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114410553497083		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2114410553497083 | validation: 0.21907545218481395]
	TIME [epoch: 5.72 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25537293549036527		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.25537293549036527 | validation: 0.2778827336566774]
	TIME [epoch: 5.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199983557802418		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.2199983557802418 | validation: 0.3663254626877368]
	TIME [epoch: 5.71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29351604553050104		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.29351604553050104 | validation: 0.4960202000903864]
	TIME [epoch: 5.71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26618122387394083		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.26618122387394083 | validation: 0.24632006685658753]
	TIME [epoch: 5.71 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4334734320168496		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.4334734320168496 | validation: 0.238527967796218]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547147269879533		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.2547147269879533 | validation: 0.16791734246455906]
	TIME [epoch: 5.71 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964678003778935		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.1964678003778935 | validation: 0.15494632897443691]
	TIME [epoch: 5.71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988688295967003		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.19988688295967003 | validation: 0.22809510478250503]
	TIME [epoch: 5.72 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191800424410524		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2191800424410524 | validation: 0.17973609157131748]
	TIME [epoch: 5.71 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2249695863309711		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2249695863309711 | validation: 0.35452454567863373]
	TIME [epoch: 5.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203057942020327		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2203057942020327 | validation: 0.15423820418865006]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24069096602597864		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.24069096602597864 | validation: 0.15050111313185102]
	TIME [epoch: 5.72 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19040885542177666		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.19040885542177666 | validation: 0.34211452543334486]
	TIME [epoch: 5.71 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676434010545673		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.2676434010545673 | validation: 0.19969149789527899]
	TIME [epoch: 5.71 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24691018558262293		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.24691018558262293 | validation: 0.16266778864411627]
	TIME [epoch: 5.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963548983818487		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1963548983818487 | validation: 0.18267078767645323]
	TIME [epoch: 5.71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086798544327539		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2086798544327539 | validation: 0.3422441814017192]
	TIME [epoch: 5.75 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23980995643847086		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.23980995643847086 | validation: 0.21290114533615548]
	TIME [epoch: 5.71 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832113482305842		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.1832113482305842 | validation: 0.195618315458201]
	TIME [epoch: 5.71 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20802749417454697		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.20802749417454697 | validation: 0.269881493758882]
	TIME [epoch: 5.71 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20705654429748419		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.20705654429748419 | validation: 0.15519815309168494]
	TIME [epoch: 5.71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17632693521485454		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.17632693521485454 | validation: 0.19526171819786625]
	TIME [epoch: 5.71 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3729978560275672		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.3729978560275672 | validation: 0.22932173452273347]
	TIME [epoch: 5.75 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20150052369673058		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.20150052369673058 | validation: 0.18960344717157646]
	TIME [epoch: 5.71 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573869037669165		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.17573869037669165 | validation: 0.15938373049236318]
	TIME [epoch: 5.72 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17233502746461896		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.17233502746461896 | validation: 0.11516984576111945]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22345120642369584		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.22345120642369584 | validation: 0.15294385927097312]
	TIME [epoch: 5.71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871487340126834		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.1871487340126834 | validation: 0.29763506503775844]
	TIME [epoch: 5.72 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29589084461351456		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.29589084461351456 | validation: 0.20632159427612742]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945404426272035		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2945404426272035 | validation: 0.20399100143690527]
	TIME [epoch: 5.71 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320187078727139		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2320187078727139 | validation: 0.22286905480230956]
	TIME [epoch: 5.72 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24542931436106		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.24542931436106 | validation: 0.16276147275177277]
	TIME [epoch: 5.72 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23152663552099864		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.23152663552099864 | validation: 0.2767960580440348]
	TIME [epoch: 5.72 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263686060422482		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.263686060422482 | validation: 0.2605715217148486]
	TIME [epoch: 5.72 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16714999698633723		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.16714999698633723 | validation: 0.18701829631376077]
	TIME [epoch: 5.74 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890133993892028		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.1890133993892028 | validation: 0.4117490685859505]
	TIME [epoch: 5.71 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947601293920454		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.2947601293920454 | validation: 0.23439486029499834]
	TIME [epoch: 5.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22289681727440405		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.22289681727440405 | validation: 0.1817862546995941]
	TIME [epoch: 5.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26570542381623397		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.26570542381623397 | validation: 0.5504814829878688]
	TIME [epoch: 5.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2966300131910353		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2966300131910353 | validation: 0.12798922330731696]
	TIME [epoch: 5.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16866476681234854		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.16866476681234854 | validation: 0.2698323988923567]
	TIME [epoch: 5.76 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23824596984548627		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.23824596984548627 | validation: 0.2164712104738762]
	TIME [epoch: 5.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18837513330726371		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.18837513330726371 | validation: 0.2434458567187972]
	TIME [epoch: 5.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19347036002068702		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.19347036002068702 | validation: 0.28330161359752587]
	TIME [epoch: 5.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962826370443599		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1962826370443599 | validation: 0.13981601960165596]
	TIME [epoch: 5.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733760096622697		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1733760096622697 | validation: 0.19898734416916597]
	TIME [epoch: 5.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2261094827768145		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2261094827768145 | validation: 0.2195486332065176]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19657391830245433		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.19657391830245433 | validation: 0.23475130840086128]
	TIME [epoch: 5.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18969176146480765		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.18969176146480765 | validation: 0.260520986490036]
	TIME [epoch: 5.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240036635798011		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.2240036635798011 | validation: 0.34150095436022526]
	TIME [epoch: 5.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2478402443194387		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.2478402443194387 | validation: 0.2518848177695893]
	TIME [epoch: 5.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21767090213667137		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.21767090213667137 | validation: 0.3100187806341593]
	TIME [epoch: 5.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23553243797929196		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.23553243797929196 | validation: 0.12642403367835006]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16697371707956282		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.16697371707956282 | validation: 0.1861435691246948]
	TIME [epoch: 5.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949027267930915		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.2949027267930915 | validation: 0.184863889085844]
	TIME [epoch: 5.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16229194769690183		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.16229194769690183 | validation: 0.12265159795490899]
	TIME [epoch: 5.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570454237388621		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1570454237388621 | validation: 0.18024618120962266]
	TIME [epoch: 5.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924152301004277		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1924152301004277 | validation: 0.2458015105240765]
	TIME [epoch: 5.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841964031313787		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1841964031313787 | validation: 0.2331281390975078]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169714630586565		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.16169714630586565 | validation: 0.26426729646847297]
	TIME [epoch: 5.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20216486410773515		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.20216486410773515 | validation: 0.1688307248557339]
	TIME [epoch: 5.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958185375934573		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1958185375934573 | validation: 0.2444151947342224]
	TIME [epoch: 5.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16461724139661044		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.16461724139661044 | validation: 0.16803718479189728]
	TIME [epoch: 5.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14317952643053933		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.14317952643053933 | validation: 0.3392913385295404]
	TIME [epoch: 5.72 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19568911256720264		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.19568911256720264 | validation: 0.1109470530853838]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_563.pth
	Model improved!!!
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669932274506396		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.12669932274506396 | validation: 0.15301398459921536]
	TIME [epoch: 5.72 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461947790628783		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1461947790628783 | validation: 0.28050793634286253]
	TIME [epoch: 5.72 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1667902564268164		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.1667902564268164 | validation: 0.165881666728761]
	TIME [epoch: 5.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17624655480694162		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.17624655480694162 | validation: 0.1575995432268324]
	TIME [epoch: 5.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17302734958796392		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.17302734958796392 | validation: 0.20844619074841875]
	TIME [epoch: 5.72 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26955189780913325		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.26955189780913325 | validation: 0.12207929940805656]
	TIME [epoch: 5.76 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.214304076968176		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.214304076968176 | validation: 0.25244447216012195]
	TIME [epoch: 5.72 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18170213774013202		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.18170213774013202 | validation: 0.11134368267616683]
	TIME [epoch: 5.72 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16190611955419001		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.16190611955419001 | validation: 0.1603345991863889]
	TIME [epoch: 5.72 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1511811636306774		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.1511811636306774 | validation: 0.3662920279541461]
	TIME [epoch: 5.72 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25506245505020314		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.25506245505020314 | validation: 0.22146742292000776]
	TIME [epoch: 5.72 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837052640406102		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1837052640406102 | validation: 0.14318565411731293]
	TIME [epoch: 5.76 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22684468905880398		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.22684468905880398 | validation: 0.30386361805207]
	TIME [epoch: 5.72 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18972805597352274		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.18972805597352274 | validation: 0.12816644400422889]
	TIME [epoch: 5.72 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13158272840004165		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.13158272840004165 | validation: 0.163996155114932]
	TIME [epoch: 5.72 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434239649706038		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.17434239649706038 | validation: 0.1457448184061752]
	TIME [epoch: 5.72 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597903906580162		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1597903906580162 | validation: 0.16323530403898723]
	TIME [epoch: 5.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130341423550737		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.13130341423550737 | validation: 0.13624733358343633]
	TIME [epoch: 5.76 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17767558746604245		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.17767558746604245 | validation: 0.22136420485570557]
	TIME [epoch: 5.72 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15667274216640512		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.15667274216640512 | validation: 0.13049872321223263]
	TIME [epoch: 5.72 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12888248438912941		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.12888248438912941 | validation: 0.10582183046040332]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256815567903702		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1256815567903702 | validation: 0.2915121521943213]
	TIME [epoch: 5.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16883236803920007		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.16883236803920007 | validation: 0.1498608266186081]
	TIME [epoch: 5.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1864984766159971		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.1864984766159971 | validation: 0.176546148248825]
	TIME [epoch: 5.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190272886812276		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.13190272886812276 | validation: 0.09380268142046909]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21388161984022475		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.21388161984022475 | validation: 0.2797735121156741]
	TIME [epoch: 5.71 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19025576065460698		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.19025576065460698 | validation: 0.1572104888958993]
	TIME [epoch: 5.71 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21549636299157632		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.21549636299157632 | validation: 0.10709637351932419]
	TIME [epoch: 5.71 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244823293550392		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.19244823293550392 | validation: 0.20682169865595043]
	TIME [epoch: 5.71 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15303305974780373		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.15303305974780373 | validation: 0.1165864232322307]
	TIME [epoch: 5.75 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366144577896303		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1366144577896303 | validation: 0.1035260616867087]
	TIME [epoch: 5.72 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14623193064532183		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.14623193064532183 | validation: 0.1125973406245991]
	TIME [epoch: 5.71 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288092478454238		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.12288092478454238 | validation: 0.19316230913129814]
	TIME [epoch: 5.71 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956240654329613		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.1956240654329613 | validation: 0.258132329834935]
	TIME [epoch: 5.71 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046941643965683		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.2046941643965683 | validation: 0.1269199802116663]
	TIME [epoch: 5.72 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16551341855898788		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.16551341855898788 | validation: 0.19912262039073284]
	TIME [epoch: 5.75 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511395968905158		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2511395968905158 | validation: 0.11828326163165898]
	TIME [epoch: 5.72 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20052439938967503		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.20052439938967503 | validation: 0.18771963612930734]
	TIME [epoch: 5.72 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472387641648887		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1472387641648887 | validation: 0.27055700129255245]
	TIME [epoch: 5.71 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16793393550628857		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.16793393550628857 | validation: 0.14732260409310569]
	TIME [epoch: 5.72 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2399559080698137		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.2399559080698137 | validation: 0.12246148848474528]
	TIME [epoch: 5.72 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12250028808503223		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.12250028808503223 | validation: 0.11617528596823729]
	TIME [epoch: 5.75 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16676992733100673		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.16676992733100673 | validation: 0.1318437572701402]
	TIME [epoch: 5.72 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146032161582711		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.146032161582711 | validation: 0.1396693128308479]
	TIME [epoch: 5.72 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16672891575320775		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.16672891575320775 | validation: 0.13945349348446953]
	TIME [epoch: 5.71 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12437822033699406		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.12437822033699406 | validation: 0.11113097533615018]
	TIME [epoch: 5.72 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083541989313243		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.12083541989313243 | validation: 0.30295408394466317]
	TIME [epoch: 5.72 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955779886090916		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.19955779886090916 | validation: 0.11989665791379255]
	TIME [epoch: 5.75 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12989778447519235		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.12989778447519235 | validation: 0.3359338122492862]
	TIME [epoch: 5.72 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17313795793660253		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.17313795793660253 | validation: 0.15681481935747674]
	TIME [epoch: 5.71 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962278947226376		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.11962278947226376 | validation: 0.20018063323304103]
	TIME [epoch: 5.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17240357989388075		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.17240357989388075 | validation: 0.19483741083451744]
	TIME [epoch: 5.72 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36348226726580857		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.36348226726580857 | validation: 0.1212914525011941]
	TIME [epoch: 5.72 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554098340083253		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.15554098340083253 | validation: 0.286658155089174]
	TIME [epoch: 5.75 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18346080304827533		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.18346080304827533 | validation: 0.20503578088202218]
	TIME [epoch: 5.72 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16316436044596566		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.16316436044596566 | validation: 0.1132883478825532]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10638515627481304		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.10638515627481304 | validation: 0.12520579997532758]
	TIME [epoch: 5.72 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21006612913759257		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.21006612913759257 | validation: 0.2816406943014633]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671740460044365		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1671740460044365 | validation: 0.17116512985650523]
	TIME [epoch: 5.72 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13716787484468884		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.13716787484468884 | validation: 0.268798333315675]
	TIME [epoch: 5.75 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18191122967395218		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.18191122967395218 | validation: 0.13131301078449034]
	TIME [epoch: 5.72 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20677072513046874		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.20677072513046874 | validation: 0.20031742869900498]
	TIME [epoch: 5.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727529899546391		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1727529899546391 | validation: 0.17692701786834086]
	TIME [epoch: 5.71 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17805849664116305		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.17805849664116305 | validation: 0.10306804674229415]
	TIME [epoch: 5.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21110547381087003		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.21110547381087003 | validation: 0.22345256197511806]
	TIME [epoch: 5.71 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16641754159857344		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.16641754159857344 | validation: 0.10358123140071897]
	TIME [epoch: 5.75 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698389215935196		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.12698389215935196 | validation: 0.13700316718394218]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883366868369135		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.13883366868369135 | validation: 0.13081303070421194]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13884869299243477		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.13884869299243477 | validation: 0.1522518392065375]
	TIME [epoch: 5.72 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12107643642888644		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.12107643642888644 | validation: 0.1648216198898881]
	TIME [epoch: 5.72 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18817264154277885		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.18817264154277885 | validation: 0.1559406028993648]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20214766886846403		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.20214766886846403 | validation: 0.36582760843485745]
	TIME [epoch: 5.75 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23069861845511325		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.23069861845511325 | validation: 0.10636071193861714]
	TIME [epoch: 5.72 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13737366873769738		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.13737366873769738 | validation: 0.12220932845992354]
	TIME [epoch: 5.72 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452251335128028		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.10452251335128028 | validation: 0.1406973803627123]
	TIME [epoch: 5.72 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12472150760996002		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.12472150760996002 | validation: 0.10378320211968277]
	TIME [epoch: 5.71 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11666384174144326		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.11666384174144326 | validation: 0.264844608946094]
	TIME [epoch: 5.72 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20259236807898084		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.20259236807898084 | validation: 0.17867837220662064]
	TIME [epoch: 5.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12911609906548627		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.12911609906548627 | validation: 0.11501763764855913]
	TIME [epoch: 5.72 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11218680555600093		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.11218680555600093 | validation: 0.32057329808478907]
	TIME [epoch: 5.72 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16014199045260388		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.16014199045260388 | validation: 0.1738644834986444]
	TIME [epoch: 5.71 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11487096231284694		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.11487096231284694 | validation: 0.1357272413029138]
	TIME [epoch: 5.72 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12141504416256015		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.12141504416256015 | validation: 0.14041572937869495]
	TIME [epoch: 5.72 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12102026586588245		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.12102026586588245 | validation: 0.11578601930724315]
	TIME [epoch: 5.75 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12690284129807639		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.12690284129807639 | validation: 0.14767454353253137]
	TIME [epoch: 5.72 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977890441294471		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.09977890441294471 | validation: 0.07910444577700025]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465357098403795		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.12465357098403795 | validation: 0.13370444202835502]
	TIME [epoch: 5.71 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353151017062207		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.10353151017062207 | validation: 0.12002877393717651]
	TIME [epoch: 5.71 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14590045314989936		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.14590045314989936 | validation: 0.10832799249314715]
	TIME [epoch: 5.71 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323248406266861		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1323248406266861 | validation: 0.12000283187045639]
	TIME [epoch: 5.75 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288041114549554		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1288041114549554 | validation: 0.13407561777492596]
	TIME [epoch: 5.72 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481691010889788		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1481691010889788 | validation: 0.17841054783640747]
	TIME [epoch: 5.71 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13426669265081392		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.13426669265081392 | validation: 0.18584648217057598]
	TIME [epoch: 5.71 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408829163564451		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1408829163564451 | validation: 0.10906497867178477]
	TIME [epoch: 5.71 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249654621737661		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.1249654621737661 | validation: 0.12680049621745565]
	TIME [epoch: 5.71 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10784178831349142		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.10784178831349142 | validation: 0.11675177081817972]
	TIME [epoch: 5.75 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15837622425503564		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15837622425503564 | validation: 0.1550059027952761]
	TIME [epoch: 5.72 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135595866027866		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.12135595866027866 | validation: 0.12147951670862575]
	TIME [epoch: 5.71 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14094807354203423		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.14094807354203423 | validation: 0.12180207785488101]
	TIME [epoch: 5.71 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659880101312239		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.09659880101312239 | validation: 0.23923133392824236]
	TIME [epoch: 5.71 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17002699798083706		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.17002699798083706 | validation: 0.08822035032586595]
	TIME [epoch: 5.71 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210448320259846		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.10210448320259846 | validation: 0.06750939720223491]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09381884830101825		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.09381884830101825 | validation: 0.10310112406130387]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10266758918994448		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.10266758918994448 | validation: 0.07381544887081042]
	TIME [epoch: 5.71 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620916914709104		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.09620916914709104 | validation: 0.0803474477343577]
	TIME [epoch: 5.71 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08950196711656805		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.08950196711656805 | validation: 0.2353967039672817]
	TIME [epoch: 5.71 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551622237616183		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1551622237616183 | validation: 0.17645573427419925]
	TIME [epoch: 5.71 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11361783548889783		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.11361783548889783 | validation: 0.1692235908740691]
	TIME [epoch: 5.75 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16452552440018375		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.16452552440018375 | validation: 0.11370714937622511]
	TIME [epoch: 5.72 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12200885923574256		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.12200885923574256 | validation: 0.14355967980898388]
	TIME [epoch: 5.71 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11268329399155198		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.11268329399155198 | validation: 0.1380367409572031]
	TIME [epoch: 5.71 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10927854524221323		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10927854524221323 | validation: 0.0944634543854884]
	TIME [epoch: 5.71 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750046871235086		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10750046871235086 | validation: 0.11458656257067273]
	TIME [epoch: 5.71 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12866264817694223		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.12866264817694223 | validation: 0.20804583628824191]
	TIME [epoch: 5.75 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512094827095808		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1512094827095808 | validation: 0.11174106970418858]
	TIME [epoch: 5.71 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914683680874267		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.0914683680874267 | validation: 0.09622760993647429]
	TIME [epoch: 5.71 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09520916744308201		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.09520916744308201 | validation: 0.08258182062345416]
	TIME [epoch: 5.71 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497200454766943		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.11497200454766943 | validation: 0.13433077893752599]
	TIME [epoch: 5.71 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704177980219306		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.12704177980219306 | validation: 0.12501982776611686]
	TIME [epoch: 5.71 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15845029547455844		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.15845029547455844 | validation: 0.14700570343018915]
	TIME [epoch: 5.75 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14154071957403735		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.14154071957403735 | validation: 0.15180408200135403]
	TIME [epoch: 5.72 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927459976163149		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11927459976163149 | validation: 0.15637284357552197]
	TIME [epoch: 5.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121507835285709		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1121507835285709 | validation: 0.10537953281532815]
	TIME [epoch: 5.71 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13028017177301301		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.13028017177301301 | validation: 0.10262193434709552]
	TIME [epoch: 5.71 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526949031385943		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.1526949031385943 | validation: 0.0897746290566706]
	TIME [epoch: 5.71 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09750218120003407		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.09750218120003407 | validation: 0.1574910451035689]
	TIME [epoch: 5.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10972786843045634		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.10972786843045634 | validation: 0.10393583055682036]
	TIME [epoch: 5.72 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08571604255939487		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.08571604255939487 | validation: 0.12959226468037857]
	TIME [epoch: 5.71 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261626240056936		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.1261626240056936 | validation: 0.16406109042942857]
	TIME [epoch: 5.71 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503116517719987		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.12503116517719987 | validation: 0.1006687357904869]
	TIME [epoch: 5.71 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261350977704476		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.11261350977704476 | validation: 0.08917730080574784]
	TIME [epoch: 5.71 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14496380830166933		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.14496380830166933 | validation: 0.13649553190193944]
	TIME [epoch: 5.75 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10965019742644544		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.10965019742644544 | validation: 0.11175465085978681]
	TIME [epoch: 5.72 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11653601207022957		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.11653601207022957 | validation: 0.11543587476166726]
	TIME [epoch: 5.71 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13094729083957987		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.13094729083957987 | validation: 0.1151550521900435]
	TIME [epoch: 5.71 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757003243407677		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.12757003243407677 | validation: 0.11909100057014105]
	TIME [epoch: 5.71 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10473964495704743		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.10473964495704743 | validation: 0.13664090817100902]
	TIME [epoch: 5.71 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344503690006381		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1344503690006381 | validation: 0.220695919796932]
	TIME [epoch: 5.75 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960249925388203		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1960249925388203 | validation: 0.30442821048259194]
	TIME [epoch: 5.71 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532136889839337		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.1532136889839337 | validation: 0.15834753020404793]
	TIME [epoch: 5.71 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12253618096815558		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.12253618096815558 | validation: 0.17887959055674757]
	TIME [epoch: 5.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14052410806068252		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.14052410806068252 | validation: 0.12064622256768719]
	TIME [epoch: 5.71 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10154624641373866		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.10154624641373866 | validation: 0.09692623836203866]
	TIME [epoch: 5.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227993967703587		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.11227993967703587 | validation: 0.16633392746508371]
	TIME [epoch: 5.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452431107165412		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.11452431107165412 | validation: 0.2597207606354789]
	TIME [epoch: 5.71 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13943267339896775		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.13943267339896775 | validation: 0.10320160988607448]
	TIME [epoch: 5.71 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232369966249953		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.10232369966249953 | validation: 0.12987981604276372]
	TIME [epoch: 5.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13410264899395355		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.13410264899395355 | validation: 0.23766690568546708]
	TIME [epoch: 5.71 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806010910239536		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.13806010910239536 | validation: 0.096167539332361]
	TIME [epoch: 5.71 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979147719037423		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0979147719037423 | validation: 0.0961258547231173]
	TIME [epoch: 5.74 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08887669731007242		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08887669731007242 | validation: 0.09090861794731739]
	TIME [epoch: 5.72 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11350341922293455		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.11350341922293455 | validation: 0.09765412921904698]
	TIME [epoch: 5.71 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10769911053633346		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.10769911053633346 | validation: 0.12707514508908704]
	TIME [epoch: 5.71 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11370761927781323		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.11370761927781323 | validation: 0.17865158108661583]
	TIME [epoch: 5.71 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12142558741031124		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.12142558741031124 | validation: 0.14723124077412197]
	TIME [epoch: 5.71 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057595952440182		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.10057595952440182 | validation: 0.11458963437626003]
	TIME [epoch: 5.74 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818951776085567		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09818951776085567 | validation: 0.07995711539146608]
	TIME [epoch: 5.72 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16084493430852226		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.16084493430852226 | validation: 0.10602970021740317]
	TIME [epoch: 5.71 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102641352268058		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.11102641352268058 | validation: 0.11797271176114339]
	TIME [epoch: 5.71 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996161942630956		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.09996161942630956 | validation: 0.13787598365497725]
	TIME [epoch: 5.71 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1150236930310618		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1150236930310618 | validation: 0.1571087402644162]
	TIME [epoch: 5.71 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154567993184904		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1154567993184904 | validation: 0.09486161174533937]
	TIME [epoch: 5.74 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11708310458536059		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.11708310458536059 | validation: 0.1458714763687859]
	TIME [epoch: 5.73 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573591375554803		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.10573591375554803 | validation: 0.13077640257368287]
	TIME [epoch: 5.72 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09674847794005596		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.09674847794005596 | validation: 0.14519567055492932]
	TIME [epoch: 5.72 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227849561532212		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.10227849561532212 | validation: 0.10931865026194974]
	TIME [epoch: 5.72 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12283950471077729		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.12283950471077729 | validation: 0.20143737171258708]
	TIME [epoch: 5.72 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13887958760097932		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.13887958760097932 | validation: 0.17312886960417437]
	TIME [epoch: 5.75 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125283150014137		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.11125283150014137 | validation: 0.08106356297791897]
	TIME [epoch: 5.74 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949112620187601		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.0949112620187601 | validation: 0.12230172966339875]
	TIME [epoch: 5.73 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052447157145196		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.10052447157145196 | validation: 0.1134766961127092]
	TIME [epoch: 5.72 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479000337458892		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.10479000337458892 | validation: 0.08952799037506297]
	TIME [epoch: 5.72 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070223767578134		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.09070223767578134 | validation: 0.11090415489878229]
	TIME [epoch: 5.72 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580390727910786		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.08580390727910786 | validation: 0.07687825330836252]
	TIME [epoch: 5.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530550852294632		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.09530550852294632 | validation: 0.19806758046809833]
	TIME [epoch: 5.73 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12464267492878961		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.12464267492878961 | validation: 0.14295162788242957]
	TIME [epoch: 5.73 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381711996597835		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1381711996597835 | validation: 0.13653732516268224]
	TIME [epoch: 5.71 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17702169066313267		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.17702169066313267 | validation: 0.12234506591536605]
	TIME [epoch: 5.72 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10772991015803823		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.10772991015803823 | validation: 0.1309953407044112]
	TIME [epoch: 5.72 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12821704582727195		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.12821704582727195 | validation: 0.14226021801266495]
	TIME [epoch: 5.75 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121021146948452		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1121021146948452 | validation: 0.10423909106675741]
	TIME [epoch: 5.72 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022665601866442		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09022665601866442 | validation: 0.17150919013153382]
	TIME [epoch: 5.72 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15465044482677762		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15465044482677762 | validation: 0.18840254835591533]
	TIME [epoch: 5.72 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026635831592253		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.12026635831592253 | validation: 0.10278088897926145]
	TIME [epoch: 5.72 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992148819747554		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.09992148819747554 | validation: 0.13785438152533178]
	TIME [epoch: 5.72 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168866496301915		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.10168866496301915 | validation: 0.09835026858452235]
	TIME [epoch: 5.74 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09523842761817987		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.09523842761817987 | validation: 0.12178995897174562]
	TIME [epoch: 5.72 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08973090130499191		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.08973090130499191 | validation: 0.08857877005520205]
	TIME [epoch: 5.72 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860038568361917		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.08860038568361917 | validation: 0.1190352671798126]
	TIME [epoch: 5.72 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1773648881814189		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1773648881814189 | validation: 0.11271084034462639]
	TIME [epoch: 5.72 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482013620502264		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.11482013620502264 | validation: 0.09177923191797464]
	TIME [epoch: 5.71 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12039809878264959		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.12039809878264959 | validation: 0.07168894047921887]
	TIME [epoch: 5.74 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361015906404248		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.08361015906404248 | validation: 0.09841650673999422]
	TIME [epoch: 5.72 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08220879996719543		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.08220879996719543 | validation: 0.07853540921281564]
	TIME [epoch: 5.71 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351960362008353		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.07351960362008353 | validation: 0.1072997108198489]
	TIME [epoch: 5.71 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08933279729779528		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.08933279729779528 | validation: 0.10513997873295924]
	TIME [epoch: 5.71 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135547144272297		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1135547144272297 | validation: 0.1592143549349407]
	TIME [epoch: 5.71 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12390155981624325		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.12390155981624325 | validation: 0.0699327117365827]
	TIME [epoch: 5.74 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216929834755267		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.10216929834755267 | validation: 0.09081919692374794]
	TIME [epoch: 5.73 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862989891210481		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.10862989891210481 | validation: 0.0982543565334077]
	TIME [epoch: 5.72 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0804189300953865		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0804189300953865 | validation: 0.09515106894881062]
	TIME [epoch: 5.72 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308599229702766		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08308599229702766 | validation: 0.08427256634829107]
	TIME [epoch: 5.72 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08338182622567712		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.08338182622567712 | validation: 0.08704484095740928]
	TIME [epoch: 5.72 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793657737196242		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11793657737196242 | validation: 0.08409829031775733]
	TIME [epoch: 5.73 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09686121129456465		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.09686121129456465 | validation: 0.11227723664692302]
	TIME [epoch: 5.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07422922869851799		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.07422922869851799 | validation: 0.0705266806066636]
	TIME [epoch: 5.72 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07464318790010628		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.07464318790010628 | validation: 0.11650238701492988]
	TIME [epoch: 5.72 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319432517458143		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.08319432517458143 | validation: 0.08676096596664894]
	TIME [epoch: 5.72 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09884460742703596		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.09884460742703596 | validation: 0.090181350385783]
	TIME [epoch: 5.72 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09230212803613598		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.09230212803613598 | validation: 0.09094449741819755]
	TIME [epoch: 5.73 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732549813603405		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.08732549813603405 | validation: 0.09097297028433922]
	TIME [epoch: 5.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078538187478256		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.078538187478256 | validation: 0.07695888590364319]
	TIME [epoch: 5.72 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128973807477939		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.08128973807477939 | validation: 0.08550283720391644]
	TIME [epoch: 5.72 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822059248945153		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.07822059248945153 | validation: 0.07786244160066859]
	TIME [epoch: 5.72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08993556778588996		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.08993556778588996 | validation: 0.10470003945451457]
	TIME [epoch: 5.72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462607759532096		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06462607759532096 | validation: 0.061814369257693055]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07019124794402305		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.07019124794402305 | validation: 0.0723452043124346]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598364520474323		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.09598364520474323 | validation: 0.08087356977017766]
	TIME [epoch: 5.72 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12521303562715635		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.12521303562715635 | validation: 0.07999006439507898]
	TIME [epoch: 5.72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07318888666632187		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.07318888666632187 | validation: 0.10841850929881247]
	TIME [epoch: 5.73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155556824689815		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.08155556824689815 | validation: 0.08907614331324819]
	TIME [epoch: 5.73 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968622217175773		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.07968622217175773 | validation: 0.057505251751777425]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783415715429411		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09783415715429411 | validation: 0.08333074621549677]
	TIME [epoch: 5.71 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050059276939976		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.09050059276939976 | validation: 0.121725162603773]
	TIME [epoch: 5.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16048816743862526		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.16048816743862526 | validation: 0.1267040091623341]
	TIME [epoch: 5.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08226804863184997		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.08226804863184997 | validation: 0.08486421798995254]
	TIME [epoch: 5.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748686816812521		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.07748686816812521 | validation: 0.08723952516801779]
	TIME [epoch: 5.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907424543075595		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.07907424543075595 | validation: 0.0705397191092774]
	TIME [epoch: 5.73 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06598140830820584		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.06598140830820584 | validation: 0.08130126167016342]
	TIME [epoch: 5.72 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11862045415616848		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.11862045415616848 | validation: 0.07858369662839416]
	TIME [epoch: 5.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080735392202726		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.080735392202726 | validation: 0.09841921586729566]
	TIME [epoch: 5.72 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08411779045243767		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.08411779045243767 | validation: 0.07552587438109543]
	TIME [epoch: 5.72 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06284767721512485		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.06284767721512485 | validation: 0.07528117016692547]
	TIME [epoch: 5.72 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07305129314972275		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.07305129314972275 | validation: 0.0873502666982829]
	TIME [epoch: 5.75 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07804318474731528		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.07804318474731528 | validation: 0.11965138915627757]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676274415842878		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.09676274415842878 | validation: 0.08874686274698018]
	TIME [epoch: 5.72 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676452731520081		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10676452731520081 | validation: 0.06374281098799799]
	TIME [epoch: 5.72 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353923499530462		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.06353923499530462 | validation: 0.07846440037687429]
	TIME [epoch: 5.72 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11527783044462604		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.11527783044462604 | validation: 0.05980879396009493]
	TIME [epoch: 5.72 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05745205550757736		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.05745205550757736 | validation: 0.14329636449908936]
	TIME [epoch: 5.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330670461290596		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.08330670461290596 | validation: 0.14534402468588672]
	TIME [epoch: 5.74 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286648364610934		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1286648364610934 | validation: 0.14123807285452034]
	TIME [epoch: 5.72 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08989514210626519		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.08989514210626519 | validation: 0.11394962368099303]
	TIME [epoch: 5.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09418056174669129		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.09418056174669129 | validation: 0.13917502341919197]
	TIME [epoch: 5.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790157476651533		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09790157476651533 | validation: 0.10394517300021917]
	TIME [epoch: 5.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07388131384806983		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.07388131384806983 | validation: 0.07936789470347666]
	TIME [epoch: 5.76 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07362189318964184		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.07362189318964184 | validation: 0.0751693916025455]
	TIME [epoch: 5.73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07221062174738041		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.07221062174738041 | validation: 0.11661054992411167]
	TIME [epoch: 5.72 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10386769459540056		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.10386769459540056 | validation: 0.14569878052208401]
	TIME [epoch: 5.72 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0940240462251516		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.0940240462251516 | validation: 0.07704047988265182]
	TIME [epoch: 5.72 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0798129625387421		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.0798129625387421 | validation: 0.09748112852170757]
	TIME [epoch: 5.72 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947058229169884		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0947058229169884 | validation: 0.11089416911953422]
	TIME [epoch: 5.74 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09852206481622015		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.09852206481622015 | validation: 0.10190318882181344]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730643546393867		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.08730643546393867 | validation: 0.0818986279334749]
	TIME [epoch: 5.72 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269926542072436		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.1269926542072436 | validation: 0.13461130602397156]
	TIME [epoch: 5.72 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08023660163170993		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.08023660163170993 | validation: 0.08348014822587613]
	TIME [epoch: 5.72 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09460296864085557		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.09460296864085557 | validation: 0.13652643468983422]
	TIME [epoch: 5.72 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112313820452018		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.10112313820452018 | validation: 0.09254484465078942]
	TIME [epoch: 5.74 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627989152086643		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.08627989152086643 | validation: 0.24469900368054265]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12639141045310173		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.12639141045310173 | validation: 0.08087859475773955]
	TIME [epoch: 5.72 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350274906227017		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.07350274906227017 | validation: 0.08266257212325456]
	TIME [epoch: 5.72 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10472308003877445		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.10472308003877445 | validation: 0.10224496565835495]
	TIME [epoch: 5.72 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391354793098917		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.08391354793098917 | validation: 0.07662668832104318]
	TIME [epoch: 5.72 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637719906752002		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0637719906752002 | validation: 0.09629256126184514]
	TIME [epoch: 5.73 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09973543089602487		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.09973543089602487 | validation: 0.07605036563261919]
	TIME [epoch: 5.75 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06973254574229552		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.06973254574229552 | validation: 0.11656547933619411]
	TIME [epoch: 5.72 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793841727513202		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.10793841727513202 | validation: 0.10428412308244742]
	TIME [epoch: 5.72 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418124678447186		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.11418124678447186 | validation: 0.14777550493502353]
	TIME [epoch: 5.72 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11431456690599692		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.11431456690599692 | validation: 0.13364535977811984]
	TIME [epoch: 5.72 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214436146192292		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.10214436146192292 | validation: 0.11397055669475681]
	TIME [epoch: 5.73 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882727311417644		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.07882727311417644 | validation: 0.07436790305004322]
	TIME [epoch: 5.73 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08199218741154052		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08199218741154052 | validation: 0.17965685599167672]
	TIME [epoch: 5.71 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11650620656910321		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.11650620656910321 | validation: 0.11704260868222459]
	TIME [epoch: 5.72 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07837676209229985		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.07837676209229985 | validation: 0.10998082801920539]
	TIME [epoch: 5.72 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09037176980681777		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.09037176980681777 | validation: 0.07690807208086876]
	TIME [epoch: 5.72 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617034316828538		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.08617034316828538 | validation: 0.08551674234254014]
	TIME [epoch: 5.73 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776891412172867		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08776891412172867 | validation: 0.0671685936059829]
	TIME [epoch: 5.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000286770062958		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.07000286770062958 | validation: 0.06212482791856287]
	TIME [epoch: 5.72 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791221348332692		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.08791221348332692 | validation: 0.06505366623329753]
	TIME [epoch: 5.72 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0699611909022617		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0699611909022617 | validation: 0.09234537655406981]
	TIME [epoch: 5.72 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08074956802007333		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08074956802007333 | validation: 0.0952477973051674]
	TIME [epoch: 5.71 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789186614949429		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.0789186614949429 | validation: 0.06583330636282474]
	TIME [epoch: 5.73 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706412642572654		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.06706412642572654 | validation: 0.08041032161240072]
	TIME [epoch: 5.75 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07387935372239396		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07387935372239396 | validation: 0.07031591116129723]
	TIME [epoch: 5.72 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796165154114429		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0796165154114429 | validation: 0.06752067622644409]
	TIME [epoch: 5.71 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08020072655040003		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.08020072655040003 | validation: 0.09022054491796952]
	TIME [epoch: 5.72 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356306496680565		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1356306496680565 | validation: 0.107130354026698]
	TIME [epoch: 5.72 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598296477446082		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.09598296477446082 | validation: 0.08190892603066234]
	TIME [epoch: 5.74 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06547144214904725		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.06547144214904725 | validation: 0.12814057301125098]
	TIME [epoch: 5.75 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09173432260007515		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09173432260007515 | validation: 0.07490016712589248]
	TIME [epoch: 5.72 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10986409872068771		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.10986409872068771 | validation: 0.15416867026349676]
	TIME [epoch: 5.72 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974641203701747		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.10974641203701747 | validation: 0.08748187438508465]
	TIME [epoch: 5.72 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319089338996581		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.06319089338996581 | validation: 0.07511612619000166]
	TIME [epoch: 5.71 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964939140781343		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.06964939140781343 | validation: 0.0748779881931879]
	TIME [epoch: 5.73 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07763793129370725		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.07763793129370725 | validation: 0.06859175528484533]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07004137228018047		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.07004137228018047 | validation: 0.06894752234512555]
	TIME [epoch: 5.72 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0669457386153517		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0669457386153517 | validation: 0.06279105911626175]
	TIME [epoch: 5.73 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712858405841479		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.0712858405841479 | validation: 0.10294083061293381]
	TIME [epoch: 5.72 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08410470340517606		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08410470340517606 | validation: 0.08524744419562257]
	TIME [epoch: 5.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06953771118406973		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.06953771118406973 | validation: 0.07378402079055761]
	TIME [epoch: 5.73 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749525252290202		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.11749525252290202 | validation: 0.11620382281387925]
	TIME [epoch: 5.73 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842917971180551		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.06842917971180551 | validation: 0.10766824993106458]
	TIME [epoch: 5.72 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07916262612663277		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07916262612663277 | validation: 0.17211963583989662]
	TIME [epoch: 5.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989797388015698		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.10989797388015698 | validation: 0.1339692448042623]
	TIME [epoch: 5.72 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889432611365011		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.09889432611365011 | validation: 0.08234355160835762]
	TIME [epoch: 5.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481126225291805		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.07481126225291805 | validation: 0.09373464098826091]
	TIME [epoch: 5.73 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972860622502681		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.07972860622502681 | validation: 0.1135405597172284]
	TIME [epoch: 5.73 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996297480559244		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.06996297480559244 | validation: 0.06551211086865508]
	TIME [epoch: 5.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013166388236029		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.07013166388236029 | validation: 0.07696126067069878]
	TIME [epoch: 5.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05922917449867708		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.05922917449867708 | validation: 0.082838272695301]
	TIME [epoch: 5.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13052316089840893		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.13052316089840893 | validation: 0.08250978859339535]
	TIME [epoch: 5.71 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08057018737557055		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08057018737557055 | validation: 0.1005881275522047]
	TIME [epoch: 5.72 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10476946741646656		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.10476946741646656 | validation: 0.21876439382076596]
	TIME [epoch: 5.74 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10234090262016342		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.10234090262016342 | validation: 0.08351031513263323]
	TIME [epoch: 5.71 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06396574375479362		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.06396574375479362 | validation: 0.12010427117372582]
	TIME [epoch: 5.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08918280879103817		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.08918280879103817 | validation: 0.06388837340239248]
	TIME [epoch: 5.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189057339022843		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.06189057339022843 | validation: 0.08010641713874293]
	TIME [epoch: 5.71 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07139203418027838		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.07139203418027838 | validation: 0.0692776506273155]
	TIME [epoch: 5.72 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06270306390276673		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.06270306390276673 | validation: 0.09071618119061978]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215094854257642		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.07215094854257642 | validation: 0.06905720091780453]
	TIME [epoch: 5.71 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058542184668113534		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.058542184668113534 | validation: 0.08370923277052414]
	TIME [epoch: 5.71 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06687328619766938		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.06687328619766938 | validation: 0.07000393102846433]
	TIME [epoch: 5.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271460652994176		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.06271460652994176 | validation: 0.06710747626866331]
	TIME [epoch: 5.71 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129593479360729		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.05129593479360729 | validation: 0.06859993096557175]
	TIME [epoch: 5.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06125841961456499		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06125841961456499 | validation: 0.09102348030002917]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0690678948867329		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0690678948867329 | validation: 0.07430767524585777]
	TIME [epoch: 5.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08790512385096455		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08790512385096455 | validation: 0.07564229747797961]
	TIME [epoch: 5.71 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0555674787820959		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0555674787820959 | validation: 0.11384319201894076]
	TIME [epoch: 5.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11362087373656404		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.11362087373656404 | validation: 0.0802772562847396]
	TIME [epoch: 5.71 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07044835807392824		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.07044835807392824 | validation: 0.0841209954295639]
	TIME [epoch: 5.71 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06878429190384755		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.06878429190384755 | validation: 0.1257460844450262]
	TIME [epoch: 5.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124839400012276		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.11124839400012276 | validation: 0.07477825659296106]
	TIME [epoch: 5.71 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06911489883227565		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.06911489883227565 | validation: 0.07228885322642055]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688664185153245		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.07688664185153245 | validation: 0.10515671205727056]
	TIME [epoch: 5.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07934771815482415		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.07934771815482415 | validation: 0.15521053754812097]
	TIME [epoch: 5.71 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251384563844418		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.10251384563844418 | validation: 0.11827076533304448]
	TIME [epoch: 5.71 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418435947815134		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.07418435947815134 | validation: 0.07885467690454362]
	TIME [epoch: 5.74 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713945532530266		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.07713945532530266 | validation: 0.06923964640065888]
	TIME [epoch: 5.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425952436346874		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.05425952436346874 | validation: 0.08059550830157601]
	TIME [epoch: 5.71 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815177873673652		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.07815177873673652 | validation: 0.08612733201620257]
	TIME [epoch: 5.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0708141767091522		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0708141767091522 | validation: 0.07523796957539154]
	TIME [epoch: 5.71 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057354667319797714		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.057354667319797714 | validation: 0.0792092580829028]
	TIME [epoch: 5.72 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155908247895025		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.08155908247895025 | validation: 0.06907285879581715]
	TIME [epoch: 5.75 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055148173021340945		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.055148173021340945 | validation: 0.07121806733169826]
	TIME [epoch: 5.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431893102905256		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.06431893102905256 | validation: 0.11411619798768577]
	TIME [epoch: 5.71 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08072003728850212		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.08072003728850212 | validation: 0.05871436424489947]
	TIME [epoch: 5.72 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06403826963746809		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.06403826963746809 | validation: 0.07076397996328765]
	TIME [epoch: 5.71 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0920047474547169		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.0920047474547169 | validation: 0.12636549083534057]
	TIME [epoch: 5.71 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013695425295393		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.09013695425295393 | validation: 0.10790783438941415]
	TIME [epoch: 5.75 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09428689741343455		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09428689741343455 | validation: 0.09625434909694619]
	TIME [epoch: 5.72 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684843752371627		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0684843752371627 | validation: 0.09093376432973184]
	TIME [epoch: 5.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07345590210058298		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.07345590210058298 | validation: 0.0582468004716194]
	TIME [epoch: 5.71 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05372916086850811		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.05372916086850811 | validation: 0.0922320319124405]
	TIME [epoch: 5.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1226069876455122		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1226069876455122 | validation: 0.0885357823118544]
	TIME [epoch: 5.71 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08223188890606224		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08223188890606224 | validation: 0.08349406400597957]
	TIME [epoch: 5.75 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439694348952736		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.07439694348952736 | validation: 0.07211182917070882]
	TIME [epoch: 5.71 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959095153914254		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.05959095153914254 | validation: 0.07776492131745982]
	TIME [epoch: 5.71 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13616088762537787		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.13616088762537787 | validation: 0.09494060289873651]
	TIME [epoch: 5.72 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994796786974664		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.07994796786974664 | validation: 0.06366842336482216]
	TIME [epoch: 5.71 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058602480320651386		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.058602480320651386 | validation: 0.06884464596418148]
	TIME [epoch: 5.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620257911827834		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.06620257911827834 | validation: 0.06710123029059424]
	TIME [epoch: 5.74 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09627873363866704		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09627873363866704 | validation: 0.1083368194080456]
	TIME [epoch: 5.72 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06870768387457338		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.06870768387457338 | validation: 0.12488403000051655]
	TIME [epoch: 5.71 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928488344015641		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.07928488344015641 | validation: 0.09366330600448547]
	TIME [epoch: 5.71 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06050091797601961		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.06050091797601961 | validation: 0.07767029199465038]
	TIME [epoch: 5.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06627340256935456		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.06627340256935456 | validation: 0.0657604094207123]
	TIME [epoch: 5.71 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059644300628940064		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.059644300628940064 | validation: 0.05517349040397502]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_930.pth
	Model improved!!!
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0744902465306167		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.0744902465306167 | validation: 0.13131123387742416]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07760088583380698		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07760088583380698 | validation: 0.0660249188496133]
	TIME [epoch: 5.71 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059282402247564085		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.059282402247564085 | validation: 0.10217131439932997]
	TIME [epoch: 5.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07852219471739443		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07852219471739443 | validation: 0.06504850831732825]
	TIME [epoch: 5.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056515087563467126		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.056515087563467126 | validation: 0.07812145908220201]
	TIME [epoch: 5.72 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608193752321292		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.06608193752321292 | validation: 0.10398578606266169]
	TIME [epoch: 5.74 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752381103557754		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07752381103557754 | validation: 0.07467671344171967]
	TIME [epoch: 5.71 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06777435931225724		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.06777435931225724 | validation: 0.06201763929908536]
	TIME [epoch: 5.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0567672150521458		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0567672150521458 | validation: 0.08131392983622397]
	TIME [epoch: 5.72 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644840073164167		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.0644840073164167 | validation: 0.10523062552932992]
	TIME [epoch: 5.71 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810954230829123		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.07810954230829123 | validation: 0.06824250631717974]
	TIME [epoch: 5.72 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060838566877273806		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.060838566877273806 | validation: 0.07124860829190664]
	TIME [epoch: 5.74 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557842797665461		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.0557842797665461 | validation: 0.08077770043268988]
	TIME [epoch: 5.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351303778966253		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.07351303778966253 | validation: 0.09613229546423138]
	TIME [epoch: 5.71 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06282361021916118		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.06282361021916118 | validation: 0.07131660431424529]
	TIME [epoch: 5.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059152026334082314		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.059152026334082314 | validation: 0.07348299529705414]
	TIME [epoch: 5.72 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147193229107127		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.07147193229107127 | validation: 0.11084924921949735]
	TIME [epoch: 5.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015337422406936		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.07015337422406936 | validation: 0.0875261971894695]
	TIME [epoch: 5.74 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926792785850824		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.06926792785850824 | validation: 0.057666465127942004]
	TIME [epoch: 5.71 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05246306171771815		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.05246306171771815 | validation: 0.0847030468054005]
	TIME [epoch: 5.71 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058718101903791536		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.058718101903791536 | validation: 0.08103189264271204]
	TIME [epoch: 5.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030026382305838		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.08030026382305838 | validation: 0.1329102642808888]
	TIME [epoch: 5.71 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09729339238203967		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.09729339238203967 | validation: 0.09708526131484617]
	TIME [epoch: 5.72 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887437779084553		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.06887437779084553 | validation: 0.08266223393468673]
	TIME [epoch: 5.75 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708571396987353		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.06708571396987353 | validation: 0.0863220967359115]
	TIME [epoch: 5.72 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05950907700833431		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.05950907700833431 | validation: 0.06137658883231616]
	TIME [epoch: 5.72 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755605879956667		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0755605879956667 | validation: 0.1490849998752874]
	TIME [epoch: 5.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791508650741952		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.0791508650741952 | validation: 0.15453005777874204]
	TIME [epoch: 5.72 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09978918012553498		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09978918012553498 | validation: 0.0647314453707869]
	TIME [epoch: 5.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05866763855849488		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.05866763855849488 | validation: 0.06855972435193791]
	TIME [epoch: 5.74 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058112981808266934		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.058112981808266934 | validation: 0.07737060647571058]
	TIME [epoch: 5.71 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07440199718630533		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.07440199718630533 | validation: 0.08923884272784598]
	TIME [epoch: 5.71 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06179847161147384		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.06179847161147384 | validation: 0.07725937353798543]
	TIME [epoch: 5.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05186040619271265		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.05186040619271265 | validation: 0.06947063295641642]
	TIME [epoch: 5.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06985674606219912		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.06985674606219912 | validation: 0.07058996092399535]
	TIME [epoch: 5.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05305302391578084		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.05305302391578084 | validation: 0.06437598909068011]
	TIME [epoch: 5.74 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05235833997356523		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.05235833997356523 | validation: 0.06689791912065104]
	TIME [epoch: 5.71 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07959199883299417		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.07959199883299417 | validation: 0.07975268305559415]
	TIME [epoch: 5.72 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057817042396911614		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.057817042396911614 | validation: 0.0640962410522074]
	TIME [epoch: 5.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05281509625466369		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.05281509625466369 | validation: 0.07621936128944552]
	TIME [epoch: 5.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057490736701424364		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.057490736701424364 | validation: 0.07188953439262492]
	TIME [epoch: 5.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929162285246756		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.05929162285246756 | validation: 0.09711390106013841]
	TIME [epoch: 5.74 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05969846233957063		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.05969846233957063 | validation: 0.08945800995070892]
	TIME [epoch: 5.71 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05435619896882868		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.05435619896882868 | validation: 0.06091685950629262]
	TIME [epoch: 5.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791077055828146		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.05791077055828146 | validation: 0.08983886947843164]
	TIME [epoch: 5.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06698343616234835		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.06698343616234835 | validation: 0.06528926621749126]
	TIME [epoch: 5.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049271504660257856		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.049271504660257856 | validation: 0.06391527284468361]
	TIME [epoch: 5.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06292635042622763		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.06292635042622763 | validation: 0.060417226161843356]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053927499837974166		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.053927499837974166 | validation: 0.05455970666345023]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_979.pth
	Model improved!!!
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05232170637899204		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.05232170637899204 | validation: 0.0530162642448504]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679659670510527		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0679659670510527 | validation: 0.055149513742201554]
	TIME [epoch: 5.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926187949578197		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.06926187949578197 | validation: 0.05947865645168287]
	TIME [epoch: 5.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153458333089338		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08153458333089338 | validation: 0.09763904966735483]
	TIME [epoch: 5.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331116550405097		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.07331116550405097 | validation: 0.09859684455872322]
	TIME [epoch: 5.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08438698817318377		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.08438698817318377 | validation: 0.0637377170400137]
	TIME [epoch: 5.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054504784292623024		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.054504784292623024 | validation: 0.05466946643926699]
	TIME [epoch: 5.71 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055382336144006686		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.055382336144006686 | validation: 0.08519133590010816]
	TIME [epoch: 5.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053674801507208325		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.053674801507208325 | validation: 0.06367348939311678]
	TIME [epoch: 5.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051053202547205266		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.051053202547205266 | validation: 0.06889694963887184]
	TIME [epoch: 5.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061413829074993646		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.061413829074993646 | validation: 0.07272837287535909]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060874963258989445		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.060874963258989445 | validation: 0.07806306525882827]
	TIME [epoch: 5.71 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487702579921728		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.0487702579921728 | validation: 0.07820038215508951]
	TIME [epoch: 5.72 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054332167531905576		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.054332167531905576 | validation: 0.08946774939354342]
	TIME [epoch: 5.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07416140866356251		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07416140866356251 | validation: 0.09827282157877683]
	TIME [epoch: 5.72 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07504531823678204		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.07504531823678204 | validation: 0.06898164156838274]
	TIME [epoch: 5.72 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337781633503812		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.07337781633503812 | validation: 0.06980113004656699]
	TIME [epoch: 5.76 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056934948684442245		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.056934948684442245 | validation: 0.06748572980665916]
	TIME [epoch: 5.73 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051883475282015444		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.051883475282015444 | validation: 0.07736291118160334]
	TIME [epoch: 5.72 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056301804667343074		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.056301804667343074 | validation: 0.07298434044648282]
	TIME [epoch: 5.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060274649885573295		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.060274649885573295 | validation: 0.06513884745958158]
	TIME [epoch: 5.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05419992461237648		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.05419992461237648 | validation: 0.05684791890132232]
	TIME [epoch: 5.72 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045228416116184736		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.045228416116184736 | validation: 0.06275795075594326]
	TIME [epoch: 5.74 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06940409064362102		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.06940409064362102 | validation: 0.07997373643582907]
	TIME [epoch: 5.71 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05556248597674647		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.05556248597674647 | validation: 0.07311545800584864]
	TIME [epoch: 5.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612414912780549		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.0612414912780549 | validation: 0.06364003663912693]
	TIME [epoch: 5.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054469675299150366		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.054469675299150366 | validation: 0.07043712072895257]
	TIME [epoch: 5.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05664365147298491		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.05664365147298491 | validation: 0.10416045789200841]
	TIME [epoch: 5.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08038064002228384		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.08038064002228384 | validation: 0.08332410053658444]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05514116186996588		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.05514116186996588 | validation: 0.06254098370524994]
	TIME [epoch: 5.71 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329754966887341		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.05329754966887341 | validation: 0.10189936858124457]
	TIME [epoch: 5.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719044404055229		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.0719044404055229 | validation: 0.0756791157007374]
	TIME [epoch: 5.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052248298247535845		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.052248298247535845 | validation: 0.06245455629377908]
	TIME [epoch: 5.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0579316431250265		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0579316431250265 | validation: 0.07048138761739837]
	TIME [epoch: 5.72 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05280853108222435		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.05280853108222435 | validation: 0.06341199014128372]
	TIME [epoch: 5.75 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059649454483753375		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.059649454483753375 | validation: 0.07093667829453285]
	TIME [epoch: 5.73 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549891347463584		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0549891347463584 | validation: 0.06874853000743407]
	TIME [epoch: 5.72 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295662668539488		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.06295662668539488 | validation: 0.07847325437935836]
	TIME [epoch: 5.72 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057093655791904695		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.057093655791904695 | validation: 0.061760357239849364]
	TIME [epoch: 5.72 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04221769446904883		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04221769446904883 | validation: 0.057660771394681926]
	TIME [epoch: 5.72 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04664889485538477		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.04664889485538477 | validation: 0.06446617912616912]
	TIME [epoch: 5.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05405925018424328		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.05405925018424328 | validation: 0.07556298831391747]
	TIME [epoch: 5.71 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323706639869933		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06323706639869933 | validation: 0.10329833322651269]
	TIME [epoch: 5.72 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534354240946049		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.08534354240946049 | validation: 0.14402111549261512]
	TIME [epoch: 5.72 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619401813107214		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.07619401813107214 | validation: 0.07058058305626179]
	TIME [epoch: 5.72 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05019782894872338		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.05019782894872338 | validation: 0.0757325079410125]
	TIME [epoch: 5.72 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05450629484782007		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.05450629484782007 | validation: 0.05892561615688717]
	TIME [epoch: 5.76 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648108873814368		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.0648108873814368 | validation: 0.057275491540647136]
	TIME [epoch: 5.73 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029081940778374		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.06029081940778374 | validation: 0.08731786067167914]
	TIME [epoch: 5.72 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060337245004024556		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.060337245004024556 | validation: 0.08819572596256425]
	TIME [epoch: 5.72 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06993060370694928		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.06993060370694928 | validation: 0.052207576458674146]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1030.pth
	Model improved!!!
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06366638966097043		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.06366638966097043 | validation: 0.06289579997643101]
	TIME [epoch: 5.72 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639596127350526		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.0639596127350526 | validation: 0.06973047260234216]
	TIME [epoch: 5.76 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05821893358108331		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05821893358108331 | validation: 0.0729959758305759]
	TIME [epoch: 5.73 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095690107907487		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.095690107907487 | validation: 0.08657659385318957]
	TIME [epoch: 5.72 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526331190584875		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08526331190584875 | validation: 0.06792225612324508]
	TIME [epoch: 5.72 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052275336853697556		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.052275336853697556 | validation: 0.06131417696547211]
	TIME [epoch: 5.72 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623813405804601		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.04623813405804601 | validation: 0.06715710900667982]
	TIME [epoch: 5.72 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05071002810890133		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.05071002810890133 | validation: 0.08039834896504978]
	TIME [epoch: 5.76 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05295195828377227		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.05295195828377227 | validation: 0.06784922638632343]
	TIME [epoch: 5.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487213846853722		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.06487213846853722 | validation: 0.05522552856019918]
	TIME [epoch: 5.71 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055151979543432365		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.055151979543432365 | validation: 0.06931304703956363]
	TIME [epoch: 5.72 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0576750012459016		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.0576750012459016 | validation: 0.06631858917178562]
	TIME [epoch: 5.72 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711779737197936		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.05711779737197936 | validation: 0.06665123275958272]
	TIME [epoch: 5.72 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050987367635614275		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.050987367635614275 | validation: 0.06149217297670239]
	TIME [epoch: 5.76 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843235237007262		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.04843235237007262 | validation: 0.06305483461126256]
	TIME [epoch: 5.73 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06099726210623675		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.06099726210623675 | validation: 0.0764064487804694]
	TIME [epoch: 5.72 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06564884547360436		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.06564884547360436 | validation: 0.08470304630819797]
	TIME [epoch: 5.72 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07257370958116266		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07257370958116266 | validation: 0.05843799350183551]
	TIME [epoch: 5.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05246723103809761		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.05246723103809761 | validation: 0.06496781397284115]
	TIME [epoch: 5.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719691323509114		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.05719691323509114 | validation: 0.05828097171699281]
	TIME [epoch: 5.73 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622205909532457		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.05622205909532457 | validation: 0.06954112030602325]
	TIME [epoch: 5.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05205181210464629		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.05205181210464629 | validation: 0.06714928244788691]
	TIME [epoch: 5.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379720953322748		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06379720953322748 | validation: 0.07647362662825077]
	TIME [epoch: 5.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05807587686968241		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.05807587686968241 | validation: 0.06420291144383418]
	TIME [epoch: 5.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050645848855513306		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.050645848855513306 | validation: 0.06269642555468061]
	TIME [epoch: 5.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05840815024318352		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.05840815024318352 | validation: 0.058942091861260426]
	TIME [epoch: 5.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441087344994689		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.06441087344994689 | validation: 0.1039349753738599]
	TIME [epoch: 5.71 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06627466558925826		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.06627466558925826 | validation: 0.06146997449579073]
	TIME [epoch: 5.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047753728327165255		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.047753728327165255 | validation: 0.10849239272084131]
	TIME [epoch: 5.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07072132626674069		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.07072132626674069 | validation: 0.06381268634989727]
	TIME [epoch: 5.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047990524554545354		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.047990524554545354 | validation: 0.05835842457625863]
	TIME [epoch: 5.72 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05376442363670485		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.05376442363670485 | validation: 0.08303385028283002]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0899903798655087		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.0899903798655087 | validation: 0.0887539800029701]
	TIME [epoch: 5.72 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07419399641570279		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07419399641570279 | validation: 0.08597512580699766]
	TIME [epoch: 5.72 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05376183245970344		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.05376183245970344 | validation: 0.06557529121351278]
	TIME [epoch: 5.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958018380302081		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04958018380302081 | validation: 0.06442725869287996]
	TIME [epoch: 5.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059050294346486884		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.059050294346486884 | validation: 0.11141484101262034]
	TIME [epoch: 5.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06723813717966359		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06723813717966359 | validation: 0.0736502808544502]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056849877875780025		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.056849877875780025 | validation: 0.07116661873921519]
	TIME [epoch: 5.71 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720375849854708		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0720375849854708 | validation: 0.06734009519164026]
	TIME [epoch: 5.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049852092672150315		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.049852092672150315 | validation: 0.0647848596410985]
	TIME [epoch: 5.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058794145120729877		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.058794145120729877 | validation: 0.06447250437284308]
	TIME [epoch: 5.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07343468771653265		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07343468771653265 | validation: 0.08857916397187206]
	TIME [epoch: 5.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926323481446922		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.06926323481446922 | validation: 0.07264617171379004]
	TIME [epoch: 5.73 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06097997407005655		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.06097997407005655 | validation: 0.06990597141760098]
	TIME [epoch: 5.71 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058164593944459116		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.058164593944459116 | validation: 0.06640451677240293]
	TIME [epoch: 5.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051349780680585905		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.051349780680585905 | validation: 0.07001874399161331]
	TIME [epoch: 5.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527713622394595		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.07527713622394595 | validation: 0.07544375526172796]
	TIME [epoch: 5.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05188675225566556		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.05188675225566556 | validation: 0.05442451294429196]
	TIME [epoch: 5.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04809073795186589		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.04809073795186589 | validation: 0.05798212971832728]
	TIME [epoch: 5.75 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057439318312792746		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.057439318312792746 | validation: 0.07738138886864236]
	TIME [epoch: 5.73 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04867217006896837		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.04867217006896837 | validation: 0.06690876265097234]
	TIME [epoch: 5.72 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768648194589206		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.05768648194589206 | validation: 0.09143587624732416]
	TIME [epoch: 5.72 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088314226106429		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.05088314226106429 | validation: 0.06087188165262254]
	TIME [epoch: 5.72 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824493145002413		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.08824493145002413 | validation: 0.07794801709613007]
	TIME [epoch: 5.72 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05378618766027183		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.05378618766027183 | validation: 0.06870525225075427]
	TIME [epoch: 5.73 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05417245930764483		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.05417245930764483 | validation: 0.0538407024259467]
	TIME [epoch: 5.73 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04893546221769837		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.04893546221769837 | validation: 0.06284422369174011]
	TIME [epoch: 5.71 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046956649008144016		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.046956649008144016 | validation: 0.060778402265759035]
	TIME [epoch: 5.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995028910854126		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.06995028910854126 | validation: 0.05782090939139416]
	TIME [epoch: 5.71 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827094986965811		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.04827094986965811 | validation: 0.060006349794313824]
	TIME [epoch: 5.72 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04629001666714217		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.04629001666714217 | validation: 0.06631935703154601]
	TIME [epoch: 5.75 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05601177221776095		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.05601177221776095 | validation: 0.09947393379179469]
	TIME [epoch: 5.73 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132655106170097		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07132655106170097 | validation: 0.06724334167925085]
	TIME [epoch: 5.72 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06427286431488194		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06427286431488194 | validation: 0.08427509399442223]
	TIME [epoch: 5.72 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05613015698131811		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.05613015698131811 | validation: 0.06546780981958202]
	TIME [epoch: 5.72 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05085559128196147		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.05085559128196147 | validation: 0.06311553714766442]
	TIME [epoch: 5.72 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910038648616178		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05910038648616178 | validation: 0.09651877289176167]
	TIME [epoch: 5.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05460548854413562		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.05460548854413562 | validation: 0.0770560574575571]
	TIME [epoch: 5.73 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05593559737233754		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.05593559737233754 | validation: 0.04622170765369805]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1100.pth
	Model improved!!!
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050102175373803945		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.050102175373803945 | validation: 0.057346850132877165]
	TIME [epoch: 5.71 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590446960551037		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.04590446960551037 | validation: 0.05743376090308463]
	TIME [epoch: 5.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0461150545997816		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0461150545997816 | validation: 0.06341557943290975]
	TIME [epoch: 5.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811864940944523		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.07811864940944523 | validation: 0.07054227242786461]
	TIME [epoch: 5.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568838622753244		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0568838622753244 | validation: 0.051503776935921675]
	TIME [epoch: 5.71 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04906362187891961		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.04906362187891961 | validation: 0.05615289387052371]
	TIME [epoch: 5.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059445579826633246		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.059445579826633246 | validation: 0.07617155693275945]
	TIME [epoch: 5.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057161068247397		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.057161068247397 | validation: 0.07242858265719827]
	TIME [epoch: 5.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05025316186893365		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.05025316186893365 | validation: 0.05302400583966147]
	TIME [epoch: 5.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05275954303229918		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.05275954303229918 | validation: 0.07467086648923174]
	TIME [epoch: 5.73 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755743181438437		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06755743181438437 | validation: 0.06268960292684671]
	TIME [epoch: 5.71 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548402005019836		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04548402005019836 | validation: 0.07636312995585963]
	TIME [epoch: 5.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608205332839657		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0608205332839657 | validation: 0.06511315489184658]
	TIME [epoch: 5.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569040039355072		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0569040039355072 | validation: 0.06759659871703602]
	TIME [epoch: 5.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04940246560062771		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.04940246560062771 | validation: 0.06066151969016595]
	TIME [epoch: 5.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0489758159469149		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0489758159469149 | validation: 0.052588659337284245]
	TIME [epoch: 5.73 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045483205727867196		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.045483205727867196 | validation: 0.07403469763519174]
	TIME [epoch: 5.72 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540506972359108		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0540506972359108 | validation: 0.05797845358611728]
	TIME [epoch: 5.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048318085275997125		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.048318085275997125 | validation: 0.0661901609561587]
	TIME [epoch: 5.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052132029919068235		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.052132029919068235 | validation: 0.06087976352925962]
	TIME [epoch: 5.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620920914331418		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06620920914331418 | validation: 0.0840811511671054]
	TIME [epoch: 5.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997784254615385		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.05997784254615385 | validation: 0.05787776123414871]
	TIME [epoch: 5.73 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508825039157564		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.04508825039157564 | validation: 0.057868941471788546]
	TIME [epoch: 5.72 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046708507506753254		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.046708507506753254 | validation: 0.06971300840611795]
	TIME [epoch: 5.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05205004825202954		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.05205004825202954 | validation: 0.062130871356067124]
	TIME [epoch: 5.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773830326943245		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.05773830326943245 | validation: 0.07288822374561514]
	TIME [epoch: 5.71 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050642880201763364		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.050642880201763364 | validation: 0.06429066351235325]
	TIME [epoch: 5.71 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049959229454529096		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.049959229454529096 | validation: 0.07114719188022992]
	TIME [epoch: 5.73 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049685925115635625		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.049685925115635625 | validation: 0.061081623653037244]
	TIME [epoch: 5.72 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05112209215328096		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.05112209215328096 | validation: 0.05778227890580772]
	TIME [epoch: 5.71 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617385306190445		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.05617385306190445 | validation: 0.06151150404875194]
	TIME [epoch: 5.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411096328095136		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.05411096328095136 | validation: 0.07133861070584639]
	TIME [epoch: 5.71 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164830164236975		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.05164830164236975 | validation: 0.08023083781738855]
	TIME [epoch: 5.71 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04781455603773323		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04781455603773323 | validation: 0.08053335694068818]
	TIME [epoch: 5.73 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06109737344935974		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.06109737344935974 | validation: 0.06612406407424333]
	TIME [epoch: 5.72 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162306793306308		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.04162306793306308 | validation: 0.06344576477462169]
	TIME [epoch: 5.71 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047235596339201505		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.047235596339201505 | validation: 0.06373811625703758]
	TIME [epoch: 5.71 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059082245419235006		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.059082245419235006 | validation: 0.06591620859805582]
	TIME [epoch: 5.71 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046244612508316865		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.046244612508316865 | validation: 0.05365718089305659]
	TIME [epoch: 5.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566805068086914		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.04566805068086914 | validation: 0.058841682872622404]
	TIME [epoch: 5.73 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050537813837645836		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.050537813837645836 | validation: 0.07982222011589679]
	TIME [epoch: 5.72 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068089500832583		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.068089500832583 | validation: 0.0684711048632786]
	TIME [epoch: 5.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049064206879258325		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.049064206879258325 | validation: 0.05298710017232218]
	TIME [epoch: 5.71 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412613826130683		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.04412613826130683 | validation: 0.06737150356410589]
	TIME [epoch: 5.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04167249266158257		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04167249266158257 | validation: 0.05399975875353403]
	TIME [epoch: 5.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068005937114113		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.05068005937114113 | validation: 0.07342143992932468]
	TIME [epoch: 5.73 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400560172353707		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.05400560172353707 | validation: 0.05878479285037809]
	TIME [epoch: 5.72 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06191872524604723		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.06191872524604723 | validation: 0.08687086729098521]
	TIME [epoch: 5.71 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06274152175482084		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.06274152175482084 | validation: 0.05636415947000476]
	TIME [epoch: 5.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755106992404848		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.04755106992404848 | validation: 0.056254734517519625]
	TIME [epoch: 5.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049251297857044095		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.049251297857044095 | validation: 0.09746620136547755]
	TIME [epoch: 5.71 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06441514427093116		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.06441514427093116 | validation: 0.05753824531746101]
	TIME [epoch: 5.73 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857981011222322		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.04857981011222322 | validation: 0.05759527977504732]
	TIME [epoch: 5.72 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388005979278676		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.05388005979278676 | validation: 0.11006762034911662]
	TIME [epoch: 5.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07554429464555762		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.07554429464555762 | validation: 0.05576528237808795]
	TIME [epoch: 5.71 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565762590094825		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.04565762590094825 | validation: 0.06073217948999556]
	TIME [epoch: 5.71 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04682547147509669		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.04682547147509669 | validation: 0.08161974193269639]
	TIME [epoch: 5.71 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05225285499994761		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.05225285499994761 | validation: 0.056753263746078295]
	TIME [epoch: 5.72 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377349422712264		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.05377349422712264 | validation: 0.07741846750910153]
	TIME [epoch: 5.73 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392712007900341		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.05392712007900341 | validation: 0.06401913447758266]
	TIME [epoch: 5.71 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471977551620294		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.0471977551620294 | validation: 0.05986973520533547]
	TIME [epoch: 5.71 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049945995271379		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.05049945995271379 | validation: 0.06962596594251799]
	TIME [epoch: 5.71 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065649031343135		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.05065649031343135 | validation: 0.060625769819203]
	TIME [epoch: 5.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046724032625752865		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.046724032625752865 | validation: 0.07283356937637935]
	TIME [epoch: 5.72 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869463543383508		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.04869463543383508 | validation: 0.09819435526207172]
	TIME [epoch: 5.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06929197001729182		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.06929197001729182 | validation: 0.060757838029516106]
	TIME [epoch: 5.71 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042058967671705756		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.042058967671705756 | validation: 0.055783895351227894]
	TIME [epoch: 5.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052738922033380646		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.052738922033380646 | validation: 0.05510743177247521]
	TIME [epoch: 5.71 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04903822196700486		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.04903822196700486 | validation: 0.07208741176719329]
	TIME [epoch: 5.71 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052569817589855794		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.052569817589855794 | validation: 0.07530627316686005]
	TIME [epoch: 5.72 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049436476196072617		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.049436476196072617 | validation: 0.07233090760030128]
	TIME [epoch: 5.73 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04871064951329127		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.04871064951329127 | validation: 0.05076028307591583]
	TIME [epoch: 5.71 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04378498281815038		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.04378498281815038 | validation: 0.05929729697155402]
	TIME [epoch: 5.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05037344042376886		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.05037344042376886 | validation: 0.07494437267710395]
	TIME [epoch: 5.71 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04888439965610788		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.04888439965610788 | validation: 0.05652671841135017]
	TIME [epoch: 5.71 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053319059456732834		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.053319059456732834 | validation: 0.06511207074991973]
	TIME [epoch: 5.72 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057403823664561954		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.057403823664561954 | validation: 0.04964511399579347]
	TIME [epoch: 5.73 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04471684285226643		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.04471684285226643 | validation: 0.059506484897497984]
	TIME [epoch: 5.71 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390659991326903		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.04390659991326903 | validation: 0.05911675437387858]
	TIME [epoch: 5.71 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04496016893438535		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.04496016893438535 | validation: 0.05579938654149421]
	TIME [epoch: 5.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605660803894087		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.04605660803894087 | validation: 0.05440845653200656]
	TIME [epoch: 5.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04804987351849199		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.04804987351849199 | validation: 0.05719475322545263]
	TIME [epoch: 5.72 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045721852531643944		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.045721852531643944 | validation: 0.0656443225251439]
	TIME [epoch: 5.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045623263567966435		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.045623263567966435 | validation: 0.0656423763434686]
	TIME [epoch: 5.71 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049561196646597694		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.049561196646597694 | validation: 0.05591476312156877]
	TIME [epoch: 5.71 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04021509418176061		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.04021509418176061 | validation: 0.05888485053884874]
	TIME [epoch: 5.71 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04806240199150891		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.04806240199150891 | validation: 0.09415493779154471]
	TIME [epoch: 5.71 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061168018457437065		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.061168018457437065 | validation: 0.06354365576396968]
	TIME [epoch: 5.71 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041773785322935256		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.041773785322935256 | validation: 0.059114351042316146]
	TIME [epoch: 5.73 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0506986937711565		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.0506986937711565 | validation: 0.0493614522874791]
	TIME [epoch: 5.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308027759480252		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.04308027759480252 | validation: 0.06226685725492013]
	TIME [epoch: 5.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04825680547309297		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.04825680547309297 | validation: 0.06358618831492381]
	TIME [epoch: 5.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04897128059765929		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.04897128059765929 | validation: 0.06390429289988704]
	TIME [epoch: 5.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046199064214469704		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.046199064214469704 | validation: 0.050765091273883116]
	TIME [epoch: 5.71 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0434166114555789		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0434166114555789 | validation: 0.05437974459941952]
	TIME [epoch: 5.73 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049698120024041		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.049698120024041 | validation: 0.05060775341279835]
	TIME [epoch: 5.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586304990351782		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.04586304990351782 | validation: 0.05390393555223723]
	TIME [epoch: 5.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055005869935921006		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.055005869935921006 | validation: 0.055865558910171434]
	TIME [epoch: 5.71 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042418155341398936		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.042418155341398936 | validation: 0.05764569031584701]
	TIME [epoch: 5.72 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731091728073187		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.04731091728073187 | validation: 0.06244934276847216]
	TIME [epoch: 5.72 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540025719631624		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.04540025719631624 | validation: 0.057448486344410465]
	TIME [epoch: 5.74 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04145773680859552		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.04145773680859552 | validation: 0.05808882200837875]
	TIME [epoch: 5.71 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376825278665955		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0376825278665955 | validation: 0.05903938348613853]
	TIME [epoch: 5.71 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04163629063196925		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.04163629063196925 | validation: 0.05055259418834401]
	TIME [epoch: 5.71 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04133643291527721		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.04133643291527721 | validation: 0.06044052050764579]
	TIME [epoch: 5.71 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050798785389618864		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.050798785389618864 | validation: 0.05832589119885282]
	TIME [epoch: 5.72 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048482116684920765		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.048482116684920765 | validation: 0.048153872937934016]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04006066189807948		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.04006066189807948 | validation: 0.054896899235294436]
	TIME [epoch: 5.71 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04707722871366819		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.04707722871366819 | validation: 0.07160136452709712]
	TIME [epoch: 5.71 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045820179928941975		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.045820179928941975 | validation: 0.0543959273495398]
	TIME [epoch: 5.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04250486428113978		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.04250486428113978 | validation: 0.06736866324977663]
	TIME [epoch: 5.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057759129748176305		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.057759129748176305 | validation: 0.057993375032849404]
	TIME [epoch: 5.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04281462807463029		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.04281462807463029 | validation: 0.05896743184983566]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045459046372184335		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.045459046372184335 | validation: 0.058989533505826294]
	TIME [epoch: 5.71 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047283404210341606		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.047283404210341606 | validation: 0.07018169137918663]
	TIME [epoch: 5.71 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054421655515248954		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.054421655515248954 | validation: 0.05500231400747067]
	TIME [epoch: 5.71 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043036070075152304		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.043036070075152304 | validation: 0.053836992386535394]
	TIME [epoch: 5.71 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041552424337341874		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.041552424337341874 | validation: 0.05149989264950266]
	TIME [epoch: 5.71 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042927890989691964		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.042927890989691964 | validation: 0.058554486521119886]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042983515449384474		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.042983515449384474 | validation: 0.0610247199174872]
	TIME [epoch: 5.71 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903309715255877		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.03903309715255877 | validation: 0.053895614542073034]
	TIME [epoch: 5.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043177376342957624		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.043177376342957624 | validation: 0.05024012377207797]
	TIME [epoch: 5.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04264735803494557		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.04264735803494557 | validation: 0.06427040546393659]
	TIME [epoch: 5.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04324258812851975		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.04324258812851975 | validation: 0.05965453871068755]
	TIME [epoch: 5.71 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605010751969487		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.05605010751969487 | validation: 0.0924661573429507]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06737744070507704		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.06737744070507704 | validation: 0.04580949913107439]
	TIME [epoch: 5.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1226.pth
	Model improved!!!
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03832320519438687		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03832320519438687 | validation: 0.048672017494488955]
	TIME [epoch: 5.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981155561770801		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.04981155561770801 | validation: 0.05931914179261577]
	TIME [epoch: 5.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042499013371582274		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.042499013371582274 | validation: 0.06063819084007952]
	TIME [epoch: 5.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045161465586718325		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.045161465586718325 | validation: 0.06758157442219899]
	TIME [epoch: 5.71 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761677600355631		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.04761677600355631 | validation: 0.06124470253514448]
	TIME [epoch: 5.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0469771090560302		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.0469771090560302 | validation: 0.060195486838412214]
	TIME [epoch: 5.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214504677599337		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.04214504677599337 | validation: 0.05223930505586929]
	TIME [epoch: 5.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729821291789164		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.03729821291789164 | validation: 0.04863744423263354]
	TIME [epoch: 5.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03938100618509706		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.03938100618509706 | validation: 0.04887796010394082]
	TIME [epoch: 5.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04935704582733619		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.04935704582733619 | validation: 0.05264320413578707]
	TIME [epoch: 5.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0432939556912481		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.0432939556912481 | validation: 0.05594434205333777]
	TIME [epoch: 5.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04941388819125918		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.04941388819125918 | validation: 0.060931314112551656]
	TIME [epoch: 5.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213897322766321		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.04213897322766321 | validation: 0.05063313134804883]
	TIME [epoch: 5.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042984882537351006		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.042984882537351006 | validation: 0.06670000740134778]
	TIME [epoch: 5.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647605169558729		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.04647605169558729 | validation: 0.06511550427300794]
	TIME [epoch: 5.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222739397515573		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.05222739397515573 | validation: 0.05509509769828158]
	TIME [epoch: 5.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041077439961184764		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.041077439961184764 | validation: 0.0450512285748137]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1243.pth
	Model improved!!!
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524520915033138		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04524520915033138 | validation: 0.0617188796311311]
	TIME [epoch: 5.71 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04510500665376962		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04510500665376962 | validation: 0.06554219954791035]
	TIME [epoch: 5.71 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049232219696756584		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.049232219696756584 | validation: 0.043593416603562474]
	TIME [epoch: 5.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1246.pth
	Model improved!!!
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049188588006921274		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.049188588006921274 | validation: 0.07681863487976445]
	TIME [epoch: 5.72 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565938998388199		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.05565938998388199 | validation: 0.053234203318951824]
	TIME [epoch: 5.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043950025842254575		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.043950025842254575 | validation: 0.05469471837883935]
	TIME [epoch: 5.73 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04045202310783764		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.04045202310783764 | validation: 0.05695903471334341]
	TIME [epoch: 5.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383511945943733		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.04383511945943733 | validation: 0.05828440228003646]
	TIME [epoch: 5.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184002621837906		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06184002621837906 | validation: 0.08051684926705949]
	TIME [epoch: 5.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052435505523398665		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.052435505523398665 | validation: 0.07180393812609853]
	TIME [epoch: 5.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051105723843609965		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.051105723843609965 | validation: 0.07030633721890077]
	TIME [epoch: 5.71 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048168273904481		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.048168273904481 | validation: 0.0641473005378621]
	TIME [epoch: 5.75 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414449637043187		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.04414449637043187 | validation: 0.06035148465043138]
	TIME [epoch: 5.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049527535636268216		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.049527535636268216 | validation: 0.06349604844119897]
	TIME [epoch: 5.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715755545647777		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.05715755545647777 | validation: 0.05843086510220572]
	TIME [epoch: 5.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049742568142909435		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.049742568142909435 | validation: 0.04714558934581633]
	TIME [epoch: 5.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808142783737206		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.03808142783737206 | validation: 0.06438150963578598]
	TIME [epoch: 5.71 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489834276116797		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.04489834276116797 | validation: 0.06485424986846941]
	TIME [epoch: 5.74 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046698034790129316		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.046698034790129316 | validation: 0.059869530877751015]
	TIME [epoch: 5.7 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413424480239006		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.04413424480239006 | validation: 0.05876839256275792]
	TIME [epoch: 5.71 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05515732486849945		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.05515732486849945 | validation: 0.06298724036723295]
	TIME [epoch: 5.72 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389006816779089		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.04389006816779089 | validation: 0.058379023643800876]
	TIME [epoch: 5.72 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0416655437921819		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0416655437921819 | validation: 0.06738371129929892]
	TIME [epoch: 5.73 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972170838621222		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.03972170838621222 | validation: 0.04779618517159772]
	TIME [epoch: 5.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041345252293465945		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.041345252293465945 | validation: 0.055703992003795555]
	TIME [epoch: 5.72 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581198874431937		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.04581198874431937 | validation: 0.06586244054620423]
	TIME [epoch: 5.71 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04959100425151963		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.04959100425151963 | validation: 0.07100214744424814]
	TIME [epoch: 5.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558035356083939		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.05558035356083939 | validation: 0.050739643381335714]
	TIME [epoch: 5.71 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04199999943078258		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.04199999943078258 | validation: 0.05365283082981462]
	TIME [epoch: 5.71 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044700173424909256		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.044700173424909256 | validation: 0.053765968682074824]
	TIME [epoch: 5.73 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484283221382885		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.0484283221382885 | validation: 0.056361128667001624]
	TIME [epoch: 5.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483021048290557		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.04483021048290557 | validation: 0.059108917980639726]
	TIME [epoch: 5.71 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048867546194159145		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.048867546194159145 | validation: 0.06276631387057346]
	TIME [epoch: 5.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047262229345617315		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.047262229345617315 | validation: 0.04890827487638928]
	TIME [epoch: 5.71 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371883838112954		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.04371883838112954 | validation: 0.061992139246829725]
	TIME [epoch: 5.73 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468156900911212		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0468156900911212 | validation: 0.05459305644944598]
	TIME [epoch: 5.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03826476289349297		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03826476289349297 | validation: 0.0579099334318576]
	TIME [epoch: 5.72 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05000246994051252		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.05000246994051252 | validation: 0.06032855909164342]
	TIME [epoch: 5.71 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999705800093024		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.04999705800093024 | validation: 0.0544214974882385]
	TIME [epoch: 5.71 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03952597146585028		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.03952597146585028 | validation: 0.05836922721433474]
	TIME [epoch: 5.71 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052161795566848884		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.052161795566848884 | validation: 0.05515593543650907]
	TIME [epoch: 5.73 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04123886389216185		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.04123886389216185 | validation: 0.06756481208939313]
	TIME [epoch: 5.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05083856874230984		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.05083856874230984 | validation: 0.05351143546210459]
	TIME [epoch: 5.72 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042206564843521685		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.042206564843521685 | validation: 0.05256852770603527]
	TIME [epoch: 5.71 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05026386005594477		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.05026386005594477 | validation: 0.05233779651213547]
	TIME [epoch: 5.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043269173111970524		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.043269173111970524 | validation: 0.06703827190325788]
	TIME [epoch: 5.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05633046333603048		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.05633046333603048 | validation: 0.057788224172722016]
	TIME [epoch: 5.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789834285981067		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.04789834285981067 | validation: 0.05586192874216513]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04778157712770024		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.04778157712770024 | validation: 0.05128718587870462]
	TIME [epoch: 5.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048992231500676775		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.048992231500676775 | validation: 0.056573878224157846]
	TIME [epoch: 5.71 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047350896029245894		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.047350896029245894 | validation: 0.0575103642113519]
	TIME [epoch: 5.71 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049973905166923724		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.049973905166923724 | validation: 0.07995612601536094]
	TIME [epoch: 5.71 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049387057992046096		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.049387057992046096 | validation: 0.06533450080156933]
	TIME [epoch: 5.72 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209876267598518		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04209876267598518 | validation: 0.05645806321820091]
	TIME [epoch: 5.73 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065346307708731		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.04065346307708731 | validation: 0.06137683100280917]
	TIME [epoch: 5.71 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045030646709369		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.045030646709369 | validation: 0.05007615630411573]
	TIME [epoch: 5.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0557095459808485		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.0557095459808485 | validation: 0.06340861313478081]
	TIME [epoch: 5.72 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003811425613637		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.05003811425613637 | validation: 0.060245194213244785]
	TIME [epoch: 5.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184331054305179		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.04184331054305179 | validation: 0.05518643042668928]
	TIME [epoch: 5.72 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662442701254822		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.04662442701254822 | validation: 0.054396956771311275]
	TIME [epoch: 5.75 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04325706292791444		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.04325706292791444 | validation: 0.06412926551220693]
	TIME [epoch: 5.72 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949010089087843		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.03949010089087843 | validation: 0.047072729564396364]
	TIME [epoch: 5.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0401910237513894		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0401910237513894 | validation: 0.05443743768282463]
	TIME [epoch: 5.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04170540602691632		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.04170540602691632 | validation: 0.05179295447553907]
	TIME [epoch: 5.71 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04250301082944468		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04250301082944468 | validation: 0.05198649587287703]
	TIME [epoch: 5.72 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045145352806108076		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.045145352806108076 | validation: 0.06721318944740214]
	TIME [epoch: 5.76 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049602810879639275		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.049602810879639275 | validation: 0.05425755212545697]
	TIME [epoch: 5.72 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04333350108727776		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.04333350108727776 | validation: 0.06622470091999905]
	TIME [epoch: 5.71 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052409729545345694		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.052409729545345694 | validation: 0.07856378401272716]
	TIME [epoch: 5.72 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049655801152978525		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.049655801152978525 | validation: 0.06522446736908015]
	TIME [epoch: 5.7 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193996752445197		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.04193996752445197 | validation: 0.05186039906614477]
	TIME [epoch: 5.7 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046262426211813534		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.046262426211813534 | validation: 0.0545589024948482]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042840871420806385		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.042840871420806385 | validation: 0.0460233440836823]
	TIME [epoch: 5.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035662864016484754		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.035662864016484754 | validation: 0.057755729621309565]
	TIME [epoch: 5.7 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044846240266367535		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.044846240266367535 | validation: 0.06293052036987717]
	TIME [epoch: 5.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044295947854978014		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.044295947854978014 | validation: 0.04788045727341541]
	TIME [epoch: 5.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037848203872924084		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.037848203872924084 | validation: 0.07250870588397115]
	TIME [epoch: 5.7 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04601766716230184		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.04601766716230184 | validation: 0.045663454189886966]
	TIME [epoch: 5.75 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04804299654134071		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.04804299654134071 | validation: 0.05612133326783827]
	TIME [epoch: 5.71 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694012784378927		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.04694012784378927 | validation: 0.0766896364087473]
	TIME [epoch: 5.72 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053243788751338825		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.053243788751338825 | validation: 0.06120064057362574]
	TIME [epoch: 5.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04408198804171366		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.04408198804171366 | validation: 0.04639302705138509]
	TIME [epoch: 5.71 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427184966910844		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.0427184966910844 | validation: 0.05290735168119992]
	TIME [epoch: 5.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043339434041329304		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.043339434041329304 | validation: 0.05341061509571532]
	TIME [epoch: 5.75 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318966049340408		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.04318966049340408 | validation: 0.05237093547862471]
	TIME [epoch: 5.71 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044236191614191706		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.044236191614191706 | validation: 0.0535527639335481]
	TIME [epoch: 5.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04102252418821496		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.04102252418821496 | validation: 0.05150170054332495]
	TIME [epoch: 5.72 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114317811288577		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.04114317811288577 | validation: 0.05672510554639667]
	TIME [epoch: 5.7 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047082205196795346		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.047082205196795346 | validation: 0.05621767621709524]
	TIME [epoch: 5.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039064497024015196		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.039064497024015196 | validation: 0.059633743082043014]
	TIME [epoch: 5.75 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795813323595612		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03795813323595612 | validation: 0.046341642065356264]
	TIME [epoch: 5.7 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092364472059804		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.05092364472059804 | validation: 0.07444895651285764]
	TIME [epoch: 5.7 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05046632167351041		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.05046632167351041 | validation: 0.050790397224563605]
	TIME [epoch: 5.71 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738648026373249		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.04738648026373249 | validation: 0.06302695118129059]
	TIME [epoch: 5.71 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05070094859121809		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.05070094859121809 | validation: 0.06050437093032902]
	TIME [epoch: 5.72 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853782023700222		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.04853782023700222 | validation: 0.058355788013483297]
	TIME [epoch: 5.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043089710090600086		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.043089710090600086 | validation: 0.05919626342442363]
	TIME [epoch: 5.7 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048618366182329086		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.048618366182329086 | validation: 0.06973396589749246]
	TIME [epoch: 5.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04450775492411618		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.04450775492411618 | validation: 0.05262234346288802]
	TIME [epoch: 5.72 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04167129046471451		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.04167129046471451 | validation: 0.05886418613595186]
	TIME [epoch: 5.71 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0400082098747779		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.0400082098747779 | validation: 0.05751534538954213]
	TIME [epoch: 5.71 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648231894075766		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.04648231894075766 | validation: 0.06419698257101839]
	TIME [epoch: 5.74 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696591992556031		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.04696591992556031 | validation: 0.06351867838324948]
	TIME [epoch: 5.72 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040299846691959774		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.040299846691959774 | validation: 0.05111614494937684]
	TIME [epoch: 5.71 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044672183806656586		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.044672183806656586 | validation: 0.06094503967110276]
	TIME [epoch: 5.71 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04458054225969019		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.04458054225969019 | validation: 0.06184747437362449]
	TIME [epoch: 5.72 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586082682933636		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.04586082682933636 | validation: 0.05216018665114083]
	TIME [epoch: 5.72 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129647463701092		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.05129647463701092 | validation: 0.07305381686332024]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772136075947067		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.04772136075947067 | validation: 0.062616070325952]
	TIME [epoch: 5.72 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04234768436955518		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.04234768436955518 | validation: 0.05426370216909589]
	TIME [epoch: 5.72 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040311085457916465		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.040311085457916465 | validation: 0.048723660931159936]
	TIME [epoch: 5.72 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044174197696453865		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.044174197696453865 | validation: 0.0658506309874498]
	TIME [epoch: 5.71 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04303555754659784		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.04303555754659784 | validation: 0.05558798233451969]
	TIME [epoch: 5.72 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04291842284343318		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.04291842284343318 | validation: 0.052101063243706]
	TIME [epoch: 5.75 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043356867193886456		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.043356867193886456 | validation: 0.056543691399640966]
	TIME [epoch: 5.72 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047922808677455436		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.047922808677455436 | validation: 0.05689239425680604]
	TIME [epoch: 5.72 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803032126905954		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03803032126905954 | validation: 0.07210293791409168]
	TIME [epoch: 5.72 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04437469900064191		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.04437469900064191 | validation: 0.05032437500035468]
	TIME [epoch: 5.72 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046143253972355004		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.046143253972355004 | validation: 0.05392582132742608]
	TIME [epoch: 5.72 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044852789512639255		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.044852789512639255 | validation: 0.060150636890552285]
	TIME [epoch: 5.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047613572186822606		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.047613572186822606 | validation: 0.05039140953118627]
	TIME [epoch: 5.72 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275775599498635		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.04275775599498635 | validation: 0.058918743577252006]
	TIME [epoch: 5.72 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137162836652303		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.04137162836652303 | validation: 0.058546970204842584]
	TIME [epoch: 5.72 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04178000989328632		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.04178000989328632 | validation: 0.05548560479653571]
	TIME [epoch: 5.72 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04055174200464168		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.04055174200464168 | validation: 0.0572741295867709]
	TIME [epoch: 5.72 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04344185602105747		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.04344185602105747 | validation: 0.049029978459520784]
	TIME [epoch: 5.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114788812418506		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.04114788812418506 | validation: 0.0591038512743234]
	TIME [epoch: 5.72 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04213341034604283		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.04213341034604283 | validation: 0.05255091460636775]
	TIME [epoch: 5.72 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000652227103764		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.04000652227103764 | validation: 0.05160806678003496]
	TIME [epoch: 5.72 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828530881703854		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03828530881703854 | validation: 0.05835108889481786]
	TIME [epoch: 5.72 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04375064458021265		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.04375064458021265 | validation: 0.052055476695310986]
	TIME [epoch: 5.72 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04189750218798899		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.04189750218798899 | validation: 0.06210485137550375]
	TIME [epoch: 5.76 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470232261843752		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.04470232261843752 | validation: 0.05828725276193976]
	TIME [epoch: 5.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043990761339884846		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.043990761339884846 | validation: 0.05705682335457672]
	TIME [epoch: 5.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228881310120715		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.04228881310120715 | validation: 0.057097608602032224]
	TIME [epoch: 5.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386589783820176		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0386589783820176 | validation: 0.05131492440468468]
	TIME [epoch: 5.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042890198293981836		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.042890198293981836 | validation: 0.04819746078081777]
	TIME [epoch: 5.72 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041214029038450624		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.041214029038450624 | validation: 0.04884013841077222]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042972984349362316		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.042972984349362316 | validation: 0.06296973433517712]
	TIME [epoch: 5.72 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390563742608604		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.04390563742608604 | validation: 0.05726047955516363]
	TIME [epoch: 5.71 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04245501144830221		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.04245501144830221 | validation: 0.06170723265826312]
	TIME [epoch: 5.72 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196268502247823		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.04196268502247823 | validation: 0.06324716514009066]
	TIME [epoch: 5.71 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04353421660078624		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.04353421660078624 | validation: 0.06050063395049178]
	TIME [epoch: 5.72 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0379116589916904		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.0379116589916904 | validation: 0.06545053392043927]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040269814812108354		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.040269814812108354 | validation: 0.06000046798641868]
	TIME [epoch: 5.71 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398408177841419		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.0398408177841419 | validation: 0.054922925689396815]
	TIME [epoch: 5.72 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04198031900259582		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.04198031900259582 | validation: 0.0456681211048946]
	TIME [epoch: 5.72 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040705535927719146		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.040705535927719146 | validation: 0.05715709746295832]
	TIME [epoch: 5.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04015402243118928		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.04015402243118928 | validation: 0.05789016158204631]
	TIME [epoch: 5.72 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03872701897845357		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.03872701897845357 | validation: 0.05377439927595153]
	TIME [epoch: 5.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04313534269365632		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.04313534269365632 | validation: 0.055394695530188]
	TIME [epoch: 5.73 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04334282753885618		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.04334282753885618 | validation: 0.055317403668019946]
	TIME [epoch: 5.72 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04321432001978502		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.04321432001978502 | validation: 0.061389491122242124]
	TIME [epoch: 5.72 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04336893203792122		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.04336893203792122 | validation: 0.052629698835184174]
	TIME [epoch: 5.72 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044485560319113986		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.044485560319113986 | validation: 0.06475353327278664]
	TIME [epoch: 5.72 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04862393536447999		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.04862393536447999 | validation: 0.049354362817282046]
	TIME [epoch: 5.74 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034812674166698		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.04034812674166698 | validation: 0.04853078567069656]
	TIME [epoch: 5.72 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042958272733785274		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.042958272733785274 | validation: 0.052870787435425406]
	TIME [epoch: 5.72 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0421368075335702		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.0421368075335702 | validation: 0.060259047428169926]
	TIME [epoch: 5.72 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04832377247369532		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.04832377247369532 | validation: 0.06496596835595314]
	TIME [epoch: 5.72 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04643836828012335		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.04643836828012335 | validation: 0.05247031720804842]
	TIME [epoch: 5.72 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040595213250112915		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.040595213250112915 | validation: 0.061322727698467666]
	TIME [epoch: 5.73 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04011917578281599		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.04011917578281599 | validation: 0.06867233450603412]
	TIME [epoch: 5.71 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05010253874365089		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.05010253874365089 | validation: 0.062481808255047074]
	TIME [epoch: 5.72 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05037182694340416		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05037182694340416 | validation: 0.053847312695273715]
	TIME [epoch: 5.72 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041612127215068996		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.041612127215068996 | validation: 0.047489724812901785]
	TIME [epoch: 5.72 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040762476533624595		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.040762476533624595 | validation: 0.06012398081124998]
	TIME [epoch: 5.72 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04232876333512829		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.04232876333512829 | validation: 0.06009941424711045]
	TIME [epoch: 5.76 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04016506802691699		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.04016506802691699 | validation: 0.05240987984597171]
	TIME [epoch: 5.71 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04519217859629573		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04519217859629573 | validation: 0.07306035702100726]
	TIME [epoch: 5.72 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388293612437704		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.05388293612437704 | validation: 0.07770093495022039]
	TIME [epoch: 5.72 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051179724757278666		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.051179724757278666 | validation: 0.05889366863833484]
	TIME [epoch: 5.72 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04400379765306153		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.04400379765306153 | validation: 0.06410758133849888]
	TIME [epoch: 5.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684927822551294		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.04684927822551294 | validation: 0.05334932445137277]
	TIME [epoch: 5.76 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666596601188862		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.04666596601188862 | validation: 0.05588869007774764]
	TIME [epoch: 5.72 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04077254601905701		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.04077254601905701 | validation: 0.06056299436617023]
	TIME [epoch: 5.72 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040971455148717306		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.040971455148717306 | validation: 0.05895778354040025]
	TIME [epoch: 5.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04454150729016821		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.04454150729016821 | validation: 0.06168534644427693]
	TIME [epoch: 5.72 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735302929190408		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.04735302929190408 | validation: 0.05702927223627745]
	TIME [epoch: 5.71 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04059559272633627		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.04059559272633627 | validation: 0.05756121400999074]
	TIME [epoch: 5.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039756423347369035		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.039756423347369035 | validation: 0.05341961647686226]
	TIME [epoch: 5.72 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045854156058917434		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.045854156058917434 | validation: 0.053626987473310204]
	TIME [epoch: 5.7 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037847410907437075		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.037847410907437075 | validation: 0.06444945771272506]
	TIME [epoch: 5.72 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081816749557852		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.04081816749557852 | validation: 0.05769676760127283]
	TIME [epoch: 5.7 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04422708800011773		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.04422708800011773 | validation: 0.0625074078543804]
	TIME [epoch: 5.71 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0447760049864562		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.0447760049864562 | validation: 0.049083627703216004]
	TIME [epoch: 5.76 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04414153976972995		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.04414153976972995 | validation: 0.04437271391389435]
	TIME [epoch: 5.72 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04152102770128997		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.04152102770128997 | validation: 0.047599618567159226]
	TIME [epoch: 5.71 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03867300604587542		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.03867300604587542 | validation: 0.05213019666138691]
	TIME [epoch: 5.72 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045817752850921		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.045817752850921 | validation: 0.06888869267988156]
	TIME [epoch: 5.71 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05194945434027713		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.05194945434027713 | validation: 0.06439100342068904]
	TIME [epoch: 5.72 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069391226935487		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.05069391226935487 | validation: 0.049284397640270726]
	TIME [epoch: 5.76 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420431985553492		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0420431985553492 | validation: 0.04499353063848073]
	TIME [epoch: 5.74 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041460985487044		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.04041460985487044 | validation: 0.05177017606748415]
	TIME [epoch: 5.72 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366671358133701		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.04366671358133701 | validation: 0.05474103601493263]
	TIME [epoch: 5.71 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039754060984293876		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.039754060984293876 | validation: 0.05431025772126484]
	TIME [epoch: 5.72 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709424156850057		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.03709424156850057 | validation: 0.05242639091018747]
	TIME [epoch: 5.72 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03874859368160146		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03874859368160146 | validation: 0.0533459067564373]
	TIME [epoch: 5.76 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798062261802565		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.04798062261802565 | validation: 0.054177940302673554]
	TIME [epoch: 5.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132454029105173		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.04132454029105173 | validation: 0.05006522199973923]
	TIME [epoch: 5.72 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039929353285239874		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.039929353285239874 | validation: 0.05171583841482337]
	TIME [epoch: 5.72 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037384197690243884		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.037384197690243884 | validation: 0.05546091800572194]
	TIME [epoch: 5.7 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04007002550328851		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.04007002550328851 | validation: 0.06041329447549732]
	TIME [epoch: 5.72 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039359587561680745		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.039359587561680745 | validation: 0.05853531642812163]
	TIME [epoch: 5.76 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209999167753586		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.04209999167753586 | validation: 0.057944365179229934]
	TIME [epoch: 5.72 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050637965911219024		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.050637965911219024 | validation: 0.04838671910201499]
	TIME [epoch: 5.72 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039065826160761326		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.039065826160761326 | validation: 0.05280434327199652]
	TIME [epoch: 5.71 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03804802734380604		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.03804802734380604 | validation: 0.050787489740294484]
	TIME [epoch: 5.72 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154881422404098		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.04154881422404098 | validation: 0.047293635070061686]
	TIME [epoch: 5.72 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480992860576335		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.04480992860576335 | validation: 0.048518918952937716]
	TIME [epoch: 5.76 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04064036200696619		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.04064036200696619 | validation: 0.053252065170749215]
	TIME [epoch: 5.72 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03868182518515357		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.03868182518515357 | validation: 0.048624535133758036]
	TIME [epoch: 5.72 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041339728783164144		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.041339728783164144 | validation: 0.05911282182097773]
	TIME [epoch: 5.72 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04151799430623688		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.04151799430623688 | validation: 0.058926581197399956]
	TIME [epoch: 5.72 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0396402760085945		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0396402760085945 | validation: 0.054624600996585074]
	TIME [epoch: 5.72 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891618740094886		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.04891618740094886 | validation: 0.06074588356578914]
	TIME [epoch: 5.76 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112790380761332		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.04112790380761332 | validation: 0.05531811278790581]
	TIME [epoch: 5.72 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471788270758004		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.0471788270758004 | validation: 0.05233852359497136]
	TIME [epoch: 5.72 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04128058404504875		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.04128058404504875 | validation: 0.06491917688008313]
	TIME [epoch: 5.71 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04284730601384008		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.04284730601384008 | validation: 0.06168817528574089]
	TIME [epoch: 5.72 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041037773015294265		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.041037773015294265 | validation: 0.055784461294629245]
	TIME [epoch: 5.71 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04306345036679922		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.04306345036679922 | validation: 0.05732602524369661]
	TIME [epoch: 5.75 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039671873176151264		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.039671873176151264 | validation: 0.051735989226865835]
	TIME [epoch: 5.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04029604053261111		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.04029604053261111 | validation: 0.0535263041783867]
	TIME [epoch: 5.72 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244489894094923		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.04244489894094923 | validation: 0.05764117066770165]
	TIME [epoch: 5.72 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03854431428708348		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.03854431428708348 | validation: 0.06487102626868568]
	TIME [epoch: 5.72 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850410408830689		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.03850410408830689 | validation: 0.05673836467814313]
	TIME [epoch: 5.7 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037983569764840255		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.037983569764840255 | validation: 0.05580698229573592]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037996403477042834		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.037996403477042834 | validation: 0.05802635784795454]
	TIME [epoch: 5.71 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042227710763786855		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.042227710763786855 | validation: 0.062226905167203896]
	TIME [epoch: 5.7 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040287662175239054		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.040287662175239054 | validation: 0.05222395755865919]
	TIME [epoch: 5.72 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037264350915337446		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.037264350915337446 | validation: 0.05875011564056426]
	TIME [epoch: 5.72 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922870410379166		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.03922870410379166 | validation: 0.056710858473481764]
	TIME [epoch: 5.71 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04334684442027556		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.04334684442027556 | validation: 0.05383539601494887]
	TIME [epoch: 5.75 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162931236933953		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.04162931236933953 | validation: 0.053251008555362134]
	TIME [epoch: 5.71 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035536035971022305		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.035536035971022305 | validation: 0.05463846921145147]
	TIME [epoch: 5.7 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041297607083203305		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.041297607083203305 | validation: 0.05171171587489462]
	TIME [epoch: 5.7 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039666307720556876		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.039666307720556876 | validation: 0.05240280661678215]
	TIME [epoch: 5.7 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04596815426235441		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.04596815426235441 | validation: 0.048388444048622796]
	TIME [epoch: 5.7 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986322659115349		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.03986322659115349 | validation: 0.0529665844742393]
	TIME [epoch: 5.74 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042801367673914736		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.042801367673914736 | validation: 0.05382925454691192]
	TIME [epoch: 5.71 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039347629274183796		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.039347629274183796 | validation: 0.06003727692074957]
	TIME [epoch: 5.7 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406788052978221		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.0406788052978221 | validation: 0.06166985733650746]
	TIME [epoch: 5.7 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04375847721407218		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.04375847721407218 | validation: 0.05676446009327496]
	TIME [epoch: 5.7 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04040906167396331		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.04040906167396331 | validation: 0.060107254537465064]
	TIME [epoch: 5.7 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176831614775628		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.04176831614775628 | validation: 0.05719718792350854]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04247192708672899		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.04247192708672899 | validation: 0.05640061710299467]
	TIME [epoch: 5.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040561414469037715		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.040561414469037715 | validation: 0.05548705038784526]
	TIME [epoch: 5.72 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04055188067663945		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.04055188067663945 | validation: 0.055689069448082724]
	TIME [epoch: 5.7 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038981438887114		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.04038981438887114 | validation: 0.05385595494523512]
	TIME [epoch: 5.72 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383075571252903		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.04383075571252903 | validation: 0.05542233447743659]
	TIME [epoch: 5.71 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044319968274476984		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.044319968274476984 | validation: 0.063221527910264]
	TIME [epoch: 5.75 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162009846652712		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.04162009846652712 | validation: 0.05421472923565463]
	TIME [epoch: 5.72 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773882036006496		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.03773882036006496 | validation: 0.05695037244585236]
	TIME [epoch: 5.71 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366290528554856		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.0366290528554856 | validation: 0.057721911680031365]
	TIME [epoch: 5.72 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214810892690113		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.04214810892690113 | validation: 0.060272363467810015]
	TIME [epoch: 5.72 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03958308550834688		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.03958308550834688 | validation: 0.0566833687873111]
	TIME [epoch: 5.72 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805358132583422		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.03805358132583422 | validation: 0.04801263791557239]
	TIME [epoch: 5.75 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337630148206249		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.04337630148206249 | validation: 0.057776867620936645]
	TIME [epoch: 5.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04107837052598984		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.04107837052598984 | validation: 0.05692195773643505]
	TIME [epoch: 5.71 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040679495045795266		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.040679495045795266 | validation: 0.06726798085839943]
	TIME [epoch: 5.72 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04141850747353615		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.04141850747353615 | validation: 0.053347589543631856]
	TIME [epoch: 5.71 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893067685399356		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.03893067685399356 | validation: 0.05393446267745738]
	TIME [epoch: 5.71 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037416030997401886		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.037416030997401886 | validation: 0.04627021664798286]
	TIME [epoch: 5.76 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612042978315001		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.03612042978315001 | validation: 0.05578004603013669]
	TIME [epoch: 5.72 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039400774789350106		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.039400774789350106 | validation: 0.05311861002774687]
	TIME [epoch: 5.72 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03832344261179804		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.03832344261179804 | validation: 0.056689173980769975]
	TIME [epoch: 5.72 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038398341607612185		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.038398341607612185 | validation: 0.05856177642384282]
	TIME [epoch: 5.69 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040047188560465366		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.040047188560465366 | validation: 0.047460955737972405]
	TIME [epoch: 5.71 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037416816696258966		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.037416816696258966 | validation: 0.05217126759375366]
	TIME [epoch: 5.74 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040138437044407414		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.040138437044407414 | validation: 0.05106464325611553]
	TIME [epoch: 5.71 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044657201588044274		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.044657201588044274 | validation: 0.06866543791939163]
	TIME [epoch: 5.7 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03957325566139659		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.03957325566139659 | validation: 0.055705228418263426]
	TIME [epoch: 5.71 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930897462709078		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.03930897462709078 | validation: 0.05900067250234314]
	TIME [epoch: 5.72 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653919106529328		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.04653919106529328 | validation: 0.058731613160243515]
	TIME [epoch: 5.72 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04822848467921567		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.04822848467921567 | validation: 0.0579872766816337]
	TIME [epoch: 5.75 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04045285089552947		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.04045285089552947 | validation: 0.053422174353224924]
	TIME [epoch: 5.73 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03872863531649868		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.03872863531649868 | validation: 0.054922364934172095]
	TIME [epoch: 5.72 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038104906455642615		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.038104906455642615 | validation: 0.053824555789485]
	TIME [epoch: 5.72 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04020744066802239		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.04020744066802239 | validation: 0.057992152239588625]
	TIME [epoch: 5.71 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03732747480427768		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.03732747480427768 | validation: 0.05577123986692234]
	TIME [epoch: 5.7 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042129144039970964		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.042129144039970964 | validation: 0.054903504241570956]
	TIME [epoch: 5.73 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038617890366344235		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.038617890366344235 | validation: 0.053659745005729835]
	TIME [epoch: 5.71 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04212203006332871		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.04212203006332871 | validation: 0.05534038249792325]
	TIME [epoch: 5.7 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356523617829634		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.04356523617829634 | validation: 0.04863723271576736]
	TIME [epoch: 5.7 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03958687753330356		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03958687753330356 | validation: 0.05186247182332908]
	TIME [epoch: 5.7 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000509373239167		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.04000509373239167 | validation: 0.053590651406245915]
	TIME [epoch: 5.7 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04074858881245508		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.04074858881245508 | validation: 0.04571228369793949]
	TIME [epoch: 5.73 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042666200475417304		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.042666200475417304 | validation: 0.04845694158095751]
	TIME [epoch: 5.71 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048931632667992796		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.048931632667992796 | validation: 0.05392391407950789]
	TIME [epoch: 5.7 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04181324449225972		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.04181324449225972 | validation: 0.05544947363146491]
	TIME [epoch: 5.7 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041651796250830375		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.041651796250830375 | validation: 0.059206664445067274]
	TIME [epoch: 5.7 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04119810863769745		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.04119810863769745 | validation: 0.05593855102103122]
	TIME [epoch: 5.7 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039585682888968576		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.039585682888968576 | validation: 0.05221726807056386]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03326522327784939		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.03326522327784939 | validation: 0.05250989394704604]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039384001730323345		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.039384001730323345 | validation: 0.050093557860511714]
	TIME [epoch: 5.7 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039405152701074544		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.039405152701074544 | validation: 0.053349102046500986]
	TIME [epoch: 5.7 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395536500945426		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.0395536500945426 | validation: 0.052366274876315407]
	TIME [epoch: 5.7 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04191122723980291		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.04191122723980291 | validation: 0.05571782702603475]
	TIME [epoch: 5.7 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041761008845457775		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.041761008845457775 | validation: 0.05415998981405379]
	TIME [epoch: 5.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03676667108795994		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.03676667108795994 | validation: 0.05020205192264232]
	TIME [epoch: 5.71 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385257848270149		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.04385257848270149 | validation: 0.04389295011387353]
	TIME [epoch: 5.7 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03619258903174793		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.03619258903174793 | validation: 0.052506134801888996]
	TIME [epoch: 5.7 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069278552999525		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.04069278552999525 | validation: 0.050792784190806774]
	TIME [epoch: 5.7 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042191457951423206		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.042191457951423206 | validation: 0.04967030264475194]
	TIME [epoch: 5.7 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03507536220722152		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.03507536220722152 | validation: 0.061287576155360936]
	TIME [epoch: 5.73 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776305470358908		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.03776305470358908 | validation: 0.0524045128570997]
	TIME [epoch: 5.71 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747397791219195		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.03747397791219195 | validation: 0.051480845786153404]
	TIME [epoch: 5.7 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041357651022785144		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.041357651022785144 | validation: 0.05672983793073417]
	TIME [epoch: 5.7 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040747512761289593		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.040747512761289593 | validation: 0.05331671942259542]
	TIME [epoch: 5.7 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975967558588839		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.03975967558588839 | validation: 0.04917213161508995]
	TIME [epoch: 5.7 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04066727944234475		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.04066727944234475 | validation: 0.04971722073486649]
	TIME [epoch: 5.72 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041228842689266784		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.041228842689266784 | validation: 0.06279058380733446]
	TIME [epoch: 5.71 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309649164440472		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.04309649164440472 | validation: 0.05861733921294556]
	TIME [epoch: 5.7 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04266105910593005		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.04266105910593005 | validation: 0.05657309838996445]
	TIME [epoch: 5.7 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038629695499500266		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.038629695499500266 | validation: 0.04483799017946436]
	TIME [epoch: 5.7 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03866177793804483		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03866177793804483 | validation: 0.04845648640799209]
	TIME [epoch: 5.71 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043294938819270996		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.043294938819270996 | validation: 0.04651931133457249]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065973193129159		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.04065973193129159 | validation: 0.05817675432590722]
	TIME [epoch: 5.71 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034155840111943		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.04034155840111943 | validation: 0.05272550511900732]
	TIME [epoch: 5.7 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994496187844389		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.03994496187844389 | validation: 0.06075926295442331]
	TIME [epoch: 5.7 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04321493831964095		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.04321493831964095 | validation: 0.05665966506505875]
	TIME [epoch: 5.7 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044130771908062826		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.044130771908062826 | validation: 0.057789194987266555]
	TIME [epoch: 5.72 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045638175405615246		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.045638175405615246 | validation: 0.05700094185937582]
	TIME [epoch: 5.75 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403586852537094		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.04403586852537094 | validation: 0.05453941241555226]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043516143993291116		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.043516143993291116 | validation: 0.06531437383972116]
	TIME [epoch: 5.72 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040642441362423204		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.040642441362423204 | validation: 0.0441661252154627]
	TIME [epoch: 5.7 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04366397193640621		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.04366397193640621 | validation: 0.05520758579541012]
	TIME [epoch: 5.71 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903666923932567		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.03903666923932567 | validation: 0.058140218810991476]
	TIME [epoch: 5.71 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048623802012831466		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.048623802012831466 | validation: 0.059122586637082]
	TIME [epoch: 5.74 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04814819776068875		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.04814819776068875 | validation: 0.06231936453797289]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04477705359565391		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.04477705359565391 | validation: 0.05396598713976621]
	TIME [epoch: 5.71 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04281224873467536		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.04281224873467536 | validation: 0.05100848149226632]
	TIME [epoch: 5.71 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594102907892907		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.04594102907892907 | validation: 0.06470774069083012]
	TIME [epoch: 5.71 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04779682185400545		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.04779682185400545 | validation: 0.05659917858990711]
	TIME [epoch: 5.7 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04282683058978624		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.04282683058978624 | validation: 0.05381547443555389]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03936282106041158		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.03936282106041158 | validation: 0.05298219851668058]
	TIME [epoch: 5.71 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039375838855535326		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.039375838855535326 | validation: 0.06292951037463577]
	TIME [epoch: 5.7 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038366245294506336		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.038366245294506336 | validation: 0.04805196494091329]
	TIME [epoch: 5.72 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04018146162122596		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.04018146162122596 | validation: 0.05616568258985187]
	TIME [epoch: 5.7 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03829024954883952		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.03829024954883952 | validation: 0.05525059610893642]
	TIME [epoch: 5.7 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039408923845107		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.04039408923845107 | validation: 0.047107336560528686]
	TIME [epoch: 5.73 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04073795965264646		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.04073795965264646 | validation: 0.053170961864139984]
	TIME [epoch: 5.71 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037871595525248505		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.037871595525248505 | validation: 0.049410551232029934]
	TIME [epoch: 5.7 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038288046459290244		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.038288046459290244 | validation: 0.044547163422697836]
	TIME [epoch: 5.7 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04056153725564367		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.04056153725564367 | validation: 0.04381992912969808]
	TIME [epoch: 5.7 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040170675993461614		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.040170675993461614 | validation: 0.050102836846709076]
	TIME [epoch: 5.7 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944813472577679		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.03944813472577679 | validation: 0.05329015933836086]
	TIME [epoch: 5.71 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03931763309438556		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.03931763309438556 | validation: 0.05822030795503241]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04311053196066894		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.04311053196066894 | validation: 0.07251571864212947]
	TIME [epoch: 5.72 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048644852355040444		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.048644852355040444 | validation: 0.06864440432450421]
	TIME [epoch: 5.72 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043292646124482734		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.043292646124482734 | validation: 0.057970170085368714]
	TIME [epoch: 5.71 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307326696511461		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.04307326696511461 | validation: 0.055645823285377614]
	TIME [epoch: 5.71 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991405751899445		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.03991405751899445 | validation: 0.050172429970974354]
	TIME [epoch: 5.73 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184306647705575		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.04184306647705575 | validation: 0.057117799679351135]
	TIME [epoch: 5.74 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045334395258479016		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.045334395258479016 | validation: 0.05023804003145096]
	TIME [epoch: 5.71 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036779708806941654		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.036779708806941654 | validation: 0.054209308385327275]
	TIME [epoch: 5.71 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04030005509671257		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.04030005509671257 | validation: 0.052997154531819905]
	TIME [epoch: 5.71 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04343913396612359		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.04343913396612359 | validation: 0.06077449915264014]
	TIME [epoch: 5.71 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04180124763809585		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.04180124763809585 | validation: 0.043881605757556785]
	TIME [epoch: 5.72 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036885096639389256		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.036885096639389256 | validation: 0.055993129947024996]
	TIME [epoch: 5.72 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036494768081292164		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.036494768081292164 | validation: 0.06008478964633191]
	TIME [epoch: 5.71 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04097475249794627		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.04097475249794627 | validation: 0.053381675855385745]
	TIME [epoch: 5.71 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044670623475773594		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.044670623475773594 | validation: 0.06360265862520169]
	TIME [epoch: 5.7 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406646330853883		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.0406646330853883 | validation: 0.061462978266067066]
	TIME [epoch: 5.7 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0423068966452183		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.0423068966452183 | validation: 0.06188356912408167]
	TIME [epoch: 5.72 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847122766757907		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.03847122766757907 | validation: 0.04935857847734296]
	TIME [epoch: 5.74 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042284742917962054		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.042284742917962054 | validation: 0.05429026295650996]
	TIME [epoch: 5.72 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03916340676435037		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.03916340676435037 | validation: 0.058786861568694934]
	TIME [epoch: 5.71 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761195949331272		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.03761195949331272 | validation: 0.04572200073682265]
	TIME [epoch: 5.71 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040000880046015194		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.040000880046015194 | validation: 0.06444357945287467]
	TIME [epoch: 5.71 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038363386481670536		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.038363386481670536 | validation: 0.05375658452369212]
	TIME [epoch: 5.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039315433213717096		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.039315433213717096 | validation: 0.04993147163062275]
	TIME [epoch: 5.74 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039840568789389935		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.039840568789389935 | validation: 0.05053579222437824]
	TIME [epoch: 5.72 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04319949022089076		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.04319949022089076 | validation: 0.06091332568218712]
	TIME [epoch: 5.72 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04079023908341908		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.04079023908341908 | validation: 0.055978876310667385]
	TIME [epoch: 5.7 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04400325363492807		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.04400325363492807 | validation: 0.04763368719349615]
	TIME [epoch: 5.69 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159442746708807		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.04159442746708807 | validation: 0.0460762122757005]
	TIME [epoch: 5.71 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03421223443877886		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.03421223443877886 | validation: 0.0577990383438261]
	TIME [epoch: 5.72 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03950468763721838		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.03950468763721838 | validation: 0.05863824699664666]
	TIME [epoch: 5.7 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03765565035646648		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.03765565035646648 | validation: 0.05914048543642029]
	TIME [epoch: 5.7 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039842135001383734		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.039842135001383734 | validation: 0.049472156483925576]
	TIME [epoch: 5.69 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038938714657419014		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.038938714657419014 | validation: 0.05516446746218194]
	TIME [epoch: 5.69 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353121314392293		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.0353121314392293 | validation: 0.05783955646111188]
	TIME [epoch: 5.7 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035833310513816136		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.035833310513816136 | validation: 0.05718163774748046]
	TIME [epoch: 5.72 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730555624858311		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.03730555624858311 | validation: 0.06168490378176668]
	TIME [epoch: 5.72 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037347933311850254		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.037347933311850254 | validation: 0.0524250898980808]
	TIME [epoch: 5.72 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876880136892357		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03876880136892357 | validation: 0.057536386081327495]
	TIME [epoch: 5.72 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037029569894727256		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.037029569894727256 | validation: 0.05832212977778251]
	TIME [epoch: 5.72 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860119532476269		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.03860119532476269 | validation: 0.051345570152902024]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040686222519165094		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.040686222519165094 | validation: 0.05083036655671535]
	TIME [epoch: 5.75 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044594335230919616		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.044594335230919616 | validation: 0.046507379610305113]
	TIME [epoch: 5.72 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972720025293616		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03972720025293616 | validation: 0.05406853642816484]
	TIME [epoch: 5.72 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840850012698895		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03840850012698895 | validation: 0.05529010850533449]
	TIME [epoch: 5.72 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039766634812524834		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.039766634812524834 | validation: 0.06511769492329408]
	TIME [epoch: 5.72 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038636090383495254		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.038636090383495254 | validation: 0.05819517092020541]
	TIME [epoch: 5.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920202176926901		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.03920202176926901 | validation: 0.05449086156200843]
	TIME [epoch: 5.75 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03573871657630487		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.03573871657630487 | validation: 0.05195719369936892]
	TIME [epoch: 5.72 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040831558913869206		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.040831558913869206 | validation: 0.05140256725107321]
	TIME [epoch: 5.72 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797052950580247		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.03797052950580247 | validation: 0.05439497950003508]
	TIME [epoch: 5.72 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03979701340952473		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.03979701340952473 | validation: 0.04672813252270859]
	TIME [epoch: 5.72 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04058619496291911		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.04058619496291911 | validation: 0.05250233398128745]
	TIME [epoch: 5.73 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825260763001049		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.03825260763001049 | validation: 0.05723886763783387]
	TIME [epoch: 5.72 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387265271962946		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.0387265271962946 | validation: 0.05394555711803856]
	TIME [epoch: 5.72 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467681527276699		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03467681527276699 | validation: 0.057656770590266346]
	TIME [epoch: 5.72 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04221940385381777		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.04221940385381777 | validation: 0.05324605991964305]
	TIME [epoch: 5.71 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343343503670992		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.0343343503670992 | validation: 0.05676477802903962]
	TIME [epoch: 5.69 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04095772481231164		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.04095772481231164 | validation: 0.05632121191815416]
	TIME [epoch: 5.71 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04605294819412677		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.04605294819412677 | validation: 0.050283904517246354]
	TIME [epoch: 5.72 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326157876103289		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.04326157876103289 | validation: 0.04796342749328997]
	TIME [epoch: 5.7 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03683161874496704		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.03683161874496704 | validation: 0.05492047550247271]
	TIME [epoch: 5.71 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03733890669827341		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.03733890669827341 | validation: 0.052110417172653974]
	TIME [epoch: 5.71 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03720773703972456		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.03720773703972456 | validation: 0.04648068056914398]
	TIME [epoch: 5.72 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038159483756715684		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.038159483756715684 | validation: 0.05103281664633563]
	TIME [epoch: 5.73 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03723684448147581		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.03723684448147581 | validation: 0.04825816008382321]
	TIME [epoch: 5.74 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040380177561010526		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.040380177561010526 | validation: 0.05069376706823098]
	TIME [epoch: 5.72 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475551333712369		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.03475551333712369 | validation: 0.05713056181471238]
	TIME [epoch: 5.72 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03830084491954807		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.03830084491954807 | validation: 0.056065768160944024]
	TIME [epoch: 5.72 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038177759773534506		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.038177759773534506 | validation: 0.056651440676929]
	TIME [epoch: 5.71 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713131930510668		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.03713131930510668 | validation: 0.05873336996141598]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142994505244098		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.04142994505244098 | validation: 0.047389680658883215]
	TIME [epoch: 5.74 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730684876487933		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.03730684876487933 | validation: 0.03872285193087316]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1665.pth
	Model improved!!!
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03746977182754842		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.03746977182754842 | validation: 0.059235689540326195]
	TIME [epoch: 5.71 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03898204510467259		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.03898204510467259 | validation: 0.05767779221088766]
	TIME [epoch: 5.71 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838350106793896		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.03838350106793896 | validation: 0.04670736236978614]
	TIME [epoch: 5.72 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038239197038373716		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.038239197038373716 | validation: 0.047505544160872396]
	TIME [epoch: 5.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035208657675098946		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.035208657675098946 | validation: 0.052103488942874754]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042785939188802455		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.042785939188802455 | validation: 0.055349286048128124]
	TIME [epoch: 5.71 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673964184724049		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.03673964184724049 | validation: 0.059812897926196394]
	TIME [epoch: 5.72 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039079577217703734		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.039079577217703734 | validation: 0.05566079462594331]
	TIME [epoch: 5.71 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177574366491817		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.04177574366491817 | validation: 0.05278864112818164]
	TIME [epoch: 5.7 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04043009803317878		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.04043009803317878 | validation: 0.05352082614866061]
	TIME [epoch: 5.71 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099591540678208		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.04099591540678208 | validation: 0.05302098139563367]
	TIME [epoch: 5.72 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03975633057982222		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.03975633057982222 | validation: 0.0561851705987395]
	TIME [epoch: 5.7 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03980251348264482		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.03980251348264482 | validation: 0.052403412910645396]
	TIME [epoch: 5.7 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03878906344869334		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.03878906344869334 | validation: 0.05060850872858172]
	TIME [epoch: 5.7 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265912219772989		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.04265912219772989 | validation: 0.05228352141506559]
	TIME [epoch: 5.7 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03937465016054301		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.03937465016054301 | validation: 0.05525155677544917]
	TIME [epoch: 5.71 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112290292040877		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.04112290292040877 | validation: 0.049381349557366276]
	TIME [epoch: 5.72 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04092037041189313		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.04092037041189313 | validation: 0.040626556224071936]
	TIME [epoch: 5.7 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03782212976213088		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.03782212976213088 | validation: 0.050490433703301314]
	TIME [epoch: 5.7 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041660467350987426		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.041660467350987426 | validation: 0.057459423254993584]
	TIME [epoch: 5.69 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03575477858528288		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.03575477858528288 | validation: 0.05157111929668126]
	TIME [epoch: 5.71 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383679294594282		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.0383679294594282 | validation: 0.053084695881178305]
	TIME [epoch: 5.71 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036563917899899094		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.036563917899899094 | validation: 0.05399385482382589]
	TIME [epoch: 5.72 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04201411606175672		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.04201411606175672 | validation: 0.055821838848846464]
	TIME [epoch: 5.7 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009066054464192		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.04009066054464192 | validation: 0.05745095114715501]
	TIME [epoch: 5.7 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039937492618526665		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.039937492618526665 | validation: 0.05624511625533216]
	TIME [epoch: 5.7 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03788171941637103		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.03788171941637103 | validation: 0.048268683660525995]
	TIME [epoch: 5.7 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254782259240307		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.04254782259240307 | validation: 0.06360960169292812]
	TIME [epoch: 5.71 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03979559493456258		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.03979559493456258 | validation: 0.04743086833621088]
	TIME [epoch: 5.72 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038586985528209904		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.038586985528209904 | validation: 0.048977655513766934]
	TIME [epoch: 5.7 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0364772128048724		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.0364772128048724 | validation: 0.04799342876455689]
	TIME [epoch: 5.69 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824726961941437		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.03824726961941437 | validation: 0.05005954146017749]
	TIME [epoch: 5.69 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032570931120867494		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.032570931120867494 | validation: 0.05146813131444028]
	TIME [epoch: 5.71 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03714062202985556		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.03714062202985556 | validation: 0.053188314523978965]
	TIME [epoch: 5.71 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03659740272967915		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.03659740272967915 | validation: 0.056209871277443056]
	TIME [epoch: 5.74 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03892519572817521		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.03892519572817521 | validation: 0.04685763371452414]
	TIME [epoch: 5.7 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039246425276854575		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.039246425276854575 | validation: 0.04866778137102929]
	TIME [epoch: 5.72 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794239774106894		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.03794239774106894 | validation: 0.05315309868843164]
	TIME [epoch: 5.71 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04106792535633376		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.04106792535633376 | validation: 0.04871322760344229]
	TIME [epoch: 5.71 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03754748308321799		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03754748308321799 | validation: 0.04669065943232909]
	TIME [epoch: 5.72 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03218370734477446		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.03218370734477446 | validation: 0.05107022138175351]
	TIME [epoch: 5.74 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761527590384916		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.03761527590384916 | validation: 0.0523043824271422]
	TIME [epoch: 5.71 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039163424919000364		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.039163424919000364 | validation: 0.05222997510313249]
	TIME [epoch: 5.71 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04206886550042153		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.04206886550042153 | validation: 0.05149297651420749]
	TIME [epoch: 5.7 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039231394313015845		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.039231394313015845 | validation: 0.056155816551508926]
	TIME [epoch: 5.71 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041916243381795955		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.041916243381795955 | validation: 0.04842682609795976]
	TIME [epoch: 5.71 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039998499466303		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.04039998499466303 | validation: 0.050288724485923635]
	TIME [epoch: 5.74 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040751783195005636		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.040751783195005636 | validation: 0.06222341480811479]
	TIME [epoch: 5.7 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03673244722859724		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.03673244722859724 | validation: 0.0550900976306421]
	TIME [epoch: 5.7 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041855497034054216		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.041855497034054216 | validation: 0.04526655674127215]
	TIME [epoch: 5.7 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040559755525870864		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.040559755525870864 | validation: 0.04543710789116897]
	TIME [epoch: 5.7 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04057019787087647		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.04057019787087647 | validation: 0.055090516792360024]
	TIME [epoch: 5.71 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03937337758585174		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.03937337758585174 | validation: 0.057453500961020365]
	TIME [epoch: 5.72 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037627290032991687		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.037627290032991687 | validation: 0.051048205142930216]
	TIME [epoch: 5.69 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779147615024961		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.03779147615024961 | validation: 0.050181850967449135]
	TIME [epoch: 5.7 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03756145685285823		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.03756145685285823 | validation: 0.05191672698187182]
	TIME [epoch: 5.7 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860169337255703		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.03860169337255703 | validation: 0.05767805709586256]
	TIME [epoch: 5.7 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03650418733165187		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03650418733165187 | validation: 0.05727337866465637]
	TIME [epoch: 5.72 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038657144413587786		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.038657144413587786 | validation: 0.0476143799788137]
	TIME [epoch: 5.72 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040997623319353374		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.040997623319353374 | validation: 0.05420072972752852]
	TIME [epoch: 5.7 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420886820246481		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.0420886820246481 | validation: 0.05298910653685263]
	TIME [epoch: 5.7 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994056731362819		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.03994056731362819 | validation: 0.05892999280348493]
	TIME [epoch: 5.71 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040273280055913255		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.040273280055913255 | validation: 0.0547008106779771]
	TIME [epoch: 5.71 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041213227587112156		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.041213227587112156 | validation: 0.05628512758840567]
	TIME [epoch: 5.7 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039896801570237145		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.039896801570237145 | validation: 0.04514984704408131]
	TIME [epoch: 5.72 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467804874207154		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.03467804874207154 | validation: 0.046673263732895515]
	TIME [epoch: 5.72 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747845545774833		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.03747845545774833 | validation: 0.05443968933291504]
	TIME [epoch: 5.69 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03817775753331724		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.03817775753331724 | validation: 0.054770619162382045]
	TIME [epoch: 5.69 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04094925326340994		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.04094925326340994 | validation: 0.0501893657283354]
	TIME [epoch: 5.69 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03768180672253216		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.03768180672253216 | validation: 0.06364303944499484]
	TIME [epoch: 5.72 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230837808465704		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.04230837808465704 | validation: 0.05238654059095118]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040748977254239385		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.040748977254239385 | validation: 0.053515790585526135]
	TIME [epoch: 5.71 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033881385304242714		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.033881385304242714 | validation: 0.052683233912155146]
	TIME [epoch: 5.7 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034935108613339885		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.034935108613339885 | validation: 0.05513614881637028]
	TIME [epoch: 5.7 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819396757220595		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.03819396757220595 | validation: 0.04560674963288752]
	TIME [epoch: 5.7 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03873715800122023		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.03873715800122023 | validation: 0.05126693329710516]
	TIME [epoch: 5.71 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036247814134051246		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.036247814134051246 | validation: 0.05977649597345121]
	TIME [epoch: 5.72 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03805338493374927		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.03805338493374927 | validation: 0.057480141782253094]
	TIME [epoch: 5.7 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729342641425397		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.03729342641425397 | validation: 0.05593934816899045]
	TIME [epoch: 5.7 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03832409295935363		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.03832409295935363 | validation: 0.052214978911082455]
	TIME [epoch: 5.7 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038590589500543		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.04038590589500543 | validation: 0.05401679834867465]
	TIME [epoch: 5.71 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365716785131325		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.0365716785131325 | validation: 0.05089504389677266]
	TIME [epoch: 5.72 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040870299157116326		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.040870299157116326 | validation: 0.046935892468890454]
	TIME [epoch: 5.72 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03810373089979377		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.03810373089979377 | validation: 0.05421515123951056]
	TIME [epoch: 5.71 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0364559144375265		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0364559144375265 | validation: 0.053446708840408585]
	TIME [epoch: 5.7 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03925070545814759		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.03925070545814759 | validation: 0.05243412115102232]
	TIME [epoch: 5.7 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438093968551893		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.03438093968551893 | validation: 0.052381880776948386]
	TIME [epoch: 5.7 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558894074227045		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.03558894074227045 | validation: 0.0492905199885921]
	TIME [epoch: 5.73 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03644515794073345		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03644515794073345 | validation: 0.047435503698233815]
	TIME [epoch: 5.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03339138353584731		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03339138353584731 | validation: 0.05763567330998311]
	TIME [epoch: 5.69 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03405495449790235		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.03405495449790235 | validation: 0.05646185770729902]
	TIME [epoch: 5.7 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03759561691624124		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.03759561691624124 | validation: 0.05614175216720674]
	TIME [epoch: 5.7 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036820151666632536		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.036820151666632536 | validation: 0.05990324652645148]
	TIME [epoch: 5.7 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03910331932811567		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03910331932811567 | validation: 0.05054421978777427]
	TIME [epoch: 5.71 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850131462407025		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.03850131462407025 | validation: 0.05500301672459273]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036365731906075636		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.036365731906075636 | validation: 0.05162402419390224]
	TIME [epoch: 5.7 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378930688999598		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.0378930688999598 | validation: 0.05015228258405537]
	TIME [epoch: 5.71 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554223778884748		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.03554223778884748 | validation: 0.048570294321065244]
	TIME [epoch: 5.7 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855850063504922		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.03855850063504922 | validation: 0.06049627396440835]
	TIME [epoch: 5.69 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0401389482263622		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0401389482263622 | validation: 0.04737704744584627]
	TIME [epoch: 5.71 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0398922002226796		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.0398922002226796 | validation: 0.05398882758207765]
	TIME [epoch: 5.73 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03845199654219449		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.03845199654219449 | validation: 0.05492799089988143]
	TIME [epoch: 5.7 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038436435647516365		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.038436435647516365 | validation: 0.05031291095287434]
	TIME [epoch: 5.7 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040537814595525		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.040537814595525 | validation: 0.046251637769876196]
	TIME [epoch: 5.71 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03912494324537543		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.03912494324537543 | validation: 0.04523047249662158]
	TIME [epoch: 5.71 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03980826469572238		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.03980826469572238 | validation: 0.05062445861944245]
	TIME [epoch: 5.7 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850788226869565		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.03850788226869565 | validation: 0.05789183991706225]
	TIME [epoch: 5.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879378305255899		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.03879378305255899 | validation: 0.04651153092110445]
	TIME [epoch: 5.7 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747303471267034		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.03747303471267034 | validation: 0.057018833097349064]
	TIME [epoch: 5.7 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03977505237853531		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.03977505237853531 | validation: 0.047835439028131685]
	TIME [epoch: 5.71 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038157449149406365		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.038157449149406365 | validation: 0.05945556855603924]
	TIME [epoch: 5.7 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040323828515016084		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.040323828515016084 | validation: 0.05168258460288265]
	TIME [epoch: 5.7 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03677880322256813		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.03677880322256813 | validation: 0.053807563694194885]
	TIME [epoch: 5.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03871487534649671		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.03871487534649671 | validation: 0.059873472124045854]
	TIME [epoch: 5.7 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0369573179220229		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.0369573179220229 | validation: 0.05098915235170668]
	TIME [epoch: 5.71 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201785795256677		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.03201785795256677 | validation: 0.05535484743092848]
	TIME [epoch: 5.71 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410501734184402		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.0410501734184402 | validation: 0.04913817446489278]
	TIME [epoch: 5.7 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0394606176594624		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.0394606176594624 | validation: 0.05543081374684403]
	TIME [epoch: 5.71 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196079377356608		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.04196079377356608 | validation: 0.049923754810481676]
	TIME [epoch: 5.74 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063523989356528		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.04063523989356528 | validation: 0.05573910638903699]
	TIME [epoch: 5.71 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504581726601857		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03504581726601857 | validation: 0.047131565349924215]
	TIME [epoch: 5.71 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0360710746632349		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.0360710746632349 | validation: 0.05258275897019688]
	TIME [epoch: 5.69 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037878027338298315		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.037878027338298315 | validation: 0.05935083236996915]
	TIME [epoch: 5.71 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951797028858177		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.03951797028858177 | validation: 0.05079019275627468]
	TIME [epoch: 5.71 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041606177465341315		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.041606177465341315 | validation: 0.059944520312096614]
	TIME [epoch: 5.74 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038877947969734185		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.038877947969734185 | validation: 0.05746766008030029]
	TIME [epoch: 5.7 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039147676474819676		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.039147676474819676 | validation: 0.05270071683098758]
	TIME [epoch: 5.71 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841866194653331		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.03841866194653331 | validation: 0.05355445154804572]
	TIME [epoch: 5.69 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03870465998930722		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.03870465998930722 | validation: 0.04825885273724792]
	TIME [epoch: 5.7 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03922796059927741		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.03922796059927741 | validation: 0.05958584543298608]
	TIME [epoch: 5.7 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675133286540468		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.03675133286540468 | validation: 0.054503337852275034]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040265505726685295		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.040265505726685295 | validation: 0.05549645626591634]
	TIME [epoch: 5.7 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036088494889911615		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.036088494889911615 | validation: 0.04505128140340755]
	TIME [epoch: 5.69 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03456134081836972		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.03456134081836972 | validation: 0.04951417133475346]
	TIME [epoch: 5.71 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03426101771900137		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.03426101771900137 | validation: 0.04048084749783334]
	TIME [epoch: 5.69 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384072513440162		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.03384072513440162 | validation: 0.05018361405793573]
	TIME [epoch: 5.71 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808218975928173		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.03808218975928173 | validation: 0.05080836559670404]
	TIME [epoch: 5.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930041231034773		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.03930041231034773 | validation: 0.05567029400959925]
	TIME [epoch: 5.7 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03996102665868946		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.03996102665868946 | validation: 0.05067404084465176]
	TIME [epoch: 5.69 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04253221505312315		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.04253221505312315 | validation: 0.04453974332540447]
	TIME [epoch: 5.71 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038559670256446216		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.038559670256446216 | validation: 0.05781685695553451]
	TIME [epoch: 5.71 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038329408911935835		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.038329408911935835 | validation: 0.06383569332226552]
	TIME [epoch: 5.7 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034027753376257394		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.034027753376257394 | validation: 0.05648402840103468]
	TIME [epoch: 5.73 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136588635187198		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.04136588635187198 | validation: 0.05272752170521154]
	TIME [epoch: 5.7 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04185944870807237		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.04185944870807237 | validation: 0.046718660298378366]
	TIME [epoch: 5.69 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453547339048033		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.03453547339048033 | validation: 0.05229930604974609]
	TIME [epoch: 5.71 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039309221995859865		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.039309221995859865 | validation: 0.04986722365953217]
	TIME [epoch: 5.69 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03932884883718414		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.03932884883718414 | validation: 0.05481440362820467]
	TIME [epoch: 5.7 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04077240317308953		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.04077240317308953 | validation: 0.045556740750760445]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0371232281580626		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.0371232281580626 | validation: 0.04435822189965949]
	TIME [epoch: 5.7 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035194434311353266		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.035194434311353266 | validation: 0.049267251700739596]
	TIME [epoch: 5.69 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035881560852119354		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.035881560852119354 | validation: 0.044088930817257704]
	TIME [epoch: 5.69 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0394246225596312		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.0394246225596312 | validation: 0.059881576377707434]
	TIME [epoch: 5.69 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041869511496836376		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.041869511496836376 | validation: 0.05812463922103003]
	TIME [epoch: 5.7 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038741135040143974		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.038741135040143974 | validation: 0.05532182917619081]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035938943679154255		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.035938943679154255 | validation: 0.04960890286737029]
	TIME [epoch: 5.7 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038645225900750244		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.038645225900750244 | validation: 0.05194973586244654]
	TIME [epoch: 5.69 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04011117675405222		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.04011117675405222 | validation: 0.04566065957042843]
	TIME [epoch: 5.7 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03743476632114787		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.03743476632114787 | validation: 0.05425887068527138]
	TIME [epoch: 5.69 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988348860441522		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.03988348860441522 | validation: 0.04762695468414978]
	TIME [epoch: 5.7 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03877969633015058		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.03877969633015058 | validation: 0.04932050777204044]
	TIME [epoch: 5.75 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03770315848351456		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.03770315848351456 | validation: 0.05782339394284839]
	TIME [epoch: 5.7 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038278606832612944		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.038278606832612944 | validation: 0.04993082616603124]
	TIME [epoch: 5.7 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03785057507589961		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.03785057507589961 | validation: 0.048682825007158544]
	TIME [epoch: 5.69 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03684258977381677		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.03684258977381677 | validation: 0.04508549291922265]
	TIME [epoch: 5.69 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656651059372896		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.03656651059372896 | validation: 0.057381432246526184]
	TIME [epoch: 5.7 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884916672579322		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03884916672579322 | validation: 0.04961060922058629]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593378677235809		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.03593378677235809 | validation: 0.04858799594510237]
	TIME [epoch: 5.7 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795425708945208		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.03795425708945208 | validation: 0.04740655304948085]
	TIME [epoch: 5.72 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03646843022878993		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.03646843022878993 | validation: 0.052697568660530686]
	TIME [epoch: 5.71 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037793680735634		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.037793680735634 | validation: 0.05117494651534304]
	TIME [epoch: 5.71 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511534871238455		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.03511534871238455 | validation: 0.05081444910439714]
	TIME [epoch: 5.72 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03683809292007966		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.03683809292007966 | validation: 0.057443254078289416]
	TIME [epoch: 5.75 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468791854094669		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.03468791854094669 | validation: 0.05442549086376474]
	TIME [epoch: 5.72 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039492445208327634		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.039492445208327634 | validation: 0.05406173678263236]
	TIME [epoch: 5.72 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04255657639668242		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.04255657639668242 | validation: 0.05762596088748256]
	TIME [epoch: 5.71 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917620598502589		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.03917620598502589 | validation: 0.05202301934133534]
	TIME [epoch: 5.7 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03981435289584084		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.03981435289584084 | validation: 0.04624032252127715]
	TIME [epoch: 5.7 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03650869867057802		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.03650869867057802 | validation: 0.04905170679063243]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038902861294826965		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.038902861294826965 | validation: 0.052897388473858165]
	TIME [epoch: 5.7 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0387787823045168		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.0387787823045168 | validation: 0.05748998728590605]
	TIME [epoch: 5.69 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04090005599708109		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.04090005599708109 | validation: 0.05851344691687763]
	TIME [epoch: 5.7 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0430364723374726		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.0430364723374726 | validation: 0.055814981325833436]
	TIME [epoch: 5.69 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04282883613278948		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.04282883613278948 | validation: 0.055533424311142505]
	TIME [epoch: 5.7 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038969852194538045		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.038969852194538045 | validation: 0.055188438957950975]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039262169578721653		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.039262169578721653 | validation: 0.05388943084747322]
	TIME [epoch: 5.72 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04186973837634897		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.04186973837634897 | validation: 0.054760584702694896]
	TIME [epoch: 5.7 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022719190075265		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.04022719190075265 | validation: 0.05286308342944746]
	TIME [epoch: 5.69 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036621118127465435		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.036621118127465435 | validation: 0.05941305877126534]
	TIME [epoch: 5.69 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03763832919325234		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.03763832919325234 | validation: 0.05668580561815278]
	TIME [epoch: 5.7 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740237543900876		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.03740237543900876 | validation: 0.057409883750639316]
	TIME [epoch: 5.74 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040278037836397926		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.040278037836397926 | validation: 0.05534152237418812]
	TIME [epoch: 5.7 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038617150480882434		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.038617150480882434 | validation: 0.053714344137055975]
	TIME [epoch: 5.69 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581952882948818		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.03581952882948818 | validation: 0.04972555560500084]
	TIME [epoch: 5.69 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039284811490975624		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.039284811490975624 | validation: 0.04957023794557227]
	TIME [epoch: 5.7 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795288043824534		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.03795288043824534 | validation: 0.05339253324102662]
	TIME [epoch: 5.7 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035088629879404885		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.035088629879404885 | validation: 0.05822024643542594]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039117084089313026		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.039117084089313026 | validation: 0.05223796430627713]
	TIME [epoch: 5.7 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03998367624332675		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.03998367624332675 | validation: 0.05371757755588278]
	TIME [epoch: 5.7 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03853496611644833		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.03853496611644833 | validation: 0.05133736911607856]
	TIME [epoch: 5.69 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036166089340949836		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.036166089340949836 | validation: 0.050628361512075205]
	TIME [epoch: 5.69 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037349158058178636		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.037349158058178636 | validation: 0.052625351641385584]
	TIME [epoch: 5.7 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036295501962786775		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.036295501962786775 | validation: 0.04854446992858083]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039571020690913325		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.039571020690913325 | validation: 0.04760736182743429]
	TIME [epoch: 5.7 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357485419071267		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.0357485419071267 | validation: 0.059901008164919924]
	TIME [epoch: 5.7 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03875557360730724		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.03875557360730724 | validation: 0.04716140478345567]
	TIME [epoch: 5.7 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03929118379731265		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.03929118379731265 | validation: 0.0580564491426987]
	TIME [epoch: 5.7 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920020307262774		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.03920020307262774 | validation: 0.04878295655001514]
	TIME [epoch: 5.7 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402567815262877		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03402567815262877 | validation: 0.053474031098184306]
	TIME [epoch: 5.73 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401331670772065		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.03401331670772065 | validation: 0.056204939178496754]
	TIME [epoch: 5.7 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03504422023243532		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.03504422023243532 | validation: 0.03907622924709217]
	TIME [epoch: 5.69 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034769381545785176		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.034769381545785176 | validation: 0.05149615689877713]
	TIME [epoch: 5.7 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038095229465303006		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.038095229465303006 | validation: 0.053876494579615644]
	TIME [epoch: 5.7 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253006232448548		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.03253006232448548 | validation: 0.05144690229952922]
	TIME [epoch: 5.69 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033547085079418566		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.033547085079418566 | validation: 0.049655625060406806]
	TIME [epoch: 5.74 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03643424632845511		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.03643424632845511 | validation: 0.05129077033599375]
	TIME [epoch: 5.7 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03675292128345753		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.03675292128345753 | validation: 0.053741975305751685]
	TIME [epoch: 5.7 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703121532882978		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03703121532882978 | validation: 0.05092919140803044]
	TIME [epoch: 5.7 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0397325397789376		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0397325397789376 | validation: 0.049273208913957006]
	TIME [epoch: 5.7 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862108546230987		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.03862108546230987 | validation: 0.041574796962172436]
	TIME [epoch: 5.7 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03759015362545806		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.03759015362545806 | validation: 0.053052014433894616]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036556677449972416		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.036556677449972416 | validation: 0.05174117452767933]
	TIME [epoch: 5.7 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038155145563137455		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.038155145563137455 | validation: 0.044154886042534064]
	TIME [epoch: 5.69 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038821299469309095		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.038821299469309095 | validation: 0.0496091356368113]
	TIME [epoch: 5.69 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042969897536197815		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.042969897536197815 | validation: 0.048271881045347236]
	TIME [epoch: 5.69 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376122807481451		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.0376122807481451 | validation: 0.05011373109731291]
	TIME [epoch: 5.69 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03810262528374		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.03810262528374 | validation: 0.04540326740644834]
	TIME [epoch: 5.74 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03906880709099135		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.03906880709099135 | validation: 0.0560282237285152]
	TIME [epoch: 5.7 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03781814801389		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.03781814801389 | validation: 0.04490016098328022]
	TIME [epoch: 5.71 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037491028958385776		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.037491028958385776 | validation: 0.05393641373116303]
	TIME [epoch: 5.69 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361863315934481		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.03361863315934481 | validation: 0.04287013093075663]
	TIME [epoch: 5.69 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036917483713436366		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.036917483713436366 | validation: 0.04921888599127549]
	TIME [epoch: 5.69 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03861804892718532		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.03861804892718532 | validation: 0.058070724082467794]
	TIME [epoch: 5.73 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038534467744470155		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.038534467744470155 | validation: 0.05092120586137805]
	TIME [epoch: 5.7 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03738094233660533		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.03738094233660533 | validation: 0.04816798562646498]
	TIME [epoch: 5.69 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041862742951978046		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.041862742951978046 | validation: 0.04960908881482345]
	TIME [epoch: 5.69 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944772360369407		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.03944772360369407 | validation: 0.05111416031118175]
	TIME [epoch: 5.7 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393201216215458		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.03393201216215458 | validation: 0.05563839628807582]
	TIME [epoch: 5.7 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037517658441950125		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.037517658441950125 | validation: 0.05921228610420496]
	TIME [epoch: 5.75 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03639387871392892		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.03639387871392892 | validation: 0.04816274537136973]
	TIME [epoch: 5.72 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03526052222624067		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.03526052222624067 | validation: 0.05680129002114155]
	TIME [epoch: 5.69 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035878975573793694		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.035878975573793694 | validation: 0.0521427031399817]
	TIME [epoch: 5.7 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037901043018902576		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.037901043018902576 | validation: 0.05188692969666968]
	TIME [epoch: 5.69 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924720178167408		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.03924720178167408 | validation: 0.05163371093341074]
	TIME [epoch: 5.69 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03729010976367335		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.03729010976367335 | validation: 0.04523287685785549]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035933130133777025		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.035933130133777025 | validation: 0.043935183452054265]
	TIME [epoch: 5.7 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146939112606606		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.03146939112606606 | validation: 0.04831789766059972]
	TIME [epoch: 5.69 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787807387135106		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.03787807387135106 | validation: 0.05206352281759198]
	TIME [epoch: 5.69 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037784264019338334		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.037784264019338334 | validation: 0.045407850193899084]
	TIME [epoch: 5.69 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909497469452847		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.03909497469452847 | validation: 0.05130146134872087]
	TIME [epoch: 5.69 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688153759374743		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.03688153759374743 | validation: 0.05477864717762456]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03776916303180635		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.03776916303180635 | validation: 0.05082878238496687]
	TIME [epoch: 5.72 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041981176938499995		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.041981176938499995 | validation: 0.049240673919514415]
	TIME [epoch: 5.71 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032770546490520025		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.032770546490520025 | validation: 0.04699565928075014]
	TIME [epoch: 5.71 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033610982371221454		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.033610982371221454 | validation: 0.05381101444711929]
	TIME [epoch: 5.71 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583486668193544		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.03583486668193544 | validation: 0.04545867403798148]
	TIME [epoch: 5.71 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03757277248360688		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03757277248360688 | validation: 0.04608652673586823]
	TIME [epoch: 5.75 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040519677722421175		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.040519677722421175 | validation: 0.03831540474122648]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r4_20240310_032214/states/model_tr_study202_1923.pth
	Model improved!!!
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864865231373456		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.03864865231373456 | validation: 0.05011009086811991]
	TIME [epoch: 5.71 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03722781497074455		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.03722781497074455 | validation: 0.05202681660818827]
	TIME [epoch: 5.71 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566116092496682		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.03566116092496682 | validation: 0.05171798081107571]
	TIME [epoch: 5.71 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038141385149526516		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.038141385149526516 | validation: 0.052526559400203066]
	TIME [epoch: 5.7 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670620195171059		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.03670620195171059 | validation: 0.05032003745698536]
	TIME [epoch: 5.75 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403912582801998		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.0403912582801998 | validation: 0.051148789928281584]
	TIME [epoch: 5.7 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03554228719611109		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.03554228719611109 | validation: 0.04932208351651198]
	TIME [epoch: 5.71 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0356024558377334		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.0356024558377334 | validation: 0.051588381505179276]
	TIME [epoch: 5.71 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03654313810142496		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.03654313810142496 | validation: 0.049472362460285434]
	TIME [epoch: 5.71 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035383147860128826		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.035383147860128826 | validation: 0.046537464577728664]
	TIME [epoch: 5.71 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0364442798242307		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.0364442798242307 | validation: 0.04884672218502695]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995736093056353		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.03995736093056353 | validation: 0.0551200504773264]
	TIME [epoch: 5.72 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590105998096517		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.03590105998096517 | validation: 0.04689430718760356]
	TIME [epoch: 5.71 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038610274665223245		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.038610274665223245 | validation: 0.049040156914461085]
	TIME [epoch: 5.71 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03507045762854147		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03507045762854147 | validation: 0.05173409959643156]
	TIME [epoch: 5.71 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03758454566367516		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.03758454566367516 | validation: 0.0541672337685301]
	TIME [epoch: 5.71 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458945384768789		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.03458945384768789 | validation: 0.05118058409180913]
	TIME [epoch: 5.75 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036206995126694175		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.036206995126694175 | validation: 0.050212405858186475]
	TIME [epoch: 5.72 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036240787151127246		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.036240787151127246 | validation: 0.054556529672927456]
	TIME [epoch: 5.72 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03613405573595621		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.03613405573595621 | validation: 0.06152963553337973]
	TIME [epoch: 5.71 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626273053861435		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.03626273053861435 | validation: 0.04988539087705218]
	TIME [epoch: 5.71 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03963833985678226		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.03963833985678226 | validation: 0.04225107777024326]
	TIME [epoch: 5.7 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039273880524195545		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.039273880524195545 | validation: 0.05028169017432595]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037442499567167845		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.037442499567167845 | validation: 0.05211476267738974]
	TIME [epoch: 5.71 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802108655423859		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.03802108655423859 | validation: 0.052646799763868816]
	TIME [epoch: 5.69 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039104312543059204		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.039104312543059204 | validation: 0.04829639427485731]
	TIME [epoch: 5.7 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656597536752613		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03656597536752613 | validation: 0.05017282465068838]
	TIME [epoch: 5.71 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709061607885632		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.03709061607885632 | validation: 0.05587051280761708]
	TIME [epoch: 5.7 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512343778684738		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.03512343778684738 | validation: 0.056776046708469065]
	TIME [epoch: 5.75 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486427362697253		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.03486427362697253 | validation: 0.050485578389341666]
	TIME [epoch: 5.7 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03601055017909113		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.03601055017909113 | validation: 0.0553623665074747]
	TIME [epoch: 5.71 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03804580908705357		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.03804580908705357 | validation: 0.051137586858960006]
	TIME [epoch: 5.7 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03739213408829615		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.03739213408829615 | validation: 0.05462494302521835]
	TIME [epoch: 5.71 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03571206000465725		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.03571206000465725 | validation: 0.046962614316851545]
	TIME [epoch: 5.71 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731544621472596		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.03731544621472596 | validation: 0.04544169784967953]
	TIME [epoch: 5.75 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682435836515327		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.03682435836515327 | validation: 0.04451313532292781]
	TIME [epoch: 5.7 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366293905225524		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.0366293905225524 | validation: 0.05107446356506408]
	TIME [epoch: 5.71 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035517700898781396		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.035517700898781396 | validation: 0.05320676497530161]
	TIME [epoch: 5.71 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485884949931297		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.03485884949931297 | validation: 0.054358123911837454]
	TIME [epoch: 5.71 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03735595395430216		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.03735595395430216 | validation: 0.05646831377079433]
	TIME [epoch: 5.71 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035988038519069385		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.035988038519069385 | validation: 0.05199082068730653]
	TIME [epoch: 5.75 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717230683431347		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.03717230683431347 | validation: 0.05077826222402948]
	TIME [epoch: 5.72 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03789431900866447		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.03789431900866447 | validation: 0.050898414483702206]
	TIME [epoch: 5.71 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036085601555135474		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.036085601555135474 | validation: 0.053333015402234965]
	TIME [epoch: 5.71 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03719371620021297		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.03719371620021297 | validation: 0.052627674118789214]
	TIME [epoch: 5.71 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04108442419448956		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.04108442419448956 | validation: 0.0513224575300578]
	TIME [epoch: 5.71 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04304282635313003		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.04304282635313003 | validation: 0.050300691284921414]
	TIME [epoch: 5.75 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03273284949070801		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.03273284949070801 | validation: 0.049104409046209614]
	TIME [epoch: 5.72 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524301811029379		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.03524301811029379 | validation: 0.050155507382886794]
	TIME [epoch: 5.71 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038072736028999916		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.038072736028999916 | validation: 0.05257835616215564]
	TIME [epoch: 5.71 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951139057345075		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.03951139057345075 | validation: 0.053232430584530914]
	TIME [epoch: 5.7 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03878682994872762		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.03878682994872762 | validation: 0.05794299828139531]
	TIME [epoch: 5.7 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03704838767191747		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.03704838767191747 | validation: 0.04797151945551521]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037915046541831796		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.037915046541831796 | validation: 0.06419026739034686]
	TIME [epoch: 5.72 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035040879350014736		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.035040879350014736 | validation: 0.048146139456749996]
	TIME [epoch: 5.71 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585802951895989		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.03585802951895989 | validation: 0.05489123235987856]
	TIME [epoch: 5.71 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485567546289631		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.03485567546289631 | validation: 0.05043725195465419]
	TIME [epoch: 5.69 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04040159737754669		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.04040159737754669 | validation: 0.047464855085886826]
	TIME [epoch: 5.71 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035400585546932636		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.035400585546932636 | validation: 0.05008053596384304]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03911175135261879		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.03911175135261879 | validation: 0.04850496261430827]
	TIME [epoch: 5.71 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03732716719561575		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.03732716719561575 | validation: 0.0486585760882918]
	TIME [epoch: 5.7 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038602898129940215		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.038602898129940215 | validation: 0.045360086674013214]
	TIME [epoch: 5.7 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04057745114738766		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.04057745114738766 | validation: 0.04351137350932636]
	TIME [epoch: 5.7 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512509705991514		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.03512509705991514 | validation: 0.04609825630933434]
	TIME [epoch: 5.7 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035784079064958056		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.035784079064958056 | validation: 0.04449365189482224]
	TIME [epoch: 5.75 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037267825061433855		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.037267825061433855 | validation: 0.05031338291913125]
	TIME [epoch: 5.71 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794965306264307		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.03794965306264307 | validation: 0.04777317121380497]
	TIME [epoch: 5.7 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040666871955539516		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.040666871955539516 | validation: 0.050623841360947795]
	TIME [epoch: 5.7 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0400786082828693		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.0400786082828693 | validation: 0.051109548816867294]
	TIME [epoch: 5.69 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04033440723295784		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.04033440723295784 | validation: 0.05074166289344944]
	TIME [epoch: 5.71 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03697988557817013		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.03697988557817013 | validation: 0.03872191616341744]
	TIME [epoch: 5.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03822693045524181		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.03822693045524181 | validation: 0.050952373293563495]
	TIME [epoch: 5.7 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03399947872405041		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.03399947872405041 | validation: 0.046678836102815396]
	TIME [epoch: 5.71 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039721192333926875		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.039721192333926875 | validation: 0.05005550184187356]
	TIME [epoch: 5.71 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438367883638942		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.03438367883638942 | validation: 0.04062191772095112]
	TIME [epoch: 5.71 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744448246518986		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.03744448246518986 | validation: 0.04358620296143993]
	TIME [epoch: 5.7 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630179093447639		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03630179093447639 | validation: 0.045435098126148876]
	TIME [epoch: 5.74 sec]
Finished training in 11655.631 seconds.
