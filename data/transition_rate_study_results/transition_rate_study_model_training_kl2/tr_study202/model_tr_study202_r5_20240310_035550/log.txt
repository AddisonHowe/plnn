Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r5', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1454663585

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.53822689606463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.53822689606463 | validation: 7.666544172353707]
	TIME [epoch: 90.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.499529397493191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.499529397493191 | validation: 11.311871383077172]
	TIME [epoch: 5.81 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.09740341100737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.09740341100737 | validation: 9.408384611115912]
	TIME [epoch: 5.74 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.925168552699477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.925168552699477 | validation: 9.965389962444034]
	TIME [epoch: 5.75 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.225776460458642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.225776460458642 | validation: 6.093997393717747]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782666152227592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.782666152227592 | validation: 5.140948028920332]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.347420033708207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.347420033708207 | validation: 4.356900451222678]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.19986421772614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.19986421772614 | validation: 4.5326502443086225]
	TIME [epoch: 5.77 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.894322430363277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.894322430363277 | validation: 5.631462290614644]
	TIME [epoch: 5.75 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.764144960330685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.764144960330685 | validation: 4.2303052510917345]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.901119461967724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.901119461967724 | validation: 4.225605605377806]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7626512094686078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7626512094686078 | validation: 4.208924219040149]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7043248679528564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7043248679528564 | validation: 4.078453348335083]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.667391447099285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.667391447099285 | validation: 4.067115986657889]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7635017648956324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7635017648956324 | validation: 3.90250135712823]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6855618886241297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6855618886241297 | validation: 3.8237502453888976]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7125777512183036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7125777512183036 | validation: 4.204223704763051]
	TIME [epoch: 5.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7961693276959925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7961693276959925 | validation: 3.7036315540308733]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5841690289307215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5841690289307215 | validation: 3.2904198806704335]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5840288685612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5840288685612 | validation: 4.320543511599275]
	TIME [epoch: 5.74 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5584723446141875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5584723446141875 | validation: 3.4402743762448367]
	TIME [epoch: 5.77 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6274887854722646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6274887854722646 | validation: 3.2412187356744595]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4789224384679223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4789224384679223 | validation: 3.400609171583184]
	TIME [epoch: 5.74 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297387688857707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.297387688857707 | validation: 3.121236834571614]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3823971162854356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3823971162854356 | validation: 3.7758811292303758]
	TIME [epoch: 5.73 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7485701089319576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7485701089319576 | validation: 3.1405295686501367]
	TIME [epoch: 5.75 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1510343362936553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1510343362936553 | validation: 2.9046874631601067]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.039876934676875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.039876934676875 | validation: 3.225599741752892]
	TIME [epoch: 5.77 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0053743933594483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0053743933594483 | validation: 2.8694515217208805]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6792412360703404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6792412360703404 | validation: 3.1966461478982793]
	TIME [epoch: 5.74 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.046855253334696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.046855253334696 | validation: 2.533525034911863]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6366098670441165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6366098670441165 | validation: 2.613346731935585]
	TIME [epoch: 5.73 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6296209285663963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6296209285663963 | validation: 2.9479744323796457]
	TIME [epoch: 5.73 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.757593099308233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.757593099308233 | validation: 2.187943057316036]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.579158809757369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.579158809757369 | validation: 2.0590314303381483]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7184577554028984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7184577554028984 | validation: 2.3645861241257573]
	TIME [epoch: 5.73 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2748547968237887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2748547968237887 | validation: 1.9298155716880028]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.56609617444761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.56609617444761 | validation: 2.0916785153965396]
	TIME [epoch: 5.73 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8968062213627475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8968062213627475 | validation: 2.751062510573835]
	TIME [epoch: 5.73 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.344448988330369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.344448988330369 | validation: 1.820636853452951]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9753276165848312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9753276165848312 | validation: 2.675500903794274]
	TIME [epoch: 5.75 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.017142494460817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.017142494460817 | validation: 2.097255647147148]
	TIME [epoch: 5.73 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7763695192770528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7763695192770528 | validation: 1.6012194916045261]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.735501116509015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.735501116509015 | validation: 2.2098018786998286]
	TIME [epoch: 5.74 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.925545136070391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.925545136070391 | validation: 1.8572317937285727]
	TIME [epoch: 5.75 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7975616366178082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7975616366178082 | validation: 1.7879048397635469]
	TIME [epoch: 5.74 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6847898500747116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6847898500747116 | validation: 1.9972338052710654]
	TIME [epoch: 5.78 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4520579974584318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4520579974584318 | validation: 1.582420004272797]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5426018401505048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5426018401505048 | validation: 1.1628954410907697]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4887712881948731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4887712881948731 | validation: 3.779049811005213]
	TIME [epoch: 5.74 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.777185480718205		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.777185480718205 | validation: 1.8967518287516691]
	TIME [epoch: 5.73 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3603843042464294		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.3603843042464294 | validation: 1.2249227113550272]
	TIME [epoch: 5.73 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526807749806457		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.526807749806457 | validation: 1.217316206871006]
	TIME [epoch: 5.78 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1461590974896554		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.1461590974896554 | validation: 1.3267473429075614]
	TIME [epoch: 5.75 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4138931333019862		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.4138931333019862 | validation: 1.0588016265197158]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783090015765318		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.9783090015765318 | validation: 1.9930706680921844]
	TIME [epoch: 5.73 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5675609464985338		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.5675609464985338 | validation: 1.3367923227612568]
	TIME [epoch: 5.74 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4097147338188383		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.4097147338188383 | validation: 1.704921213344631]
	TIME [epoch: 5.74 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3118612075655594		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.3118612075655594 | validation: 0.9123133022195015]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031508202967018		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.031508202967018 | validation: 1.2614609571643554]
	TIME [epoch: 5.76 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159427681284206		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.159427681284206 | validation: 1.2473953599382601]
	TIME [epoch: 5.74 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1516429340069227		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.1516429340069227 | validation: 1.0787193927044405]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1854201681275085		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.1854201681275085 | validation: 0.8983053764897289]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0990583334539765		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.0990583334539765 | validation: 1.3042201381869796]
	TIME [epoch: 5.74 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3016004200663644		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.3016004200663644 | validation: 1.3822270238056036]
	TIME [epoch: 5.75 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542053826967291		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.1542053826967291 | validation: 1.428670815003314]
	TIME [epoch: 5.78 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1410600231964958		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.1410600231964958 | validation: 1.0371478739899633]
	TIME [epoch: 5.75 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.012144604670607		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.012144604670607 | validation: 1.0942056941760194]
	TIME [epoch: 5.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589340026228915		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.0589340026228915 | validation: 1.3677795497073977]
	TIME [epoch: 5.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1004094349602322		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.1004094349602322 | validation: 0.7583805672257506]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9367590577092998		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.9367590577092998 | validation: 1.0282721976957998]
	TIME [epoch: 5.73 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9868753045049207		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.9868753045049207 | validation: 0.7225742489476423]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8527107878081254		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.8527107878081254 | validation: 0.712946938446712]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9622882805930772		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.9622882805930772 | validation: 1.8177933166910787]
	TIME [epoch: 5.73 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590452224781837		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.0590452224781837 | validation: 0.7141208945527353]
	TIME [epoch: 5.73 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9012300882642081		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.9012300882642081 | validation: 2.859857461072166]
	TIME [epoch: 5.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8237977208248504		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.8237977208248504 | validation: 1.4174112921610993]
	TIME [epoch: 5.72 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0508000640835764		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.0508000640835764 | validation: 0.7344579984625978]
	TIME [epoch: 5.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866811121161105		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.866811121161105 | validation: 0.9572115916593663]
	TIME [epoch: 5.74 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8913266880988121		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.8913266880988121 | validation: 0.9208765136596532]
	TIME [epoch: 5.73 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9074865159710308		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.9074865159710308 | validation: 0.8864542566389877]
	TIME [epoch: 5.73 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9667430403933116		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.9667430403933116 | validation: 0.789228818530719]
	TIME [epoch: 5.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9318197337270873		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.9318197337270873 | validation: 0.8760156990980094]
	TIME [epoch: 5.72 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9095881158036605		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.9095881158036605 | validation: 0.7199915920054885]
	TIME [epoch: 5.73 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.992276097572173		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.992276097572173 | validation: 1.156604833787347]
	TIME [epoch: 5.77 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8992590068712836		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.8992590068712836 | validation: 1.2281076142337939]
	TIME [epoch: 5.73 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542065366908193		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.9542065366908193 | validation: 1.2397183829508651]
	TIME [epoch: 5.72 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9681221251928552		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.9681221251928552 | validation: 1.4752282228578761]
	TIME [epoch: 5.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9484562797025067		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.9484562797025067 | validation: 1.3530011159683937]
	TIME [epoch: 5.72 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9309679152117126		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.9309679152117126 | validation: 1.0120667866869075]
	TIME [epoch: 5.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8485131514596527		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.8485131514596527 | validation: 1.294493956867441]
	TIME [epoch: 5.75 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9834600795212414		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.9834600795212414 | validation: 0.6974522703185424]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280435703561891		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.8280435703561891 | validation: 0.8696446319514852]
	TIME [epoch: 5.73 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635866382407389		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.6635866382407389 | validation: 0.9797531950419768]
	TIME [epoch: 5.73 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7709766147805124		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.7709766147805124 | validation: 0.8178765508656851]
	TIME [epoch: 5.72 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869163107445629		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.869163107445629 | validation: 0.8803477112311672]
	TIME [epoch: 5.73 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7957308307331815		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.7957308307331815 | validation: 0.9495338299964464]
	TIME [epoch: 5.73 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8576403048703436		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.8576403048703436 | validation: 0.6363240077708658]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7395028112137556		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.7395028112137556 | validation: 0.6356198874178663]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775829313113814		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.6775829313113814 | validation: 0.7801479109780808]
	TIME [epoch: 5.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409376837903738		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.8409376837903738 | validation: 0.6762170572050562]
	TIME [epoch: 5.72 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323670681142601		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.6323670681142601 | validation: 0.853552579820934]
	TIME [epoch: 5.72 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1611615222565435		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.1611615222565435 | validation: 1.297729631553216]
	TIME [epoch: 5.72 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.040274802612889		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.040274802612889 | validation: 1.100857158414457]
	TIME [epoch: 5.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9855611786006553		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.9855611786006553 | validation: 0.7747671967044266]
	TIME [epoch: 5.73 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.859841871715641		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.859841871715641 | validation: 0.8259046338111702]
	TIME [epoch: 5.73 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663166239472609		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6663166239472609 | validation: 1.1906473303344616]
	TIME [epoch: 5.72 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8706021434158913		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.8706021434158913 | validation: 0.6186712877915482]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7377710448221695		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.7377710448221695 | validation: 0.7835765242870505]
	TIME [epoch: 5.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7309382221343377		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.7309382221343377 | validation: 0.7417081482652031]
	TIME [epoch: 5.74 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5518771955855846		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.5518771955855846 | validation: 0.4865775308251102]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7006633107205489		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.7006633107205489 | validation: 0.7762363095886423]
	TIME [epoch: 5.73 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425279014723284		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.8425279014723284 | validation: 0.6876272728913904]
	TIME [epoch: 5.73 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790118435229598		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.7790118435229598 | validation: 0.5664265165125628]
	TIME [epoch: 5.73 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361236951402		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5361236951402 | validation: 0.8306501418184163]
	TIME [epoch: 5.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976238159200434		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.6976238159200434 | validation: 0.512669443512593]
	TIME [epoch: 5.73 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017455068814203		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.6017455068814203 | validation: 0.6012526795758304]
	TIME [epoch: 5.76 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893212437221519		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.6893212437221519 | validation: 0.6882435283791495]
	TIME [epoch: 5.73 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6710322633503207		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.6710322633503207 | validation: 0.5208373818660285]
	TIME [epoch: 5.73 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5609522187317214		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5609522187317214 | validation: 0.7187116465684126]
	TIME [epoch: 5.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382838872799044		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.6382838872799044 | validation: 0.4535207390397293]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6528225432885978		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.6528225432885978 | validation: 0.4624523031537282]
	TIME [epoch: 5.73 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481099452742888		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.7481099452742888 | validation: 0.524504855054465]
	TIME [epoch: 5.74 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.838305985700212		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.838305985700212 | validation: 0.6213698035708033]
	TIME [epoch: 5.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640512835735288		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.640512835735288 | validation: 0.6155224631872886]
	TIME [epoch: 5.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768213753050685		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5768213753050685 | validation: 0.9315246336937643]
	TIME [epoch: 5.73 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7252721877278285		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.7252721877278285 | validation: 0.5648992756657816]
	TIME [epoch: 5.75 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914557516401482		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.6914557516401482 | validation: 0.5692327666355113]
	TIME [epoch: 5.73 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584427428573931		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.5584427428573931 | validation: 1.1772807696790373]
	TIME [epoch: 5.74 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070238519095096		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7070238519095096 | validation: 0.6433330297640513]
	TIME [epoch: 5.77 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340712720978957		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0340712720978957 | validation: 0.6907873690428613]
	TIME [epoch: 5.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463570698484681		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.7463570698484681 | validation: 0.7353277504006391]
	TIME [epoch: 5.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7870510049340844		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.7870510049340844 | validation: 0.47175256092645607]
	TIME [epoch: 5.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5415343392064007		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.5415343392064007 | validation: 0.8135069921437693]
	TIME [epoch: 5.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674166830230817		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.674166830230817 | validation: 0.503626423118679]
	TIME [epoch: 5.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501408442053885		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.501408442053885 | validation: 0.4666544972162436]
	TIME [epoch: 5.74 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151972239218495		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.5151972239218495 | validation: 0.7750590248856447]
	TIME [epoch: 5.78 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5410884995021179		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.5410884995021179 | validation: 1.3374130802612316]
	TIME [epoch: 5.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276346374656739		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.7276346374656739 | validation: 0.4724261908771523]
	TIME [epoch: 5.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616346566036699		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.616346566036699 | validation: 0.5191138844692488]
	TIME [epoch: 5.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5250066664937381		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.5250066664937381 | validation: 0.436627935760248]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5741767093106662		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.5741767093106662 | validation: 1.2095124223720286]
	TIME [epoch: 5.73 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8624142211443295		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.8624142211443295 | validation: 1.0230706939641607]
	TIME [epoch: 5.79 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6592980360141097		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.6592980360141097 | validation: 0.4085938109249109]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684986287779621		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.684986287779621 | validation: 0.5141590984117016]
	TIME [epoch: 5.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971184255216864		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.5971184255216864 | validation: 0.5197530320649778]
	TIME [epoch: 5.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438359546513015		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.6438359546513015 | validation: 0.7352418356799673]
	TIME [epoch: 5.73 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8331707643442734		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.8331707643442734 | validation: 0.7124790073425368]
	TIME [epoch: 5.73 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694791571612893		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.694791571612893 | validation: 0.5102264235265698]
	TIME [epoch: 5.76 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5551123453870218		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.5551123453870218 | validation: 0.4915898734156714]
	TIME [epoch: 5.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41034402791267954		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.41034402791267954 | validation: 1.219565191625886]
	TIME [epoch: 5.74 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7736833967066705		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.7736833967066705 | validation: 0.5544035866306203]
	TIME [epoch: 5.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001274000861273		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.6001274000861273 | validation: 0.5754097801685361]
	TIME [epoch: 5.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406102799432326		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.7406102799432326 | validation: 0.49719948762818184]
	TIME [epoch: 5.73 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655387191785719		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.5655387191785719 | validation: 0.4013874250714971]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554647055520898		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.554647055520898 | validation: 0.5584751209102031]
	TIME [epoch: 5.77 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883672923928721		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.5883672923928721 | validation: 1.2551621918393971]
	TIME [epoch: 5.73 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9255303233642246		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.9255303233642246 | validation: 0.639772447159842]
	TIME [epoch: 5.73 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561022376585966		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.5561022376585966 | validation: 0.5144880170050086]
	TIME [epoch: 5.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67307986172392		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.67307986172392 | validation: 0.7327309068153204]
	TIME [epoch: 5.73 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855588159272107		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.6855588159272107 | validation: 1.2091468797200842]
	TIME [epoch: 5.73 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9602199469152959		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.9602199469152959 | validation: 0.46739047170819736]
	TIME [epoch: 5.76 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165544774326336		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.6165544774326336 | validation: 0.47217347717549346]
	TIME [epoch: 5.74 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5282133034379503		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.5282133034379503 | validation: 0.43940815344181533]
	TIME [epoch: 5.73 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140008895598024		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.6140008895598024 | validation: 0.429560301667197]
	TIME [epoch: 5.73 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121127975998881		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.5121127975998881 | validation: 0.4028302052104644]
	TIME [epoch: 5.73 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6371503355642008		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.6371503355642008 | validation: 0.33417149541431346]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543250052800979		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.5543250052800979 | validation: 0.4529310607350787]
	TIME [epoch: 5.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563678144199308		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.563678144199308 | validation: 0.525180345336332]
	TIME [epoch: 5.76 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43168689502146707		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.43168689502146707 | validation: 0.5389401890767173]
	TIME [epoch: 5.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459468584755329		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.4459468584755329 | validation: 0.6913648020439908]
	TIME [epoch: 5.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386704466614318		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.5386704466614318 | validation: 0.4745083965746555]
	TIME [epoch: 5.73 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45521113217745757		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.45521113217745757 | validation: 1.059258239127793]
	TIME [epoch: 5.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530153712244822		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.6530153712244822 | validation: 0.5827718336884444]
	TIME [epoch: 5.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4402710304544691		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.4402710304544691 | validation: 0.9050306053973821]
	TIME [epoch: 5.76 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026714720148706		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.6026714720148706 | validation: 0.6873564808714079]
	TIME [epoch: 5.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46665218993668584		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.46665218993668584 | validation: 0.5397193728719075]
	TIME [epoch: 5.73 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5002923098393522		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.5002923098393522 | validation: 0.44770099363030974]
	TIME [epoch: 5.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307030858479304		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.4307030858479304 | validation: 0.4778113995439748]
	TIME [epoch: 5.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438225999320201		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.5438225999320201 | validation: 0.4404325212532146]
	TIME [epoch: 5.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215765130186411		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4215765130186411 | validation: 0.7077374240261388]
	TIME [epoch: 5.74 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727548994932048		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.6727548994932048 | validation: 0.5020323086950722]
	TIME [epoch: 5.76 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547667271431213		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.5547667271431213 | validation: 0.5743603195059636]
	TIME [epoch: 5.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5652459316784505		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5652459316784505 | validation: 0.4367155765272095]
	TIME [epoch: 5.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44549254975693164		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.44549254975693164 | validation: 0.9258727006390671]
	TIME [epoch: 5.73 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468539766566368		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.6468539766566368 | validation: 0.66852092592907]
	TIME [epoch: 5.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891253907517472		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.4891253907517472 | validation: 1.2143160324155375]
	TIME [epoch: 5.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392844235130408		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6392844235130408 | validation: 1.0559345929609618]
	TIME [epoch: 5.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961468175793099		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.5961468175793099 | validation: 0.6139524298679898]
	TIME [epoch: 5.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846388096729052		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.5846388096729052 | validation: 0.4979959658742496]
	TIME [epoch: 5.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468498205431625		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.4468498205431625 | validation: 0.8253816995415022]
	TIME [epoch: 5.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7346601395547429		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7346601395547429 | validation: 1.475231579364731]
	TIME [epoch: 5.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8103799225540199		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8103799225540199 | validation: 0.6558948345777416]
	TIME [epoch: 5.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5417057780135506		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.5417057780135506 | validation: 0.4505413117556478]
	TIME [epoch: 5.73 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931524060035618		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.5931524060035618 | validation: 0.44233831303780774]
	TIME [epoch: 5.77 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473992799922926		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.473992799922926 | validation: 0.5066157959442383]
	TIME [epoch: 5.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4856628400039899		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.4856628400039899 | validation: 0.8033495349258746]
	TIME [epoch: 5.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760538232528092		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.6760538232528092 | validation: 0.9121339731998386]
	TIME [epoch: 5.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753185453764008		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.6753185453764008 | validation: 0.516406691536559]
	TIME [epoch: 5.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858481249387397		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.5858481249387397 | validation: 0.5563667270362148]
	TIME [epoch: 5.73 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4729441982397444		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.4729441982397444 | validation: 0.9085835021940364]
	TIME [epoch: 5.75 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741833483160944		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.741833483160944 | validation: 0.5883751991434405]
	TIME [epoch: 5.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6280717775851326		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.6280717775851326 | validation: 0.6472729743031177]
	TIME [epoch: 5.73 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48483238084798264		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.48483238084798264 | validation: 0.5804061639977426]
	TIME [epoch: 5.73 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45080243288087773		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.45080243288087773 | validation: 0.4294778321706836]
	TIME [epoch: 5.73 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497646084387131		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.4497646084387131 | validation: 0.7558187735787119]
	TIME [epoch: 5.73 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568085048220613		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.568085048220613 | validation: 0.46907625536394776]
	TIME [epoch: 5.73 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577299532601353		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.577299532601353 | validation: 0.5734229645597314]
	TIME [epoch: 5.77 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45700725574033946		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.45700725574033946 | validation: 0.4812742465600099]
	TIME [epoch: 5.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130729605252196		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.5130729605252196 | validation: 0.5560149619918605]
	TIME [epoch: 5.73 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136421586544088		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5136421586544088 | validation: 0.6564626744376122]
	TIME [epoch: 5.72 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142532602787805		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.5142532602787805 | validation: 0.41995350728516373]
	TIME [epoch: 5.72 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320464611504436		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5320464611504436 | validation: 0.3955184666978766]
	TIME [epoch: 5.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473091253496147		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.473091253496147 | validation: 0.6625614993214315]
	TIME [epoch: 5.75 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076464655055708		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5076464655055708 | validation: 0.3906031591959357]
	TIME [epoch: 5.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204955532743101		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.4204955532743101 | validation: 0.664276816462704]
	TIME [epoch: 5.73 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693035426942249		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.4693035426942249 | validation: 0.42296125206993995]
	TIME [epoch: 5.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497690324474748		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.4497690324474748 | validation: 0.41239014005997543]
	TIME [epoch: 5.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4989669108354897		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.4989669108354897 | validation: 0.4152910878400138]
	TIME [epoch: 5.73 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779078364258838		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.4779078364258838 | validation: 0.407609550687707]
	TIME [epoch: 5.73 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43508579232865874		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.43508579232865874 | validation: 0.6757622646230224]
	TIME [epoch: 5.77 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883949031819026		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.4883949031819026 | validation: 0.8015246824035853]
	TIME [epoch: 5.73 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.660828925844199		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.660828925844199 | validation: 0.5412286507696452]
	TIME [epoch: 5.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719740031109825		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.4719740031109825 | validation: 0.8102665346927765]
	TIME [epoch: 5.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056739620012965		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.6056739620012965 | validation: 0.4656333063645539]
	TIME [epoch: 5.73 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40881759035804643		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.40881759035804643 | validation: 0.7808152132999852]
	TIME [epoch: 5.73 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069836907096521		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.5069836907096521 | validation: 0.43075950193607193]
	TIME [epoch: 5.75 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47581439573285633		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.47581439573285633 | validation: 0.505572829227806]
	TIME [epoch: 5.74 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7946273100642954		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.7946273100642954 | validation: 0.4231351528007999]
	TIME [epoch: 5.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49562595032879353		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.49562595032879353 | validation: 0.39834564129778627]
	TIME [epoch: 5.73 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40398139658224314		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.40398139658224314 | validation: 0.4603813679734532]
	TIME [epoch: 5.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41309020732066914		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.41309020732066914 | validation: 0.42713136042701283]
	TIME [epoch: 5.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40954325715756434		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.40954325715756434 | validation: 0.5064993796282878]
	TIME [epoch: 5.72 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42346162722943814		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.42346162722943814 | validation: 0.4599861439121159]
	TIME [epoch: 5.77 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.392281811659955		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.392281811659955 | validation: 0.6398889364796456]
	TIME [epoch: 5.73 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721821272270963		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.4721821272270963 | validation: 0.42266504590257825]
	TIME [epoch: 5.72 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36648528713784245		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.36648528713784245 | validation: 0.5794331235539563]
	TIME [epoch: 5.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462580486533262		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.5462580486533262 | validation: 0.45431999201998763]
	TIME [epoch: 5.72 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4774661969307332		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.4774661969307332 | validation: 1.0514778585888125]
	TIME [epoch: 5.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376438083365696		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.1376438083365696 | validation: 1.6321635329660102]
	TIME [epoch: 5.75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.801164674778616		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.801164674778616 | validation: 0.4576890769989005]
	TIME [epoch: 5.74 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37714525471581284		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.37714525471581284 | validation: 0.5271624580699242]
	TIME [epoch: 5.73 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581697883734375		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.4581697883734375 | validation: 0.5509674766812114]
	TIME [epoch: 5.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4170238396152555		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.4170238396152555 | validation: 0.510097959602228]
	TIME [epoch: 5.73 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271654665296792		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.4271654665296792 | validation: 1.1479344185115008]
	TIME [epoch: 5.72 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127707629205566		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7127707629205566 | validation: 0.7372432814821207]
	TIME [epoch: 5.72 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6043124252535377		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6043124252535377 | validation: 0.6062467048744882]
	TIME [epoch: 5.77 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178879343806763		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.5178879343806763 | validation: 1.0402719450945666]
	TIME [epoch: 5.72 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536915020122009		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.5536915020122009 | validation: 0.5975962553452061]
	TIME [epoch: 5.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4475564818620479		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.4475564818620479 | validation: 0.658882402343887]
	TIME [epoch: 5.72 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976574824870661		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.4976574824870661 | validation: 0.4604875117775735]
	TIME [epoch: 5.72 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41578090207524787		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.41578090207524787 | validation: 0.512960753259606]
	TIME [epoch: 5.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638824737387669		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.4638824737387669 | validation: 0.42313291674893266]
	TIME [epoch: 5.75 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49981985326082845		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.49981985326082845 | validation: 0.4840399670713356]
	TIME [epoch: 5.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35737443081827297		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.35737443081827297 | validation: 0.8787531527910334]
	TIME [epoch: 5.73 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806111613818417		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.5806111613818417 | validation: 0.5597613119786055]
	TIME [epoch: 5.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4389702296972413		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.4389702296972413 | validation: 0.48313638195096514]
	TIME [epoch: 5.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43483249690924153		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.43483249690924153 | validation: 0.537315212209715]
	TIME [epoch: 5.72 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36717838150139304		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.36717838150139304 | validation: 0.4660264541191666]
	TIME [epoch: 5.73 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735038222568284		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3735038222568284 | validation: 0.6466077609815545]
	TIME [epoch: 5.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697262538948501		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.697262538948501 | validation: 0.6176139560576676]
	TIME [epoch: 5.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4393327516995633		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.4393327516995633 | validation: 0.4460024646169633]
	TIME [epoch: 5.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4150457174505712		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.4150457174505712 | validation: 0.4163254057285141]
	TIME [epoch: 5.72 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41439955198427747		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.41439955198427747 | validation: 0.4159988124845462]
	TIME [epoch: 5.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5112672006334728		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5112672006334728 | validation: 0.45684444070452374]
	TIME [epoch: 5.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.430316254919875		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.430316254919875 | validation: 0.6179930324485045]
	TIME [epoch: 5.74 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413749306271364		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.4413749306271364 | validation: 0.7768222797556072]
	TIME [epoch: 5.75 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46819497760385986		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.46819497760385986 | validation: 0.550865706743553]
	TIME [epoch: 5.73 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4201296240034116		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.4201296240034116 | validation: 0.6552840147180627]
	TIME [epoch: 5.73 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082956196191222		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5082956196191222 | validation: 0.42396393003349647]
	TIME [epoch: 5.73 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632700802487623		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.3632700802487623 | validation: 0.650383775586202]
	TIME [epoch: 5.73 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529689269606403		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5529689269606403 | validation: 0.5648809505377143]
	TIME [epoch: 5.73 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149186341825548		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6149186341825548 | validation: 0.6451967051072266]
	TIME [epoch: 5.76 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40991104424380004		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.40991104424380004 | validation: 0.7948580510159539]
	TIME [epoch: 5.73 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.508822729912551		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.508822729912551 | validation: 0.8031725481589561]
	TIME [epoch: 5.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560178224959511		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.560178224959511 | validation: 0.4642333441238536]
	TIME [epoch: 5.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42781313832891954		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.42781313832891954 | validation: 0.4475077951818214]
	TIME [epoch: 5.73 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3939082237739395		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3939082237739395 | validation: 0.4462022928525374]
	TIME [epoch: 5.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109401003891074		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6109401003891074 | validation: 0.5626341126647314]
	TIME [epoch: 5.74 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600335727978211		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.5600335727978211 | validation: 0.45852523636180237]
	TIME [epoch: 5.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924882489071884		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.5924882489071884 | validation: 0.47518917150398665]
	TIME [epoch: 5.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932335093648097		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3932335093648097 | validation: 0.45256602801881196]
	TIME [epoch: 5.73 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39677820935482616		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.39677820935482616 | validation: 0.5082404090755493]
	TIME [epoch: 5.73 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893901650439235		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.5893901650439235 | validation: 0.585210190940657]
	TIME [epoch: 5.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789542489907269		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5789542489907269 | validation: 0.4104607203991876]
	TIME [epoch: 5.74 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3407488287740408		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3407488287740408 | validation: 0.4461918937512662]
	TIME [epoch: 5.77 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35688278681421615		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.35688278681421615 | validation: 0.3552910151354831]
	TIME [epoch: 5.73 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46657756221348373		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.46657756221348373 | validation: 0.36508330246770476]
	TIME [epoch: 5.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4008080232670199		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.4008080232670199 | validation: 0.6191403059861778]
	TIME [epoch: 5.73 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404111354445611		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.4404111354445611 | validation: 0.48674105362993997]
	TIME [epoch: 5.73 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926102565647719		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.3926102565647719 | validation: 0.5481801463759789]
	TIME [epoch: 5.73 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302869034195073		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.4302869034195073 | validation: 0.43619585788988047]
	TIME [epoch: 5.74 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37500837118192865		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.37500837118192865 | validation: 0.44944556268287794]
	TIME [epoch: 5.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.324067092473572		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.324067092473572 | validation: 0.5005726616097853]
	TIME [epoch: 5.73 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33199784446974767		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.33199784446974767 | validation: 0.6120619284794289]
	TIME [epoch: 5.73 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561146224388541		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4561146224388541 | validation: 0.42980585214136136]
	TIME [epoch: 5.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33063213008955034		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.33063213008955034 | validation: 0.4269472342985597]
	TIME [epoch: 5.73 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708958429410676		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.3708958429410676 | validation: 0.370088939168143]
	TIME [epoch: 5.73 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153403158077328		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3153403158077328 | validation: 0.390891516004223]
	TIME [epoch: 5.77 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40531101623490595		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.40531101623490595 | validation: 0.3858811337545961]
	TIME [epoch: 5.73 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3506645063607142		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.3506645063607142 | validation: 0.33777964136282423]
	TIME [epoch: 5.73 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36579528239000547		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.36579528239000547 | validation: 0.41902764497043604]
	TIME [epoch: 5.73 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818194633500207		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.3818194633500207 | validation: 0.497349568594619]
	TIME [epoch: 5.73 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.419986786784822		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.419986786784822 | validation: 0.4479898100259383]
	TIME [epoch: 5.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34862369505995366		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.34862369505995366 | validation: 0.3811053690249911]
	TIME [epoch: 5.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38354083293762975		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.38354083293762975 | validation: 0.3540313294505281]
	TIME [epoch: 5.76 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117879189922044		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.3117879189922044 | validation: 0.35564713947462884]
	TIME [epoch: 5.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224115808979163		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.3224115808979163 | validation: 0.6244701803960935]
	TIME [epoch: 5.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49832291250946575		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.49832291250946575 | validation: 0.36964423985835915]
	TIME [epoch: 5.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652545146607746		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.4652545146607746 | validation: 0.3558628935019019]
	TIME [epoch: 5.73 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32943978047749833		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.32943978047749833 | validation: 0.3549463628836116]
	TIME [epoch: 5.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33813666318145835		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.33813666318145835 | validation: 0.39166824268016615]
	TIME [epoch: 5.77 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34164785840213774		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.34164785840213774 | validation: 0.5929189072124281]
	TIME [epoch: 5.73 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402543957811024		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3402543957811024 | validation: 0.5058100988460104]
	TIME [epoch: 5.73 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3628157965412455		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.3628157965412455 | validation: 0.3384230251536414]
	TIME [epoch: 5.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41954791399216745		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.41954791399216745 | validation: 0.4550204781854851]
	TIME [epoch: 5.74 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3519271160521753		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.3519271160521753 | validation: 0.36054797569570585]
	TIME [epoch: 5.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488808150248561		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.3488808150248561 | validation: 0.3139272276311096]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507127833073066		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.507127833073066 | validation: 0.4763343485024177]
	TIME [epoch: 5.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41372541664417056		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.41372541664417056 | validation: 0.38757833369141664]
	TIME [epoch: 5.75 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3419551628094796		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3419551628094796 | validation: 0.39586602151099576]
	TIME [epoch: 5.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33544910932555005		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.33544910932555005 | validation: 0.3912404896689624]
	TIME [epoch: 5.75 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41451764690383486		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.41451764690383486 | validation: 0.3317203284029423]
	TIME [epoch: 5.75 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29124184388162905		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.29124184388162905 | validation: 0.544102307696218]
	TIME [epoch: 5.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804148440153564		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.3804148440153564 | validation: 0.31143114104193764]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25915716429725116		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.25915716429725116 | validation: 0.33728466494207837]
	TIME [epoch: 5.74 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903307753781764		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.2903307753781764 | validation: 0.4603536674850423]
	TIME [epoch: 5.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35711895680948497		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.35711895680948497 | validation: 0.41188556441757124]
	TIME [epoch: 5.74 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542733049221333		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3542733049221333 | validation: 0.3561683755252604]
	TIME [epoch: 5.73 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621760529354554		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.3621760529354554 | validation: 0.44159058218772246]
	TIME [epoch: 5.73 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3551003265035092		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3551003265035092 | validation: 0.30012137861719607]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36030930837065517		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.36030930837065517 | validation: 0.44475389868057025]
	TIME [epoch: 5.77 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34122019720723584		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.34122019720723584 | validation: 0.35946624952889195]
	TIME [epoch: 5.75 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32556061941248104		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.32556061941248104 | validation: 0.602212239748819]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38672426768239226		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.38672426768239226 | validation: 0.31079413480269075]
	TIME [epoch: 5.73 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33397871318376393		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.33397871318376393 | validation: 0.40080696184177383]
	TIME [epoch: 5.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3653631232222387		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.3653631232222387 | validation: 0.45849645512075415]
	TIME [epoch: 5.74 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33738368532371055		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.33738368532371055 | validation: 0.33727874007522074]
	TIME [epoch: 5.79 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411197414782347		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3411197414782347 | validation: 0.3398666192312335]
	TIME [epoch: 5.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29892941379356847		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.29892941379356847 | validation: 0.32605897223942537]
	TIME [epoch: 5.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33007918301682604		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.33007918301682604 | validation: 0.31014004927756167]
	TIME [epoch: 5.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850801961559444		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.2850801961559444 | validation: 0.3236075186281519]
	TIME [epoch: 5.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141397733248565		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.3141397733248565 | validation: 0.5614416015154363]
	TIME [epoch: 5.75 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36740155785495343		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.36740155785495343 | validation: 0.29322744914489135]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33911188443321305		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.33911188443321305 | validation: 0.3011459676245739]
	TIME [epoch: 5.77 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2615883435032096		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.2615883435032096 | validation: 0.5573452212650938]
	TIME [epoch: 5.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418262101741855		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.418262101741855 | validation: 0.3535958491965486]
	TIME [epoch: 5.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285683066798357		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.3285683066798357 | validation: 0.31796555443086955]
	TIME [epoch: 5.73 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32681156908682374		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.32681156908682374 | validation: 0.5169982188320015]
	TIME [epoch: 5.73 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318010142618134		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3318010142618134 | validation: 0.42481996594387783]
	TIME [epoch: 5.74 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2884716804511737		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.2884716804511737 | validation: 0.3650715434542132]
	TIME [epoch: 5.78 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3175734088109875		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.3175734088109875 | validation: 0.2715099888044975]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29409613953817604		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.29409613953817604 | validation: 0.40768199405929884]
	TIME [epoch: 5.75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968828180620741		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2968828180620741 | validation: 0.2563046888392937]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929889884729135		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.3929889884729135 | validation: 0.37230224634699227]
	TIME [epoch: 5.73 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30539971015910033		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.30539971015910033 | validation: 0.34464292387202505]
	TIME [epoch: 5.73 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016638745126738		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3016638745126738 | validation: 0.41008572371229135]
	TIME [epoch: 5.77 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667560567039739		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3667560567039739 | validation: 0.3255171582399294]
	TIME [epoch: 5.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278238343610199		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3278238343610199 | validation: 0.2841181022859479]
	TIME [epoch: 5.73 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4474900848706994		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4474900848706994 | validation: 0.4648152663321028]
	TIME [epoch: 5.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726680792368854		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4726680792368854 | validation: 0.4042994982352154]
	TIME [epoch: 5.74 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288221336885854		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.288221336885854 | validation: 0.3598432402523784]
	TIME [epoch: 5.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29177176954061135		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.29177176954061135 | validation: 0.3754877364704058]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742577707919662		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2742577707919662 | validation: 0.35596002319460285]
	TIME [epoch: 5.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684506630045599		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2684506630045599 | validation: 0.29146391862696513]
	TIME [epoch: 5.73 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25887614170463197		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.25887614170463197 | validation: 0.39353502235888044]
	TIME [epoch: 5.73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373541667573586		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.373541667573586 | validation: 0.4646152839013176]
	TIME [epoch: 5.73 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090139416592731		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.3090139416592731 | validation: 0.2587400182959992]
	TIME [epoch: 5.74 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2288984278526509		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.2288984278526509 | validation: 0.6014479548375685]
	TIME [epoch: 5.73 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778105176067078		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.3778105176067078 | validation: 0.31325185431643376]
	TIME [epoch: 5.79 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27569537656947574		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.27569537656947574 | validation: 0.4424411335644978]
	TIME [epoch: 5.74 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.322876089815503		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.322876089815503 | validation: 0.28829251944533224]
	TIME [epoch: 5.74 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26382847670501264		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.26382847670501264 | validation: 0.323548672051715]
	TIME [epoch: 5.73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24488292769193296		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.24488292769193296 | validation: 0.251431231227736]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092843365550513		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.2092843365550513 | validation: 0.39476968636735293]
	TIME [epoch: 5.73 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025164641016218		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.4025164641016218 | validation: 0.41074647769006606]
	TIME [epoch: 5.77 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42307280919923196		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.42307280919923196 | validation: 0.4905229996327371]
	TIME [epoch: 5.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972210609959669		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.3972210609959669 | validation: 0.44915636408492854]
	TIME [epoch: 5.74 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106564238740474		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.3106564238740474 | validation: 0.289208116258181]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29700824573011936		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.29700824573011936 | validation: 0.4004461050693923]
	TIME [epoch: 5.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26435706341018705		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.26435706341018705 | validation: 0.3541318761608157]
	TIME [epoch: 5.73 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499556289753725		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.2499556289753725 | validation: 0.4054246928679138]
	TIME [epoch: 5.73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3829192512698076		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.3829192512698076 | validation: 0.4098759693343093]
	TIME [epoch: 5.78 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29433825764263183		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.29433825764263183 | validation: 0.5604299948071996]
	TIME [epoch: 5.74 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2941696552061559		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2941696552061559 | validation: 0.3214104074865495]
	TIME [epoch: 5.74 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33554426260844505		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.33554426260844505 | validation: 0.31295787353812343]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.349651139422734		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.349651139422734 | validation: 0.35729383220606176]
	TIME [epoch: 5.73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35513900750242855		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.35513900750242855 | validation: 0.3597888293318941]
	TIME [epoch: 5.73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28922516936350007		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.28922516936350007 | validation: 0.36051742107421925]
	TIME [epoch: 5.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569658414272637		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2569658414272637 | validation: 0.2796692755834459]
	TIME [epoch: 5.77 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23747814431862596		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.23747814431862596 | validation: 0.4206542738186775]
	TIME [epoch: 5.73 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979230100827431		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2979230100827431 | validation: 0.36785478526441956]
	TIME [epoch: 5.73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3224356150002842		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3224356150002842 | validation: 0.31709206918722366]
	TIME [epoch: 5.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28991557666674855		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.28991557666674855 | validation: 0.29597563232983837]
	TIME [epoch: 5.73 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28973471544692286		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.28973471544692286 | validation: 0.32313785851000487]
	TIME [epoch: 5.73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28944043916250045		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.28944043916250045 | validation: 0.231377778920267]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095816221383472		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3095816221383472 | validation: 0.2917689455668113]
	TIME [epoch: 5.75 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24273377501256221		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.24273377501256221 | validation: 0.2666645088676479]
	TIME [epoch: 5.75 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968121087085474		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.21968121087085474 | validation: 0.3055900227245512]
	TIME [epoch: 5.75 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763952133858774		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.2763952133858774 | validation: 0.30978625263373355]
	TIME [epoch: 5.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2115051200636114		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.2115051200636114 | validation: 0.2671646085864053]
	TIME [epoch: 5.75 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2236762262855096		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2236762262855096 | validation: 0.25757231749850307]
	TIME [epoch: 5.78 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25124092840370116		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.25124092840370116 | validation: 0.380971513440152]
	TIME [epoch: 5.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495832224542513		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.3495832224542513 | validation: 0.2572152191102409]
	TIME [epoch: 5.75 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176193913149658		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.2176193913149658 | validation: 0.2854691231518605]
	TIME [epoch: 5.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24949598535276968		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.24949598535276968 | validation: 0.24767264685291016]
	TIME [epoch: 5.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947609495563258		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.2947609495563258 | validation: 0.29395854995693865]
	TIME [epoch: 5.75 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22493830010709776		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.22493830010709776 | validation: 0.533612195937922]
	TIME [epoch: 5.75 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38803643349661815		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.38803643349661815 | validation: 0.41153097655860676]
	TIME [epoch: 5.79 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26406602456126654		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.26406602456126654 | validation: 0.302710958212576]
	TIME [epoch: 5.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2219041450824632		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2219041450824632 | validation: 0.5513738663085969]
	TIME [epoch: 5.75 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37166614324343694		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.37166614324343694 | validation: 0.3134495751542818]
	TIME [epoch: 5.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604606791890639		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2604606791890639 | validation: 0.30418516653341804]
	TIME [epoch: 5.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24141474435693272		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.24141474435693272 | validation: 0.4100398197681526]
	TIME [epoch: 5.75 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923892597030345		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2923892597030345 | validation: 0.46429304606558375]
	TIME [epoch: 5.78 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25312793498003155		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.25312793498003155 | validation: 0.26956379470322006]
	TIME [epoch: 5.76 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2005369023246973		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2005369023246973 | validation: 0.3168521923675807]
	TIME [epoch: 5.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625530824512832		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2625530824512832 | validation: 0.290411541495636]
	TIME [epoch: 5.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234059344576606		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2234059344576606 | validation: 0.40153225069057724]
	TIME [epoch: 5.75 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279523703620149		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.279523703620149 | validation: 0.4777868024033092]
	TIME [epoch: 5.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621788216861736		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.3621788216861736 | validation: 0.25331957479332257]
	TIME [epoch: 5.75 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24115393896401902		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.24115393896401902 | validation: 0.36036914586234603]
	TIME [epoch: 5.79 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24549247880130337		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.24549247880130337 | validation: 0.252155916447919]
	TIME [epoch: 5.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26275444223603006		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.26275444223603006 | validation: 0.30239917607585065]
	TIME [epoch: 5.75 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182898941840024		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2182898941840024 | validation: 0.2721966062156401]
	TIME [epoch: 5.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25126383835641464		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.25126383835641464 | validation: 0.3112667208900332]
	TIME [epoch: 5.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28812233636456547		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.28812233636456547 | validation: 0.256397511918869]
	TIME [epoch: 5.75 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27076928796807026		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.27076928796807026 | validation: 0.32647326574123015]
	TIME [epoch: 5.77 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704767015907015		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.2704767015907015 | validation: 0.2919180130075045]
	TIME [epoch: 5.76 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27176987120049184		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.27176987120049184 | validation: 0.24800205808710052]
	TIME [epoch: 5.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24959052860270875		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.24959052860270875 | validation: 0.2938502380063803]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27120601390579563		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.27120601390579563 | validation: 0.22820970502591864]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29375688946051387		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.29375688946051387 | validation: 0.34812582237720263]
	TIME [epoch: 5.75 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518569228520241		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2518569228520241 | validation: 0.22775369836697018]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24311307263747048		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.24311307263747048 | validation: 0.400637645958966]
	TIME [epoch: 5.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23157329538458588		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.23157329538458588 | validation: 0.23853781583574765]
	TIME [epoch: 5.74 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20350358850678957		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.20350358850678957 | validation: 0.22797726033861995]
	TIME [epoch: 5.73 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889612017438525		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.1889612017438525 | validation: 0.3052556923727813]
	TIME [epoch: 5.73 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23273140689918698		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.23273140689918698 | validation: 0.2683336140409102]
	TIME [epoch: 5.73 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22679989873974954		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.22679989873974954 | validation: 0.29831294235667905]
	TIME [epoch: 5.73 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296840546605259		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.2296840546605259 | validation: 0.22062171086394874]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22991292947320793		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.22991292947320793 | validation: 0.33327613460703776]
	TIME [epoch: 5.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27481851485242204		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.27481851485242204 | validation: 0.2560658158004049]
	TIME [epoch: 5.73 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704078701312987		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.2704078701312987 | validation: 0.34847660155777077]
	TIME [epoch: 5.73 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1979437208022006		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1979437208022006 | validation: 0.4381769377998913]
	TIME [epoch: 5.73 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811354390984052		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.2811354390984052 | validation: 0.23728534027477508]
	TIME [epoch: 5.73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23605068667801407		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.23605068667801407 | validation: 0.34277501978168057]
	TIME [epoch: 5.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275704334490819		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.275704334490819 | validation: 0.22953329264234068]
	TIME [epoch: 5.76 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064332056321804		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.20064332056321804 | validation: 0.2640223606588147]
	TIME [epoch: 5.73 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18910800982033152		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.18910800982033152 | validation: 0.2054690607865084]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060141674139172		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2060141674139172 | validation: 0.21390017415866142]
	TIME [epoch: 5.73 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22336807513903983		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.22336807513903983 | validation: 0.30669379039861855]
	TIME [epoch: 5.73 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20797478944136683		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.20797478944136683 | validation: 0.3045070652403648]
	TIME [epoch: 5.73 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24886171061429685		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.24886171061429685 | validation: 0.20506438324153414]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234535052006964		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2234535052006964 | validation: 0.5060569824929011]
	TIME [epoch: 5.73 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023734705243199		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.3023734705243199 | validation: 0.25962176067128084]
	TIME [epoch: 5.73 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16695491723855055		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.16695491723855055 | validation: 0.33351473685473815]
	TIME [epoch: 5.72 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.296135598260978		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.296135598260978 | validation: 0.2948009309297785]
	TIME [epoch: 5.73 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518361138810769		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.2518361138810769 | validation: 0.20313589506444452]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25494451500620674		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.25494451500620674 | validation: 0.21948020094734438]
	TIME [epoch: 5.76 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23141483832001444		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.23141483832001444 | validation: 0.2640408917382341]
	TIME [epoch: 5.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19538447123300579		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.19538447123300579 | validation: 0.32615771641597596]
	TIME [epoch: 5.73 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788915987081437		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.2788915987081437 | validation: 0.2617446796529976]
	TIME [epoch: 5.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428749308212823		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2428749308212823 | validation: 0.2437080089509558]
	TIME [epoch: 5.73 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21472057352000784		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.21472057352000784 | validation: 0.39548035974322376]
	TIME [epoch: 5.74 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756498088088544		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2756498088088544 | validation: 0.21297740120044736]
	TIME [epoch: 5.73 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18744946675295276		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.18744946675295276 | validation: 0.369100743722158]
	TIME [epoch: 5.78 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25063082312506424		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.25063082312506424 | validation: 0.19699187995950332]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19597959891254213		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.19597959891254213 | validation: 0.3632222925005332]
	TIME [epoch: 5.73 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26919296854255154		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.26919296854255154 | validation: 0.32130917533797126]
	TIME [epoch: 5.73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22546561657885722		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.22546561657885722 | validation: 0.29687079807120764]
	TIME [epoch: 5.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19785008341032315		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.19785008341032315 | validation: 0.25648847503316247]
	TIME [epoch: 5.73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988665733041942		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2988665733041942 | validation: 0.2553596857396227]
	TIME [epoch: 5.77 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266547965928805		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2266547965928805 | validation: 0.3106116321057615]
	TIME [epoch: 5.74 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21961175861083224		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.21961175861083224 | validation: 0.2020278992852672]
	TIME [epoch: 5.73 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17246250358950532		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.17246250358950532 | validation: 0.20930237953412306]
	TIME [epoch: 5.73 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239622731739118		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.239622731739118 | validation: 0.21749175780783808]
	TIME [epoch: 5.73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547891582711407		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2547891582711407 | validation: 0.23878847497097674]
	TIME [epoch: 5.73 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048548075351868		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.2048548075351868 | validation: 0.23738920205583167]
	TIME [epoch: 5.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2316148211050496		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2316148211050496 | validation: 0.2393936910165447]
	TIME [epoch: 5.76 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2170372502141174		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2170372502141174 | validation: 0.26683551103554015]
	TIME [epoch: 5.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19920142096225116		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.19920142096225116 | validation: 0.316197127243688]
	TIME [epoch: 5.74 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3359893427636004		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3359893427636004 | validation: 0.27015506542284884]
	TIME [epoch: 5.73 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24136473915283668		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.24136473915283668 | validation: 0.2476634063301171]
	TIME [epoch: 5.74 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981081740936574		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1981081740936574 | validation: 0.23082286203606917]
	TIME [epoch: 5.73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866860193476391		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.1866860193476391 | validation: 0.26771603676733047]
	TIME [epoch: 5.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655741133062434		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2655741133062434 | validation: 0.19543860380026373]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782844742321609		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1782844742321609 | validation: 0.22592845658629188]
	TIME [epoch: 5.73 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20252256975195748		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.20252256975195748 | validation: 0.3935195483433034]
	TIME [epoch: 5.73 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642848614460836		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.2642848614460836 | validation: 0.5300831454066844]
	TIME [epoch: 5.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943684238220647		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.2943684238220647 | validation: 0.20582351628769083]
	TIME [epoch: 5.72 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24145865013972853		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.24145865013972853 | validation: 0.21706728154670368]
	TIME [epoch: 5.73 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1759516046699971		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.1759516046699971 | validation: 0.1781910833189734]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16530841731915105		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.16530841731915105 | validation: 0.204195924242106]
	TIME [epoch: 5.73 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17861795873356193		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.17861795873356193 | validation: 0.26772792834428805]
	TIME [epoch: 5.72 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2431565836378916		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.2431565836378916 | validation: 0.23762233943401193]
	TIME [epoch: 5.73 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18325897629960491		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.18325897629960491 | validation: 0.2509751378600417]
	TIME [epoch: 5.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627466217067151		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2627466217067151 | validation: 0.26257587461865417]
	TIME [epoch: 5.73 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114711830287416		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.2114711830287416 | validation: 0.2713079017090426]
	TIME [epoch: 5.75 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22113618049826173		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.22113618049826173 | validation: 0.20602155293941882]
	TIME [epoch: 5.73 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079366384504827		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2079366384504827 | validation: 0.323994889800421]
	TIME [epoch: 5.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520319853622881		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2520319853622881 | validation: 0.3294484018269255]
	TIME [epoch: 5.74 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120308681814019		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.2120308681814019 | validation: 0.21357197142822784]
	TIME [epoch: 5.74 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17997619946019133		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.17997619946019133 | validation: 0.26290020125485264]
	TIME [epoch: 5.74 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20671658674102122		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.20671658674102122 | validation: 0.22818665031806512]
	TIME [epoch: 5.75 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18413990952406573		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.18413990952406573 | validation: 0.22977005004746914]
	TIME [epoch: 5.78 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23647929612018848		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.23647929612018848 | validation: 0.1987909851920283]
	TIME [epoch: 5.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936599674424049		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.1936599674424049 | validation: 0.18600869462020758]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548772543013479		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.1548772543013479 | validation: 0.34246688174732554]
	TIME [epoch: 5.73 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23622445511542658		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.23622445511542658 | validation: 0.2535118704706119]
	TIME [epoch: 5.74 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18475796062335104		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.18475796062335104 | validation: 0.20737523895836274]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19510506632727903		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.19510506632727903 | validation: 0.2332736027098561]
	TIME [epoch: 5.78 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19156435606777727		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.19156435606777727 | validation: 0.25976050832955966]
	TIME [epoch: 5.73 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19411808577109718		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.19411808577109718 | validation: 0.2981241939254872]
	TIME [epoch: 5.73 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21123258761892136		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.21123258761892136 | validation: 0.2619519187327689]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18113729331932388		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.18113729331932388 | validation: 0.3255677440179517]
	TIME [epoch: 5.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755213196951409		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.2755213196951409 | validation: 0.2822703730905508]
	TIME [epoch: 5.74 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22689943266391208		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.22689943266391208 | validation: 0.23103197924010221]
	TIME [epoch: 5.76 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17232553482221438		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.17232553482221438 | validation: 0.24316131420439335]
	TIME [epoch: 5.77 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17777331011590014		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.17777331011590014 | validation: 0.26587602506691105]
	TIME [epoch: 5.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1672009224822603		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1672009224822603 | validation: 0.18737577435124914]
	TIME [epoch: 5.73 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17643743590695582		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17643743590695582 | validation: 0.21891929076708094]
	TIME [epoch: 5.72 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19896061128545733		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.19896061128545733 | validation: 0.21761804684292835]
	TIME [epoch: 5.73 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17764484976420017		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.17764484976420017 | validation: 0.23614554939851054]
	TIME [epoch: 5.73 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20113671585788803		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.20113671585788803 | validation: 0.19793073595316604]
	TIME [epoch: 5.78 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17526181776111582		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.17526181776111582 | validation: 0.20406167789969007]
	TIME [epoch: 5.75 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18260966708401768		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.18260966708401768 | validation: 0.21596141170543434]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17846167258832357		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.17846167258832357 | validation: 0.21056532043751247]
	TIME [epoch: 5.73 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296113678632526		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2296113678632526 | validation: 0.24513681085500125]
	TIME [epoch: 5.74 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20406797040459626		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.20406797040459626 | validation: 0.25818887361900417]
	TIME [epoch: 5.72 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19893052405705855		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.19893052405705855 | validation: 0.22850339612978307]
	TIME [epoch: 5.76 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15893745012041144		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.15893745012041144 | validation: 0.17071440375323638]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655332173284486		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.1655332173284486 | validation: 0.1659820661142603]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14338165639807562		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.14338165639807562 | validation: 0.1835384894595335]
	TIME [epoch: 5.73 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18488169057279819		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.18488169057279819 | validation: 0.20383760928590164]
	TIME [epoch: 5.72 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729555164156202		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.1729555164156202 | validation: 0.4400118759971812]
	TIME [epoch: 5.72 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939886376366088		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2939886376366088 | validation: 0.2698843051068565]
	TIME [epoch: 5.73 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876081321097956		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1876081321097956 | validation: 0.1924690084927009]
	TIME [epoch: 5.76 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131496171892193		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.22131496171892193 | validation: 0.2531847520104795]
	TIME [epoch: 5.73 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938742564412176		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1938742564412176 | validation: 0.26140194895904784]
	TIME [epoch: 5.72 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19393516337200684		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.19393516337200684 | validation: 0.26339401625290665]
	TIME [epoch: 5.72 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699019103154458		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1699019103154458 | validation: 0.20411130513687467]
	TIME [epoch: 5.72 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394668577016565		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2394668577016565 | validation: 0.17616299052027845]
	TIME [epoch: 5.72 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16366003636304732		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.16366003636304732 | validation: 0.19242914230768698]
	TIME [epoch: 5.75 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20398026657678742		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.20398026657678742 | validation: 0.2104435725026474]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828971511333998		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.1828971511333998 | validation: 0.22147373245211172]
	TIME [epoch: 5.72 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442962219844749		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.1442962219844749 | validation: 0.18157440710982728]
	TIME [epoch: 5.72 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15236722306770406		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.15236722306770406 | validation: 0.2433551339601506]
	TIME [epoch: 5.72 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22022166537780935		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.22022166537780935 | validation: 0.17570553256195845]
	TIME [epoch: 5.72 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156848981972742		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.156848981972742 | validation: 0.22766552474012078]
	TIME [epoch: 5.72 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519392792669111		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.1519392792669111 | validation: 0.20295997292679807]
	TIME [epoch: 5.76 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17907967439623984		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.17907967439623984 | validation: 0.19731048546042723]
	TIME [epoch: 5.73 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20349949052153282		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.20349949052153282 | validation: 0.19528692034620398]
	TIME [epoch: 5.72 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22641294236117215		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.22641294236117215 | validation: 0.22677408922807452]
	TIME [epoch: 5.72 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18291648549014958		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.18291648549014958 | validation: 0.31324116776215644]
	TIME [epoch: 5.72 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1633288048006704		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1633288048006704 | validation: 0.14811864103270844]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12233606635174951		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.12233606635174951 | validation: 0.14610722849726818]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543328078573715		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.1543328078573715 | validation: 0.20318434905124064]
	TIME [epoch: 5.74 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16772032077430454		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.16772032077430454 | validation: 0.33405949780542243]
	TIME [epoch: 5.72 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21742637399737585		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.21742637399737585 | validation: 0.19816766493897145]
	TIME [epoch: 5.72 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13758072021470175		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.13758072021470175 | validation: 0.22968824691523274]
	TIME [epoch: 5.72 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17601618173943415		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.17601618173943415 | validation: 0.1741695304268675]
	TIME [epoch: 5.73 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16716629439048758		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.16716629439048758 | validation: 0.20404238576798875]
	TIME [epoch: 5.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17213924868628874		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.17213924868628874 | validation: 0.18337804528053858]
	TIME [epoch: 5.75 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21594343527120313		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.21594343527120313 | validation: 0.19615957774131346]
	TIME [epoch: 5.73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14146731157052228		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.14146731157052228 | validation: 0.2024002592890398]
	TIME [epoch: 5.72 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14099700575254184		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14099700575254184 | validation: 0.15599770718274789]
	TIME [epoch: 5.72 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12771253894685114		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.12771253894685114 | validation: 0.24642953807498102]
	TIME [epoch: 5.72 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17501544462188584		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.17501544462188584 | validation: 0.23007216882251846]
	TIME [epoch: 5.72 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15929802729906667		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15929802729906667 | validation: 0.21130659148853995]
	TIME [epoch: 5.76 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647051247656577		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.1647051247656577 | validation: 0.25446014769407344]
	TIME [epoch: 5.73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2159410689341277		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2159410689341277 | validation: 0.19502046888485466]
	TIME [epoch: 5.72 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16554109050611016		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.16554109050611016 | validation: 0.15222065043312696]
	TIME [epoch: 5.72 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20182054860200435		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.20182054860200435 | validation: 0.25044105066641753]
	TIME [epoch: 5.73 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22715541055048477		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.22715541055048477 | validation: 0.16602749941672948]
	TIME [epoch: 5.72 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16164991310675944		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.16164991310675944 | validation: 0.21675630106901078]
	TIME [epoch: 5.73 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529902366630072		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1529902366630072 | validation: 0.21074935556682586]
	TIME [epoch: 5.75 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16150878851349162		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.16150878851349162 | validation: 0.17955609088249425]
	TIME [epoch: 5.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164511744988631		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.164511744988631 | validation: 0.19068423584662408]
	TIME [epoch: 5.72 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403694690264854		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1403694690264854 | validation: 0.1628792468357369]
	TIME [epoch: 5.72 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15536979533281922		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.15536979533281922 | validation: 0.15562141002024654]
	TIME [epoch: 5.73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2003581502875584		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2003581502875584 | validation: 0.21871469975478985]
	TIME [epoch: 5.73 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18785355815608887		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.18785355815608887 | validation: 0.19547069718387222]
	TIME [epoch: 5.76 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16122259273140332		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.16122259273140332 | validation: 0.19079943271860886]
	TIME [epoch: 5.73 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467532106670377		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1467532106670377 | validation: 0.16913952205141972]
	TIME [epoch: 5.72 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328467579918141		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.1328467579918141 | validation: 0.15172327714633946]
	TIME [epoch: 5.73 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16080344349639353		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.16080344349639353 | validation: 0.16915861789489847]
	TIME [epoch: 5.72 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12089649268180774		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.12089649268180774 | validation: 0.19800707781162408]
	TIME [epoch: 5.72 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790996623375718		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.14790996623375718 | validation: 0.18108491201355345]
	TIME [epoch: 5.73 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16333399651989655		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16333399651989655 | validation: 0.17042327947856264]
	TIME [epoch: 5.75 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15733170808078453		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.15733170808078453 | validation: 0.3784926687501032]
	TIME [epoch: 5.73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2486755182364366		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.2486755182364366 | validation: 0.18663497191364736]
	TIME [epoch: 5.72 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13864741531374902		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.13864741531374902 | validation: 0.16836319589956167]
	TIME [epoch: 5.72 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17775958258763855		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.17775958258763855 | validation: 0.17452548761264383]
	TIME [epoch: 5.72 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14445114553024163		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.14445114553024163 | validation: 0.18588847835062297]
	TIME [epoch: 5.72 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630154851374833		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.1630154851374833 | validation: 0.21822551297298043]
	TIME [epoch: 5.76 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17666264900656714		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.17666264900656714 | validation: 0.32608686041634743]
	TIME [epoch: 5.73 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828933731219174		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1828933731219174 | validation: 0.150055695093174]
	TIME [epoch: 5.72 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967397268160024		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.17967397268160024 | validation: 0.2335611023958986]
	TIME [epoch: 5.72 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17580963842714775		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.17580963842714775 | validation: 0.15523633416699054]
	TIME [epoch: 5.72 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15211603926441608		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.15211603926441608 | validation: 0.29129723929440204]
	TIME [epoch: 5.72 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18834398764632265		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.18834398764632265 | validation: 0.18158906619031456]
	TIME [epoch: 5.73 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429234415106935		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1429234415106935 | validation: 0.18947755061404678]
	TIME [epoch: 5.75 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15622948907729403		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.15622948907729403 | validation: 0.18200620275419593]
	TIME [epoch: 5.72 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12830025628050729		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.12830025628050729 | validation: 0.15058464399383722]
	TIME [epoch: 5.72 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290035789073375		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1290035789073375 | validation: 0.16193612413401126]
	TIME [epoch: 5.72 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200492807592775		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.15200492807592775 | validation: 0.14093572058435694]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_607.pth
	Model improved!!!
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20263840859155907		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.20263840859155907 | validation: 0.18755281449676678]
	TIME [epoch: 5.72 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22477751419151842		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.22477751419151842 | validation: 0.22270298509859018]
	TIME [epoch: 5.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14367691805821428		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.14367691805821428 | validation: 0.15305197748419158]
	TIME [epoch: 5.72 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14264590977324978		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.14264590977324978 | validation: 0.14656651069837165]
	TIME [epoch: 5.72 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561772981268586		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.14561772981268586 | validation: 0.1849894594692106]
	TIME [epoch: 5.72 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15522940717463748		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.15522940717463748 | validation: 0.19841921747272945]
	TIME [epoch: 5.72 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933700062088874		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.12933700062088874 | validation: 0.17194534469875522]
	TIME [epoch: 5.72 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17117489675289496		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.17117489675289496 | validation: 0.19499339237423854]
	TIME [epoch: 5.73 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13595255046410332		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.13595255046410332 | validation: 0.1584810925272727]
	TIME [epoch: 5.75 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13881003071731324		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.13881003071731324 | validation: 0.16544424038016517]
	TIME [epoch: 5.72 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12363492272309877		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.12363492272309877 | validation: 0.21224276111582732]
	TIME [epoch: 5.72 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479815590321569		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1479815590321569 | validation: 0.15711805174979232]
	TIME [epoch: 5.72 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558083628001339		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1558083628001339 | validation: 0.15114872657988637]
	TIME [epoch: 5.72 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711602077495906		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.14711602077495906 | validation: 0.17001682572514415]
	TIME [epoch: 5.72 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14691348433347967		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.14691348433347967 | validation: 0.16425836687807313]
	TIME [epoch: 5.76 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12545747383587164		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.12545747383587164 | validation: 0.193849119293632]
	TIME [epoch: 5.72 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965012845718787		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.15965012845718787 | validation: 0.18724281965119496]
	TIME [epoch: 5.72 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967937871188345		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15967937871188345 | validation: 0.18360665630639184]
	TIME [epoch: 5.72 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13469824973998704		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.13469824973998704 | validation: 0.18229329263080093]
	TIME [epoch: 5.72 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14797883403889028		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.14797883403889028 | validation: 0.22031537571808024]
	TIME [epoch: 5.72 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837560146134909		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1837560146134909 | validation: 0.14750847107374374]
	TIME [epoch: 5.73 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427558379651894		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.1427558379651894 | validation: 0.23520518812474916]
	TIME [epoch: 5.74 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15203799914879518		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.15203799914879518 | validation: 0.160055433861941]
	TIME [epoch: 5.72 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453272486973025		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1453272486973025 | validation: 0.18903515357869388]
	TIME [epoch: 5.72 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636552524312394		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.1636552524312394 | validation: 0.1381588588139593]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12763968514893007		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.12763968514893007 | validation: 0.13737892042210506]
	TIME [epoch: 5.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_633.pth
	Model improved!!!
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881818662426666		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.14881818662426666 | validation: 0.2013987907729819]
	TIME [epoch: 5.72 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12907323793758366		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.12907323793758366 | validation: 0.14823194892813296]
	TIME [epoch: 5.76 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316562975398086		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.13316562975398086 | validation: 0.16039639744927814]
	TIME [epoch: 5.72 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824054813690842		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.13824054813690842 | validation: 0.1510375176534384]
	TIME [epoch: 5.72 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924166374680592		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.14924166374680592 | validation: 0.2883193471173715]
	TIME [epoch: 5.72 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603052454869119		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2603052454869119 | validation: 0.16162532895324788]
	TIME [epoch: 5.72 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15092894276560492		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15092894276560492 | validation: 0.257801671532619]
	TIME [epoch: 5.72 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15621428875576504		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.15621428875576504 | validation: 0.12133401025773577]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295525071231491		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.11295525071231491 | validation: 0.16368077016853363]
	TIME [epoch: 5.76 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14819383808409567		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.14819383808409567 | validation: 0.15752505917420262]
	TIME [epoch: 5.73 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892134826650573		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.12892134826650573 | validation: 0.19735820247296654]
	TIME [epoch: 5.72 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410061581776842		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1410061581776842 | validation: 0.16100680719871704]
	TIME [epoch: 5.73 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14717230848699292		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.14717230848699292 | validation: 0.20639658166055097]
	TIME [epoch: 5.73 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974676773981676		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.16974676773981676 | validation: 0.15964983039168978]
	TIME [epoch: 5.72 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15297393330222123		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.15297393330222123 | validation: 0.12512506370438498]
	TIME [epoch: 5.76 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085955707595132		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.1085955707595132 | validation: 0.12924989194531789]
	TIME [epoch: 5.72 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13649850411633646		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.13649850411633646 | validation: 0.1380481853509281]
	TIME [epoch: 5.73 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13415403176445126		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.13415403176445126 | validation: 0.14601175548277026]
	TIME [epoch: 5.72 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333600867140646		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.1333600867140646 | validation: 0.14190148667924063]
	TIME [epoch: 5.73 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14179040526068865		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.14179040526068865 | validation: 0.1211824371831046]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11886241042808611		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.11886241042808611 | validation: 0.19321261053841138]
	TIME [epoch: 5.76 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14136180207325494		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.14136180207325494 | validation: 0.15474642570665842]
	TIME [epoch: 5.76 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364771456060566		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.12364771456060566 | validation: 0.17766666170076587]
	TIME [epoch: 5.74 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14700359410233865		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.14700359410233865 | validation: 0.2578299230351911]
	TIME [epoch: 5.73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17269986294169926		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.17269986294169926 | validation: 0.15950176480028794]
	TIME [epoch: 5.73 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15655704194057476		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.15655704194057476 | validation: 0.1592303904710989]
	TIME [epoch: 5.72 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809450962359456		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.12809450962359456 | validation: 0.12491647419361006]
	TIME [epoch: 5.73 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18675656546282463		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.18675656546282463 | validation: 0.205559910868709]
	TIME [epoch: 5.76 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126387895020126		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.14126387895020126 | validation: 0.13476535902232298]
	TIME [epoch: 5.73 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10859636058014592		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.10859636058014592 | validation: 0.1135974512572416]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173576426606945		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.13173576426606945 | validation: 0.206040728999475]
	TIME [epoch: 5.73 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14880102880708698		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14880102880708698 | validation: 0.11576880686678492]
	TIME [epoch: 5.73 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13058280767218108		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.13058280767218108 | validation: 0.19187048500879925]
	TIME [epoch: 5.72 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554220091678429		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1554220091678429 | validation: 0.14254000676504927]
	TIME [epoch: 5.77 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11589450788146598		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.11589450788146598 | validation: 0.20195656727209638]
	TIME [epoch: 5.74 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362846589696291		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.1362846589696291 | validation: 0.20523888819725294]
	TIME [epoch: 5.73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23306435094818367		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.23306435094818367 | validation: 0.18750431999142322]
	TIME [epoch: 5.73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420876358216832		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1420876358216832 | validation: 0.1465213731394151]
	TIME [epoch: 5.74 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310106537261259		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1310106537261259 | validation: 0.15785662891492916]
	TIME [epoch: 5.73 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12818066363804564		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.12818066363804564 | validation: 0.12661428481448092]
	TIME [epoch: 5.72 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286511567654631		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.1286511567654631 | validation: 0.11948285430343723]
	TIME [epoch: 5.77 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049731425625391		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.10049731425625391 | validation: 0.14133909593931684]
	TIME [epoch: 5.73 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13305818459535224		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.13305818459535224 | validation: 0.15491828064666974]
	TIME [epoch: 5.73 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510884507640451		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.1510884507640451 | validation: 0.2789086186740832]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27924493726349997		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.27924493726349997 | validation: 0.17308055925208976]
	TIME [epoch: 5.73 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207725942758354		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1207725942758354 | validation: 0.15371359472620047]
	TIME [epoch: 5.73 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563899343226332		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1563899343226332 | validation: 0.2549780839256575]
	TIME [epoch: 5.77 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19845474148404527		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.19845474148404527 | validation: 0.14332272747253377]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13571207501445787		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.13571207501445787 | validation: 0.12279255285555728]
	TIME [epoch: 5.73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054123756068696		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.11054123756068696 | validation: 0.1384279537646834]
	TIME [epoch: 5.72 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418608624135826		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1418608624135826 | validation: 0.13354850969054508]
	TIME [epoch: 5.72 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468086325600833		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.11468086325600833 | validation: 0.14859045278185526]
	TIME [epoch: 5.73 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12213121598095117		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.12213121598095117 | validation: 0.1503215083070962]
	TIME [epoch: 5.72 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12137465676530151		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.12137465676530151 | validation: 0.27716984811954903]
	TIME [epoch: 5.77 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18834389721857345		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.18834389721857345 | validation: 0.12439954143245853]
	TIME [epoch: 5.73 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968556788332246		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.11968556788332246 | validation: 0.126606212798849]
	TIME [epoch: 5.74 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12180952515269501		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.12180952515269501 | validation: 0.1524138375475845]
	TIME [epoch: 5.73 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502269099341192		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1502269099341192 | validation: 0.19883848931467096]
	TIME [epoch: 5.73 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829734347337837		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.12829734347337837 | validation: 0.1324355742713188]
	TIME [epoch: 5.72 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1144615701651738		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.1144615701651738 | validation: 0.13077298727698755]
	TIME [epoch: 5.75 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11520647785385002		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.11520647785385002 | validation: 0.1627372821273852]
	TIME [epoch: 5.73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18746632062624555		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.18746632062624555 | validation: 0.16461074575917437]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12305163627721069		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.12305163627721069 | validation: 0.1405940744222535]
	TIME [epoch: 5.72 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11507481287147367		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.11507481287147367 | validation: 0.10501423095802949]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130990566049882		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.12130990566049882 | validation: 0.12534950878525863]
	TIME [epoch: 5.74 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376271140337572		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.1376271140337572 | validation: 0.14507861674880396]
	TIME [epoch: 5.75 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859458106611355		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.13859458106611355 | validation: 0.18336285741840214]
	TIME [epoch: 5.77 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279821617274603		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1279821617274603 | validation: 0.15741232438303085]
	TIME [epoch: 5.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15282503721336005		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.15282503721336005 | validation: 0.12718913557253636]
	TIME [epoch: 5.74 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133952508660617		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.10133952508660617 | validation: 0.10769376894559698]
	TIME [epoch: 5.74 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10511887233744908		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10511887233744908 | validation: 0.14997994281766996]
	TIME [epoch: 5.74 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421236513163854		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.11421236513163854 | validation: 0.11059804120926835]
	TIME [epoch: 5.74 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09862516120683033		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.09862516120683033 | validation: 0.11586179624855932]
	TIME [epoch: 5.77 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13797289842591923		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.13797289842591923 | validation: 0.20174550634524477]
	TIME [epoch: 5.74 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353629147471422		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.1353629147471422 | validation: 0.12000005400787746]
	TIME [epoch: 5.74 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11618779276779402		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.11618779276779402 | validation: 0.14825695496652022]
	TIME [epoch: 5.74 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252510763181076		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1252510763181076 | validation: 0.13620399738993733]
	TIME [epoch: 5.74 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12136236950427898		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.12136236950427898 | validation: 0.18303361404044105]
	TIME [epoch: 5.74 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12088267620925365		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.12088267620925365 | validation: 0.17616906254800424]
	TIME [epoch: 5.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13907128550860706		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.13907128550860706 | validation: 0.15080399365493782]
	TIME [epoch: 5.77 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316227938637758		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.12316227938637758 | validation: 0.1542285086040702]
	TIME [epoch: 5.74 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138009474938677		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.12138009474938677 | validation: 0.17319095908597398]
	TIME [epoch: 5.74 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16187960776245508		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.16187960776245508 | validation: 0.11382652496471835]
	TIME [epoch: 5.74 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10788210076683434		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.10788210076683434 | validation: 0.11431281598319787]
	TIME [epoch: 5.74 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19682795799387867		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.19682795799387867 | validation: 0.16062477107764955]
	TIME [epoch: 5.74 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13462707049631298		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.13462707049631298 | validation: 0.18909288860901213]
	TIME [epoch: 5.78 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17524595150514438		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.17524595150514438 | validation: 0.15469498080395144]
	TIME [epoch: 5.74 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11409322063615956		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.11409322063615956 | validation: 0.3319797543111238]
	TIME [epoch: 5.74 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20506559348945416		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.20506559348945416 | validation: 0.13465381946135016]
	TIME [epoch: 5.74 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12260319410238833		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.12260319410238833 | validation: 0.12270483550695155]
	TIME [epoch: 5.74 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089821894169036		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.10089821894169036 | validation: 0.12121629732508166]
	TIME [epoch: 5.74 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031238334382248		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.11031238334382248 | validation: 0.15466901891283738]
	TIME [epoch: 5.75 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354163454283231		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.11354163454283231 | validation: 0.16880982186448037]
	TIME [epoch: 5.77 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11980931184967852		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.11980931184967852 | validation: 0.12933033940362898]
	TIME [epoch: 5.74 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314808860781181		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1314808860781181 | validation: 0.1513920651280548]
	TIME [epoch: 5.74 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098164084968143		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.11098164084968143 | validation: 0.11944456078684533]
	TIME [epoch: 5.74 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11265955607735517		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.11265955607735517 | validation: 0.12483466910079656]
	TIME [epoch: 5.74 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817970958600505		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.12817970958600505 | validation: 0.11509372915932556]
	TIME [epoch: 5.74 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081544828703378		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1081544828703378 | validation: 0.14711723064685042]
	TIME [epoch: 5.78 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378405285100744		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.12378405285100744 | validation: 0.10803596363611995]
	TIME [epoch: 5.74 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12886607355089502		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.12886607355089502 | validation: 0.14487205395439406]
	TIME [epoch: 5.74 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11099967452529698		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.11099967452529698 | validation: 0.1287937363834146]
	TIME [epoch: 5.74 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110671459085377		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.1110671459085377 | validation: 0.27817410579903157]
	TIME [epoch: 5.74 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483227411353309		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.1483227411353309 | validation: 0.12249769436953514]
	TIME [epoch: 5.74 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11956759353817323		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.11956759353817323 | validation: 0.14637111396686336]
	TIME [epoch: 5.75 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274354458934846		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.1274354458934846 | validation: 0.15928380128177733]
	TIME [epoch: 5.77 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11678249779939509		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.11678249779939509 | validation: 0.12275104039853849]
	TIME [epoch: 5.74 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12216224223462009		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.12216224223462009 | validation: 0.1848301735198438]
	TIME [epoch: 5.74 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11574844932836459		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.11574844932836459 | validation: 0.12547371518434272]
	TIME [epoch: 5.74 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13871151644565882		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.13871151644565882 | validation: 0.1371096779684788]
	TIME [epoch: 5.74 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15311964761172117		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15311964761172117 | validation: 0.11788947952862469]
	TIME [epoch: 5.74 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523112169877333		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1523112169877333 | validation: 0.11126613365740433]
	TIME [epoch: 5.78 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027520548343862		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.09027520548343862 | validation: 0.09951330889755132]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872649012179642		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.09872649012179642 | validation: 0.12038541523329184]
	TIME [epoch: 5.74 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861487236227623		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.09861487236227623 | validation: 0.23979359168358336]
	TIME [epoch: 5.74 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13631556969786635		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.13631556969786635 | validation: 0.10646046667545943]
	TIME [epoch: 5.74 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09228362430385378		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.09228362430385378 | validation: 0.10903202339655488]
	TIME [epoch: 5.74 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10636761794152019		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.10636761794152019 | validation: 0.14622228826076605]
	TIME [epoch: 5.76 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11414152159759772		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.11414152159759772 | validation: 0.1390979299899166]
	TIME [epoch: 5.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034522223448437		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.11034522223448437 | validation: 0.13174527699652114]
	TIME [epoch: 5.74 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10691312448870868		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.10691312448870868 | validation: 0.1581995326707417]
	TIME [epoch: 5.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501748820823146		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.11501748820823146 | validation: 0.12678062606745047]
	TIME [epoch: 5.74 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449336345847585		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1449336345847585 | validation: 0.17811964613127035]
	TIME [epoch: 5.74 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388570623911049		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.1388570623911049 | validation: 0.11332136667645144]
	TIME [epoch: 5.74 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10720831509806542		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.10720831509806542 | validation: 0.10721039494523323]
	TIME [epoch: 5.78 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11644038166449633		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.11644038166449633 | validation: 0.11102891019014952]
	TIME [epoch: 5.74 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365585162906353		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1365585162906353 | validation: 0.1504033383333445]
	TIME [epoch: 5.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11132364692981248		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.11132364692981248 | validation: 0.10777225645868745]
	TIME [epoch: 5.74 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339211940544988		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.14339211940544988 | validation: 0.12357497851892348]
	TIME [epoch: 5.74 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10118779819691034		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.10118779819691034 | validation: 0.12029912060770598]
	TIME [epoch: 5.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613615249514037		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.12613615249514037 | validation: 0.1576435282863353]
	TIME [epoch: 5.76 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285570249092366		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.1285570249092366 | validation: 0.14541347954626876]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448703891106499		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.1448703891106499 | validation: 0.1156124630482603]
	TIME [epoch: 5.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14689846191776032		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.14689846191776032 | validation: 0.11192859682727761]
	TIME [epoch: 5.74 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10147852855161542		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10147852855161542 | validation: 0.13043104514112502]
	TIME [epoch: 5.74 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078331418909808		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.11078331418909808 | validation: 0.12015298707310784]
	TIME [epoch: 5.74 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09154004765991121		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.09154004765991121 | validation: 0.126792803898316]
	TIME [epoch: 5.74 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338505911741551		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.10338505911741551 | validation: 0.10532739639834596]
	TIME [epoch: 5.78 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062726412650326		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.10062726412650326 | validation: 0.12260689142099601]
	TIME [epoch: 5.74 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09651221043061817		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.09651221043061817 | validation: 0.13421619496111306]
	TIME [epoch: 5.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727507744245576		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.10727507744245576 | validation: 0.12178195178586106]
	TIME [epoch: 5.74 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041411591382866		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.10041411591382866 | validation: 0.10797413536727395]
	TIME [epoch: 5.74 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438069502542395		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.10438069502542395 | validation: 0.11489845485439425]
	TIME [epoch: 5.74 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897933135719943		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09897933135719943 | validation: 0.12676506314306246]
	TIME [epoch: 5.76 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573936091589284		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.10573936091589284 | validation: 0.11156140000986367]
	TIME [epoch: 5.75 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10615737826836555		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.10615737826836555 | validation: 0.13182843582120218]
	TIME [epoch: 5.74 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934736352778253		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.10934736352778253 | validation: 0.12351192803709282]
	TIME [epoch: 5.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09831640961369281		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.09831640961369281 | validation: 0.1108896223298899]
	TIME [epoch: 5.74 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244910884715884		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11244910884715884 | validation: 0.1385342112061557]
	TIME [epoch: 5.74 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613329267977186		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.12613329267977186 | validation: 0.1433813308829634]
	TIME [epoch: 5.74 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09907422524638387		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.09907422524638387 | validation: 0.1173398024221425]
	TIME [epoch: 5.77 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866312765564978		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.10866312765564978 | validation: 0.1261749795118996]
	TIME [epoch: 5.74 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09383754859575105		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09383754859575105 | validation: 0.1623188558553467]
	TIME [epoch: 5.74 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11430447933763274		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.11430447933763274 | validation: 0.09340700123431188]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09123432007930543		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.09123432007930543 | validation: 0.1321670484315796]
	TIME [epoch: 5.74 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13192532941802027		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.13192532941802027 | validation: 0.1027279300528313]
	TIME [epoch: 5.74 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10645794439416038		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.10645794439416038 | validation: 0.11400961767925345]
	TIME [epoch: 5.76 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09776626637802362		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.09776626637802362 | validation: 0.13191582099910773]
	TIME [epoch: 5.75 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12690954884000255		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12690954884000255 | validation: 0.1407705616950212]
	TIME [epoch: 5.74 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10085796073198824		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.10085796073198824 | validation: 0.1558615462580492]
	TIME [epoch: 5.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225347817257118		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1225347817257118 | validation: 0.1497309603232471]
	TIME [epoch: 5.74 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12014312274875388		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.12014312274875388 | validation: 0.10720396740069488]
	TIME [epoch: 5.74 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227737408651513		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.10227737408651513 | validation: 0.12406561309639556]
	TIME [epoch: 5.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0951313389966196		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.0951313389966196 | validation: 0.11313694058256786]
	TIME [epoch: 5.78 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12266381210836699		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.12266381210836699 | validation: 0.11919877454527093]
	TIME [epoch: 5.74 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375192321379325		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.09375192321379325 | validation: 0.1415650683578179]
	TIME [epoch: 5.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255298031610441		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10255298031610441 | validation: 0.11782664195307557]
	TIME [epoch: 5.74 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08942802285149053		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.08942802285149053 | validation: 0.11133369781142664]
	TIME [epoch: 5.74 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924944079684642		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.08924944079684642 | validation: 0.16012405763665122]
	TIME [epoch: 5.74 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10836493107535203		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.10836493107535203 | validation: 0.1382046644855617]
	TIME [epoch: 5.77 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861848608296503		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.09861848608296503 | validation: 0.1567054422496669]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505386915059843		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1505386915059843 | validation: 0.11712220731742626]
	TIME [epoch: 5.74 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498411953746455		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.1498411953746455 | validation: 0.1568250854032866]
	TIME [epoch: 5.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09372034596820536		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.09372034596820536 | validation: 0.12128266714562645]
	TIME [epoch: 5.74 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09366095926474874		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09366095926474874 | validation: 0.12345333036647768]
	TIME [epoch: 5.74 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017692549965784		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.10017692549965784 | validation: 0.11583650748691693]
	TIME [epoch: 5.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530920995672508		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11530920995672508 | validation: 0.16255669920664367]
	TIME [epoch: 5.77 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834262215852684		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.10834262215852684 | validation: 0.11629832738430095]
	TIME [epoch: 5.74 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502417304526004		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.09502417304526004 | validation: 0.12661057903929784]
	TIME [epoch: 5.74 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10917890146395788		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.10917890146395788 | validation: 0.1372450144213312]
	TIME [epoch: 5.74 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10818626301299653		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.10818626301299653 | validation: 0.10138728753078528]
	TIME [epoch: 5.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09430486978373476		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.09430486978373476 | validation: 0.1511890035880746]
	TIME [epoch: 5.74 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987900583540997		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.0987900583540997 | validation: 0.13429842685397836]
	TIME [epoch: 5.77 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10009800345693261		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.10009800345693261 | validation: 0.10035059957918208]
	TIME [epoch: 5.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09863975772043762		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.09863975772043762 | validation: 0.12556088084968808]
	TIME [epoch: 5.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0935345929429418		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0935345929429418 | validation: 0.1112284212580084]
	TIME [epoch: 5.74 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.095000436614345		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.095000436614345 | validation: 0.1850708302526337]
	TIME [epoch: 5.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799731501284657		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.13799731501284657 | validation: 0.16066028564333265]
	TIME [epoch: 5.74 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861579639216609		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.10861579639216609 | validation: 0.12096997806131529]
	TIME [epoch: 5.74 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124606501763032		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.09124606501763032 | validation: 0.11680108430828127]
	TIME [epoch: 5.77 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590147391841416		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.08590147391841416 | validation: 0.10910018384828699]
	TIME [epoch: 5.74 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307616383933894		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1307616383933894 | validation: 0.11077168997609241]
	TIME [epoch: 5.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08852711817110355		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.08852711817110355 | validation: 0.11270762414384543]
	TIME [epoch: 5.74 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109938327162937		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.10109938327162937 | validation: 0.13933130419141063]
	TIME [epoch: 5.74 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772624200192184		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.09772624200192184 | validation: 0.11329791858531944]
	TIME [epoch: 5.74 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417517157064754		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.08417517157064754 | validation: 0.11192575271018328]
	TIME [epoch: 5.77 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198560912091992		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.10198560912091992 | validation: 0.1206544177492066]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125874849710955		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.09125874849710955 | validation: 0.11446702226929677]
	TIME [epoch: 5.74 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11062178737300866		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.11062178737300866 | validation: 0.1112266933651399]
	TIME [epoch: 5.74 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11275886887524149		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11275886887524149 | validation: 0.10514126996196314]
	TIME [epoch: 5.74 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08754056008101205		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.08754056008101205 | validation: 0.12717297099371436]
	TIME [epoch: 5.74 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09210032404748089		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.09210032404748089 | validation: 0.11209595514335596]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994371452226258		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.09994371452226258 | validation: 0.12054165982420804]
	TIME [epoch: 5.76 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09333914850962205		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.09333914850962205 | validation: 0.10542530302586191]
	TIME [epoch: 5.74 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09101133894050534		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.09101133894050534 | validation: 0.12472658173813876]
	TIME [epoch: 5.74 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690905077251435		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.10690905077251435 | validation: 0.11814625520833331]
	TIME [epoch: 5.74 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640086726153594		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.10640086726153594 | validation: 0.14100766407899648]
	TIME [epoch: 5.73 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791653889021845		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.10791653889021845 | validation: 0.13667493700568312]
	TIME [epoch: 5.74 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08414520539448253		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.08414520539448253 | validation: 0.12136725670362639]
	TIME [epoch: 5.77 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10932673516495484		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.10932673516495484 | validation: 0.1062020699885748]
	TIME [epoch: 5.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312956554696825		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.09312956554696825 | validation: 0.10755786982963397]
	TIME [epoch: 5.74 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345301413681109		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.10345301413681109 | validation: 0.10624539526938229]
	TIME [epoch: 5.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09848423399288973		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.09848423399288973 | validation: 0.09921709749863766]
	TIME [epoch: 5.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563738682084271		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.08563738682084271 | validation: 0.11764880461323805]
	TIME [epoch: 5.73 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851646414650176		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.08851646414650176 | validation: 0.17774177958189838]
	TIME [epoch: 5.75 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342728184692785		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.1342728184692785 | validation: 0.10554579332192451]
	TIME [epoch: 5.76 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941991344537295		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0941991344537295 | validation: 0.0849890724681837]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880554117988542		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.07880554117988542 | validation: 0.0983994426438742]
	TIME [epoch: 5.73 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10096812562278079		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10096812562278079 | validation: 0.1233640988330472]
	TIME [epoch: 5.73 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0901919978994153		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.0901919978994153 | validation: 0.09408597834530649]
	TIME [epoch: 5.73 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386417888211686		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.09386417888211686 | validation: 0.12852481833994342]
	TIME [epoch: 5.73 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10646432477559117		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.10646432477559117 | validation: 0.12116981836860344]
	TIME [epoch: 5.77 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10028407045933913		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.10028407045933913 | validation: 0.1020334941780774]
	TIME [epoch: 5.73 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08554643476537886		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08554643476537886 | validation: 0.11330197915915971]
	TIME [epoch: 5.73 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09437613386213715		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.09437613386213715 | validation: 0.12715815257526608]
	TIME [epoch: 5.73 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310542217092686		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.10310542217092686 | validation: 0.20268371099145438]
	TIME [epoch: 5.73 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145982613296957		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2145982613296957 | validation: 0.150342878423421]
	TIME [epoch: 5.73 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11792771850124152		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.11792771850124152 | validation: 0.11417254193897719]
	TIME [epoch: 5.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294125933484461		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08294125933484461 | validation: 0.08883181581003793]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259405365271112		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08259405365271112 | validation: 0.125235692894962]
	TIME [epoch: 5.73 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10501884146243348		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.10501884146243348 | validation: 0.10352270431890659]
	TIME [epoch: 5.73 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0889386007537789		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0889386007537789 | validation: 0.11379540742855582]
	TIME [epoch: 5.73 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475922183277504		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.08475922183277504 | validation: 0.11758216799378705]
	TIME [epoch: 5.72 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985739358938935		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09985739358938935 | validation: 0.10879138996935268]
	TIME [epoch: 5.73 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056826466474788		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.09056826466474788 | validation: 0.09763118652431263]
	TIME [epoch: 5.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09487324358744487		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.09487324358744487 | validation: 0.13358216693860211]
	TIME [epoch: 5.73 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09164695013372084		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.09164695013372084 | validation: 0.1117954137721548]
	TIME [epoch: 5.72 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653078772322043		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.09653078772322043 | validation: 0.10627247143344003]
	TIME [epoch: 5.73 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08616726005598378		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.08616726005598378 | validation: 0.1109812255830864]
	TIME [epoch: 5.72 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697038826824098		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.10697038826824098 | validation: 0.14171015148100982]
	TIME [epoch: 5.72 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132381816407584		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.132381816407584 | validation: 0.11692867422949248]
	TIME [epoch: 5.73 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108553666877522		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.10108553666877522 | validation: 0.10451932545338266]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09068792334813958		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09068792334813958 | validation: 0.18616150527054548]
	TIME [epoch: 5.73 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12387565780085573		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.12387565780085573 | validation: 0.10289063159893902]
	TIME [epoch: 5.73 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596819781843737		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.08596819781843737 | validation: 0.11174335354706141]
	TIME [epoch: 5.72 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841223602283965		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.08841223602283965 | validation: 0.09390607365420472]
	TIME [epoch: 5.73 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715600905221986		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.11715600905221986 | validation: 0.11930853778468724]
	TIME [epoch: 5.72 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10958252074814646		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.10958252074814646 | validation: 0.1173874188530668]
	TIME [epoch: 5.76 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09876813869636325		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.09876813869636325 | validation: 0.16554796950141193]
	TIME [epoch: 5.72 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357475308108506		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.10357475308108506 | validation: 0.1065891711792119]
	TIME [epoch: 5.73 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0850411804828031		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0850411804828031 | validation: 0.15490803395762728]
	TIME [epoch: 5.73 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942676108145195		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.10942676108145195 | validation: 0.12284676597202591]
	TIME [epoch: 5.73 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0946801217616319		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.0946801217616319 | validation: 0.10773607542312004]
	TIME [epoch: 5.73 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0862168310116109		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.0862168310116109 | validation: 0.11824656277804721]
	TIME [epoch: 5.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944908550962057		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0944908550962057 | validation: 0.09758842209064188]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08647777715988192		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.08647777715988192 | validation: 0.10860797243126377]
	TIME [epoch: 5.73 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153351657396594		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08153351657396594 | validation: 0.10342379908926576]
	TIME [epoch: 5.73 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700869625063158		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.09700869625063158 | validation: 0.10932606780239437]
	TIME [epoch: 5.72 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576732358427189		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.08576732358427189 | validation: 0.10017855267091286]
	TIME [epoch: 5.73 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155950453376629		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.08155950453376629 | validation: 0.11936754887110002]
	TIME [epoch: 5.72 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08559461791985637		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08559461791985637 | validation: 0.10226995751001262]
	TIME [epoch: 5.76 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08242509546213574		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.08242509546213574 | validation: 0.11070725429279651]
	TIME [epoch: 5.72 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944854468891127		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0944854468891127 | validation: 0.12439580673832133]
	TIME [epoch: 5.72 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09234614243543812		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.09234614243543812 | validation: 0.160518479002739]
	TIME [epoch: 5.72 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13305374363461442		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.13305374363461442 | validation: 0.11397522231996975]
	TIME [epoch: 5.73 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650070055560266		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.08650070055560266 | validation: 0.10827276478295642]
	TIME [epoch: 5.73 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962306644740505		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.07962306644740505 | validation: 0.09737948467246561]
	TIME [epoch: 5.73 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09253816148093498		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.09253816148093498 | validation: 0.10485015549667827]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09585093106110604		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.09585093106110604 | validation: 0.10012645137070095]
	TIME [epoch: 5.73 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0854217709440595		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.0854217709440595 | validation: 0.10317839441775534]
	TIME [epoch: 5.72 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531514767865722		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.08531514767865722 | validation: 0.10500817243946778]
	TIME [epoch: 5.73 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08938373181661047		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08938373181661047 | validation: 0.11438442700425171]
	TIME [epoch: 5.72 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513933547259734		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.09513933547259734 | validation: 0.1353549679536577]
	TIME [epoch: 5.72 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004648235493249		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.11004648235493249 | validation: 0.11123509000555803]
	TIME [epoch: 5.78 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309106244095556		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.08309106244095556 | validation: 0.09662367239656067]
	TIME [epoch: 5.73 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718628688814976		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.09718628688814976 | validation: 0.10608169428657532]
	TIME [epoch: 5.73 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340518178313869		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.08340518178313869 | validation: 0.13265350257672026]
	TIME [epoch: 5.72 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738008926160326		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.08738008926160326 | validation: 0.12895954770068532]
	TIME [epoch: 5.74 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772866867265659		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.09772866867265659 | validation: 0.1149551450301118]
	TIME [epoch: 5.72 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09029352326732715		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09029352326732715 | validation: 0.10702728029880273]
	TIME [epoch: 5.73 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08861679229192278		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.08861679229192278 | validation: 0.12026725523209315]
	TIME [epoch: 5.76 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09064105607059768		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09064105607059768 | validation: 0.10621602730558982]
	TIME [epoch: 5.74 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842502209352195		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.07842502209352195 | validation: 0.09635827433789135]
	TIME [epoch: 5.72 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049343835968428		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.09049343835968428 | validation: 0.11774127693231437]
	TIME [epoch: 5.72 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08427677320808953		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08427677320808953 | validation: 0.1094810970212302]
	TIME [epoch: 5.74 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137859600772801		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.08137859600772801 | validation: 0.10116897855551846]
	TIME [epoch: 5.73 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305740675732817		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08305740675732817 | validation: 0.11020080624781098]
	TIME [epoch: 5.77 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477436472610566		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.12477436472610566 | validation: 0.14956058083445756]
	TIME [epoch: 5.73 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10779154664731361		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.10779154664731361 | validation: 0.09453759282694414]
	TIME [epoch: 5.73 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760017031446733		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.0760017031446733 | validation: 0.09972549570431234]
	TIME [epoch: 5.74 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09567582468179546		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.09567582468179546 | validation: 0.09877036806001353]
	TIME [epoch: 5.72 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031734056801227		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09031734056801227 | validation: 0.09648772878975109]
	TIME [epoch: 5.73 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085414956790066		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.08085414956790066 | validation: 0.09235187029887214]
	TIME [epoch: 5.74 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792552467201336		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0792552467201336 | validation: 0.0874003749697397]
	TIME [epoch: 5.76 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08292388016409731		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.08292388016409731 | validation: 0.10145443453858956]
	TIME [epoch: 5.73 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782802099130476		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.0782802099130476 | validation: 0.09673893039756731]
	TIME [epoch: 5.72 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130839843096346		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.08130839843096346 | validation: 0.0976057588053364]
	TIME [epoch: 5.73 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883122108444204		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.07883122108444204 | validation: 0.08813207119963033]
	TIME [epoch: 5.72 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07877165176666467		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.07877165176666467 | validation: 0.14326138202703115]
	TIME [epoch: 5.73 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11185676599158419		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.11185676599158419 | validation: 0.09836028524054335]
	TIME [epoch: 5.76 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08290336672117532		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.08290336672117532 | validation: 0.09696266660294539]
	TIME [epoch: 5.73 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0757128660475947		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0757128660475947 | validation: 0.0952888911560283]
	TIME [epoch: 5.72 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07380803404964897		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.07380803404964897 | validation: 0.10326246740914226]
	TIME [epoch: 5.73 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07068335396343399		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07068335396343399 | validation: 0.09690073928815933]
	TIME [epoch: 5.72 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936886001651254		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0936886001651254 | validation: 0.1416126025060739]
	TIME [epoch: 5.73 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000405607607017		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1000405607607017 | validation: 0.15594512252898143]
	TIME [epoch: 5.74 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464290298573967		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.13464290298573967 | validation: 0.09703734742377115]
	TIME [epoch: 5.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945308394003292		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.07945308394003292 | validation: 0.08598904859569526]
	TIME [epoch: 5.73 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08241030907644983		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.08241030907644983 | validation: 0.11022894519426187]
	TIME [epoch: 5.72 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902944656609862		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08902944656609862 | validation: 0.11268442324992244]
	TIME [epoch: 5.73 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0914374053793711		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0914374053793711 | validation: 0.1215196858930331]
	TIME [epoch: 5.73 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08464063869034982		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.08464063869034982 | validation: 0.0996549840241891]
	TIME [epoch: 5.74 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08094157311047843		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.08094157311047843 | validation: 0.12895621412780384]
	TIME [epoch: 5.77 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089587684090205		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.089587684090205 | validation: 0.12562338397961922]
	TIME [epoch: 5.73 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08044489919195003		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.08044489919195003 | validation: 0.0966650469569416]
	TIME [epoch: 5.72 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611550432945508		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.08611550432945508 | validation: 0.10916283572627009]
	TIME [epoch: 5.72 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238946324437023		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.10238946324437023 | validation: 0.15000865576591196]
	TIME [epoch: 5.74 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10790380580906991		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.10790380580906991 | validation: 0.12878297888302342]
	TIME [epoch: 5.72 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286204341789949		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1286204341789949 | validation: 0.10521039190392173]
	TIME [epoch: 5.74 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0871336026126155		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.0871336026126155 | validation: 0.10820259495108109]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013556591441244		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08013556591441244 | validation: 0.1142099805586979]
	TIME [epoch: 5.73 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08367046249289203		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.08367046249289203 | validation: 0.13571467970707485]
	TIME [epoch: 5.73 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09147352579872464		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.09147352579872464 | validation: 0.10911803119839764]
	TIME [epoch: 5.73 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07977440923844244		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.07977440923844244 | validation: 0.10169754657008717]
	TIME [epoch: 5.74 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950398333095718		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.07950398333095718 | validation: 0.10973119446465956]
	TIME [epoch: 5.72 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254552514275121		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.08254552514275121 | validation: 0.12597804019716283]
	TIME [epoch: 5.77 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09070413836127544		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09070413836127544 | validation: 0.10737582086133601]
	TIME [epoch: 5.73 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09291850435692131		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.09291850435692131 | validation: 0.1257402085117421]
	TIME [epoch: 5.73 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08002172667038149		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.08002172667038149 | validation: 0.09306266342365714]
	TIME [epoch: 5.74 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370363537191207		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.1370363537191207 | validation: 0.10146460025029186]
	TIME [epoch: 5.73 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08219721850158188		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.08219721850158188 | validation: 0.11799933105768777]
	TIME [epoch: 5.73 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08640216925444769		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08640216925444769 | validation: 0.11231031728155656]
	TIME [epoch: 5.74 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755701618410477		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.07755701618410477 | validation: 0.09830247836068502]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14062846559080738		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.14062846559080738 | validation: 0.13391081334228275]
	TIME [epoch: 5.74 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980616958753017		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08980616958753017 | validation: 0.11843652490175002]
	TIME [epoch: 5.73 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09604179245931907		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.09604179245931907 | validation: 0.08947754898799559]
	TIME [epoch: 5.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10812332994931768		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.10812332994931768 | validation: 0.10551709470633473]
	TIME [epoch: 5.72 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646558668367324		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.08646558668367324 | validation: 0.10058204962171342]
	TIME [epoch: 5.73 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08103633843386743		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.08103633843386743 | validation: 0.10450761511364551]
	TIME [epoch: 5.78 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07910743105528013		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.07910743105528013 | validation: 0.09235838611290703]
	TIME [epoch: 5.74 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08402367342384101		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.08402367342384101 | validation: 0.0960504722118548]
	TIME [epoch: 5.73 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831061297013969		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08831061297013969 | validation: 0.11011149806619025]
	TIME [epoch: 5.73 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076504855958529		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.076504855958529 | validation: 0.09148343308841589]
	TIME [epoch: 5.74 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07770149410619943		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.07770149410619943 | validation: 0.11517279962390226]
	TIME [epoch: 5.73 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002612952521536		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.1002612952521536 | validation: 0.10480119427299023]
	TIME [epoch: 5.74 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08170462008199662		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.08170462008199662 | validation: 0.1097568148841622]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678976467215009		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.08678976467215009 | validation: 0.14937346999680656]
	TIME [epoch: 5.73 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09370009477991487		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.09370009477991487 | validation: 0.10135019984543657]
	TIME [epoch: 5.73 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07716562770543499		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.07716562770543499 | validation: 0.11219101191012369]
	TIME [epoch: 5.73 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761026176806989		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0761026176806989 | validation: 0.08762263866933856]
	TIME [epoch: 5.74 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07674874986539523		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.07674874986539523 | validation: 0.09016696777092649]
	TIME [epoch: 5.73 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294536969921428		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.07294536969921428 | validation: 0.1008006515766688]
	TIME [epoch: 5.77 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.112198973723088		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.112198973723088 | validation: 0.09882717285164716]
	TIME [epoch: 5.74 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894518583058124		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0894518583058124 | validation: 0.09829750682066343]
	TIME [epoch: 5.72 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298695638636693		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.07298695638636693 | validation: 0.10505125912533]
	TIME [epoch: 5.73 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989841683872845		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.07989841683872845 | validation: 0.09105795153561999]
	TIME [epoch: 5.74 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811217253075639		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.07811217253075639 | validation: 0.10786460529056885]
	TIME [epoch: 5.74 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07341689705772786		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.07341689705772786 | validation: 0.11160282244033447]
	TIME [epoch: 5.75 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515981738216714		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.09515981738216714 | validation: 0.0956355641154046]
	TIME [epoch: 5.77 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07887660121277155		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.07887660121277155 | validation: 0.1045144881594343]
	TIME [epoch: 5.74 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294122749251859		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.08294122749251859 | validation: 0.1056460118111906]
	TIME [epoch: 5.74 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07314946749905273		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.07314946749905273 | validation: 0.08398832025675237]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_995.pth
	Model improved!!!
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641525839650085		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.07641525839650085 | validation: 0.08393917302952562]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_996.pth
	Model improved!!!
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892498758177582		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.07892498758177582 | validation: 0.10225640530242043]
	TIME [epoch: 5.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858030549192879		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.08858030549192879 | validation: 0.0908125233443901]
	TIME [epoch: 5.78 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054964600343831		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.08054964600343831 | validation: 0.1064433939282587]
	TIME [epoch: 5.74 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09748972211407103		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.09748972211407103 | validation: 0.1363547679806774]
	TIME [epoch: 5.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09139963180693109		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.09139963180693109 | validation: 0.08943852770421584]
	TIME [epoch: 5.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.082358145340799		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.082358145340799 | validation: 0.09126925047939011]
	TIME [epoch: 5.73 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07525454380150365		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.07525454380150365 | validation: 0.15742533641293388]
	TIME [epoch: 5.73 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231210374568898		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.11231210374568898 | validation: 0.1250264864220183]
	TIME [epoch: 5.76 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384179353028087		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.08384179353028087 | validation: 0.10889219960566196]
	TIME [epoch: 5.75 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684405091262032		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.08684405091262032 | validation: 0.10537703830841479]
	TIME [epoch: 5.74 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07800147486311743		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.07800147486311743 | validation: 0.11165798563764287]
	TIME [epoch: 5.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08992179145626357		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.08992179145626357 | validation: 0.1004982826620845]
	TIME [epoch: 5.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07972959155499802		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.07972959155499802 | validation: 0.10557011784645531]
	TIME [epoch: 5.74 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837548082808021		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0837548082808021 | validation: 0.13676367541491316]
	TIME [epoch: 5.74 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09338927278114265		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.09338927278114265 | validation: 0.11178727487374655]
	TIME [epoch: 5.77 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08194908201876032		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.08194908201876032 | validation: 0.10188677308163561]
	TIME [epoch: 5.74 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973341544250252		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.07973341544250252 | validation: 0.09436735357409727]
	TIME [epoch: 5.74 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07953014706608541		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.07953014706608541 | validation: 0.09913996371379927]
	TIME [epoch: 5.74 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947080458121054		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0947080458121054 | validation: 0.11448288013474058]
	TIME [epoch: 5.74 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809419413927781		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0809419413927781 | validation: 0.11940836976594467]
	TIME [epoch: 5.74 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08873648296994774		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.08873648296994774 | validation: 0.113911692480362]
	TIME [epoch: 5.76 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07389328497241394		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.07389328497241394 | validation: 0.08828501836646409]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09013284193313252		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.09013284193313252 | validation: 0.11478569253533104]
	TIME [epoch: 5.74 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08776053150164229		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.08776053150164229 | validation: 0.10162814323359748]
	TIME [epoch: 5.74 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08396236584794527		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.08396236584794527 | validation: 0.12950452309029464]
	TIME [epoch: 5.74 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822348282709533		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.0822348282709533 | validation: 0.10341499977457462]
	TIME [epoch: 5.74 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797094560848722		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.0797094560848722 | validation: 0.10202819801673053]
	TIME [epoch: 5.74 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07371315576760432		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.07371315576760432 | validation: 0.08106031677494129]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1024.pth
	Model improved!!!
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555185878090411		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08555185878090411 | validation: 0.11266695934808453]
	TIME [epoch: 5.74 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209192137457845		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.08209192137457845 | validation: 0.11839157562204498]
	TIME [epoch: 5.74 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09099105662192537		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.09099105662192537 | validation: 0.11760736167068535]
	TIME [epoch: 5.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08178671324982557		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08178671324982557 | validation: 0.10183267193937022]
	TIME [epoch: 5.73 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563669048636386		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07563669048636386 | validation: 0.08807331956226584]
	TIME [epoch: 5.74 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169132780083025		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07169132780083025 | validation: 0.09426253162656956]
	TIME [epoch: 5.77 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07349556649060518		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.07349556649060518 | validation: 0.11150178529310058]
	TIME [epoch: 5.74 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936515345561058		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.0936515345561058 | validation: 0.09178248399671322]
	TIME [epoch: 5.74 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11706414831470682		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11706414831470682 | validation: 0.12399177957375375]
	TIME [epoch: 5.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08775174990921847		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.08775174990921847 | validation: 0.10024176772144187]
	TIME [epoch: 5.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10001331275329547		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.10001331275329547 | validation: 0.12679649287452696]
	TIME [epoch: 5.74 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867223113810864		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.07867223113810864 | validation: 0.09145090456076084]
	TIME [epoch: 5.74 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07682963795888167		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.07682963795888167 | validation: 0.10772382375488868]
	TIME [epoch: 5.76 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07155772242764877		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.07155772242764877 | validation: 0.09726598659088026]
	TIME [epoch: 5.74 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07581633371516384		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.07581633371516384 | validation: 0.0811527183527257]
	TIME [epoch: 5.74 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07620497267696745		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.07620497267696745 | validation: 0.11095751974638507]
	TIME [epoch: 5.74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764371053314514		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0764371053314514 | validation: 0.09932629800951999]
	TIME [epoch: 5.74 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07212319317102615		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.07212319317102615 | validation: 0.10319316465281066]
	TIME [epoch: 5.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08074347791451444		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.08074347791451444 | validation: 0.09209228112932749]
	TIME [epoch: 5.77 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080002118352343		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.080002118352343 | validation: 0.11607264502726569]
	TIME [epoch: 5.74 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07953070295776576		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.07953070295776576 | validation: 0.10629385921287546]
	TIME [epoch: 5.74 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772077767648076		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0772077767648076 | validation: 0.09694807479139578]
	TIME [epoch: 5.73 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872333889378753		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07872333889378753 | validation: 0.10967166784064546]
	TIME [epoch: 5.74 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477474297240433		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07477474297240433 | validation: 0.0919735378735264]
	TIME [epoch: 5.73 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0722605386186721		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0722605386186721 | validation: 0.10733800355075199]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0762423491825655		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0762423491825655 | validation: 0.10306953254402046]
	TIME [epoch: 5.76 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07041370906874317		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.07041370906874317 | validation: 0.09520629130070293]
	TIME [epoch: 5.74 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642100300397821		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.07642100300397821 | validation: 0.10268039087032232]
	TIME [epoch: 5.73 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944161215724814		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06944161215724814 | validation: 0.0977228088377156]
	TIME [epoch: 5.73 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856179213147489		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.0856179213147489 | validation: 0.09363983480024626]
	TIME [epoch: 5.73 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07320255285574608		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.07320255285574608 | validation: 0.0977153851635161]
	TIME [epoch: 5.74 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030381983975204		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.08030381983975204 | validation: 0.10546404520134829]
	TIME [epoch: 5.77 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521241516363585		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.07521241516363585 | validation: 0.11848866360150691]
	TIME [epoch: 5.74 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574585609693255		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.07574585609693255 | validation: 0.10626412054756561]
	TIME [epoch: 5.74 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098990605827205		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.08098990605827205 | validation: 0.10255550824635075]
	TIME [epoch: 5.73 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802826749834081		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.07802826749834081 | validation: 0.10098658692167232]
	TIME [epoch: 5.73 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452910879081635		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.07452910879081635 | validation: 0.10551772447189225]
	TIME [epoch: 5.73 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083023613725586		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.083023613725586 | validation: 0.10394616892403921]
	TIME [epoch: 5.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593634583292908		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.07593634583292908 | validation: 0.09327480472614068]
	TIME [epoch: 5.76 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08076423765552954		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.08076423765552954 | validation: 0.08967758784107048]
	TIME [epoch: 5.74 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08271110163832737		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.08271110163832737 | validation: 0.10159896364476953]
	TIME [epoch: 5.74 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07965715896214388		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.07965715896214388 | validation: 0.128983620663962]
	TIME [epoch: 5.74 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.086085309014822		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.086085309014822 | validation: 0.10118619974103296]
	TIME [epoch: 5.74 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07991330100672792		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.07991330100672792 | validation: 0.09317624695780684]
	TIME [epoch: 5.74 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833488326959259		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0833488326959259 | validation: 0.11424698392250653]
	TIME [epoch: 5.77 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08418449697164732		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08418449697164732 | validation: 0.0933143223321426]
	TIME [epoch: 5.74 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0594570639514727		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0594570639514727 | validation: 0.09128302283621441]
	TIME [epoch: 5.74 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06866462120652735		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.06866462120652735 | validation: 0.1024688055378025]
	TIME [epoch: 5.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0697485294682045		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.0697485294682045 | validation: 0.09724052061595458]
	TIME [epoch: 5.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701106281007469		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07701106281007469 | validation: 0.1002291912036184]
	TIME [epoch: 5.74 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07066375011153708		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.07066375011153708 | validation: 0.10521430353197139]
	TIME [epoch: 5.75 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759143135334579		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.07759143135334579 | validation: 0.10240901914188115]
	TIME [epoch: 5.76 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07287020651601889		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07287020651601889 | validation: 0.09146123301114244]
	TIME [epoch: 5.74 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468998961954573		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.07468998961954573 | validation: 0.10507534754097136]
	TIME [epoch: 5.74 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07382025520475095		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07382025520475095 | validation: 0.10447352273758799]
	TIME [epoch: 5.74 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07278696645105559		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.07278696645105559 | validation: 0.097633097264203]
	TIME [epoch: 5.73 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647606172340286		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.0647606172340286 | validation: 0.1024361945131109]
	TIME [epoch: 5.74 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740773012933979		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.0740773012933979 | validation: 0.10300551219027929]
	TIME [epoch: 5.77 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09162814648634768		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.09162814648634768 | validation: 0.09074826481225527]
	TIME [epoch: 5.74 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07198435287033984		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.07198435287033984 | validation: 0.08168619258472239]
	TIME [epoch: 5.74 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07552399787631787		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07552399787631787 | validation: 0.09790493075819527]
	TIME [epoch: 5.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07445043463414283		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.07445043463414283 | validation: 0.09226514192684983]
	TIME [epoch: 5.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686028430225202		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0686028430225202 | validation: 0.10191408607040824]
	TIME [epoch: 5.74 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418988071944063		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.07418988071944063 | validation: 0.09577613654762819]
	TIME [epoch: 5.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07776778554134252		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.07776778554134252 | validation: 0.097366499619841]
	TIME [epoch: 5.76 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07248778454697558		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.07248778454697558 | validation: 0.08793106257572472]
	TIME [epoch: 5.74 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07369027261542971		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.07369027261542971 | validation: 0.09232130340039944]
	TIME [epoch: 5.74 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06919250313126156		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.06919250313126156 | validation: 0.08997352884233832]
	TIME [epoch: 5.73 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07611083209001758		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.07611083209001758 | validation: 0.0932904239439804]
	TIME [epoch: 5.73 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081031339495113		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07081031339495113 | validation: 0.1094264217487985]
	TIME [epoch: 5.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323681154093906		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.07323681154093906 | validation: 0.11037857031023261]
	TIME [epoch: 5.77 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08237277301435574		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.08237277301435574 | validation: 0.11646405811514587]
	TIME [epoch: 5.74 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021224438941536		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.09021224438941536 | validation: 0.0866769589067981]
	TIME [epoch: 5.73 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771031143397786		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.0771031143397786 | validation: 0.10992991066707088]
	TIME [epoch: 5.73 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08866831223807434		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.08866831223807434 | validation: 0.10722615383065279]
	TIME [epoch: 5.74 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07100538650392534		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.07100538650392534 | validation: 0.1130987615280073]
	TIME [epoch: 5.73 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08648304181292209		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.08648304181292209 | validation: 0.12238521755357602]
	TIME [epoch: 5.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07715879102989166		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.07715879102989166 | validation: 0.10153101193637873]
	TIME [epoch: 5.76 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06489012419052394		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.06489012419052394 | validation: 0.0834713576025916]
	TIME [epoch: 5.74 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472763674825506		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.06472763674825506 | validation: 0.09869644414195633]
	TIME [epoch: 5.74 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08587969149265061		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.08587969149265061 | validation: 0.114022040543225]
	TIME [epoch: 5.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873591745374707		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0873591745374707 | validation: 0.11786105481908851]
	TIME [epoch: 5.74 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10694522875716536		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.10694522875716536 | validation: 0.11763020279915544]
	TIME [epoch: 5.74 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902644641208334		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.07902644641208334 | validation: 0.08699634571369645]
	TIME [epoch: 5.77 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392094947968536		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.07392094947968536 | validation: 0.1068489845555407]
	TIME [epoch: 5.74 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448038282229061		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.07448038282229061 | validation: 0.08750874974005943]
	TIME [epoch: 5.74 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816031285940266		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.06816031285940266 | validation: 0.09154012413233478]
	TIME [epoch: 5.74 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06532278964240026		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.06532278964240026 | validation: 0.10308400060789896]
	TIME [epoch: 5.73 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691589731758712		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0691589731758712 | validation: 0.08774232048484767]
	TIME [epoch: 5.74 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750282830954779		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.0750282830954779 | validation: 0.09275190442633303]
	TIME [epoch: 5.74 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676211024080096		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.06676211024080096 | validation: 0.09311476974781897]
	TIME [epoch: 5.77 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0650315513899742		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0650315513899742 | validation: 0.09177637032140243]
	TIME [epoch: 5.74 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785587399060854		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.06785587399060854 | validation: 0.08855884303916678]
	TIME [epoch: 5.74 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650805283405531		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.06650805283405531 | validation: 0.09501063907089552]
	TIME [epoch: 5.74 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07055171173683937		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.07055171173683937 | validation: 0.1044862142457534]
	TIME [epoch: 5.73 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521814546003076		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.08521814546003076 | validation: 0.10934970293820757]
	TIME [epoch: 5.74 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770497687949252		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0770497687949252 | validation: 0.09994332164397181]
	TIME [epoch: 5.77 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08550775539562462		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.08550775539562462 | validation: 0.10183112795072558]
	TIME [epoch: 5.74 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791712938783356		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.07791712938783356 | validation: 0.10436891720505045]
	TIME [epoch: 5.74 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07391533218342304		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.07391533218342304 | validation: 0.08524508352027234]
	TIME [epoch: 5.73 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07069613158198189		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.07069613158198189 | validation: 0.10860951114199072]
	TIME [epoch: 5.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108974172351771		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.08108974172351771 | validation: 0.10294038798561304]
	TIME [epoch: 5.74 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466786365306892		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.07466786365306892 | validation: 0.09178030192611449]
	TIME [epoch: 5.75 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0697725803265124		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0697725803265124 | validation: 0.10251395657175172]
	TIME [epoch: 5.76 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06882207129205639		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.06882207129205639 | validation: 0.09419065275915828]
	TIME [epoch: 5.74 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232002031904901		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.07232002031904901 | validation: 0.10408957950267357]
	TIME [epoch: 5.74 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08036280851815479		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.08036280851815479 | validation: 0.10178948632965366]
	TIME [epoch: 5.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023314956772922		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.07023314956772922 | validation: 0.10170817870388878]
	TIME [epoch: 5.73 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06922331055910025		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.06922331055910025 | validation: 0.10133348881348259]
	TIME [epoch: 5.74 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06668176995867378		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.06668176995867378 | validation: 0.09704154974718915]
	TIME [epoch: 5.77 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06406803821879493		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.06406803821879493 | validation: 0.09772951561388311]
	TIME [epoch: 5.74 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07082357600524124		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.07082357600524124 | validation: 0.10087941155994223]
	TIME [epoch: 5.74 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719547996602118		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.07719547996602118 | validation: 0.08602600563625055]
	TIME [epoch: 5.74 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017201707349482		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.07017201707349482 | validation: 0.10163086140040299]
	TIME [epoch: 5.74 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07471851392025501		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.07471851392025501 | validation: 0.0935545079381702]
	TIME [epoch: 5.74 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793254270577748		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.06793254270577748 | validation: 0.09484930092581674]
	TIME [epoch: 5.76 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399541084988218		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.07399541084988218 | validation: 0.10385671359527869]
	TIME [epoch: 5.75 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07544708480519162		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07544708480519162 | validation: 0.10145747572344348]
	TIME [epoch: 5.74 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07912142314604034		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.07912142314604034 | validation: 0.09384066876628731]
	TIME [epoch: 5.74 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0684393296609184		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0684393296609184 | validation: 0.10904748206822902]
	TIME [epoch: 5.73 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08836312160739246		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.08836312160739246 | validation: 0.10119073160352308]
	TIME [epoch: 5.74 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06525448863722262		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.06525448863722262 | validation: 0.08960765005128334]
	TIME [epoch: 5.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07049718802975236		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.07049718802975236 | validation: 0.10428127423248462]
	TIME [epoch: 5.77 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378250184022865		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.07378250184022865 | validation: 0.09616018199258485]
	TIME [epoch: 5.74 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740301426546077		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0740301426546077 | validation: 0.1008985772685921]
	TIME [epoch: 5.74 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675117663724815		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.0675117663724815 | validation: 0.0955703079506107]
	TIME [epoch: 5.74 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06719219135341677		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.06719219135341677 | validation: 0.10905028282466109]
	TIME [epoch: 5.74 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08797947168502858		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.08797947168502858 | validation: 0.12232036284202828]
	TIME [epoch: 5.74 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08308873674946995		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.08308873674946995 | validation: 0.10732075490878781]
	TIME [epoch: 5.76 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860868528316746		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.06860868528316746 | validation: 0.09460835573747389]
	TIME [epoch: 5.75 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06866198735602173		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.06866198735602173 | validation: 0.0849377000145639]
	TIME [epoch: 5.74 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06905992121242685		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.06905992121242685 | validation: 0.08574776721361949]
	TIME [epoch: 5.74 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015060936904684		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.06015060936904684 | validation: 0.0923874666422184]
	TIME [epoch: 5.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08317263874059201		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.08317263874059201 | validation: 0.09653032267716828]
	TIME [epoch: 5.74 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720717686657654		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.06720717686657654 | validation: 0.1024759658036628]
	TIME [epoch: 5.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06780188727655692		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.06780188727655692 | validation: 0.10113636137534318]
	TIME [epoch: 5.77 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532417950093212		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.07532417950093212 | validation: 0.09817927119271794]
	TIME [epoch: 5.74 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127607963044699		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.07127607963044699 | validation: 0.10384304505890146]
	TIME [epoch: 5.74 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067810533554489		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.07067810533554489 | validation: 0.08512378781811117]
	TIME [epoch: 5.73 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826975196420116		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.07826975196420116 | validation: 0.08930571418788028]
	TIME [epoch: 5.73 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746436366914415		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.0746436366914415 | validation: 0.09300163769110682]
	TIME [epoch: 5.73 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06829471747991743		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.06829471747991743 | validation: 0.0939781875955733]
	TIME [epoch: 5.76 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703730403080088		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.06703730403080088 | validation: 0.08499978796416185]
	TIME [epoch: 5.75 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06448981930562415		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.06448981930562415 | validation: 0.08422468564098315]
	TIME [epoch: 5.74 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293424480197515		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.06293424480197515 | validation: 0.08098958960590252]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1169.pth
	Model improved!!!
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546603693982779		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.06546603693982779 | validation: 0.08329043682744924]
	TIME [epoch: 5.74 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444519655141465		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.06444519655141465 | validation: 0.09070147846513031]
	TIME [epoch: 5.74 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06916311621370899		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.06916311621370899 | validation: 0.09281530423610825]
	TIME [epoch: 5.74 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07259920548650416		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.07259920548650416 | validation: 0.08505883289013041]
	TIME [epoch: 5.77 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06459350712984789		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.06459350712984789 | validation: 0.0897654536887429]
	TIME [epoch: 5.74 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06850321348264653		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.06850321348264653 | validation: 0.09311417183180488]
	TIME [epoch: 5.74 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06515722001869506		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.06515722001869506 | validation: 0.08919368676093971]
	TIME [epoch: 5.74 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189937213086624		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.07189937213086624 | validation: 0.09768179896787488]
	TIME [epoch: 5.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791838280513173		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.07791838280513173 | validation: 0.08909421276328068]
	TIME [epoch: 5.73 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755803496312552		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.07755803496312552 | validation: 0.11599894651588707]
	TIME [epoch: 5.76 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07785024747330596		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.07785024747330596 | validation: 0.09538153817872713]
	TIME [epoch: 5.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720408181018847		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0720408181018847 | validation: 0.09281535028740884]
	TIME [epoch: 5.74 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715957476549543		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.0715957476549543 | validation: 0.09502184788532109]
	TIME [epoch: 5.74 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389287615894186		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.06389287615894186 | validation: 0.08699100670485951]
	TIME [epoch: 5.74 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06942617746766691		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.06942617746766691 | validation: 0.08189280254318865]
	TIME [epoch: 5.73 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06745875122359107		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.06745875122359107 | validation: 0.08970505234429141]
	TIME [epoch: 5.74 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150539886968404		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.07150539886968404 | validation: 0.09427041897402663]
	TIME [epoch: 5.77 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06776272963050582		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.06776272963050582 | validation: 0.09600436570588826]
	TIME [epoch: 5.74 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06951324550962393		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.06951324550962393 | validation: 0.0992933618318643]
	TIME [epoch: 5.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07706625539689375		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.07706625539689375 | validation: 0.08618753167966926]
	TIME [epoch: 5.73 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466994833546788		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.06466994833546788 | validation: 0.08556034517902159]
	TIME [epoch: 5.73 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06757428495113627		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.06757428495113627 | validation: 0.09656332799165089]
	TIME [epoch: 5.74 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176443585604479		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.07176443585604479 | validation: 0.08182095456010949]
	TIME [epoch: 5.76 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06825086939868033		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06825086939868033 | validation: 0.07945967960420987]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1193.pth
	Model improved!!!
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06846091152350284		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.06846091152350284 | validation: 0.08900835208110434]
	TIME [epoch: 5.74 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936783865168725		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.06936783865168725 | validation: 0.08906411681598563]
	TIME [epoch: 5.73 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232566244545521		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.07232566244545521 | validation: 0.08885438733187886]
	TIME [epoch: 5.73 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394438684845982		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.07394438684845982 | validation: 0.08921130486872601]
	TIME [epoch: 5.73 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07152129689561057		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.07152129689561057 | validation: 0.08901293693220565]
	TIME [epoch: 5.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0709121934099492		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.0709121934099492 | validation: 0.10420676938747711]
	TIME [epoch: 5.76 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907770614718732		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.07907770614718732 | validation: 0.08848360648416337]
	TIME [epoch: 5.74 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06833834645585568		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.06833834645585568 | validation: 0.09758090297311926]
	TIME [epoch: 5.73 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0818315041025321		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.0818315041025321 | validation: 0.09778545335437683]
	TIME [epoch: 5.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0685600544855154		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.0685600544855154 | validation: 0.07595738753776674]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07138385437245154		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.07138385437245154 | validation: 0.08544629220687504]
	TIME [epoch: 5.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662154287914147		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0662154287914147 | validation: 0.0855739222795636]
	TIME [epoch: 5.78 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790366813318804		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.06790366813318804 | validation: 0.08215531358773344]
	TIME [epoch: 5.74 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06774982109006808		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.06774982109006808 | validation: 0.09068859089419462]
	TIME [epoch: 5.74 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552544097654113		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06552544097654113 | validation: 0.09156586752911246]
	TIME [epoch: 5.74 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859900172543853		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.07859900172543853 | validation: 0.09182282274688518]
	TIME [epoch: 5.73 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686451931452165		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.0686451931452165 | validation: 0.08231362235289343]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472835912242131		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06472835912242131 | validation: 0.0896369501040082]
	TIME [epoch: 5.76 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728479555651141		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.0728479555651141 | validation: 0.09162000768072037]
	TIME [epoch: 5.75 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06717841578582594		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.06717841578582594 | validation: 0.08039070023053979]
	TIME [epoch: 5.74 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0623663047139719		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0623663047139719 | validation: 0.09219235099996002]
	TIME [epoch: 5.74 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06391164511424925		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.06391164511424925 | validation: 0.07917616228585268]
	TIME [epoch: 5.74 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612983057892358		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06612983057892358 | validation: 0.07843692131796236]
	TIME [epoch: 5.74 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377882266579883		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06377882266579883 | validation: 0.08014301683231315]
	TIME [epoch: 5.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487551221719653		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.06487551221719653 | validation: 0.08752491668987585]
	TIME [epoch: 5.77 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105974936054263		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.07105974936054263 | validation: 0.10202853350007311]
	TIME [epoch: 5.74 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298510192103762		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.07298510192103762 | validation: 0.07909742722517271]
	TIME [epoch: 5.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06160188359017833		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.06160188359017833 | validation: 0.08292726740119336]
	TIME [epoch: 5.74 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804056293474563		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.05804056293474563 | validation: 0.08599956991105381]
	TIME [epoch: 5.73 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652438829064843		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.06652438829064843 | validation: 0.08244202649847679]
	TIME [epoch: 5.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672178549077719		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.06672178549077719 | validation: 0.08244762174536845]
	TIME [epoch: 5.76 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664843565891987		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.06664843565891987 | validation: 0.09028460167894053]
	TIME [epoch: 5.75 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06938547070898182		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.06938547070898182 | validation: 0.08565574469573538]
	TIME [epoch: 5.74 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07125194957618436		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.07125194957618436 | validation: 0.0773684250898678]
	TIME [epoch: 5.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06206200733387301		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.06206200733387301 | validation: 0.08569561113892898]
	TIME [epoch: 5.74 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293859885770031		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06293859885770031 | validation: 0.08042850423681555]
	TIME [epoch: 5.74 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06033904906821899		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.06033904906821899 | validation: 0.09048392580827627]
	TIME [epoch: 5.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356934474987405		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.06356934474987405 | validation: 0.07547559641042993]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1231.pth
	Model improved!!!
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06495291173347408		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.06495291173347408 | validation: 0.07643814036364968]
	TIME [epoch: 5.74 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06516808659093319		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.06516808659093319 | validation: 0.08527665585888304]
	TIME [epoch: 5.74 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646996820688385		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.06646996820688385 | validation: 0.09387296228072389]
	TIME [epoch: 5.74 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0730625919547671		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0730625919547671 | validation: 0.08901881730645063]
	TIME [epoch: 5.74 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06257442686737827		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.06257442686737827 | validation: 0.08590391412891148]
	TIME [epoch: 5.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451222986976565		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.06451222986976565 | validation: 0.09047651744225645]
	TIME [epoch: 5.76 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07007202227838819		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.07007202227838819 | validation: 0.09582998968322448]
	TIME [epoch: 5.75 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717963242496975		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.0717963242496975 | validation: 0.09526584957893261]
	TIME [epoch: 5.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979091037002061		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.06979091037002061 | validation: 0.1045789715242094]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0721547324533626		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.0721547324533626 | validation: 0.09472214614448976]
	TIME [epoch: 5.74 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768405502046704		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.06768405502046704 | validation: 0.08918882189634342]
	TIME [epoch: 5.74 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059529479957872194		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.059529479957872194 | validation: 0.08427268713112657]
	TIME [epoch: 5.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510105455255116		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.06510105455255116 | validation: 0.09138671816181038]
	TIME [epoch: 5.76 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821030975216584		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.06821030975216584 | validation: 0.09210437530982912]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361820319096095		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.06361820319096095 | validation: 0.09277018800159591]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06723075830048506		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.06723075830048506 | validation: 0.09283829182829433]
	TIME [epoch: 5.74 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530928136712027		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.07530928136712027 | validation: 0.08764540089601297]
	TIME [epoch: 5.73 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768578713818373		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.06768578713818373 | validation: 0.08419043069507925]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06197108604785807		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.06197108604785807 | validation: 0.08750197887576727]
	TIME [epoch: 5.77 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062362815543371364		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.062362815543371364 | validation: 0.09637772759871988]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06411580872600989		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.06411580872600989 | validation: 0.08631959782330487]
	TIME [epoch: 5.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0656168540775089		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.0656168540775089 | validation: 0.08758716165317854]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758622911158162		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.06758622911158162 | validation: 0.07282311318393901]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1254.pth
	Model improved!!!
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06346358683596542		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.06346358683596542 | validation: 0.08610256800000408]
	TIME [epoch: 5.74 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06735704345842225		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.06735704345842225 | validation: 0.09380538085183492]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05905885564536206		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.05905885564536206 | validation: 0.09374966580963318]
	TIME [epoch: 5.76 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06736495251719404		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.06736495251719404 | validation: 0.0830712304576436]
	TIME [epoch: 5.73 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06253306211508554		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.06253306211508554 | validation: 0.07900942257441855]
	TIME [epoch: 5.73 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06218594270078298		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.06218594270078298 | validation: 0.08277296625928632]
	TIME [epoch: 5.73 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343243213555948		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.06343243213555948 | validation: 0.08429699567727628]
	TIME [epoch: 5.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0674155398029983		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.0674155398029983 | validation: 0.08245167319964962]
	TIME [epoch: 5.73 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07096591207043343		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.07096591207043343 | validation: 0.08494611217325959]
	TIME [epoch: 5.77 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06647232595725243		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.06647232595725243 | validation: 0.08968492645955665]
	TIME [epoch: 5.74 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664389600063131		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.0664389600063131 | validation: 0.08603586156242976]
	TIME [epoch: 5.73 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278134625243378		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.06278134625243378 | validation: 0.08563609509026471]
	TIME [epoch: 5.73 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06042371945423251		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.06042371945423251 | validation: 0.08420890327269412]
	TIME [epoch: 5.73 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761723192539384		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06761723192539384 | validation: 0.08142158773066686]
	TIME [epoch: 5.73 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0614095182599317		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.0614095182599317 | validation: 0.0886397265475548]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0640940189202337		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.0640940189202337 | validation: 0.08626286678376247]
	TIME [epoch: 5.76 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06958075176182972		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.06958075176182972 | validation: 0.08376233623151823]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675878903367641		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.06675878903367641 | validation: 0.08771703438357026]
	TIME [epoch: 5.73 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06461880859070981		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.06461880859070981 | validation: 0.08604320584178023]
	TIME [epoch: 5.73 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06156554172192268		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.06156554172192268 | validation: 0.0903615317391076]
	TIME [epoch: 5.73 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879209884877505		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.06879209884877505 | validation: 0.08195867412886397]
	TIME [epoch: 5.74 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06107882465979792		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.06107882465979792 | validation: 0.08247859036601479]
	TIME [epoch: 5.77 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558738180159722		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.06558738180159722 | validation: 0.09009585244760436]
	TIME [epoch: 5.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031071902226951		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.06031071902226951 | validation: 0.09078428020032255]
	TIME [epoch: 5.74 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06528038740291174		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.06528038740291174 | validation: 0.095126893820377]
	TIME [epoch: 5.73 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272036740027932		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.06272036740027932 | validation: 0.08026061508397338]
	TIME [epoch: 5.73 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542867298142592		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.06542867298142592 | validation: 0.08686253731433576]
	TIME [epoch: 5.73 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062048968106474534		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.062048968106474534 | validation: 0.07951369193865439]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06599970524064167		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.06599970524064167 | validation: 0.08116553621899658]
	TIME [epoch: 5.76 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128794714803065		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.06128794714803065 | validation: 0.0740302330006023]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06465500028843267		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.06465500028843267 | validation: 0.09046666210858767]
	TIME [epoch: 5.73 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07024960515475476		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.07024960515475476 | validation: 0.0927417537449028]
	TIME [epoch: 5.73 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06971278804491528		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.06971278804491528 | validation: 0.0909589363348176]
	TIME [epoch: 5.73 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546261527662173		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.06546261527662173 | validation: 0.0974676236677766]
	TIME [epoch: 5.73 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06999753132610656		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.06999753132610656 | validation: 0.08504020953498075]
	TIME [epoch: 5.77 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06760085809483522		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06760085809483522 | validation: 0.07604496661638978]
	TIME [epoch: 5.74 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006011416131865		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06006011416131865 | validation: 0.08316449620532941]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06560975788806797		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.06560975788806797 | validation: 0.08506204394674342]
	TIME [epoch: 5.73 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061879467462633134		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.061879467462633134 | validation: 0.0797797100152088]
	TIME [epoch: 5.74 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720976469115057		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.06720976469115057 | validation: 0.08316046705955073]
	TIME [epoch: 5.73 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06497461211998887		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.06497461211998887 | validation: 0.09485005025157214]
	TIME [epoch: 5.76 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06808810223250056		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.06808810223250056 | validation: 0.08028119915452596]
	TIME [epoch: 5.75 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353823735224383		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.06353823735224383 | validation: 0.07701855585636765]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061426742526930686		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.061426742526930686 | validation: 0.08415290967280718]
	TIME [epoch: 5.73 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0657717647854965		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.0657717647854965 | validation: 0.09035439955056383]
	TIME [epoch: 5.73 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06825695805392495		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.06825695805392495 | validation: 0.08876586275037222]
	TIME [epoch: 5.73 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060332196214961505		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.060332196214961505 | validation: 0.08542830857411735]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06694077816188085		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.06694077816188085 | validation: 0.08572280329404658]
	TIME [epoch: 5.77 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319106771316682		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.06319106771316682 | validation: 0.07690119512728848]
	TIME [epoch: 5.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300152418029646		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06300152418029646 | validation: 0.08518686553332164]
	TIME [epoch: 5.73 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06210549364942483		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06210549364942483 | validation: 0.08152308763282266]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599763998215601		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.0599763998215601 | validation: 0.08215958178723876]
	TIME [epoch: 5.73 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642694791597886		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.06642694791597886 | validation: 0.0793907709115847]
	TIME [epoch: 5.73 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06947973409641783		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.06947973409641783 | validation: 0.08725109476913095]
	TIME [epoch: 5.76 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06341215092465023		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.06341215092465023 | validation: 0.08279477490403793]
	TIME [epoch: 5.75 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06196792272718969		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.06196792272718969 | validation: 0.07821507065660228]
	TIME [epoch: 5.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0601375114690501		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.0601375114690501 | validation: 0.08992299998676566]
	TIME [epoch: 5.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06517561894525212		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.06517561894525212 | validation: 0.07941162313173726]
	TIME [epoch: 5.73 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06186088370808897		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.06186088370808897 | validation: 0.07730500918383465]
	TIME [epoch: 5.74 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644840418284293		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.0644840418284293 | validation: 0.08858507322608623]
	TIME [epoch: 5.74 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129698571575424		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.06129698571575424 | validation: 0.07955696682348376]
	TIME [epoch: 5.77 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061464467950443635		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.061464467950443635 | validation: 0.09620721300703909]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468990013292794		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.06468990013292794 | validation: 0.09078414419802705]
	TIME [epoch: 5.73 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787907442520338		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.06787907442520338 | validation: 0.08934452094666143]
	TIME [epoch: 5.73 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061811485778914745		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.061811485778914745 | validation: 0.08031039754508737]
	TIME [epoch: 5.73 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0615501072297592		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.0615501072297592 | validation: 0.09001299344399386]
	TIME [epoch: 5.73 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546374538340498		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.06546374538340498 | validation: 0.08058796860243199]
	TIME [epoch: 5.76 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06155844988255223		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06155844988255223 | validation: 0.08203145960354895]
	TIME [epoch: 5.75 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06806327419922134		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.06806327419922134 | validation: 0.08325698205446365]
	TIME [epoch: 5.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06146143998356444		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.06146143998356444 | validation: 0.09393060631525008]
	TIME [epoch: 5.73 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509327033043398		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.06509327033043398 | validation: 0.08194538197254751]
	TIME [epoch: 5.73 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382816278348272		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.06382816278348272 | validation: 0.09049038554455774]
	TIME [epoch: 5.73 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06303219422594342		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.06303219422594342 | validation: 0.09418832721296276]
	TIME [epoch: 5.73 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06650419989955475		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.06650419989955475 | validation: 0.08402723659047442]
	TIME [epoch: 5.77 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060150908122941944		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.060150908122941944 | validation: 0.08673274380514766]
	TIME [epoch: 5.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926002867329411		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.05926002867329411 | validation: 0.08004380279132622]
	TIME [epoch: 5.73 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966660243749934		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05966660243749934 | validation: 0.08585811053797947]
	TIME [epoch: 5.73 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0631004833517998		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.0631004833517998 | validation: 0.08374113287834895]
	TIME [epoch: 5.73 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644162986576761		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.0644162986576761 | validation: 0.08526192764472247]
	TIME [epoch: 5.73 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06666990056641568		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.06666990056641568 | validation: 0.09270469323278965]
	TIME [epoch: 5.76 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856656344985824		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.06856656344985824 | validation: 0.09051889283257093]
	TIME [epoch: 5.75 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06898396474495502		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.06898396474495502 | validation: 0.0841194096327872]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0616251941038837		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.0616251941038837 | validation: 0.08348754520751035]
	TIME [epoch: 5.73 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06199961495479972		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.06199961495479972 | validation: 0.07772581302998996]
	TIME [epoch: 5.74 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06336103643479199		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.06336103643479199 | validation: 0.09090600385489155]
	TIME [epoch: 5.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06358027196499201		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.06358027196499201 | validation: 0.08010605970976752]
	TIME [epoch: 5.73 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379618006171273		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.06379618006171273 | validation: 0.08788596029171906]
	TIME [epoch: 5.77 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953743485123092		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.05953743485123092 | validation: 0.08389871376683974]
	TIME [epoch: 5.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05677293768210456		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.05677293768210456 | validation: 0.07446176183205162]
	TIME [epoch: 5.73 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060461197672534384		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.060461197672534384 | validation: 0.07934612094356981]
	TIME [epoch: 5.73 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288480970142184		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.06288480970142184 | validation: 0.0853216619730962]
	TIME [epoch: 5.73 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05872439562363303		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.05872439562363303 | validation: 0.08137197468261884]
	TIME [epoch: 5.73 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06300044326499701		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.06300044326499701 | validation: 0.08391878021530876]
	TIME [epoch: 5.76 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060869432937622286		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.060869432937622286 | validation: 0.08096881380836178]
	TIME [epoch: 5.75 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592023819194593		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.0592023819194593 | validation: 0.08206720483359063]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836432110451508		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.05836432110451508 | validation: 0.09294707306415578]
	TIME [epoch: 5.73 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062493453098424266		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.062493453098424266 | validation: 0.08158519092369958]
	TIME [epoch: 5.73 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791322642328474		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.05791322642328474 | validation: 0.08164970811139438]
	TIME [epoch: 5.73 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059778186202588006		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.059778186202588006 | validation: 0.0819169911638944]
	TIME [epoch: 5.74 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062130060382893294		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.062130060382893294 | validation: 0.07755999281077733]
	TIME [epoch: 5.77 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05507954793810206		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.05507954793810206 | validation: 0.08152215033045304]
	TIME [epoch: 5.74 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06080234549895647		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.06080234549895647 | validation: 0.0806499288192008]
	TIME [epoch: 5.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06670672036113809		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.06670672036113809 | validation: 0.0835568599210183]
	TIME [epoch: 5.73 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07290076107934756		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.07290076107934756 | validation: 0.08835765056416932]
	TIME [epoch: 5.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07522914865109817		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.07522914865109817 | validation: 0.09048661222881205]
	TIME [epoch: 5.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017485833312966		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.07017485833312966 | validation: 0.0907461173465158]
	TIME [epoch: 5.76 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06150854362270665		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.06150854362270665 | validation: 0.08392891461802152]
	TIME [epoch: 5.75 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686749628389779		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.06686749628389779 | validation: 0.09320375312708616]
	TIME [epoch: 5.74 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06063137361607589		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.06063137361607589 | validation: 0.08393966820776766]
	TIME [epoch: 5.74 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788960306767922		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.05788960306767922 | validation: 0.08315353000813602]
	TIME [epoch: 5.74 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06132959101752058		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.06132959101752058 | validation: 0.09853704385919604]
	TIME [epoch: 5.74 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07034029198309669		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.07034029198309669 | validation: 0.09365244649787043]
	TIME [epoch: 5.74 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06708537261196006		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.06708537261196006 | validation: 0.09560948290565575]
	TIME [epoch: 5.77 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06457997095038047		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.06457997095038047 | validation: 0.09084593266341769]
	TIME [epoch: 5.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0681370919283869		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0681370919283869 | validation: 0.08457411287633633]
	TIME [epoch: 5.74 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06254603761562176		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.06254603761562176 | validation: 0.08326091788036882]
	TIME [epoch: 5.73 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967420245442956		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.05967420245442956 | validation: 0.08496377690571366]
	TIME [epoch: 5.74 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05955479771389848		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.05955479771389848 | validation: 0.07858157423207274]
	TIME [epoch: 5.74 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06178058657354131		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.06178058657354131 | validation: 0.0941035108871973]
	TIME [epoch: 5.76 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06502232105841083		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.06502232105841083 | validation: 0.0883998139280703]
	TIME [epoch: 5.75 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293416427173626		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.06293416427173626 | validation: 0.08414314886102223]
	TIME [epoch: 5.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06082815362207347		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.06082815362207347 | validation: 0.07832831850705554]
	TIME [epoch: 5.74 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012036536407289		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.06012036536407289 | validation: 0.0853828057742637]
	TIME [epoch: 5.74 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06253637811868376		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.06253637811868376 | validation: 0.0839321219260782]
	TIME [epoch: 5.73 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0606591502117554		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0606591502117554 | validation: 0.08513132544874484]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269275392061908		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.06269275392061908 | validation: 0.08914981582810869]
	TIME [epoch: 5.77 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562585580933352		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.0562585580933352 | validation: 0.08601138853213575]
	TIME [epoch: 5.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06175247148990247		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.06175247148990247 | validation: 0.084608608895076]
	TIME [epoch: 5.74 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06249167703035083		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.06249167703035083 | validation: 0.07656087402646464]
	TIME [epoch: 5.73 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05731971454537076		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.05731971454537076 | validation: 0.08979200860173692]
	TIME [epoch: 5.73 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06418677794575534		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.06418677794575534 | validation: 0.08999651668115596]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06491706110850108		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.06491706110850108 | validation: 0.09375526647511924]
	TIME [epoch: 5.77 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144794440007674		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.06144794440007674 | validation: 0.08633159361768161]
	TIME [epoch: 5.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059474128468290935		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.059474128468290935 | validation: 0.08844210864761134]
	TIME [epoch: 5.73 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062058182146041016		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.062058182146041016 | validation: 0.08678163880221183]
	TIME [epoch: 5.73 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644530317894048		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0644530317894048 | validation: 0.08940520140221246]
	TIME [epoch: 5.73 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344728671331706		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.06344728671331706 | validation: 0.08784592914027357]
	TIME [epoch: 5.73 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295860589667746		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.06295860589667746 | validation: 0.0948410236294309]
	TIME [epoch: 5.75 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625203270234864		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.0625203270234864 | validation: 0.08627603411573324]
	TIME [epoch: 5.76 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618621832631554		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.0618621832631554 | validation: 0.08624225281296198]
	TIME [epoch: 5.74 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06295125731529304		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.06295125731529304 | validation: 0.07990164634530698]
	TIME [epoch: 5.74 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062362540169897694		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.062362540169897694 | validation: 0.0822057770394425]
	TIME [epoch: 5.73 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060948721841584924		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.060948721841584924 | validation: 0.07925457232367203]
	TIME [epoch: 5.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06579290081673766		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.06579290081673766 | validation: 0.08501149241149915]
	TIME [epoch: 5.73 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06728455177908875		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.06728455177908875 | validation: 0.09461201826746823]
	TIME [epoch: 5.77 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06693505609921947		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.06693505609921947 | validation: 0.08283265758871064]
	TIME [epoch: 5.74 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06478922714234392		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.06478922714234392 | validation: 0.08158453038701076]
	TIME [epoch: 5.73 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283064672583602		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.06283064672583602 | validation: 0.0939787493044107]
	TIME [epoch: 5.73 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061955785958639584		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.061955785958639584 | validation: 0.08913504106072914]
	TIME [epoch: 5.73 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408392480337498		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.06408392480337498 | validation: 0.07877714375002237]
	TIME [epoch: 5.73 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06192814128536303		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.06192814128536303 | validation: 0.07897538284224134]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06328740820459994		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.06328740820459994 | validation: 0.08041494266121735]
	TIME [epoch: 5.76 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635754629790834		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0635754629790834 | validation: 0.07906328388861014]
	TIME [epoch: 5.74 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964577759371087		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05964577759371087 | validation: 0.07930099065396083]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0618166055917654		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.0618166055917654 | validation: 0.08074693704324162]
	TIME [epoch: 5.73 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05881225970480351		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.05881225970480351 | validation: 0.0711137951202226]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1410.pth
	Model improved!!!
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05809552862055401		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.05809552862055401 | validation: 0.08165976295230638]
	TIME [epoch: 5.74 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716247092426351		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.06716247092426351 | validation: 0.0801144952249342]
	TIME [epoch: 5.77 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926001458786975		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.05926001458786975 | validation: 0.07079513114156848]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1413.pth
	Model improved!!!
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06439053618735197		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.06439053618735197 | validation: 0.0823467862125983]
	TIME [epoch: 5.73 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06768353898272696		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.06768353898272696 | validation: 0.0837592096670195]
	TIME [epoch: 5.74 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06020218494806747		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.06020218494806747 | validation: 0.0767955649743938]
	TIME [epoch: 5.73 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06246017406425168		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.06246017406425168 | validation: 0.07480519156264631]
	TIME [epoch: 5.73 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06099158667592315		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.06099158667592315 | validation: 0.08491905688329084]
	TIME [epoch: 5.76 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06718644438200169		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.06718644438200169 | validation: 0.08617310473243281]
	TIME [epoch: 5.75 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667039390780198		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.0667039390780198 | validation: 0.08808641027363912]
	TIME [epoch: 5.74 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06148892066936591		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.06148892066936591 | validation: 0.08638142504078193]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060487047035619815		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.060487047035619815 | validation: 0.07915200613197661]
	TIME [epoch: 5.73 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05989080034825229		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.05989080034825229 | validation: 0.07999662935819397]
	TIME [epoch: 5.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816130628920295		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.05816130628920295 | validation: 0.0740590633268526]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05945925852192419		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.05945925852192419 | validation: 0.08579396894745898]
	TIME [epoch: 5.77 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06087990910080522		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.06087990910080522 | validation: 0.08685269840253877]
	TIME [epoch: 5.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018579105035943		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.06018579105035943 | validation: 0.08983464320790287]
	TIME [epoch: 5.73 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0620005220364455		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.0620005220364455 | validation: 0.08485175851178839]
	TIME [epoch: 5.73 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06426481144400595		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.06426481144400595 | validation: 0.08141725693866647]
	TIME [epoch: 5.73 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600537882776894		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.06600537882776894 | validation: 0.07998149228418587]
	TIME [epoch: 5.73 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06277747254099587		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06277747254099587 | validation: 0.08043060064988453]
	TIME [epoch: 5.76 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05646866043136978		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.05646866043136978 | validation: 0.07574034815353566]
	TIME [epoch: 5.75 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058461169976008524		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.058461169976008524 | validation: 0.08934389543416177]
	TIME [epoch: 5.74 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06329370756294853		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.06329370756294853 | validation: 0.08611749117289319]
	TIME [epoch: 5.73 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671837632076708		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0671837632076708 | validation: 0.08235462390597623]
	TIME [epoch: 5.73 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493930679114879		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.06493930679114879 | validation: 0.08483996390118945]
	TIME [epoch: 5.73 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06471952799898623		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.06471952799898623 | validation: 0.08980890167313497]
	TIME [epoch: 5.73 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060660100394306436		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.060660100394306436 | validation: 0.08150515243620582]
	TIME [epoch: 5.77 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609369285020824		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.05609369285020824 | validation: 0.08671379812271035]
	TIME [epoch: 5.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06193999161094235		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.06193999161094235 | validation: 0.084634429609018]
	TIME [epoch: 5.73 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05989169540706546		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.05989169540706546 | validation: 0.08328973556553429]
	TIME [epoch: 5.73 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924468799790895		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.05924468799790895 | validation: 0.08892661952283863]
	TIME [epoch: 5.73 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06140087333391804		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.06140087333391804 | validation: 0.08449785221784467]
	TIME [epoch: 5.73 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0529317265660097		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.0529317265660097 | validation: 0.08389737991575157]
	TIME [epoch: 5.76 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059543561472184606		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.059543561472184606 | validation: 0.09177996656941304]
	TIME [epoch: 5.75 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06586519211046805		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.06586519211046805 | validation: 0.0898509675869274]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0696268643576321		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.0696268643576321 | validation: 0.09238077671024916]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925605166672641		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.05925605166672641 | validation: 0.08311932152296034]
	TIME [epoch: 5.73 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058294602971055785		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.058294602971055785 | validation: 0.07221795448952201]
	TIME [epoch: 5.73 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059869140065045234		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.059869140065045234 | validation: 0.07608920166561525]
	TIME [epoch: 5.73 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913942806419995		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.05913942806419995 | validation: 0.08907521777444216]
	TIME [epoch: 5.77 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344449384469866		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.06344449384469866 | validation: 0.09036930131006059]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062481979793465044		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.062481979793465044 | validation: 0.08145566502762046]
	TIME [epoch: 5.73 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06285912295358631		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.06285912295358631 | validation: 0.07673709869910149]
	TIME [epoch: 5.73 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06232184811632524		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.06232184811632524 | validation: 0.08889202891772702]
	TIME [epoch: 5.73 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06553736627018475		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.06553736627018475 | validation: 0.08355267700507735]
	TIME [epoch: 5.73 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888561445068748		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.05888561445068748 | validation: 0.08399605232504616]
	TIME [epoch: 5.76 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056760240539457794		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.056760240539457794 | validation: 0.08485287076229357]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06542515374624355		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.06542515374624355 | validation: 0.0873025163950999]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06398132070575026		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.06398132070575026 | validation: 0.09209114415537027]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629406950639977		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.06629406950639977 | validation: 0.09085463227540264]
	TIME [epoch: 5.73 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280157127707397		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.07280157127707397 | validation: 0.08089989544476525]
	TIME [epoch: 5.73 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0668762742017991		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.0668762742017991 | validation: 0.08658971523969608]
	TIME [epoch: 5.73 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061036438372468096		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.061036438372468096 | validation: 0.08458484250632894]
	TIME [epoch: 5.77 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057942165651592464		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.057942165651592464 | validation: 0.0855719806872581]
	TIME [epoch: 5.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0595753620385658		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.0595753620385658 | validation: 0.08705070769233897]
	TIME [epoch: 5.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05898174786043772		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.05898174786043772 | validation: 0.08731239605933169]
	TIME [epoch: 5.73 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06351660130221728		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.06351660130221728 | validation: 0.08375060701796974]
	TIME [epoch: 5.73 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06049267587450356		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.06049267587450356 | validation: 0.09096699428115108]
	TIME [epoch: 5.73 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06690232966037796		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.06690232966037796 | validation: 0.09016752449240148]
	TIME [epoch: 5.77 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06323929316178627		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.06323929316178627 | validation: 0.08110929084470263]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05916391500811848		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.05916391500811848 | validation: 0.08278400125570176]
	TIME [epoch: 5.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090658165593284		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.06090658165593284 | validation: 0.08009502001426036]
	TIME [epoch: 5.73 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061610412924431486		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.061610412924431486 | validation: 0.08668145277896504]
	TIME [epoch: 5.73 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056594328429988336		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.056594328429988336 | validation: 0.09498152235206844]
	TIME [epoch: 5.73 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941295868552853		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.05941295868552853 | validation: 0.08543222639783565]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061402057564307666		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.061402057564307666 | validation: 0.0812814467647699]
	TIME [epoch: 5.76 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381220335439594		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.06381220335439594 | validation: 0.08210133109467953]
	TIME [epoch: 5.73 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06035343691865084		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.06035343691865084 | validation: 0.08714508713649838]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060993274141013465		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.060993274141013465 | validation: 0.08466385157573895]
	TIME [epoch: 5.73 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05941768482597566		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.05941768482597566 | validation: 0.07922892034554065]
	TIME [epoch: 5.73 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06060950112556428		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.06060950112556428 | validation: 0.07747880276295417]
	TIME [epoch: 5.73 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904747370977147		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.05904747370977147 | validation: 0.08947527174934258]
	TIME [epoch: 5.77 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06762501285022587		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.06762501285022587 | validation: 0.08807008075550556]
	TIME [epoch: 5.74 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06212296487398068		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.06212296487398068 | validation: 0.07922111215982691]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06067725620697086		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.06067725620697086 | validation: 0.08320663566131874]
	TIME [epoch: 5.73 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058909041626580595		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.058909041626580595 | validation: 0.07516458807083734]
	TIME [epoch: 5.73 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06144471461583034		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.06144471461583034 | validation: 0.08431519155898413]
	TIME [epoch: 5.73 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574314126202535		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.05574314126202535 | validation: 0.07707244408682065]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911965410813286		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.05911965410813286 | validation: 0.08042327227027764]
	TIME [epoch: 5.76 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061887018034583165		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.061887018034583165 | validation: 0.08810730141635335]
	TIME [epoch: 5.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06625899324065584		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.06625899324065584 | validation: 0.08456630241809725]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062174667214922895		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.062174667214922895 | validation: 0.07620837378496097]
	TIME [epoch: 5.73 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059867346368849536		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.059867346368849536 | validation: 0.08726210881971604]
	TIME [epoch: 5.73 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05949876414308712		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.05949876414308712 | validation: 0.08971389224806713]
	TIME [epoch: 5.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913945316906644		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05913945316906644 | validation: 0.09162979999022014]
	TIME [epoch: 5.77 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06402249591385549		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.06402249591385549 | validation: 0.08427194234310602]
	TIME [epoch: 5.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061724175505899814		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.061724175505899814 | validation: 0.08952127425582317]
	TIME [epoch: 5.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05722080757972181		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.05722080757972181 | validation: 0.08219606191740002]
	TIME [epoch: 5.73 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879454205771442		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.05879454205771442 | validation: 0.08152110560103669]
	TIME [epoch: 5.73 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06057005498211578		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.06057005498211578 | validation: 0.09048367872512972]
	TIME [epoch: 5.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801243869577877		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.05801243869577877 | validation: 0.082200040541157]
	TIME [epoch: 5.74 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0590990916603646		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.0590990916603646 | validation: 0.08185298569505944]
	TIME [epoch: 5.76 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059650571527810003		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.059650571527810003 | validation: 0.08396215576773056]
	TIME [epoch: 5.73 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053549312671456954		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.053549312671456954 | validation: 0.07965732511587899]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611037487889255		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.05611037487889255 | validation: 0.08696695750039901]
	TIME [epoch: 5.73 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05739371427734419		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.05739371427734419 | validation: 0.07904861629852258]
	TIME [epoch: 5.73 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711208863052412		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.05711208863052412 | validation: 0.08433897248584778]
	TIME [epoch: 5.73 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055828854665516306		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.055828854665516306 | validation: 0.08340096270393808]
	TIME [epoch: 5.77 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189527413057658		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.06189527413057658 | validation: 0.08370152583247077]
	TIME [epoch: 5.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059679213400127044		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.059679213400127044 | validation: 0.08076943174007471]
	TIME [epoch: 5.73 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05385322008836181		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05385322008836181 | validation: 0.07795159340036743]
	TIME [epoch: 5.73 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873804784974122		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05873804784974122 | validation: 0.07733719397292178]
	TIME [epoch: 5.73 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061599973594710325		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.061599973594710325 | validation: 0.08333864601076416]
	TIME [epoch: 5.73 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790423399545085		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.05790423399545085 | validation: 0.08298895369850819]
	TIME [epoch: 5.74 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055426454165412024		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.055426454165412024 | validation: 0.08047292160905371]
	TIME [epoch: 5.76 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05453611290701369		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.05453611290701369 | validation: 0.08526449440719996]
	TIME [epoch: 5.74 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056555565499807815		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.056555565499807815 | validation: 0.08451452214534495]
	TIME [epoch: 5.73 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058577428629635706		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.058577428629635706 | validation: 0.0805213021589843]
	TIME [epoch: 5.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06267955428357212		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.06267955428357212 | validation: 0.07986794584754066]
	TIME [epoch: 5.73 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06216915538290724		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.06216915538290724 | validation: 0.07948876920338249]
	TIME [epoch: 5.73 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060267344952812205		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.060267344952812205 | validation: 0.08019930669441987]
	TIME [epoch: 5.77 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060081316911938215		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.060081316911938215 | validation: 0.0822700849585318]
	TIME [epoch: 5.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05960613961356731		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.05960613961356731 | validation: 0.07911474177777429]
	TIME [epoch: 5.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888467689817893		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.05888467689817893 | validation: 0.08622039421196055]
	TIME [epoch: 5.74 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008245001318607		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.06008245001318607 | validation: 0.07882090943325379]
	TIME [epoch: 5.73 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06683127964147051		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.06683127964147051 | validation: 0.08712428594380542]
	TIME [epoch: 5.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06367616980071736		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.06367616980071736 | validation: 0.08164700858370878]
	TIME [epoch: 5.75 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06117148861072692		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.06117148861072692 | validation: 0.08091804017877319]
	TIME [epoch: 5.76 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059964666272023605		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.059964666272023605 | validation: 0.0797356611876182]
	TIME [epoch: 5.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06035312676781557		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.06035312676781557 | validation: 0.0768077692661459]
	TIME [epoch: 5.74 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06138849421722909		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.06138849421722909 | validation: 0.080372460482067]
	TIME [epoch: 5.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05732892314984441		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.05732892314984441 | validation: 0.0785919476090484]
	TIME [epoch: 5.73 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058327774829734315		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.058327774829734315 | validation: 0.08054111068208382]
	TIME [epoch: 5.73 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060308216088320175		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.060308216088320175 | validation: 0.07459862210867291]
	TIME [epoch: 5.77 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062395423138480816		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.062395423138480816 | validation: 0.08403181499464696]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06169421617470556		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.06169421617470556 | validation: 0.092001740759197]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058833895499708695		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.058833895499708695 | validation: 0.08935650748280317]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262185829758012		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.06262185829758012 | validation: 0.08292544712481659]
	TIME [epoch: 5.73 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06151504207193152		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.06151504207193152 | validation: 0.08035945511632527]
	TIME [epoch: 5.73 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061019209627502194		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.061019209627502194 | validation: 0.08581198743394076]
	TIME [epoch: 5.76 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382949682913511		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.06382949682913511 | validation: 0.0860661056179506]
	TIME [epoch: 5.74 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918015656335825		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.05918015656335825 | validation: 0.08142020996965238]
	TIME [epoch: 5.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05993542854456797		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.05993542854456797 | validation: 0.08009098633916738]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061072369152811015		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.061072369152811015 | validation: 0.07982242444180407]
	TIME [epoch: 5.73 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058242015833096544		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.058242015833096544 | validation: 0.08731329338774721]
	TIME [epoch: 5.73 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06107468962818062		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.06107468962818062 | validation: 0.08662528465919853]
	TIME [epoch: 5.73 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05931731392719816		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.05931731392719816 | validation: 0.08146563071941632]
	TIME [epoch: 5.77 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858903770444321		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.05858903770444321 | validation: 0.09163214664170631]
	TIME [epoch: 5.74 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06210119299062405		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.06210119299062405 | validation: 0.08583698020918852]
	TIME [epoch: 5.73 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057016489188208536		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.057016489188208536 | validation: 0.07932137450899183]
	TIME [epoch: 5.73 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657353785558216		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.05657353785558216 | validation: 0.07971166918129216]
	TIME [epoch: 5.73 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827950038217429		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.05827950038217429 | validation: 0.08034006653613818]
	TIME [epoch: 5.73 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0597387556185615		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.0597387556185615 | validation: 0.08394853367803747]
	TIME [epoch: 5.76 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059996178161254604		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.059996178161254604 | validation: 0.0767483846296226]
	TIME [epoch: 5.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604990112803887		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.0604990112803887 | validation: 0.08112470318109319]
	TIME [epoch: 5.73 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007027990281735		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.06007027990281735 | validation: 0.08893277179221679]
	TIME [epoch: 5.73 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010575030080455		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.06010575030080455 | validation: 0.07934146984688185]
	TIME [epoch: 5.73 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0660322584968164		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0660322584968164 | validation: 0.08684401125497619]
	TIME [epoch: 5.73 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06182132084751377		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.06182132084751377 | validation: 0.08946611595898045]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06104758825548404		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.06104758825548404 | validation: 0.08271609337613267]
	TIME [epoch: 5.77 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06176060132489678		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.06176060132489678 | validation: 0.08101413733169299]
	TIME [epoch: 5.74 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060408933488670796		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.060408933488670796 | validation: 0.08276682234026744]
	TIME [epoch: 5.73 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061626809563349975		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.061626809563349975 | validation: 0.0921234993084541]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187914331700985		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.06187914331700985 | validation: 0.08248484953716202]
	TIME [epoch: 5.73 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06285338405363917		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.06285338405363917 | validation: 0.08814763419399889]
	TIME [epoch: 5.73 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644515609141601		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.0644515609141601 | validation: 0.09289924484287745]
	TIME [epoch: 5.76 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06110492602194641		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.06110492602194641 | validation: 0.07950783011504205]
	TIME [epoch: 5.75 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081315977428321		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.06081315977428321 | validation: 0.08018485738027957]
	TIME [epoch: 5.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386769858270641		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.06386769858270641 | validation: 0.08659666883048457]
	TIME [epoch: 5.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914469650741991		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.05914469650741991 | validation: 0.09595045888013623]
	TIME [epoch: 5.74 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06425148515477293		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.06425148515477293 | validation: 0.08539839832267981]
	TIME [epoch: 5.73 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06264662343793838		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.06264662343793838 | validation: 0.08645750720762901]
	TIME [epoch: 5.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06275401538481439		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.06275401538481439 | validation: 0.0885111582394347]
	TIME [epoch: 5.77 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258115859787648		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.06258115859787648 | validation: 0.08371207927832906]
	TIME [epoch: 5.74 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05735731762386817		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.05735731762386817 | validation: 0.08311534644964334]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0606610033939769		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.0606610033939769 | validation: 0.08615914717151131]
	TIME [epoch: 5.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925535257316532		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.05925535257316532 | validation: 0.0752092999627587]
	TIME [epoch: 5.73 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05810358430226584		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.05810358430226584 | validation: 0.07914453850040827]
	TIME [epoch: 5.73 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05823405803732633		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.05823405803732633 | validation: 0.07672600190196129]
	TIME [epoch: 5.76 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061905692977701085		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.061905692977701085 | validation: 0.07380194483305964]
	TIME [epoch: 5.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05851761653741544		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.05851761653741544 | validation: 0.07777801567121431]
	TIME [epoch: 5.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967930324559958		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05967930324559958 | validation: 0.08109860939303488]
	TIME [epoch: 5.73 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135803361033157		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.06135803361033157 | validation: 0.06902966277013142]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1584.pth
	Model improved!!!
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05891271022156259		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.05891271022156259 | validation: 0.07355850327576047]
	TIME [epoch: 5.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0573129236099636		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.0573129236099636 | validation: 0.07768317401447296]
	TIME [epoch: 5.74 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05800855110813548		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.05800855110813548 | validation: 0.07882917797126934]
	TIME [epoch: 5.76 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288078444042791		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.06288078444042791 | validation: 0.08442522705448241]
	TIME [epoch: 5.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060789647745142325		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.060789647745142325 | validation: 0.07308500324339319]
	TIME [epoch: 5.73 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059316067799735694		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.059316067799735694 | validation: 0.07767761418254436]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055990158617510014		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.055990158617510014 | validation: 0.07713572615455304]
	TIME [epoch: 5.73 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05859648305915062		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.05859648305915062 | validation: 0.0695446486865892]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05794683935854966		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.05794683935854966 | validation: 0.08083491282733098]
	TIME [epoch: 5.77 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05721875350907758		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.05721875350907758 | validation: 0.08365353480548338]
	TIME [epoch: 5.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834149741144635		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.05834149741144635 | validation: 0.07742761685080439]
	TIME [epoch: 5.73 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057299654665722025		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.057299654665722025 | validation: 0.07645999389389556]
	TIME [epoch: 5.73 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056825764671704554		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.056825764671704554 | validation: 0.08169101120265168]
	TIME [epoch: 5.73 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05393486810978341		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.05393486810978341 | validation: 0.08378448083245701]
	TIME [epoch: 5.73 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06042231938340024		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.06042231938340024 | validation: 0.0819438223404808]
	TIME [epoch: 5.74 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061720103800778775		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.061720103800778775 | validation: 0.08520347580047545]
	TIME [epoch: 5.76 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865416568286514		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.05865416568286514 | validation: 0.08670697630981287]
	TIME [epoch: 5.74 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376443368828347		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.06376443368828347 | validation: 0.08367499606939648]
	TIME [epoch: 5.73 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06462644918135099		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.06462644918135099 | validation: 0.07557181549404614]
	TIME [epoch: 5.73 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466302986936953		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.06466302986936953 | validation: 0.07831334860257644]
	TIME [epoch: 5.73 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230262651951272		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.06230262651951272 | validation: 0.077897476003696]
	TIME [epoch: 5.73 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06202559429514819		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.06202559429514819 | validation: 0.08009604326948136]
	TIME [epoch: 5.77 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05781650337295577		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.05781650337295577 | validation: 0.07875240471543067]
	TIME [epoch: 5.74 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06016168535576425		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.06016168535576425 | validation: 0.08723157802908517]
	TIME [epoch: 5.73 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699697434043892		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.05699697434043892 | validation: 0.0832167888829698]
	TIME [epoch: 5.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056750154610263705		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.056750154610263705 | validation: 0.08166757239884027]
	TIME [epoch: 5.73 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538357129679072		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.05538357129679072 | validation: 0.07854412866733715]
	TIME [epoch: 5.73 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058140703913566905		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.058140703913566905 | validation: 0.08351218192442525]
	TIME [epoch: 5.74 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493065673993783		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.05493065673993783 | validation: 0.07546550069308791]
	TIME [epoch: 5.76 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054029534761779574		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.054029534761779574 | validation: 0.0806766674385786]
	TIME [epoch: 5.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893985360531742		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.05893985360531742 | validation: 0.08686039650561714]
	TIME [epoch: 5.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055325193089653994		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.055325193089653994 | validation: 0.07687588773953138]
	TIME [epoch: 5.73 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904554015512983		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.05904554015512983 | validation: 0.07920820577760922]
	TIME [epoch: 5.74 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05911391282811671		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.05911391282811671 | validation: 0.07447933171477225]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05889409139885054		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.05889409139885054 | validation: 0.0769874727133574]
	TIME [epoch: 5.77 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05604763829150286		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.05604763829150286 | validation: 0.08611522689467375]
	TIME [epoch: 5.74 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017579450891668		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.06017579450891668 | validation: 0.07446460843420416]
	TIME [epoch: 5.74 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05821889320713207		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.05821889320713207 | validation: 0.08409328518576074]
	TIME [epoch: 5.73 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058950739474739194		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.058950739474739194 | validation: 0.08704049388919753]
	TIME [epoch: 5.73 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839912422478557		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05839912422478557 | validation: 0.07816423359312291]
	TIME [epoch: 5.73 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058080131252312706		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.058080131252312706 | validation: 0.08278310649716493]
	TIME [epoch: 5.75 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05563607558889016		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.05563607558889016 | validation: 0.07488802754682952]
	TIME [epoch: 5.76 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05705398231694383		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.05705398231694383 | validation: 0.08384167948066676]
	TIME [epoch: 5.74 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733998096542262		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.05733998096542262 | validation: 0.07764133708737771]
	TIME [epoch: 5.73 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05897650047884269		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.05897650047884269 | validation: 0.08242855992563566]
	TIME [epoch: 5.73 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05685561874792164		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.05685561874792164 | validation: 0.07488633104533406]
	TIME [epoch: 5.73 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05812744453672147		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.05812744453672147 | validation: 0.07835335242996233]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06011599587997161		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.06011599587997161 | validation: 0.07420474492103867]
	TIME [epoch: 5.77 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058873469796319876		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.058873469796319876 | validation: 0.08281862773195062]
	TIME [epoch: 5.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05915872493946811		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.05915872493946811 | validation: 0.08542408952247932]
	TIME [epoch: 5.73 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059111026579977285		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.059111026579977285 | validation: 0.0787429174530415]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05655032882460876		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.05655032882460876 | validation: 0.08783677231395846]
	TIME [epoch: 5.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060863885347174046		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.060863885347174046 | validation: 0.0765004873021456]
	TIME [epoch: 5.73 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055642080722660456		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.055642080722660456 | validation: 0.07702343812424055]
	TIME [epoch: 5.76 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05620669202445218		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.05620669202445218 | validation: 0.08705098006219476]
	TIME [epoch: 5.74 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711348697174576		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.05711348697174576 | validation: 0.07566599531997271]
	TIME [epoch: 5.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058727461293452056		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.058727461293452056 | validation: 0.0834125845255641]
	TIME [epoch: 5.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834237740329765		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.05834237740329765 | validation: 0.0814973280024768]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908656713215609		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.05908656713215609 | validation: 0.08466978468389798]
	TIME [epoch: 5.73 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05859751607968583		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.05859751607968583 | validation: 0.07161797492956146]
	TIME [epoch: 5.73 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05574510478465181		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.05574510478465181 | validation: 0.085387315499514]
	TIME [epoch: 5.77 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056224240465980166		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.056224240465980166 | validation: 0.0752865074160562]
	TIME [epoch: 5.74 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493534370365308		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.05493534370365308 | validation: 0.08275836027068283]
	TIME [epoch: 5.73 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06079070576760699		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.06079070576760699 | validation: 0.0846458919039058]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932554324058523		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.05932554324058523 | validation: 0.08083492741007861]
	TIME [epoch: 5.73 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054510409443624216		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.054510409443624216 | validation: 0.08346875155134795]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060453049117669785		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.060453049117669785 | validation: 0.0829268931801336]
	TIME [epoch: 5.76 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060421192747673734		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.060421192747673734 | validation: 0.0859036585646139]
	TIME [epoch: 5.75 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058420709105092		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.06058420709105092 | validation: 0.07682048598655879]
	TIME [epoch: 5.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05681728715983513		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.05681728715983513 | validation: 0.07615546882178151]
	TIME [epoch: 5.74 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05937315166356151		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.05937315166356151 | validation: 0.078083136185938]
	TIME [epoch: 5.73 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056296643389764395		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.056296643389764395 | validation: 0.07312865612478467]
	TIME [epoch: 5.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05729817597498994		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.05729817597498994 | validation: 0.08461431943394081]
	TIME [epoch: 5.74 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058871206324773946		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.058871206324773946 | validation: 0.08269576831002497]
	TIME [epoch: 5.77 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05864641952750129		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.05864641952750129 | validation: 0.08168942754740488]
	TIME [epoch: 5.74 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05932150851096685		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.05932150851096685 | validation: 0.0898519637285853]
	TIME [epoch: 5.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06114776478088671		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.06114776478088671 | validation: 0.08326987597626329]
	TIME [epoch: 5.73 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060611593661242594		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.060611593661242594 | validation: 0.08529795680602253]
	TIME [epoch: 5.73 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06123786869842182		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.06123786869842182 | validation: 0.07993458035525842]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05567299005965766		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.05567299005965766 | validation: 0.08455007573938887]
	TIME [epoch: 5.76 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05890449650267931		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.05890449650267931 | validation: 0.07787342480565186]
	TIME [epoch: 5.75 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603986931860638		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.05603986931860638 | validation: 0.07358317382478083]
	TIME [epoch: 5.74 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622146427996198		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.05622146427996198 | validation: 0.07792644715696827]
	TIME [epoch: 5.74 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617662484533331		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.05617662484533331 | validation: 0.07363700264809529]
	TIME [epoch: 5.73 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056918131564227446		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.056918131564227446 | validation: 0.07464253319173876]
	TIME [epoch: 5.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058369804021616734		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.058369804021616734 | validation: 0.08519226187332347]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053497194019872574		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.053497194019872574 | validation: 0.08189008287326517]
	TIME [epoch: 5.77 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245157509247892		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.06245157509247892 | validation: 0.0767895352263516]
	TIME [epoch: 5.74 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054619911476785084		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.054619911476785084 | validation: 0.08302815811153715]
	TIME [epoch: 5.73 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733676240176658		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.05733676240176658 | validation: 0.08175785969894356]
	TIME [epoch: 5.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056861810199588844		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.056861810199588844 | validation: 0.07373218104683726]
	TIME [epoch: 5.73 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888219806196359		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.05888219806196359 | validation: 0.07951972764822128]
	TIME [epoch: 5.73 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059503627227244005		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.059503627227244005 | validation: 0.08506029634755603]
	TIME [epoch: 5.76 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058000747388789235		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.058000747388789235 | validation: 0.0790210860541125]
	TIME [epoch: 5.75 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061457542537328005		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.061457542537328005 | validation: 0.07752582253805393]
	TIME [epoch: 5.74 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058245931665625		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.058245931665625 | validation: 0.07903639548985864]
	TIME [epoch: 5.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059298880160612424		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.059298880160612424 | validation: 0.08008683359644322]
	TIME [epoch: 5.73 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622097123178053		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.06622097123178053 | validation: 0.07778282200100171]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05854343028309254		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.05854343028309254 | validation: 0.07657640111894805]
	TIME [epoch: 5.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307877119696145		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.06307877119696145 | validation: 0.08266572008962676]
	TIME [epoch: 5.77 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321048386024675		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.06321048386024675 | validation: 0.08218656375187404]
	TIME [epoch: 5.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058172548764535655		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.058172548764535655 | validation: 0.08061964058899694]
	TIME [epoch: 5.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06037679078555141		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.06037679078555141 | validation: 0.08516562572111337]
	TIME [epoch: 5.74 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060343159246504734		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.060343159246504734 | validation: 0.0796382911627105]
	TIME [epoch: 5.73 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893753706569209		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.05893753706569209 | validation: 0.07473084239071712]
	TIME [epoch: 5.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05695673271160267		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.05695673271160267 | validation: 0.07730693201203372]
	TIME [epoch: 5.76 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055952081522460145		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.055952081522460145 | validation: 0.08306669574010346]
	TIME [epoch: 5.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05663710410366918		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.05663710410366918 | validation: 0.07874561882957659]
	TIME [epoch: 5.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057643064746025395		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.057643064746025395 | validation: 0.08259170751462001]
	TIME [epoch: 5.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058742166729165074		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.058742166729165074 | validation: 0.07888401881324895]
	TIME [epoch: 5.73 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744775827983488		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.05744775827983488 | validation: 0.08853920175958788]
	TIME [epoch: 5.73 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06068740502556738		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.06068740502556738 | validation: 0.0774099284633899]
	TIME [epoch: 5.74 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786240420207111		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.05786240420207111 | validation: 0.07923125808478668]
	TIME [epoch: 5.76 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06343175498319194		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.06343175498319194 | validation: 0.07969115652582176]
	TIME [epoch: 5.74 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060878452687292924		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.060878452687292924 | validation: 0.07514301238144737]
	TIME [epoch: 5.73 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05475975787578649		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.05475975787578649 | validation: 0.07946416011247905]
	TIME [epoch: 5.73 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056697403578745476		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.056697403578745476 | validation: 0.08364936260336464]
	TIME [epoch: 5.73 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896622706308551		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.05896622706308551 | validation: 0.07849204541532119]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961880704330412		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.05961880704330412 | validation: 0.08310560950368681]
	TIME [epoch: 5.77 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313257753721996		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.06313257753721996 | validation: 0.08317232455671505]
	TIME [epoch: 5.74 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05915641228671394		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.05915641228671394 | validation: 0.08696918992037894]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06145546655300281		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.06145546655300281 | validation: 0.08185319322257771]
	TIME [epoch: 5.73 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843795846717904		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.05843795846717904 | validation: 0.06759657773931058]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1707.pth
	Model improved!!!
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052127282345543285		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.052127282345543285 | validation: 0.07816272536121349]
	TIME [epoch: 5.74 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060850983470905236		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.060850983470905236 | validation: 0.09444125250874139]
	TIME [epoch: 5.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058987220987156086		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.058987220987156086 | validation: 0.08558492236217446]
	TIME [epoch: 5.76 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060066231765652324		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.060066231765652324 | validation: 0.0786534496543469]
	TIME [epoch: 5.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056397478535088835		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.056397478535088835 | validation: 0.08362652260739271]
	TIME [epoch: 5.73 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05694668967681074		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.05694668967681074 | validation: 0.07912953961179206]
	TIME [epoch: 5.73 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05587220799599135		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.05587220799599135 | validation: 0.07456349158374823]
	TIME [epoch: 5.73 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054333245169354505		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.054333245169354505 | validation: 0.08045290140320954]
	TIME [epoch: 5.73 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059083722727078944		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.059083722727078944 | validation: 0.08172975919390711]
	TIME [epoch: 5.77 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0599474988280445		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.0599474988280445 | validation: 0.07267686951083871]
	TIME [epoch: 5.74 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05895364939190445		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.05895364939190445 | validation: 0.08095238868374591]
	TIME [epoch: 5.73 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05886104894283861		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.05886104894283861 | validation: 0.07895736740707139]
	TIME [epoch: 5.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058103497574885914		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.058103497574885914 | validation: 0.0823498836049189]
	TIME [epoch: 5.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05755112646803785		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.05755112646803785 | validation: 0.07879639349890004]
	TIME [epoch: 5.73 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06292474307741705		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.06292474307741705 | validation: 0.08206656516521652]
	TIME [epoch: 5.75 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159267148137643		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.06159267148137643 | validation: 0.07870793395950211]
	TIME [epoch: 5.75 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873833319297915		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.05873833319297915 | validation: 0.07774728346373903]
	TIME [epoch: 5.73 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717974822039161		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.05717974822039161 | validation: 0.07584152007422772]
	TIME [epoch: 5.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521956343666882		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.05521956343666882 | validation: 0.08277969182294219]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556171242112963		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.0556171242112963 | validation: 0.07781535652096827]
	TIME [epoch: 5.73 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058703142567498444		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.058703142567498444 | validation: 0.07401654478847151]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056588252487741825		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.056588252487741825 | validation: 0.08447372307210423]
	TIME [epoch: 5.77 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05901871675119631		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.05901871675119631 | validation: 0.07445868935302703]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057199900589354806		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.057199900589354806 | validation: 0.0800614291574232]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05306784016650923		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.05306784016650923 | validation: 0.08781678290415336]
	TIME [epoch: 5.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873531063269674		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.05873531063269674 | validation: 0.0832079452239528]
	TIME [epoch: 5.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05739292531202962		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.05739292531202962 | validation: 0.07621749112375159]
	TIME [epoch: 5.73 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059187090808048994		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.059187090808048994 | validation: 0.0854298024612685]
	TIME [epoch: 5.76 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05709341664468209		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.05709341664468209 | validation: 0.08721492304505465]
	TIME [epoch: 5.74 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0593932028144606		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.0593932028144606 | validation: 0.0802664585967239]
	TIME [epoch: 5.74 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056657644300088586		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.056657644300088586 | validation: 0.0801360798808604]
	TIME [epoch: 5.73 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05874830941711505		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.05874830941711505 | validation: 0.08318844630710569]
	TIME [epoch: 5.73 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05665023154489729		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.05665023154489729 | validation: 0.07455862088623334]
	TIME [epoch: 5.73 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05707620400473967		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.05707620400473967 | validation: 0.08330387149806644]
	TIME [epoch: 5.74 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0575427027784264		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0575427027784264 | validation: 0.08154780787792353]
	TIME [epoch: 5.77 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05599159607679281		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.05599159607679281 | validation: 0.07639492101082694]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0594356193838798		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.0594356193838798 | validation: 0.07119542980399113]
	TIME [epoch: 5.73 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900261180864584		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.05900261180864584 | validation: 0.08222154168733421]
	TIME [epoch: 5.73 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627572086268791		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.05627572086268791 | validation: 0.07592184906434932]
	TIME [epoch: 5.73 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058896720372991075		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.058896720372991075 | validation: 0.08367207369436017]
	TIME [epoch: 5.73 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05711273009168847		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.05711273009168847 | validation: 0.08150472095878179]
	TIME [epoch: 5.75 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059648992006025844		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.059648992006025844 | validation: 0.08231911081791783]
	TIME [epoch: 5.74 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565683821775103		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0565683821775103 | validation: 0.07671216946438858]
	TIME [epoch: 5.73 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187179987058909		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.06187179987058909 | validation: 0.08090617777954315]
	TIME [epoch: 5.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060781705895244995		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.060781705895244995 | validation: 0.07378501601585093]
	TIME [epoch: 5.73 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057392171606660256		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.057392171606660256 | validation: 0.08198495150586578]
	TIME [epoch: 5.73 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058019912641131446		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.058019912641131446 | validation: 0.07848148356195976]
	TIME [epoch: 5.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061333851268393004		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.061333851268393004 | validation: 0.07651320302260395]
	TIME [epoch: 5.77 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647126994800698		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.05647126994800698 | validation: 0.08759179913726943]
	TIME [epoch: 5.73 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023116988123962		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.06023116988123962 | validation: 0.07739354478805965]
	TIME [epoch: 5.73 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059394229562999466		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.059394229562999466 | validation: 0.08075737401064167]
	TIME [epoch: 5.73 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057608501500535716		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.057608501500535716 | validation: 0.07939581739558657]
	TIME [epoch: 5.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05962793970645036		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.05962793970645036 | validation: 0.07921697026495489]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058119646397065725		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.058119646397065725 | validation: 0.07956548577721259]
	TIME [epoch: 5.76 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0627409277894161		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.0627409277894161 | validation: 0.07591988154424813]
	TIME [epoch: 5.75 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05643595341247022		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.05643595341247022 | validation: 0.07467338502520632]
	TIME [epoch: 5.74 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058203062765191604		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.058203062765191604 | validation: 0.07422204135929002]
	TIME [epoch: 5.73 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05796292586756025		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.05796292586756025 | validation: 0.07906572289282499]
	TIME [epoch: 5.73 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05598266798945473		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.05598266798945473 | validation: 0.08230414630615107]
	TIME [epoch: 5.73 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964493610505696		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.05964493610505696 | validation: 0.08363328215500031]
	TIME [epoch: 5.73 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059362084600187597		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.059362084600187597 | validation: 0.08085897583621739]
	TIME [epoch: 5.77 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795826896426011		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.05795826896426011 | validation: 0.07388497651358131]
	TIME [epoch: 5.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05823260056251804		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.05823260056251804 | validation: 0.08110617175059058]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836183028584627		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.05836183028584627 | validation: 0.07744036282721987]
	TIME [epoch: 5.73 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053995294491395146		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.053995294491395146 | validation: 0.0773937738299874]
	TIME [epoch: 5.73 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059156582154541205		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.059156582154541205 | validation: 0.08172894756345427]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05337513942721939		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.05337513942721939 | validation: 0.0875593988507352]
	TIME [epoch: 5.76 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925490013600041		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.05925490013600041 | validation: 0.07753162750845105]
	TIME [epoch: 5.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05888567950608847		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.05888567950608847 | validation: 0.08202607362086191]
	TIME [epoch: 5.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05842906949629566		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.05842906949629566 | validation: 0.07684301368771565]
	TIME [epoch: 5.74 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470918261024904		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.05470918261024904 | validation: 0.07135363632893389]
	TIME [epoch: 5.73 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059183327767212655		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.059183327767212655 | validation: 0.07926288605807642]
	TIME [epoch: 5.73 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863448337056517		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.05863448337056517 | validation: 0.08000861015400224]
	TIME [epoch: 5.74 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953719527929199		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.05953719527929199 | validation: 0.08137141693696447]
	TIME [epoch: 5.76 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05841802813333713		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.05841802813333713 | validation: 0.07896008810368148]
	TIME [epoch: 5.73 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057893728207442464		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.057893728207442464 | validation: 0.08574505954949531]
	TIME [epoch: 5.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0562126505403979		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0562126505403979 | validation: 0.07715658025283614]
	TIME [epoch: 5.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699405971335646		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.05699405971335646 | validation: 0.07783125675734816]
	TIME [epoch: 5.73 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056582534978339684		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.056582534978339684 | validation: 0.08687457748285664]
	TIME [epoch: 5.73 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572341046386295		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.0572341046386295 | validation: 0.08357801337434487]
	TIME [epoch: 5.77 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0569142745966026		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.0569142745966026 | validation: 0.08495859851711723]
	TIME [epoch: 5.74 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058738866311031035		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.058738866311031035 | validation: 0.07171189551208183]
	TIME [epoch: 5.74 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057488488674417165		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.057488488674417165 | validation: 0.07376626237084177]
	TIME [epoch: 5.73 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714387944645415		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.05714387944645415 | validation: 0.07640503625037408]
	TIME [epoch: 5.73 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05826533889024055		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.05826533889024055 | validation: 0.07805167353366634]
	TIME [epoch: 5.73 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06508695688970255		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.06508695688970255 | validation: 0.08330053284091289]
	TIME [epoch: 5.74 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05839792266680917		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.05839792266680917 | validation: 0.08436354330165713]
	TIME [epoch: 5.76 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058811493048204204		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.058811493048204204 | validation: 0.07670350207519394]
	TIME [epoch: 5.73 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533001961349965		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.05533001961349965 | validation: 0.08132981890629225]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054457886826780114		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.054457886826780114 | validation: 0.07639009699270755]
	TIME [epoch: 5.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058736838469331906		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.058736838469331906 | validation: 0.0789779867613149]
	TIME [epoch: 5.73 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05646752126722811		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.05646752126722811 | validation: 0.084874771684217]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05513209793098601		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.05513209793098601 | validation: 0.07587609362321743]
	TIME [epoch: 5.77 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060817246538579006		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.060817246538579006 | validation: 0.0806060872833121]
	TIME [epoch: 5.74 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055940028124407654		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.055940028124407654 | validation: 0.07360562274054541]
	TIME [epoch: 5.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058163250232229374		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.058163250232229374 | validation: 0.07512422578428261]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06206641502441506		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.06206641502441506 | validation: 0.0864686853300303]
	TIME [epoch: 5.73 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05824369336798917		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.05824369336798917 | validation: 0.07731558549084235]
	TIME [epoch: 5.73 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06046154513504271		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.06046154513504271 | validation: 0.07755273859788034]
	TIME [epoch: 5.74 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055252401877159615		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.055252401877159615 | validation: 0.08385914507337187]
	TIME [epoch: 5.76 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058246369803909875		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.058246369803909875 | validation: 0.08635592012171742]
	TIME [epoch: 5.73 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683131396617418		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.05683131396617418 | validation: 0.07895917860170414]
	TIME [epoch: 5.74 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762054107355906		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.05762054107355906 | validation: 0.07923760691904176]
	TIME [epoch: 5.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059983510185318056		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.059983510185318056 | validation: 0.08565457043043682]
	TIME [epoch: 5.73 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056005449374234975		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.056005449374234975 | validation: 0.08296037407346064]
	TIME [epoch: 5.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0578707254569644		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.0578707254569644 | validation: 0.07766589037945472]
	TIME [epoch: 5.77 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05791421816608809		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.05791421816608809 | validation: 0.08121017796067723]
	TIME [epoch: 5.74 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060817131702207795		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.060817131702207795 | validation: 0.08023768193735192]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744798234846876		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.05744798234846876 | validation: 0.0815269249721101]
	TIME [epoch: 5.73 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059078506634211256		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.059078506634211256 | validation: 0.08302889246033285]
	TIME [epoch: 5.74 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05778573339406718		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.05778573339406718 | validation: 0.083601213801874]
	TIME [epoch: 5.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060260482742018714		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.060260482742018714 | validation: 0.07706123475391334]
	TIME [epoch: 5.74 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05609624542863299		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.05609624542863299 | validation: 0.07933670666121803]
	TIME [epoch: 5.76 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05829681101511072		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.05829681101511072 | validation: 0.08377836005150936]
	TIME [epoch: 5.74 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966199798876461		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.05966199798876461 | validation: 0.0782325369756703]
	TIME [epoch: 5.74 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997083217410257		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.05997083217410257 | validation: 0.07723916670270119]
	TIME [epoch: 5.73 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059973237847692866		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.059973237847692866 | validation: 0.08155136488065833]
	TIME [epoch: 5.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06007659279949962		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.06007659279949962 | validation: 0.08087781360934265]
	TIME [epoch: 5.74 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057561109824586704		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.057561109824586704 | validation: 0.08461363155255086]
	TIME [epoch: 5.77 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06126577172054734		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.06126577172054734 | validation: 0.07992374857237187]
	TIME [epoch: 5.74 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577326525739867		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0577326525739867 | validation: 0.07687399336318444]
	TIME [epoch: 5.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06084868823391733		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.06084868823391733 | validation: 0.07233141301476226]
	TIME [epoch: 5.73 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05904968845824372		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.05904968845824372 | validation: 0.07965724859831017]
	TIME [epoch: 5.73 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0578017847032075		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0578017847032075 | validation: 0.0793890453734074]
	TIME [epoch: 5.73 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744634928160018		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.05744634928160018 | validation: 0.07607549915407283]
	TIME [epoch: 5.76 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718596246975801		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.05718596246975801 | validation: 0.07922887834673939]
	TIME [epoch: 5.74 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595625253701239		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.05595625253701239 | validation: 0.07498260068444287]
	TIME [epoch: 5.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706296020728706		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.05706296020728706 | validation: 0.08286082626713295]
	TIME [epoch: 5.73 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925697803494625		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.05925697803494625 | validation: 0.07645727500696062]
	TIME [epoch: 5.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059790408285941246		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.059790408285941246 | validation: 0.0719190804711584]
	TIME [epoch: 5.73 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058036605575017344		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.058036605575017344 | validation: 0.07710980060504993]
	TIME [epoch: 5.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0532137913275625		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.0532137913275625 | validation: 0.0736486520120173]
	TIME [epoch: 5.77 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05706546441476891		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.05706546441476891 | validation: 0.08336886982097359]
	TIME [epoch: 5.74 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015802479488193		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.06015802479488193 | validation: 0.07850060518652789]
	TIME [epoch: 5.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053756265971973895		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.053756265971973895 | validation: 0.08171601575264084]
	TIME [epoch: 5.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059188771819597086		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.059188771819597086 | validation: 0.08459189022291566]
	TIME [epoch: 5.73 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05640417728200685		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.05640417728200685 | validation: 0.08033165679729161]
	TIME [epoch: 5.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762546794564312		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.05762546794564312 | validation: 0.08398122752041076]
	TIME [epoch: 5.76 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05675898175912457		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.05675898175912457 | validation: 0.08837847086644848]
	TIME [epoch: 5.74 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06043201281275795		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.06043201281275795 | validation: 0.08059644270881279]
	TIME [epoch: 5.73 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714868078009539		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.05714868078009539 | validation: 0.08070279484410758]
	TIME [epoch: 5.74 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817396534640791		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.05817396534640791 | validation: 0.08293483557153758]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05683184552145577		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.05683184552145577 | validation: 0.08420219885523238]
	TIME [epoch: 5.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05764031348696097		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.05764031348696097 | validation: 0.08408961106390439]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05610395056293725		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.05610395056293725 | validation: 0.08337957989562594]
	TIME [epoch: 5.77 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543016140616803		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.05543016140616803 | validation: 0.07853785852739398]
	TIME [epoch: 5.74 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056609486562184626		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.056609486562184626 | validation: 0.07669688010587397]
	TIME [epoch: 5.73 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627899177263502		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.05627899177263502 | validation: 0.08861054373138619]
	TIME [epoch: 5.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05669575363425591		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.05669575363425591 | validation: 0.07777967532790762]
	TIME [epoch: 5.73 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055722086755707806		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.055722086755707806 | validation: 0.07477171095714094]
	TIME [epoch: 5.73 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05350542191973224		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.05350542191973224 | validation: 0.07825021320107091]
	TIME [epoch: 5.76 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05602589939632152		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.05602589939632152 | validation: 0.08119505064537164]
	TIME [epoch: 5.74 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563482934209458		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.0563482934209458 | validation: 0.06780838572233813]
	TIME [epoch: 5.73 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05417550394709822		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.05417550394709822 | validation: 0.07679921181641676]
	TIME [epoch: 5.73 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452105644781606		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.05452105644781606 | validation: 0.07487742084135988]
	TIME [epoch: 5.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658892044676909		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.05658892044676909 | validation: 0.0796845156397466]
	TIME [epoch: 5.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05694322854099202		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.05694322854099202 | validation: 0.08761580467760731]
	TIME [epoch: 5.74 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654977821451344		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.05654977821451344 | validation: 0.08107904638023436]
	TIME [epoch: 5.77 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05459101381952528		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.05459101381952528 | validation: 0.07791182841380134]
	TIME [epoch: 5.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054377008675864924		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.054377008675864924 | validation: 0.07742872618521458]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056001076853119246		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.056001076853119246 | validation: 0.08484620407290556]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837315750825354		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.05837315750825354 | validation: 0.08522164980819179]
	TIME [epoch: 5.73 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057303552611988426		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.057303552611988426 | validation: 0.07599928713629885]
	TIME [epoch: 5.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05752588134724061		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.05752588134724061 | validation: 0.07910779602925871]
	TIME [epoch: 5.76 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057446801948496336		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.057446801948496336 | validation: 0.08166118197518124]
	TIME [epoch: 5.75 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05965067746905607		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.05965067746905607 | validation: 0.0757085347192773]
	TIME [epoch: 5.74 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543587712935161		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.05543587712935161 | validation: 0.07360806940380045]
	TIME [epoch: 5.73 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470065368186919		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.05470065368186919 | validation: 0.07335918984087847]
	TIME [epoch: 5.73 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054441550625243654		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.054441550625243654 | validation: 0.08563605836494347]
	TIME [epoch: 5.73 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056460416711257996		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.056460416711257996 | validation: 0.0804066902764842]
	TIME [epoch: 5.73 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055431037303430505		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.055431037303430505 | validation: 0.08156866328125296]
	TIME [epoch: 5.76 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05979441325532496		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.05979441325532496 | validation: 0.07395035920536733]
	TIME [epoch: 5.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058044996551467776		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.058044996551467776 | validation: 0.07911540290778335]
	TIME [epoch: 5.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05671550466240077		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.05671550466240077 | validation: 0.08424142632452358]
	TIME [epoch: 5.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059805730869353355		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.059805730869353355 | validation: 0.08203423733412735]
	TIME [epoch: 5.73 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05555759916934761		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.05555759916934761 | validation: 0.07521122586960927]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05790821528875192		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.05790821528875192 | validation: 0.08216100945285668]
	TIME [epoch: 5.76 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06039061328181838		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.06039061328181838 | validation: 0.08620254481125365]
	TIME [epoch: 5.74 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059076649493005576		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.059076649493005576 | validation: 0.07466459773954426]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05588497429418147		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.05588497429418147 | validation: 0.07026999917265346]
	TIME [epoch: 5.73 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05595043243644381		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.05595043243644381 | validation: 0.07968086007789248]
	TIME [epoch: 5.73 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060161800845625106		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.060161800845625106 | validation: 0.07821787577292377]
	TIME [epoch: 5.73 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648351821568553		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.05648351821568553 | validation: 0.0761113057161512]
	TIME [epoch: 5.74 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05658507145335358		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.05658507145335358 | validation: 0.07176557120347819]
	TIME [epoch: 5.76 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429571246124657		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.05429571246124657 | validation: 0.07445784049848776]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05851296719250258		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.05851296719250258 | validation: 0.08375524582652602]
	TIME [epoch: 5.73 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05424070012929026		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.05424070012929026 | validation: 0.07220103568132338]
	TIME [epoch: 5.73 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056681406415688126		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.056681406415688126 | validation: 0.07964399469108137]
	TIME [epoch: 5.73 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05582183457458162		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.05582183457458162 | validation: 0.08034087986971968]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491498919863525		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.05491498919863525 | validation: 0.06360177047793342]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240310_035550/states/model_tr_study202_1897.pth
	Model improved!!!
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058159405371154715		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.058159405371154715 | validation: 0.07529278957006433]
	TIME [epoch: 5.74 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0554254145116764		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.0554254145116764 | validation: 0.07566711207848352]
	TIME [epoch: 5.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0571048577918118		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.0571048577918118 | validation: 0.07987553660553935]
	TIME [epoch: 5.73 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05740693254277509		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.05740693254277509 | validation: 0.07855287986525988]
	TIME [epoch: 5.73 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058876287152853396		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.058876287152853396 | validation: 0.08136143231679331]
	TIME [epoch: 5.73 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05127603611237271		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.05127603611237271 | validation: 0.08864615106295659]
	TIME [epoch: 5.74 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058038801881956516		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.058038801881956516 | validation: 0.07778406412208337]
	TIME [epoch: 5.76 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05733686192332834		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.05733686192332834 | validation: 0.07431655139357064]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597285100108201		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.05597285100108201 | validation: 0.08873658287597783]
	TIME [epoch: 5.73 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480140692051973		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.05480140692051973 | validation: 0.07886966812975113]
	TIME [epoch: 5.74 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05466937681191329		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.05466937681191329 | validation: 0.07230601509225959]
	TIME [epoch: 5.73 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05480179207395209		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.05480179207395209 | validation: 0.08244391225001964]
	TIME [epoch: 5.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553596034998511		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.0553596034998511 | validation: 0.07715752859388743]
	TIME [epoch: 5.77 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05820176758721591		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.05820176758721591 | validation: 0.08024422412421409]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006590124654987		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.06006590124654987 | validation: 0.08324862799869416]
	TIME [epoch: 5.74 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779874081039799		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.05779874081039799 | validation: 0.07885489746136196]
	TIME [epoch: 5.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511621146241586		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.05511621146241586 | validation: 0.08027623305403751]
	TIME [epoch: 5.73 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0583163824314448		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.0583163824314448 | validation: 0.07868282479655371]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058481556527145914		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.058481556527145914 | validation: 0.07754826507911204]
	TIME [epoch: 5.76 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058429264731000324		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.058429264731000324 | validation: 0.07710608292266491]
	TIME [epoch: 5.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691474999786254		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.05691474999786254 | validation: 0.08009197282144896]
	TIME [epoch: 5.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054789514614626		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.054789514614626 | validation: 0.08212147809854699]
	TIME [epoch: 5.73 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05464337660797494		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.05464337660797494 | validation: 0.08035482711905174]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054584052499550506		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.054584052499550506 | validation: 0.0784786170510277]
	TIME [epoch: 5.73 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05804543912331735		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.05804543912331735 | validation: 0.08059964205568715]
	TIME [epoch: 5.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055907100963158846		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.055907100963158846 | validation: 0.0800357699090354]
	TIME [epoch: 5.77 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058283024779544015		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.058283024779544015 | validation: 0.07774685565047136]
	TIME [epoch: 5.74 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06173229095246792		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.06173229095246792 | validation: 0.07484614584021305]
	TIME [epoch: 5.73 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368266336343281		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.05368266336343281 | validation: 0.07867765132918708]
	TIME [epoch: 5.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055521008583813265		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.055521008583813265 | validation: 0.0742460857403981]
	TIME [epoch: 5.73 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057878872736072035		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.057878872736072035 | validation: 0.07474543419597296]
	TIME [epoch: 5.73 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056994205340992345		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.056994205340992345 | validation: 0.08333954198219658]
	TIME [epoch: 5.76 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360954325528213		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.05360954325528213 | validation: 0.07908237829364262]
	TIME [epoch: 5.75 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05564437235708362		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.05564437235708362 | validation: 0.08480823395069727]
	TIME [epoch: 5.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05391603758736965		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.05391603758736965 | validation: 0.07617237532928427]
	TIME [epoch: 5.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0514661534741071		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.0514661534741071 | validation: 0.07861399892211086]
	TIME [epoch: 5.74 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05823793722151		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.05823793722151 | validation: 0.07707295059122271]
	TIME [epoch: 5.73 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057718098948643395		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.057718098948643395 | validation: 0.07589716539252223]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545591793277658		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.0545591793277658 | validation: 0.0803315171737255]
	TIME [epoch: 5.77 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058008209307199604		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.058008209307199604 | validation: 0.0821901639451201]
	TIME [epoch: 5.73 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758687731804621		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.05758687731804621 | validation: 0.08338619653018654]
	TIME [epoch: 5.73 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060374466889956374		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.060374466889956374 | validation: 0.07456502735325272]
	TIME [epoch: 5.73 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05774190081371086		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.05774190081371086 | validation: 0.06714835627705497]
	TIME [epoch: 5.73 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05493599824657697		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.05493599824657697 | validation: 0.07800918538035542]
	TIME [epoch: 5.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469671645748801		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.05469671645748801 | validation: 0.07603705896548317]
	TIME [epoch: 5.76 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0601072786638701		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.0601072786638701 | validation: 0.08226604561924797]
	TIME [epoch: 5.74 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05465697434312405		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.05465697434312405 | validation: 0.07988399324153916]
	TIME [epoch: 5.74 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760236119084407		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.05760236119084407 | validation: 0.08846301096526812]
	TIME [epoch: 5.73 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05821338889198247		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.05821338889198247 | validation: 0.07718450545863713]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05712849866724363		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.05712849866724363 | validation: 0.07910001515511406]
	TIME [epoch: 5.73 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561824875127329		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.0561824875127329 | validation: 0.07666871564137574]
	TIME [epoch: 5.74 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0556516768712403		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.0556516768712403 | validation: 0.0806826580657778]
	TIME [epoch: 5.77 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054253105841309414		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.054253105841309414 | validation: 0.08021243810265069]
	TIME [epoch: 5.74 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05692910003958771		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.05692910003958771 | validation: 0.0793712126116904]
	TIME [epoch: 5.73 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059122304246951744		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.059122304246951744 | validation: 0.07824665289924686]
	TIME [epoch: 5.73 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05795601194029333		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.05795601194029333 | validation: 0.07693747281484387]
	TIME [epoch: 5.73 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05947180147474726		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.05947180147474726 | validation: 0.0785455828993433]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659047982752223		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.05659047982752223 | validation: 0.08081782013491104]
	TIME [epoch: 5.77 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05623577779272926		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.05623577779272926 | validation: 0.07869818066047345]
	TIME [epoch: 5.74 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060197104570012254		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.060197104570012254 | validation: 0.07895524528342097]
	TIME [epoch: 5.73 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05437198402209137		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.05437198402209137 | validation: 0.07226049799730869]
	TIME [epoch: 5.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05894644613646744		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.05894644613646744 | validation: 0.08729379056875079]
	TIME [epoch: 5.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858200014353227		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.05858200014353227 | validation: 0.07219988686023199]
	TIME [epoch: 5.73 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05410053843820682		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.05410053843820682 | validation: 0.08148460124509682]
	TIME [epoch: 5.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758037617600395		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.05758037617600395 | validation: 0.07253850743458887]
	TIME [epoch: 5.76 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523419456983516		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.05523419456983516 | validation: 0.07730851788604538]
	TIME [epoch: 5.74 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538975684575374		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.05538975684575374 | validation: 0.07765849663890798]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926003083457389		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.05926003083457389 | validation: 0.08225494849582077]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057986529118813794		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.057986529118813794 | validation: 0.07250503038691523]
	TIME [epoch: 5.73 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05704592439969111		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.05704592439969111 | validation: 0.07797201909304206]
	TIME [epoch: 5.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05687127151077435		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.05687127151077435 | validation: 0.07634157151095124]
	TIME [epoch: 5.77 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054353459977140695		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.054353459977140695 | validation: 0.0806818858520126]
	TIME [epoch: 5.74 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05526083785848156		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.05526083785848156 | validation: 0.07457491381351176]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05713466918633797		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.05713466918633797 | validation: 0.07734897330715856]
	TIME [epoch: 5.73 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059883374433831515		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.059883374433831515 | validation: 0.07730101727379206]
	TIME [epoch: 5.73 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06158911790447707		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.06158911790447707 | validation: 0.07490632343733294]
	TIME [epoch: 5.73 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05750364466772749		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.05750364466772749 | validation: 0.08196873972142511]
	TIME [epoch: 5.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05526024008375469		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.05526024008375469 | validation: 0.0835196122653609]
	TIME [epoch: 5.76 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570187367793778		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.05570187367793778 | validation: 0.0732847885660709]
	TIME [epoch: 5.74 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058612924168534614		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.058612924168534614 | validation: 0.07434900529723136]
	TIME [epoch: 5.73 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05846334700079382		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.05846334700079382 | validation: 0.07875908620167525]
	TIME [epoch: 5.73 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06044158386789998		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.06044158386789998 | validation: 0.07850234123521804]
	TIME [epoch: 5.73 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05793059594363622		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.05793059594363622 | validation: 0.08014290224338723]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059122313946442365		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.059122313946442365 | validation: 0.0862369986244289]
	TIME [epoch: 5.77 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604504814481269		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.0604504814481269 | validation: 0.07817337802503327]
	TIME [epoch: 5.74 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320394817552924		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.05320394817552924 | validation: 0.07373638312750823]
	TIME [epoch: 5.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056267884417123784		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.056267884417123784 | validation: 0.07211841661977524]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353746030218074		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.06353746030218074 | validation: 0.07883219275376907]
	TIME [epoch: 5.73 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05831253023242568		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.05831253023242568 | validation: 0.08372562101934795]
	TIME [epoch: 5.73 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053202905929823636		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.053202905929823636 | validation: 0.07773457972195431]
	TIME [epoch: 5.74 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05473387784336891		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.05473387784336891 | validation: 0.07962696523929931]
	TIME [epoch: 5.76 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908090211365363		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.05908090211365363 | validation: 0.0754711460828591]
	TIME [epoch: 5.74 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057141195440982465		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.057141195440982465 | validation: 0.0714964709798246]
	TIME [epoch: 5.74 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05665784132836981		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.05665784132836981 | validation: 0.08047822166587743]
	TIME [epoch: 5.73 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0581104451761974		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.0581104451761974 | validation: 0.07919111029444968]
	TIME [epoch: 5.73 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061277165444321754		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.061277165444321754 | validation: 0.08228605000487167]
	TIME [epoch: 5.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06105190364873304		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.06105190364873304 | validation: 0.07173868954877949]
	TIME [epoch: 5.77 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051704408002785626		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.051704408002785626 | validation: 0.08125734877584777]
	TIME [epoch: 5.74 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056268977483801254		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.056268977483801254 | validation: 0.07439528486949862]
	TIME [epoch: 5.73 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910758722660782		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.05910758722660782 | validation: 0.07799230802731871]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057146196479492165		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.057146196479492165 | validation: 0.07252870417975214]
	TIME [epoch: 5.73 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718809302115692		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.05718809302115692 | validation: 0.06750193201575048]
	TIME [epoch: 5.73 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598223831883044		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.0598223831883044 | validation: 0.08566093199080736]
	TIME [epoch: 5.76 sec]
Finished training in 11683.120 seconds.
