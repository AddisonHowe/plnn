Args:
Namespace(name='model_tr_study202', outdir='out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5', training_data='data/transition_rate_studies/tr_study202/tr_study202_training/r5', validation_data='data/transition_rate_studies/tr_study202/tr_study202_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1574287864

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/20] avg loss: 11.840536828519467		[learning rate: 0.01]
		[batch 20/20] avg loss: 10.292708345230354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.06662258687491 | validation: 9.845279710556758]
	TIME [epoch: 53.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/20] avg loss: 8.93202678255339		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.543115406746203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.237571094649798 | validation: 6.7397979025666315]
	TIME [epoch: 8.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.692362968572877		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.4515216847761865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.071942326674533 | validation: 6.305068883629643]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.744533104820658		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.751396928711644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.747965016766152 | validation: 4.863948226607306]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.609835484821451		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.1317070309436215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.370771257882535 | validation: 4.0100780971559935]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.003597840766246		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.753528392852872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.878563116809559 | validation: 5.134976874783397]
	TIME [epoch: 8.47 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.713262718409795		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.997989719803838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.855626219106817 | validation: 3.737069260766233]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.731349128236468		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.6054717256840703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6684104269602686 | validation: 4.001323507209068]
	TIME [epoch: 8.44 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.6004246434830685		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4555178001175975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.527971221800333 | validation: 3.8352784816985563]
	TIME [epoch: 8.47 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.3917354133992097		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5251313529151767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4584333831571934 | validation: 3.639532214803941]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.291469692688083		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.460624138171557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3760469154298205 | validation: 3.5318535185594353]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2850585234552474		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.251151340053773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.268104931754511 | validation: 4.056251110893447]
	TIME [epoch: 8.44 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1785558550915214		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.286009216064845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2322825355781832 | validation: 3.621719730191034]
	TIME [epoch: 8.52 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.263812380925831		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2579027096260527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.260857545275942 | validation: 3.588887610806013]
	TIME [epoch: 8.46 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0854287283549082		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2440107969843597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.164719762669633 | validation: 3.733996488850942]
	TIME [epoch: 8.45 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0190975029892373		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2534004649774646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.136248983983351 | validation: 3.283054885187428]
	TIME [epoch: 8.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1815608921575658		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1896817289013133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1856213105294393 | validation: 3.3901303219101813]
	TIME [epoch: 8.49 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.057870394145128		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2891858069672266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.173528100556177 | validation: 4.075399505303472]
	TIME [epoch: 8.44 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2368074042226516		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.3661810848043814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.301494244513516 | validation: 3.941559386731207]
	TIME [epoch: 8.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1445970905714824		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.04570042198586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0951487562786713 | validation: 4.187940635714629]
	TIME [epoch: 8.52 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.9857717781815944		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0987030621945086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.042237420188052 | validation: 3.821684294069174]
	TIME [epoch: 8.45 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1723259976608906		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8721526974933305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.02223934757711 | validation: 3.5366718618468296]
	TIME [epoch: 8.45 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1831405848269703		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8539098801534064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0185252324901883 | validation: 3.232803160807921]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0276293358200017		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9598436436841458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9937364897520737 | validation: 3.3625614090065223]
	TIME [epoch: 8.46 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.9682511397165454		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9373324752994727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9527918075080093 | validation: 3.088843807461501]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.9205407352155186		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8784246071979607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.89948267120674 | validation: 3.0308837480131454]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.900648019955063		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7335364112785645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.817092215616814 | validation: 3.067731804470708]
	TIME [epoch: 8.46 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.962925391304913		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8823432627638175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9226343270343653 | validation: 2.9709233639632266]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.8594253947609984		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7986749589153233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8290501768381606 | validation: 3.6747239470924313]
	TIME [epoch: 8.45 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.823927392125049		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.857376695690392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8406520439077205 | validation: 3.2425855637797407]
	TIME [epoch: 8.43 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.8181647739094577		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7970646897542992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8076147318318787 | validation: 3.5759076056470636]
	TIME [epoch: 8.46 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.822805983738704		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.727967721703308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.775386852721006 | validation: 3.3488269577611396]
	TIME [epoch: 8.44 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.699039632986369		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.83896102550264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7690003292445047 | validation: 2.9414665738295707]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.812049650687101		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7375038828414224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.774776766764262 | validation: 2.970218620848155]
	TIME [epoch: 8.44 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.658227198530255		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.642822535077845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6505248668040493 | validation: 2.930535761487653]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.6832324540261525		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6290432593314343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.656137856678794 | validation: 3.3997089759820254]
	TIME [epoch: 8.44 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.7544671184235026		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.5624048984972414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.658436008460372 | validation: 3.2094200684327316]
	TIME [epoch: 8.44 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.583416919142638		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.636086621967901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6097517705552695 | validation: 2.917800220930162]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.6928177571374925		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.5209833380374906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6069005475874913 | validation: 3.1228303640180317]
	TIME [epoch: 8.46 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.692719330857343		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.459675916704243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5761976237807938 | validation: 2.7163293141769222]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.3947010220969482		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8662844976424875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.630492759869718 | validation: 2.754607134669554]
	TIME [epoch: 8.46 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.396834511077768		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9067733960994753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6518039535886215 | validation: 2.7281557888528187]
	TIME [epoch: 8.46 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.4268533133646786		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.5542371807988562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.990545247081767 | validation: 1.0770837803393996]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2056532414193863		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2022051912000624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2039292163097242 | validation: 0.9861397065382965]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0804884784203268		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.2521554138770825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1663219461487047 | validation: 0.9691985379872983]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.100770952581741		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.1126143462250067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.106692649403374 | validation: 0.8224417728741329]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0470143618272607		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9419773130570528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9944958374421569 | validation: 1.1583888601099992]
	TIME [epoch: 8.43 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9500276987317843		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9299886277750483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9400081632534162 | validation: 0.7731273595945274]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0495618705630458		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8548310544026503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9521964624828481 | validation: 1.0546398964226225]
	TIME [epoch: 8.43 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0623684338341062		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.861967742113144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.962168087973625 | validation: 0.8492597995469046]
	TIME [epoch: 8.47 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.369286099506351		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8525786748202521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1109323871633017 | validation: 0.7442901549847138]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.860918355698612		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7786764964082078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.81979742605341 | validation: 1.1730064940561644]
	TIME [epoch: 8.44 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0180598121003643		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9246825260025513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9713711690514579 | validation: 1.495150056181142]
	TIME [epoch: 8.45 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9377876302956587		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7929102218674549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8653489260815567 | validation: 0.9218505754059529]
	TIME [epoch: 8.44 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1687553539029598		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8090130781057526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9888842160043563 | validation: 0.588738493138786]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7957820217238292		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.0836850750737042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9397335483987668 | validation: 0.74401543325585]
	TIME [epoch: 8.43 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9452583394321277		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7832562095537317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8642572744929297 | validation: 0.8552521312665504]
	TIME [epoch: 8.45 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0386910397635227		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8495965358279731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9441437877957478 | validation: 0.6339693172985429]
	TIME [epoch: 8.46 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7530662370398752		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7547629410509628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7539145890454191 | validation: 0.7489125769797828]
	TIME [epoch: 8.45 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.821873719985939		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.926785999442259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8743298597140992 | validation: 0.6645465856315693]
	TIME [epoch: 8.43 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9187461967827982		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9662676284532123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9425069126180053 | validation: 0.5540293821686428]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.684850132469954		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.851113845898021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7679819891839876 | validation: 0.8548286014215459]
	TIME [epoch: 8.42 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.0798204548841313		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7220355065548214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9009279807194762 | validation: 0.502734297979611]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8239003959263107		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6483199526878245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7361101743070677 | validation: 1.0535531724874758]
	TIME [epoch: 8.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7740372289645568		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.0007810215637882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8874091252641726 | validation: 1.0165039662981776]
	TIME [epoch: 8.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6385954995416327		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6868614367112295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6627284681264312 | validation: 1.364726479547858]
	TIME [epoch: 8.46 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7563223980547296		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9215420069678759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8389322025113026 | validation: 0.555883246577003]
	TIME [epoch: 8.45 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.722895236351208		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6567517427343535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6898234895427808 | validation: 0.7156048845043742]
	TIME [epoch: 8.49 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6912567791704355		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6997532451761277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6955050121732815 | validation: 1.0321635919730707]
	TIME [epoch: 8.46 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.661423797040144		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6858872049909099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6736555010155267 | validation: 0.4871730255699622]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.736021043712553		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6842816235796463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7101513336460996 | validation: 0.6213736644545701]
	TIME [epoch: 8.48 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6571717283467697		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7106661060628945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6839189172048321 | validation: 0.6547537561375345]
	TIME [epoch: 8.51 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8181424051576981		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6657117895100634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7419270973338807 | validation: 0.4726830287575997]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8198850426247285		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6442414750074572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7320632588160927 | validation: 0.41793661083779915]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6411599238343512		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5658973641226629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.603528643978507 | validation: 1.6540050065929761]
	TIME [epoch: 8.46 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6767780177823355		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6413196863784372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6590488520803863 | validation: 0.6272105672516178]
	TIME [epoch: 8.44 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7373185127575475		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7093152593431061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7233168860503267 | validation: 0.912968616333274]
	TIME [epoch: 8.44 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7193591291708317		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6551378848608154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6872485070158235 | validation: 1.2112611068228567]
	TIME [epoch: 8.46 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6946184011143228		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5584723021486192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6265453516314711 | validation: 0.5727169558443423]
	TIME [epoch: 8.44 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7540499438784576		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5890754701781462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.671562707028302 | validation: 0.5278081079400962]
	TIME [epoch: 8.43 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7303530268188121		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6207010146313977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.675527020725105 | validation: 0.52708277919703]
	TIME [epoch: 8.43 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6093365380229909		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5079354007679238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5586359693954575 | validation: 0.8028317521054752]
	TIME [epoch: 8.46 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5848936160820278		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7133678736099027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6491307448459654 | validation: 0.5227360766728321]
	TIME [epoch: 8.44 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5522912569281049		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6676910538977564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6099911554129307 | validation: 0.654704772966421]
	TIME [epoch: 8.43 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.586340445809963		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6424607008670484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.614400573338506 | validation: 0.47287726418539533]
	TIME [epoch: 8.44 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8717301586794916		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5780632540918914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7248967063856916 | validation: 0.7236128530747383]
	TIME [epoch: 8.45 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6278180418418949		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6578952401760038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6428566410089493 | validation: 0.45848049933963675]
	TIME [epoch: 8.48 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6805588934833648		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5166736206909572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5986162570871612 | validation: 0.5630010920229019]
	TIME [epoch: 8.42 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5778779736389076		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6398244915098055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6088512325743567 | validation: 0.5262236413008674]
	TIME [epoch: 8.45 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6329177260432377		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5740964801386225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.60350710309093 | validation: 1.0315412460231397]
	TIME [epoch: 8.45 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5930412818907702		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7246616749552208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6588514784229955 | validation: 0.43945557258394546]
	TIME [epoch: 8.43 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5883216504184889		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5958666756298105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5920941630241497 | validation: 0.3769965498144271]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5986820157938537		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.524305099285822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.561493557539838 | validation: 0.5512381886348421]
	TIME [epoch: 8.46 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6580120439860014		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5741737052636549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6160928746248281 | validation: 0.41301521303767524]
	TIME [epoch: 8.44 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.44132136613865036		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5755199546435201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5084206603910852 | validation: 0.41578273277264377]
	TIME [epoch: 8.43 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45028378808853436		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5456898158414484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49798680196499134 | validation: 0.53996529419895]
	TIME [epoch: 8.45 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.634939532373548		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7850461771006433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7099928547370957 | validation: 0.40775828290084415]
	TIME [epoch: 8.42 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.49922584790453656		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6466277834519458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5729268156782412 | validation: 0.4567232911679706]
	TIME [epoch: 8.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5462931327626973		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6713150421766377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6088040874696674 | validation: 0.4740528098998935]
	TIME [epoch: 8.41 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5107174704152062		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.592415181073949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5515663257445776 | validation: 0.7143474173233807]
	TIME [epoch: 8.44 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.537425944890848		[learning rate: 0.0099837]
		[batch 20/20] avg loss: 0.6296953044344048		[learning rate: 0.0099655]
	Learning Rate: 0.00996552
	LOSS [training: 0.5835606246626265 | validation: 0.49743062252060377]
	TIME [epoch: 8.41 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6100210132055677		[learning rate: 0.0099474]
		[batch 20/20] avg loss: 0.5197723973081902		[learning rate: 0.0099294]
	Learning Rate: 0.00992935
	LOSS [training: 0.564896705256879 | validation: 0.5951625382015994]
	TIME [epoch: 8.42 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.516587767249521		[learning rate: 0.0099113]
		[batch 20/20] avg loss: 0.5372711046377164		[learning rate: 0.0098933]
	Learning Rate: 0.00989332
	LOSS [training: 0.5269294359436187 | validation: 0.5912970426845365]
	TIME [epoch: 8.43 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5706347337316571		[learning rate: 0.0098754]
		[batch 20/20] avg loss: 0.524925283142571		[learning rate: 0.0098574]
	Learning Rate: 0.00985742
	LOSS [training: 0.5477800084371142 | validation: 0.6533741879215382]
	TIME [epoch: 8.42 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5203113847063529		[learning rate: 0.0098395]
		[batch 20/20] avg loss: 0.49458144313453467		[learning rate: 0.0098216]
	Learning Rate: 0.00982164
	LOSS [training: 0.5074464139204438 | validation: 0.605431950715495]
	TIME [epoch: 8.42 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5257272135798654		[learning rate: 0.0098038]
		[batch 20/20] avg loss: 0.5460541617005223		[learning rate: 0.009786]
	Learning Rate: 0.009786
	LOSS [training: 0.5358906876401939 | validation: 0.48850841483558344]
	TIME [epoch: 8.41 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.42090058446524364		[learning rate: 0.0097682]
		[batch 20/20] avg loss: 0.6270680723028375		[learning rate: 0.0097505]
	Learning Rate: 0.00975049
	LOSS [training: 0.5239843283840405 | validation: 0.7689604562987504]
	TIME [epoch: 8.45 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5087789150218928		[learning rate: 0.0097328]
		[batch 20/20] avg loss: 0.45780171281557475		[learning rate: 0.0097151]
	Learning Rate: 0.0097151
	LOSS [training: 0.4832903139187338 | validation: 0.5979079939644611]
	TIME [epoch: 8.42 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7181123507769428		[learning rate: 0.0096975]
		[batch 20/20] avg loss: 0.6265325793753614		[learning rate: 0.0096798]
	Learning Rate: 0.00967984
	LOSS [training: 0.6723224650761522 | validation: 0.42803603411922886]
	TIME [epoch: 8.41 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.48233071881615636		[learning rate: 0.0096623]
		[batch 20/20] avg loss: 0.5318819654857974		[learning rate: 0.0096447]
	Learning Rate: 0.00964472
	LOSS [training: 0.5071063421509767 | validation: 0.5774381816514657]
	TIME [epoch: 8.44 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5444204243151792		[learning rate: 0.0096272]
		[batch 20/20] avg loss: 0.4923256847478085		[learning rate: 0.0096097]
	Learning Rate: 0.00960972
	LOSS [training: 0.5183730545314941 | validation: 0.6610893825456732]
	TIME [epoch: 8.45 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5450127759102646		[learning rate: 0.0095923]
		[batch 20/20] avg loss: 0.48111070429520647		[learning rate: 0.0095748]
	Learning Rate: 0.00957484
	LOSS [training: 0.5130617401027355 | validation: 0.7456688872022785]
	TIME [epoch: 8.42 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.60199751523492		[learning rate: 0.0095575]
		[batch 20/20] avg loss: 0.7783554519628689		[learning rate: 0.0095401]
	Learning Rate: 0.00954009
	LOSS [training: 0.6901764835988945 | validation: 0.6527871092008499]
	TIME [epoch: 8.41 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5316271840409513		[learning rate: 0.0095228]
		[batch 20/20] avg loss: 0.5442323933536275		[learning rate: 0.0095055]
	Learning Rate: 0.00950547
	LOSS [training: 0.5379297886972895 | validation: 0.2493421508281566]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5106817788026057		[learning rate: 0.0094882]
		[batch 20/20] avg loss: 0.47392647490676254		[learning rate: 0.009471]
	Learning Rate: 0.00947098
	LOSS [training: 0.4923041268546841 | validation: 0.5627578082706131]
	TIME [epoch: 8.42 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5192126537521033		[learning rate: 0.0094538]
		[batch 20/20] avg loss: 0.6148433436408965		[learning rate: 0.0094366]
	Learning Rate: 0.0094366
	LOSS [training: 0.5670279986964999 | validation: 0.3693453861350372]
	TIME [epoch: 8.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.43576695235894175		[learning rate: 0.0094195]
		[batch 20/20] avg loss: 0.5378953832770582		[learning rate: 0.0094024]
	Learning Rate: 0.00940236
	LOSS [training: 0.48683116781799995 | validation: 0.4165121868554168]
	TIME [epoch: 8.45 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.583577590101582		[learning rate: 0.0093853]
		[batch 20/20] avg loss: 0.4695807044886372		[learning rate: 0.0093682]
	Learning Rate: 0.00936824
	LOSS [training: 0.5265791472951096 | validation: 0.2673109382780431]
	TIME [epoch: 8.44 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45188475774921627		[learning rate: 0.0093512]
		[batch 20/20] avg loss: 0.5871910032019478		[learning rate: 0.0093342]
	Learning Rate: 0.00933424
	LOSS [training: 0.5195378804755821 | validation: 0.5594076797422237]
	TIME [epoch: 8.42 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8038609650635321		[learning rate: 0.0093173]
		[batch 20/20] avg loss: 0.5282113466215472		[learning rate: 0.0093004]
	Learning Rate: 0.00930036
	LOSS [training: 0.6660361558425396 | validation: 0.6803752081627612]
	TIME [epoch: 8.44 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4808315207489267		[learning rate: 0.0092835]
		[batch 20/20] avg loss: 0.5476085530984378		[learning rate: 0.0092666]
	Learning Rate: 0.00926661
	LOSS [training: 0.5142200369236823 | validation: 0.5351902762247557]
	TIME [epoch: 8.46 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4505203811027504		[learning rate: 0.0092498]
		[batch 20/20] avg loss: 0.5095477489144405		[learning rate: 0.009233]
	Learning Rate: 0.00923298
	LOSS [training: 0.4800340650085954 | validation: 0.6171431655962487]
	TIME [epoch: 8.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.534873872113004		[learning rate: 0.0092162]
		[batch 20/20] avg loss: 0.4927777495642568		[learning rate: 0.0091995]
	Learning Rate: 0.00919948
	LOSS [training: 0.5138258108386303 | validation: 0.47326809616796706]
	TIME [epoch: 8.44 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.41271014617035284		[learning rate: 0.0091828]
		[batch 20/20] avg loss: 0.54785156377343		[learning rate: 0.0091661]
	Learning Rate: 0.00916609
	LOSS [training: 0.48028085497189144 | validation: 0.3206405951575646]
	TIME [epoch: 8.44 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5491330113304377		[learning rate: 0.0091494]
		[batch 20/20] avg loss: 0.6666016180508827		[learning rate: 0.0091328]
	Learning Rate: 0.00913283
	LOSS [training: 0.6078673146906601 | validation: 0.5816183944859493]
	TIME [epoch: 8.52 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5162985561498956		[learning rate: 0.0091162]
		[batch 20/20] avg loss: 0.5545810824535236		[learning rate: 0.0090997]
	Learning Rate: 0.00909968
	LOSS [training: 0.5354398193017095 | validation: 0.4252735011960749]
	TIME [epoch: 8.44 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45864913819419517		[learning rate: 0.0090832]
		[batch 20/20] avg loss: 0.45422541821805834		[learning rate: 0.0090667]
	Learning Rate: 0.00906666
	LOSS [training: 0.4564372782061267 | validation: 0.32274131858794736]
	TIME [epoch: 8.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45663547962511253		[learning rate: 0.0090502]
		[batch 20/20] avg loss: 0.5207930879402737		[learning rate: 0.0090338]
	Learning Rate: 0.00903376
	LOSS [training: 0.4887142837826931 | validation: 0.45447997945589524]
	TIME [epoch: 8.44 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4846773144025926		[learning rate: 0.0090174]
		[batch 20/20] avg loss: 0.4259452193917167		[learning rate: 0.009001]
	Learning Rate: 0.00900097
	LOSS [training: 0.4553112668971548 | validation: 1.108921804428273]
	TIME [epoch: 8.46 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5348910449406732		[learning rate: 0.0089846]
		[batch 20/20] avg loss: 0.5428433597398976		[learning rate: 0.0089683]
	Learning Rate: 0.00896831
	LOSS [training: 0.5388672023402854 | validation: 0.6327103501766795]
	TIME [epoch: 8.45 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45429329784177136		[learning rate: 0.008952]
		[batch 20/20] avg loss: 0.490437686855506		[learning rate: 0.0089358]
	Learning Rate: 0.00893576
	LOSS [training: 0.47236549234863856 | validation: 0.5984894838266365]
	TIME [epoch: 8.43 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5233626178925102		[learning rate: 0.0089195]
		[batch 20/20] avg loss: 0.494788547868999		[learning rate: 0.0089033]
	Learning Rate: 0.00890333
	LOSS [training: 0.5090755828807547 | validation: 0.6644410356110375]
	TIME [epoch: 8.47 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4758003631399146		[learning rate: 0.0088872]
		[batch 20/20] avg loss: 0.52223293797951		[learning rate: 0.008871]
	Learning Rate: 0.00887102
	LOSS [training: 0.49901665055971234 | validation: 1.362855689111587]
	TIME [epoch: 8.44 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.514298919532219		[learning rate: 0.0088549]
		[batch 20/20] avg loss: 0.4202545987642969		[learning rate: 0.0088388]
	Learning Rate: 0.00883883
	LOSS [training: 0.4672767591482579 | validation: 0.345207280320315]
	TIME [epoch: 8.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4684208726041902		[learning rate: 0.0088228]
		[batch 20/20] avg loss: 0.4381753010393812		[learning rate: 0.0088068]
	Learning Rate: 0.00880675
	LOSS [training: 0.4532980868217858 | validation: 0.6265884491809234]
	TIME [epoch: 8.46 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5430769600497263		[learning rate: 0.0087908]
		[batch 20/20] avg loss: 0.5273062522729053		[learning rate: 0.0087748]
	Learning Rate: 0.00877479
	LOSS [training: 0.5351916061613159 | validation: 0.38335735294440054]
	TIME [epoch: 8.46 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4402402940650795		[learning rate: 0.0087589]
		[batch 20/20] avg loss: 0.6010585305915883		[learning rate: 0.0087429]
	Learning Rate: 0.00874295
	LOSS [training: 0.5206494123283341 | validation: 0.6128164887760178]
	TIME [epoch: 8.46 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5659426181596042		[learning rate: 0.0087271]
		[batch 20/20] avg loss: 0.5330771586097182		[learning rate: 0.0087112]
	Learning Rate: 0.00871122
	LOSS [training: 0.5495098883846613 | validation: 0.5891315009946547]
	TIME [epoch: 8.44 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5076284698284695		[learning rate: 0.0086954]
		[batch 20/20] avg loss: 0.5109730651932681		[learning rate: 0.0086796]
	Learning Rate: 0.00867961
	LOSS [training: 0.5093007675108687 | validation: 0.47787080566051454]
	TIME [epoch: 8.48 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5384116143146371		[learning rate: 0.0086638]
		[batch 20/20] avg loss: 0.47736532758933015		[learning rate: 0.0086481]
	Learning Rate: 0.00864811
	LOSS [training: 0.5078884709519836 | validation: 0.4204109213359354]
	TIME [epoch: 8.45 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4667835356247346		[learning rate: 0.0086324]
		[batch 20/20] avg loss: 0.5094826176431497		[learning rate: 0.0086167]
	Learning Rate: 0.00861672
	LOSS [training: 0.48813307663394223 | validation: 0.6348863714414386]
	TIME [epoch: 8.48 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.554626626529171		[learning rate: 0.0086011]
		[batch 20/20] avg loss: 0.6354352254954619		[learning rate: 0.0085855]
	Learning Rate: 0.00858545
	LOSS [training: 0.5950309260123164 | validation: 0.41749289269994205]
	TIME [epoch: 8.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4979966578478792		[learning rate: 0.0085699]
		[batch 20/20] avg loss: 0.4832466427761992		[learning rate: 0.0085543]
	Learning Rate: 0.00855429
	LOSS [training: 0.49062165031203914 | validation: 0.5123714442237789]
	TIME [epoch: 8.47 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39968523031362096		[learning rate: 0.0085388]
		[batch 20/20] avg loss: 0.5545240934777902		[learning rate: 0.0085232]
	Learning Rate: 0.00852325
	LOSS [training: 0.47710466189570544 | validation: 0.621503170925717]
	TIME [epoch: 8.45 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6027004023569202		[learning rate: 0.0085078]
		[batch 20/20] avg loss: 0.4271921736961227		[learning rate: 0.0084923]
	Learning Rate: 0.00849232
	LOSS [training: 0.5149462880265214 | validation: 0.37421490718759975]
	TIME [epoch: 8.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5380206436895743		[learning rate: 0.0084769]
		[batch 20/20] avg loss: 0.4730199443039928		[learning rate: 0.0084615]
	Learning Rate: 0.0084615
	LOSS [training: 0.5055202939967834 | validation: 0.47803677763256314]
	TIME [epoch: 8.48 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.42869288823080504		[learning rate: 0.0084461]
		[batch 20/20] avg loss: 0.4640873067428569		[learning rate: 0.0084308]
	Learning Rate: 0.00843079
	LOSS [training: 0.446390097486831 | validation: 0.450917559350583]
	TIME [epoch: 8.49 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4096556238719421		[learning rate: 0.0084155]
		[batch 20/20] avg loss: 0.6553223094822964		[learning rate: 0.0084002]
	Learning Rate: 0.0084002
	LOSS [training: 0.5324889666771193 | validation: 0.4453240360570274]
	TIME [epoch: 8.44 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.40717521435102755		[learning rate: 0.0083849]
		[batch 20/20] avg loss: 0.48295016201024304		[learning rate: 0.0083697]
	Learning Rate: 0.00836971
	LOSS [training: 0.4450626881806352 | validation: 0.48577810429797125]
	TIME [epoch: 8.47 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4656577796899759		[learning rate: 0.0083545]
		[batch 20/20] avg loss: 0.5369128996891831		[learning rate: 0.0083393]
	Learning Rate: 0.00833934
	LOSS [training: 0.5012853396895796 | validation: 0.8254578671482549]
	TIME [epoch: 8.49 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5004512245638765		[learning rate: 0.0083242]
		[batch 20/20] avg loss: 0.5036767087923987		[learning rate: 0.0083091]
	Learning Rate: 0.00830907
	LOSS [training: 0.5020639666781376 | validation: 0.3598702316475908]
	TIME [epoch: 8.45 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5777565096912842		[learning rate: 0.008294]
		[batch 20/20] avg loss: 0.33719898681874183		[learning rate: 0.0082789]
	Learning Rate: 0.00827892
	LOSS [training: 0.457477748255013 | validation: 0.2937081705453696]
	TIME [epoch: 8.45 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4287044216226293		[learning rate: 0.0082639]
		[batch 20/20] avg loss: 0.39643334376940287		[learning rate: 0.0082489]
	Learning Rate: 0.00824887
	LOSS [training: 0.4125688826960162 | validation: 0.3906003074188031]
	TIME [epoch: 8.45 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.44042340348274334		[learning rate: 0.0082339]
		[batch 20/20] avg loss: 0.46664123431265236		[learning rate: 0.0082189]
	Learning Rate: 0.00821894
	LOSS [training: 0.45353231889769796 | validation: 0.2806363263502469]
	TIME [epoch: 8.46 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3862827377145189		[learning rate: 0.008204]
		[batch 20/20] avg loss: 0.4193142806819413		[learning rate: 0.0081891]
	Learning Rate: 0.00818911
	LOSS [training: 0.40279850919823 | validation: 0.3615484244740744]
	TIME [epoch: 8.48 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5528643835789675		[learning rate: 0.0081742]
		[batch 20/20] avg loss: 0.477884501047846		[learning rate: 0.0081594]
	Learning Rate: 0.00815939
	LOSS [training: 0.5153744423134067 | validation: 0.3592179758373679]
	TIME [epoch: 8.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4435531306171872		[learning rate: 0.0081446]
		[batch 20/20] avg loss: 0.575659605041433		[learning rate: 0.0081298]
	Learning Rate: 0.00812978
	LOSS [training: 0.50960636782931 | validation: 0.3177032423526206]
	TIME [epoch: 8.49 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4085061045143982		[learning rate: 0.008115]
		[batch 20/20] avg loss: 0.430035042053232		[learning rate: 0.0081003]
	Learning Rate: 0.00810028
	LOSS [training: 0.419270573283815 | validation: 0.6283843441961987]
	TIME [epoch: 8.44 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.37857792337508		[learning rate: 0.0080856]
		[batch 20/20] avg loss: 0.45548924535638147		[learning rate: 0.0080709]
	Learning Rate: 0.00807088
	LOSS [training: 0.4170335843657308 | validation: 0.5987345955626325]
	TIME [epoch: 8.45 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4884009417487092		[learning rate: 0.0080562]
		[batch 20/20] avg loss: 0.4540908850685481		[learning rate: 0.0080416]
	Learning Rate: 0.00804159
	LOSS [training: 0.4712459134086287 | validation: 0.3372470038821124]
	TIME [epoch: 8.45 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4233344724512683		[learning rate: 0.008027]
		[batch 20/20] avg loss: 0.37186073119382657		[learning rate: 0.0080124]
	Learning Rate: 0.00801241
	LOSS [training: 0.39759760182254755 | validation: 0.32084170800891754]
	TIME [epoch: 8.46 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39832247597229675		[learning rate: 0.0079979]
		[batch 20/20] avg loss: 0.48692816224691027		[learning rate: 0.0079833]
	Learning Rate: 0.00798333
	LOSS [training: 0.4426253191096035 | validation: 0.28574189983742665]
	TIME [epoch: 8.44 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4577761675367351		[learning rate: 0.0079688]
		[batch 20/20] avg loss: 0.3921558375090294		[learning rate: 0.0079544]
	Learning Rate: 0.00795436
	LOSS [training: 0.4249660025228822 | validation: 0.3306977811818841]
	TIME [epoch: 8.44 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.36708213712556137		[learning rate: 0.0079399]
		[batch 20/20] avg loss: 0.37792366757774587		[learning rate: 0.0079255]
	Learning Rate: 0.00792549
	LOSS [training: 0.3725029023516536 | validation: 0.3755949706726125]
	TIME [epoch: 8.48 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4248789704274287		[learning rate: 0.0079111]
		[batch 20/20] avg loss: 0.3396689563439291		[learning rate: 0.0078967]
	Learning Rate: 0.00789673
	LOSS [training: 0.3822739633856789 | validation: 0.49245043928368537]
	TIME [epoch: 8.46 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4222703885198632		[learning rate: 0.0078824]
		[batch 20/20] avg loss: 0.4712269597311998		[learning rate: 0.0078681]
	Learning Rate: 0.00786807
	LOSS [training: 0.44674867412553143 | validation: 0.4673154939630795]
	TIME [epoch: 8.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.44630990745264054		[learning rate: 0.0078538]
		[batch 20/20] avg loss: 0.45238628824949007		[learning rate: 0.0078395]
	Learning Rate: 0.00783952
	LOSS [training: 0.4493480978510652 | validation: 0.4613994937806947]
	TIME [epoch: 8.45 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.36280859750556294		[learning rate: 0.0078253]
		[batch 20/20] avg loss: 0.4741455329549436		[learning rate: 0.0078111]
	Learning Rate: 0.00781107
	LOSS [training: 0.41847706523025324 | validation: 0.34317693135909483]
	TIME [epoch: 8.47 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6408525845312204		[learning rate: 0.0077969]
		[batch 20/20] avg loss: 0.44331121672102425		[learning rate: 0.0077827]
	Learning Rate: 0.00778272
	LOSS [training: 0.5420819006261224 | validation: 0.3468683396591871]
	TIME [epoch: 8.44 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3572251637181004		[learning rate: 0.0077686]
		[batch 20/20] avg loss: 0.3362887160439407		[learning rate: 0.0077545]
	Learning Rate: 0.00775448
	LOSS [training: 0.34675693988102063 | validation: 0.5304646678443711]
	TIME [epoch: 8.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.398177834722957		[learning rate: 0.0077404]
		[batch 20/20] avg loss: 0.5678250988526542		[learning rate: 0.0077263]
	Learning Rate: 0.00772634
	LOSS [training: 0.48300146678780553 | validation: 0.30256723785675355]
	TIME [epoch: 8.47 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3534263684962104		[learning rate: 0.0077123]
		[batch 20/20] avg loss: 0.34225993955130524		[learning rate: 0.0076983]
	Learning Rate: 0.0076983
	LOSS [training: 0.34784315402375776 | validation: 0.32440947950363325]
	TIME [epoch: 8.45 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3380575088879306		[learning rate: 0.0076843]
		[batch 20/20] avg loss: 0.36986562248440596		[learning rate: 0.0076704]
	Learning Rate: 0.00767036
	LOSS [training: 0.35396156568616827 | validation: 0.2908788300956789]
	TIME [epoch: 8.45 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.47217499905432814		[learning rate: 0.0076564]
		[batch 20/20] avg loss: 0.7015588762147849		[learning rate: 0.0076425]
	Learning Rate: 0.00764252
	LOSS [training: 0.5868669376345566 | validation: 0.2509524696363745]
	TIME [epoch: 8.46 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4945520985243708		[learning rate: 0.0076286]
		[batch 20/20] avg loss: 0.3565183052790819		[learning rate: 0.0076148]
	Learning Rate: 0.00761479
	LOSS [training: 0.42553520190172633 | validation: 0.3726047141197907]
	TIME [epoch: 8.49 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.402713168735671		[learning rate: 0.007601]
		[batch 20/20] avg loss: 0.8694416305501221		[learning rate: 0.0075872]
	Learning Rate: 0.00758715
	LOSS [training: 0.6360773996428966 | validation: 5.546455520295914]
	TIME [epoch: 8.45 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.641401894535425		[learning rate: 0.0075734]
		[batch 20/20] avg loss: 0.3604685265554005		[learning rate: 0.0075596]
	Learning Rate: 0.00755962
	LOSS [training: 1.0009352105454128 | validation: 0.4637683572598331]
	TIME [epoch: 8.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4813683243237998		[learning rate: 0.0075459]
		[batch 20/20] avg loss: 0.820074953720141		[learning rate: 0.0075322]
	Learning Rate: 0.00753219
	LOSS [training: 0.6507216390219703 | validation: 0.3544271344568439]
	TIME [epoch: 8.45 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4504263172703971		[learning rate: 0.0075185]
		[batch 20/20] avg loss: 0.4129449145726391		[learning rate: 0.0075049]
	Learning Rate: 0.00750485
	LOSS [training: 0.4316856159215181 | validation: 0.2279287037585284]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5081627466002946		[learning rate: 0.0074912]
		[batch 20/20] avg loss: 0.5323761271904307		[learning rate: 0.0074776]
	Learning Rate: 0.00747762
	LOSS [training: 0.5202694368953626 | validation: 0.7560219217040584]
	TIME [epoch: 8.44 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.773046757707277		[learning rate: 0.007464]
		[batch 20/20] avg loss: 0.5002737091851006		[learning rate: 0.0074505]
	Learning Rate: 0.00745048
	LOSS [training: 0.6366602334461888 | validation: 0.5258455596180687]
	TIME [epoch: 8.44 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.37447980314473234		[learning rate: 0.0074369]
		[batch 20/20] avg loss: 0.42081702036348273		[learning rate: 0.0074234]
	Learning Rate: 0.00742344
	LOSS [training: 0.3976484117541076 | validation: 0.7611087819998343]
	TIME [epoch: 8.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4978910804420444		[learning rate: 0.00741]
		[batch 20/20] avg loss: 0.5627705195229322		[learning rate: 0.0073965]
	Learning Rate: 0.0073965
	LOSS [training: 0.5303307999824882 | validation: 0.5552155177371398]
	TIME [epoch: 8.44 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.503320032486663		[learning rate: 0.0073831]
		[batch 20/20] avg loss: 0.5571644099761616		[learning rate: 0.0073697]
	Learning Rate: 0.00736966
	LOSS [training: 0.5302422212314124 | validation: 0.38657887034199123]
	TIME [epoch: 8.43 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5142191501932868		[learning rate: 0.0073563]
		[batch 20/20] avg loss: 0.48253099411178046		[learning rate: 0.0073429]
	Learning Rate: 0.00734291
	LOSS [training: 0.4983750721525338 | validation: 0.43147501463375004]
	TIME [epoch: 8.47 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39121602324581745		[learning rate: 0.0073296]
		[batch 20/20] avg loss: 0.41141797153027115		[learning rate: 0.0073163]
	Learning Rate: 0.00731627
	LOSS [training: 0.40131699738804427 | validation: 5.0963986364927125]
	TIME [epoch: 8.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1640800427188849		[learning rate: 0.007303]
		[batch 20/20] avg loss: 0.6428551817714725		[learning rate: 0.0072897]
	Learning Rate: 0.00728971
	LOSS [training: 0.9034676122451785 | validation: 0.2209548564644193]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4611335858030233		[learning rate: 0.0072765]
		[batch 20/20] avg loss: 0.5709622581080802		[learning rate: 0.0072633]
	Learning Rate: 0.00726326
	LOSS [training: 0.5160479219555517 | validation: 0.46920676496428615]
	TIME [epoch: 8.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4644090370603114		[learning rate: 0.0072501]
		[batch 20/20] avg loss: 0.40982722190340193		[learning rate: 0.0072369]
	Learning Rate: 0.0072369
	LOSS [training: 0.4371181294818567 | validation: 0.899681136233571]
	TIME [epoch: 8.47 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4703668805571592		[learning rate: 0.0072238]
		[batch 20/20] avg loss: 0.4517124471288277		[learning rate: 0.0072106]
	Learning Rate: 0.00721064
	LOSS [training: 0.46103966384299344 | validation: 0.3748906927273491]
	TIME [epoch: 8.44 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4570599357106742		[learning rate: 0.0071975]
		[batch 20/20] avg loss: 0.4331533860986845		[learning rate: 0.0071845]
	Learning Rate: 0.00718447
	LOSS [training: 0.44510666090467926 | validation: 0.49341948181278383]
	TIME [epoch: 8.43 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5574119666174283		[learning rate: 0.0071714]
		[batch 20/20] avg loss: 0.4162455147927126		[learning rate: 0.0071584]
	Learning Rate: 0.0071584
	LOSS [training: 0.48682874070507054 | validation: 0.5617129817392283]
	TIME [epoch: 8.47 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4171535651381201		[learning rate: 0.0071454]
		[batch 20/20] avg loss: 0.34944383971773657		[learning rate: 0.0071324]
	Learning Rate: 0.00713242
	LOSS [training: 0.3832987024279284 | validation: 3.0482767824601984]
	TIME [epoch: 8.47 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8316685469074214		[learning rate: 0.0071195]
		[batch 20/20] avg loss: 0.40917545290570934		[learning rate: 0.0071065]
	Learning Rate: 0.00710653
	LOSS [training: 0.6204219999065655 | validation: 0.42329745370057476]
	TIME [epoch: 8.43 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.40169283274001016		[learning rate: 0.0070936]
		[batch 20/20] avg loss: 0.2927274261986762		[learning rate: 0.0070807]
	Learning Rate: 0.00708074
	LOSS [training: 0.3472101294693432 | validation: 0.27222117588863826]
	TIME [epoch: 8.44 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5631479394488504		[learning rate: 0.0070679]
		[batch 20/20] avg loss: 0.39331255545300686		[learning rate: 0.007055]
	Learning Rate: 0.00705505
	LOSS [training: 0.4782302474509287 | validation: 0.2981816017129162]
	TIME [epoch: 8.49 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.44974376154597806		[learning rate: 0.0070422]
		[batch 20/20] avg loss: 0.36173245783270264		[learning rate: 0.0070294]
	Learning Rate: 0.00702945
	LOSS [training: 0.4057381096893403 | validation: 0.9849652883520179]
	TIME [epoch: 8.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5432398819680299		[learning rate: 0.0070167]
		[batch 20/20] avg loss: 0.4375121386807761		[learning rate: 0.0070039]
	Learning Rate: 0.00700394
	LOSS [training: 0.49037601032440303 | validation: 0.4139533638991921]
	TIME [epoch: 8.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3634873354522633		[learning rate: 0.0069912]
		[batch 20/20] avg loss: 0.3864012602729033		[learning rate: 0.0069785]
	Learning Rate: 0.00697852
	LOSS [training: 0.3749442978625832 | validation: 0.4326885964880254]
	TIME [epoch: 8.43 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5356877900464687		[learning rate: 0.0069658]
		[batch 20/20] avg loss: 0.3947869171812554		[learning rate: 0.0069532]
	Learning Rate: 0.00695319
	LOSS [training: 0.46523735361386204 | validation: 0.5606929801205717]
	TIME [epoch: 8.47 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3750282591073627		[learning rate: 0.0069406]
		[batch 20/20] avg loss: 0.4203746622935478		[learning rate: 0.006928]
	Learning Rate: 0.00692796
	LOSS [training: 0.39770146070045526 | validation: 0.8683972293831819]
	TIME [epoch: 8.44 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1645815473971093		[learning rate: 0.0069154]
		[batch 20/20] avg loss: 0.47932392450648054		[learning rate: 0.0069028]
	Learning Rate: 0.00690282
	LOSS [training: 0.8219527359517949 | validation: 0.6748213463271284]
	TIME [epoch: 8.45 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3925045048769715		[learning rate: 0.0068903]
		[batch 20/20] avg loss: 0.46733492787800507		[learning rate: 0.0068778]
	Learning Rate: 0.00687777
	LOSS [training: 0.4299197163774882 | validation: 0.3491465176680929]
	TIME [epoch: 8.47 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.40396625657022367		[learning rate: 0.0068653]
		[batch 20/20] avg loss: 0.6970889856848621		[learning rate: 0.0068528]
	Learning Rate: 0.00685281
	LOSS [training: 0.5505276211275428 | validation: 0.418465919897995]
	TIME [epoch: 8.45 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.44214891740865314		[learning rate: 0.0068404]
		[batch 20/20] avg loss: 0.45565099142383386		[learning rate: 0.0068279]
	Learning Rate: 0.00682794
	LOSS [training: 0.4488999544162435 | validation: 0.7055091629911764]
	TIME [epoch: 8.44 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.47263728587920883		[learning rate: 0.0068155]
		[batch 20/20] avg loss: 0.38257103365199174		[learning rate: 0.0068032]
	Learning Rate: 0.00680316
	LOSS [training: 0.42760415976560023 | validation: 0.23836440333583572]
	TIME [epoch: 8.44 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.399154346066135		[learning rate: 0.0067908]
		[batch 20/20] avg loss: 0.3674574528353268		[learning rate: 0.0067785]
	Learning Rate: 0.00677847
	LOSS [training: 0.38330589945073096 | validation: 0.3482148892621087]
	TIME [epoch: 8.48 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3695519082168722		[learning rate: 0.0067662]
		[batch 20/20] avg loss: 0.3350714108809603		[learning rate: 0.0067539]
	Learning Rate: 0.00675387
	LOSS [training: 0.3523116595489163 | validation: 0.6343275933824927]
	TIME [epoch: 8.47 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5004410041519429		[learning rate: 0.0067416]
		[batch 20/20] avg loss: 0.3945065875557925		[learning rate: 0.0067294]
	Learning Rate: 0.00672936
	LOSS [training: 0.4474737958538677 | validation: 0.40957992754420297]
	TIME [epoch: 8.43 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4297989684471581		[learning rate: 0.0067171]
		[batch 20/20] avg loss: 0.4423684488612275		[learning rate: 0.0067049]
	Learning Rate: 0.00670494
	LOSS [training: 0.4360837086541928 | validation: 0.33505778337952125]
	TIME [epoch: 8.46 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.37278496500075303		[learning rate: 0.0066928]
		[batch 20/20] avg loss: 0.5060534004889516		[learning rate: 0.0066806]
	Learning Rate: 0.0066806
	LOSS [training: 0.4394191827448524 | validation: 0.3907342363263158]
	TIME [epoch: 8.45 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.34646782218267047		[learning rate: 0.0066685]
		[batch 20/20] avg loss: 0.41417578132803146		[learning rate: 0.0066564]
	Learning Rate: 0.00665636
	LOSS [training: 0.380321801755351 | validation: 0.4599493804513578]
	TIME [epoch: 8.45 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3109672766721373		[learning rate: 0.0066443]
		[batch 20/20] avg loss: 0.5271459245189763		[learning rate: 0.0066322]
	Learning Rate: 0.0066322
	LOSS [training: 0.4190566005955569 | validation: 0.4181804647558759]
	TIME [epoch: 8.44 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.35939133647675064		[learning rate: 0.0066202]
		[batch 20/20] avg loss: 0.39770970250982457		[learning rate: 0.0066081]
	Learning Rate: 0.00660814
	LOSS [training: 0.37855051949328766 | validation: 0.31025784058903794]
	TIME [epoch: 8.47 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.41946423768304336		[learning rate: 0.0065961]
		[batch 20/20] avg loss: 0.3665788550565367		[learning rate: 0.0065842]
	Learning Rate: 0.00658415
	LOSS [training: 0.39302154636979003 | validation: 0.4377284025885828]
	TIME [epoch: 8.45 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39743614489809886		[learning rate: 0.0065722]
		[batch 20/20] avg loss: 0.36346699478045086		[learning rate: 0.0065603]
	Learning Rate: 0.00656026
	LOSS [training: 0.3804515698392749 | validation: 0.39381182929063374]
	TIME [epoch: 8.45 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6788538123593562		[learning rate: 0.0065483]
		[batch 20/20] avg loss: 0.5537868287931922		[learning rate: 0.0065365]
	Learning Rate: 0.00653645
	LOSS [training: 0.6163203205762742 | validation: 0.6969141935528327]
	TIME [epoch: 8.44 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4606998525805855		[learning rate: 0.0065246]
		[batch 20/20] avg loss: 0.39878964975392894		[learning rate: 0.0065127]
	Learning Rate: 0.00651273
	LOSS [training: 0.4297447511672572 | validation: 0.3965018268865171]
	TIME [epoch: 8.47 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39871611918156863		[learning rate: 0.0065009]
		[batch 20/20] avg loss: 0.3496904847708789		[learning rate: 0.0064891]
	Learning Rate: 0.0064891
	LOSS [training: 0.37420330197622376 | validation: 0.372241718541771]
	TIME [epoch: 8.44 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.40957136197977784		[learning rate: 0.0064773]
		[batch 20/20] avg loss: 0.44130760637288374		[learning rate: 0.0064655]
	Learning Rate: 0.00646555
	LOSS [training: 0.4254394841763308 | validation: 0.44178984774954116]
	TIME [epoch: 8.45 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.32430550453590146		[learning rate: 0.0064538]
		[batch 20/20] avg loss: 0.3125200220735565		[learning rate: 0.0064421]
	Learning Rate: 0.00644208
	LOSS [training: 0.318412763304729 | validation: 0.4111757432290694]
	TIME [epoch: 8.47 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.46570437757219196		[learning rate: 0.0064304]
		[batch 20/20] avg loss: 0.346819636913665		[learning rate: 0.0064187]
	Learning Rate: 0.0064187
	LOSS [training: 0.4062620072429285 | validation: 0.18272099170302827]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3680753314529879		[learning rate: 0.006407]
		[batch 20/20] avg loss: 0.4010667166890435		[learning rate: 0.0063954]
	Learning Rate: 0.00639541
	LOSS [training: 0.3845710240710156 | validation: 0.3765821047002419]
	TIME [epoch: 8.45 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.32848527034697483		[learning rate: 0.0063838]
		[batch 20/20] avg loss: 0.2923396575423614		[learning rate: 0.0063722]
	Learning Rate: 0.0063722
	LOSS [training: 0.31041246394466815 | validation: 0.27080892721798355]
	TIME [epoch: 8.46 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3788153018972515		[learning rate: 0.0063606]
		[batch 20/20] avg loss: 0.345159648531406		[learning rate: 0.0063491]
	Learning Rate: 0.00634908
	LOSS [training: 0.3619874752143287 | validation: 0.21818858272381483]
	TIME [epoch: 8.45 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.36042048182261344		[learning rate: 0.0063375]
		[batch 20/20] avg loss: 0.3376619507661257		[learning rate: 0.006326]
	Learning Rate: 0.00632603
	LOSS [training: 0.3490412162943696 | validation: 0.44601848585744397]
	TIME [epoch: 8.42 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3437038389161236		[learning rate: 0.0063145]
		[batch 20/20] avg loss: 0.29943338015290155		[learning rate: 0.0063031]
	Learning Rate: 0.00630308
	LOSS [training: 0.32156860953451255 | validation: 0.4021854955816496]
	TIME [epoch: 8.48 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3187509441954851		[learning rate: 0.0062916]
		[batch 20/20] avg loss: 0.30333351795201186		[learning rate: 0.0062802]
	Learning Rate: 0.0062802
	LOSS [training: 0.3110422310737485 | validation: 0.24485143944521548]
	TIME [epoch: 8.45 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28978298490043664		[learning rate: 0.0062688]
		[batch 20/20] avg loss: 0.35572245121907253		[learning rate: 0.0062574]
	Learning Rate: 0.00625741
	LOSS [training: 0.3227527180597546 | validation: 0.4176700344790483]
	TIME [epoch: 8.44 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.37546871529235715		[learning rate: 0.006246]
		[batch 20/20] avg loss: 0.32158498164562066		[learning rate: 0.0062347]
	Learning Rate: 0.0062347
	LOSS [training: 0.3485268484689889 | validation: 0.24315179510077173]
	TIME [epoch: 8.44 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.35601163632905103		[learning rate: 0.0062234]
		[batch 20/20] avg loss: 0.30784247684191324		[learning rate: 0.0062121]
	Learning Rate: 0.00621208
	LOSS [training: 0.33192705658548216 | validation: 0.22864729012922336]
	TIME [epoch: 8.48 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.31141019923860414		[learning rate: 0.0062008]
		[batch 20/20] avg loss: 0.35132658778271864		[learning rate: 0.0061895]
	Learning Rate: 0.00618953
	LOSS [training: 0.33136839351066144 | validation: 0.47497388260455314]
	TIME [epoch: 8.46 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.30391842634047056		[learning rate: 0.0061783]
		[batch 20/20] avg loss: 0.30579511538459336		[learning rate: 0.0061671]
	Learning Rate: 0.00616707
	LOSS [training: 0.30485677086253193 | validation: 0.2007452188774005]
	TIME [epoch: 8.44 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27584334014041734		[learning rate: 0.0061559]
		[batch 20/20] avg loss: 0.4526487296128622		[learning rate: 0.0061447]
	Learning Rate: 0.00614469
	LOSS [training: 0.36424603487663976 | validation: 0.2789943046605671]
	TIME [epoch: 8.43 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5335588739099363		[learning rate: 0.0061335]
		[batch 20/20] avg loss: 0.3244470850787073		[learning rate: 0.0061224]
	Learning Rate: 0.00612239
	LOSS [training: 0.42900297949432187 | validation: 0.32249914054020545]
	TIME [epoch: 8.45 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3104440337839681		[learning rate: 0.0061113]
		[batch 20/20] avg loss: 0.3230741869391591		[learning rate: 0.0061002]
	Learning Rate: 0.00610017
	LOSS [training: 0.3167591103615636 | validation: 0.656684769388536]
	TIME [epoch: 8.45 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4220840409724443		[learning rate: 0.0060891]
		[batch 20/20] avg loss: 0.32023526585852213		[learning rate: 0.006078]
	Learning Rate: 0.00607803
	LOSS [training: 0.37115965341548324 | validation: 0.2396864968789057]
	TIME [epoch: 8.44 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3401285282813653		[learning rate: 0.006067]
		[batch 20/20] avg loss: 0.32957415189672457		[learning rate: 0.006056]
	Learning Rate: 0.00605598
	LOSS [training: 0.334851340089045 | validation: 0.23606872562891845]
	TIME [epoch: 8.44 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.29458100024027567		[learning rate: 0.006045]
		[batch 20/20] avg loss: 0.4063636785651443		[learning rate: 0.006034]
	Learning Rate: 0.006034
	LOSS [training: 0.35047233940270994 | validation: 0.22197330032926285]
	TIME [epoch: 8.46 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2785441330853753		[learning rate: 0.006023]
		[batch 20/20] avg loss: 0.2675881998562019		[learning rate: 0.0060121]
	Learning Rate: 0.0060121
	LOSS [training: 0.27306616647078863 | validation: 0.23173278362178054]
	TIME [epoch: 8.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.29452216461797615		[learning rate: 0.0060012]
		[batch 20/20] avg loss: 0.35054603733581435		[learning rate: 0.0059903]
	Learning Rate: 0.00599028
	LOSS [training: 0.3225341009768952 | validation: 0.21800277303176338]
	TIME [epoch: 8.42 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.33924142856542505		[learning rate: 0.0059794]
		[batch 20/20] avg loss: 0.34146022022355427		[learning rate: 0.0059685]
	Learning Rate: 0.00596854
	LOSS [training: 0.34035082439448966 | validation: 0.2012388813174327]
	TIME [epoch: 8.42 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28785309550513577		[learning rate: 0.0059577]
		[batch 20/20] avg loss: 0.314567742237351		[learning rate: 0.0059469]
	Learning Rate: 0.00594688
	LOSS [training: 0.3012104188712434 | validation: 0.26594152848677594]
	TIME [epoch: 8.46 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27361719399147255		[learning rate: 0.0059361]
		[batch 20/20] avg loss: 0.3001262128281331		[learning rate: 0.0059253]
	Learning Rate: 0.0059253
	LOSS [training: 0.2868717034098028 | validation: 0.1888685047462464]
	TIME [epoch: 8.44 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28508819327985035		[learning rate: 0.0059145]
		[batch 20/20] avg loss: 0.2377191263515474		[learning rate: 0.0059038]
	Learning Rate: 0.0059038
	LOSS [training: 0.2614036598156989 | validation: 0.2188470431414203]
	TIME [epoch: 8.43 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.33715349041435566		[learning rate: 0.0058931]
		[batch 20/20] avg loss: 0.49894398601318635		[learning rate: 0.0058824]
	Learning Rate: 0.00588237
	LOSS [training: 0.4180487382137709 | validation: 0.3608815277818839]
	TIME [epoch: 8.46 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3564733079764184		[learning rate: 0.0058717]
		[batch 20/20] avg loss: 0.3242914611702779		[learning rate: 0.005861]
	Learning Rate: 0.00586103
	LOSS [training: 0.34038238457334813 | validation: 0.31146561764024794]
	TIME [epoch: 8.44 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.29566218680545137		[learning rate: 0.0058504]
		[batch 20/20] avg loss: 0.4852589376964579		[learning rate: 0.0058398]
	Learning Rate: 0.00583976
	LOSS [training: 0.3904605622509546 | validation: 0.3367426527725334]
	TIME [epoch: 8.47 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3342611490014246		[learning rate: 0.0058291]
		[batch 20/20] avg loss: 0.27328941900208453		[learning rate: 0.0058186]
	Learning Rate: 0.00581856
	LOSS [training: 0.3037752840017546 | validation: 0.3189451513924664]
	TIME [epoch: 8.45 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2696976009434954		[learning rate: 0.005808]
		[batch 20/20] avg loss: 0.3550099093608087		[learning rate: 0.0057974]
	Learning Rate: 0.00579745
	LOSS [training: 0.312353755152152 | validation: 0.19869633432666617]
	TIME [epoch: 8.46 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3484642559771368		[learning rate: 0.0057869]
		[batch 20/20] avg loss: 0.2685625277247926		[learning rate: 0.0057764]
	Learning Rate: 0.00577641
	LOSS [training: 0.3085133918509647 | validation: 0.25027486312483715]
	TIME [epoch: 8.43 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3042337011543365		[learning rate: 0.0057659]
		[batch 20/20] avg loss: 0.24841754917077163		[learning rate: 0.0057554]
	Learning Rate: 0.00575545
	LOSS [training: 0.27632562516255416 | validation: 0.30044755831596814]
	TIME [epoch: 8.43 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26153424807970416		[learning rate: 0.005745]
		[batch 20/20] avg loss: 0.2550286818406152		[learning rate: 0.0057346]
	Learning Rate: 0.00573456
	LOSS [training: 0.25828146496015975 | validation: 0.202435053055394]
	TIME [epoch: 8.45 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2690371301484536		[learning rate: 0.0057241]
		[batch 20/20] avg loss: 0.2838055693594464		[learning rate: 0.0057137]
	Learning Rate: 0.00571375
	LOSS [training: 0.27642134975394994 | validation: 0.17510167664551174]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28031730618382417		[learning rate: 0.0057034]
		[batch 20/20] avg loss: 0.2672132089321978		[learning rate: 0.005693]
	Learning Rate: 0.00569301
	LOSS [training: 0.27376525755801095 | validation: 0.2499630422944892]
	TIME [epoch: 8.47 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.22413137609713368		[learning rate: 0.0056827]
		[batch 20/20] avg loss: 0.3073745986952118		[learning rate: 0.0056724]
	Learning Rate: 0.00567235
	LOSS [training: 0.26575298739617265 | validation: 0.2499690992395604]
	TIME [epoch: 8.46 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3489094747787236		[learning rate: 0.005662]
		[batch 20/20] avg loss: 0.2560367002104986		[learning rate: 0.0056518]
	Learning Rate: 0.00565177
	LOSS [training: 0.30247308749461116 | validation: 0.21615322350456218]
	TIME [epoch: 8.49 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2421296208963956		[learning rate: 0.0056415]
		[batch 20/20] avg loss: 0.3589452692364625		[learning rate: 0.0056313]
	Learning Rate: 0.00563126
	LOSS [training: 0.3005374450664291 | validation: 0.19527521344354726]
	TIME [epoch: 8.46 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2706524784961157		[learning rate: 0.005621]
		[batch 20/20] avg loss: 0.27587666748857176		[learning rate: 0.0056108]
	Learning Rate: 0.00561082
	LOSS [training: 0.2732645729923437 | validation: 0.24309735953923886]
	TIME [epoch: 8.46 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28984483202116984		[learning rate: 0.0056006]
		[batch 20/20] avg loss: 0.350330039985581		[learning rate: 0.0055905]
	Learning Rate: 0.00559046
	LOSS [training: 0.3200874360033754 | validation: 0.20864852515357882]
	TIME [epoch: 8.46 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26161760663420364		[learning rate: 0.0055803]
		[batch 20/20] avg loss: 0.24268423113897838		[learning rate: 0.0055702]
	Learning Rate: 0.00557017
	LOSS [training: 0.252150918886591 | validation: 0.16349767747946925]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.19510960778070782		[learning rate: 0.0055601]
		[batch 20/20] avg loss: 0.31451539476266815		[learning rate: 0.00555]
	Learning Rate: 0.00554996
	LOSS [training: 0.25481250127168803 | validation: 0.3200773823229235]
	TIME [epoch: 8.46 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2845781644265498		[learning rate: 0.0055399]
		[batch 20/20] avg loss: 0.2508549836118161		[learning rate: 0.0055298]
	Learning Rate: 0.00552981
	LOSS [training: 0.267716574019183 | validation: 0.17559053462368718]
	TIME [epoch: 8.47 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2341394400758221		[learning rate: 0.0055198]
		[batch 20/20] avg loss: 0.31278916887142677		[learning rate: 0.0055097]
	Learning Rate: 0.00550975
	LOSS [training: 0.2734643044736244 | validation: 0.28930897469659883]
	TIME [epoch: 8.47 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.37346944430100526		[learning rate: 0.0054997]
		[batch 20/20] avg loss: 0.27033023041015214		[learning rate: 0.0054898]
	Learning Rate: 0.00548975
	LOSS [training: 0.3218998373555787 | validation: 0.2812513075687806]
	TIME [epoch: 8.47 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.29096388671415774		[learning rate: 0.0054798]
		[batch 20/20] avg loss: 0.24232428615731288		[learning rate: 0.0054698]
	Learning Rate: 0.00546983
	LOSS [training: 0.26664408643573534 | validation: 0.5877079557297703]
	TIME [epoch: 8.47 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.39095436236415304		[learning rate: 0.0054599]
		[batch 20/20] avg loss: 0.32740454931432883		[learning rate: 0.00545]
	Learning Rate: 0.00544998
	LOSS [training: 0.3591794558392409 | validation: 0.30440158346684165]
	TIME [epoch: 8.47 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2705410093018314		[learning rate: 0.0054401]
		[batch 20/20] avg loss: 0.4238965714859149		[learning rate: 0.0054302]
	Learning Rate: 0.0054302
	LOSS [training: 0.34721879039387316 | validation: 0.2380044401821657]
	TIME [epoch: 8.49 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2528088670025864		[learning rate: 0.0054203]
		[batch 20/20] avg loss: 0.4147439460767498		[learning rate: 0.0054105]
	Learning Rate: 0.00541049
	LOSS [training: 0.3337764065396681 | validation: 0.2874241383172982]
	TIME [epoch: 8.46 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.32270633581926234		[learning rate: 0.0054007]
		[batch 20/20] avg loss: 0.3008637369472863		[learning rate: 0.0053909]
	Learning Rate: 0.00539086
	LOSS [training: 0.3117850363832743 | validation: 0.14182598161695806]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.32133746737198815		[learning rate: 0.0053811]
		[batch 20/20] avg loss: 0.26948068716725987		[learning rate: 0.0053713]
	Learning Rate: 0.00537129
	LOSS [training: 0.295409077269624 | validation: 0.140792766203989]
	TIME [epoch: 8.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3262808525443269		[learning rate: 0.0053615]
		[batch 20/20] avg loss: 0.2831227845646539		[learning rate: 0.0053518]
	Learning Rate: 0.0053518
	LOSS [training: 0.3047018185544904 | validation: 0.12217863805754055]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2287327498724717		[learning rate: 0.0053421]
		[batch 20/20] avg loss: 0.33048170731350546		[learning rate: 0.0053324]
	Learning Rate: 0.00533238
	LOSS [training: 0.2796072285929886 | validation: 0.26134004917605175]
	TIME [epoch: 8.45 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7890276626751577		[learning rate: 0.0053227]
		[batch 20/20] avg loss: 0.23367134817524718		[learning rate: 0.005313]
	Learning Rate: 0.00531303
	LOSS [training: 0.5113495054252025 | validation: 0.1850679846969118]
	TIME [epoch: 8.48 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.38564376846018716		[learning rate: 0.0053034]
		[batch 20/20] avg loss: 0.6109793755552666		[learning rate: 0.0052937]
	Learning Rate: 0.00529375
	LOSS [training: 0.49831157200772697 | validation: 0.22181712325688274]
	TIME [epoch: 8.46 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2681523424683431		[learning rate: 0.0052841]
		[batch 20/20] avg loss: 0.3617394011426215		[learning rate: 0.0052745]
	Learning Rate: 0.00527454
	LOSS [training: 0.3149458718054823 | validation: 0.2889003330508225]
	TIME [epoch: 8.44 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.25038792108569197		[learning rate: 0.005265]
		[batch 20/20] avg loss: 0.2925867753676815		[learning rate: 0.0052554]
	Learning Rate: 0.00525539
	LOSS [training: 0.27148734822668674 | validation: 0.5541520294028395]
	TIME [epoch: 8.44 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3113466107883279		[learning rate: 0.0052458]
		[batch 20/20] avg loss: 0.23151149955732514		[learning rate: 0.0052363]
	Learning Rate: 0.00523632
	LOSS [training: 0.27142905517282656 | validation: 0.19401044262385786]
	TIME [epoch: 8.45 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3398091245302576		[learning rate: 0.0052268]
		[batch 20/20] avg loss: 0.2699491283005145		[learning rate: 0.0052173]
	Learning Rate: 0.00521732
	LOSS [training: 0.30487912641538606 | validation: 0.3317817833257298]
	TIME [epoch: 8.49 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.24562438734018		[learning rate: 0.0052078]
		[batch 20/20] avg loss: 0.35517986282096375		[learning rate: 0.0051984]
	Learning Rate: 0.00519839
	LOSS [training: 0.3004021250805719 | validation: 0.24072749420469214]
	TIME [epoch: 8.45 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28962365411846014		[learning rate: 0.0051889]
		[batch 20/20] avg loss: 0.36503598081134503		[learning rate: 0.0051795]
	Learning Rate: 0.00517952
	LOSS [training: 0.32732981746490253 | validation: 0.3218053455512767]
	TIME [epoch: 8.43 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4262173521535373		[learning rate: 0.0051701]
		[batch 20/20] avg loss: 0.30385162497235474		[learning rate: 0.0051607]
	Learning Rate: 0.00516072
	LOSS [training: 0.365034488562946 | validation: 0.1655475611717608]
	TIME [epoch: 8.47 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26703268913951395		[learning rate: 0.0051513]
		[batch 20/20] avg loss: 0.30596776455928365		[learning rate: 0.005142]
	Learning Rate: 0.00514199
	LOSS [training: 0.28650022684939874 | validation: 0.20674225238373609]
	TIME [epoch: 8.44 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3120102700055849		[learning rate: 0.0051327]
		[batch 20/20] avg loss: 0.304963767012604		[learning rate: 0.0051233]
	Learning Rate: 0.00512333
	LOSS [training: 0.30848701850909455 | validation: 0.18833906199848566]
	TIME [epoch: 8.43 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.41398215286026063		[learning rate: 0.005114]
		[batch 20/20] avg loss: 0.36470149900455784		[learning rate: 0.0051047]
	Learning Rate: 0.00510474
	LOSS [training: 0.3893418259324092 | validation: 0.17369438921344205]
	TIME [epoch: 8.46 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28279820415750245		[learning rate: 0.0050955]
		[batch 20/20] avg loss: 0.3315252563752047		[learning rate: 0.0050862]
	Learning Rate: 0.00508622
	LOSS [training: 0.3071617302663535 | validation: 0.6308884923074675]
	TIME [epoch: 8.47 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2816642118618141		[learning rate: 0.005077]
		[batch 20/20] avg loss: 0.3479801654754235		[learning rate: 0.0050678]
	Learning Rate: 0.00506776
	LOSS [training: 0.3148221886686188 | validation: 0.19588787052424939]
	TIME [epoch: 8.46 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2664303401366842		[learning rate: 0.0050586]
		[batch 20/20] avg loss: 0.3115753632568623		[learning rate: 0.0050494]
	Learning Rate: 0.00504937
	LOSS [training: 0.2890028516967732 | validation: 0.21300792057276946]
	TIME [epoch: 8.43 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3066628056660566		[learning rate: 0.0050402]
		[batch 20/20] avg loss: 0.2771105921355749		[learning rate: 0.005031]
	Learning Rate: 0.00503104
	LOSS [training: 0.29188669890081564 | validation: 0.5696858273656519]
	TIME [epoch: 8.47 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27898709878084943		[learning rate: 0.0050219]
		[batch 20/20] avg loss: 0.5253494593497953		[learning rate: 0.0050128]
	Learning Rate: 0.00501278
	LOSS [training: 0.4021682790653224 | validation: 0.4342907890218327]
	TIME [epoch: 8.44 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.38848416708854844		[learning rate: 0.0050037]
		[batch 20/20] avg loss: 0.34198049039461087		[learning rate: 0.0049946]
	Learning Rate: 0.00499459
	LOSS [training: 0.3652323287415796 | validation: 0.6149189741406409]
	TIME [epoch: 8.45 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.32713615197150625		[learning rate: 0.0049855]
		[batch 20/20] avg loss: 0.2591462130317089		[learning rate: 0.0049765]
	Learning Rate: 0.00497647
	LOSS [training: 0.2931411825016077 | validation: 0.43914378034220364]
	TIME [epoch: 8.44 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.280757871899331		[learning rate: 0.0049674]
		[batch 20/20] avg loss: 0.6850314351538483		[learning rate: 0.0049584]
	Learning Rate: 0.00495841
	LOSS [training: 0.4828946535265898 | validation: 0.3675043606214802]
	TIME [epoch: 8.47 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3002310638085428		[learning rate: 0.0049494]
		[batch 20/20] avg loss: 0.32712746549426763		[learning rate: 0.0049404]
	Learning Rate: 0.00494041
	LOSS [training: 0.31367926465140517 | validation: 0.2274669881723906]
	TIME [epoch: 8.43 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.329702332181119		[learning rate: 0.0049314]
		[batch 20/20] avg loss: 0.37871060031310877		[learning rate: 0.0049225]
	Learning Rate: 0.00492248
	LOSS [training: 0.35420646624711394 | validation: 0.18154480392990513]
	TIME [epoch: 8.44 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3326432886327583		[learning rate: 0.0049135]
		[batch 20/20] avg loss: 0.38205983569566093		[learning rate: 0.0049046]
	Learning Rate: 0.00490462
	LOSS [training: 0.3573515621642097 | validation: 0.29225715513723505]
	TIME [epoch: 8.46 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2540018103404647		[learning rate: 0.0048957]
		[batch 20/20] avg loss: 0.5441924646750714		[learning rate: 0.0048868]
	Learning Rate: 0.00488682
	LOSS [training: 0.39909713750776804 | validation: 0.3475878653789374]
	TIME [epoch: 8.44 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.22714318529980965		[learning rate: 0.0048779]
		[batch 20/20] avg loss: 0.2941850822444427		[learning rate: 0.0048691]
	Learning Rate: 0.00486909
	LOSS [training: 0.26066413377212616 | validation: 0.1734707907086424]
	TIME [epoch: 8.47 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.21933657130675668		[learning rate: 0.0048602]
		[batch 20/20] avg loss: 0.32226427066291186		[learning rate: 0.0048514]
	Learning Rate: 0.00485141
	LOSS [training: 0.27080042098483426 | validation: 0.2513341137651838]
	TIME [epoch: 8.44 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.24281837432140918		[learning rate: 0.0048426]
		[batch 20/20] avg loss: 0.26065957717374666		[learning rate: 0.0048338]
	Learning Rate: 0.00483381
	LOSS [training: 0.25173897574757786 | validation: 0.20719328002489595]
	TIME [epoch: 8.47 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.24906490241310203		[learning rate: 0.004825]
		[batch 20/20] avg loss: 0.2714424037788712		[learning rate: 0.0048163]
	Learning Rate: 0.00481627
	LOSS [training: 0.2602536530959866 | validation: 0.31169425118659183]
	TIME [epoch: 8.44 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.394450663768387		[learning rate: 0.0048075]
		[batch 20/20] avg loss: 0.25103336791636754		[learning rate: 0.0047988]
	Learning Rate: 0.00479879
	LOSS [training: 0.3227420158423772 | validation: 0.2959018348713951]
	TIME [epoch: 8.44 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4352022340583053		[learning rate: 0.0047901]
		[batch 20/20] avg loss: 0.4578537459664897		[learning rate: 0.0047814]
	Learning Rate: 0.00478137
	LOSS [training: 0.4465279900123975 | validation: 0.17088434975120323]
	TIME [epoch: 8.45 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26654142706530487		[learning rate: 0.0047727]
		[batch 20/20] avg loss: 0.2337474991643044		[learning rate: 0.004764]
	Learning Rate: 0.00476402
	LOSS [training: 0.25014446311480465 | validation: 0.15076627601108658]
	TIME [epoch: 8.45 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.33692358449413434		[learning rate: 0.0047554]
		[batch 20/20] avg loss: 0.21542087282102446		[learning rate: 0.0047467]
	Learning Rate: 0.00474673
	LOSS [training: 0.2761722286575794 | validation: 0.1782083543455216]
	TIME [epoch: 8.45 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.22223309008241016		[learning rate: 0.0047381]
		[batch 20/20] avg loss: 0.2832325041867675		[learning rate: 0.0047295]
	Learning Rate: 0.00472951
	LOSS [training: 0.25273279713458885 | validation: 0.12816561398120985]
	TIME [epoch: 8.44 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5010564398268549		[learning rate: 0.0047209]
		[batch 20/20] avg loss: 0.2576144667724158		[learning rate: 0.0047123]
	Learning Rate: 0.00471234
	LOSS [training: 0.37933545329963525 | validation: 0.11157252601210065]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3366086796030627		[learning rate: 0.0047038]
		[batch 20/20] avg loss: 0.24425464855224602		[learning rate: 0.0046952]
	Learning Rate: 0.00469524
	LOSS [training: 0.2904316640776544 | validation: 0.1426079792448225]
	TIME [epoch: 8.44 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.30099152672619733		[learning rate: 0.0046867]
		[batch 20/20] avg loss: 0.23884529905916918		[learning rate: 0.0046782]
	Learning Rate: 0.0046782
	LOSS [training: 0.2699184128926832 | validation: 0.12437779847830055]
	TIME [epoch: 8.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26132838609951436		[learning rate: 0.0046697]
		[batch 20/20] avg loss: 0.24623318714210188		[learning rate: 0.0046612]
	Learning Rate: 0.00466122
	LOSS [training: 0.2537807866208081 | validation: 0.4927206166254764]
	TIME [epoch: 8.45 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2370548811292572		[learning rate: 0.0046528]
		[batch 20/20] avg loss: 0.29738627127171485		[learning rate: 0.0046443]
	Learning Rate: 0.00464431
	LOSS [training: 0.267220576200486 | validation: 0.2160319293751724]
	TIME [epoch: 8.45 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27983463915940554		[learning rate: 0.0046359]
		[batch 20/20] avg loss: 0.23448679238429831		[learning rate: 0.0046275]
	Learning Rate: 0.00462745
	LOSS [training: 0.25716071577185196 | validation: 0.19314823927447514]
	TIME [epoch: 8.44 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27113597588808197		[learning rate: 0.004619]
		[batch 20/20] avg loss: 0.2793219281508009		[learning rate: 0.0046107]
	Learning Rate: 0.00461066
	LOSS [training: 0.2752289520194414 | validation: 0.16816161565750748]
	TIME [epoch: 8.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.29494458563599224		[learning rate: 0.0046023]
		[batch 20/20] avg loss: 0.23230066329513283		[learning rate: 0.0045939]
	Learning Rate: 0.00459393
	LOSS [training: 0.26362262446556256 | validation: 0.1289855191828999]
	TIME [epoch: 8.47 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3988616930848439		[learning rate: 0.0045856]
		[batch 20/20] avg loss: 0.24046538868248302		[learning rate: 0.0045773]
	Learning Rate: 0.00457726
	LOSS [training: 0.31966354088366344 | validation: 0.1695237229876743]
	TIME [epoch: 8.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28623300036527205		[learning rate: 0.0045689]
		[batch 20/20] avg loss: 0.2288984572554616		[learning rate: 0.0045606]
	Learning Rate: 0.00456065
	LOSS [training: 0.2575657288103669 | validation: 0.21534888761967447]
	TIME [epoch: 8.44 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3091062822932181		[learning rate: 0.0045524]
		[batch 20/20] avg loss: 0.2540875790699265		[learning rate: 0.0045441]
	Learning Rate: 0.00454409
	LOSS [training: 0.2815969306815723 | validation: 0.2419681980784321]
	TIME [epoch: 8.44 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2375387569183526		[learning rate: 0.0045358]
		[batch 20/20] avg loss: 0.22826538973135774		[learning rate: 0.0045276]
	Learning Rate: 0.0045276
	LOSS [training: 0.23290207332485519 | validation: 0.28848937798398583]
	TIME [epoch: 8.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.28321570729673456		[learning rate: 0.0045194]
		[batch 20/20] avg loss: 0.2595253141582913		[learning rate: 0.0045112]
	Learning Rate: 0.00451117
	LOSS [training: 0.27137051072751295 | validation: 0.14473579143186682]
	TIME [epoch: 8.43 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.24655531899446834		[learning rate: 0.004503]
		[batch 20/20] avg loss: 0.2431014443069815		[learning rate: 0.0044948]
	Learning Rate: 0.0044948
	LOSS [training: 0.2448283816507249 | validation: 0.40430904554602876]
	TIME [epoch: 8.43 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3425823162805274		[learning rate: 0.0044866]
		[batch 20/20] avg loss: 0.2623859839845533		[learning rate: 0.0044785]
	Learning Rate: 0.00447849
	LOSS [training: 0.3024841501325404 | validation: 0.14071226857866762]
	TIME [epoch: 8.47 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.24983815112354768		[learning rate: 0.0044704]
		[batch 20/20] avg loss: 0.24451305058954093		[learning rate: 0.0044622]
	Learning Rate: 0.00446224
	LOSS [training: 0.24717560085654428 | validation: 0.16354656108362722]
	TIME [epoch: 8.45 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2650859241103275		[learning rate: 0.0044541]
		[batch 20/20] avg loss: 0.33947170084171713		[learning rate: 0.004446]
	Learning Rate: 0.00444604
	LOSS [training: 0.30227881247602234 | validation: 0.18630160410900876]
	TIME [epoch: 8.48 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2755018052597342		[learning rate: 0.004438]
		[batch 20/20] avg loss: 0.2190461284362364		[learning rate: 0.0044299]
	Learning Rate: 0.00442991
	LOSS [training: 0.24727396684798525 | validation: 0.23350749170479915]
	TIME [epoch: 8.45 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.27468177667102867		[learning rate: 0.0044219]
		[batch 20/20] avg loss: 0.23627616964784798		[learning rate: 0.0044138]
	Learning Rate: 0.00441383
	LOSS [training: 0.25547897315943835 | validation: 0.16268147654677936]
	TIME [epoch: 8.46 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.18880005964238572		[learning rate: 0.0044058]
		[batch 20/20] avg loss: 0.2695651147246506		[learning rate: 0.0043978]
	Learning Rate: 0.00439781
	LOSS [training: 0.22918258718351817 | validation: 0.269623962675025]
	TIME [epoch: 8.44 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.26690585556322466		[learning rate: 0.0043898]
		[batch 20/20] avg loss: 0.29537240945319904		[learning rate: 0.0043819]
	Learning Rate: 0.00438185
	LOSS [training: 0.28113913250821176 | validation: 0.18990936566886446]
	TIME [epoch: 8.45 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.22884554817070554		[learning rate: 0.0043739]
		[batch 20/20] avg loss: 0.3724005613780743		[learning rate: 0.004366]
	Learning Rate: 0.00436595
	LOSS [training: 0.30062305477438994 | validation: 0.7366779772239863]
	TIME [epoch: 8.44 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7149946198882919		[learning rate: 0.004358]
		[batch 20/20] avg loss: 0.2049825229524575		[learning rate: 0.0043501]
	Learning Rate: 0.00435011
	LOSS [training: 0.4599885714203748 | validation: 0.9494877992165114]
	TIME [epoch: 8.46 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.49719120263791766		[learning rate: 0.0043422]
		[batch 20/20] avg loss: 0.23794304241683034		[learning rate: 0.0043343]
	Learning Rate: 0.00433432
	LOSS [training: 0.367567122527374 | validation: 0.1606173207057838]
	TIME [epoch: 8.47 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.324683094376068		[learning rate: 0.0043264]
		[batch 20/20] avg loss: 0.5337031340596772		[learning rate: 0.0043186]
	Learning Rate: 0.00431859
	LOSS [training: 0.42919311421787254 | validation: 0.32030402240914524]
	TIME [epoch: 8.46 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6643202549924744		[learning rate: 0.0043107]
		[batch 20/20] avg loss: 0.598863132627973		[learning rate: 0.0043029]
	Learning Rate: 0.00430292
	LOSS [training: 0.6315916938102235 | validation: 0.6212014268892516]
	TIME [epoch: 8.46 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.35254216681517203		[learning rate: 0.0042951]
		[batch 20/20] avg loss: 0.27050798741637394		[learning rate: 0.0042873]
	Learning Rate: 0.0042873
	LOSS [training: 0.311525077115773 | validation: 0.21498014234859647]
	TIME [epoch: 8.44 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.20401203546428087		[learning rate: 0.0042795]
		[batch 20/20] avg loss: 0.20242783032506115		[learning rate: 0.0042717]
	Learning Rate: 0.00427174
	LOSS [training: 0.20321993289467097 | validation: 0.14435893262021612]
	TIME [epoch: 8.44 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2682229363409955		[learning rate: 0.004264]
		[batch 20/20] avg loss: 0.2327401352577249		[learning rate: 0.0042562]
	Learning Rate: 0.00425624
	LOSS [training: 0.25048153579936017 | validation: 0.136600059828332]
	TIME [epoch: 8.45 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.280604522045733		[learning rate: 0.0042485]
		[batch 20/20] avg loss: 0.2514314739032097		[learning rate: 0.0042408]
	Learning Rate: 0.0042408
	LOSS [training: 0.26601799797447134 | validation: 0.3370960146711617]
	TIME [epoch: 8.46 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2416462403465338		[learning rate: 0.0042331]
		[batch 20/20] avg loss: 0.2557978357956139		[learning rate: 0.0042254]
	Learning Rate: 0.00422541
	LOSS [training: 0.2487220380710738 | validation: 0.31503305913608437]
	TIME [epoch: 8.45 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.33920197198826496		[learning rate: 0.0042177]
		[batch 20/20] avg loss: 0.23457782899355725		[learning rate: 0.0042101]
	Learning Rate: 0.00421007
	LOSS [training: 0.28688990049091107 | validation: 0.24365097688568008]
	TIME [epoch: 8.44 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.1977593867921467		[learning rate: 0.0042024]
		[batch 20/20] avg loss: 0.2810396008391754		[learning rate: 0.0041948]
	Learning Rate: 0.00419479
	LOSS [training: 0.23939949381566103 | validation: 0.4132449417029948]
	TIME [epoch: 8.47 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.23953983313417226		[learning rate: 0.0041872]
		[batch 20/20] avg loss: 0.27056368111464935		[learning rate: 0.0041796]
	Learning Rate: 0.00417957
	LOSS [training: 0.2550517571244108 | validation: 0.17516018457016758]
	TIME [epoch: 8.45 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.31732690626803695		[learning rate: 0.004172]
		[batch 20/20] avg loss: 0.30686538479556125		[learning rate: 0.0041644]
	Learning Rate: 0.0041644
	LOSS [training: 0.31209614553179904 | validation: 0.22349241764067823]
	TIME [epoch: 8.49 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.231526354162325		[learning rate: 0.0041568]
		[batch 20/20] avg loss: 0.24336894722422095		[learning rate: 0.0041493]
	Learning Rate: 0.00414929
	LOSS [training: 0.23744765069327287 | validation: 0.17858067644830408]
	TIME [epoch: 8.44 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2349098662525555		[learning rate: 0.0041418]
		[batch 20/20] avg loss: 0.26599377401207414		[learning rate: 0.0041342]
	Learning Rate: 0.00413423
	LOSS [training: 0.25045182013231476 | validation: 0.14937975673434825]
	TIME [epoch: 8.47 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3578497584010759		[learning rate: 0.0041267]
		[batch 20/20] avg loss: 0.26358099086451003		[learning rate: 0.0041192]
	Learning Rate: 0.00411923
	LOSS [training: 0.310715374632793 | validation: 0.2749712964713432]
	TIME [epoch: 8.43 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2768127367623707		[learning rate: 0.0041117]
		[batch 20/20] avg loss: 0.3551841854077999		[learning rate: 0.0041043]
	Learning Rate: 0.00410428
	LOSS [training: 0.3159984610850854 | validation: 0.3017733779316738]
	TIME [epoch: 8.44 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.1959139099327679		[learning rate: 0.0040968]
		[batch 20/20] avg loss: 0.242186667319027		[learning rate: 0.0040894]
	Learning Rate: 0.00408938
	LOSS [training: 0.21905028862589745 | validation: 0.1438048372249774]
	TIME [epoch: 8.46 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.23704034443639857		[learning rate: 0.004082]
		[batch 20/20] avg loss: 0.23398347528417335		[learning rate: 0.0040745]
	Learning Rate: 0.00407454
	LOSS [training: 0.23551190986028597 | validation: 0.148562518844157]
	TIME [epoch: 8.44 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3779394854382555		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.3763028447505731		[learning rate: 0.0040598]
	Learning Rate: 0.00405976
	LOSS [training: 0.37712116509441423 | validation: 0.14956720482399768]
	TIME [epoch: 8.45 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.33190536236254364		[learning rate: 0.0040524]
		[batch 20/20] avg loss: 0.22168759530432963		[learning rate: 0.004045]
	Learning Rate: 0.00404502
	LOSS [training: 0.2767964788334366 | validation: 0.22537155747458276]
	TIME [epoch: 8.45 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.3828570513857909		[learning rate: 0.0040377]
		[batch 20/20] avg loss: 0.19546195736264946		[learning rate: 0.0040303]
	Learning Rate: 0.00403034
	LOSS [training: 0.2891595043742202 | validation: 0.24246345243692569]
	TIME [epoch: 8.46 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5658929313552591		[learning rate: 0.004023]
		[batch 20/20] avg loss: 0.4603607453218809		[learning rate: 0.0040157]
	Learning Rate: 0.00401572
	LOSS [training: 0.5131268383385701 | validation: 0.14876840410368686]
	TIME [epoch: 8.45 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.2163810629312118		[learning rate: 0.0040084]
		[batch 20/20] avg loss: 0.20581989633157782		[learning rate: 0.0040011]
	Learning Rate: 0.00400114
	LOSS [training: 0.2111004796313948 | validation: 0.14401305742517634]
	TIME [epoch: 8.44 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.18132659488379957		[learning rate: 0.0039939]
		[batch 20/20] avg loss: 0.2040227528757474		[learning rate: 0.0039866]
	Learning Rate: 0.00398662
	LOSS [training: 0.1926746738797735 | validation: 0.09957185880350991]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study202/model_tr_study202_r5_20240219_193931/states/model_tr_study202_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.265134768791433		[learning rate: 0.0039794]
		[batch 20/20] avg loss: 0.209301184655912		[learning rate: 0.0039722]
	Learning Rate: 0.00397216
	LOSS [training: 0.23721797672367245 | validation: 0.15567249535948313]
	TIME [epoch: 8.45 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.1915351456357413		[learning rate: 0.0039649]
		[batch 20/20] avg loss: 0.25256493874946384		[learning rate: 0.0039577]
	Learning Rate: 0.00395774
	LOSS [training: 0.22205004219260255 | validation: 0.13740813651581188]
	TIME [epoch: 8.42 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.536495796808198		[learning rate: 0.0039506]
		[batch 20/20] avg loss: 0.21311800145671764		[learning rate: 0.0039434]
	Learning Rate: 0.00394338
	LOSS [training: 0.3748068991324579 | validation: 0.11134795603217959]
	TIME [epoch: 8.42 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4767542982109359		[learning rate: 0.0039362]
		[batch 20/20] avg loss: 0.29814222135354157		[learning rate: 0.0039291]
	Learning Rate: 0.00392907
	LOSS [training: 0.38744825978223874 | validation: 0.1959796811842787]
	TIME [epoch: 8.45 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5163729433769787		[learning rate: 0.0039219]
		[batch 20/20] avg loss: 0.6192498802386982		[learning rate: 0.0039148]
	Learning Rate: 0.00391481
	LOSS [training: 0.5678114118078383 | validation: 0.73887766298977]
	TIME [epoch: 8.42 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8598273278033239		[learning rate: 0.0039077]
		[batch 20/20] avg loss: 0.3091248354942838		[learning rate: 0.0039006]
	Learning Rate: 0.0039006
	LOSS [training: 0.5844760816488039 | validation: 2.0588727032147305]
	TIME [epoch: 8.42 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9089241888821986		[learning rate: 0.0038935]
		[batch 20/20] avg loss: 1.2958142152655423		[learning rate: 0.0038864]
	Learning Rate: 0.00388645
	LOSS [training: 1.1023692020738705 | validation: 0.467780605897025]
	TIME [epoch: 8.43 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.41385824518996606		[learning rate: 0.0038794]
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
ERROR:
Encountered nan in loss and reached the maximum number of model alterations: 4.
