Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r0', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2387173393

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.534602530691924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.534602530691924 | validation: 10.363780283014787]
	TIME [epoch: 52.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.417744576665713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.417744576665713 | validation: 6.959170848477314]
	TIME [epoch: 8.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.852395719443909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852395719443909 | validation: 5.438861573381813]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.3285933163297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3285933163297 | validation: 4.467274315672118]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.861796924127732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.861796924127732 | validation: 3.998345176139072]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.793464524196421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.793464524196421 | validation: 3.8556993468702547]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.689903738061092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.689903738061092 | validation: 4.280045491930471]
	TIME [epoch: 8.66 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.613033369370858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.613033369370858 | validation: 3.6938721190987307]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.509282350743013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.509282350743013 | validation: 4.245827524865597]
	TIME [epoch: 8.47 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.512212058226934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.512212058226934 | validation: 3.6138486350399726]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.397016932355332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.397016932355332 | validation: 4.409051570224622]
	TIME [epoch: 8.44 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.31756094195325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.31756094195325 | validation: 3.534006209002526]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.203580981213915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.203580981213915 | validation: 3.3899144939042642]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2516747384623965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2516747384623965 | validation: 3.385828094714819]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.306504151510175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.306504151510175 | validation: 4.011730310900915]
	TIME [epoch: 8.44 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.211606932516982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.211606932516982 | validation: 3.5116664705584864]
	TIME [epoch: 8.44 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.161998973815192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.161998973815192 | validation: 3.8423758233500585]
	TIME [epoch: 8.47 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.381578496527818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.381578496527818 | validation: 3.9056382372514777]
	TIME [epoch: 8.45 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.943684496102663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.943684496102663 | validation: 4.384871837183207]
	TIME [epoch: 8.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.317531995060069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.317531995060069 | validation: 3.3230884141546895]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.079096729773917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.079096729773917 | validation: 3.6333323027380784]
	TIME [epoch: 8.47 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8409587079262444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8409587079262444 | validation: 5.584782962998308]
	TIME [epoch: 8.44 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.160908830385373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.160908830385373 | validation: 3.1189841662726803]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8686167384876837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8686167384876837 | validation: 3.8303692266938523]
	TIME [epoch: 8.46 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8923956720592563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8923956720592563 | validation: 3.283145938165166]
	TIME [epoch: 8.44 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8353099743165524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8353099743165524 | validation: 4.167300623148223]
	TIME [epoch: 8.43 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.913540104265196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.913540104265196 | validation: 3.7188252490702727]
	TIME [epoch: 8.44 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8561282113128463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8561282113128463 | validation: 3.0131899397998168]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.909807423182893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.909807423182893 | validation: 3.5592940497992]
	TIME [epoch: 8.45 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.664386110392867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.664386110392867 | validation: 3.1246657924338526]
	TIME [epoch: 8.44 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8966339654229865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8966339654229865 | validation: 3.4081455677296937]
	TIME [epoch: 8.44 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.015098115384224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.015098115384224 | validation: 3.2340037056590965]
	TIME [epoch: 8.45 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.730957061702175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.730957061702175 | validation: 4.421975832425892]
	TIME [epoch: 8.46 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.851018790649173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.851018790649173 | validation: 3.204417527046686]
	TIME [epoch: 8.43 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6764117609500957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6764117609500957 | validation: 4.128420978885017]
	TIME [epoch: 8.44 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9349138607941065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9349138607941065 | validation: 3.1967093653025493]
	TIME [epoch: 8.46 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7078209920432905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7078209920432905 | validation: 3.0181691578714593]
	TIME [epoch: 8.46 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.734517680830546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.734517680830546 | validation: 3.2578783361631776]
	TIME [epoch: 8.44 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.824661528389504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.824661528389504 | validation: 3.090911077067906]
	TIME [epoch: 8.45 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.607071563139807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.607071563139807 | validation: 3.0822948315333605]
	TIME [epoch: 8.47 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6605500733145093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6605500733145093 | validation: 2.992631019385325]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.078697035671897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.078697035671897 | validation: 3.038326693500541]
	TIME [epoch: 8.44 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6278279027083364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6278279027083364 | validation: 2.8974218312535345]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8083531016045007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8083531016045007 | validation: 3.2323590231971995]
	TIME [epoch: 8.48 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.557397483148553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.557397483148553 | validation: 3.4258029699867816]
	TIME [epoch: 8.44 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.68649343702297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.68649343702297 | validation: 2.82960021732519]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7140477138465435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7140477138465435 | validation: 3.8233799779365176]
	TIME [epoch: 8.43 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.649601523870763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.649601523870763 | validation: 3.064565075290011]
	TIME [epoch: 8.46 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5402788765758437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5402788765758437 | validation: 2.7459567258327935]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4974790841088614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4974790841088614 | validation: 2.8513076531784773]
	TIME [epoch: 8.44 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5588509257681737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5588509257681737 | validation: 3.192329328584309]
	TIME [epoch: 8.44 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.474940420386205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.474940420386205 | validation: 2.7058835562383234]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9944104659530986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9944104659530986 | validation: 3.0728405654678896]
	TIME [epoch: 8.43 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7349163052460894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7349163052460894 | validation: 2.708009625850391]
	TIME [epoch: 8.43 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4983044025349956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4983044025349956 | validation: 3.1360790104921863]
	TIME [epoch: 8.43 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4435991530520482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4435991530520482 | validation: 3.636036487487247]
	TIME [epoch: 8.46 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.476285840049031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.476285840049031 | validation: 2.749610407215117]
	TIME [epoch: 8.43 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8407645056270843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8407645056270843 | validation: 2.842708958868445]
	TIME [epoch: 8.43 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.336904183331666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.336904183331666 | validation: 3.4352640093900444]
	TIME [epoch: 8.42 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4793479217754184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4793479217754184 | validation: 3.771948566650496]
	TIME [epoch: 8.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.645483803736897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.645483803736897 | validation: 3.0255080694868433]
	TIME [epoch: 8.43 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.41196056100461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.41196056100461 | validation: 2.9100553850059123]
	TIME [epoch: 8.44 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.444159819208598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.444159819208598 | validation: 2.743868881492018]
	TIME [epoch: 8.43 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.55267197120457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.55267197120457 | validation: 3.124431531497711]
	TIME [epoch: 8.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3867998639618144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3867998639618144 | validation: 3.094158159770589]
	TIME [epoch: 8.43 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.342754363852857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342754363852857 | validation: 3.937498956291784]
	TIME [epoch: 8.43 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.440671789845762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.440671789845762 | validation: 3.0452570295345236]
	TIME [epoch: 8.43 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3981081216118114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3981081216118114 | validation: 3.0322659154334146]
	TIME [epoch: 8.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.461482691636937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.461482691636937 | validation: 2.9512541840738526]
	TIME [epoch: 8.42 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3659957604163404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3659957604163404 | validation: 2.742167768215281]
	TIME [epoch: 8.44 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3487651416967688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3487651416967688 | validation: 3.331111994401347]
	TIME [epoch: 8.42 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.463556023532793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.463556023532793 | validation: 2.7610534964939895]
	TIME [epoch: 8.45 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3833179569929883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3833179569929883 | validation: 2.9364238657483215]
	TIME [epoch: 8.43 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3313477600062193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3313477600062193 | validation: 3.157923033132435]
	TIME [epoch: 8.42 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.339347164460894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.339347164460894 | validation: 2.6135560862916933]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.390033548516919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.390033548516919 | validation: 2.9678848463360286]
	TIME [epoch: 8.44 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.340534390588954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.340534390588954 | validation: 2.6742718981264715]
	TIME [epoch: 8.43 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.474185029793889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.474185029793889 | validation: 3.120370234069751]
	TIME [epoch: 8.43 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3676925972317724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3676925972317724 | validation: 2.5958704481540127]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2618348922394853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2618348922394853 | validation: 2.8344089491140974]
	TIME [epoch: 8.45 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.307552220669917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.307552220669917 | validation: 3.0171248300441205]
	TIME [epoch: 8.43 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.589143994084511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.589143994084511 | validation: 2.8673215581551403]
	TIME [epoch: 8.43 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3026940343322564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3026940343322564 | validation: 2.6984902497574286]
	TIME [epoch: 8.43 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.33123808395361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.33123808395361 | validation: 2.7755611436978893]
	TIME [epoch: 8.44 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4223878917481807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4223878917481807 | validation: 3.022703110602367]
	TIME [epoch: 8.43 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4194658137353087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4194658137353087 | validation: 2.8350749016012626]
	TIME [epoch: 8.43 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3981204256849282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3981204256849282 | validation: 2.804670996908161]
	TIME [epoch: 8.42 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3583701917287834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3583701917287834 | validation: 3.3020400042419733]
	TIME [epoch: 8.46 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3712387047306587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3712387047306587 | validation: 2.824171787391458]
	TIME [epoch: 8.43 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2905818482360814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2905818482360814 | validation: 3.4132942018952495]
	TIME [epoch: 8.42 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2831819052384077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2831819052384077 | validation: 3.18773859231343]
	TIME [epoch: 8.43 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4213120189521717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4213120189521717 | validation: 2.669524970489132]
	TIME [epoch: 8.45 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3970930158289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3970930158289 | validation: 2.6493185044303527]
	TIME [epoch: 8.42 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.356120530596332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.356120530596332 | validation: 2.874785624963338]
	TIME [epoch: 8.43 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.284014778414555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.284014778414555 | validation: 2.7113797914023157]
	TIME [epoch: 8.44 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3855376943144884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3855376943144884 | validation: 2.930578883640548]
	TIME [epoch: 8.44 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.320560836464442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.320560836464442 | validation: 2.6366102181580264]
	TIME [epoch: 8.42 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.242703536079175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.242703536079175 | validation: 2.5648869023011684]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2882570148757226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2882570148757226 | validation: 2.604829366923064]
	TIME [epoch: 8.44 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.264389215343235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.264389215343235 | validation: 2.5852632353824374]
	TIME [epoch: 8.44 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.419446850199204		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 3.419446850199204 | validation: 2.7592866416981763]
	TIME [epoch: 8.43 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2620728380084167		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 3.2620728380084167 | validation: 3.598196312183655]
	TIME [epoch: 8.43 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.470381512037426		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 3.470381512037426 | validation: 2.707319997097434]
	TIME [epoch: 8.45 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.202174679636047		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 3.202174679636047 | validation: 3.137056115475731]
	TIME [epoch: 8.44 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.30135985920271		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 3.30135985920271 | validation: 2.6728851716402007]
	TIME [epoch: 8.43 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4246640309247134		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 3.4246640309247134 | validation: 3.2092705077585064]
	TIME [epoch: 8.44 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.386424608226182		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 3.386424608226182 | validation: 2.838059307894045]
	TIME [epoch: 8.45 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.242069234115538		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 3.242069234115538 | validation: 2.930816258197643]
	TIME [epoch: 8.43 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2881835371666384		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 3.2881835371666384 | validation: 2.5903610511890562]
	TIME [epoch: 8.42 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2107602540581412		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 3.2107602540581412 | validation: 2.651818828074025]
	TIME [epoch: 8.42 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3743701840876996		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 3.3743701840876996 | validation: 3.3156274770740506]
	TIME [epoch: 8.46 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4097468157062445		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 3.4097468157062445 | validation: 3.005674864781293]
	TIME [epoch: 8.43 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2807016582145687		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 3.2807016582145687 | validation: 2.8767004080782956]
	TIME [epoch: 8.43 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.279301357283265		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 3.279301357283265 | validation: 2.7757587246258844]
	TIME [epoch: 8.44 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.303168265221158		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 3.303168265221158 | validation: 2.5957683096057607]
	TIME [epoch: 8.45 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1768928565113472		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 3.1768928565113472 | validation: 2.6877943508793494]
	TIME [epoch: 8.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.45835671418419		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 3.45835671418419 | validation: 2.7827108186353247]
	TIME [epoch: 8.44 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.232097506351315		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 3.232097506351315 | validation: 2.5448013708593153]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.162817612623009		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 3.162817612623009 | validation: 2.7540181102507537]
	TIME [epoch: 8.45 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.27463601819352		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 3.27463601819352 | validation: 2.570169022210311]
	TIME [epoch: 8.44 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1593324263755345		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 3.1593324263755345 | validation: 3.290824929362993]
	TIME [epoch: 8.43 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2397155069291963		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 3.2397155069291963 | validation: 2.650547569044496]
	TIME [epoch: 8.45 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2841185112787317		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 3.2841185112787317 | validation: 2.8389112102264473]
	TIME [epoch: 8.45 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.195747994461696		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 3.195747994461696 | validation: 3.6672816394066405]
	TIME [epoch: 8.43 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3375767398877634		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 3.3375767398877634 | validation: 2.963184598604415]
	TIME [epoch: 8.44 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.232327734488969		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 3.232327734488969 | validation: 3.499039184157609]
	TIME [epoch: 8.44 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4022824075989604		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 3.4022824075989604 | validation: 2.6675019980721455]
	TIME [epoch: 8.46 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1917497374258184		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 3.1917497374258184 | validation: 2.5802268082743787]
	TIME [epoch: 8.45 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.206494649669705		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 3.206494649669705 | validation: 2.836317604621236]
	TIME [epoch: 8.45 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2258451424658245		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 3.2258451424658245 | validation: 3.110308548321621]
	TIME [epoch: 8.46 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3944830910799277		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 3.3944830910799277 | validation: 3.020628998694482]
	TIME [epoch: 8.44 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2670918684317085		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 3.2670918684317085 | validation: 3.074803940536377]
	TIME [epoch: 8.44 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.240649357951342		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 3.240649357951342 | validation: 2.628065450579548]
	TIME [epoch: 8.44 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.214671948553458		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 3.214671948553458 | validation: 2.5281122943618954]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.250661550138156		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 3.250661550138156 | validation: 2.6696685492184065]
	TIME [epoch: 8.43 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2064784598001568		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 3.2064784598001568 | validation: 2.9235249010315543]
	TIME [epoch: 8.43 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2321354873233346		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 3.2321354873233346 | validation: 3.0688393539920296]
	TIME [epoch: 8.43 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.33316028680073		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 3.33316028680073 | validation: 2.6524885603403177]
	TIME [epoch: 8.46 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.135100878650055		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 3.135100878650055 | validation: 2.6771451894759335]
	TIME [epoch: 8.44 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3055523096101083		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 3.3055523096101083 | validation: 2.6291272186219152]
	TIME [epoch: 8.44 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2162417277518003		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 3.2162417277518003 | validation: 2.55556877910972]
	TIME [epoch: 8.44 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1408090669018227		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 3.1408090669018227 | validation: 2.7713078174670756]
	TIME [epoch: 8.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2489586976970948		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 3.2489586976970948 | validation: 2.599093324499574]
	TIME [epoch: 8.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.17191912805066		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 3.17191912805066 | validation: 2.7988916403906297]
	TIME [epoch: 8.44 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1980029024523926		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 3.1980029024523926 | validation: 3.0127319276362527]
	TIME [epoch: 8.44 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2740188196998274		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 3.2740188196998274 | validation: 3.0780787735525914]
	TIME [epoch: 8.45 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.288854939340289		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 3.288854939340289 | validation: 2.5702405037455427]
	TIME [epoch: 8.44 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2157423128906757		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 3.2157423128906757 | validation: 2.5885521822480606]
	TIME [epoch: 8.43 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.192559738381318		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 3.192559738381318 | validation: 2.559915161854893]
	TIME [epoch: 8.43 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.235281169924041		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 3.235281169924041 | validation: 2.557862512660072]
	TIME [epoch: 8.46 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1744396478938706		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 3.1744396478938706 | validation: 2.5893708680951915]
	TIME [epoch: 8.43 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.18609450667655		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 3.18609450667655 | validation: 3.242638235105149]
	TIME [epoch: 8.43 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2426902498703627		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 3.2426902498703627 | validation: 2.558543260514546]
	TIME [epoch: 8.45 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2065443513064635		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 3.2065443513064635 | validation: 2.7199223530749395]
	TIME [epoch: 8.45 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.189392759748627		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 3.189392759748627 | validation: 2.7466143875370603]
	TIME [epoch: 8.43 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1468749107567264		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 3.1468749107567264 | validation: 2.527784817621648]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.204208171949977		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 3.204208171949977 | validation: 2.5917405921410657]
	TIME [epoch: 8.47 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.095498291413819		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 3.095498291413819 | validation: 2.5599855071554165]
	TIME [epoch: 8.45 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2059222257339144		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 3.2059222257339144 | validation: 2.6625115260930556]
	TIME [epoch: 8.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.170240711119903		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 3.170240711119903 | validation: 2.672463393696504]
	TIME [epoch: 8.44 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.149931857486514		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 3.149931857486514 | validation: 2.54413255758378]
	TIME [epoch: 8.46 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.097075780998992		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 3.097075780998992 | validation: 2.5300231669602167]
	TIME [epoch: 8.46 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.118944063648357		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 3.118944063648357 | validation: 2.569213179039285]
	TIME [epoch: 8.45 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1484771466103454		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 3.1484771466103454 | validation: 2.509322939738021]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1113375540867616		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 3.1113375540867616 | validation: 2.5173374784536744]
	TIME [epoch: 8.47 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.226938185579661		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 3.226938185579661 | validation: 2.6948836172789417]
	TIME [epoch: 8.44 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.126759804758037		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 3.126759804758037 | validation: 2.521127578525851]
	TIME [epoch: 8.45 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0878983091815173		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 3.0878983091815173 | validation: 2.673874753186141]
	TIME [epoch: 8.44 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1131254273201816		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 3.1131254273201816 | validation: 2.4907869337133715]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.150894173185288		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 3.150894173185288 | validation: 2.513704584451047]
	TIME [epoch: 8.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1168239049772204		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 3.1168239049772204 | validation: 2.501393686790255]
	TIME [epoch: 8.44 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1827277503278624		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 3.1827277503278624 | validation: 3.0006775364685834]
	TIME [epoch: 8.45 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.173349307845689		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 3.173349307845689 | validation: 2.5427553678197707]
	TIME [epoch: 8.46 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.117530480178865		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 3.117530480178865 | validation: 2.6002893825556814]
	TIME [epoch: 8.45 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1970304086701056		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 3.1970304086701056 | validation: 2.6313006141172264]
	TIME [epoch: 8.44 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.248734019166469		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 3.248734019166469 | validation: 2.5366539794521312]
	TIME [epoch: 8.44 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1239669823695415		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 3.1239669823695415 | validation: 2.64771945289133]
	TIME [epoch: 8.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.086849122601892		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 3.086849122601892 | validation: 2.564061309066791]
	TIME [epoch: 8.46 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1244002154633685		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 3.1244002154633685 | validation: 2.51504507623338]
	TIME [epoch: 8.43 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1756506530597557		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 3.1756506530597557 | validation: 2.546320476032677]
	TIME [epoch: 8.44 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.125872024105278		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 3.125872024105278 | validation: 2.598498752776689]
	TIME [epoch: 8.46 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1102752041858808		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 3.1102752041858808 | validation: 2.56162200805801]
	TIME [epoch: 8.44 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1480284444822706		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 3.1480284444822706 | validation: 2.7970570308429767]
	TIME [epoch: 8.43 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1196431080970135		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 3.1196431080970135 | validation: 2.7132147584970165]
	TIME [epoch: 8.43 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.111515434082537		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 3.111515434082537 | validation: 2.5483806634593025]
	TIME [epoch: 8.45 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0782279504370473		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 3.0782279504370473 | validation: 2.7182092355674965]
	TIME [epoch: 8.44 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.131772491538279		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 3.131772491538279 | validation: 2.801677675693802]
	TIME [epoch: 8.44 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1770799509353838		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 3.1770799509353838 | validation: 2.684333738994324]
	TIME [epoch: 8.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1251680926873715		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 3.1251680926873715 | validation: 2.5183499953136455]
	TIME [epoch: 8.46 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0652562070263376		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 3.0652562070263376 | validation: 2.749054463769103]
	TIME [epoch: 8.43 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1679330034471866		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 3.1679330034471866 | validation: 2.9770342877466227]
	TIME [epoch: 8.44 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1868503270627615		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 3.1868503270627615 | validation: 2.52131880311047]
	TIME [epoch: 8.43 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1425511808120166		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 3.1425511808120166 | validation: 2.578914916704331]
	TIME [epoch: 8.46 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0979553962304407		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 3.0979553962304407 | validation: 2.536074560224111]
	TIME [epoch: 8.44 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.079877398083526		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 3.079877398083526 | validation: 2.942863984874589]
	TIME [epoch: 8.43 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1468478945423177		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 3.1468478945423177 | validation: 2.640777480966652]
	TIME [epoch: 8.44 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1500686343636155		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 3.1500686343636155 | validation: 2.63893983570474]
	TIME [epoch: 8.46 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.196114209808933		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 3.196114209808933 | validation: 2.6789868272860335]
	TIME [epoch: 8.44 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.118870979664379		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 3.118870979664379 | validation: 2.521292441747516]
	TIME [epoch: 8.44 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1570848415109225		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 3.1570848415109225 | validation: 2.517275540629995]
	TIME [epoch: 8.44 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.076741640286505		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 3.076741640286505 | validation: 2.5224518416541857]
	TIME [epoch: 8.46 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.080974975996063		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 3.080974975996063 | validation: 2.699347817712776]
	TIME [epoch: 8.43 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1211464550983634		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 3.1211464550983634 | validation: 2.955738406844628]
	TIME [epoch: 8.44 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2162098147528475		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 3.2162098147528475 | validation: 2.612783671799006]
	TIME [epoch: 8.45 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1117926904938153		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 3.1117926904938153 | validation: 2.543324378499366]
	TIME [epoch: 8.44 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0969532716145514		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 3.0969532716145514 | validation: 2.509163095340684]
	TIME [epoch: 8.43 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.125061390239043		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 3.125061390239043 | validation: 2.64371311257311]
	TIME [epoch: 8.44 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1674104926720568		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 3.1674104926720568 | validation: 2.4998612604148573]
	TIME [epoch: 8.46 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1016107426468085		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 3.1016107426468085 | validation: 2.53303057084943]
	TIME [epoch: 8.43 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.121131631081268		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 3.121131631081268 | validation: 2.9074386494844715]
	TIME [epoch: 8.43 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1160310219936695		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 3.1160310219936695 | validation: 2.5741804073702266]
	TIME [epoch: 8.44 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0868481589157293		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 3.0868481589157293 | validation: 2.509683496502911]
	TIME [epoch: 8.46 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1168922375987056		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 3.1168922375987056 | validation: 2.5591266110388067]
	TIME [epoch: 8.44 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.105791475836952		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 3.105791475836952 | validation: 2.555966959041726]
	TIME [epoch: 8.44 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1362381744928833		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 3.1362381744928833 | validation: 2.524237143527551]
	TIME [epoch: 8.45 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.083693239740342		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 3.083693239740342 | validation: 2.5579429884760727]
	TIME [epoch: 8.45 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0868374109380077		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 3.0868374109380077 | validation: 2.5312777387506333]
	TIME [epoch: 8.44 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.075840336172558		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 3.075840336172558 | validation: 2.7313051158909887]
	TIME [epoch: 8.44 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.131179886497694		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 3.131179886497694 | validation: 2.5408711777230444]
	TIME [epoch: 8.47 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1234758914330176		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 3.1234758914330176 | validation: 2.5555592100163036]
	TIME [epoch: 8.44 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1033362770922195		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 3.1033362770922195 | validation: 2.511215683528682]
	TIME [epoch: 8.43 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.168532882298225		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 3.168532882298225 | validation: 2.5660982229646323]
	TIME [epoch: 8.44 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0746803244897034		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 3.0746803244897034 | validation: 2.6683660878442357]
	TIME [epoch: 8.46 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.092883359566628		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 3.092883359566628 | validation: 2.5357223054438616]
	TIME [epoch: 8.44 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0929197288356676		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 3.0929197288356676 | validation: 2.5714848286229617]
	TIME [epoch: 8.43 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1202618564533515		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 3.1202618564533515 | validation: 2.524292314510552]
	TIME [epoch: 8.44 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1114445357324314		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 3.1114445357324314 | validation: 2.5309929445435477]
	TIME [epoch: 8.47 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0580798905504087		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 3.0580798905504087 | validation: 2.550089534063263]
	TIME [epoch: 8.43 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.084349506330869		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 3.084349506330869 | validation: 2.4955470469038312]
	TIME [epoch: 8.44 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2276627735661		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 3.2276627735661 | validation: 2.542145817178795]
	TIME [epoch: 8.44 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.109906717269614		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 3.109906717269614 | validation: 2.5006369345878503]
	TIME [epoch: 8.44 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.080539029709322		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 3.080539029709322 | validation: 2.4984303865561244]
	TIME [epoch: 8.43 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.072763878968776		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 3.072763878968776 | validation: 2.511192504479559]
	TIME [epoch: 8.43 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0797370146177463		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 3.0797370146177463 | validation: 2.5344258490652996]
	TIME [epoch: 8.45 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.106469977482848		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 3.106469977482848 | validation: 2.550839533667176]
	TIME [epoch: 8.44 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.059466057763634		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 3.059466057763634 | validation: 2.53721153476933]
	TIME [epoch: 8.43 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.129959214075628		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 3.129959214075628 | validation: 2.735423754388414]
	TIME [epoch: 8.43 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1017965687993696		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 3.1017965687993696 | validation: 2.525377771618375]
	TIME [epoch: 8.45 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.100410058839874		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 3.100410058839874 | validation: 2.6875470093365332]
	TIME [epoch: 8.43 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0886058923041726		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 3.0886058923041726 | validation: 2.6509185303752805]
	TIME [epoch: 8.43 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1061319791380275		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 3.1061319791380275 | validation: 2.6616097271941115]
	TIME [epoch: 8.42 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.21946705765789		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 3.21946705765789 | validation: 2.5199908203790313]
	TIME [epoch: 8.46 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0727326391580396		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 3.0727326391580396 | validation: 2.5573161692517705]
	TIME [epoch: 8.43 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.083406943938264		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 3.083406943938264 | validation: 3.0815904687524096]
	TIME [epoch: 8.42 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1336699942610213		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 3.1336699942610213 | validation: 2.504366246392708]
	TIME [epoch: 8.43 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0352574886465753		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 3.0352574886465753 | validation: 2.5351121512983554]
	TIME [epoch: 8.44 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0494047033950045		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 3.0494047033950045 | validation: 2.51915051622923]
	TIME [epoch: 8.42 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0399391762027284		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 3.0399391762027284 | validation: 2.717911877451312]
	TIME [epoch: 8.43 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1000150686372825		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 3.1000150686372825 | validation: 2.505285596097198]
	TIME [epoch: 8.45 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0677317236908523		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 3.0677317236908523 | validation: 2.509295606273778]
	TIME [epoch: 8.43 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0574998736958263		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 3.0574998736958263 | validation: 2.5105968343155847]
	TIME [epoch: 8.43 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0549030630789047		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 3.0549030630789047 | validation: 2.5404349933488657]
	TIME [epoch: 8.43 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.082461335364325		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 3.082461335364325 | validation: 2.496996466734964]
	TIME [epoch: 8.45 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1239479366497247		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 3.1239479366497247 | validation: 2.559050391596564]
	TIME [epoch: 8.43 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.07968322661495		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 3.07968322661495 | validation: 2.5009847693131793]
	TIME [epoch: 8.43 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0547493882543355		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 3.0547493882543355 | validation: 2.556950845078556]
	TIME [epoch: 8.42 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1058728312532766		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 3.1058728312532766 | validation: 2.5561192792601792]
	TIME [epoch: 8.46 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0831766952953576		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 3.0831766952953576 | validation: 2.4972203886040862]
	TIME [epoch: 8.43 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0547600960054715		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 3.0547600960054715 | validation: 2.5135656158504696]
	TIME [epoch: 8.43 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.119681979079896		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 3.119681979079896 | validation: 2.513545533660364]
	TIME [epoch: 8.43 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0700679435809075		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 3.0700679435809075 | validation: 2.617396210379268]
	TIME [epoch: 8.45 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.075404145603275		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 3.075404145603275 | validation: 2.6403648116635505]
	TIME [epoch: 8.43 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.135926754273695		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 3.135926754273695 | validation: 2.5549244350472233]
	TIME [epoch: 8.43 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.040711736123198		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 3.040711736123198 | validation: 2.609279814624331]
	TIME [epoch: 8.44 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0576884650576566		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 3.0576884650576566 | validation: 2.5982581889069385]
	TIME [epoch: 8.45 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.090120426786169		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 3.090120426786169 | validation: 2.5016983726127613]
	TIME [epoch: 8.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0573080415725515		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 3.0573080415725515 | validation: 2.5773402966177166]
	TIME [epoch: 8.43 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0792352264405833		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 3.0792352264405833 | validation: 2.1075042114000144]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3277183292259678		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 2.3277183292259678 | validation: 1.91390850476308]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1240702467414594		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 2.1240702467414594 | validation: 1.5376634290195645]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0192075981412456		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 2.0192075981412456 | validation: 1.4928596900268625]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.9735631306145542		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 1.9735631306145542 | validation: 1.5018132815837917]
	TIME [epoch: 8.43 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2348571146234915		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 2.2348571146234915 | validation: 1.2859553076824513]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0059938248535287		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 2.0059938248535287 | validation: 1.5136288265815279]
	TIME [epoch: 8.42 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8282201743630047		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 1.8282201743630047 | validation: 1.3997665206396646]
	TIME [epoch: 8.42 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7729478368058238		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 1.7729478368058238 | validation: 1.2747882181409564]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_276.pth
	Model improved!!!
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6372895660630362		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 1.6372895660630362 | validation: 1.2720393883311083]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5651246769434413		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 1.5651246769434413 | validation: 1.2895823434726876]
	TIME [epoch: 8.43 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4548515062818566		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 1.4548515062818566 | validation: 1.0414547377906462]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.326765449660913		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 1.326765449660913 | validation: 0.9623790542753119]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3054816239346367		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 1.3054816239346367 | validation: 1.0526264697050505]
	TIME [epoch: 8.42 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1852386103218153		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 1.1852386103218153 | validation: 0.7906708511403353]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1062867108946246		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 1.1062867108946246 | validation: 0.8961507247812972]
	TIME [epoch: 8.42 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0994131406430143		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 1.0994131406430143 | validation: 0.8346590412576455]
	TIME [epoch: 8.45 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0191665213079208		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 1.0191665213079208 | validation: 0.7582852937533427]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9312163831713225		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.9312163831713225 | validation: 0.7514267568911683]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9756362668588562		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.9756362668588562 | validation: 0.841220380839693]
	TIME [epoch: 8.42 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8976143916241164		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.8976143916241164 | validation: 0.6875418542458209]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8838316532320626		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.8838316532320626 | validation: 0.6054864767462704]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8415539137387034		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.8415539137387034 | validation: 0.6233153094518341]
	TIME [epoch: 8.42 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7287036313363326		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.7287036313363326 | validation: 0.5884458708425953]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7563439771133866		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.7563439771133866 | validation: 0.5254086495282986]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7352379863827385		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.7352379863827385 | validation: 0.5078096485145103]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6971790472604728		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.6971790472604728 | validation: 0.5061383112584628]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6614282307577735		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.6614282307577735 | validation: 0.5171375674964385]
	TIME [epoch: 8.43 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6731852419751101		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.6731852419751101 | validation: 0.6288188763236116]
	TIME [epoch: 8.45 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7181586506012968		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.7181586506012968 | validation: 0.6476415616784028]
	TIME [epoch: 8.43 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7356903829971948		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.7356903829971948 | validation: 0.5516773596544821]
	TIME [epoch: 8.43 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6641254072897551		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.6641254072897551 | validation: 0.5164580324874174]
	TIME [epoch: 8.44 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.653310040262554		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.653310040262554 | validation: 0.5071020180513743]
	TIME [epoch: 8.44 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6775899780327757		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.6775899780327757 | validation: 0.47520156069432773]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6121166671018619		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.6121166671018619 | validation: 0.5162173175371311]
	TIME [epoch: 8.43 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.668369313008631		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.668369313008631 | validation: 0.47975885636175225]
	TIME [epoch: 8.43 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6903544437424924		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.6903544437424924 | validation: 0.44104840968233877]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6995151528259372		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.6995151528259372 | validation: 0.4579649721967223]
	TIME [epoch: 8.42 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6099868343435011		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.6099868343435011 | validation: 0.7425886522104996]
	TIME [epoch: 8.43 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5950387273915988		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.5950387273915988 | validation: 0.5809107339211733]
	TIME [epoch: 8.44 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6243201001123087		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.6243201001123087 | validation: 0.5657950301431864]
	TIME [epoch: 8.43 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7270550363417125		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.7270550363417125 | validation: 0.6901339855221659]
	TIME [epoch: 8.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7028110723695673		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.7028110723695673 | validation: 0.5633946871351418]
	TIME [epoch: 8.43 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5950707852116766		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.5950707852116766 | validation: 0.4760102987446949]
	TIME [epoch: 8.45 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.589767407110112		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.589767407110112 | validation: 0.40651139409667336]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5645962179268327		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.5645962179268327 | validation: 0.45580080500499465]
	TIME [epoch: 8.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6097933636923021		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.6097933636923021 | validation: 0.551801628602842]
	TIME [epoch: 8.42 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6281714680923298		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.6281714680923298 | validation: 0.6932347575266402]
	TIME [epoch: 8.44 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.595635693889237		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.595635693889237 | validation: 0.48876662843193563]
	TIME [epoch: 8.43 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5926382235612437		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.5926382235612437 | validation: 0.48408865639206006]
	TIME [epoch: 8.42 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5998613807709345		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.5998613807709345 | validation: 0.48367874693968393]
	TIME [epoch: 8.42 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5390169667062015		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.5390169667062015 | validation: 0.510483389538707]
	TIME [epoch: 8.44 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5632273525502579		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.5632273525502579 | validation: 0.36532593848832895]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5588008430040243		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.5588008430040243 | validation: 0.3756653573157348]
	TIME [epoch: 8.42 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5097454270238844		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.5097454270238844 | validation: 0.46428579973443573]
	TIME [epoch: 8.42 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5300322158774334		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.5300322158774334 | validation: 0.5434617211113932]
	TIME [epoch: 8.44 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6594573028120831		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.6594573028120831 | validation: 0.6975914693520837]
	TIME [epoch: 8.43 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5682718715949187		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.5682718715949187 | validation: 0.5988508403089758]
	TIME [epoch: 8.42 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5733586165178769		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.5733586165178769 | validation: 0.5508871419676434]
	TIME [epoch: 8.43 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5708422920907092		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.5708422920907092 | validation: 0.3763299513974036]
	TIME [epoch: 8.45 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5440459040923509		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.5440459040923509 | validation: 0.38367127835585807]
	TIME [epoch: 8.43 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6369684952147677		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.6369684952147677 | validation: 0.4640769983312396]
	TIME [epoch: 8.42 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5200831084666312		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.5200831084666312 | validation: 0.3810032540182543]
	TIME [epoch: 8.42 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5608890468024721		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.5608890468024721 | validation: 0.46828043523341756]
	TIME [epoch: 8.45 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5143683217265913		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.5143683217265913 | validation: 0.37445722943065507]
	TIME [epoch: 8.42 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5171536740780712		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.5171536740780712 | validation: 0.5743747973203166]
	TIME [epoch: 8.43 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5207923186485843		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.5207923186485843 | validation: 0.3652062039046251]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5599742554729567		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.5599742554729567 | validation: 0.5036688742327644]
	TIME [epoch: 8.44 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5421384444253341		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.5421384444253341 | validation: 0.3453925849371624]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.504479843607915		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.504479843607915 | validation: 0.37341783750798296]
	TIME [epoch: 8.42 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5229493545893542		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.5229493545893542 | validation: 0.4450132310159044]
	TIME [epoch: 8.42 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5644110468481965		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.5644110468481965 | validation: 0.5437846280972498]
	TIME [epoch: 8.44 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5276039443856753		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.5276039443856753 | validation: 0.37041825522561617]
	TIME [epoch: 8.42 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4762611020192016		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.4762611020192016 | validation: 0.483379060356279]
	TIME [epoch: 8.42 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5280556678492759		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.5280556678492759 | validation: 0.32216918607286116]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49706936202476626		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.49706936202476626 | validation: 0.3715477189997629]
	TIME [epoch: 8.44 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.485112552610957		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.485112552610957 | validation: 0.6167401512205251]
	TIME [epoch: 8.42 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48167968231198444		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.48167968231198444 | validation: 0.36588718854882407]
	TIME [epoch: 8.42 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4955823746619738		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.4955823746619738 | validation: 0.33375280655781714]
	TIME [epoch: 8.44 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49345238391883867		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.49345238391883867 | validation: 0.32001478555478674]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5484789189594529		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.5484789189594529 | validation: 0.5192288410075625]
	TIME [epoch: 8.42 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4843862332947495		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.4843862332947495 | validation: 0.3961501561951827]
	TIME [epoch: 8.43 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5462370270813339		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.5462370270813339 | validation: 0.29942424956139924]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5068754812331118		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.5068754812331118 | validation: 0.4370374248007004]
	TIME [epoch: 8.44 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5104745358274781		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.5104745358274781 | validation: 0.4709234326729984]
	TIME [epoch: 8.42 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5265236957113284		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.5265236957113284 | validation: 0.4379143456472981]
	TIME [epoch: 8.43 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5145058023161788		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.5145058023161788 | validation: 0.3567199185341283]
	TIME [epoch: 8.44 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45879791227971634		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.45879791227971634 | validation: 0.4461923201697361]
	TIME [epoch: 8.43 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4923860016430878		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.4923860016430878 | validation: 0.37362387442293776]
	TIME [epoch: 8.44 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42671915659830806		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.42671915659830806 | validation: 0.9311050137475918]
	TIME [epoch: 8.43 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5696952961574548		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.5696952961574548 | validation: 0.4196364355269302]
	TIME [epoch: 8.46 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6108357537278095		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.6108357537278095 | validation: 0.40271675324101297]
	TIME [epoch: 8.44 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4355179192481625		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.4355179192481625 | validation: 0.35111042622842703]
	TIME [epoch: 8.43 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4576827998126759		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.4576827998126759 | validation: 0.30745616296819833]
	TIME [epoch: 8.43 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5123138574899514		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.5123138574899514 | validation: 0.3354542145288528]
	TIME [epoch: 8.46 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44689497410943196		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.44689497410943196 | validation: 0.5442894070055615]
	TIME [epoch: 8.43 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4657573394896469		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.4657573394896469 | validation: 0.3271479458899168]
	TIME [epoch: 8.44 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.489071531253226		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.489071531253226 | validation: 0.31422527249681764]
	TIME [epoch: 8.43 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4565719604930125		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.4565719604930125 | validation: 0.39266803180178156]
	TIME [epoch: 8.46 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41769461094274885		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.41769461094274885 | validation: 0.4823143911738679]
	TIME [epoch: 8.43 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48693477808592506		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.48693477808592506 | validation: 0.6435532434777029]
	TIME [epoch: 8.43 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4713037233541737		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.4713037233541737 | validation: 0.42242212258085193]
	TIME [epoch: 8.43 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45143705130736295		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.45143705130736295 | validation: 0.3455924486505883]
	TIME [epoch: 8.46 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3963545030555717		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.3963545030555717 | validation: 0.27277646846953757]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.379136398438161		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.379136398438161 | validation: 0.30666242589351944]
	TIME [epoch: 8.43 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42507237118883817		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.42507237118883817 | validation: 0.42293209232741635]
	TIME [epoch: 8.42 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4686941731269189		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.4686941731269189 | validation: 0.3414555623150573]
	TIME [epoch: 8.45 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40738358366065147		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.40738358366065147 | validation: 0.4870556246541612]
	TIME [epoch: 8.43 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.441080945595849		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.441080945595849 | validation: 0.3168552571088058]
	TIME [epoch: 8.42 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43203544751561324		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.43203544751561324 | validation: 0.4060004352292167]
	TIME [epoch: 8.43 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3928426525983163		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.3928426525983163 | validation: 0.3139745556214417]
	TIME [epoch: 8.45 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4383765343816527		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.4383765343816527 | validation: 0.3143796285597061]
	TIME [epoch: 8.43 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4100294715526213		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.4100294715526213 | validation: 0.429276328145998]
	TIME [epoch: 8.43 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42532216820502367		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.42532216820502367 | validation: 0.25751315045358114]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42421398728966286		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.42421398728966286 | validation: 0.2977279074148776]
	TIME [epoch: 8.45 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43720789587351083		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.43720789587351083 | validation: 0.2857053962512486]
	TIME [epoch: 8.43 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3619689663850669		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.3619689663850669 | validation: 0.26400533274142857]
	TIME [epoch: 8.43 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3918992337943985		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.3918992337943985 | validation: 0.2729325956517745]
	TIME [epoch: 8.44 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4096021128173851		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.4096021128173851 | validation: 0.41255619397573434]
	TIME [epoch: 8.44 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3526639830889364		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.3526639830889364 | validation: 0.6046806205488839]
	TIME [epoch: 8.43 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4326741748095131		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.4326741748095131 | validation: 0.42905416580388633]
	TIME [epoch: 8.43 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3576559811812074		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.3576559811812074 | validation: 0.3301092090502955]
	TIME [epoch: 8.44 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39587678741597665		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.39587678741597665 | validation: 0.4066329788973183]
	TIME [epoch: 8.44 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48074068641681994		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.48074068641681994 | validation: 0.2544650415490849]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.361621473324506		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.361621473324506 | validation: 0.2818937159692379]
	TIME [epoch: 8.42 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4046874500111911		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.4046874500111911 | validation: 0.2723430196649273]
	TIME [epoch: 8.44 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37848607529023603		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.37848607529023603 | validation: 0.3562744413087504]
	TIME [epoch: 8.43 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37088483461007116		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.37088483461007116 | validation: 0.305066666826412]
	TIME [epoch: 8.42 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41092519435457886		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.41092519435457886 | validation: 0.44992928179163605]
	TIME [epoch: 8.42 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41889789885223133		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.41889789885223133 | validation: 0.4438860949372394]
	TIME [epoch: 8.45 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3800403226443549		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.3800403226443549 | validation: 0.32386256278275016]
	TIME [epoch: 8.43 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3726900743119995		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.3726900743119995 | validation: 0.3781694408476187]
	TIME [epoch: 8.43 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3392327748716658		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.3392327748716658 | validation: 0.824571212197339]
	TIME [epoch: 8.42 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5012266131281157		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.5012266131281157 | validation: 0.31116497711436736]
	TIME [epoch: 8.45 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46201684982548386		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.46201684982548386 | validation: 0.3556823267021626]
	TIME [epoch: 8.43 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3853260861397179		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.3853260861397179 | validation: 0.42560093002970306]
	TIME [epoch: 8.42 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36588466842195133		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.36588466842195133 | validation: 0.3352787388787881]
	TIME [epoch: 8.42 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4102987430971131		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.4102987430971131 | validation: 0.3180957072762354]
	TIME [epoch: 8.45 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37212278350701455		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.37212278350701455 | validation: 0.2842768533180055]
	TIME [epoch: 8.43 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37812904068090314		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.37812904068090314 | validation: 0.31435793092091063]
	TIME [epoch: 8.43 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3191866634326499		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.3191866634326499 | validation: 0.2792166819677589]
	TIME [epoch: 8.42 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4171859363813918		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.4171859363813918 | validation: 0.365884104602898]
	TIME [epoch: 8.45 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.336881348963212		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.336881348963212 | validation: 0.3813208531683097]
	TIME [epoch: 8.43 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3959835327884281		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.3959835327884281 | validation: 0.4156633407807083]
	TIME [epoch: 8.42 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3937509268868878		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.3937509268868878 | validation: 0.32609024167302936]
	TIME [epoch: 8.43 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40361508117005884		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.40361508117005884 | validation: 0.4454306245444384]
	TIME [epoch: 8.45 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4340395488747055		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.4340395488747055 | validation: 0.2691070300746838]
	TIME [epoch: 8.43 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3310075636590557		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.3310075636590557 | validation: 0.3801689961746178]
	TIME [epoch: 8.43 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.396708522690065		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.396708522690065 | validation: 0.43543717489817807]
	TIME [epoch: 8.42 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3239091698928871		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.3239091698928871 | validation: 0.3031170641680297]
	TIME [epoch: 8.45 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3416092016416273		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.3416092016416273 | validation: 0.26604072349365765]
	TIME [epoch: 8.43 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35114394151412265		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.35114394151412265 | validation: 0.21991976086679887]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38209674475966493		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.38209674475966493 | validation: 0.42610579626327505]
	TIME [epoch: 8.42 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38767092239515943		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.38767092239515943 | validation: 0.2951794542092696]
	TIME [epoch: 8.44 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45943370616525064		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.45943370616525064 | validation: 0.3280492255235278]
	TIME [epoch: 8.42 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5601741025599191		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.5601741025599191 | validation: 0.49288117691251054]
	TIME [epoch: 8.42 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4123369821971883		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.4123369821971883 | validation: 0.2735875241921084]
	TIME [epoch: 8.43 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3797324531010581		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.3797324531010581 | validation: 0.2980544248772493]
	TIME [epoch: 8.45 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35742779588140516		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.35742779588140516 | validation: 0.3983895823741203]
	TIME [epoch: 8.43 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37864769388277475		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.37864769388277475 | validation: 0.28931508624764934]
	TIME [epoch: 8.42 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36893513186876153		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.36893513186876153 | validation: 0.35254618954261874]
	TIME [epoch: 8.42 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38822251922747425		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.38822251922747425 | validation: 0.2739843623909338]
	TIME [epoch: 8.45 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34125216284449617		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.34125216284449617 | validation: 0.3524910219381522]
	TIME [epoch: 8.42 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.354364315263818		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.354364315263818 | validation: 0.2757104209673966]
	TIME [epoch: 8.42 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3553751428288955		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.3553751428288955 | validation: 0.25913828052739507]
	TIME [epoch: 8.43 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31530419829362427		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.31530419829362427 | validation: 0.4946232241472547]
	TIME [epoch: 8.45 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32596427719583604		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.32596427719583604 | validation: 0.4733712246565694]
	TIME [epoch: 8.42 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41951255777511187		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.41951255777511187 | validation: 0.32035654215369247]
	TIME [epoch: 8.43 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35475037412712507		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.35475037412712507 | validation: 0.2408420233494206]
	TIME [epoch: 8.43 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32589574177166847		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.32589574177166847 | validation: 0.2956241817204964]
	TIME [epoch: 8.44 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3493521693269356		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.3493521693269356 | validation: 0.30849626066254077]
	TIME [epoch: 8.43 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3220107660532603		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.3220107660532603 | validation: 0.32048567772546677]
	TIME [epoch: 8.43 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32949726144365055		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.32949726144365055 | validation: 0.24360947299629954]
	TIME [epoch: 8.44 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3289019769618199		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.3289019769618199 | validation: 0.31398822916845526]
	TIME [epoch: 8.44 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3365226992293884		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.3365226992293884 | validation: 0.27602247355980875]
	TIME [epoch: 8.43 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3233014577404785		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.3233014577404785 | validation: 0.32178897635597586]
	TIME [epoch: 8.43 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3380437466598727		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.3380437466598727 | validation: 0.30759021719236185]
	TIME [epoch: 8.44 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.349955867910701		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.349955867910701 | validation: 0.28515669097271273]
	TIME [epoch: 8.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45219912131943146		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.45219912131943146 | validation: 0.3588318491185869]
	TIME [epoch: 8.43 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3268517787014623		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.3268517787014623 | validation: 0.3608301165354676]
	TIME [epoch: 8.43 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3094518227829909		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.3094518227829909 | validation: 0.4134903443171882]
	TIME [epoch: 8.44 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47160773468420886		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.47160773468420886 | validation: 0.2597850034487511]
	TIME [epoch: 8.44 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2847271306583843		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.2847271306583843 | validation: 0.336839310965122]
	TIME [epoch: 8.43 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3300131555686067		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.3300131555686067 | validation: 0.3511513181627993]
	TIME [epoch: 8.43 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3933237850078879		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.3933237850078879 | validation: 0.3340679174540773]
	TIME [epoch: 8.45 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28775878708345365		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.28775878708345365 | validation: 0.2922721980271486]
	TIME [epoch: 8.44 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3589088680881547		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.3589088680881547 | validation: 0.42066579472117]
	TIME [epoch: 8.43 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3608019851934731		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.3608019851934731 | validation: 0.3238232428757425]
	TIME [epoch: 8.43 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38673905801522035		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.38673905801522035 | validation: 0.49712548826189285]
	TIME [epoch: 8.45 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33983558033989303		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.33983558033989303 | validation: 0.40598545863711044]
	TIME [epoch: 8.43 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33304304080353375		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.33304304080353375 | validation: 0.25839246931031895]
	TIME [epoch: 8.43 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3734161111034345		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.3734161111034345 | validation: 0.27644787826727246]
	TIME [epoch: 8.42 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3041369440597974		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.3041369440597974 | validation: 0.25301078970560853]
	TIME [epoch: 8.45 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30026511634894587		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.30026511634894587 | validation: 0.3132684568849503]
	TIME [epoch: 8.43 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2999717330376577		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.2999717330376577 | validation: 0.26021829880352526]
	TIME [epoch: 8.43 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32623233725181455		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.32623233725181455 | validation: 0.34131697400111904]
	TIME [epoch: 8.42 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3500735526136589		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.3500735526136589 | validation: 0.2120306378315439]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2972159449467616		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.2972159449467616 | validation: 0.2093697073445202]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2740949544039097		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.2740949544039097 | validation: 0.3700088718022869]
	TIME [epoch: 8.42 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3199078764072706		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.3199078764072706 | validation: 0.29283489039439914]
	TIME [epoch: 8.42 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.272789326519857		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.272789326519857 | validation: 0.2763934029353247]
	TIME [epoch: 8.44 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30110129779418715		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.30110129779418715 | validation: 0.24296850113353852]
	TIME [epoch: 8.42 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2993778943289645		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.2993778943289645 | validation: 0.2644189730510672]
	TIME [epoch: 8.42 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2879074409910124		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.2879074409910124 | validation: 0.3041808656192577]
	TIME [epoch: 8.42 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3209158438276433		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.3209158438276433 | validation: 0.2573649119133303]
	TIME [epoch: 8.44 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3113394642673336		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.3113394642673336 | validation: 0.23432252474965445]
	TIME [epoch: 8.43 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33641453179212516		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.33641453179212516 | validation: 0.27903045858363507]
	TIME [epoch: 8.42 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3292065140207028		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.3292065140207028 | validation: 0.25363750977683397]
	TIME [epoch: 8.42 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32205126665935113		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.32205126665935113 | validation: 0.3371763958576691]
	TIME [epoch: 8.44 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29870823041303834		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.29870823041303834 | validation: 0.35738148759517496]
	TIME [epoch: 8.42 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3678361316601039		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.3678361316601039 | validation: 0.21661032261778512]
	TIME [epoch: 8.42 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3611085464389868		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.3611085464389868 | validation: 0.32503379192532955]
	TIME [epoch: 8.42 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30415319186338374		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.30415319186338374 | validation: 0.24728941186315864]
	TIME [epoch: 8.45 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3166939023041361		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.3166939023041361 | validation: 0.20772767389795627]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2981057781828952		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.2981057781828952 | validation: 0.3061542780721836]
	TIME [epoch: 8.42 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32060186267986535		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.32060186267986535 | validation: 0.28460597914907493]
	TIME [epoch: 8.42 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.345127826895409		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.345127826895409 | validation: 0.3327726887606677]
	TIME [epoch: 8.44 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29601664525650395		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.29601664525650395 | validation: 0.2516892051789917]
	TIME [epoch: 8.42 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26948254676915245		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.26948254676915245 | validation: 0.27124884316744524]
	TIME [epoch: 8.42 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30743669316994787		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.30743669316994787 | validation: 0.28406166231274876]
	TIME [epoch: 8.42 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2847803740273563		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.2847803740273563 | validation: 0.3664375225616525]
	TIME [epoch: 8.44 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3164715008434127		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.3164715008434127 | validation: 0.2327525142533457]
	TIME [epoch: 8.42 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28455974530988376		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.28455974530988376 | validation: 0.2623674746018724]
	TIME [epoch: 8.42 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26427488788672127		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.26427488788672127 | validation: 0.26836271269271417]
	TIME [epoch: 8.43 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27203641957410535		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.27203641957410535 | validation: 0.3160192794369179]
	TIME [epoch: 8.44 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.348008690732043		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.348008690732043 | validation: 0.31259143433147507]
	TIME [epoch: 8.42 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25377647403153863		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.25377647403153863 | validation: 0.2673758976904462]
	TIME [epoch: 8.42 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2740719303409156		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.2740719303409156 | validation: 0.22350653259616027]
	TIME [epoch: 8.43 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.251330891630854		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.251330891630854 | validation: 0.27152960578843605]
	TIME [epoch: 8.44 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3003180875304095		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.3003180875304095 | validation: 0.25026678917503387]
	TIME [epoch: 8.42 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25475667425880666		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.25475667425880666 | validation: 0.21246022613868232]
	TIME [epoch: 8.42 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27771553379809816		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.27771553379809816 | validation: 0.23400994621921217]
	TIME [epoch: 8.43 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29552895811160107		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.29552895811160107 | validation: 0.308396583869869]
	TIME [epoch: 8.43 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24056212434465243		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.24056212434465243 | validation: 0.20386207352862157]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.296639973297656		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.296639973297656 | validation: 0.3469340080736269]
	TIME [epoch: 8.42 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3059910868967316		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.3059910868967316 | validation: 0.21993675890918848]
	TIME [epoch: 8.44 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23841562964252513		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.23841562964252513 | validation: 0.21502987806775928]
	TIME [epoch: 8.42 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31352681147577555		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.31352681147577555 | validation: 0.22355322432946592]
	TIME [epoch: 8.42 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21382688823650012		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.21382688823650012 | validation: 0.2372019417213339]
	TIME [epoch: 8.42 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2462036428102922		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.2462036428102922 | validation: 0.2259947483304812]
	TIME [epoch: 8.44 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25084525466319013		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.25084525466319013 | validation: 0.2736931679737459]
	TIME [epoch: 8.42 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34335204235502953		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.34335204235502953 | validation: 0.3274642512888898]
	TIME [epoch: 8.43 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2628968899048784		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.2628968899048784 | validation: 0.26810494723470346]
	TIME [epoch: 8.43 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3809087586729537		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.3809087586729537 | validation: 0.264206356645204]
	TIME [epoch: 8.45 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2819115548248481		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.2819115548248481 | validation: 0.2875840217992334]
	TIME [epoch: 8.43 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25160820798469813		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.25160820798469813 | validation: 0.3197355551785247]
	TIME [epoch: 8.42 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39293088669790943		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.39293088669790943 | validation: 0.25747100099800746]
	TIME [epoch: 8.42 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.257966736517684		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.257966736517684 | validation: 0.18854483618266238]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_515.pth
	Model improved!!!
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2837342049959705		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.2837342049959705 | validation: 0.23927080390823102]
	TIME [epoch: 8.43 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23687814718710126		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.23687814718710126 | validation: 0.2822061499648057]
	TIME [epoch: 8.43 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30087257623409147		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.30087257623409147 | validation: 0.2233133869313072]
	TIME [epoch: 8.43 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28185481436756715		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.28185481436756715 | validation: 0.21947078917959228]
	TIME [epoch: 8.45 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23341177698873222		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.23341177698873222 | validation: 0.21851338256672437]
	TIME [epoch: 8.43 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23134896917975287		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.23134896917975287 | validation: 0.1940647691256329]
	TIME [epoch: 8.43 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26755900974016184		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.26755900974016184 | validation: 0.28809097673024453]
	TIME [epoch: 8.43 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2608042231229758		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.2608042231229758 | validation: 0.26710541597011883]
	TIME [epoch: 8.45 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25975461073803896		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.25975461073803896 | validation: 0.24252543121975556]
	TIME [epoch: 8.43 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28246861409246493		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.28246861409246493 | validation: 0.2591405949494785]
	TIME [epoch: 8.43 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24091623439808346		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.24091623439808346 | validation: 0.2281087935315973]
	TIME [epoch: 8.43 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.269265430798589		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.269265430798589 | validation: 0.24269542655072796]
	TIME [epoch: 8.46 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23824756331681457		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.23824756331681457 | validation: 0.2128213785737718]
	TIME [epoch: 8.43 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2652741726877976		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.2652741726877976 | validation: 0.31420215860298617]
	TIME [epoch: 8.43 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3049386633202717		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.3049386633202717 | validation: 0.25424128095690407]
	TIME [epoch: 8.43 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29221700913019283		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.29221700913019283 | validation: 0.2581729657847191]
	TIME [epoch: 8.46 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2752389507743887		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.2752389507743887 | validation: 0.20406611115566994]
	TIME [epoch: 8.43 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3130903315932057		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.3130903315932057 | validation: 0.2686416669256294]
	TIME [epoch: 8.43 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28080693641627064		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.28080693641627064 | validation: 0.31933745328285035]
	TIME [epoch: 8.43 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.266820077852395		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.266820077852395 | validation: 0.25564823725194497]
	TIME [epoch: 8.46 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2497957566618024		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.2497957566618024 | validation: 0.289836154191396]
	TIME [epoch: 8.43 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2926228049474524		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.2926228049474524 | validation: 0.2608447278235599]
	TIME [epoch: 8.43 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24722170214668907		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.24722170214668907 | validation: 0.29438448850387344]
	TIME [epoch: 8.43 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29149681837334146		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.29149681837334146 | validation: 0.44082222682414485]
	TIME [epoch: 8.46 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31800235142974376		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.31800235142974376 | validation: 0.24803867940633434]
	TIME [epoch: 8.43 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2487103317337636		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.2487103317337636 | validation: 0.24612221896042458]
	TIME [epoch: 8.44 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2826867184717349		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.2826867184717349 | validation: 0.30556681821554726]
	TIME [epoch: 8.44 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32140519465184		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.32140519465184 | validation: 0.2322671453406408]
	TIME [epoch: 8.44 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24752992982905758		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.24752992982905758 | validation: 0.25161588453089356]
	TIME [epoch: 8.43 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25096267075591905		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.25096267075591905 | validation: 0.33300793894975605]
	TIME [epoch: 8.43 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28847228671507846		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.28847228671507846 | validation: 0.22188710431426484]
	TIME [epoch: 8.44 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3062015221277929		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.3062015221277929 | validation: 0.2335721518805254]
	TIME [epoch: 8.44 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.257615138808609		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.257615138808609 | validation: 0.21828888927258205]
	TIME [epoch: 8.44 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2807864076664579		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.2807864076664579 | validation: 0.20700856169817689]
	TIME [epoch: 8.43 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2581639899028021		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.2581639899028021 | validation: 0.25679747619594906]
	TIME [epoch: 8.44 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24646030625702045		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.24646030625702045 | validation: 0.306873469177191]
	TIME [epoch: 8.44 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2410921018074724		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.2410921018074724 | validation: 0.27051408153503576]
	TIME [epoch: 8.43 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23776547587561958		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.23776547587561958 | validation: 0.22137068836721047]
	TIME [epoch: 8.43 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21625776847467457		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.21625776847467457 | validation: 0.3915427689100752]
	TIME [epoch: 8.44 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27060332913752316		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.27060332913752316 | validation: 0.3452060659288786]
	TIME [epoch: 8.43 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2855160882082356		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.2855160882082356 | validation: 0.3056824563365853]
	TIME [epoch: 8.43 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23780101264672635		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.23780101264672635 | validation: 0.18964300703594272]
	TIME [epoch: 8.43 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2370604146109491		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.2370604146109491 | validation: 0.19485788769631263]
	TIME [epoch: 8.45 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3009385973528649		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.3009385973528649 | validation: 0.49714689671376533]
	TIME [epoch: 8.43 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32040164332058085		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.32040164332058085 | validation: 0.19145806869018817]
	TIME [epoch: 8.43 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26959107090252366		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.26959107090252366 | validation: 0.20188358522079342]
	TIME [epoch: 8.43 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24806789989111394		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.24806789989111394 | validation: 0.22312874824494322]
	TIME [epoch: 8.45 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23347037534606363		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.23347037534606363 | validation: 0.2654241684066796]
	TIME [epoch: 8.43 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2488036768494649		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.2488036768494649 | validation: 0.24030696527236073]
	TIME [epoch: 8.42 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2393116704287918		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.2393116704287918 | validation: 0.33461391527792517]
	TIME [epoch: 8.43 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22299161917727517		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.22299161917727517 | validation: 0.4032493944635389]
	TIME [epoch: 8.46 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37528495188736183		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.37528495188736183 | validation: 0.21822509911496085]
	TIME [epoch: 8.43 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27124541026233534		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.27124541026233534 | validation: 0.23845106803325727]
	TIME [epoch: 8.43 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36381837178380383		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.36381837178380383 | validation: 0.2220901707137306]
	TIME [epoch: 8.43 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2696183382640905		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.2696183382640905 | validation: 0.2096691407929354]
	TIME [epoch: 8.46 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2448196277546646		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.2448196277546646 | validation: 0.20297447012982134]
	TIME [epoch: 8.43 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29200275801958586		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.29200275801958586 | validation: 0.2063982711425987]
	TIME [epoch: 8.43 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2700644862235507		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.2700644862235507 | validation: 0.20399293806440516]
	TIME [epoch: 8.43 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22507385514111444		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.22507385514111444 | validation: 0.3423440935654699]
	TIME [epoch: 8.45 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.273646224527332		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.273646224527332 | validation: 0.23057784474541576]
	TIME [epoch: 8.43 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2542231465552768		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.2542231465552768 | validation: 0.5539684839524981]
	TIME [epoch: 8.43 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3245170673109282		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.3245170673109282 | validation: 0.19597824580590717]
	TIME [epoch: 8.43 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2848615775560871		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.2848615775560871 | validation: 0.2278437148176296]
	TIME [epoch: 8.45 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23035262319126612		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.23035262319126612 | validation: 0.3475292531118854]
	TIME [epoch: 8.43 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23533631665958943		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.23533631665958943 | validation: 0.20072929859698804]
	TIME [epoch: 8.43 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22219799826303657		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.22219799826303657 | validation: 0.22822925434561542]
	TIME [epoch: 8.43 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2892604881617854		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.2892604881617854 | validation: 0.24452000227142945]
	TIME [epoch: 8.45 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25439581682999857		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.25439581682999857 | validation: 0.2733791733329873]
	TIME [epoch: 8.43 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2530367770289827		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.2530367770289827 | validation: 0.23857509450284226]
	TIME [epoch: 8.43 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40881420947482877		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.40881420947482877 | validation: 0.3464546639507964]
	TIME [epoch: 8.43 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2867241418439432		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.2867241418439432 | validation: 0.22976158028854202]
	TIME [epoch: 8.45 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.260871798573759		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.260871798573759 | validation: 0.2345791904786213]
	TIME [epoch: 8.43 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2304923155223954		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.2304923155223954 | validation: 0.28877422886651005]
	TIME [epoch: 8.43 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23188238975893252		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.23188238975893252 | validation: 0.213768130604019]
	TIME [epoch: 8.43 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23485266089686893		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.23485266089686893 | validation: 0.19367939832049774]
	TIME [epoch: 8.46 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2303421756406006		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.2303421756406006 | validation: 0.2192873717003786]
	TIME [epoch: 8.43 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3724568434456225		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.3724568434456225 | validation: 0.3636307161306087]
	TIME [epoch: 8.43 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3056396553253251		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.3056396553253251 | validation: 0.2496361360194756]
	TIME [epoch: 8.43 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.227927296029773		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.227927296029773 | validation: 0.23851129331435839]
	TIME [epoch: 8.45 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2215801177316843		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.2215801177316843 | validation: 0.2586447948757864]
	TIME [epoch: 8.43 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4098261936399963		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.4098261936399963 | validation: 0.8514007087013157]
	TIME [epoch: 8.43 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37413026104228103		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.37413026104228103 | validation: 0.1943714945163092]
	TIME [epoch: 8.44 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.258936216483894		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.258936216483894 | validation: 0.214874744607577]
	TIME [epoch: 8.45 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2505518932773081		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.2505518932773081 | validation: 0.2455604471370231]
	TIME [epoch: 8.43 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2812040632550991		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.2812040632550991 | validation: 0.26125045426410193]
	TIME [epoch: 8.43 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2508215044048203		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.2508215044048203 | validation: 0.2954677147115503]
	TIME [epoch: 8.44 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27349851640410494		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.27349851640410494 | validation: 0.2465762068514154]
	TIME [epoch: 8.45 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23616035441865332		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.23616035441865332 | validation: 0.2845059534349407]
	TIME [epoch: 8.44 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23604426254620914		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.23604426254620914 | validation: 0.20353991383856357]
	TIME [epoch: 8.43 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2775097700973018		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.2775097700973018 | validation: 0.26598096768695917]
	TIME [epoch: 8.44 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2323291102627782		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.2323291102627782 | validation: 0.2381694082352993]
	TIME [epoch: 8.44 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21191178266033672		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.21191178266033672 | validation: 0.21935837307245407]
	TIME [epoch: 8.43 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2328339920432557		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.2328339920432557 | validation: 0.2408453689967962]
	TIME [epoch: 8.43 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30040011469460975		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.30040011469460975 | validation: 0.18669393009566537]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_609.pth
	Model improved!!!
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26726202561201134		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.26726202561201134 | validation: 0.3328795155941807]
	TIME [epoch: 8.44 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2867101037693089		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.2867101037693089 | validation: 0.20919951968343395]
	TIME [epoch: 8.42 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22153645881219175		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.22153645881219175 | validation: 0.22478397100147252]
	TIME [epoch: 8.42 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1949664152402642		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.1949664152402642 | validation: 0.18659615743323124]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2153006032492341		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.2153006032492341 | validation: 0.18071654291654005]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2124997301262332		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.2124997301262332 | validation: 0.19883745175970352]
	TIME [epoch: 8.42 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18848428039177603		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.18848428039177603 | validation: 0.22187281726005312]
	TIME [epoch: 8.43 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2966422622032516		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.2966422622032516 | validation: 0.4491872561615836]
	TIME [epoch: 8.44 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2514746551111453		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.2514746551111453 | validation: 0.2369176610093359]
	TIME [epoch: 8.43 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2273416841911125		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.2273416841911125 | validation: 0.45135718430727845]
	TIME [epoch: 8.42 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2825441898286022		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.2825441898286022 | validation: 0.25978511301162677]
	TIME [epoch: 8.43 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21727713218763994		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.21727713218763994 | validation: 0.21250737815378712]
	TIME [epoch: 8.45 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21563464288538822		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.21563464288538822 | validation: 0.21131613017317313]
	TIME [epoch: 8.43 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23124264469730488		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.23124264469730488 | validation: 0.27504620596213014]
	TIME [epoch: 8.43 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20121565401386388		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.20121565401386388 | validation: 0.21862453228599718]
	TIME [epoch: 8.43 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2482125220670781		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.2482125220670781 | validation: 0.20543866247868028]
	TIME [epoch: 8.45 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20590441397386577		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.20590441397386577 | validation: 0.1974814815877108]
	TIME [epoch: 8.43 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24745932607483137		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.24745932607483137 | validation: 0.3505538413109863]
	TIME [epoch: 8.43 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21898837076272057		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.21898837076272057 | validation: 0.26043304228088654]
	TIME [epoch: 8.43 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21234699072958638		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.21234699072958638 | validation: 0.22803064810920243]
	TIME [epoch: 8.45 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2361842721274731		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.2361842721274731 | validation: 0.19235591919015485]
	TIME [epoch: 8.43 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21463193256274443		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.21463193256274443 | validation: 0.19598113183707017]
	TIME [epoch: 8.43 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2321500722882405		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.2321500722882405 | validation: 0.27495615626537906]
	TIME [epoch: 8.43 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18825719481918773		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.18825719481918773 | validation: 0.23575355438615328]
	TIME [epoch: 8.45 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23370787784079977		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.23370787784079977 | validation: 0.24952410468638414]
	TIME [epoch: 8.42 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20345979277786091		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.20345979277786091 | validation: 0.20940887074375256]
	TIME [epoch: 8.42 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21772822237329786		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.21772822237329786 | validation: 0.22369557146391422]
	TIME [epoch: 8.42 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20243568120222805		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.20243568120222805 | validation: 0.20090556647659075]
	TIME [epoch: 8.45 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21664373464310277		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.21664373464310277 | validation: 0.18843294718854753]
	TIME [epoch: 8.42 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21196738666029852		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.21196738666029852 | validation: 0.2995589726728928]
	TIME [epoch: 8.43 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21025750313207467		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.21025750313207467 | validation: 0.26465694584700294]
	TIME [epoch: 8.42 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20488801352521727		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.20488801352521727 | validation: 0.2121018190663294]
	TIME [epoch: 8.45 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17564016251108308		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.17564016251108308 | validation: 0.2390001514908576]
	TIME [epoch: 8.43 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21351584071933938		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.21351584071933938 | validation: 0.20300051972071614]
	TIME [epoch: 8.42 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2005853276898637		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.2005853276898637 | validation: 0.20562993348209085]
	TIME [epoch: 8.43 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23275355579128582		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.23275355579128582 | validation: 0.23534225323986574]
	TIME [epoch: 8.45 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21543534507603032		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.21543534507603032 | validation: 0.23398982684365904]
	TIME [epoch: 8.43 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2159218787904254		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.2159218787904254 | validation: 0.21411284428349409]
	TIME [epoch: 8.43 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1917502306744304		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.1917502306744304 | validation: 0.22349670864611143]
	TIME [epoch: 8.43 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2417576274211687		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.2417576274211687 | validation: 0.2173849649852606]
	TIME [epoch: 8.45 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957247292407205		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.1957247292407205 | validation: 0.21546381954094185]
	TIME [epoch: 8.43 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1932226190774451		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.1932226190774451 | validation: 0.21858493160572479]
	TIME [epoch: 8.43 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21665669210766395		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.21665669210766395 | validation: 0.2002013004167174]
	TIME [epoch: 8.44 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19124993542879826		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.19124993542879826 | validation: 0.16994356717903933]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20495578946519713		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.20495578946519713 | validation: 0.17892167549356858]
	TIME [epoch: 8.42 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21488602363721937		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.21488602363721937 | validation: 0.22337886824872338]
	TIME [epoch: 8.42 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.254459772673063		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.254459772673063 | validation: 0.19846762265346557]
	TIME [epoch: 8.42 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16769716456511524		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.16769716456511524 | validation: 0.18200121321374685]
	TIME [epoch: 8.43 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18023731761317424		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.18023731761317424 | validation: 0.21862139765189995]
	TIME [epoch: 8.42 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2320549556031279		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.2320549556031279 | validation: 0.266210704314064]
	TIME [epoch: 8.42 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084562882819995		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.2084562882819995 | validation: 0.17950294157920607]
	TIME [epoch: 8.43 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20136995133260957		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.20136995133260957 | validation: 0.23802341530606436]
	TIME [epoch: 8.43 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21141071791190838		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.21141071791190838 | validation: 0.2190434970352922]
	TIME [epoch: 8.42 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17433321074542626		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.17433321074542626 | validation: 0.22973917831698287]
	TIME [epoch: 8.42 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19683781700223785		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.19683781700223785 | validation: 0.23220281153494965]
	TIME [epoch: 8.44 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19985175334520217		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.19985175334520217 | validation: 0.26992051124156574]
	TIME [epoch: 8.42 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22613066500223183		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.22613066500223183 | validation: 0.17653806150709656]
	TIME [epoch: 8.42 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18911009432728057		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.18911009432728057 | validation: 0.21522407177477293]
	TIME [epoch: 8.41 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747608961764042		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.2747608961764042 | validation: 0.1938045863763212]
	TIME [epoch: 8.44 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18539059016419057		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.18539059016419057 | validation: 0.25721493018667996]
	TIME [epoch: 8.42 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2177396836422595		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.2177396836422595 | validation: 0.18426924432903724]
	TIME [epoch: 8.42 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1851298017866529		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.1851298017866529 | validation: 0.2394070285122446]
	TIME [epoch: 8.41 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20704114807513824		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.20704114807513824 | validation: 0.18800393587014885]
	TIME [epoch: 8.44 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21538988118090097		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.21538988118090097 | validation: 0.19829582969574316]
	TIME [epoch: 8.42 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20194363674683208		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.20194363674683208 | validation: 0.18004882938333522]
	TIME [epoch: 8.42 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2012649532224891		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.2012649532224891 | validation: 0.20785233749993365]
	TIME [epoch: 8.42 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3305721578012376		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.3305721578012376 | validation: 0.23641273464803558]
	TIME [epoch: 8.43 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19947348252626082		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.19947348252626082 | validation: 0.1648678056892244]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18206427635501757		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.18206427635501757 | validation: 0.18514334332281024]
	TIME [epoch: 8.42 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16474125813808277		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.16474125813808277 | validation: 0.15448639916717838]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1809855484904481		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.1809855484904481 | validation: 0.18946917792102952]
	TIME [epoch: 8.44 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21597897477407874		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.21597897477407874 | validation: 0.20639171975627937]
	TIME [epoch: 8.42 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16924667285431344		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.16924667285431344 | validation: 0.25613290712654]
	TIME [epoch: 8.42 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18549380725975034		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.18549380725975034 | validation: 0.2014427633385243]
	TIME [epoch: 8.42 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19200667376594702		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.19200667376594702 | validation: 0.2758450578031528]
	TIME [epoch: 8.45 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20131220944161013		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.20131220944161013 | validation: 0.1748939256030585]
	TIME [epoch: 8.42 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22403788408758682		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.22403788408758682 | validation: 0.18417192756339643]
	TIME [epoch: 8.42 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534928608924125		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.1534928608924125 | validation: 0.1779982423513431]
	TIME [epoch: 8.42 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26547412184373387		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.26547412184373387 | validation: 0.22766509888346775]
	TIME [epoch: 8.44 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22707880315821755		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.22707880315821755 | validation: 0.2161999248872909]
	TIME [epoch: 8.42 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17261381181290575		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.17261381181290575 | validation: 0.20436598697738212]
	TIME [epoch: 8.43 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1695134489232488		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.1695134489232488 | validation: 0.19029628766999998]
	TIME [epoch: 8.42 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1879165639828914		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.1879165639828914 | validation: 0.2689522543909566]
	TIME [epoch: 8.44 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18293708212992124		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.18293708212992124 | validation: 0.19820810776162526]
	TIME [epoch: 8.42 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1734748734970852		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.1734748734970852 | validation: 0.24780445061189202]
	TIME [epoch: 8.42 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19154741786145185		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.19154741786145185 | validation: 0.2303244109209016]
	TIME [epoch: 8.42 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056609618513757		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.2056609618513757 | validation: 0.160556370863086]
	TIME [epoch: 8.44 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25184914397433644		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.25184914397433644 | validation: 0.3550789928343944]
	TIME [epoch: 8.42 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24364215592569977		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.24364215592569977 | validation: 0.2443139775214159]
	TIME [epoch: 8.42 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23486277290764074		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.23486277290764074 | validation: 0.18399437424980786]
	TIME [epoch: 8.42 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18608350311037236		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.18608350311037236 | validation: 0.1668660627015725]
	TIME [epoch: 8.44 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17289961255385972		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.17289961255385972 | validation: 0.20842487608036164]
	TIME [epoch: 8.42 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14089816998645657		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.14089816998645657 | validation: 0.16791869475890955]
	TIME [epoch: 8.42 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16030872475498242		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.16030872475498242 | validation: 0.20717327597510607]
	TIME [epoch: 8.43 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18240761420368062		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.18240761420368062 | validation: 0.26538829047915813]
	TIME [epoch: 8.44 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056836950766625		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.2056836950766625 | validation: 0.1515258174822091]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18052787219496294		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.18052787219496294 | validation: 0.1754369654967643]
	TIME [epoch: 8.43 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1801232524391795		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.1801232524391795 | validation: 0.19854650330145113]
	TIME [epoch: 8.43 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18883115894379537		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.18883115894379537 | validation: 0.1761575837004694]
	TIME [epoch: 8.43 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18629265535976744		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.18629265535976744 | validation: 0.15997466233444563]
	TIME [epoch: 8.43 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15540683700232782		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.15540683700232782 | validation: 0.18044558571312058]
	TIME [epoch: 8.42 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2232180164508574		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.2232180164508574 | validation: 0.23186104054458176]
	TIME [epoch: 8.44 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16878060270469553		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.16878060270469553 | validation: 0.21595966544437176]
	TIME [epoch: 8.43 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19495834158292355		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.19495834158292355 | validation: 0.19002874706010042]
	TIME [epoch: 8.42 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18391173715781917		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.18391173715781917 | validation: 0.21077630841847983]
	TIME [epoch: 8.43 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19697926375735936		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.19697926375735936 | validation: 0.3437320592682164]
	TIME [epoch: 8.45 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26039746496516164		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.26039746496516164 | validation: 0.15949091292430156]
	TIME [epoch: 8.42 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1686049602223608		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.1686049602223608 | validation: 0.2308050057196533]
	TIME [epoch: 8.42 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15792629479275408		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.15792629479275408 | validation: 0.19964229363431152]
	TIME [epoch: 8.41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19011433217708115		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.19011433217708115 | validation: 0.2185751856243877]
	TIME [epoch: 8.45 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1614548098363197		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.1614548098363197 | validation: 0.16824852017039446]
	TIME [epoch: 8.43 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1354529415966837		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.1354529415966837 | validation: 0.17129626273408755]
	TIME [epoch: 8.42 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1633555358767668		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.1633555358767668 | validation: 0.17980375157352518]
	TIME [epoch: 8.42 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1772427101076459		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.1772427101076459 | validation: 0.15538902434121532]
	TIME [epoch: 8.44 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23644362415121378		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.23644362415121378 | validation: 0.2092068135900843]
	TIME [epoch: 8.43 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1499639557858128		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.1499639557858128 | validation: 0.17243898183790837]
	TIME [epoch: 8.42 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26351045641715365		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.26351045641715365 | validation: 0.29049946058119286]
	TIME [epoch: 8.42 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18978080771990574		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.18978080771990574 | validation: 0.1747843516216157]
	TIME [epoch: 8.44 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17678255704630302		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.17678255704630302 | validation: 0.2256222872119489]
	TIME [epoch: 8.43 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15752973034814172		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.15752973034814172 | validation: 0.22643055370775794]
	TIME [epoch: 8.42 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17440713193202473		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.17440713193202473 | validation: 0.1477918788450017]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19234691960235314		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.19234691960235314 | validation: 0.17223199712088094]
	TIME [epoch: 8.45 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.151861899387235		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.151861899387235 | validation: 0.18304691040894283]
	TIME [epoch: 8.43 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15276496471015996		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.15276496471015996 | validation: 0.16229314813739745]
	TIME [epoch: 8.42 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15243960476112425		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.15243960476112425 | validation: 0.19607665737893026]
	TIME [epoch: 8.42 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15298406847081333		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.15298406847081333 | validation: 0.1392892172508577]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_735.pth
	Model improved!!!
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622063748480537		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.1622063748480537 | validation: 0.1697342550926887]
	TIME [epoch: 8.43 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13988129958891524		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.13988129958891524 | validation: 0.16104395157423407]
	TIME [epoch: 8.43 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17843413461129348		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.17843413461129348 | validation: 0.15085389962730886]
	TIME [epoch: 8.43 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18398573803511248		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.18398573803511248 | validation: 0.17357153648479717]
	TIME [epoch: 8.46 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12759204478918154		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.12759204478918154 | validation: 0.15892979048122421]
	TIME [epoch: 8.43 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17410943204385654		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.17410943204385654 | validation: 0.18666620576974116]
	TIME [epoch: 8.43 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12985962546808652		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.12985962546808652 | validation: 0.18836837121030164]
	TIME [epoch: 8.43 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15406664228397535		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.15406664228397535 | validation: 0.21691097288054625]
	TIME [epoch: 8.45 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19477066521662695		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.19477066521662695 | validation: 0.1563043794510739]
	TIME [epoch: 8.43 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1381659875787025		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.1381659875787025 | validation: 0.2031913170088695]
	TIME [epoch: 8.43 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15605288948686355		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.15605288948686355 | validation: 0.17114502073621216]
	TIME [epoch: 8.43 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13672901837633886		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.13672901837633886 | validation: 0.27687666599519456]
	TIME [epoch: 8.45 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17909738350101823		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.17909738350101823 | validation: 0.18812662925053142]
	TIME [epoch: 8.43 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.186957434455778		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.186957434455778 | validation: 0.2981842674888324]
	TIME [epoch: 8.43 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18571371762875422		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.18571371762875422 | validation: 0.1643449860677066]
	TIME [epoch: 8.44 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18774064797799755		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.18774064797799755 | validation: 0.17524709893031543]
	TIME [epoch: 8.45 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13456762635254707		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.13456762635254707 | validation: 0.18651449063338676]
	TIME [epoch: 8.43 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13235557712268467		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.13235557712268467 | validation: 0.167848740235401]
	TIME [epoch: 8.43 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17435308229242963		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.17435308229242963 | validation: 0.15035075189048852]
	TIME [epoch: 8.44 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841999396480062		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.16841999396480062 | validation: 0.16634446875348755]
	TIME [epoch: 8.45 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.142822879381996		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.142822879381996 | validation: 0.15507037078662428]
	TIME [epoch: 8.43 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2025059873334046		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.2025059873334046 | validation: 0.20638184379235225]
	TIME [epoch: 8.43 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15511733285214135		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.15511733285214135 | validation: 0.18539594842870533]
	TIME [epoch: 8.44 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15518886586704778		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.15518886586704778 | validation: 0.16783929428646904]
	TIME [epoch: 8.45 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1622628325172882		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.1622628325172882 | validation: 0.20514324486145608]
	TIME [epoch: 8.44 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14470461699919476		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.14470461699919476 | validation: 0.22421565003899685]
	TIME [epoch: 8.43 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1805717402145563		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.1805717402145563 | validation: 0.16490921673667702]
	TIME [epoch: 8.44 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13877637443946345		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.13877637443946345 | validation: 0.16271223794680614]
	TIME [epoch: 8.44 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15249968264165756		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.15249968264165756 | validation: 0.19594156977378357]
	TIME [epoch: 8.44 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16816182394521995		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.16816182394521995 | validation: 0.1963863870742]
	TIME [epoch: 8.46 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1563495246820627		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.1563495246820627 | validation: 0.16471017607566213]
	TIME [epoch: 8.45 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1530231913955768		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.1530231913955768 | validation: 0.17608829466856285]
	TIME [epoch: 8.44 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19212920740583023		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.19212920740583023 | validation: 0.14943374696597067]
	TIME [epoch: 8.43 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13062880810526367		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.13062880810526367 | validation: 0.1337957122435714]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13412034346979776		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.13412034346979776 | validation: 0.16542521173199326]
	TIME [epoch: 8.45 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476228112400591		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.1476228112400591 | validation: 0.25488574442390044]
	TIME [epoch: 8.43 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17317731150234036		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.17317731150234036 | validation: 0.1589384825775788]
	TIME [epoch: 8.42 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15051979722813633		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.15051979722813633 | validation: 0.18361324561113262]
	TIME [epoch: 8.43 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2158880237706131		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.2158880237706131 | validation: 0.39472512424607165]
	TIME [epoch: 8.44 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4092136007402457		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.4092136007402457 | validation: 0.15347278443392084]
	TIME [epoch: 8.43 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13662727068788316		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.13662727068788316 | validation: 0.13764861745504853]
	TIME [epoch: 8.42 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17214503864725184		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.17214503864725184 | validation: 0.29221873908666834]
	TIME [epoch: 8.42 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22271112781246477		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.22271112781246477 | validation: 0.2071423801267134]
	TIME [epoch: 8.45 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15409404728534776		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.15409404728534776 | validation: 0.17527623042653906]
	TIME [epoch: 8.43 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1288953164488889		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.1288953164488889 | validation: 0.16102500206908535]
	TIME [epoch: 8.43 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12551662230522445		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.12551662230522445 | validation: 0.16228861777935966]
	TIME [epoch: 8.43 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16342900303445515		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.16342900303445515 | validation: 0.17889183068168324]
	TIME [epoch: 8.45 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12301585404827545		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.12301585404827545 | validation: 0.12154673024913742]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1734165829015783		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.1734165829015783 | validation: 0.693641961729132]
	TIME [epoch: 8.42 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33782109694499973		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.33782109694499973 | validation: 0.16444983560396392]
	TIME [epoch: 8.43 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13680248165223421		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.13680248165223421 | validation: 0.2111115521759241]
	TIME [epoch: 8.44 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20638525376026004		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.20638525376026004 | validation: 0.13665368177596532]
	TIME [epoch: 8.43 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12738934636700877		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.12738934636700877 | validation: 0.1644065255642002]
	TIME [epoch: 8.42 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14081317063988985		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.14081317063988985 | validation: 0.12288827091158977]
	TIME [epoch: 8.43 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14790704465190255		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.14790704465190255 | validation: 0.16246257048943602]
	TIME [epoch: 8.45 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14266935842483758		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.14266935842483758 | validation: 0.16159015306755853]
	TIME [epoch: 8.43 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1365969225028406		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.1365969225028406 | validation: 0.1353200101177507]
	TIME [epoch: 8.43 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14973464837339293		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.14973464837339293 | validation: 0.1987315450119782]
	TIME [epoch: 8.43 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14931455760595067		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.14931455760595067 | validation: 0.1442691706578431]
	TIME [epoch: 8.45 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12668348440639354		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.12668348440639354 | validation: 0.14176914219850356]
	TIME [epoch: 8.43 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11508810836523793		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.11508810836523793 | validation: 0.15105256456640168]
	TIME [epoch: 8.42 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1366102463656822		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.1366102463656822 | validation: 0.2460397860033427]
	TIME [epoch: 8.43 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20410083523975825		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.20410083523975825 | validation: 0.17258004237732477]
	TIME [epoch: 8.45 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13762323972093057		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.13762323972093057 | validation: 0.17352102580040243]
	TIME [epoch: 8.42 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16660858540554496		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.16660858540554496 | validation: 0.17409222433881838]
	TIME [epoch: 8.42 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.148082696372355		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.148082696372355 | validation: 0.13521076569966728]
	TIME [epoch: 8.44 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12163874514277942		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.12163874514277942 | validation: 0.17046087988453335]
	TIME [epoch: 8.43 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15012766020421717		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.15012766020421717 | validation: 0.1418346886413336]
	TIME [epoch: 8.43 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13156472471072284		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.13156472471072284 | validation: 0.15717679528011275]
	TIME [epoch: 8.42 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1378568057487762		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.1378568057487762 | validation: 0.1611198215546386]
	TIME [epoch: 8.44 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12385743088953238		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.12385743088953238 | validation: 0.15621259337226517]
	TIME [epoch: 8.44 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15533426404735481		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.15533426404735481 | validation: 0.14824571462502753]
	TIME [epoch: 8.42 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16828745646483526		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.16828745646483526 | validation: 0.1249524258267478]
	TIME [epoch: 8.42 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14699006052013067		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.14699006052013067 | validation: 0.13346810944648402]
	TIME [epoch: 8.43 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11609210131834846		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.11609210131834846 | validation: 0.15573996678390636]
	TIME [epoch: 8.44 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17551987513764922		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.17551987513764922 | validation: 0.17408788237655914]
	TIME [epoch: 8.42 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14688020811752237		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.14688020811752237 | validation: 0.14160222732800812]
	TIME [epoch: 8.42 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14168060943442354		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.14168060943442354 | validation: 0.15017828272999065]
	TIME [epoch: 8.43 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15072189626732438		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.15072189626732438 | validation: 0.1245300029452512]
	TIME [epoch: 8.43 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13237032873705248		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.13237032873705248 | validation: 0.2041485724393363]
	TIME [epoch: 8.42 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1995480002809153		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.1995480002809153 | validation: 0.1444769524645536]
	TIME [epoch: 8.42 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14298336201881567		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.14298336201881567 | validation: 0.1391728673246956]
	TIME [epoch: 8.44 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15901635457272242		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.15901635457272242 | validation: 0.13061472559432052]
	TIME [epoch: 8.43 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1469628459280414		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.1469628459280414 | validation: 0.22642273781117678]
	TIME [epoch: 8.42 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17153300083155157		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.17153300083155157 | validation: 0.1458440489498606]
	TIME [epoch: 8.42 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1322896362976152		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.1322896362976152 | validation: 0.16889428049360294]
	TIME [epoch: 8.44 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11917164383943395		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.11917164383943395 | validation: 0.12675357327776066]
	TIME [epoch: 8.43 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14169793476765574		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.14169793476765574 | validation: 0.16488974386734467]
	TIME [epoch: 8.42 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14706182287732059		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.14706182287732059 | validation: 0.14917533550752865]
	TIME [epoch: 8.43 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13206584331263918		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.13206584331263918 | validation: 0.16589018166048927]
	TIME [epoch: 8.44 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14893223554453647		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.14893223554453647 | validation: 0.1379392546945602]
	TIME [epoch: 8.43 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14535075389846475		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.14535075389846475 | validation: 0.15465743384150837]
	TIME [epoch: 8.42 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17796158268597895		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.17796158268597895 | validation: 0.1654371707764406]
	TIME [epoch: 8.42 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12792968508681166		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.12792968508681166 | validation: 0.14785342292102566]
	TIME [epoch: 8.45 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15921455495692144		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.15921455495692144 | validation: 0.1575671247405833]
	TIME [epoch: 8.42 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12738069588483886		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.12738069588483886 | validation: 0.14032218251165288]
	TIME [epoch: 8.42 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18035928565830578		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.18035928565830578 | validation: 0.14976738515365665]
	TIME [epoch: 8.42 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11998673186653445		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.11998673186653445 | validation: 0.1637230248264746]
	TIME [epoch: 8.45 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12059802986229332		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.12059802986229332 | validation: 0.12254292890563437]
	TIME [epoch: 8.42 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11350928935377605		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.11350928935377605 | validation: 0.16261262544522054]
	TIME [epoch: 8.42 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14290335154261888		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.14290335154261888 | validation: 0.14258906421071454]
	TIME [epoch: 8.42 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1356460791787158		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.1356460791787158 | validation: 0.19952072378955432]
	TIME [epoch: 8.44 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13777131935570383		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.13777131935570383 | validation: 0.19453578176957598]
	TIME [epoch: 8.42 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15011762590007094		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.15011762590007094 | validation: 0.14972773261671976]
	TIME [epoch: 8.42 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11314624152456246		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.11314624152456246 | validation: 0.15263706173658756]
	TIME [epoch: 8.42 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14618528632496816		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.14618528632496816 | validation: 0.13097817599933398]
	TIME [epoch: 8.45 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12443754090065517		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.12443754090065517 | validation: 0.13868519923287276]
	TIME [epoch: 8.42 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12669951151023415		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.12669951151023415 | validation: 0.15877948110889742]
	TIME [epoch: 8.41 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12051942006626475		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.12051942006626475 | validation: 0.1616621530005606]
	TIME [epoch: 8.42 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11680028537464697		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.11680028537464697 | validation: 0.1490051408104672]
	TIME [epoch: 8.44 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1690524229947736		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.1690524229947736 | validation: 0.19255235629945353]
	TIME [epoch: 8.42 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1451509895297653		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.1451509895297653 | validation: 0.16049406714231723]
	TIME [epoch: 8.42 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1332283277280875		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.1332283277280875 | validation: 0.18817194787357833]
	TIME [epoch: 8.42 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.263981873756335		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.263981873756335 | validation: 0.14901574941367293]
	TIME [epoch: 8.45 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11978112761572841		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.11978112761572841 | validation: 0.18009578075827]
	TIME [epoch: 8.42 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1887945428135395		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.1887945428135395 | validation: 0.20223452261022706]
	TIME [epoch: 8.43 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18946425916983617		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.18946425916983617 | validation: 0.1640198436302857]
	TIME [epoch: 8.42 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24300158909929165		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.24300158909929165 | validation: 0.14411384060483215]
	TIME [epoch: 8.44 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13314016546077181		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.13314016546077181 | validation: 0.1858598459090264]
	TIME [epoch: 8.42 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14888678776090908		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.14888678776090908 | validation: 0.11672086705590232]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_855.pth
	Model improved!!!
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12388969235737883		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.12388969235737883 | validation: 0.13571365144992917]
	TIME [epoch: 8.42 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19648911971384614		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.19648911971384614 | validation: 0.176513857429615]
	TIME [epoch: 8.44 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17553812924008727		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.17553812924008727 | validation: 0.1783149531477905]
	TIME [epoch: 8.41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14397864784543804		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.14397864784543804 | validation: 0.12785415918065898]
	TIME [epoch: 8.42 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11593774426723695		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.11593774426723695 | validation: 0.15529624126038483]
	TIME [epoch: 8.43 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17518590628335332		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.17518590628335332 | validation: 0.1538192046427514]
	TIME [epoch: 8.43 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11285692085568752		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.11285692085568752 | validation: 0.13277869592118186]
	TIME [epoch: 8.41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12968312098925644		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.12968312098925644 | validation: 0.13233559107391646]
	TIME [epoch: 8.42 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11656765882816689		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.11656765882816689 | validation: 0.10870220452447514]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_864.pth
	Model improved!!!
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14614560753466627		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.14614560753466627 | validation: 0.1393796104565202]
	TIME [epoch: 8.43 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12557673703459152		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.12557673703459152 | validation: 0.17001234200855725]
	TIME [epoch: 8.41 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11827893515894708		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.11827893515894708 | validation: 0.13921357029366624]
	TIME [epoch: 8.41 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534424812223975		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.1534424812223975 | validation: 0.17550333169954602]
	TIME [epoch: 8.42 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12582942757694854		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.12582942757694854 | validation: 0.13362846929337696]
	TIME [epoch: 8.43 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12814826413863262		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.12814826413863262 | validation: 0.14693818340513845]
	TIME [epoch: 8.41 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1139467488222975		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.1139467488222975 | validation: 0.3293647128969259]
	TIME [epoch: 8.41 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15265675254932753		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.15265675254932753 | validation: 0.1871121767126081]
	TIME [epoch: 8.43 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10701310408117079		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.10701310408117079 | validation: 0.1539144811364379]
	TIME [epoch: 8.41 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11915828016950632		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.11915828016950632 | validation: 0.14605737286056888]
	TIME [epoch: 8.42 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11019506237914108		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.11019506237914108 | validation: 0.11884324144889519]
	TIME [epoch: 8.41 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12991345491083267		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.12991345491083267 | validation: 0.1402177772874148]
	TIME [epoch: 8.43 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18869630616815872		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.18869630616815872 | validation: 0.19798898359083406]
	TIME [epoch: 8.42 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17609943812421994		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.17609943812421994 | validation: 0.16586489416395583]
	TIME [epoch: 8.41 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2403195367956692		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.2403195367956692 | validation: 0.2259780781473849]
	TIME [epoch: 8.41 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1636426236764427		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.1636426236764427 | validation: 0.16642836238766623]
	TIME [epoch: 8.43 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15115367805265503		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.15115367805265503 | validation: 0.1289123665456431]
	TIME [epoch: 8.42 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1204497752642694		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.1204497752642694 | validation: 0.1170799555325614]
	TIME [epoch: 8.41 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17750788313367166		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.17750788313367166 | validation: 0.1658401670249633]
	TIME [epoch: 8.41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15359363435620227		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.15359363435620227 | validation: 0.16107886972619045]
	TIME [epoch: 8.43 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12552635365585896		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.12552635365585896 | validation: 0.21953164237807243]
	TIME [epoch: 8.42 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13912184042200007		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.13912184042200007 | validation: 0.15784010376963273]
	TIME [epoch: 8.42 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11408764322788126		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.11408764322788126 | validation: 0.20758407302610293]
	TIME [epoch: 8.42 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15612618393657088		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.15612618393657088 | validation: 0.1463691429398341]
	TIME [epoch: 8.44 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11271341546825657		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.11271341546825657 | validation: 0.15691674372949665]
	TIME [epoch: 8.42 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10706397297897925		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.10706397297897925 | validation: 0.1231424354321331]
	TIME [epoch: 8.42 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16206967260722732		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.16206967260722732 | validation: 0.2442520965994913]
	TIME [epoch: 8.42 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23449059451058035		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.23449059451058035 | validation: 0.12415899319863943]
	TIME [epoch: 8.44 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21071772457121313		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.21071772457121313 | validation: 0.12953392849821543]
	TIME [epoch: 8.42 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15809805120884732		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.15809805120884732 | validation: 0.13280661378104477]
	TIME [epoch: 8.42 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14190420467040488		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.14190420467040488 | validation: 0.13104317227760853]
	TIME [epoch: 8.42 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1165742867622415		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.1165742867622415 | validation: 0.2790289085947899]
	TIME [epoch: 8.44 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.191015889989446		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.191015889989446 | validation: 0.13005135817825939]
	TIME [epoch: 8.41 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1366741573253795		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.1366741573253795 | validation: 0.12484622784750884]
	TIME [epoch: 8.42 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13722668639491026		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.13722668639491026 | validation: 0.2306761176510727]
	TIME [epoch: 8.41 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1325192814304363		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.1325192814304363 | validation: 0.14771622558358732]
	TIME [epoch: 8.45 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10482589651273828		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.10482589651273828 | validation: 0.13114226784962835]
	TIME [epoch: 8.42 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12886204726269881		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.12886204726269881 | validation: 0.19744794768976043]
	TIME [epoch: 8.42 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1440071888905978		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.1440071888905978 | validation: 0.13856704255378544]
	TIME [epoch: 8.42 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12089403643325239		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.12089403643325239 | validation: 0.17001723696150312]
	TIME [epoch: 8.44 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1136214842815401		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.1136214842815401 | validation: 0.1441112034561749]
	TIME [epoch: 8.42 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11937866339505773		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.11937866339505773 | validation: 0.12974905457529548]
	TIME [epoch: 8.42 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11297501820812014		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.11297501820812014 | validation: 0.15031510475711035]
	TIME [epoch: 8.42 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1125652370593508		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.1125652370593508 | validation: 0.12910931097057277]
	TIME [epoch: 8.44 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10728987288133249		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.10728987288133249 | validation: 0.13346077739275844]
	TIME [epoch: 8.41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10864661509406659		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.10864661509406659 | validation: 0.12574732900545282]
	TIME [epoch: 8.42 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11662921702708898		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.11662921702708898 | validation: 0.12992128845174178]
	TIME [epoch: 8.42 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1277768404340775		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.1277768404340775 | validation: 0.14925923347668868]
	TIME [epoch: 8.44 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12543278167498334		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.12543278167498334 | validation: 0.14443100128758696]
	TIME [epoch: 8.42 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10515059705854593		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.10515059705854593 | validation: 0.17466472958991783]
	TIME [epoch: 8.42 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14647318986555555		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.14647318986555555 | validation: 0.1588955795268105]
	TIME [epoch: 8.41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12077943523465526		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.12077943523465526 | validation: 0.12276729132739703]
	TIME [epoch: 8.43 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11584371192061418		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.11584371192061418 | validation: 0.1270361299501318]
	TIME [epoch: 8.42 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10543119020602412		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.10543119020602412 | validation: 0.16714496362759737]
	TIME [epoch: 8.42 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1253675153209986		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.1253675153209986 | validation: 0.1301523274100195]
	TIME [epoch: 8.42 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1152550469258661		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.1152550469258661 | validation: 0.14937752644807778]
	TIME [epoch: 8.43 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1107744254765326		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.1107744254765326 | validation: 0.1751495499135758]
	TIME [epoch: 8.42 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10945491157880238		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.10945491157880238 | validation: 0.17036114174698516]
	TIME [epoch: 8.42 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1133860553297505		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.1133860553297505 | validation: 0.15155333632670043]
	TIME [epoch: 8.42 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10662154042320844		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.10662154042320844 | validation: 0.14465524035956423]
	TIME [epoch: 8.43 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11350034226250441		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.11350034226250441 | validation: 0.15000461453132993]
	TIME [epoch: 8.41 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12009805410871525		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.12009805410871525 | validation: 0.13190832376194941]
	TIME [epoch: 8.41 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11803193284333305		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.11803193284333305 | validation: 0.13896858619665545]
	TIME [epoch: 8.42 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09972300008708163		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.09972300008708163 | validation: 0.13680157956054623]
	TIME [epoch: 8.44 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12295823120082847		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.12295823120082847 | validation: 0.14306111224310414]
	TIME [epoch: 8.42 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1089410066810271		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.1089410066810271 | validation: 0.1308650673186309]
	TIME [epoch: 8.42 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11123618456345455		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.11123618456345455 | validation: 0.12234302368118641]
	TIME [epoch: 8.42 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09974186881009753		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.09974186881009753 | validation: 0.13510253281775192]
	TIME [epoch: 8.43 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14294218604920758		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.14294218604920758 | validation: 0.1758183817410704]
	TIME [epoch: 8.41 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14125039589524246		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.14125039589524246 | validation: 0.13650520402161548]
	TIME [epoch: 8.42 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10884065686957507		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.10884065686957507 | validation: 0.14658613295215828]
	TIME [epoch: 8.43 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10559186867366474		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.10559186867366474 | validation: 0.15231821967485432]
	TIME [epoch: 8.42 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10627555554674488		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.10627555554674488 | validation: 0.12864661886381665]
	TIME [epoch: 8.41 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10945377055434864		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.10945377055434864 | validation: 0.13682737680496615]
	TIME [epoch: 8.41 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13082433591680317		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.13082433591680317 | validation: 0.16754727853498447]
	TIME [epoch: 8.43 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1269685993109296		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.1269685993109296 | validation: 0.14034346797896632]
	TIME [epoch: 8.42 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15353842959296457		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.15353842959296457 | validation: 0.139468972915207]
	TIME [epoch: 8.41 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11716715619385265		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.11716715619385265 | validation: 0.1443268861087632]
	TIME [epoch: 8.41 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11582881480078389		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.11582881480078389 | validation: 0.12767555098208103]
	TIME [epoch: 8.44 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10730322821457808		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.10730322821457808 | validation: 0.14640419801936588]
	TIME [epoch: 8.42 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11575119268054139		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.11575119268054139 | validation: 0.13921111711091688]
	TIME [epoch: 8.41 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10097473880885206		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.10097473880885206 | validation: 0.15553419673654828]
	TIME [epoch: 8.42 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09888365251078397		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.09888365251078397 | validation: 0.12847664809402998]
	TIME [epoch: 8.43 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062140865765419		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.10062140865765419 | validation: 0.14002749763655814]
	TIME [epoch: 8.41 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11150249015817407		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.11150249015817407 | validation: 0.12359183234775906]
	TIME [epoch: 8.42 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10339988996081255		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.10339988996081255 | validation: 0.11930710617289725]
	TIME [epoch: 8.41 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933871782492483		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.09933871782492483 | validation: 0.16631935802384412]
	TIME [epoch: 8.43 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12248616878152477		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.12248616878152477 | validation: 0.1807024649023747]
	TIME [epoch: 8.42 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2327875446424284		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.2327875446424284 | validation: 0.3120149436771391]
	TIME [epoch: 8.42 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1607334865764507		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.1607334865764507 | validation: 0.1357152314671509]
	TIME [epoch: 8.42 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09800373021395756		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.09800373021395756 | validation: 0.1311822338911906]
	TIME [epoch: 8.43 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11746603837753491		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.11746603837753491 | validation: 0.3411594626195444]
	TIME [epoch: 8.41 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16971737605823484		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.16971737605823484 | validation: 0.14760375139652782]
	TIME [epoch: 8.41 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09618547663764199		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.09618547663764199 | validation: 0.11190625995982512]
	TIME [epoch: 8.41 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.121438639636066		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.121438639636066 | validation: 0.1865734810278648]
	TIME [epoch: 8.43 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13945216928719306		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.13945216928719306 | validation: 0.13395327740439697]
	TIME [epoch: 8.42 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10812257521652832		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.10812257521652832 | validation: 0.1642805828581039]
	TIME [epoch: 8.42 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15278579746943755		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.15278579746943755 | validation: 0.12320455895313905]
	TIME [epoch: 8.42 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481934347683955		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.10481934347683955 | validation: 0.14020248570713317]
	TIME [epoch: 8.43 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1008214939156891		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.1008214939156891 | validation: 0.12969701343631598]
	TIME [epoch: 8.42 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1009029287407501		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.1009029287407501 | validation: 0.11297564882856982]
	TIME [epoch: 8.41 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08983030372273536		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.08983030372273536 | validation: 0.1267388968004624]
	TIME [epoch: 8.42 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10887677491518352		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.10887677491518352 | validation: 0.1267416511075377]
	TIME [epoch: 8.44 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10263242202552385		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.10263242202552385 | validation: 0.16441110261113837]
	TIME [epoch: 8.42 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10465538742978572		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.10465538742978572 | validation: 0.1236615264373758]
	TIME [epoch: 8.42 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.106996844028366		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.106996844028366 | validation: 0.12234335296155374]
	TIME [epoch: 8.41 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10186300224006858		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.10186300224006858 | validation: 0.12024607668827447]
	TIME [epoch: 8.43 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10785944697772318		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.10785944697772318 | validation: 0.14577106645203636]
	TIME [epoch: 8.41 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11103433202498814		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.11103433202498814 | validation: 0.1497870421110314]
	TIME [epoch: 8.41 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10221764728775981		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.10221764728775981 | validation: 0.13087624583439517]
	TIME [epoch: 8.42 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10722628012879967		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.10722628012879967 | validation: 0.1280637923340835]
	TIME [epoch: 8.43 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10004539856098087		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.10004539856098087 | validation: 0.11794019357572422]
	TIME [epoch: 8.42 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1103278430226328		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.1103278430226328 | validation: 0.19091591326245133]
	TIME [epoch: 8.42 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12017777212768328		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.12017777212768328 | validation: 0.11511637782799634]
	TIME [epoch: 8.42 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09464342205711307		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.09464342205711307 | validation: 0.13757540927050782]
	TIME [epoch: 8.44 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1055712690554302		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.1055712690554302 | validation: 0.1491270989132243]
	TIME [epoch: 8.42 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11387591351679711		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.11387591351679711 | validation: 0.12313039448631974]
	TIME [epoch: 8.41 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08772055039474583		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.08772055039474583 | validation: 0.11530417588784027]
	TIME [epoch: 8.43 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14241150760342308		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.14241150760342308 | validation: 0.23775285841656285]
	TIME [epoch: 8.42 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14367683576553208		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.14367683576553208 | validation: 0.1425224349378861]
	TIME [epoch: 8.43 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10295507795108683		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.10295507795108683 | validation: 0.12750488281538538]
	TIME [epoch: 8.41 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09791650807075838		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.09791650807075838 | validation: 0.11240789553609867]
	TIME [epoch: 8.42 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1029098831339776		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.1029098831339776 | validation: 0.14203826778372064]
	TIME [epoch: 8.43 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395378613828126		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.1395378613828126 | validation: 0.2871187814932858]
	TIME [epoch: 8.42 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13264188551861056		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.13264188551861056 | validation: 0.1133592697636536]
	TIME [epoch: 8.42 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10116792777940786		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.10116792777940786 | validation: 0.13387774307594907]
	TIME [epoch: 8.43 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12536136393782565		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.12536136393782565 | validation: 0.3469395899984268]
	TIME [epoch: 8.43 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19633302265546637		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.19633302265546637 | validation: 0.12141444154478799]
	TIME [epoch: 8.42 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15458681989505696		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.15458681989505696 | validation: 0.17122426137340713]
	TIME [epoch: 8.42 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12224410189721502		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.12224410189721502 | validation: 0.12973683101343908]
	TIME [epoch: 8.43 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09484653913684679		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.09484653913684679 | validation: 0.13358512912757298]
	TIME [epoch: 8.42 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11165802862922629		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.11165802862922629 | validation: 0.1391808844679586]
	TIME [epoch: 8.41 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09255039791546928		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.09255039791546928 | validation: 0.10727560106886799]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_997.pth
	Model improved!!!
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09760211489900597		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.09760211489900597 | validation: 0.12512200292975223]
	TIME [epoch: 8.43 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1165519413705162		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.1165519413705162 | validation: 0.15573615621307896]
	TIME [epoch: 8.41 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10828899881937053		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.10828899881937053 | validation: 0.14576395717142182]
	TIME [epoch: 8.41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11544660523874994		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.11544660523874994 | validation: 0.13775745493278466]
	TIME [epoch: 8.41 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441439887309022		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.09441439887309022 | validation: 0.13533828004292298]
	TIME [epoch: 8.43 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09229179120735813		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.09229179120735813 | validation: 0.12672556146386982]
	TIME [epoch: 8.41 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11415482877097646		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.11415482877097646 | validation: 0.13581668557610788]
	TIME [epoch: 8.41 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1036860357972665		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.1036860357972665 | validation: 0.13698257675063163]
	TIME [epoch: 8.41 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09649137779192606		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.09649137779192606 | validation: 0.1579741476067772]
	TIME [epoch: 8.42 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10358326626977665		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.10358326626977665 | validation: 0.12466041904109673]
	TIME [epoch: 8.41 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09555391638579115		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.09555391638579115 | validation: 0.1350501914450066]
	TIME [epoch: 8.41 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10994749207853767		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.10994749207853767 | validation: 0.11894162738638706]
	TIME [epoch: 8.41 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09227299792386355		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.09227299792386355 | validation: 0.16794071674917854]
	TIME [epoch: 8.43 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10925826915159972		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.10925826915159972 | validation: 0.12225654415218684]
	TIME [epoch: 8.42 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1102864022340548		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.1102864022340548 | validation: 0.14620628496450955]
	TIME [epoch: 8.41 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1148069086718001		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.1148069086718001 | validation: 0.14094805837205931]
	TIME [epoch: 8.41 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10956303393309359		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.10956303393309359 | validation: 0.12920609386120674]
	TIME [epoch: 8.43 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10658640847962082		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.10658640847962082 | validation: 0.12877315398119332]
	TIME [epoch: 8.41 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09615491602193645		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.09615491602193645 | validation: 0.15381451376075966]
	TIME [epoch: 8.42 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10890253257993532		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.10890253257993532 | validation: 0.13896789992428293]
	TIME [epoch: 8.41 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931023673004445		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.0931023673004445 | validation: 0.12017026238195566]
	TIME [epoch: 8.44 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09779669201414867		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.09779669201414867 | validation: 0.12758503688120654]
	TIME [epoch: 8.41 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09499709059882692		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.09499709059882692 | validation: 0.13683574020463102]
	TIME [epoch: 8.41 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11941983540906531		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.11941983540906531 | validation: 0.11950120239438197]
	TIME [epoch: 8.42 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0936556549905948		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.0936556549905948 | validation: 0.12571457339440373]
	TIME [epoch: 8.44 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10157170568402085		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.10157170568402085 | validation: 0.1268694206422005]
	TIME [epoch: 8.41 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09671841582306188		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.09671841582306188 | validation: 0.14420570444898106]
	TIME [epoch: 8.42 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1028619282652636		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.1028619282652636 | validation: 0.11923738486560093]
	TIME [epoch: 8.42 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0977717094000394		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.0977717094000394 | validation: 0.15197657601805203]
	TIME [epoch: 8.44 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09529109459073709		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.09529109459073709 | validation: 0.12007690985157306]
	TIME [epoch: 8.42 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0856241547637752		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.0856241547637752 | validation: 0.12062315973772599]
	TIME [epoch: 8.42 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08786569592012664		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.08786569592012664 | validation: 0.1389992998659511]
	TIME [epoch: 8.42 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09206368124400174		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.09206368124400174 | validation: 0.12428334160705279]
	TIME [epoch: 8.44 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0892832333006955		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.0892832333006955 | validation: 0.12002019149643789]
	TIME [epoch: 8.42 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08655790734423431		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.08655790734423431 | validation: 0.12963809778601865]
	TIME [epoch: 8.41 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10009106568625589		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.10009106568625589 | validation: 0.14641454658898273]
	TIME [epoch: 8.42 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10345033876750656		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.10345033876750656 | validation: 0.14330721713970973]
	TIME [epoch: 8.44 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0988129131458014		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.0988129131458014 | validation: 0.16866260368897656]
	TIME [epoch: 8.41 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14335438463564731		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.14335438463564731 | validation: 0.12378125694248951]
	TIME [epoch: 8.42 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10279783777521004		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.10279783777521004 | validation: 0.11071394470869061]
	TIME [epoch: 8.42 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09055892864748369		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.09055892864748369 | validation: 0.12685939462953633]
	TIME [epoch: 8.43 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09421102857357619		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.09421102857357619 | validation: 0.12664572080966197]
	TIME [epoch: 8.42 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09761323190008565		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.09761323190008565 | validation: 0.1432589193598789]
	TIME [epoch: 8.41 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10324824903652592		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.10324824903652592 | validation: 0.16323345862305016]
	TIME [epoch: 8.43 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09413381719005931		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.09413381719005931 | validation: 0.13571092766800008]
	TIME [epoch: 8.43 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10418934228155545		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.10418934228155545 | validation: 0.14016208457504545]
	TIME [epoch: 8.41 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09717427047625386		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.09717427047625386 | validation: 0.12466147237688553]
	TIME [epoch: 8.41 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09685080438175026		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.09685080438175026 | validation: 0.12203318697708805]
	TIME [epoch: 8.42 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11043908508559004		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.11043908508559004 | validation: 0.12118651921245112]
	TIME [epoch: 8.43 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12480593623906086		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.12480593623906086 | validation: 0.13050924378859696]
	TIME [epoch: 8.42 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10015915899929069		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.10015915899929069 | validation: 0.10995723712882192]
	TIME [epoch: 8.41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1007628445961825		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.1007628445961825 | validation: 0.14614345915908544]
	TIME [epoch: 8.43 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11311563462184601		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.11311563462184601 | validation: 0.12650622444769377]
	TIME [epoch: 8.42 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10811176689206267		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.10811176689206267 | validation: 0.12115405369709753]
	TIME [epoch: 8.42 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09192325052641573		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.09192325052641573 | validation: 0.14069424614425302]
	TIME [epoch: 8.41 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10301829903831736		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.10301829903831736 | validation: 0.1329158409350308]
	TIME [epoch: 8.43 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09440036700342955		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.09440036700342955 | validation: 0.1303668196493874]
	TIME [epoch: 8.43 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08953346508267024		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.08953346508267024 | validation: 0.13521198077896848]
	TIME [epoch: 8.42 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09216938733606586		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.09216938733606586 | validation: 0.14514205637126945]
	TIME [epoch: 8.41 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10096566432172623		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.10096566432172623 | validation: 0.118912907674658]
	TIME [epoch: 8.43 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1079428556446741		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.1079428556446741 | validation: 0.14811940143534474]
	TIME [epoch: 8.42 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11563009663864869		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.11563009663864869 | validation: 0.1463298566111264]
	TIME [epoch: 8.41 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398860458930604		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.08398860458930604 | validation: 0.1325145037411999]
	TIME [epoch: 8.41 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08868644539147293		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.08868644539147293 | validation: 0.1379833274986399]
	TIME [epoch: 8.43 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12285193047905736		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.12285193047905736 | validation: 0.1289796944758789]
	TIME [epoch: 8.42 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08706546822840706		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.08706546822840706 | validation: 0.14277044518563412]
	TIME [epoch: 8.42 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11112618628475031		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.11112618628475031 | validation: 0.13005165932711465]
	TIME [epoch: 8.42 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09256158510093832		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.09256158510093832 | validation: 0.1215760845810478]
	TIME [epoch: 8.43 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09037065576905601		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.09037065576905601 | validation: 0.1171043981519306]
	TIME [epoch: 8.42 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09244116457792717		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.09244116457792717 | validation: 0.13998068218198334]
	TIME [epoch: 8.42 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09333638723140344		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.09333638723140344 | validation: 0.12885163565363167]
	TIME [epoch: 8.41 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08832040053415453		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.08832040053415453 | validation: 0.134693606368137]
	TIME [epoch: 8.43 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08113613723374614		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.08113613723374614 | validation: 0.12721343494321433]
	TIME [epoch: 8.42 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08315061678972609		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.08315061678972609 | validation: 0.10301177429769395]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1071.pth
	Model improved!!!
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08422809807267709		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.08422809807267709 | validation: 0.12904866587322406]
	TIME [epoch: 8.41 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08996975235522753		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.08996975235522753 | validation: 0.14474321451149103]
	TIME [epoch: 8.44 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10492774733113268		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.10492774733113268 | validation: 0.13120380468338289]
	TIME [epoch: 8.41 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12774926418741656		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.12774926418741656 | validation: 0.12431867734279502]
	TIME [epoch: 8.41 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09531422562698676		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.09531422562698676 | validation: 0.1192822178295031]
	TIME [epoch: 8.42 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10610232623171889		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.10610232623171889 | validation: 0.16160289777564651]
	TIME [epoch: 8.44 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09852149715731372		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.09852149715731372 | validation: 0.13342530740677525]
	TIME [epoch: 8.42 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09100642780778227		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.09100642780778227 | validation: 0.12942897164615377]
	TIME [epoch: 8.42 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09348302524769739		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.09348302524769739 | validation: 0.13546764068674189]
	TIME [epoch: 8.41 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08781888068457779		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.08781888068457779 | validation: 0.12762903172800522]
	TIME [epoch: 8.43 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0832982124548938		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.0832982124548938 | validation: 0.09975102238132158]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09555803519088552		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.09555803519088552 | validation: 0.12894661547599498]
	TIME [epoch: 8.41 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08768461466865299		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.08768461466865299 | validation: 0.12129073855777217]
	TIME [epoch: 8.42 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09855578726145271		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.09855578726145271 | validation: 0.12581585849841742]
	TIME [epoch: 8.43 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0953888369410506		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.0953888369410506 | validation: 0.1394064678759222]
	TIME [epoch: 8.41 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09604862899739502		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.09604862899739502 | validation: 0.14680126696561197]
	TIME [epoch: 8.41 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09061450664239526		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.09061450664239526 | validation: 0.11717458768431226]
	TIME [epoch: 8.41 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08649102635761038		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.08649102635761038 | validation: 0.13586299458275408]
	TIME [epoch: 8.43 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08875019760694505		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.08875019760694505 | validation: 0.1436678438861911]
	TIME [epoch: 8.41 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10744834732024314		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.10744834732024314 | validation: 0.11888228549053076]
	TIME [epoch: 8.41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09156016757193422		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.09156016757193422 | validation: 0.1266646020679658]
	TIME [epoch: 8.4 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08771892195343867		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.08771892195343867 | validation: 0.11960621993424118]
	TIME [epoch: 8.43 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09653361710077203		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.09653361710077203 | validation: 0.11979464095798398]
	TIME [epoch: 8.42 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08684670290218059		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.08684670290218059 | validation: 0.12174522463877971]
	TIME [epoch: 8.41 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09008412512751547		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.09008412512751547 | validation: 0.11290674406617418]
	TIME [epoch: 8.42 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11605073675618098		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.11605073675618098 | validation: 0.14775617498787472]
	TIME [epoch: 8.42 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09448403790810594		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.09448403790810594 | validation: 0.12187579953375058]
	TIME [epoch: 8.41 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09682865684796653		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.09682865684796653 | validation: 0.13894455070317954]
	TIME [epoch: 8.41 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08584136021157035		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.08584136021157035 | validation: 0.11736783184175385]
	TIME [epoch: 8.42 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09792826397600872		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.09792826397600872 | validation: 0.1168226292249177]
	TIME [epoch: 8.42 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08097814642455359		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.08097814642455359 | validation: 0.1334038803969888]
	TIME [epoch: 8.41 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10332313303766139		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.10332313303766139 | validation: 0.12755697202256944]
	TIME [epoch: 8.41 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09238249501789833		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.09238249501789833 | validation: 0.12787268940307056]
	TIME [epoch: 8.42 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1088089695271369		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.1088089695271369 | validation: 0.11833342999077742]
	TIME [epoch: 8.42 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0829075573522835		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.0829075573522835 | validation: 0.11284361347457048]
	TIME [epoch: 8.41 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08247067210891933		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.08247067210891933 | validation: 0.11704549559435005]
	TIME [epoch: 8.41 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10158014494491485		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.10158014494491485 | validation: 0.11716378522787042]
	TIME [epoch: 8.42 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08708777485014377		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.08708777485014377 | validation: 0.12113109399655339]
	TIME [epoch: 8.42 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08860625378033007		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.08860625378033007 | validation: 0.12243154567240006]
	TIME [epoch: 8.41 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09312951441109704		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.09312951441109704 | validation: 0.11539728300907218]
	TIME [epoch: 8.41 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08692090932761022		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.08692090932761022 | validation: 0.1369042280243461]
	TIME [epoch: 8.42 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08988938539513039		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.08988938539513039 | validation: 0.12614509541433114]
	TIME [epoch: 8.42 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09890738976636738		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.09890738976636738 | validation: 0.12327233493539477]
	TIME [epoch: 8.4 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09219057380981857		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.09219057380981857 | validation: 0.12077188991191247]
	TIME [epoch: 8.41 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10493932680264884		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.10493932680264884 | validation: 0.11665667521544582]
	TIME [epoch: 8.42 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08449056532815075		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.08449056532815075 | validation: 0.13237280207088908]
	TIME [epoch: 8.41 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09011318181700204		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.09011318181700204 | validation: 0.13109727198147283]
	TIME [epoch: 8.41 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09703051586577045		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.09703051586577045 | validation: 0.13829211396841956]
	TIME [epoch: 8.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10478632261930827		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.10478632261930827 | validation: 0.17134712766876964]
	TIME [epoch: 8.43 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09574387500741166		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.09574387500741166 | validation: 0.11799476104878459]
	TIME [epoch: 8.41 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07706803015769886		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.07706803015769886 | validation: 0.11247304380727234]
	TIME [epoch: 8.41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09437611338504216		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.09437611338504216 | validation: 0.11762662764685744]
	TIME [epoch: 8.41 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07654784908110439		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.07654784908110439 | validation: 0.1241497919428593]
	TIME [epoch: 8.43 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08500064374148449		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.08500064374148449 | validation: 0.10471213006591258]
	TIME [epoch: 8.42 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09214414999688068		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.09214414999688068 | validation: 0.1150624889222481]
	TIME [epoch: 8.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09143210434280144		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.09143210434280144 | validation: 0.14825635026468487]
	TIME [epoch: 8.41 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015614512558071		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.08015614512558071 | validation: 0.12143455472400351]
	TIME [epoch: 8.42 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08960061777510557		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.08960061777510557 | validation: 0.11728050357722053]
	TIME [epoch: 8.42 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09190552447219917		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.09190552447219917 | validation: 0.11735417251556582]
	TIME [epoch: 8.41 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08536691346353419		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.08536691346353419 | validation: 0.15344185671673882]
	TIME [epoch: 8.41 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09541372339406635		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.09541372339406635 | validation: 0.11337018857765668]
	TIME [epoch: 8.42 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09743381693479763		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.09743381693479763 | validation: 0.14298365511585368]
	TIME [epoch: 8.42 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11614997877412307		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.11614997877412307 | validation: 0.14539007031376003]
	TIME [epoch: 8.41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08451589483089501		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.08451589483089501 | validation: 0.12520626821634798]
	TIME [epoch: 8.41 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08331939823035565		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.08331939823035565 | validation: 0.11464668627012972]
	TIME [epoch: 8.43 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08267114520553286		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.08267114520553286 | validation: 0.11196574923532057]
	TIME [epoch: 8.41 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0878141734003102		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.0878141734003102 | validation: 0.12015231780550911]
	TIME [epoch: 8.41 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08573265324184795		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.08573265324184795 | validation: 0.11489969449343457]
	TIME [epoch: 8.41 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08697025226378069		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.08697025226378069 | validation: 0.12113640311621304]
	TIME [epoch: 8.43 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08723304084455437		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.08723304084455437 | validation: 0.12835450827690376]
	TIME [epoch: 8.41 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09631450168164485		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.09631450168164485 | validation: 0.11784654236866404]
	TIME [epoch: 8.41 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08588424098194461		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.08588424098194461 | validation: 0.11108735072892953]
	TIME [epoch: 8.41 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08625446463909849		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.08625446463909849 | validation: 0.14794948712092704]
	TIME [epoch: 8.43 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10320177433319824		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.10320177433319824 | validation: 0.11567543890312293]
	TIME [epoch: 8.41 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08729786737098226		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.08729786737098226 | validation: 0.16092677131800803]
	TIME [epoch: 8.41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10227475318796012		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.10227475318796012 | validation: 0.12315280267117809]
	TIME [epoch: 8.42 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08302551124020069		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.08302551124020069 | validation: 0.12838824399285492]
	TIME [epoch: 8.44 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.080847447645106		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.080847447645106 | validation: 0.12787770055163455]
	TIME [epoch: 8.41 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09520086825368387		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.09520086825368387 | validation: 0.14934230656102784]
	TIME [epoch: 8.41 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054132406607454		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.09054132406607454 | validation: 0.10573267948404691]
	TIME [epoch: 8.41 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08790846021336216		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.08790846021336216 | validation: 0.10744327929820655]
	TIME [epoch: 8.43 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07978744851876123		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.07978744851876123 | validation: 0.11779029064910548]
	TIME [epoch: 8.41 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08361239708685632		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.08361239708685632 | validation: 0.12646566396130116]
	TIME [epoch: 8.41 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11327027656297498		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.11327027656297498 | validation: 0.12543648007279776]
	TIME [epoch: 8.41 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08535983042915558		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.08535983042915558 | validation: 0.12124046311267372]
	TIME [epoch: 8.44 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08309398912103128		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.08309398912103128 | validation: 0.11071987087374674]
	TIME [epoch: 8.41 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0851638178389777		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.0851638178389777 | validation: 0.12745914467188288]
	TIME [epoch: 8.42 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10012721930414126		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.10012721930414126 | validation: 0.12062538594577446]
	TIME [epoch: 8.42 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08462554895564321		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.08462554895564321 | validation: 0.12676287654542184]
	TIME [epoch: 8.43 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07938468407323544		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.07938468407323544 | validation: 0.1159276827849004]
	TIME [epoch: 8.42 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08335815354469844		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.08335815354469844 | validation: 0.11970608567502472]
	TIME [epoch: 8.41 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0875915998409482		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.0875915998409482 | validation: 0.1266412702729196]
	TIME [epoch: 8.42 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0835323847133039		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.0835323847133039 | validation: 0.1200275323387626]
	TIME [epoch: 8.43 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07716888373730381		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.07716888373730381 | validation: 0.12006399332044448]
	TIME [epoch: 8.41 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07939245638844866		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.07939245638844866 | validation: 0.12568396847367547]
	TIME [epoch: 8.41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0907671803534005		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.0907671803534005 | validation: 0.1208672222834617]
	TIME [epoch: 8.42 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08288293103520425		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.08288293103520425 | validation: 0.11452693313544349]
	TIME [epoch: 8.42 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10018188768460863		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.10018188768460863 | validation: 0.144498417177785]
	TIME [epoch: 8.41 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.203876220545511		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.203876220545511 | validation: 0.18865268478095068]
	TIME [epoch: 8.41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13094451797610998		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.13094451797610998 | validation: 0.10957044843803246]
	TIME [epoch: 8.42 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08587786109004839		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.08587786109004839 | validation: 0.16090825088875296]
	TIME [epoch: 8.43 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10331192498507939		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.10331192498507939 | validation: 0.11931182876494742]
	TIME [epoch: 8.41 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08336170222434924		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.08336170222434924 | validation: 0.13672876171592185]
	TIME [epoch: 8.42 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0869738385019442		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.0869738385019442 | validation: 0.12312849096953928]
	TIME [epoch: 8.42 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07606770520831617		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.07606770520831617 | validation: 0.10478261908646255]
	TIME [epoch: 8.43 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08561830441914994		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.08561830441914994 | validation: 0.12791036296868186]
	TIME [epoch: 8.41 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10954418300022913		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.10954418300022913 | validation: 0.12090813350709848]
	TIME [epoch: 8.41 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10360421290342729		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.10360421290342729 | validation: 0.12398258986226532]
	TIME [epoch: 8.43 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08283090454458127		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.08283090454458127 | validation: 0.12507110035113722]
	TIME [epoch: 8.42 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08079199347257643		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.08079199347257643 | validation: 0.10415859496208632]
	TIME [epoch: 8.41 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08393320789317202		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.08393320789317202 | validation: 0.1065642307683211]
	TIME [epoch: 8.42 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07732943108906787		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.07732943108906787 | validation: 0.11730028420935287]
	TIME [epoch: 8.43 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08287941327357336		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.08287941327357336 | validation: 0.10225224650964998]
	TIME [epoch: 8.42 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07917113062195248		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.07917113062195248 | validation: 0.11463351625779283]
	TIME [epoch: 8.41 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07851346854060537		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.07851346854060537 | validation: 0.12354855973989273]
	TIME [epoch: 8.41 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10822342866437226		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.10822342866437226 | validation: 0.12660288813921977]
	TIME [epoch: 8.43 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09142864031644019		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.09142864031644019 | validation: 0.13911198826125024]
	TIME [epoch: 8.42 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08370137089807464		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.08370137089807464 | validation: 0.1234155293537807]
	TIME [epoch: 8.41 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07990589732232091		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.07990589732232091 | validation: 0.11558636634852819]
	TIME [epoch: 8.42 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08157073987940347		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.08157073987940347 | validation: 0.10887706385071765]
	TIME [epoch: 8.43 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07678539005889394		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.07678539005889394 | validation: 0.10432228517262736]
	TIME [epoch: 8.42 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08627926360869406		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.08627926360869406 | validation: 0.11366523481554512]
	TIME [epoch: 8.41 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08305260330778948		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.08305260330778948 | validation: 0.10712607017880607]
	TIME [epoch: 8.41 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08425106576337442		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.08425106576337442 | validation: 0.11139878491659194]
	TIME [epoch: 8.43 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09545084791627877		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.09545084791627877 | validation: 0.11227000466222714]
	TIME [epoch: 8.42 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281041998693245		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.1281041998693245 | validation: 0.1212917972629802]
	TIME [epoch: 8.41 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10472245783042058		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.10472245783042058 | validation: 0.11282948015965474]
	TIME [epoch: 8.41 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08072267834752303		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.08072267834752303 | validation: 0.10190168887896914]
	TIME [epoch: 8.43 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08121575381697628		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.08121575381697628 | validation: 0.11736947514071529]
	TIME [epoch: 8.42 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07802161102897834		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.07802161102897834 | validation: 0.11101885607282663]
	TIME [epoch: 8.41 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08338900310142523		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.08338900310142523 | validation: 0.1135134988217282]
	TIME [epoch: 8.41 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10098948723533456		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.10098948723533456 | validation: 0.12052488837122836]
	TIME [epoch: 8.43 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0838589970904574		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.0838589970904574 | validation: 0.12775796112896745]
	TIME [epoch: 8.41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09310235943235687		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.09310235943235687 | validation: 0.11215774899761558]
	TIME [epoch: 8.41 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08305831339655839		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.08305831339655839 | validation: 0.10323804631442901]
	TIME [epoch: 8.41 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07735116900857061		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.07735116900857061 | validation: 0.09848752828324144]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1207.pth
	Model improved!!!
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09786041343469463		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.09786041343469463 | validation: 0.10814330810618672]
	TIME [epoch: 8.42 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07856146247957847		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.07856146247957847 | validation: 0.11006568307737356]
	TIME [epoch: 8.42 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0834543543732738		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.0834543543732738 | validation: 0.16152759781336273]
	TIME [epoch: 8.42 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0953310213770201		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.0953310213770201 | validation: 0.10071468931800551]
	TIME [epoch: 8.44 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966088151966229		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.07966088151966229 | validation: 0.11315272897302589]
	TIME [epoch: 8.42 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09262995734916975		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.09262995734916975 | validation: 0.11527624787020671]
	TIME [epoch: 8.42 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0950145599711871		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.0950145599711871 | validation: 0.10455524756778595]
	TIME [epoch: 8.43 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08380959790957997		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.08380959790957997 | validation: 0.12366139079743527]
	TIME [epoch: 8.44 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08671065074533589		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.08671065074533589 | validation: 0.11293037558748512]
	TIME [epoch: 8.42 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07623475206815075		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.07623475206815075 | validation: 0.10089888251891568]
	TIME [epoch: 8.42 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0734229447969924		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.0734229447969924 | validation: 0.11733273939788151]
	TIME [epoch: 8.43 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07536577352066563		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.07536577352066563 | validation: 0.11567445462955875]
	TIME [epoch: 8.43 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07163212620713755		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.07163212620713755 | validation: 0.11964953161900177]
	TIME [epoch: 8.43 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0790463562316068		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.0790463562316068 | validation: 0.11278268849719719]
	TIME [epoch: 8.42 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08470634096550143		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.08470634096550143 | validation: 0.11355926931008606]
	TIME [epoch: 8.44 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07399039193167727		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.07399039193167727 | validation: 0.11532178387798644]
	TIME [epoch: 8.43 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07785737836985539		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.07785737836985539 | validation: 0.12251054627900214]
	TIME [epoch: 8.43 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08275964611565337		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.08275964611565337 | validation: 0.11757803991742809]
	TIME [epoch: 8.42 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10894356042867406		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.10894356042867406 | validation: 0.11861783455002717]
	TIME [epoch: 8.43 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08180069142876774		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.08180069142876774 | validation: 0.10736764609002225]
	TIME [epoch: 8.43 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0707052592322168		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.0707052592322168 | validation: 0.11637857162388429]
	TIME [epoch: 8.43 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08507804671510223		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.08507804671510223 | validation: 0.1323948205976826]
	TIME [epoch: 8.42 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08254275346303937		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.08254275346303937 | validation: 0.12076227343164997]
	TIME [epoch: 8.44 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08284556509927507		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.08284556509927507 | validation: 0.10341481309507736]
	TIME [epoch: 8.43 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08230196025912861		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.08230196025912861 | validation: 0.10104391342642259]
	TIME [epoch: 8.43 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09506656860819285		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.09506656860819285 | validation: 0.11739893449849673]
	TIME [epoch: 8.43 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08306562498037873		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.08306562498037873 | validation: 0.11704449366645528]
	TIME [epoch: 8.44 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077190843031099		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.077190843031099 | validation: 0.11871188508453644]
	TIME [epoch: 8.43 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08651894582057797		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.08651894582057797 | validation: 0.11499525603668695]
	TIME [epoch: 8.42 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0802260008304803		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.0802260008304803 | validation: 0.14993299432293822]
	TIME [epoch: 8.42 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08374985912903785		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.08374985912903785 | validation: 0.11104959806445916]
	TIME [epoch: 8.44 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07895986546181225		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.07895986546181225 | validation: 0.12256965743137016]
	TIME [epoch: 8.43 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0893930248540214		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.0893930248540214 | validation: 0.1358338720580016]
	TIME [epoch: 8.42 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07450214568916132		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.07450214568916132 | validation: 0.10743527698935437]
	TIME [epoch: 8.43 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0797856868925689		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.0797856868925689 | validation: 0.11197119004090825]
	TIME [epoch: 8.44 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716168529729069		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.0716168529729069 | validation: 0.1194620276594262]
	TIME [epoch: 8.43 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0924452673118686		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.0924452673118686 | validation: 0.12526091075326765]
	TIME [epoch: 8.42 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08067224666101067		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.08067224666101067 | validation: 0.10225230440017469]
	TIME [epoch: 8.42 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0724736913828656		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.0724736913828656 | validation: 0.11927204622052925]
	TIME [epoch: 8.44 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07686176212517196		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.07686176212517196 | validation: 0.10646979057061434]
	TIME [epoch: 8.44 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08221754413502232		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.08221754413502232 | validation: 0.11914450051920453]
	TIME [epoch: 8.44 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08298185213191868		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.08298185213191868 | validation: 0.12186741666099676]
	TIME [epoch: 8.43 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08163445510990237		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.08163445510990237 | validation: 0.11414177676397022]
	TIME [epoch: 8.46 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07763846364964266		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.07763846364964266 | validation: 0.12371103179502432]
	TIME [epoch: 8.43 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0902552897024904		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.0902552897024904 | validation: 0.136159646745931]
	TIME [epoch: 8.42 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08328233947306982		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.08328233947306982 | validation: 0.10610624804637521]
	TIME [epoch: 8.43 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07767291117550305		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.07767291117550305 | validation: 0.12635715547237097]
	TIME [epoch: 8.45 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.083749672988222		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.083749672988222 | validation: 0.11731691365129851]
	TIME [epoch: 8.43 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08440988567508109		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.08440988567508109 | validation: 0.10476586156814113]
	TIME [epoch: 8.43 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719862957066854		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.0719862957066854 | validation: 0.10838809823581322]
	TIME [epoch: 8.43 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08005777537499417		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.08005777537499417 | validation: 0.10754084061097317]
	TIME [epoch: 8.45 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07282233432709478		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.07282233432709478 | validation: 0.11405454580492816]
	TIME [epoch: 8.43 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08112937969764752		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.08112937969764752 | validation: 0.10992311823197987]
	TIME [epoch: 8.43 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07280842969725154		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.07280842969725154 | validation: 0.12631412525653576]
	TIME [epoch: 8.42 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07225650025734566		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.07225650025734566 | validation: 0.11431142326480057]
	TIME [epoch: 8.45 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0721921562628219		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.0721921562628219 | validation: 0.11713889042833021]
	TIME [epoch: 8.42 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08952460928370018		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.08952460928370018 | validation: 0.12252230109704114]
	TIME [epoch: 8.43 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06931187148512441		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.06931187148512441 | validation: 0.1011231949139525]
	TIME [epoch: 8.43 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08115792211657372		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.08115792211657372 | validation: 0.10896557115844517]
	TIME [epoch: 8.45 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0707211461363077		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.0707211461363077 | validation: 0.12481709073493746]
	TIME [epoch: 8.42 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07497320984036686		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.07497320984036686 | validation: 0.10828606526543455]
	TIME [epoch: 8.43 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07962748374513073		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.07962748374513073 | validation: 0.11453735358455969]
	TIME [epoch: 8.42 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07369791098835929		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.07369791098835929 | validation: 0.11300692437964775]
	TIME [epoch: 8.45 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0710595877604611		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.0710595877604611 | validation: 0.10349460172888236]
	TIME [epoch: 8.43 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07502815605015337		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.07502815605015337 | validation: 0.11875318849382832]
	TIME [epoch: 8.43 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07281271848276452		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.07281271848276452 | validation: 0.10903111804832091]
	TIME [epoch: 8.43 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07016567214302802		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.07016567214302802 | validation: 0.1112725860747815]
	TIME [epoch: 8.44 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015309066284342		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.08015309066284342 | validation: 0.10717398453043589]
	TIME [epoch: 8.42 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07411253980910704		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.07411253980910704 | validation: 0.10087362195707666]
	TIME [epoch: 8.43 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0813747850388756		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.0813747850388756 | validation: 0.10926270646792391]
	TIME [epoch: 8.43 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07239387492465585		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.07239387492465585 | validation: 0.11298056791102384]
	TIME [epoch: 8.44 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07775327266314425		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.07775327266314425 | validation: 0.12209690170060009]
	TIME [epoch: 8.43 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07672674371972626		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.07672674371972626 | validation: 0.10947535888277168]
	TIME [epoch: 8.42 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07830445590066007		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.07830445590066007 | validation: 0.09737960514337565]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1281.pth
	Model improved!!!
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07470406177999563		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.07470406177999563 | validation: 0.11412607555291232]
	TIME [epoch: 8.43 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07148017637769465		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.07148017637769465 | validation: 0.11880698227428887]
	TIME [epoch: 8.41 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07284723873119359		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.07284723873119359 | validation: 0.11038017114572171]
	TIME [epoch: 8.42 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07428680253034964		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.07428680253034964 | validation: 0.12458274920048348]
	TIME [epoch: 8.43 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07346570244690566		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.07346570244690566 | validation: 0.10216826072218063]
	TIME [epoch: 8.42 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07525598169908737		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.07525598169908737 | validation: 0.11870874505609615]
	TIME [epoch: 8.41 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0787026189407176		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.0787026189407176 | validation: 0.11408499002712076]
	TIME [epoch: 8.41 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07012706143493246		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.07012706143493246 | validation: 0.11723166143201402]
	TIME [epoch: 8.43 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0763194166974595		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.0763194166974595 | validation: 0.13041759303170058]
	TIME [epoch: 8.42 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08592439766001082		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.08592439766001082 | validation: 0.1283015865407096]
	TIME [epoch: 8.41 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08074358060425402		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.08074358060425402 | validation: 0.10721810443366579]
	TIME [epoch: 8.41 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07343970163738614		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.07343970163738614 | validation: 0.11823296115424013]
	TIME [epoch: 8.43 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0788847236124042		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.0788847236124042 | validation: 0.10767513084778846]
	TIME [epoch: 8.42 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07054616998346146		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.07054616998346146 | validation: 0.10183055646614184]
	TIME [epoch: 8.42 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07223257953896811		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.07223257953896811 | validation: 0.10546213604338364]
	TIME [epoch: 8.4 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0728019058727413		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.0728019058727413 | validation: 0.11338974376676214]
	TIME [epoch: 8.43 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07187447280969161		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.07187447280969161 | validation: 0.11881988795039888]
	TIME [epoch: 8.41 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07738539133532843		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.07738539133532843 | validation: 0.12073781607348957]
	TIME [epoch: 8.41 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07626598404707564		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.07626598404707564 | validation: 0.12185398598873226]
	TIME [epoch: 8.41 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07115761458841144		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.07115761458841144 | validation: 0.14119046036942726]
	TIME [epoch: 8.43 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0894679428672717		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.0894679428672717 | validation: 0.11724533469561096]
	TIME [epoch: 8.42 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07738361496211207		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.07738361496211207 | validation: 0.10391485907657791]
	TIME [epoch: 8.41 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726229666759598		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.0726229666759598 | validation: 0.11226648150254115]
	TIME [epoch: 8.41 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08032867613821318		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.08032867613821318 | validation: 0.11425742038354098]
	TIME [epoch: 8.43 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07744745631933356		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.07744745631933356 | validation: 0.12956507533970954]
	TIME [epoch: 8.41 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08323099603840309		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.08323099603840309 | validation: 0.13775054666070694]
	TIME [epoch: 8.41 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07617937687926539		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.07617937687926539 | validation: 0.10615654702203728]
	TIME [epoch: 8.41 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06679318825216285		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.06679318825216285 | validation: 0.10519459511220702]
	TIME [epoch: 8.43 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07016779311600516		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.07016779311600516 | validation: 0.11170948712754142]
	TIME [epoch: 8.41 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07513705267565066		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.07513705267565066 | validation: 0.11972493968260314]
	TIME [epoch: 8.4 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08179997079599424		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.08179997079599424 | validation: 0.1096834135357593]
	TIME [epoch: 8.4 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07804648241152254		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.07804648241152254 | validation: 0.09878797125279112]
	TIME [epoch: 8.43 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07333350564199194		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.07333350564199194 | validation: 0.09737808035629586]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1314.pth
	Model improved!!!
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677917501409433		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.0677917501409433 | validation: 0.11174477599597338]
	TIME [epoch: 8.42 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07792601250082358		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.07792601250082358 | validation: 0.11049772571295995]
	TIME [epoch: 8.41 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07662532097000525		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.07662532097000525 | validation: 0.11487115224397579]
	TIME [epoch: 8.44 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07376207764627916		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.07376207764627916 | validation: 0.11288863015843925]
	TIME [epoch: 8.41 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08139210133162908		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.08139210133162908 | validation: 0.11530269274130153]
	TIME [epoch: 8.42 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07953067891723671		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.07953067891723671 | validation: 0.11909728383503757]
	TIME [epoch: 8.42 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0764528741614912		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.0764528741614912 | validation: 0.10586685758408909]
	TIME [epoch: 8.44 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719733703888196		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.0719733703888196 | validation: 0.11498248808658897]
	TIME [epoch: 8.42 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08034505777361524		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.08034505777361524 | validation: 0.1444039554056596]
	TIME [epoch: 8.42 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0809434149802962		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.0809434149802962 | validation: 0.11346701810194179]
	TIME [epoch: 8.42 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08121863337910486		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.08121863337910486 | validation: 0.12720554326790875]
	TIME [epoch: 8.43 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09489930954949585		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.09489930954949585 | validation: 0.10377195483023036]
	TIME [epoch: 8.41 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08645647113377013		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.08645647113377013 | validation: 0.11319555488518383]
	TIME [epoch: 8.41 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09099137739267484		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.09099137739267484 | validation: 0.1270618296504158]
	TIME [epoch: 8.42 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1281534198856809		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.1281534198856809 | validation: 0.16344834085152452]
	TIME [epoch: 8.43 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17210884657820952		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.17210884657820952 | validation: 0.11327288533281868]
	TIME [epoch: 8.41 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12253285845469637		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.12253285845469637 | validation: 0.10694338448746249]
	TIME [epoch: 8.41 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09473135347909464		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.09473135347909464 | validation: 0.11725002613702293]
	TIME [epoch: 8.43 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09613036804604343		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.09613036804604343 | validation: 0.11581234161468101]
	TIME [epoch: 8.43 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08143237049567983		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.08143237049567983 | validation: 0.11203645191801902]
	TIME [epoch: 8.43 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07963091521720415		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.07963091521720415 | validation: 0.11529775986765971]
	TIME [epoch: 8.42 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07620702477526804		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.07620702477526804 | validation: 0.10985928244718368]
	TIME [epoch: 8.42 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08410128470128363		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.08410128470128363 | validation: 0.10670058919752681]
	TIME [epoch: 8.43 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07120616414167541		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.07120616414167541 | validation: 0.10821293521097758]
	TIME [epoch: 8.42 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07281533992052523		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.07281533992052523 | validation: 0.11426561487901798]
	TIME [epoch: 8.42 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0810858595514805		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.0810858595514805 | validation: 0.11503977157593445]
	TIME [epoch: 8.42 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09518101492203047		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.09518101492203047 | validation: 0.11363184166423468]
	TIME [epoch: 8.43 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07964147603848928		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.07964147603848928 | validation: 0.10593771458507378]
	TIME [epoch: 8.42 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.075821836572794		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.075821836572794 | validation: 0.13090798769598244]
	TIME [epoch: 8.41 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0741810752590432		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.0741810752590432 | validation: 0.11211856653935423]
	TIME [epoch: 8.44 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0773206852517507		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.0773206852517507 | validation: 0.12131782819284978]
	TIME [epoch: 8.43 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08334145039959394		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.08334145039959394 | validation: 0.11162417007103623]
	TIME [epoch: 8.42 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07890417496011022		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.07890417496011022 | validation: 0.10741364298738956]
	TIME [epoch: 8.43 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0792314254164856		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.0792314254164856 | validation: 0.1056931797018569]
	TIME [epoch: 8.45 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07389980260937899		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.07389980260937899 | validation: 0.11561689130659195]
	TIME [epoch: 8.43 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676280531544253		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.0676280531544253 | validation: 0.1013242322139196]
	TIME [epoch: 8.42 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10634774578697417		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.10634774578697417 | validation: 0.10268003754688179]
	TIME [epoch: 8.42 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11034462073169733		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.11034462073169733 | validation: 0.12200409449233435]
	TIME [epoch: 8.44 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11820452014879593		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.11820452014879593 | validation: 0.11013541656604645]
	TIME [epoch: 8.43 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07624863479100423		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.07624863479100423 | validation: 0.12696687528467723]
	TIME [epoch: 8.43 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07287970041991125		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.07287970041991125 | validation: 0.09735219725081229]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1355.pth
	Model improved!!!
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08415690192454237		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.08415690192454237 | validation: 0.1071673331550795]
	TIME [epoch: 8.44 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08073796638126932		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.08073796638126932 | validation: 0.09891810249281045]
	TIME [epoch: 8.42 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08018578216489644		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.08018578216489644 | validation: 0.10955653277306487]
	TIME [epoch: 8.42 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07381429204904469		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.07381429204904469 | validation: 0.11190869459984752]
	TIME [epoch: 8.42 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07816781525894675		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.07816781525894675 | validation: 0.114122129771866]
	TIME [epoch: 8.44 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07509837369910069		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.07509837369910069 | validation: 0.10505980023104863]
	TIME [epoch: 8.42 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07310587131420469		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.07310587131420469 | validation: 0.09572444879974056]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1362.pth
	Model improved!!!
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07191864072032231		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.07191864072032231 | validation: 0.11207899960520865]
	TIME [epoch: 8.41 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07358942906753477		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.07358942906753477 | validation: 0.10076451601506406]
	TIME [epoch: 8.44 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07167042919832574		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.07167042919832574 | validation: 0.11840813244048182]
	TIME [epoch: 8.42 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07005494863879154		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.07005494863879154 | validation: 0.10034253667890022]
	TIME [epoch: 8.42 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07405285125346969		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.07405285125346969 | validation: 0.10038197907874627]
	TIME [epoch: 8.41 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07124904165089715		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.07124904165089715 | validation: 0.09513503783951846]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1368.pth
	Model improved!!!
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07196380410035971		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.07196380410035971 | validation: 0.10805281373638452]
	TIME [epoch: 8.41 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07551588426799029		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.07551588426799029 | validation: 0.11215039684828251]
	TIME [epoch: 8.42 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07507942161682288		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.07507942161682288 | validation: 0.113863857528221]
	TIME [epoch: 8.41 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08113635958966556		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.08113635958966556 | validation: 0.11439036721448301]
	TIME [epoch: 8.44 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07166887073840297		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.07166887073840297 | validation: 0.1049314641417085]
	TIME [epoch: 8.41 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07619126438790307		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.07619126438790307 | validation: 0.11182109730688503]
	TIME [epoch: 8.42 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07490343582375278		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.07490343582375278 | validation: 0.1123218972675252]
	TIME [epoch: 8.42 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07765192954070152		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.07765192954070152 | validation: 0.10270437535081131]
	TIME [epoch: 8.43 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07898329681209094		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.07898329681209094 | validation: 0.11144742939811131]
	TIME [epoch: 8.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868657710870894		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.06868657710870894 | validation: 0.11137831342794413]
	TIME [epoch: 8.41 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07683317843210692		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.07683317843210692 | validation: 0.11192061476134668]
	TIME [epoch: 8.42 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09716684587370032		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.09716684587370032 | validation: 0.1113219439742626]
	TIME [epoch: 8.42 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07922322947517893		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.07922322947517893 | validation: 0.10410604068796711]
	TIME [epoch: 8.42 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07317489809663642		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.07317489809663642 | validation: 0.11267909246774956]
	TIME [epoch: 8.41 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07333678546114575		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.07333678546114575 | validation: 0.10948938997230392]
	TIME [epoch: 8.42 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07281252770218871		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.07281252770218871 | validation: 0.10154208242657328]
	TIME [epoch: 8.43 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08292960537062896		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.08292960537062896 | validation: 0.10342202777210688]
	TIME [epoch: 8.42 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08556232885183998		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.08556232885183998 | validation: 0.1334202060912036]
	TIME [epoch: 8.41 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13157301228431023		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.13157301228431023 | validation: 0.12420671969861877]
	TIME [epoch: 8.42 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09986689369236204		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.09986689369236204 | validation: 0.11703706686607498]
	TIME [epoch: 8.42 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08027148029440477		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.08027148029440477 | validation: 0.10584996088680823]
	TIME [epoch: 8.41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07883202936523673		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.07883202936523673 | validation: 0.10987694402277443]
	TIME [epoch: 8.41 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775083756801109		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.0775083756801109 | validation: 0.10274192391130246]
	TIME [epoch: 8.43 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07279975734644259		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.07279975734644259 | validation: 0.10659650670904791]
	TIME [epoch: 8.41 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06769786996087684		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.06769786996087684 | validation: 0.11426592746237288]
	TIME [epoch: 8.41 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08065773751033857		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.08065773751033857 | validation: 0.10353387380991605]
	TIME [epoch: 8.41 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672282715299241		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.0672282715299241 | validation: 0.11159784010350829]
	TIME [epoch: 8.44 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07230781789978027		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.07230781789978027 | validation: 0.10168619403944035]
	TIME [epoch: 8.41 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07460414784275166		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.07460414784275166 | validation: 0.11253818945309557]
	TIME [epoch: 8.42 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07490756339238448		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.07490756339238448 | validation: 0.10983464846914065]
	TIME [epoch: 8.41 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0751312613736536		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.0751312613736536 | validation: 0.10109057391767615]
	TIME [epoch: 8.44 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08157943272700874		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.08157943272700874 | validation: 0.12646949220718187]
	TIME [epoch: 8.42 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07308765503376626		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.07308765503376626 | validation: 0.10456522732181778]
	TIME [epoch: 8.42 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07235048084011952		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.07235048084011952 | validation: 0.1123501175527993]
	TIME [epoch: 8.42 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07439150868444164		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.07439150868444164 | validation: 0.10405670539462727]
	TIME [epoch: 8.44 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07210459460007543		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.07210459460007543 | validation: 0.0983387476517851]
	TIME [epoch: 8.42 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07165430426251686		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.07165430426251686 | validation: 0.10586147406385195]
	TIME [epoch: 8.42 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07540125638810713		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.07540125638810713 | validation: 0.1054235056231092]
	TIME [epoch: 8.42 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07043480695068417		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.07043480695068417 | validation: 0.11229043274915582]
	TIME [epoch: 8.43 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07901710581140595		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.07901710581140595 | validation: 0.1143112718931614]
	TIME [epoch: 8.42 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08137913255502247		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.08137913255502247 | validation: 0.11061187775729706]
	TIME [epoch: 8.42 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07821449303785179		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.07821449303785179 | validation: 0.10935862906886333]
	TIME [epoch: 8.42 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06899531442344328		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.06899531442344328 | validation: 0.1105287095175321]
	TIME [epoch: 8.44 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07340747487416086		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.07340747487416086 | validation: 0.1148157346180348]
	TIME [epoch: 8.42 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053939429500619		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.07053939429500619 | validation: 0.11865891918142482]
	TIME [epoch: 8.42 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830556922542065		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.06830556922542065 | validation: 0.0967726449339425]
	TIME [epoch: 8.42 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07257762296933482		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.07257762296933482 | validation: 0.10940542325998012]
	TIME [epoch: 8.44 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07116543138689813		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.07116543138689813 | validation: 0.11620865557992352]
	TIME [epoch: 8.43 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0733491242482335		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.0733491242482335 | validation: 0.11101139464590164]
	TIME [epoch: 8.42 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06765911267527697		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.06765911267527697 | validation: 0.10924720765521587]
	TIME [epoch: 8.42 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09778282011735788		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.09778282011735788 | validation: 0.11457807922728377]
	TIME [epoch: 8.44 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08340403832193959		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.08340403832193959 | validation: 0.10920257958082843]
	TIME [epoch: 8.42 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07083664422522826		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.07083664422522826 | validation: 0.10254411628000826]
	TIME [epoch: 8.42 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07391302807248738		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.07391302807248738 | validation: 0.11427162144646082]
	TIME [epoch: 8.42 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0735395791699148		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.0735395791699148 | validation: 0.11371061448605654]
	TIME [epoch: 8.44 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07690542944697565		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.07690542944697565 | validation: 0.13548451084671814]
	TIME [epoch: 8.41 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07652799125465752		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.07652799125465752 | validation: 0.10607726991977319]
	TIME [epoch: 8.42 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06858122687850031		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.06858122687850031 | validation: 0.10571043661598137]
	TIME [epoch: 8.41 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07425749907867385		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.07425749907867385 | validation: 0.09496987112545485]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1427.pth
	Model improved!!!
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06992808689461485		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.06992808689461485 | validation: 0.10812937360431846]
	TIME [epoch: 8.43 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07145451834101459		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.07145451834101459 | validation: 0.11329114847358235]
	TIME [epoch: 8.42 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07319627103716049		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.07319627103716049 | validation: 0.10627380926057298]
	TIME [epoch: 8.43 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07084464680676765		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.07084464680676765 | validation: 0.10628258013385686]
	TIME [epoch: 8.43 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07363234846513421		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.07363234846513421 | validation: 0.11349062115726052]
	TIME [epoch: 8.42 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749868586465892		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.0749868586465892 | validation: 0.1037281287099513]
	TIME [epoch: 8.42 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431925100282238		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.06431925100282238 | validation: 0.11283680756167318]
	TIME [epoch: 8.43 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0739300435756773		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.0739300435756773 | validation: 0.09515499089489982]
	TIME [epoch: 8.44 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07027728385408802		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.07027728385408802 | validation: 0.10438659645607103]
	TIME [epoch: 8.42 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0740661709515046		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.0740661709515046 | validation: 0.09720310266024249]
	TIME [epoch: 8.42 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077405760691795		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.077405760691795 | validation: 0.09593172068953647]
	TIME [epoch: 8.43 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07137483635538018		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.07137483635538018 | validation: 0.0936185956531583]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1439.pth
	Model improved!!!
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07188944305418928		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.07188944305418928 | validation: 0.10269305847033192]
	TIME [epoch: 8.43 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727624313494666		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.07727624313494666 | validation: 0.11482909240315337]
	TIME [epoch: 8.41 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06484900541155268		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.06484900541155268 | validation: 0.09559341212656206]
	TIME [epoch: 8.42 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0677603182479394		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.0677603182479394 | validation: 0.1054346778315492]
	TIME [epoch: 8.42 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06369052453641452		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.06369052453641452 | validation: 0.11358838847305462]
	TIME [epoch: 8.41 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06867628076088997		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.06867628076088997 | validation: 0.10877304118086419]
	TIME [epoch: 8.41 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06295125517876184		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.06295125517876184 | validation: 0.0996102571137597]
	TIME [epoch: 8.43 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06843011886174702		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.06843011886174702 | validation: 0.10354867385173676]
	TIME [epoch: 8.41 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06950893022575762		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.06950893022575762 | validation: 0.115848902868107]
	TIME [epoch: 8.4 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06887072854972204		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.06887072854972204 | validation: 0.10965439705363252]
	TIME [epoch: 8.41 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0771869657725601		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.0771869657725601 | validation: 0.11065399348048736]
	TIME [epoch: 8.42 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08121813782599809		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.08121813782599809 | validation: 0.11477681365978007]
	TIME [epoch: 8.41 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06994063045762018		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.06994063045762018 | validation: 0.10608812716085575]
	TIME [epoch: 8.41 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723412961327218		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.0723412961327218 | validation: 0.10712841712066395]
	TIME [epoch: 8.41 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07074413157384599		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.07074413157384599 | validation: 0.10880540179312499]
	TIME [epoch: 8.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631538334490262		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.0631538334490262 | validation: 0.10763073097385945]
	TIME [epoch: 8.42 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07436372035823154		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.07436372035823154 | validation: 0.12242553819583654]
	TIME [epoch: 8.41 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07118696755899799		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.07118696755899799 | validation: 0.12017667208659147]
	TIME [epoch: 8.41 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06359731994819923		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.06359731994819923 | validation: 0.10197106431506867]
	TIME [epoch: 8.42 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07164581872006989		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.07164581872006989 | validation: 0.10283148738064893]
	TIME [epoch: 8.41 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06542564594410605		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.06542564594410605 | validation: 0.09148205153998279]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1460.pth
	Model improved!!!
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162462627976038		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.07162462627976038 | validation: 0.10387710433540236]
	TIME [epoch: 8.41 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07202454107047207		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.07202454107047207 | validation: 0.10392884135445452]
	TIME [epoch: 8.43 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0703403143506283		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.0703403143506283 | validation: 0.10411430697323827]
	TIME [epoch: 8.42 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07161900263426066		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.07161900263426066 | validation: 0.10680476061328739]
	TIME [epoch: 8.4 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07263109961358011		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.07263109961358011 | validation: 0.11330912562671144]
	TIME [epoch: 8.41 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.072676852303739		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.072676852303739 | validation: 0.10929697360674553]
	TIME [epoch: 8.43 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06900058837775427		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.06900058837775427 | validation: 0.11185765439441447]
	TIME [epoch: 8.45 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08017289785532802		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.08017289785532802 | validation: 0.11731720521846346]
	TIME [epoch: 8.43 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.079710379872719		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.079710379872719 | validation: 0.10822988598267101]
	TIME [epoch: 8.41 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0639955309040173		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.0639955309040173 | validation: 0.1048711266055787]
	TIME [epoch: 8.44 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629511123587854		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.06629511123587854 | validation: 0.10917852073375164]
	TIME [epoch: 8.42 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902822838588		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.06902822838588 | validation: 0.10686978996170349]
	TIME [epoch: 8.42 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07168580608445226		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.07168580608445226 | validation: 0.10093614902072343]
	TIME [epoch: 8.42 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661727169812268		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.0661727169812268 | validation: 0.10977760826823213]
	TIME [epoch: 8.44 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06945867102924286		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.06945867102924286 | validation: 0.11787647670543253]
	TIME [epoch: 8.41 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07620498461449965		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.07620498461449965 | validation: 0.12282907339751206]
	TIME [epoch: 8.41 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08333468577488193		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.08333468577488193 | validation: 0.10917228513125446]
	TIME [epoch: 8.43 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775968676993183		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.0775968676993183 | validation: 0.11096585777806442]
	TIME [epoch: 8.43 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07233812447364611		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.07233812447364611 | validation: 0.10274759152017263]
	TIME [epoch: 8.41 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06523152705465697		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.06523152705465697 | validation: 0.1109072789291577]
	TIME [epoch: 8.41 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056414436239718		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.07056414436239718 | validation: 0.1163200295139605]
	TIME [epoch: 8.42 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06736042579324722		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.06736042579324722 | validation: 0.11426662633758214]
	TIME [epoch: 8.44 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497333478011315		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.06497333478011315 | validation: 0.10657613786951273]
	TIME [epoch: 8.44 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07055663751068637		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.07055663751068637 | validation: 0.10929548737254421]
	TIME [epoch: 8.42 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06508257547667792		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.06508257547667792 | validation: 0.10882118008451727]
	TIME [epoch: 8.44 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07213370623786805		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.07213370623786805 | validation: 0.12097466076751143]
	TIME [epoch: 8.42 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06782327073690228		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.06782327073690228 | validation: 0.0982491415178692]
	TIME [epoch: 8.41 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06989836033432618		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.06989836033432618 | validation: 0.11155583050497941]
	TIME [epoch: 8.41 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07089835554557461		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.07089835554557461 | validation: 0.10564776824598376]
	TIME [epoch: 8.43 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06951154055656389		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.06951154055656389 | validation: 0.10235000284210928]
	TIME [epoch: 8.44 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06799776161073705		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.06799776161073705 | validation: 0.11418908093813829]
	TIME [epoch: 8.42 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06954730036935393		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.06954730036935393 | validation: 0.10366850118602718]
	TIME [epoch: 8.42 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127028094111278		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.07127028094111278 | validation: 0.11692233499146135]
	TIME [epoch: 8.41 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06682051794338434		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.06682051794338434 | validation: 0.09799970590161239]
	TIME [epoch: 8.42 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07191383394156123		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.07191383394156123 | validation: 0.1090905459236984]
	TIME [epoch: 8.41 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07312948362903422		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.07312948362903422 | validation: 0.10667937732884142]
	TIME [epoch: 8.41 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07494935481073084		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.07494935481073084 | validation: 0.11452903799979836]
	TIME [epoch: 8.42 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06921238417656825		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.06921238417656825 | validation: 0.12070902925059948]
	TIME [epoch: 8.42 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07271123792242257		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.07271123792242257 | validation: 0.11043766365804902]
	TIME [epoch: 8.41 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701282248602118		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.07701282248602118 | validation: 0.12765541851745352]
	TIME [epoch: 8.42 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08011122344826524		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.08011122344826524 | validation: 0.10899578864201581]
	TIME [epoch: 8.43 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07438441981274382		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.07438441981274382 | validation: 0.1138248405207066]
	TIME [epoch: 8.42 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07074885966038183		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.07074885966038183 | validation: 0.11989077812793225]
	TIME [epoch: 8.42 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0694976159547718		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.0694976159547718 | validation: 0.10515123822848153]
	TIME [epoch: 8.42 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06985434473341137		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.06985434473341137 | validation: 0.10449809896860447]
	TIME [epoch: 8.44 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07005092982031379		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.07005092982031379 | validation: 0.10534493194239222]
	TIME [epoch: 8.42 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747257137944013		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.06747257137944013 | validation: 0.10455872108753095]
	TIME [epoch: 8.42 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705347384636019		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.0705347384636019 | validation: 0.11940864625682662]
	TIME [epoch: 8.41 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0660336179782268		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.0660336179782268 | validation: 0.10733339403246932]
	TIME [epoch: 8.42 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06730590354667403		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.06730590354667403 | validation: 0.1015078494056927]
	TIME [epoch: 8.41 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06635718425665292		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.06635718425665292 | validation: 0.10538136966945533]
	TIME [epoch: 8.41 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06607748002297018		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.06607748002297018 | validation: 0.11855484273959924]
	TIME [epoch: 8.4 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0742358634032484		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.0742358634032484 | validation: 0.10183884976137167]
	TIME [epoch: 8.44 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06538895195509008		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.06538895195509008 | validation: 0.10065315678037214]
	TIME [epoch: 8.43 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06872921725382365		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.06872921725382365 | validation: 0.10533791381815787]
	TIME [epoch: 8.42 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682419121142206		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.0682419121142206 | validation: 0.10823528029795507]
	TIME [epoch: 8.42 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724080256315679		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.06724080256315679 | validation: 0.1018072402765606]
	TIME [epoch: 8.44 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06945791880482596		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.06945791880482596 | validation: 0.10353733076803753]
	TIME [epoch: 8.41 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07988653024666972		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.07988653024666972 | validation: 0.11585623214080984]
	TIME [epoch: 8.41 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905643361481033		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.06905643361481033 | validation: 0.0974423227015534]
	TIME [epoch: 8.4 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07048128264051612		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.07048128264051612 | validation: 0.11933814160538038]
	TIME [epoch: 8.43 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868567445532445		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.06868567445532445 | validation: 0.11774267589217581]
	TIME [epoch: 8.4 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06931010456321614		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.06931010456321614 | validation: 0.11314890820865453]
	TIME [epoch: 8.41 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06764844041340111		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.06764844041340111 | validation: 0.1026307507672031]
	TIME [epoch: 8.41 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0673376327458308		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.0673376327458308 | validation: 0.11369623047238321]
	TIME [epoch: 8.42 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688125079680518		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.07688125079680518 | validation: 0.1104534501298702]
	TIME [epoch: 8.41 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661029954980054		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.0661029954980054 | validation: 0.10325527071331683]
	TIME [epoch: 8.4 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747319315444		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.06747319315444 | validation: 0.10539577349923183]
	TIME [epoch: 8.41 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061986655423018455		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.061986655423018455 | validation: 0.11762207003203992]
	TIME [epoch: 8.43 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06590191740870333		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.06590191740870333 | validation: 0.11279166169680035]
	TIME [epoch: 8.41 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06912696904303181		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.06912696904303181 | validation: 0.10408040750170575]
	TIME [epoch: 8.42 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06661038719646657		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.06661038719646657 | validation: 0.09652716204096692]
	TIME [epoch: 8.4 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632041639308418		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.06632041639308418 | validation: 0.09740984284482587]
	TIME [epoch: 8.42 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719861549784582		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.0719861549784582 | validation: 0.11178353558214431]
	TIME [epoch: 8.41 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06959347963658248		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.06959347963658248 | validation: 0.11476174688891422]
	TIME [epoch: 8.4 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651056991202707		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.06651056991202707 | validation: 0.1171654021563183]
	TIME [epoch: 8.41 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06655514875561666		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.06655514875561666 | validation: 0.10549152188045816]
	TIME [epoch: 8.43 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06893502183029747		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.06893502183029747 | validation: 0.10871435040247944]
	TIME [epoch: 8.4 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07304213445074467		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.07304213445074467 | validation: 0.09278383554756595]
	TIME [epoch: 8.42 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07701089147996314		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.07701089147996314 | validation: 0.11421206012775707]
	TIME [epoch: 8.41 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07031171257007708		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.07031171257007708 | validation: 0.10503455459874703]
	TIME [epoch: 8.43 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723599473509958		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.0723599473509958 | validation: 0.09918797007101614]
	TIME [epoch: 8.41 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06733009107075581		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.06733009107075581 | validation: 0.10265756312439447]
	TIME [epoch: 8.41 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183939725844432		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.07183939725844432 | validation: 0.11296062072545644]
	TIME [epoch: 8.44 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07162793267628223		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.07162793267628223 | validation: 0.1213344942814282]
	TIME [epoch: 8.43 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06791741155160652		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.06791741155160652 | validation: 0.10848912110760024]
	TIME [epoch: 8.41 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07539694011982816		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.07539694011982816 | validation: 0.11989964425910105]
	TIME [epoch: 8.42 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135262294951142		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.07135262294951142 | validation: 0.1104495372369767]
	TIME [epoch: 8.43 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06982230162717586		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.06982230162717586 | validation: 0.09897508907103517]
	TIME [epoch: 8.42 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07238810814161886		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.07238810814161886 | validation: 0.10553441770437795]
	TIME [epoch: 8.42 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06623093110645455		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.06623093110645455 | validation: 0.10129246796680522]
	TIME [epoch: 8.42 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06615333720463011		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.06615333720463011 | validation: 0.10635685426949451]
	TIME [epoch: 8.43 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06981642078788693		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.06981642078788693 | validation: 0.11279341525419667]
	TIME [epoch: 8.43 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08681079734609584		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.08681079734609584 | validation: 0.101490204893169]
	TIME [epoch: 8.42 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07069594249107422		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.07069594249107422 | validation: 0.11232286783245432]
	TIME [epoch: 8.43 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936303962556709		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.06936303962556709 | validation: 0.11327648330083755]
	TIME [epoch: 8.44 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783922983505904		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.06783922983505904 | validation: 0.11759434120009238]
	TIME [epoch: 8.42 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06808909857724658		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.06808909857724658 | validation: 0.10217330784765055]
	TIME [epoch: 8.41 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066003048085969		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.066003048085969 | validation: 0.10855659894436617]
	TIME [epoch: 8.42 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06771124694768076		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.06771124694768076 | validation: 0.1232960125655557]
	TIME [epoch: 8.43 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0656391871081277		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.0656391871081277 | validation: 0.11300923087831669]
	TIME [epoch: 8.42 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06688796618957825		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.06688796618957825 | validation: 0.11055195018935983]
	TIME [epoch: 8.42 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07323699945127801		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.07323699945127801 | validation: 0.09984539874567744]
	TIME [epoch: 8.41 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06580509204642683		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.06580509204642683 | validation: 0.10021072471317403]
	TIME [epoch: 8.43 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06672357806086938		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.06672357806086938 | validation: 0.09631435458406701]
	TIME [epoch: 8.41 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06696362883778657		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.06696362883778657 | validation: 0.10439795244450414]
	TIME [epoch: 8.42 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06601812905536311		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.06601812905536311 | validation: 0.1054176760411106]
	TIME [epoch: 8.42 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06751339181017418		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.06751339181017418 | validation: 0.11003788618421259]
	TIME [epoch: 8.44 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07349558797348175		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.07349558797348175 | validation: 0.09900494246270485]
	TIME [epoch: 8.43 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183641576284341		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.07183641576284341 | validation: 0.10498236806906115]
	TIME [epoch: 8.42 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599749644866557		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.07599749644866557 | validation: 0.11012727167050133]
	TIME [epoch: 8.43 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07320123026471963		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.07320123026471963 | validation: 0.10955428922241944]
	TIME [epoch: 8.43 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06455343615030662		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.06455343615030662 | validation: 0.10457003804122489]
	TIME [epoch: 8.42 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07040563025077622		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.07040563025077622 | validation: 0.11121038238380926]
	TIME [epoch: 8.42 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07215597377975505		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.07215597377975505 | validation: 0.10330687489841789]
	TIME [epoch: 8.41 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06350987768203424		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.06350987768203424 | validation: 0.10076715277639868]
	TIME [epoch: 8.44 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434046642234643		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.06434046642234643 | validation: 0.10269137285817061]
	TIME [epoch: 8.42 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06984313888072805		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.06984313888072805 | validation: 0.11037426650455998]
	TIME [epoch: 8.42 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07313973324038517		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.07313973324038517 | validation: 0.1277503881651047]
	TIME [epoch: 8.42 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08134277251756704		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.08134277251756704 | validation: 0.1254887829427026]
	TIME [epoch: 8.45 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07509139501703288		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.07509139501703288 | validation: 0.11762044550367856]
	TIME [epoch: 8.42 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06464703866420281		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.06464703866420281 | validation: 0.10823299636807426]
	TIME [epoch: 8.42 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07103752571102416		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.07103752571102416 | validation: 0.108407246857367]
	TIME [epoch: 8.42 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06789053921511261		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.06789053921511261 | validation: 0.11034214152691804]
	TIME [epoch: 8.44 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0704278296088332		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.0704278296088332 | validation: 0.10313919336001322]
	TIME [epoch: 8.42 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300460984275561		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.07300460984275561 | validation: 0.1156196789850517]
	TIME [epoch: 8.41 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07505788707343544		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.07505788707343544 | validation: 0.10911597535565093]
	TIME [epoch: 8.42 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06754313836902738		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.06754313836902738 | validation: 0.10288191306931066]
	TIME [epoch: 8.44 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07127045200572522		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.07127045200572522 | validation: 0.09651360868886966]
	TIME [epoch: 8.42 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06195013911556031		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.06195013911556031 | validation: 0.10084268681547444]
	TIME [epoch: 8.42 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07149673696695699		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.07149673696695699 | validation: 0.1178148680715052]
	TIME [epoch: 8.41 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06592914271723996		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.06592914271723996 | validation: 0.10415247624428536]
	TIME [epoch: 8.45 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06402145595267805		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.06402145595267805 | validation: 0.10546589334558687]
	TIME [epoch: 8.41 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07111145889909584		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.07111145889909584 | validation: 0.11085328448815984]
	TIME [epoch: 8.41 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07128203760272436		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.07128203760272436 | validation: 0.10188186835264386]
	TIME [epoch: 8.42 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07610471832619625		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.07610471832619625 | validation: 0.10271673217357374]
	TIME [epoch: 8.43 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0702143871019155		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.0702143871019155 | validation: 0.11584002615649049]
	TIME [epoch: 8.43 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0709973930897897		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.0709973930897897 | validation: 0.12328635213095294]
	TIME [epoch: 8.42 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06862450633104929		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.06862450633104929 | validation: 0.10572687161265243]
	TIME [epoch: 8.43 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.065333986776854		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.065333986776854 | validation: 0.10221162498018035]
	TIME [epoch: 8.44 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06868549272095065		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.06868549272095065 | validation: 0.11568366666132437]
	TIME [epoch: 8.43 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06809651836905377		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.06809651836905377 | validation: 0.10849951240777339]
	TIME [epoch: 8.41 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07166614384460422		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.07166614384460422 | validation: 0.1041843398273148]
	TIME [epoch: 8.43 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06714195070425732		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.06714195070425732 | validation: 0.11082078044341773]
	TIME [epoch: 8.42 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277477603729503		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.07277477603729503 | validation: 0.09078443591652985]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1605.pth
	Model improved!!!
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06765999695145067		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.06765999695145067 | validation: 0.10773751343199903]
	TIME [epoch: 8.43 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0668626323939381		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.0668626323939381 | validation: 0.11182119405652657]
	TIME [epoch: 8.45 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0752079869900159		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.0752079869900159 | validation: 0.11957260311527793]
	TIME [epoch: 8.43 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07478658360098352		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.07478658360098352 | validation: 0.10931756890089397]
	TIME [epoch: 8.42 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08374720455266979		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.08374720455266979 | validation: 0.09950957348926066]
	TIME [epoch: 8.42 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07336613224956366		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.07336613224956366 | validation: 0.11252146845943017]
	TIME [epoch: 8.44 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06769597551836248		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.06769597551836248 | validation: 0.11238534756664258]
	TIME [epoch: 8.43 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07241156572911654		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.07241156572911654 | validation: 0.1061209616094169]
	TIME [epoch: 8.42 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07761313853519516		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.07761313853519516 | validation: 0.10095995431738186]
	TIME [epoch: 8.43 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07007689184559927		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.07007689184559927 | validation: 0.10446190119055829]
	TIME [epoch: 8.45 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06996737454484814		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.06996737454484814 | validation: 0.10982726818975079]
	TIME [epoch: 8.43 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07032172615565804		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.07032172615565804 | validation: 0.10834234318876027]
	TIME [epoch: 8.43 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06680162716687738		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.06680162716687738 | validation: 0.10390644868001145]
	TIME [epoch: 8.43 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06824910846947199		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.06824910846947199 | validation: 0.10895338074324032]
	TIME [epoch: 8.44 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06780590351170938		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.06780590351170938 | validation: 0.11440184528654342]
	TIME [epoch: 8.44 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07369272872261849		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.07369272872261849 | validation: 0.10998866006587554]
	TIME [epoch: 8.42 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06208308182134882		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.06208308182134882 | validation: 0.0992097023209496]
	TIME [epoch: 8.43 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0675044449737622		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.0675044449737622 | validation: 0.10241150861687275]
	TIME [epoch: 8.44 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06602372581097063		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.06602372581097063 | validation: 0.09445533044910334]
	TIME [epoch: 8.43 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339098579404581		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.06339098579404581 | validation: 0.09410728811602792]
	TIME [epoch: 8.43 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834332216277088		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.06834332216277088 | validation: 0.1026386045151261]
	TIME [epoch: 8.43 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0698075817119096		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.0698075817119096 | validation: 0.10572241913311832]
	TIME [epoch: 8.45 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07133806505398957		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.07133806505398957 | validation: 0.09435364115512837]
	TIME [epoch: 8.43 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07597282182616893		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.07597282182616893 | validation: 0.1163960344899606]
	TIME [epoch: 8.42 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07730496244254631		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.07730496244254631 | validation: 0.089419792091002]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1630.pth
	Model improved!!!
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07553336015657343		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.07553336015657343 | validation: 0.10411477459538644]
	TIME [epoch: 8.43 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08611218995536639		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.08611218995536639 | validation: 0.1228400395655797]
	TIME [epoch: 8.41 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08450038121195089		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.08450038121195089 | validation: 0.11018240053122019]
	TIME [epoch: 8.4 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07553290049810898		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.07553290049810898 | validation: 0.09631024072691763]
	TIME [epoch: 8.41 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06842428623364553		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.06842428623364553 | validation: 0.1216933624053115]
	TIME [epoch: 8.43 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06623894141013432		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.06623894141013432 | validation: 0.11259209110490842]
	TIME [epoch: 8.41 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07271597534044243		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.07271597534044243 | validation: 0.10543494390343841]
	TIME [epoch: 8.41 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707965176264688		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.06707965176264688 | validation: 0.11653300526364449]
	TIME [epoch: 8.41 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0681188078607439		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.0681188078607439 | validation: 0.09872048080179674]
	TIME [epoch: 8.43 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.065669788781439		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.065669788781439 | validation: 0.10736483366822824]
	TIME [epoch: 8.41 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0700199004221854		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.0700199004221854 | validation: 0.1078400461428222]
	TIME [epoch: 8.41 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07117117607325503		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.07117117607325503 | validation: 0.09999227579478617]
	TIME [epoch: 8.41 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555895678117027		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.06555895678117027 | validation: 0.11432535548269958]
	TIME [epoch: 8.43 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06660778194199704		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.06660778194199704 | validation: 0.09201652844447208]
	TIME [epoch: 8.4 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06925439864073991		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.06925439864073991 | validation: 0.10714614790252111]
	TIME [epoch: 8.41 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06871673446539801		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.06871673446539801 | validation: 0.11369733903818637]
	TIME [epoch: 8.41 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0699142173954593		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.0699142173954593 | validation: 0.11003504586087831]
	TIME [epoch: 8.42 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06522794219490818		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.06522794219490818 | validation: 0.10839753999729516]
	TIME [epoch: 8.41 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06828695035677881		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.06828695035677881 | validation: 0.09959253039564056]
	TIME [epoch: 8.41 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07242512060170526		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.07242512060170526 | validation: 0.09527773134967396]
	TIME [epoch: 8.41 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06967767201652685		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.06967767201652685 | validation: 0.10230834869897903]
	TIME [epoch: 8.42 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07078584584814102		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.07078584584814102 | validation: 0.10152015805338348]
	TIME [epoch: 8.41 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07177654505441967		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.07177654505441967 | validation: 0.10199913046766582]
	TIME [epoch: 8.4 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06710019738823876		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.06710019738823876 | validation: 0.10095854855770697]
	TIME [epoch: 8.42 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06613060801647183		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.06613060801647183 | validation: 0.09841763394319547]
	TIME [epoch: 8.42 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770656631725787		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.06770656631725787 | validation: 0.1090820425691863]
	TIME [epoch: 8.41 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0696806960695726		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.0696806960695726 | validation: 0.10737936152728872]
	TIME [epoch: 8.41 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0675308260419209		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.0675308260419209 | validation: 0.10584940345031729]
	TIME [epoch: 8.42 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06855343943467132		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.06855343943467132 | validation: 0.10884449887913306]
	TIME [epoch: 8.42 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999689682344512		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.06999689682344512 | validation: 0.10283139502776667]
	TIME [epoch: 8.41 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06443549825229326		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.06443549825229326 | validation: 0.10491470986785692]
	TIME [epoch: 8.41 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06701781740507626		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.06701781740507626 | validation: 0.09562322752928332]
	TIME [epoch: 8.43 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06773960891672924		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.06773960891672924 | validation: 0.08822993554611569]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240219_202301/states/model_tr_study204_1663.pth
	Model improved!!!
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06260544993504266		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.06260544993504266 | validation: 0.10731160298260857]
	TIME [epoch: 8.42 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902221054366925		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.06902221054366925 | validation: 0.10332375265462596]
	TIME [epoch: 8.42 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663089088594378		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.0663089088594378 | validation: 0.1042662000203059]
	TIME [epoch: 8.44 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724664948312178		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.06724664948312178 | validation: 0.10789475691166489]
	TIME [epoch: 8.41 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06412038965745744		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.06412038965745744 | validation: 0.09933565674998929]
	TIME [epoch: 8.41 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06162657492430228		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.06162657492430228 | validation: 0.10427880783256077]
	TIME [epoch: 8.41 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07222868490408856		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.07222868490408856 | validation: 0.10830850769601427]
	TIME [epoch: 8.43 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06654742351707749		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.06654742351707749 | validation: 0.10790875149274236]
	TIME [epoch: 8.41 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06929451748895846		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.06929451748895846 | validation: 0.11627944168788747]
	TIME [epoch: 8.41 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06695482064735124		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.06695482064735124 | validation: 0.10571839798145566]
	TIME [epoch: 8.41 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502231759556801		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.06502231759556801 | validation: 0.1074866211333665]
	TIME [epoch: 8.42 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06421901750957465		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.06421901750957465 | validation: 0.10560073103972623]
	TIME [epoch: 8.42 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06586185605205136		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.06586185605205136 | validation: 0.11195047191783147]
	TIME [epoch: 8.41 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06458645203516733		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.06458645203516733 | validation: 0.10372250776540932]
	TIME [epoch: 8.41 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06801028614625172		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.06801028614625172 | validation: 0.09431786829836497]
	TIME [epoch: 8.42 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06975141049040517		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.06975141049040517 | validation: 0.11087610031671163]
	TIME [epoch: 8.41 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06255918203014067		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.06255918203014067 | validation: 0.10588077567123629]
	TIME [epoch: 8.4 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07213871912979425		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.07213871912979425 | validation: 0.1227818815372573]
	TIME [epoch: 8.4 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06661373398963302		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.06661373398963302 | validation: 0.09940907644609137]
	TIME [epoch: 8.43 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06983422893825228		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.06983422893825228 | validation: 0.09039333506616903]
	TIME [epoch: 8.4 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07098058318711656		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.07098058318711656 | validation: 0.09876496457157857]
	TIME [epoch: 8.4 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07086109604576762		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.07086109604576762 | validation: 0.10263451050235298]
	TIME [epoch: 8.41 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06986224805228498		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.06986224805228498 | validation: 0.10810224097758833]
	TIME [epoch: 8.43 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0705390009909201		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.0705390009909201 | validation: 0.11015149239689284]
	TIME [epoch: 8.41 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06649592964980454		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.06649592964980454 | validation: 0.09975933165393364]
	TIME [epoch: 8.4 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06998547693797391		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.06998547693797391 | validation: 0.09247307956466885]
	TIME [epoch: 8.41 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463912396661163		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.06463912396661163 | validation: 0.09959477220319231]
	TIME [epoch: 8.43 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06792029030507404		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.06792029030507404 | validation: 0.10252332043590218]
	TIME [epoch: 8.41 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629882307996679		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.0629882307996679 | validation: 0.11470179887285581]
	TIME [epoch: 8.39 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06383227382584211		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.06383227382584211 | validation: 0.1034490094983217]
	TIME [epoch: 8.41 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06936024068924085		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.06936024068924085 | validation: 0.09013670952088548]
	TIME [epoch: 8.43 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06613578266903111		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.06613578266903111 | validation: 0.11259641060353662]
	TIME [epoch: 8.41 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0667116409348608		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.0667116409348608 | validation: 0.0996409809200724]
	TIME [epoch: 8.4 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06628019191527612		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.06628019191527612 | validation: 0.0973582986957438]
	TIME [epoch: 8.41 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999058223659432		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.06999058223659432 | validation: 0.11851087439189553]
	TIME [epoch: 8.42 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676294265671786		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.0676294265671786 | validation: 0.10555154020079607]
	TIME [epoch: 8.4 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06837571622250904		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.06837571622250904 | validation: 0.1075962832326886]
	TIME [epoch: 8.4 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06714660896927918		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.06714660896927918 | validation: 0.10466700454753913]
	TIME [epoch: 8.41 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07273244325553332		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.07273244325553332 | validation: 0.1109066516195053]
	TIME [epoch: 8.43 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07090004690392102		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.07090004690392102 | validation: 0.10626818286624659]
	TIME [epoch: 8.41 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06619533958299487		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.06619533958299487 | validation: 0.10843762035423418]
	TIME [epoch: 8.41 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06739442645461621		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.06739442645461621 | validation: 0.10392584806178934]
	TIME [epoch: 8.41 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06915286508547122		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.06915286508547122 | validation: 0.10625562713918216]
	TIME [epoch: 8.42 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408880025706803		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.06408880025706803 | validation: 0.11009155267293069]
	TIME [epoch: 8.41 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06743168025225434		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.06743168025225434 | validation: 0.10279063331013599]
	TIME [epoch: 8.4 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902115103956516		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.06902115103956516 | validation: 0.09611855056551957]
	TIME [epoch: 8.42 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657250364224547		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.0657250364224547 | validation: 0.11248828268486244]
	TIME [epoch: 8.41 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06838071074010034		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.06838071074010034 | validation: 0.10893018254677483]
	TIME [epoch: 8.4 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06565614266937951		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.06565614266937951 | validation: 0.1091324719694188]
	TIME [epoch: 8.4 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062335672096574334		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.062335672096574334 | validation: 0.09766703645539476]
	TIME [epoch: 8.41 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062213535179604984		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.062213535179604984 | validation: 0.09779536134694704]
	TIME [epoch: 8.42 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0668123785238997		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.0668123785238997 | validation: 0.1028285828479746]
	TIME [epoch: 8.41 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06560217030015		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.06560217030015 | validation: 0.09476459366549472]
	TIME [epoch: 8.41 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06635803232335284		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.06635803232335284 | validation: 0.09011600947275016]
	TIME [epoch: 8.42 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06823228688064598		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.06823228688064598 | validation: 0.10320993472888132]
	TIME [epoch: 8.41 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385348523057392		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.06385348523057392 | validation: 0.10776812125555219]
	TIME [epoch: 8.4 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06726933439311802		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.06726933439311802 | validation: 0.10483746215880457]
	TIME [epoch: 8.4 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06917556516331283		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.06917556516331283 | validation: 0.0996870776279701]
	TIME [epoch: 8.42 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344885404103492		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.06344885404103492 | validation: 0.10896648943082718]
	TIME [epoch: 8.41 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648726793097036		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.0648726793097036 | validation: 0.10954634226011982]
	TIME [epoch: 8.4 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06641193583353738		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.06641193583353738 | validation: 0.1042506405469181]
	TIME [epoch: 8.4 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411382546102704		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.06411382546102704 | validation: 0.09554819398115699]
	TIME [epoch: 8.43 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844814146026287		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.06844814146026287 | validation: 0.10397781225346643]
	TIME [epoch: 8.42 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06968393064718617		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.06968393064718617 | validation: 0.11050084714055586]
	TIME [epoch: 8.4 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06472220597435105		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.06472220597435105 | validation: 0.10903093944690832]
	TIME [epoch: 8.41 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06189684546820825		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.06189684546820825 | validation: 0.09866436024802044]
	TIME [epoch: 8.43 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06719907678327061		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.06719907678327061 | validation: 0.10986472011029799]
	TIME [epoch: 8.41 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06397216432742539		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.06397216432742539 | validation: 0.10068645119470668]
	TIME [epoch: 8.4 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06362571716163737		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.06362571716163737 | validation: 0.09854290041071556]
	TIME [epoch: 8.41 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06424402727388094		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.06424402727388094 | validation: 0.09126359648558988]
	TIME [epoch: 8.42 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0613686160511334		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.0613686160511334 | validation: 0.09525392659837639]
	TIME [epoch: 8.41 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06684863761203609		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.06684863761203609 | validation: 0.10656932248195197]
	TIME [epoch: 8.41 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06794509044832879		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.06794509044832879 | validation: 0.10380346066132892]
	TIME [epoch: 8.4 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06284568022933636		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.06284568022933636 | validation: 0.1047454014277784]
	TIME [epoch: 8.42 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07204787894381304		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.07204787894381304 | validation: 0.10362166436133508]
	TIME [epoch: 8.4 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06373762019309735		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.06373762019309735 | validation: 0.11767721003862142]
	TIME [epoch: 8.41 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0697093891357072		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.0697093891357072 | validation: 0.10078336748233635]
	TIME [epoch: 8.41 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06523408606969003		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.06523408606969003 | validation: 0.09755471449449565]
	TIME [epoch: 8.43 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06395469112583553		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.06395469112583553 | validation: 0.105571581413282]
	TIME [epoch: 8.4 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06783742631004487		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.06783742631004487 | validation: 0.0984610640160178]
	TIME [epoch: 8.4 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06457805222197732		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.06457805222197732 | validation: 0.10575710434338875]
	TIME [epoch: 8.41 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061575841899612425		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.061575841899612425 | validation: 0.10368340500796466]
	TIME [epoch: 8.42 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06276234657885339		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.06276234657885339 | validation: 0.10675661053421229]
	TIME [epoch: 8.41 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06687394373980858		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.06687394373980858 | validation: 0.10562879549176325]
	TIME [epoch: 8.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339116117725056		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.06339116117725056 | validation: 0.10797864284379526]
	TIME [epoch: 8.4 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06621895298725607		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.06621895298725607 | validation: 0.11329837292505782]
	TIME [epoch: 8.42 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502633080282356		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.06502633080282356 | validation: 0.11866061927480341]
	TIME [epoch: 8.41 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06563024994349154		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.06563024994349154 | validation: 0.09250901784397692]
	TIME [epoch: 8.41 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06255446957897373		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.06255446957897373 | validation: 0.10050227765622904]
	TIME [epoch: 8.41 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06480296785637293		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.06480296785637293 | validation: 0.10232477542852184]
	TIME [epoch: 8.43 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408130099293577		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.06408130099293577 | validation: 0.10051628627703897]
	TIME [epoch: 8.41 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06973071323945064		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.06973071323945064 | validation: 0.10237612248320196]
	TIME [epoch: 8.4 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719970221267959		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.0719970221267959 | validation: 0.10323398322790481]
	TIME [epoch: 8.41 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06820933503126919		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.06820933503126919 | validation: 0.10969502830059732]
	TIME [epoch: 8.42 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07053441684337018		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.07053441684337018 | validation: 0.10263756724375533]
	TIME [epoch: 8.4 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06548003506199845		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.06548003506199845 | validation: 0.09991114516638896]
	TIME [epoch: 8.4 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06265267224453981		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.06265267224453981 | validation: 0.08907462961165827]
	TIME [epoch: 8.41 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06716927149242427		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.06716927149242427 | validation: 0.1012678618962804]
	TIME [epoch: 8.42 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06552752340611959		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.06552752340611959 | validation: 0.09427248641881594]
	TIME [epoch: 8.42 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06587398277899424		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.06587398277899424 | validation: 0.09651622614730013]
	TIME [epoch: 8.41 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06644067800959455		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.06644067800959455 | validation: 0.10230208982085438]
	TIME [epoch: 8.42 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061539742962507846		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.061539742962507846 | validation: 0.09819287875933982]
	TIME [epoch: 8.42 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657914018939589		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.0657914018939589 | validation: 0.11058124959545598]
	TIME [epoch: 8.41 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662981777606514		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.0662981777606514 | validation: 0.1043683118032471]
	TIME [epoch: 8.42 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06705745790560688		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.06705745790560688 | validation: 0.11349386964259832]
	TIME [epoch: 8.42 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07159327419615098		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.07159327419615098 | validation: 0.11584806112984039]
	TIME [epoch: 8.42 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0696281774533071		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.0696281774533071 | validation: 0.10200140925164078]
	TIME [epoch: 8.41 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857374229236934		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.06857374229236934 | validation: 0.09793106872940846]
	TIME [epoch: 8.42 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643538325524725		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.06643538325524725 | validation: 0.10518563476959328]
	TIME [epoch: 8.42 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06282474555401471		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.06282474555401471 | validation: 0.10100995241579297]
	TIME [epoch: 8.43 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06260237595962784		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.06260237595962784 | validation: 0.10502974309301583]
	TIME [epoch: 8.41 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494312474823917		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.06494312474823917 | validation: 0.11461649806603386]
	TIME [epoch: 8.41 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06671236179805147		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.06671236179805147 | validation: 0.11001417668514027]
	TIME [epoch: 8.42 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07078746205131546		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.07078746205131546 | validation: 0.09955956151414516]
	TIME [epoch: 8.45 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06711437868145956		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.06711437868145956 | validation: 0.10058553554076288]
	TIME [epoch: 8.41 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07035912880710159		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.07035912880710159 | validation: 0.10786423636139959]
	TIME [epoch: 8.41 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07114892687312765		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.07114892687312765 | validation: 0.10809852467298814]
	TIME [epoch: 8.43 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06962278229300069		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.06962278229300069 | validation: 0.10183322022640653]
	TIME [epoch: 8.42 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06853587929008251		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.06853587929008251 | validation: 0.09898720949069056]
	TIME [epoch: 8.41 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06446306863564512		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.06446306863564512 | validation: 0.10490805542704812]
	TIME [epoch: 8.41 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06367758638350797		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.06367758638350797 | validation: 0.10818326903905183]
	TIME [epoch: 8.43 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061597245487527943		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.061597245487527943 | validation: 0.08953217590483556]
	TIME [epoch: 8.41 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06533747522212813		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.06533747522212813 | validation: 0.11277369126445683]
	TIME [epoch: 8.42 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06928412842949316		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.06928412842949316 | validation: 0.09957769697929372]
	TIME [epoch: 8.41 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06460582890571252		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.06460582890571252 | validation: 0.11540872307848904]
	TIME [epoch: 8.43 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06800144451212957		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.06800144451212957 | validation: 0.10468694759700842]
	TIME [epoch: 8.42 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06501180704403138		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.06501180704403138 | validation: 0.11015923987876022]
	TIME [epoch: 8.41 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06653941199503643		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.06653941199503643 | validation: 0.10236739222105189]
	TIME [epoch: 8.41 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06354564574455941		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.06354564574455941 | validation: 0.09854440763920314]
	TIME [epoch: 8.43 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060797752450116746		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.060797752450116746 | validation: 0.10813601382119806]
	TIME [epoch: 8.42 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06453517660804352		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.06453517660804352 | validation: 0.10218960765521645]
	TIME [epoch: 8.41 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06332228804646356		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.06332228804646356 | validation: 0.09649368580891454]
	TIME [epoch: 8.42 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06648755388146019		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.06648755388146019 | validation: 0.11491727882279579]
	TIME [epoch: 8.43 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06405687052122834		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.06405687052122834 | validation: 0.10560145380672195]
	TIME [epoch: 8.41 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0701258781572304		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.0701258781572304 | validation: 0.10755205672684465]
	TIME [epoch: 8.42 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06528227230192174		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.06528227230192174 | validation: 0.10323267596461644]
	TIME [epoch: 8.41 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06882644464657818		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.06882644464657818 | validation: 0.10291460875150829]
	TIME [epoch: 8.43 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06337367262180611		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.06337367262180611 | validation: 0.10222760684430945]
	TIME [epoch: 8.42 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06293448694170951		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.06293448694170951 | validation: 0.09615678396163804]
	TIME [epoch: 8.42 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06682269164096367		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.06682269164096367 | validation: 0.11026344800214341]
	TIME [epoch: 8.41 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06787134131729478		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.06787134131729478 | validation: 0.10917456378515775]
	TIME [epoch: 8.43 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061255723028203465		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.061255723028203465 | validation: 0.10446252476299842]
	TIME [epoch: 8.41 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06291654809666004		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.06291654809666004 | validation: 0.1157373370371228]
	TIME [epoch: 8.42 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06580364906659829		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.06580364906659829 | validation: 0.10335933658952412]
	TIME [epoch: 8.4 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06733120159934186		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.06733120159934186 | validation: 0.10327784466658017]
	TIME [epoch: 8.43 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124414521884495		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.06124414521884495 | validation: 0.1086714570784064]
	TIME [epoch: 8.42 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312330202090187		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.06312330202090187 | validation: 0.10141388402665981]
	TIME [epoch: 8.42 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06109726723557137		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.06109726723557137 | validation: 0.1029407615310603]
	TIME [epoch: 8.41 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0626478321565608		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.0626478321565608 | validation: 0.1034402035012113]
	TIME [epoch: 8.43 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06313009934478814		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.06313009934478814 | validation: 0.1187177769268874]
	TIME [epoch: 8.41 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06502649645478474		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.06502649645478474 | validation: 0.10827095015833707]
	TIME [epoch: 8.41 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06836457317161972		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.06836457317161972 | validation: 0.09814953642663701]
	TIME [epoch: 8.42 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06902050408209763		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.06902050408209763 | validation: 0.10909024499614439]
	TIME [epoch: 8.43 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678734268162476		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.0678734268162476 | validation: 0.11319206781866087]
	TIME [epoch: 8.42 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889416389703737		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.06889416389703737 | validation: 0.1008252422815697]
	TIME [epoch: 8.41 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07546089136635753		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.07546089136635753 | validation: 0.10803513673718732]
	TIME [epoch: 8.41 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06718937018659459		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.06718937018659459 | validation: 0.11058236498669213]
	TIME [epoch: 8.43 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06746171709979508		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.06746171709979508 | validation: 0.10671075959392648]
	TIME [epoch: 8.41 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06897385855283855		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.06897385855283855 | validation: 0.10230572072768303]
	TIME [epoch: 8.41 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06653405423347067		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.06653405423347067 | validation: 0.116280541256387]
	TIME [epoch: 8.42 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06341574678234808		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.06341574678234808 | validation: 0.09870837924619566]
	TIME [epoch: 8.43 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07006298167188477		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.07006298167188477 | validation: 0.11039454949261321]
	TIME [epoch: 8.41 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553160477698862		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.06553160477698862 | validation: 0.11104323374031938]
	TIME [epoch: 8.41 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378059397249776		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.06378059397249776 | validation: 0.09689178602344581]
	TIME [epoch: 8.42 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.064215567291836		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.064215567291836 | validation: 0.09864929376178845]
	TIME [epoch: 8.43 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06308189200260479		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.06308189200260479 | validation: 0.1109053125479568]
	TIME [epoch: 8.42 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06494045506372621		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.06494045506372621 | validation: 0.11248960382963746]
	TIME [epoch: 8.41 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06555661179616096		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.06555661179616096 | validation: 0.10161150975093347]
	TIME [epoch: 8.43 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06295942961006412		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.06295942961006412 | validation: 0.11217499821411994]
	TIME [epoch: 8.42 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06504269801307061		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.06504269801307061 | validation: 0.10036133179085122]
	TIME [epoch: 8.41 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06411591708651053		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.06411591708651053 | validation: 0.09951851600644648]
	TIME [epoch: 8.41 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06501604587268377		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.06501604587268377 | validation: 0.1100074647077499]
	TIME [epoch: 8.43 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06348016168625271		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.06348016168625271 | validation: 0.10332874033294301]
	TIME [epoch: 8.41 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857257965663865		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.06857257965663865 | validation: 0.09483413767647458]
	TIME [epoch: 8.41 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06331723621841989		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.06331723621841989 | validation: 0.10904001888940995]
	TIME [epoch: 8.42 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06562677317138248		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.06562677317138248 | validation: 0.1115647329964317]
	TIME [epoch: 8.43 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06294432305471744		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.06294432305471744 | validation: 0.1053172838114517]
	TIME [epoch: 8.42 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385693098961018		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.06385693098961018 | validation: 0.11951216844475648]
	TIME [epoch: 8.41 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06598213942076211		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.06598213942076211 | validation: 0.10759516501111989]
	TIME [epoch: 8.41 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06756034367316718		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.06756034367316718 | validation: 0.10439304093155304]
	TIME [epoch: 8.43 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661858222520886		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.0661858222520886 | validation: 0.09602607839709058]
	TIME [epoch: 8.41 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0676432842792817		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.0676432842792817 | validation: 0.0988653412745753]
	TIME [epoch: 8.42 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06803237499449448		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.06803237499449448 | validation: 0.10959989481743153]
	TIME [epoch: 8.41 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.066228913104863		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.066228913104863 | validation: 0.09895855365900443]
	TIME [epoch: 8.43 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06399133883470129		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.06399133883470129 | validation: 0.09088925972318002]
	TIME [epoch: 8.42 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631337619881597		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.0631337619881597 | validation: 0.09870550854541499]
	TIME [epoch: 8.41 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06396464744523292		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.06396464744523292 | validation: 0.11585967334309225]
	TIME [epoch: 8.41 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0621170390756897		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.0621170390756897 | validation: 0.10633350547746329]
	TIME [epoch: 8.44 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312458061427631		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.06312458061427631 | validation: 0.11052196447163742]
	TIME [epoch: 8.42 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06687528369260345		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.06687528369260345 | validation: 0.11450711665005206]
	TIME [epoch: 8.41 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844204393619233		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.06844204393619233 | validation: 0.10480019311088012]
	TIME [epoch: 8.41 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06326131134685316		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.06326131134685316 | validation: 0.10105272565683529]
	TIME [epoch: 8.43 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06653684130404894		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.06653684130404894 | validation: 0.10930799409979909]
	TIME [epoch: 8.41 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06314138623329431		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.06314138623329431 | validation: 0.10541575774062523]
	TIME [epoch: 8.41 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06689951066477132		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.06689951066477132 | validation: 0.10041521927952407]
	TIME [epoch: 8.41 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06445964368092881		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.06445964368092881 | validation: 0.10099427905392265]
	TIME [epoch: 8.44 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662092075178434		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.0662092075178434 | validation: 0.09861239111069889]
	TIME [epoch: 8.42 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06610792283871064		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.06610792283871064 | validation: 0.1106498641184714]
	TIME [epoch: 8.41 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06843033975074642		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.06843033975074642 | validation: 0.11642029747115476]
	TIME [epoch: 8.42 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06807702915366601		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.06807702915366601 | validation: 0.10576674133351566]
	TIME [epoch: 8.43 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06893535015276002		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.06893535015276002 | validation: 0.11641983422574415]
	TIME [epoch: 8.42 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0649153585327278		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.0649153585327278 | validation: 0.1095805386302437]
	TIME [epoch: 8.42 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493648931182285		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.06493648931182285 | validation: 0.09784625103420505]
	TIME [epoch: 8.41 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806544813147561		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.06806544813147561 | validation: 0.09324501089388831]
	TIME [epoch: 8.43 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06539168930716747		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.06539168930716747 | validation: 0.10772576822443597]
	TIME [epoch: 8.41 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822050467013205		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.06822050467013205 | validation: 0.09930649857429626]
	TIME [epoch: 8.41 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06775538851411769		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.06775538851411769 | validation: 0.1165375818508471]
	TIME [epoch: 8.41 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07232382962049325		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.07232382962049325 | validation: 0.10584346863133944]
	TIME [epoch: 8.44 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06333208886465923		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.06333208886465923 | validation: 0.11458246099604322]
	TIME [epoch: 8.41 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061306928767794075		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.061306928767794075 | validation: 0.10000636522064368]
	TIME [epoch: 8.41 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06567829718637441		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.06567829718637441 | validation: 0.11368242868257436]
	TIME [epoch: 8.42 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378389848004481		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.06378389848004481 | validation: 0.09682925291939223]
	TIME [epoch: 8.43 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06547454616702772		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.06547454616702772 | validation: 0.09869732156450578]
	TIME [epoch: 8.42 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0630180354392243		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.0630180354392243 | validation: 0.10359187960647345]
	TIME [epoch: 8.41 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497563864034099		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.06497563864034099 | validation: 0.10627488875486661]
	TIME [epoch: 8.42 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060862119379541335		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.060862119379541335 | validation: 0.10591889750546868]
	TIME [epoch: 8.42 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379050347671303		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.06379050347671303 | validation: 0.10053813168509135]
	TIME [epoch: 8.41 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06400713564381381		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.06400713564381381 | validation: 0.10671804797063159]
	TIME [epoch: 8.41 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06340926646820685		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.06340926646820685 | validation: 0.1049725847339442]
	TIME [epoch: 8.42 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06522929452241613		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.06522929452241613 | validation: 0.09338332416170425]
	TIME [epoch: 8.42 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499266518016109		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.06499266518016109 | validation: 0.10126724109862045]
	TIME [epoch: 8.41 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06512113126425861		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.06512113126425861 | validation: 0.10417707362382385]
	TIME [epoch: 8.41 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06733744081304467		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.06733744081304467 | validation: 0.10078884455647594]
	TIME [epoch: 8.42 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06067941397086694		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.06067941397086694 | validation: 0.11198967959216385]
	TIME [epoch: 8.43 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06743095028058482		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.06743095028058482 | validation: 0.10911024282729097]
	TIME [epoch: 8.41 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06419345676410618		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.06419345676410618 | validation: 0.11883526172270817]
	TIME [epoch: 8.41 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06643601749154955		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.06643601749154955 | validation: 0.11817788972980639]
	TIME [epoch: 8.43 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06372915992620068		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.06372915992620068 | validation: 0.10481855012862845]
	TIME [epoch: 8.41 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07068382576729262		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.07068382576729262 | validation: 0.11359583034283394]
	TIME [epoch: 8.41 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06637178176964284		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.06637178176964284 | validation: 0.10196502696924803]
	TIME [epoch: 8.41 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0659645283851066		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.0659645283851066 | validation: 0.09800968369462953]
	TIME [epoch: 8.43 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06610401646148838		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.06610401646148838 | validation: 0.10602571146534806]
	TIME [epoch: 8.42 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0670440425619781		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.0670440425619781 | validation: 0.09938674637285416]
	TIME [epoch: 8.4 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061848801846533755		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.061848801846533755 | validation: 0.10816602796279394]
	TIME [epoch: 8.41 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628460838261795		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.0628460838261795 | validation: 0.12264039277393182]
	TIME [epoch: 8.42 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06707111238932312		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.06707111238932312 | validation: 0.10275468490675616]
	TIME [epoch: 8.41 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06253191695629175		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.06253191695629175 | validation: 0.09893593338154644]
	TIME [epoch: 8.41 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06412081059927947		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.06412081059927947 | validation: 0.10186409861831039]
	TIME [epoch: 8.41 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06632678922241078		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.06632678922241078 | validation: 0.1074902052328001]
	TIME [epoch: 8.43 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06500595078235231		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.06500595078235231 | validation: 0.10783381057519426]
	TIME [epoch: 8.41 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06318625648564079		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.06318625648564079 | validation: 0.10956387199547671]
	TIME [epoch: 8.41 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06820250878659555		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.06820250878659555 | validation: 0.11134046635338962]
	TIME [epoch: 8.41 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0601446178024981		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.0601446178024981 | validation: 0.10096140439002338]
	TIME [epoch: 8.43 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06182285551203013		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.06182285551203013 | validation: 0.10497889081072223]
	TIME [epoch: 8.41 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526879535973405		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.06526879535973405 | validation: 0.10356956690690636]
	TIME [epoch: 8.41 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06174317662602587		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.06174317662602587 | validation: 0.0989440702018413]
	TIME [epoch: 8.41 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06335143157403067		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.06335143157403067 | validation: 0.10512152012407074]
	TIME [epoch: 8.43 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407455229285411		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.06407455229285411 | validation: 0.1032980680343703]
	TIME [epoch: 8.41 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06597571059317084		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.06597571059317084 | validation: 0.09935716726313912]
	TIME [epoch: 8.41 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06741270345895692		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.06741270345895692 | validation: 0.10730029196021787]
	TIME [epoch: 8.41 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06160720546811242		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.06160720546811242 | validation: 0.10229173888618913]
	TIME [epoch: 8.43 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651378384743759		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.0651378384743759 | validation: 0.09737450953533519]
	TIME [epoch: 8.41 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06404693163868996		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.06404693163868996 | validation: 0.10338651885103958]
	TIME [epoch: 8.41 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061969395511530835		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.061969395511530835 | validation: 0.09646900674458836]
	TIME [epoch: 8.41 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0641702142438865		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.0641702142438865 | validation: 0.10286339163089422]
	TIME [epoch: 8.43 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061076715551961445		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.061076715551961445 | validation: 0.10469720832995207]
	TIME [epoch: 8.41 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06390101461709718		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.06390101461709718 | validation: 0.10458134305619063]
	TIME [epoch: 8.41 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06578370559067995		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.06578370559067995 | validation: 0.0987426691625913]
	TIME [epoch: 8.41 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06825795571016517		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.06825795571016517 | validation: 0.09212734061651479]
	TIME [epoch: 8.44 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06444766553604361		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.06444766553604361 | validation: 0.09565077785693593]
	TIME [epoch: 8.4 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06677597523876565		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.06677597523876565 | validation: 0.10462717848628542]
	TIME [epoch: 8.4 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06379904888131199		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.06379904888131199 | validation: 0.10388790273600121]
	TIME [epoch: 8.41 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06204098061536663		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.06204098061536663 | validation: 0.09083548349850622]
	TIME [epoch: 8.43 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06339226840464494		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.06339226840464494 | validation: 0.09712575616458377]
	TIME [epoch: 8.42 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06655293309696683		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.06655293309696683 | validation: 0.10146524907780684]
	TIME [epoch: 8.4 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06549580416628223		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.06549580416628223 | validation: 0.10301280810505309]
	TIME [epoch: 8.41 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06581040273534625		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.06581040273534625 | validation: 0.11230498847664083]
	TIME [epoch: 8.43 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06186864462336733		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.06186864462336733 | validation: 0.10876016104584549]
	TIME [epoch: 8.41 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366671714620938		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.06366671714620938 | validation: 0.11114805081994272]
	TIME [epoch: 8.41 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651723131849808		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.0651723131849808 | validation: 0.10153139643594947]
	TIME [epoch: 8.41 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06921891627375308		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.06921891627375308 | validation: 0.10685345459460721]
	TIME [epoch: 8.43 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516818483694495		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.06516818483694495 | validation: 0.10847752979502395]
	TIME [epoch: 8.41 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06001490354740384		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.06001490354740384 | validation: 0.10716461509359676]
	TIME [epoch: 8.41 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463157561437408		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.06463157561437408 | validation: 0.10351417034261762]
	TIME [epoch: 8.42 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06931675551372413		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.06931675551372413 | validation: 0.11316949361306902]
	TIME [epoch: 8.42 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06962212478382694		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.06962212478382694 | validation: 0.10884504426081737]
	TIME [epoch: 8.42 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06196237465825316		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.06196237465825316 | validation: 0.1099132528872181]
	TIME [epoch: 8.41 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06176356247752479		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.06176356247752479 | validation: 0.0970632003604947]
	TIME [epoch: 8.42 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06343435047148072		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.06343435047148072 | validation: 0.10148735411295035]
	TIME [epoch: 8.42 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06219729791677804		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.06219729791677804 | validation: 0.09731768434473909]
	TIME [epoch: 8.41 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06333753906425668		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.06333753906425668 | validation: 0.10114879650635583]
	TIME [epoch: 8.41 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430588617774936		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.06430588617774936 | validation: 0.10982655129768777]
	TIME [epoch: 8.43 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415987429278283		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.06415987429278283 | validation: 0.11640326970807902]
	TIME [epoch: 8.42 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06504644218875003		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.06504644218875003 | validation: 0.09723276106465062]
	TIME [epoch: 8.41 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961343952644786		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.06961343952644786 | validation: 0.10807003812243617]
	TIME [epoch: 8.41 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06236178853196565		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.06236178853196565 | validation: 0.09283511021744825]
	TIME [epoch: 8.43 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06818928499210822		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.06818928499210822 | validation: 0.10359035656149679]
	TIME [epoch: 8.42 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062282219802925795		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.062282219802925795 | validation: 0.10208215911178742]
	TIME [epoch: 8.41 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06378091633853476		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.06378091633853476 | validation: 0.10456777536604794]
	TIME [epoch: 8.42 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062203024185405596		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.062203024185405596 | validation: 0.10288897769623946]
	TIME [epoch: 8.42 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06668566096895202		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.06668566096895202 | validation: 0.10615089504256836]
	TIME [epoch: 8.41 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06527035177682804		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.06527035177682804 | validation: 0.09598458808211574]
	TIME [epoch: 8.42 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06800653917816321		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.06800653917816321 | validation: 0.0988645765133115]
	TIME [epoch: 8.41 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06784248492930493		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.06784248492930493 | validation: 0.09833433702638522]
	TIME [epoch: 8.43 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06687265438133276		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.06687265438133276 | validation: 0.109767309637647]
	TIME [epoch: 8.42 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0637581854969727		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.0637581854969727 | validation: 0.09955840614015199]
	TIME [epoch: 8.41 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06340450397612013		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.06340450397612013 | validation: 0.09688857207540966]
	TIME [epoch: 8.41 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06513709213826988		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.06513709213826988 | validation: 0.11209858549054041]
	TIME [epoch: 8.44 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870817137119612		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.05870817137119612 | validation: 0.10076711039746147]
	TIME [epoch: 8.42 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0667837020941762		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.0667837020941762 | validation: 0.1089691607870774]
	TIME [epoch: 8.42 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06576270332327376		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.06576270332327376 | validation: 0.09853352360071409]
	TIME [epoch: 8.42 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830474631170393		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.06830474631170393 | validation: 0.1003291757553435]
	TIME [epoch: 8.43 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07093245491517686		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.07093245491517686 | validation: 0.08990161554347022]
	TIME [epoch: 8.42 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06396716707339134		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.06396716707339134 | validation: 0.10089823619131483]
	TIME [epoch: 8.41 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0618555557966699		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.0618555557966699 | validation: 0.10944251834257854]
	TIME [epoch: 8.41 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645907950005233		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.0645907950005233 | validation: 0.09907284460917265]
	TIME [epoch: 8.43 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06380011704516123		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.06380011704516123 | validation: 0.09967042588657504]
	TIME [epoch: 8.42 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609742541990844		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.06609742541990844 | validation: 0.09901582453339693]
	TIME [epoch: 8.42 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06271553104385527		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.06271553104385527 | validation: 0.11204174964087282]
	TIME [epoch: 8.41 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678305022990876		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.0678305022990876 | validation: 0.10559341548902902]
	TIME [epoch: 8.44 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06217080987579147		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.06217080987579147 | validation: 0.10221367463912269]
	TIME [epoch: 8.42 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06498857578024646		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.06498857578024646 | validation: 0.1035039367098421]
	TIME [epoch: 8.41 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0638421391671917		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.0638421391671917 | validation: 0.104566006393537]
	TIME [epoch: 8.42 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06695182420329436		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.06695182420329436 | validation: 0.09479826135697599]
	TIME [epoch: 8.43 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844522876179014		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.06844522876179014 | validation: 0.10317181717802429]
	TIME [epoch: 8.42 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393100154851508		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.06393100154851508 | validation: 0.10548717297997759]
	TIME [epoch: 8.41 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06732367241333581		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.06732367241333581 | validation: 0.10660268129709376]
	TIME [epoch: 8.41 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06588739942695396		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.06588739942695396 | validation: 0.10095294444078984]
	TIME [epoch: 8.44 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06631113064987927		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.06631113064987927 | validation: 0.10234239002307163]
	TIME [epoch: 8.42 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124336357003092		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.06124336357003092 | validation: 0.10089579602905466]
	TIME [epoch: 8.42 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06553609101449369		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.06553609101449369 | validation: 0.10015123444637275]
	TIME [epoch: 8.41 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06741567420034866		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.06741567420034866 | validation: 0.09774646135557585]
	TIME [epoch: 8.44 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0637270590962967		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.0637270590962967 | validation: 0.11642143551142178]
	TIME [epoch: 8.42 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06281118823020665		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.06281118823020665 | validation: 0.09715371341009109]
	TIME [epoch: 8.41 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06565462019197571		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.06565462019197571 | validation: 0.10122730852878387]
	TIME [epoch: 8.42 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06700133182023868		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.06700133182023868 | validation: 0.10187170601006791]
	TIME [epoch: 8.43 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06474398142390478		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.06474398142390478 | validation: 0.10056583962321503]
	TIME [epoch: 8.41 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06744606100699654		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.06744606100699654 | validation: 0.11325720335257525]
	TIME [epoch: 8.41 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609000308107617		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.06609000308107617 | validation: 0.10221559729857939]
	TIME [epoch: 8.42 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06616605942568114		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.06616605942568114 | validation: 0.09024241181011249]
	TIME [epoch: 8.42 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463309284135088		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.06463309284135088 | validation: 0.11608848071890288]
	TIME [epoch: 8.41 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06549072325306128		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.06549072325306128 | validation: 0.11456939388028106]
	TIME [epoch: 8.4 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564930255687121		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.06564930255687121 | validation: 0.1030914498544343]
	TIME [epoch: 8.42 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06278499678856805		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.06278499678856805 | validation: 0.08986409355223887]
	TIME [epoch: 8.42 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657685868300579		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.0657685868300579 | validation: 0.1255528123055753]
	TIME [epoch: 8.42 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06253374571889145		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.06253374571889145 | validation: 0.0943876205580888]
	TIME [epoch: 8.4 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06540392410651416		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.06540392410651416 | validation: 0.09776521730397704]
	TIME [epoch: 8.42 sec]
Finished training in 16994.590 seconds.
