Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r0', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2892530997

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.39906357893584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.39906357893584 | validation: 10.042546246278775]
	TIME [epoch: 98.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.6957721330986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.6957721330986 | validation: 8.526029576393363]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.699251822826408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.699251822826408 | validation: 8.078000241468507]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.580992864391645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.580992864391645 | validation: 6.99861830244153]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.053011208733506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.053011208733506 | validation: 6.619602357999051]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.352216025245662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.352216025245662 | validation: 5.216565338088797]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.571195766511982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.571195766511982 | validation: 4.803509860213744]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.162201908212417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.162201908212417 | validation: 4.484331010056443]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2091179622085955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2091179622085955 | validation: 4.832353821191163]
	TIME [epoch: 11.5 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.027245283550856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.027245283550856 | validation: 4.3792949212163945]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.860898745671548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.860898745671548 | validation: 4.420338871617552]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.058002250301186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.058002250301186 | validation: 6.772773768379976]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.450326553609571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.450326553609571 | validation: 4.262552951032907]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.935182275267071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.935182275267071 | validation: 3.9932577001801306]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.765516673774142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.765516673774142 | validation: 4.823324095055388]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.780997695616294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.780997695616294 | validation: 3.871775791463731]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.68630131673043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.68630131673043 | validation: 4.494234564245949]
	TIME [epoch: 11.5 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.787553727831263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.787553727831263 | validation: 4.130347956759602]
	TIME [epoch: 11.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5607181041971625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5607181041971625 | validation: 4.039033497783015]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.677855948185343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.677855948185343 | validation: 3.955742023315544]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47891589281752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.47891589281752 | validation: 4.417775027312914]
	TIME [epoch: 11.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.577795593510249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.577795593510249 | validation: 3.95662520984872]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.277944352384724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.277944352384724 | validation: 4.186943888806207]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.569294674266098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.569294674266098 | validation: 3.8588020805167704]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4814490248384296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4814490248384296 | validation: 3.826508109261057]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.24041479862322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.24041479862322 | validation: 4.362023816003521]
	TIME [epoch: 11.5 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365979958886544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.365979958886544 | validation: 4.8574289320698725]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.72319339746786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.72319339746786 | validation: 3.4844186633983725]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2961308513699095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2961308513699095 | validation: 3.482732347193289]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.257095915848656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.257095915848656 | validation: 3.4529463284165978]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.264821328647116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.264821328647116 | validation: 3.615912872026757]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.019392245716385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.019392245716385 | validation: 4.359509426324796]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.255340888291739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.255340888291739 | validation: 3.635697929010198]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.167307574014894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.167307574014894 | validation: 3.6507315842232932]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.071184964794205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.071184964794205 | validation: 3.439071478225219]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9091746300150643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9091746300150643 | validation: 4.515728207327906]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.311095421591519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.311095421591519 | validation: 3.723260783514689]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0248469380579275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0248469380579275 | validation: 3.4377388383201413]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.942210620219245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.942210620219245 | validation: 4.0193963473059275]
	TIME [epoch: 11.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209084809559146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.209084809559146 | validation: 3.5998893164345227]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.037241737203248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.037241737203248 | validation: 3.512028508867168]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.950776866683705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.950776866683705 | validation: 3.864545276629126]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.944944699724309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.944944699724309 | validation: 3.2836495095916267]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.050670644287937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.050670644287937 | validation: 3.223427726575043]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.049537631845365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049537631845365 | validation: 3.3375129304354734]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.854528508923998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.854528508923998 | validation: 3.2194971203970613]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.044922860387347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.044922860387347 | validation: 3.3306881571651497]
	TIME [epoch: 11.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7821553594347392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7821553594347392 | validation: 3.7412389374671635]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.124264631591984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.124264631591984 | validation: 3.3335466363164996]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8553648860576804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8553648860576804 | validation: 3.1519488253482235]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.029842571601288		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.029842571601288 | validation: 3.3151212065696343]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035320431225534		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.035320431225534 | validation: 3.434269825764162]
	TIME [epoch: 11.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9409653112994536		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.9409653112994536 | validation: 3.295317047346399]
	TIME [epoch: 11.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.768364042291784		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.768364042291784 | validation: 3.7284703258983063]
	TIME [epoch: 11.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.900363795090591		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.900363795090591 | validation: 3.4549798263626763]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7988390510081915		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.7988390510081915 | validation: 3.1030954455087807]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8674381262974813		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.8674381262974813 | validation: 3.358473880067298]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.78927715862186		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.78927715862186 | validation: 4.477656474634712]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.056718113952661		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.056718113952661 | validation: 3.749931680044659]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.915129037639682		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.915129037639682 | validation: 3.581941587450929]
	TIME [epoch: 11.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.049091638064423		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.049091638064423 | validation: 3.4699040316541265]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8438398443650694		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.8438398443650694 | validation: 3.2668990542990843]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.846662135953555		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.846662135953555 | validation: 3.7614335820412883]
	TIME [epoch: 11.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9095433998274878		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.9095433998274878 | validation: 3.698291863024814]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8189180129150397		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8189180129150397 | validation: 3.4368407018528617]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9170952665425216		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.9170952665425216 | validation: 3.159016004793761]
	TIME [epoch: 11.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9332251982636075		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.9332251982636075 | validation: 3.321395801815953]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.920564370934679		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.920564370934679 | validation: 3.4295225453815887]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7476920574743406		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.7476920574743406 | validation: 3.9843508565852273]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9235949309923868		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.9235949309923868 | validation: 3.524055331664556]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.776017240394073		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.776017240394073 | validation: 3.365909582527706]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.794446874122266		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.794446874122266 | validation: 3.321033492892084]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.691011823466647		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.691011823466647 | validation: 3.1394268849651144]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9198634525720135		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.9198634525720135 | validation: 3.3235141873445593]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9117919975969375		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.9117919975969375 | validation: 3.125351712843919]
	TIME [epoch: 11.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8501686809273146		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.8501686809273146 | validation: 3.6074666100068953]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.712691144628334		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.712691144628334 | validation: 3.158212723450028]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6970249197637988		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.6970249197637988 | validation: 3.622801041147022]
	TIME [epoch: 11.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8140851118489048		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.8140851118489048 | validation: 3.2691058430099873]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.709839337520576		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.709839337520576 | validation: 3.390411676222824]
	TIME [epoch: 11.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.819169696743275		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.819169696743275 | validation: 3.5003474500270837]
	TIME [epoch: 11.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.713648992040448		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.713648992040448 | validation: 3.124660045991571]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.661111729010048		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.661111729010048 | validation: 3.3041777766502185]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8045426099675472		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.8045426099675472 | validation: 3.4276776039031196]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.831891596477062		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.831891596477062 | validation: 3.2413602982637655]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7558307601319827		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.7558307601319827 | validation: 3.274623955625712]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7109847871707604		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.7109847871707604 | validation: 3.049447972274478]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.732214245030972		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.732214245030972 | validation: 3.1057982938431947]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7085732900813433		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.7085732900813433 | validation: 3.251669685136544]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.630168716635436		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.630168716635436 | validation: 3.2288970942869284]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.785894548344038		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.785894548344038 | validation: 3.1844640886796616]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.686460189744015		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.686460189744015 | validation: 3.4579489992199615]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7063892187388046		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.7063892187388046 | validation: 3.137701203345711]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.708807010414659		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.708807010414659 | validation: 3.2270574266943437]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6429009875047855		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.6429009875047855 | validation: 3.270077707974489]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6893731118306006		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.6893731118306006 | validation: 3.0561326250830088]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6521236168422995		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.6521236168422995 | validation: 3.4706862680040906]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7400316422727373		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.7400316422727373 | validation: 3.5920606807295132]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.767470725392328		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.767470725392328 | validation: 3.151883980987281]
	TIME [epoch: 11.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569910062993172		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.569910062993172 | validation: 3.882922055695633]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.871248494075821		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.871248494075821 | validation: 3.1006089110735817]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6943078205344255		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.6943078205344255 | validation: 3.070551882222436]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5751192897704156		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.5751192897704156 | validation: 2.980111728379958]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.692742733439405		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.692742733439405 | validation: 3.0691094904388003]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.614127097081312		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.614127097081312 | validation: 3.1210844208721062]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6130710730872915		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.6130710730872915 | validation: 2.9957735938311694]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.633011597124212		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.633011597124212 | validation: 3.116157269146348]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6548609390827416		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.6548609390827416 | validation: 3.160629954375612]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5694668150598154		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.5694668150598154 | validation: 3.4511352383632117]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8382588222505603		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.8382588222505603 | validation: 3.3427607284725616]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.66622832754844		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.66622832754844 | validation: 2.9353392095849666]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6040194146871034		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.6040194146871034 | validation: 3.2629322205953617]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.728913895506257		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.728913895506257 | validation: 3.074325614778045]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6332500064230646		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.6332500064230646 | validation: 3.0950109913759634]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8157680728583845		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.8157680728583845 | validation: 3.049302130341826]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8746845184983716		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.8746845184983716 | validation: 3.0100948264162164]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5787569085778745		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.5787569085778745 | validation: 3.1486337348733993]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6446306549432044		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.6446306549432044 | validation: 3.011065079804141]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5967946470592267		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.5967946470592267 | validation: 3.287858982771346]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5958378362607304		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.5958378362607304 | validation: 2.9375158251799487]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6363263065721734		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.6363263065721734 | validation: 3.0062666582794155]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6411168230690123		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.6411168230690123 | validation: 2.960585715321552]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5810265321823427		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.5810265321823427 | validation: 2.939609150792859]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6229901709102794		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.6229901709102794 | validation: 2.945342366491757]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5335486199976627		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.5335486199976627 | validation: 3.151268882283462]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5506102380978777		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.5506102380978777 | validation: 3.0677733532865927]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.601652197846293		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.601652197846293 | validation: 2.9506858288880684]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6059297107919344		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.6059297107919344 | validation: 2.9786283168000787]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5116551763323773		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.5116551763323773 | validation: 3.0182599522116913]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6182443074513517		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.6182443074513517 | validation: 2.9293162359473865]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.497025105210045		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.497025105210045 | validation: 3.012170158721408]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.659184647247954		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.659184647247954 | validation: 2.983133883647081]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1795101996127935		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.1795101996127935 | validation: 3.9063707799147607]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.915964454849899		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 3.915964454849899 | validation: 3.65700668145112]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7618123404245463		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.7618123404245463 | validation: 3.053485922042753]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6423472308381246		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.6423472308381246 | validation: 3.043226968455306]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.601781340586576		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.601781340586576 | validation: 2.9700580047909524]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5026950090955133		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.5026950090955133 | validation: 3.8113737567418697]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.768873498517973		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.768873498517973 | validation: 3.0202927107375674]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5809643799395667		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.5809643799395667 | validation: 3.1108747561835854]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.587465242247896		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.587465242247896 | validation: 3.234497972651312]
	TIME [epoch: 11.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6025180385188564		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.6025180385188564 | validation: 3.2244480447294617]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.556761814290869		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.556761814290869 | validation: 2.928128145010488]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.588967602909748		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.588967602909748 | validation: 3.0517415664502]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6003436862016986		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.6003436862016986 | validation: 2.9514648942907558]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.504426708536958		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.504426708536958 | validation: 3.1774339926788717]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.574381217526956		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.574381217526956 | validation: 2.969273566185884]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5627135696587766		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 3.5627135696587766 | validation: 2.9311514064278765]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.555444887871248		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.555444887871248 | validation: 2.9684332528978588]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.526212461712632		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.526212461712632 | validation: 3.043457299998703]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.542145411175319		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.542145411175319 | validation: 3.000027669356512]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.526750256415585		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.526750256415585 | validation: 2.938192122419997]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4805660540211036		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.4805660540211036 | validation: 3.0440093959152414]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.572222899397724		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.572222899397724 | validation: 3.052504542655774]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.500840651533499		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.500840651533499 | validation: 3.051701042659148]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.642207099193246		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.642207099193246 | validation: 3.1690664036724385]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.600164664274229		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.600164664274229 | validation: 2.972277483857927]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.551211695863082		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.551211695863082 | validation: 2.905972457389111]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4989134419343206		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.4989134419343206 | validation: 2.899069588925231]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5651577160621457		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.5651577160621457 | validation: 2.9063105872415242]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5260136328976137		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.5260136328976137 | validation: 2.9954019242115066]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.546462940525533		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.546462940525533 | validation: 2.956745480242478]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.531392399230969		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.531392399230969 | validation: 3.3447435771098437]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.699164105909789		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.699164105909789 | validation: 3.0400688595218255]
	TIME [epoch: 11.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5205130104953537		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.5205130104953537 | validation: 2.922338489726817]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5052726087689083		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.5052726087689083 | validation: 2.9776838265964063]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540529637711601		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.540529637711601 | validation: 2.984645454070157]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.602000299199719		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.602000299199719 | validation: 2.9185843827048474]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476225618017007		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.476225618017007 | validation: 3.0929752371842865]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6197796104031537		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.6197796104031537 | validation: 2.8860111195455733]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.578806664039499		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.578806664039499 | validation: 3.2023203082925797]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5093403564976273		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.5093403564976273 | validation: 2.8781009290665684]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4400501112464124		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.4400501112464124 | validation: 3.282063171191827]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7513015787554553		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.7513015787554553 | validation: 3.1206000830100606]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5258475226562225		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.5258475226562225 | validation: 2.974023628208054]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.538434946866428		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.538434946866428 | validation: 2.877415803564608]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.434311049178855		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.434311049178855 | validation: 2.9705148110081843]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6300335042774616		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.6300335042774616 | validation: 3.0478880623376656]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.549660250651317		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.549660250651317 | validation: 2.9956688443683754]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5015426895592827		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.5015426895592827 | validation: 2.900015148740706]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5439708767373883		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.5439708767373883 | validation: 2.9003312953862443]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.529724566152949		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.529724566152949 | validation: 3.2642953496990517]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.528725335459031		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.528725335459031 | validation: 2.9930070896799355]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4836404909051057		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.4836404909051057 | validation: 2.852391404826166]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.561286125083926		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.561286125083926 | validation: 2.931056571048436]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.605213874413842		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.605213874413842 | validation: 2.9168729588696647]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5245509478303267		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.5245509478303267 | validation: 3.051161403514571]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4963207214790586		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.4963207214790586 | validation: 2.9412117181605972]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.483992008322693		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.483992008322693 | validation: 2.8928533008483845]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4709135184566744		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.4709135184566744 | validation: 3.00873068881901]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5523470277197124		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.5523470277197124 | validation: 2.8963048714016013]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4242759981125133		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.4242759981125133 | validation: 2.968867007780277]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4508544254800144		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.4508544254800144 | validation: 3.0529668652918645]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.498982558978656		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.498982558978656 | validation: 2.880218507368617]
	TIME [epoch: 11.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4673393979933786		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.4673393979933786 | validation: 2.8879993258541914]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.518743235543897		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.518743235543897 | validation: 2.9444341451624756]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5671215580911815		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.5671215580911815 | validation: 3.0825812990236443]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5038211214287998		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.5038211214287998 | validation: 2.9220395085554167]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5557777801384223		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.5557777801384223 | validation: 2.9139322994727674]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5770392685617516		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.5770392685617516 | validation: 3.0972150660969406]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4996857799625545		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.4996857799625545 | validation: 2.9059179173822303]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4258074820871802		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.4258074820871802 | validation: 3.0411426544555455]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5539328291438315		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.5539328291438315 | validation: 2.90127884791358]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4527841780112283		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.4527841780112283 | validation: 2.9185850894740453]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5488861332899218		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.5488861332899218 | validation: 2.892055829652079]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5056353895304495		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.5056353895304495 | validation: 2.893517306738253]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.47766011740303		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.47766011740303 | validation: 3.416241289470517]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.642808363021738		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 3.642808363021738 | validation: 2.8707093340855407]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5051999938978797		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.5051999938978797 | validation: 3.071443632138184]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.495676978807162		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.495676978807162 | validation: 2.9716228255791544]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.527139593487259		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.527139593487259 | validation: 3.092020816195377]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4915455721251494		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.4915455721251494 | validation: 2.907593438412696]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4859351396338676		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.4859351396338676 | validation: 3.059571664455732]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5253187151387597		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.5253187151387597 | validation: 2.891787688565186]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5196285440223933		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.5196285440223933 | validation: 2.956867260141521]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5117703611274567		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.5117703611274567 | validation: 2.9619740326228032]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5499216184164903		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.5499216184164903 | validation: 2.913873035880196]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4862867512845592		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.4862867512845592 | validation: 2.868257766017749]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457850123638637		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.457850123638637 | validation: 3.001175816240581]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4950889169068113		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.4950889169068113 | validation: 3.1417395056845874]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4851910149107006		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.4851910149107006 | validation: 3.3214921229799326]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.623454063445545		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.623454063445545 | validation: 3.0287985005750397]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.564960911236387		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.564960911236387 | validation: 2.868379669363565]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428406627323925		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.428406627323925 | validation: 3.0667690747907437]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.572650915204561		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.572650915204561 | validation: 3.1352498008039777]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.514312744425496		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.514312744425496 | validation: 2.956338659782883]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.620697314797221		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.620697314797221 | validation: 2.9511929076293417]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.483135684920315		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.483135684920315 | validation: 3.090461488575168]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5082964780845494		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.5082964780845494 | validation: 2.8967265459777822]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405849558041124		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 3.405849558041124 | validation: 2.8759315623039097]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6617843686647795		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.6617843686647795 | validation: 2.9371019128747373]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4696448534294677		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.4696448534294677 | validation: 3.3099983220923286]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.522626313616043		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.522626313616043 | validation: 2.872633795068532]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.422328330018363		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.422328330018363 | validation: 2.846072941195022]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4088330763600028		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.4088330763600028 | validation: 3.1274833921397494]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.503551229533758		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 3.503551229533758 | validation: 2.899817318366591]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427741121886749		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 3.427741121886749 | validation: 2.8899426918686295]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.45274845485664		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.45274845485664 | validation: 2.9795715073459634]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.477934274713144		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 3.477934274713144 | validation: 2.8623557266859496]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.442048986232506		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.442048986232506 | validation: 2.8956649527689615]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4827609905643984		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.4827609905643984 | validation: 2.9239984259961442]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4203529336370315		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.4203529336370315 | validation: 2.904884726404]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4326615345681555		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.4326615345681555 | validation: 2.9992730538583943]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.516420245211032		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 3.516420245211032 | validation: 2.8658644154862185]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4331076220202994		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.4331076220202994 | validation: 2.864489974257689]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.439385593383083		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.439385593383083 | validation: 2.8640707765567366]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4714638128009048		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.4714638128009048 | validation: 2.876492112677363]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4178710735756384		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 3.4178710735756384 | validation: 2.8660571749162296]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3930659937992838		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.3930659937992838 | validation: 2.9256270404906197]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4121012237766752		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 3.4121012237766752 | validation: 2.8573925037297188]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.461242576063966		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.461242576063966 | validation: 2.966891094951467]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5206198350730666		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.5206198350730666 | validation: 2.868575622625465]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5951255180379005		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 3.5951255180379005 | validation: 2.9332276803142587]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4697567057169314		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 3.4697567057169314 | validation: 2.8549396345662355]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3916715045824657		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 3.3916715045824657 | validation: 2.8882339126166445]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4306742168245763		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 3.4306742168245763 | validation: 2.845582485884202]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4252325681628255		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.4252325681628255 | validation: 2.885950123339989]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4198349951052793		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 3.4198349951052793 | validation: 2.954471562737492]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4385707047462812		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 3.4385707047462812 | validation: 2.8814692531319612]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.466509102579644		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 3.466509102579644 | validation: 2.9629183546463618]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4524834589489357		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.4524834589489357 | validation: 2.8622713720934927]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4240782371229734		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.4240782371229734 | validation: 2.870189975487331]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3946578978743798		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.3946578978743798 | validation: 2.8327536395748427]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.416714085323717		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.416714085323717 | validation: 2.8196407053023638]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468357162581295		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.468357162581295 | validation: 2.849899901305241]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.451352195964133		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.451352195964133 | validation: 2.859919326111478]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4238980192088886		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.4238980192088886 | validation: 2.848371910309883]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4519003177442324		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.4519003177442324 | validation: 2.8926427124472274]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.486277638792349		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.486277638792349 | validation: 2.8857284533007714]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431050616503745		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.431050616503745 | validation: 2.9095642080603694]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.447848946512594		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.447848946512594 | validation: 2.868229651327695]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.443484859774278		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.443484859774278 | validation: 2.828237857910385]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5734083650794393		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.5734083650794393 | validation: 2.864245735445947]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.448027816852755		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.448027816852755 | validation: 2.8340880637179646]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4776175544198322		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.4776175544198322 | validation: 2.8866740209632504]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39424879309208		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.39424879309208 | validation: 2.869955285062049]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4000565379391117		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.4000565379391117 | validation: 2.8323125444285098]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413940338559261		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.413940338559261 | validation: 2.824896104473928]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.403474395871948		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.403474395871948 | validation: 2.839930578874194]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431368642819872		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.431368642819872 | validation: 2.857394110481812]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.471811344465137		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.471811344465137 | validation: 2.819113508637214]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.37990151831046		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.37990151831046 | validation: 2.883690931546256]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4461041280303357		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.4461041280303357 | validation: 2.9457466620884687]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4195261707597235		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.4195261707597235 | validation: 2.8492514539069727]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435470719158482		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.435470719158482 | validation: 2.877049336142739]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4257384552935517		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.4257384552935517 | validation: 2.923453096547287]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4094853324028294		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.4094853324028294 | validation: 2.882127337204313]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3792065347617757		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.3792065347617757 | validation: 2.88238662233426]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4121534220072585		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.4121534220072585 | validation: 2.913994494348872]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4297447155456946		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.4297447155456946 | validation: 2.897112266052407]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.432766217371698		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.432766217371698 | validation: 2.9029573130134008]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.42179380727483		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.42179380727483 | validation: 3.366824038021671]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.564951061253832		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.564951061253832 | validation: 2.892121613894259]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.396276929150514		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.396276929150514 | validation: 3.250801355245077]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515723159911342		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.515723159911342 | validation: 2.984380539160879]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4947242366373374		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.4947242366373374 | validation: 2.896773691656158]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3861620271150383		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.3861620271150383 | validation: 2.845638797078862]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405067826422153		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 3.405067826422153 | validation: 2.895640065001371]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3821427673819944		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.3821427673819944 | validation: 2.8657205416399263]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4414817843659486		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.4414817843659486 | validation: 2.9154530586394167]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435869090995685		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.435869090995685 | validation: 2.831193134973654]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3866915998167646		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.3866915998167646 | validation: 2.8610088960311852]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3723011166258967		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 3.3723011166258967 | validation: 2.816727621323159]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402926503814631		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 3.402926503814631 | validation: 2.806995813973615]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3786421830833424		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.3786421830833424 | validation: 2.811484361237086]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3951733617076343		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 3.3951733617076343 | validation: 2.981185830758577]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.430671587772533		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 3.430671587772533 | validation: 2.807434440374819]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.377134354257155		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 3.377134354257155 | validation: 2.88105010958215]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375906703720326		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 3.375906703720326 | validation: 2.877938225373451]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41185350803943		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 3.41185350803943 | validation: 2.824552071682468]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4119472837240625		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 3.4119472837240625 | validation: 2.963119244585065]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.44855397986489		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 3.44855397986489 | validation: 2.8093384271294384]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395311697799825		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 3.395311697799825 | validation: 2.7924671965331735]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383393820972665		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.383393820972665 | validation: 2.9380852392715457]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.428338534704946		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 3.428338534704946 | validation: 2.8539841117301274]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.431503849776552		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 3.431503849776552 | validation: 2.9229089148914285]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4244745318438365		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 3.4244745318438365 | validation: 2.825998022357407]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4101283907329125		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 3.4101283907329125 | validation: 2.827285522900173]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.411611908821543		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 3.411611908821543 | validation: 2.9014176348353535]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.427946374094251		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 3.427946374094251 | validation: 2.807462261864531]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378407499810865		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 3.378407499810865 | validation: 2.809682009361428]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3556060018319807		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 3.3556060018319807 | validation: 2.8678589532891046]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.41812242045693		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 3.41812242045693 | validation: 2.8096263072632475]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5447042385190524		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 3.5447042385190524 | validation: 2.8677832824261684]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3814508582049663		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 3.3814508582049663 | validation: 2.833103444898483]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398700610103701		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 3.398700610103701 | validation: 2.894373372936053]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4269955426062055		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 3.4269955426062055 | validation: 2.9991198559869]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.411267371069799		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.411267371069799 | validation: 2.822533025576695]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4233112477412018		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 3.4233112477412018 | validation: 2.9250992006913807]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476819915110107		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 3.476819915110107 | validation: 2.816339988873903]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4050189075374284		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 3.4050189075374284 | validation: 2.8818757319188113]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3674110177397707		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 3.3674110177397707 | validation: 2.8159188806827484]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3919831106712968		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 3.3919831106712968 | validation: 2.8182291180472094]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.423611594076491		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 3.423611594076491 | validation: 2.88082733215934]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389393285247643		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 3.389393285247643 | validation: 2.9037736446033193]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3710741094261776		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 3.3710741094261776 | validation: 2.8181136794464057]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402763085834088		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 3.402763085834088 | validation: 2.914500188443359]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3953504980311884		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 3.3953504980311884 | validation: 2.8072894208888024]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381248653471375		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 3.381248653471375 | validation: 2.9590145303803697]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402480741900179		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 3.402480741900179 | validation: 2.8024338164381004]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.34392385356725		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 3.34392385356725 | validation: 2.8799473768798216]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395595384720523		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 3.395595384720523 | validation: 2.8214753478933177]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.367058227454912		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 3.367058227454912 | validation: 2.7988366521227013]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.36246170845156		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 3.36246170845156 | validation: 3.117817345010229]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5270866979745894		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 3.5270866979745894 | validation: 2.947593687307917]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3717187473247066		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 3.3717187473247066 | validation: 2.8574448063405584]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.369951370213551		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 3.369951370213551 | validation: 2.9059594047968496]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.408857799620223		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 3.408857799620223 | validation: 2.8544884337488385]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3826955429386585		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 3.3826955429386585 | validation: 2.794629381640757]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.358517253919293		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 3.358517253919293 | validation: 2.828353775159041]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429755437435444		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 3.429755437435444 | validation: 2.9688451613778706]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.435765961833164		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 3.435765961833164 | validation: 2.9878130350993235]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4120632189724915		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 3.4120632189724915 | validation: 2.9809613660164094]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.421998329842038		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 3.421998329842038 | validation: 2.834938265177268]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3720791526506035		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 3.3720791526506035 | validation: 2.9158117977186957]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.365693609504056		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 3.365693609504056 | validation: 2.8375587113041307]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3524947791555446		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 3.3524947791555446 | validation: 2.7959897172329202]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3245106489057967		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 3.3245106489057967 | validation: 2.8196277975105204]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3681620778191697		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 3.3681620778191697 | validation: 2.8296785024816313]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342904827908859		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 3.342904827908859 | validation: 2.8935328487393948]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3956375625728863		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 3.3956375625728863 | validation: 2.799819653770803]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380362447783616		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 3.380362447783616 | validation: 2.858241574845928]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.389119213817313		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 3.389119213817313 | validation: 3.012180954891423]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.499232000764474		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 3.499232000764474 | validation: 2.847103747272278]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353252279132023		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 3.353252279132023 | validation: 2.8349232502073862]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3561836233435782		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 3.3561836233435782 | validation: 2.892397424036568]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378076335282459		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 3.378076335282459 | validation: 2.842078673704273]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3517787318648065		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 3.3517787318648065 | validation: 2.895476772318633]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4106678811444513		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 3.4106678811444513 | validation: 2.822020573958416]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3335173933231728		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 3.3335173933231728 | validation: 2.8057371607778827]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3934157582780786		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 3.3934157582780786 | validation: 2.935609263906434]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.399922834600768		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 3.399922834600768 | validation: 2.8148359340143476]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.338083207234164		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 3.338083207234164 | validation: 2.8142196297595636]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379773464237343		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 3.379773464237343 | validation: 2.793352153906875]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.324241459699079		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 3.324241459699079 | validation: 2.843932309460521]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35621617400031		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 3.35621617400031 | validation: 2.9258818538440874]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3766847920612655		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 3.3766847920612655 | validation: 2.7991260546056322]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3614541155172546		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 3.3614541155172546 | validation: 2.804528531875976]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.34250926563153		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 3.34250926563153 | validation: 2.7978649144303582]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3423237105371215		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 3.3423237105371215 | validation: 2.875713231542802]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3878795478770773		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 3.3878795478770773 | validation: 2.7955926263149453]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3701406275332104		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 3.3701406275332104 | validation: 2.804398987896385]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.359834270074432		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 3.359834270074432 | validation: 2.8039797168392933]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.341522882001506		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 3.341522882001506 | validation: 2.7980298019648164]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.343023649513828		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 3.343023649513828 | validation: 2.8056808967957636]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4258940293210576		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 3.4258940293210576 | validation: 2.9123895880192014]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.412671973633503		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 3.412671973633503 | validation: 2.8975317200179407]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.371417910166058		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 3.371417910166058 | validation: 2.8787736180560977]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.399666780223252		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 3.399666780223252 | validation: 2.836526285529298]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3481652147432053		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 3.3481652147432053 | validation: 2.8195121121487112]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4308097324144544		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 3.4308097324144544 | validation: 2.8839469545893652]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.571610356481666		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 3.571610356481666 | validation: 2.8560944710966134]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.365732896646217		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 3.365732896646217 | validation: 2.8424608967713727]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3404304276778776		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 3.3404304276778776 | validation: 2.8291594642462146]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3771540297035645		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 3.3771540297035645 | validation: 2.826439476481951]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.381364211351981		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 3.381364211351981 | validation: 2.816092835615086]
	TIME [epoch: 11.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3535304800871564		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 3.3535304800871564 | validation: 2.7868367451711196]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3306495152742754		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 3.3306495152742754 | validation: 2.9160566703287563]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379655543246509		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 3.379655543246509 | validation: 2.8438261895920767]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5081006189957753		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 3.5081006189957753 | validation: 2.8399845551291163]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388610602330693		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 3.388610602330693 | validation: 2.8807563968242254]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3445336664893146		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 3.3445336664893146 | validation: 2.7877838351908553]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.386824004159331		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 3.386824004159331 | validation: 2.9788605840528386]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.429231720216932		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 3.429231720216932 | validation: 2.8675479762440914]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3558403429684485		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 3.3558403429684485 | validation: 3.0638379949640573]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3864844717050233		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 3.3864844717050233 | validation: 2.79886909986651]
	TIME [epoch: 11.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3328522303970813		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 3.3328522303970813 | validation: 2.7989869248511225]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.34098564607807		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 3.34098564607807 | validation: 2.8401063142772878]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3416672920972674		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 3.3416672920972674 | validation: 2.7844177110230426]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328521671546707		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 3.328521671546707 | validation: 2.84236297403074]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3507964939110475		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 3.3507964939110475 | validation: 2.980943789729175]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405289715297439		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 3.405289715297439 | validation: 2.756774625243829]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328397914679942		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 3.328397914679942 | validation: 2.8176507783295346]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3359334920750703		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 3.3359334920750703 | validation: 2.799271077832734]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3502293463290806		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 3.3502293463290806 | validation: 2.8368248789869894]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3200011358357684		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 3.3200011358357684 | validation: 2.8345987101378456]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.358792512236484		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 3.358792512236484 | validation: 2.801975767347022]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3628586718226137		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 3.3628586718226137 | validation: 2.801934433060252]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3328068529638712		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 3.3328068529638712 | validation: 2.846042043321568]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3560436699791865		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 3.3560436699791865 | validation: 2.7973794771959697]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315927746299721		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 3.315927746299721 | validation: 2.858270788620548]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.323992454160891		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 3.323992454160891 | validation: 2.874126491809264]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.31578905981588		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 3.31578905981588 | validation: 2.784929729900607]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.360215278778414		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 3.360215278778414 | validation: 2.8494304526646532]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.332414937489946		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 3.332414937489946 | validation: 2.779414764909167]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.339059716448101		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 3.339059716448101 | validation: 2.834685237265388]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.33835377366634		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 3.33835377366634 | validation: 2.783182119730711]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3783932429681207		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 3.3783932429681207 | validation: 2.763221816049768]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.324551007334777		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 3.324551007334777 | validation: 2.8408902258257696]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3538587846404577		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 3.3538587846404577 | validation: 2.7653271879635266]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3217654768442957		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 3.3217654768442957 | validation: 2.7502597725388047]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_431.pth
	Model improved!!!
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.308773694667859		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 3.308773694667859 | validation: 2.955812327510705]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3912708780089753		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 3.3912708780089753 | validation: 2.881866919650978]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3481400441254685		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 3.3481400441254685 | validation: 2.7602524159391995]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2978817618402525		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 3.2978817618402525 | validation: 2.7819892894036857]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296472343344469		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 3.296472343344469 | validation: 2.795458166224612]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.300238587637726		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 3.300238587637726 | validation: 2.870782874789951]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3368919194239637		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 3.3368919194239637 | validation: 2.761635151741148]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3161738612013014		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 3.3161738612013014 | validation: 2.7672342978750066]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.314105799491333		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 3.314105799491333 | validation: 2.7927111412122447]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.320867602761676		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 3.320867602761676 | validation: 2.756497925268748]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.295711725273512		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 3.295711725273512 | validation: 2.868260685307683]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3241291763595093		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 3.3241291763595093 | validation: 2.7412631706683]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302901802292127		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 3.302901802292127 | validation: 2.764198895588794]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2916201054922514		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 3.2916201054922514 | validation: 2.7563021783975707]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3036957675995433		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 3.3036957675995433 | validation: 2.75755590745759]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2953699546297273		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 3.2953699546297273 | validation: 2.764764378067837]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.314425179401729		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 3.314425179401729 | validation: 3.143629277312008]
	TIME [epoch: 11.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.412983400345381		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 3.412983400345381 | validation: 2.7929245219556122]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3014823818067023		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 3.3014823818067023 | validation: 2.7866775453948605]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.309356035698601		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 3.309356035698601 | validation: 2.8587045123335315]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3172047923918506		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 3.3172047923918506 | validation: 2.757256170301734]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315349722093255		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 3.315349722093255 | validation: 2.7335428992465536]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2960882863860066		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 3.2960882863860066 | validation: 2.87034430130784]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3405226266175614		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 3.3405226266175614 | validation: 2.7850256597230705]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.300602220503096		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 3.300602220503096 | validation: 2.7509035645038775]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2929814563157813		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 3.2929814563157813 | validation: 2.7390761624740425]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.331066046234492		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 3.331066046234492 | validation: 2.7690076383410123]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3736635550137626		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 3.3736635550137626 | validation: 2.7350275887019873]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3271614490236745		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 3.3271614490236745 | validation: 2.729042949432941]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283778727683543		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 3.283778727683543 | validation: 2.909179578316947]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3455096799147994		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 3.3455096799147994 | validation: 2.7667699496467573]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2989049215756947		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 3.2989049215756947 | validation: 2.7570049855961156]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2940173001234614		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 3.2940173001234614 | validation: 2.748863925580033]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2873163394081626		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 3.2873163394081626 | validation: 2.7278473403103387]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3322044877981116		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 3.3322044877981116 | validation: 2.7798968565693327]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3108046943569116		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 3.3108046943569116 | validation: 2.7688427129379933]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2849610392695454		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 3.2849610392695454 | validation: 2.7494428542218157]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3100585625436443		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 3.3100585625436443 | validation: 2.8448119774952536]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.309598223379468		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 3.309598223379468 | validation: 2.7430064902025]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2942624961875158		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 3.2942624961875158 | validation: 2.748983376240637]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.315674120888274		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 3.315674120888274 | validation: 2.7371292485670815]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3358211975754886		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 3.3358211975754886 | validation: 2.8708137014057424]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3634741390539276		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 3.3634741390539276 | validation: 2.7493922025304496]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2885466174934033		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 3.2885466174934033 | validation: 2.7841820328295293]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3531999882434675		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 3.3531999882434675 | validation: 2.7398905200691246]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3114164342942294		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 3.3114164342942294 | validation: 2.769765019985765]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.325783013449877		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 3.325783013449877 | validation: 2.754978379136919]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.305289380799311		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 3.305289380799311 | validation: 2.7349913198724924]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2833757314743908		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 3.2833757314743908 | validation: 2.7261884331914494]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3097335600504705		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 3.3097335600504705 | validation: 2.7684269737915126]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2944146000592376		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 3.2944146000592376 | validation: 2.9030286019359908]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.318822544383635		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 3.318822544383635 | validation: 2.7296155050879456]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280306164219149		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 3.280306164219149 | validation: 2.74615544661694]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3440630672549974		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 3.3440630672549974 | validation: 2.7719746782279997]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.30024984939833		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 3.30024984939833 | validation: 2.79079989072402]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3155641504389886		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 3.3155641504389886 | validation: 2.7577548555328604]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.314433491875489		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 3.314433491875489 | validation: 2.7354700555936016]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296315742114537		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 3.296315742114537 | validation: 2.8301384717304985]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.339826564277008		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 3.339826564277008 | validation: 2.760652868925913]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.307371335074984		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 3.307371335074984 | validation: 2.745037283982449]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3261895512477113		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 3.3261895512477113 | validation: 2.7996387474940843]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3334208837033246		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 3.3334208837033246 | validation: 2.731326850821672]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.306172547435103		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 3.306172547435103 | validation: 2.757830473689103]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2820174415433554		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 3.2820174415433554 | validation: 2.777865410865631]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2849273054571277		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 3.2849273054571277 | validation: 2.8863498168870354]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353358446797625		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 3.353358446797625 | validation: 2.7459013426810364]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2791511801736295		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 3.2791511801736295 | validation: 2.727340955964071]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3310695636591987		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 3.3310695636591987 | validation: 2.8877706160753327]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3571987030501407		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 3.3571987030501407 | validation: 2.7780259428867238]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376579859561364		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 3.376579859561364 | validation: 2.8103065890286096]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310083415550861		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 3.310083415550861 | validation: 2.7187008712572647]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2943886014446804		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 3.2943886014446804 | validation: 2.777255420671385]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2917157936488834		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 3.2917157936488834 | validation: 2.731011600295347]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2957522301376057		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 3.2957522301376057 | validation: 2.7795821284781903]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302035470371283		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 3.302035470371283 | validation: 2.984236497327943]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.401723292867358		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 3.401723292867358 | validation: 2.926902611182826]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.366686969478364		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 3.366686969478364 | validation: 2.7276862347294344]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.27953594702415		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 3.27953594702415 | validation: 2.7473910500805916]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297382103084695		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 3.297382103084695 | validation: 2.7454549823118213]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2795502964556134		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 3.2795502964556134 | validation: 2.78270522313227]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2961870257658172		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 3.2961870257658172 | validation: 2.7195821054471447]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2983498141692857		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 3.2983498141692857 | validation: 2.7469623901529805]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276118586643429		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 3.276118586643429 | validation: 2.7268086357168015]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2956174499782476		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 3.2956174499782476 | validation: 2.779024959301255]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2797155575613965		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 3.2797155575613965 | validation: 2.7266282485638182]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2608580249358075		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 3.2608580249358075 | validation: 2.733934795143506]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3098141461985335		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 3.3098141461985335 | validation: 2.7732738978562503]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2933744827280362		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 3.2933744827280362 | validation: 2.8854107960693938]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.383359064471123		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 3.383359064471123 | validation: 2.733624910405646]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2869919094547506		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 3.2869919094547506 | validation: 2.9113408293488776]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.361046144642278		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 3.361046144642278 | validation: 2.7360746902354016]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2867078955319036		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 3.2867078955319036 | validation: 2.7653738896840743]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.334203004399917		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 3.334203004399917 | validation: 2.764512364013295]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.29328091712175		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 3.29328091712175 | validation: 2.7344264655060426]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297117371382947		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 3.297117371382947 | validation: 2.809744002554835]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3227995178331913		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 3.3227995178331913 | validation: 2.7321821806953626]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3046285933861914		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 3.3046285933861914 | validation: 2.7273476814898134]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2826800905062457		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 3.2826800905062457 | validation: 2.7346678348215097]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2777463452111046		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 3.2777463452111046 | validation: 2.719803528938909]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270015740737189		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 3.270015740737189 | validation: 2.8032705608413515]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.34281490615387		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 3.34281490615387 | validation: 2.7527119554196715]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.266558476395386		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 3.266558476395386 | validation: 2.814074370005371]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.29086473337091		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 3.29086473337091 | validation: 2.7559452484213014]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3128338958150136		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 3.3128338958150136 | validation: 2.7921445911407785]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.347573352618627		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 3.347573352618627 | validation: 2.8211405040561397]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.290194565953142		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 3.290194565953142 | validation: 2.7016758716118487]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2642091886684144		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 3.2642091886684144 | validation: 2.745397315867659]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.290195043596093		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 3.290195043596093 | validation: 2.7716077086543534]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2764870155217976		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 3.2764870155217976 | validation: 2.718581480975912]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2751924650766338		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 3.2751924650766338 | validation: 2.727615106713366]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273485203500183		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 3.273485203500183 | validation: 2.7293975937523345]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3249821224265297		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 3.3249821224265297 | validation: 2.7429432030776804]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276908118605734		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 3.276908118605734 | validation: 2.747523624726607]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2826185307783335		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 3.2826185307783335 | validation: 2.77282604902302]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.27802221598374		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 3.27802221598374 | validation: 2.712766127992743]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258705595450888		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 3.258705595450888 | validation: 2.704197212062843]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2685395510367465		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 3.2685395510367465 | validation: 2.7121996510732713]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2668050602738705		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 3.2668050602738705 | validation: 2.7097578747579396]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2669410880599		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 3.2669410880599 | validation: 2.7423531464302107]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2663400448385547		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 3.2663400448385547 | validation: 2.7312546498203383]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270003146638079		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 3.270003146638079 | validation: 2.739745237573252]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2834004048479093		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 3.2834004048479093 | validation: 2.7338704370361757]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268650580581683		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 3.268650580581683 | validation: 2.7132535848750137]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.293479930864055		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 3.293479930864055 | validation: 2.714445937772024]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2945058737852		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 3.2945058737852 | validation: 2.8043780699427066]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.296361070849032		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 3.296361070849032 | validation: 2.73629576527753]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2802500435671678		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 3.2802500435671678 | validation: 2.7464376276844478]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2784180589047707		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 3.2784180589047707 | validation: 2.8133052548404556]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302015645573075		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 3.302015645573075 | validation: 2.7162456225207463]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258907236549066		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 3.258907236549066 | validation: 2.7908613746278452]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.295467160255966		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 3.295467160255966 | validation: 2.734648231140353]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2868939415073806		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 3.2868939415073806 | validation: 2.7615936386118176]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.286388306910868		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 3.286388306910868 | validation: 2.7624065754903286]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275792928448567		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 3.275792928448567 | validation: 2.7253766038792766]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.293378483989715		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 3.293378483989715 | validation: 2.7093998066758673]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2910105341492586		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 3.2910105341492586 | validation: 2.7257927186166495]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2612135582441137		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 3.2612135582441137 | validation: 2.704093809076293]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.284967219434632		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 3.284967219434632 | validation: 2.7100568163280627]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2775721399555913		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 3.2775721399555913 | validation: 2.747659569348203]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2686961038171747		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 3.2686961038171747 | validation: 2.715995115387502]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269272402025252		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 3.269272402025252 | validation: 2.7216517269261464]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2684581669410977		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 3.2684581669410977 | validation: 2.7142761836661125]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268294663731264		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 3.268294663731264 | validation: 2.6977293002284783]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.284070654881318		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 3.284070654881318 | validation: 2.7296175649974677]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2778376477935773		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 3.2778376477935773 | validation: 2.7265911742123206]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2666250218038457		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 3.2666250218038457 | validation: 2.740442600865791]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2762613415989152		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 3.2762613415989152 | validation: 2.7083578160092325]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2620565300322917		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 3.2620565300322917 | validation: 2.725884130978185]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2729273652232185		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 3.2729273652232185 | validation: 2.725046314427997]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2680700856203515		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 3.2680700856203515 | validation: 2.7597416544150017]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.289416400144585		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 3.289416400144585 | validation: 2.730987818397634]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2566709491458736		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 3.2566709491458736 | validation: 2.7577282540349337]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.272979515777101		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 3.272979515777101 | validation: 2.7622672593452786]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.277873849490265		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 3.277873849490265 | validation: 2.709074361746307]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302921397992523		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 3.302921397992523 | validation: 2.7514253202933054]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280319267303423		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 3.280319267303423 | validation: 2.7061567297272324]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3623764338946462		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 3.3623764338946462 | validation: 2.7524959605037633]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2743792009015733		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 3.2743792009015733 | validation: 2.7456245235942687]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275415454685948		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 3.275415454685948 | validation: 2.7240537446326933]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.266705424576615		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 3.266705424576615 | validation: 2.712615122200646]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261611804632166		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 3.261611804632166 | validation: 2.7573013268831836]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280958240315371		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 3.280958240315371 | validation: 2.697879658804643]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2493389689440364		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 3.2493389689440364 | validation: 2.703853526278481]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2823926449921723		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 3.2823926449921723 | validation: 2.746365275614152]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3046809284513685		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 3.3046809284513685 | validation: 2.6904958737547737]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.282649928306936		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 3.282649928306936 | validation: 2.8372497198334363]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2857241822651755		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 3.2857241822651755 | validation: 2.6932171359747894]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.249822786645163		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 3.249822786645163 | validation: 2.7163616504000525]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.263061631004241		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 3.263061631004241 | validation: 2.8080364315755584]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2694265031673573		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 3.2694265031673573 | validation: 2.6999567617083113]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2538912111527365		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 3.2538912111527365 | validation: 2.707655485068047]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2949445701160576		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 3.2949445701160576 | validation: 2.711454853973306]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2644747095479936		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 3.2644747095479936 | validation: 2.703800733669375]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2576348037150087		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 3.2576348037150087 | validation: 2.7033863389597856]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2446428961422074		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 3.2446428961422074 | validation: 2.7042926948533625]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3170993339405546		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 3.3170993339405546 | validation: 2.742612654264001]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268136634169412		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 3.268136634169412 | validation: 2.7618289272445464]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280213358438394		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 3.280213358438394 | validation: 2.7250458536061304]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.281924758778415		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 3.281924758778415 | validation: 2.7319887625320907]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275516848502286		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 3.275516848502286 | validation: 2.7189695820426767]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253579963086908		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 3.253579963086908 | validation: 2.7261584605804035]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268083242769891		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 3.268083242769891 | validation: 2.7019295326398276]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2514067772220305		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 3.2514067772220305 | validation: 2.70898671108156]
	TIME [epoch: 11.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26625369209852		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 3.26625369209852 | validation: 2.74774332752065]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.274889890338473		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 3.274889890338473 | validation: 2.8395091905935943]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3003842711562292		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 3.3003842711562292 | validation: 2.7375182470890684]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2654659911942403		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 3.2654659911942403 | validation: 2.6992325559946515]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2591257775971574		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 3.2591257775971574 | validation: 2.7454740137359166]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256013837358547		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 3.256013837358547 | validation: 2.7101133835538556]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258738588545035		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 3.258738588545035 | validation: 2.8068142959158644]
	TIME [epoch: 11.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.297160571340303		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 3.297160571340303 | validation: 2.738704392612338]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273770120204289		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 3.273770120204289 | validation: 2.7241860840385077]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.263814091771212		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 3.263814091771212 | validation: 2.7162926230904305]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.272838142490107		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 3.272838142490107 | validation: 2.7096578992570155]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269099956506942		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 3.269099956506942 | validation: 2.6982637226649917]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2524343171903856		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 3.2524343171903856 | validation: 2.71032728031197]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2548679345463505		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 3.2548679345463505 | validation: 2.7010831242933317]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.255827724323008		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 3.255827724323008 | validation: 2.756207255120453]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.276216628861689		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 3.276216628861689 | validation: 2.7233020580316163]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2573218965706885		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 3.2573218965706885 | validation: 2.7744219402832653]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3032108601090604		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 3.3032108601090604 | validation: 2.7528745732480155]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26800344684219		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 3.26800344684219 | validation: 2.699100482369136]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.277569506222709		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 3.277569506222709 | validation: 2.7239388031585223]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.286612460524628		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 3.286612460524628 | validation: 2.800884522414911]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2944516745366705		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 3.2944516745366705 | validation: 2.72057778786223]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2800820201540097		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 3.2800820201540097 | validation: 2.803609053050758]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.303146856512641		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 3.303146856512641 | validation: 2.752092568373348]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2580231819235794		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 3.2580231819235794 | validation: 2.721065314634917]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2546974703573683		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 3.2546974703573683 | validation: 2.703961471001683]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2594231088424483		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 3.2594231088424483 | validation: 2.7141977870189824]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2642922268203467		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 3.2642922268203467 | validation: 2.711508946121814]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.248512886400827		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 3.248512886400827 | validation: 2.7147641705864185]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2781586676041345		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 3.2781586676041345 | validation: 2.7014137223316683]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2841902825583285		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 3.2841902825583285 | validation: 2.7613625854971935]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.259323410357522		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 3.259323410357522 | validation: 2.7314428044040233]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2637516484277134		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 3.2637516484277134 | validation: 3.019136939993586]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.402116994614744		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 3.402116994614744 | validation: 2.769207914536371]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273937605063612		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 3.273937605063612 | validation: 2.7132080262867317]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253027217145246		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 3.253027217145246 | validation: 2.7932561446435877]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2947766848514983		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 3.2947766848514983 | validation: 2.728427799974793]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269689903779609		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 3.269689903779609 | validation: 2.731779516519609]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2687253235074074		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 3.2687253235074074 | validation: 2.7291370686672773]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2666348961026976		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 3.2666348961026976 | validation: 2.766112826891943]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.266072907139084		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 3.266072907139084 | validation: 2.776872523835388]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2756741475259443		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 3.2756741475259443 | validation: 2.7373636064550655]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2570069575010714		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 3.2570069575010714 | validation: 2.7304554370731062]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.272657345312151		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 3.272657345312151 | validation: 2.713753084489893]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2682485589698076		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 3.2682485589698076 | validation: 2.69968919682954]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.257304336892511		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 3.257304336892511 | validation: 2.723622374748742]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.255878075256478		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 3.255878075256478 | validation: 2.709404607332193]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2594788588945764		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 3.2594788588945764 | validation: 2.70970785613949]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256049948440933		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 3.256049948440933 | validation: 2.7055008937297735]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2568932123666308		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 3.2568932123666308 | validation: 2.711905725371356]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250036286393284		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 3.250036286393284 | validation: 2.737079305973246]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2678636655103515		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 3.2678636655103515 | validation: 2.803473157894255]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2930678348151936		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 3.2930678348151936 | validation: 2.7754600344674127]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283682520475865		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 3.283682520475865 | validation: 2.700146197942994]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2782884072335063		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 3.2782884072335063 | validation: 2.7569943665559857]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.26861632778675		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 3.26861632778675 | validation: 2.7699755134671062]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.290278305585401		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 3.290278305585401 | validation: 2.7467974166025386]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.271482049424358		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 3.271482049424358 | validation: 2.714582555167458]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.259808192938159		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 3.259808192938159 | validation: 2.7492227690495565]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.253873109121373		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 3.253873109121373 | validation: 2.7046536660017533]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2469457714105534		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 3.2469457714105534 | validation: 2.713788497046719]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2527058327869414		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 3.2527058327869414 | validation: 2.7019604599040985]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2463024106287244		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 3.2463024106287244 | validation: 2.7019656537662002]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2451472819174003		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 3.2451472819174003 | validation: 2.7163520706267823]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2466677641642794		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 3.2466677641642794 | validation: 2.727338136068629]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.265336360591733		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 3.265336360591733 | validation: 2.6957059918508763]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.242027505065902		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 3.242027505065902 | validation: 2.7298039315122264]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2415985286131477		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 3.2415985286131477 | validation: 2.765825796925559]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2517211350740816		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 3.2517211350740816 | validation: 2.70208778860102]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2776115039742284		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 3.2776115039742284 | validation: 2.697552739420567]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.243448194706153		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 3.243448194706153 | validation: 2.710576665274696]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2475396521029833		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 3.2475396521029833 | validation: 2.698844547057708]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.248662153891125		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 3.248662153891125 | validation: 2.7041376024664645]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.264267811023981		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 3.264267811023981 | validation: 2.744659858947638]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2685076132287514		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 3.2685076132287514 | validation: 2.703644263731797]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2724778434425064		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 3.2724778434425064 | validation: 2.743922940994388]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3026627129938855		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 3.3026627129938855 | validation: 2.728379397013999]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2448314913665643		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 3.2448314913665643 | validation: 2.847270981890996]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3160770398059025		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 3.3160770398059025 | validation: 2.7430394770714304]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.262575611288267		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 3.262575611288267 | validation: 2.7100945437904307]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246139374974064		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 3.246139374974064 | validation: 2.7191415398710728]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2487953538569774		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 3.2487953538569774 | validation: 2.7186764679077986]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2525712553831667		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 3.2525712553831667 | validation: 2.735349759712766]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2935907483667974		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 3.2935907483667974 | validation: 2.7004297296732176]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.270070254666153		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 3.270070254666153 | validation: 2.735655973317031]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252677876125621		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 3.252677876125621 | validation: 2.702716033815725]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2386247820542104		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 3.2386247820542104 | validation: 2.69295050028897]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2392339280438867		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 3.2392339280438867 | validation: 2.7093554338668513]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.247544977915433		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 3.247544977915433 | validation: 2.734911539992307]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.240571126350657		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 3.240571126350657 | validation: 2.6983889340992637]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2621974515841363		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 3.2621974515841363 | validation: 2.7527210855263657]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2665854129620904		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 3.2665854129620904 | validation: 2.715885940141419]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2549314132086162		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 3.2549314132086162 | validation: 2.692570445198514]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2455457864408084		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 3.2455457864408084 | validation: 2.718969267442465]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.256709529491228		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 3.256709529491228 | validation: 2.6980053570759095]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2448121434755426		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 3.2448121434755426 | validation: 2.708920700531321]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.280168342886377		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 3.280168342886377 | validation: 2.7562800301243153]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2619166983238603		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 3.2619166983238603 | validation: 2.6904731789601644]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_712.pth
	Model improved!!!
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2452758218622106		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 3.2452758218622106 | validation: 2.711762197957676]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252126747662023		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 3.252126747662023 | validation: 2.709217945341535]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245636854299858		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 3.245636854299858 | validation: 2.711123376149742]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2427392738340375		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 3.2427392738340375 | validation: 2.708376343802952]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2665798180834793		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 3.2665798180834793 | validation: 2.7297024345982095]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.243126555923987		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 3.243126555923987 | validation: 2.7213524771830326]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.259740080602162		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 3.259740080602162 | validation: 2.74272634803055]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2820238600050042		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 3.2820238600050042 | validation: 2.6948965443952897]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2511683861629477		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 3.2511683861629477 | validation: 2.73311078138219]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2445871608052106		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 3.2445871608052106 | validation: 2.691369404824111]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2420198933468614		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 3.2420198933468614 | validation: 2.706070855351442]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.248174358292651		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 3.248174358292651 | validation: 2.747563724397271]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.281612704801481		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 3.281612704801481 | validation: 2.703086843870458]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2658483644909184		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 3.2658483644909184 | validation: 2.7171668542879717]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245552936597803		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 3.245552936597803 | validation: 2.692736765030502]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2403545922711814		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 3.2403545922711814 | validation: 2.6912934241054645]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252784744491974		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 3.252784744491974 | validation: 2.7235502528714153]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2448421621043133		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 3.2448421621043133 | validation: 2.7032061432084955]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244886239837899		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 3.244886239837899 | validation: 2.7041778559195064]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.247992734973646		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 3.247992734973646 | validation: 2.7033820037017042]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.249648978395159		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 3.249648978395159 | validation: 2.6921162488205925]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244248717975875		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 3.244248717975875 | validation: 2.696011330404133]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.283198051135854		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 3.283198051135854 | validation: 2.692596323744733]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.247370747976515		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 3.247370747976515 | validation: 2.7198815721682075]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.25874972386239		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 3.25874972386239 | validation: 2.6890702178533195]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2429316197130937		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 3.2429316197130937 | validation: 2.689300135391499]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239088673412667		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 3.239088673412667 | validation: 2.704029275194399]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239282750175486		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 3.239282750175486 | validation: 2.6852126238498437]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_740.pth
	Model improved!!!
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2410228689125216		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 3.2410228689125216 | validation: 2.725981842259926]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.254407216700839		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 3.254407216700839 | validation: 2.692987456705198]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2457609011758892		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 3.2457609011758892 | validation: 2.705673158959259]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2597339582911005		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 3.2597339582911005 | validation: 2.690226921195204]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2390471487641483		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 3.2390471487641483 | validation: 2.7003481870043955]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2457115018039446		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 3.2457115018039446 | validation: 2.6924085913832134]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234823762541925		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 3.234823762541925 | validation: 2.6934282790520423]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24433521357471		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 3.24433521357471 | validation: 2.690065537102846]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246040147351709		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 3.246040147351709 | validation: 2.736721970843185]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2738388899518864		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 3.2738388899518864 | validation: 2.71170873624019]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2499528127315864		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 3.2499528127315864 | validation: 2.697473321995007]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234896510152056		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 3.234896510152056 | validation: 2.69428541940641]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2837667956781162		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 3.2837667956781162 | validation: 2.6948068323343444]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246201864385311		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 3.246201864385311 | validation: 2.7257123889425605]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2420702508362043		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 3.2420702508362043 | validation: 2.692500528750342]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2596790505693383		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 3.2596790505693383 | validation: 2.7006042448173875]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246438263907504		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 3.246438263907504 | validation: 2.6900269674105455]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.237651142648833		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 3.237651142648833 | validation: 2.701726744868619]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236053649856006		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 3.236053649856006 | validation: 2.7354458137334228]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2641888317301957		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 3.2641888317301957 | validation: 2.698461708027309]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2380145658131188		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 3.2380145658131188 | validation: 2.7222765528916093]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250671697494324		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 3.250671697494324 | validation: 2.6895970071091586]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2459048578689558		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 3.2459048578689558 | validation: 2.7057853268636816]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2395749587041287		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 3.2395749587041287 | validation: 2.698608980211551]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231458211303068		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 3.231458211303068 | validation: 2.6966108361391616]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244635633078925		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 3.244635633078925 | validation: 2.704438928721513]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241269244974558		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 3.241269244974558 | validation: 2.6875475455688043]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236793066848697		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 3.236793066848697 | validation: 2.6898948465010943]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.265057631363872		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 3.265057631363872 | validation: 2.710587242462598]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2646041318431163		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 3.2646041318431163 | validation: 2.722573198529428]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2437656024129913		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 3.2437656024129913 | validation: 2.6893665311461827]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2325549792677295		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 3.2325549792677295 | validation: 2.681590681451396]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2343015724058333		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 3.2343015724058333 | validation: 2.686718935792394]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.249621252475162		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 3.249621252475162 | validation: 2.727169757108513]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245699616010628		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 3.245699616010628 | validation: 2.6866064918118133]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2442449490724417		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 3.2442449490724417 | validation: 2.6912799641110303]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2335185439092564		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 3.2335185439092564 | validation: 2.7161411893592]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2702447112787394		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 3.2702447112787394 | validation: 2.69394308648157]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2618812980403162		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 3.2618812980403162 | validation: 2.7114016738105176]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.240228684007471		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 3.240228684007471 | validation: 2.6927833824890217]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251745682500431		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 3.251745682500431 | validation: 2.7052210225176747]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2468909418611167		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 3.2468909418611167 | validation: 2.689783690413823]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230874547200096		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 3.230874547200096 | validation: 2.6959397839949486]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2383931113621376		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 3.2383931113621376 | validation: 2.7021424191477936]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241492485854248		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 3.241492485854248 | validation: 2.6852493918079325]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2416515069648932		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 3.2416515069648932 | validation: 2.7166183707273026]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239858068658063		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 3.239858068658063 | validation: 2.7244499053097924]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.242843263518428		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 3.242843263518428 | validation: 2.7142467869097198]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2598119204576985		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 3.2598119204576985 | validation: 2.7201384500644554]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2640290629900734		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 3.2640290629900734 | validation: 2.6871592536281983]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2342863164125912		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 3.2342863164125912 | validation: 2.6939265049331556]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241475194903267		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 3.241475194903267 | validation: 2.6873994790636493]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234824537529634		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 3.234824537529634 | validation: 2.6889839459217515]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233317065200846		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 3.233317065200846 | validation: 2.680082312990896]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_794.pth
	Model improved!!!
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2359175378235947		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 3.2359175378235947 | validation: 2.7021734233109487]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24141865947924		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 3.24141865947924 | validation: 2.72367070612813]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.260371154216047		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 3.260371154216047 | validation: 2.732683669258654]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2441142407399255		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 3.2441142407399255 | validation: 2.700601141116316]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2392066020005297		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 3.2392066020005297 | validation: 2.6865586307199165]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252055274403496		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 3.252055274403496 | validation: 2.6932977616260194]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236739736795935		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 3.236739736795935 | validation: 2.687200153513074]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.235450648528812		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 3.235450648528812 | validation: 2.6777561027212533]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.243046942230837		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 3.243046942230837 | validation: 2.6945172824668013]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2577962197978656		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 3.2577962197978656 | validation: 2.7020201294033424]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2346475635179184		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 3.2346475635179184 | validation: 2.696434591967369]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2329958665683804		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 3.2329958665683804 | validation: 2.6870865249933193]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2351622180893456		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 3.2351622180893456 | validation: 2.68869517800978]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2315354635029516		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 3.2315354635029516 | validation: 2.7376796107262664]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244034368342706		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 3.244034368342706 | validation: 2.681117937040706]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228360380490501		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 3.228360380490501 | validation: 2.6959139178832867]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2518316154005893		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 3.2518316154005893 | validation: 2.6908027382467976]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2700418928258506		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 3.2700418928258506 | validation: 2.7682863808671203]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3234625458667155		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 3.3234625458667155 | validation: 2.713057329330796]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2410734689021057		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 3.2410734689021057 | validation: 2.69290596738556]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2333115665367522		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 3.2333115665367522 | validation: 2.7056971836838164]
	TIME [epoch: 11.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230190469569795		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 3.230190469569795 | validation: 2.6820624211253046]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2338961416440215		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 3.2338961416440215 | validation: 2.701455136718873]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2339299455048582		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 3.2339299455048582 | validation: 2.686706152738125]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.247003148811877		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 3.247003148811877 | validation: 2.68184805012476]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.229683755219573		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 3.229683755219573 | validation: 2.690413859133065]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2377674090514823		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 3.2377674090514823 | validation: 2.7140157741325424]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.249161864200916		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 3.249161864200916 | validation: 2.685478183547522]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.238155376575384		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 3.238155376575384 | validation: 2.702703940566276]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234553880967855		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 3.234553880967855 | validation: 2.723822418406261]
	TIME [epoch: 11.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2402155488193287		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 3.2402155488193287 | validation: 2.685204545862039]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231361157486714		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 3.231361157486714 | validation: 2.6895723245106473]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225963662012014		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 3.225963662012014 | validation: 2.6816491164124794]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.242025673842819		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 3.242025673842819 | validation: 2.702392826359237]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250890014182585		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 3.250890014182585 | validation: 2.6967314188062694]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2533656669720834		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 3.2533656669720834 | validation: 2.6993996042220187]
	TIME [epoch: 11.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2425862023831424		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 3.2425862023831424 | validation: 2.6929995421482253]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2324172972450267		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 3.2324172972450267 | validation: 2.7286315184475876]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2406029966821976		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 3.2406029966821976 | validation: 2.680644316953854]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.235205793459598		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 3.235205793459598 | validation: 2.690568901522055]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245313281563844		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 3.245313281563844 | validation: 2.70616963476215]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232148959189945		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 3.232148959189945 | validation: 2.6874140881887163]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2300533092230124		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 3.2300533092230124 | validation: 2.6960623570384996]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239120342055537		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 3.239120342055537 | validation: 2.6783464969372495]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233991489551914		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 3.233991489551914 | validation: 2.6799297793085475]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2291072030071177		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 3.2291072030071177 | validation: 2.683602700020582]
	TIME [epoch: 11.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22985824533353		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 3.22985824533353 | validation: 2.6941877716972717]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2393028533888666		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 3.2393028533888666 | validation: 2.690041265265242]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2437612222035286		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 3.2437612222035286 | validation: 2.6803129555063463]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2332739092388523		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 3.2332739092388523 | validation: 2.690589638375944]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230094547056398		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 3.230094547056398 | validation: 2.709307628825067]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250579871412593		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 3.250579871412593 | validation: 2.7022023237789847]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241890776822172		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 3.241890776822172 | validation: 2.7160745262272004]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239882133893262		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 3.239882133893262 | validation: 2.6803225880589387]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234233208961334		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 3.234233208961334 | validation: 2.736288937033602]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.268376456459327		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 3.268376456459327 | validation: 2.703027589183128]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244929244723356		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 3.244929244723356 | validation: 2.685472685436395]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232836451376151		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 3.232836451376151 | validation: 2.6821609969334683]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2268423713013488		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 3.2268423713013488 | validation: 2.676653576481771]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227983410921569		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 3.227983410921569 | validation: 2.706208656177724]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2382859654031266		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 3.2382859654031266 | validation: 2.6812388491774555]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2288075544162194		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 3.2288075544162194 | validation: 2.725960513435523]
	TIME [epoch: 11.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239455768580112		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 3.239455768580112 | validation: 2.681458113238439]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2288930039113035		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 3.2288930039113035 | validation: 2.6850804684966376]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239935756592115		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 3.239935756592115 | validation: 2.7162318694947136]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.235485701154954		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 3.235485701154954 | validation: 2.6779592134284655]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221465459185609		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 3.221465459185609 | validation: 2.677478365011981]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220994936652121		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 3.220994936652121 | validation: 2.6801681744707286]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.238160562838363		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 3.238160562838363 | validation: 2.6849146270548783]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2368893134374503		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 3.2368893134374503 | validation: 2.7167717237787077]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2399173807108017		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 3.2399173807108017 | validation: 2.693198603577764]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2409207046059043		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 3.2409207046059043 | validation: 2.689543519445455]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2367938427746434		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 3.2367938427746434 | validation: 2.702363775452949]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.229846767223858		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 3.229846767223858 | validation: 2.6741282535936253]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2476782958972215		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 3.2476782958972215 | validation: 2.694508302152467]
	TIME [epoch: 11.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244490023785746		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 3.244490023785746 | validation: 2.6819889787974613]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227028832398535		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 3.227028832398535 | validation: 2.679357104304805]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232122133150819		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 3.232122133150819 | validation: 2.6778500234803735]
	TIME [epoch: 11.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2353703983052933		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 3.2353703983052933 | validation: 2.6851661512595117]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2269442000735307		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 3.2269442000735307 | validation: 2.679293334800917]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2296434032317567		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 3.2296434032317567 | validation: 2.686646766410749]
	TIME [epoch: 11.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.242211518328178		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 3.242211518328178 | validation: 2.6860561616623135]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224522338027942		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 3.224522338027942 | validation: 2.689148583297405]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2400858828813393		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 3.2400858828813393 | validation: 2.6932716641347203]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2405298977729995		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 3.2405298977729995 | validation: 2.674321222289906]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22671450486599		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 3.22671450486599 | validation: 2.6832659746012233]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2262660121549125		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 3.2262660121549125 | validation: 2.6801142329274934]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2216354570576815		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 3.2216354570576815 | validation: 2.680773951059626]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2225167091583575		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 3.2225167091583575 | validation: 2.6859133503110746]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252500098827069		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 3.252500098827069 | validation: 2.693403296939718]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24262014822225		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 3.24262014822225 | validation: 2.7142793357181905]
	TIME [epoch: 11.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241406124371329		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 3.241406124371329 | validation: 2.684793779777773]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.229643191710756		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 3.229643191710756 | validation: 2.67873075819818]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2268201246766357		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 3.2268201246766357 | validation: 2.687074370877564]
	TIME [epoch: 11.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230108102649984		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 3.230108102649984 | validation: 2.685129030795929]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2359830051350014		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 3.2359830051350014 | validation: 2.6876451517387876]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2354057754642476		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 3.2354057754642476 | validation: 2.687876646103955]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2240291860144166		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 3.2240291860144166 | validation: 2.7003215713796886]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230795633846025		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 3.230795633846025 | validation: 2.7069574369752774]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2555575929476137		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 3.2555575929476137 | validation: 2.67817353321463]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2264941162292495		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 3.2264941162292495 | validation: 2.6845385799989794]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228917905330474		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 3.228917905330474 | validation: 2.6924909568741375]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2227436755829335		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 3.2227436755829335 | validation: 2.672510755380179]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2375587217606325		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 3.2375587217606325 | validation: 2.6761530203881705]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22299013927933		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 3.22299013927933 | validation: 2.709890744057988]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250701034963134		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 3.250701034963134 | validation: 2.66449789635353]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_900.pth
	Model improved!!!
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225886639473975		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 3.225886639473975 | validation: 2.6893286195839257]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2459861302730877		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 3.2459861302730877 | validation: 2.7022815848810384]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2366017256936166		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 3.2366017256936166 | validation: 2.6839661865293944]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226349159666413		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 3.226349159666413 | validation: 2.700296754296346]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2429489928353146		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 3.2429489928353146 | validation: 2.693496134158312]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236536343241892		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 3.236536343241892 | validation: 2.673908294190767]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2237877850098946		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 3.2237877850098946 | validation: 2.6801351231649977]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2314267980221376		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 3.2314267980221376 | validation: 2.6822329846099593]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2266108623482395		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 3.2266108623482395 | validation: 2.694600681173787]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246979481203782		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 3.246979481203782 | validation: 2.6974575638226743]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230118777872877		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 3.230118777872877 | validation: 2.679496007164155]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227265336445168		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 3.227265336445168 | validation: 2.6770698043774424]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234590550570076		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 3.234590550570076 | validation: 2.6864997360856075]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228120527662924		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 3.228120527662924 | validation: 2.7300535245587425]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.257425363157663		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 3.257425363157663 | validation: 2.6830075487228333]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226376700824211		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 3.226376700824211 | validation: 2.679625218435788]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2311623549961883		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 3.2311623549961883 | validation: 2.696968723901721]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2359302982231566		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 3.2359302982231566 | validation: 2.6802629602641033]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222194546543981		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 3.222194546543981 | validation: 2.6983740909323473]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2338319781530696		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 3.2338319781530696 | validation: 2.671791313016811]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2232728941860347		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 3.2232728941860347 | validation: 2.6933836094180585]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232142392455152		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 3.232142392455152 | validation: 2.7015320887286145]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2443261387911626		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 3.2443261387911626 | validation: 2.6882322853095912]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234917191026503		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 3.234917191026503 | validation: 2.6836808498868527]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2258533948884924		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 3.2258533948884924 | validation: 2.680345144637792]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2354890626890978		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 3.2354890626890978 | validation: 2.683135758688527]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2278680886395694		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 3.2278680886395694 | validation: 2.6855060914713085]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2306926699303093		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 3.2306926699303093 | validation: 2.691571338640466]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2330500143046983		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 3.2330500143046983 | validation: 2.6817546827769227]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2206143517144348		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 3.2206143517144348 | validation: 2.6781106913747266]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225440948242146		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 3.225440948242146 | validation: 2.674381988668564]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2239148794782677		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 3.2239148794782677 | validation: 2.671165309403808]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2218324657238777		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 3.2218324657238777 | validation: 2.6778195572435384]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2285271445440094		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 3.2285271445440094 | validation: 2.6803624062165876]
	TIME [epoch: 11.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2298123986902727		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 3.2298123986902727 | validation: 2.679702572419901]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2282799891650087		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 3.2282799891650087 | validation: 2.7226143293336134]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2353243610365783		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 3.2353243610365783 | validation: 2.6833329300864266]
	TIME [epoch: 11.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2291550910019744		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 3.2291550910019744 | validation: 2.68044668340728]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221687338019525		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 3.221687338019525 | validation: 2.6797202899002674]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223826388092541		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 3.223826388092541 | validation: 2.6840893599765074]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2492667388165657		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 3.2492667388165657 | validation: 2.6998981450731425]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22070721636634		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 3.22070721636634 | validation: 2.694204925562243]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2267275092960985		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 3.2267275092960985 | validation: 2.6921144775539774]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2255617768771234		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 3.2255617768771234 | validation: 2.6758681712070462]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2240511995249		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 3.2240511995249 | validation: 2.6828832313842907]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2274199262120327		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 3.2274199262120327 | validation: 2.6933151080322175]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2323922503341542		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 3.2323922503341542 | validation: 2.6768830786101625]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2271915594532876		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 3.2271915594532876 | validation: 2.7019788786588537]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2366041538316486		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 3.2366041538316486 | validation: 2.6992574949106904]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2373608616295666		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 3.2373608616295666 | validation: 2.6751647691525187]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2183248214011297		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 3.2183248214011297 | validation: 2.6779976706701585]
	TIME [epoch: 11.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22836579341737		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 3.22836579341737 | validation: 2.678628612764172]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2193455334167034		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 3.2193455334167034 | validation: 2.6825033562705336]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225014078287062		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 3.225014078287062 | validation: 2.6799680277373796]
	TIME [epoch: 11.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224496074799467		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 3.224496074799467 | validation: 2.6940158493271475]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246451848939716		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 3.246451848939716 | validation: 2.68517495542853]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2291699132489367		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 3.2291699132489367 | validation: 2.6877321614038596]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2260642026881867		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 3.2260642026881867 | validation: 2.6785559751788544]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223721647503792		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 3.223721647503792 | validation: 2.6896669391740677]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2261036989950123		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 3.2261036989950123 | validation: 2.6816990553077993]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2209846887828033		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 3.2209846887828033 | validation: 2.6729140831253098]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2280168964544447		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 3.2280168964544447 | validation: 2.69080425568265]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224852651234676		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 3.224852651234676 | validation: 2.674062434799001]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2206473673347453		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 3.2206473673347453 | validation: 2.685060492409333]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224923758373749		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 3.224923758373749 | validation: 2.675135994966869]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225443269756985		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 3.225443269756985 | validation: 2.6954361423839424]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2297722704642595		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 3.2297722704642595 | validation: 2.6949634434121776]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2232568778460546		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 3.2232568778460546 | validation: 2.6770336202598912]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2244024357382037		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 3.2244024357382037 | validation: 2.69356531353086]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223937405042285		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 3.223937405042285 | validation: 2.679368772586784]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225089898923854		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 3.225089898923854 | validation: 2.6800904244898693]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222674393758041		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 3.222674393758041 | validation: 2.6776923763622165]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2272551871468242		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 3.2272551871468242 | validation: 2.677501318263854]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224567617779976		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 3.224567617779976 | validation: 2.6839848295916022]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2212289797068263		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 3.2212289797068263 | validation: 2.6737185141418696]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2167372673351973		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 3.2167372673351973 | validation: 2.6682287135939347]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2195074028570714		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 3.2195074028570714 | validation: 2.678798014600795]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222854307350387		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 3.222854307350387 | validation: 2.690642371918001]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.233002214215624		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 3.233002214215624 | validation: 2.687943889727186]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234191338981947		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 3.234191338981947 | validation: 2.682631870317955]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219328404481801		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 3.219328404481801 | validation: 2.667516445534751]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2233281059462824		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 3.2233281059462824 | validation: 2.6761515750477014]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2235285851687485		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 3.2235285851687485 | validation: 2.681706436938801]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2269697991527426		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 3.2269697991527426 | validation: 2.6809445628414768]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2216242370972976		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 3.2216242370972976 | validation: 2.6770071947553835]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2216389633865297		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 3.2216389633865297 | validation: 2.680861558070217]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226883873379719		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 3.226883873379719 | validation: 2.6667599859399536]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223416440142125		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 3.223416440142125 | validation: 2.686022543648334]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232097702710253		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 3.232097702710253 | validation: 2.6941967887178873]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2322719716427066		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 3.2322719716427066 | validation: 2.6653313450891902]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224032868426402		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 3.224032868426402 | validation: 2.6739711548461247]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2224044174705706		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 3.2224044174705706 | validation: 2.6661293358999125]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220157209043171		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 3.220157209043171 | validation: 2.6644006289589757]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_993.pth
	Model improved!!!
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221345936983398		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 3.221345936983398 | validation: 2.672229063795772]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2232183237539873		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 3.2232183237539873 | validation: 2.6870523499170313]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2460025831370016		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 3.2460025831370016 | validation: 2.7133443201021454]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2284949403494814		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 3.2284949403494814 | validation: 2.681674406927326]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230330740820107		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 3.230330740820107 | validation: 2.679600722140965]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22185168988139		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 3.22185168988139 | validation: 2.675394429449513]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226702223986534		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 3.226702223986534 | validation: 2.691343675942763]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2330002944212652		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 3.2330002944212652 | validation: 2.6766541522809453]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2300211947350452		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 3.2300211947350452 | validation: 2.696750220355052]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2276032240192367		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 3.2276032240192367 | validation: 2.679632458939734]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2211191707981732		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 3.2211191707981732 | validation: 2.682263059779468]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223848829280897		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 3.223848829280897 | validation: 2.6816939818570407]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2240865290216076		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 3.2240865290216076 | validation: 2.6923651061571707]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2238429557341286		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 3.2238429557341286 | validation: 2.6686020245542323]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2204891915008007		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 3.2204891915008007 | validation: 2.678878427426225]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22968948459859		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 3.22968948459859 | validation: 2.6689126722422594]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2184526593734475		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 3.2184526593734475 | validation: 2.685147313835823]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199033014011382		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 3.2199033014011382 | validation: 2.6698164875601513]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2204884253714066		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 3.2204884253714066 | validation: 2.677679616836885]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2255242028564406		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 3.2255242028564406 | validation: 2.6785230383628447]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2257258178929202		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 3.2257258178929202 | validation: 2.6882587784950727]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.229943710329694		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 3.229943710329694 | validation: 2.6806793210170428]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2241323091528233		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 3.2241323091528233 | validation: 2.6802320211426554]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219182175740549		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 3.219182175740549 | validation: 2.669175096616813]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216769253696645		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 3.216769253696645 | validation: 2.6699501960802254]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2268418130024736		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 3.2268418130024736 | validation: 2.70333870341595]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227291725671395		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 3.227291725671395 | validation: 2.670121914174253]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2174102500302846		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 3.2174102500302846 | validation: 2.667959672556989]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2245481663665703		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 3.2245481663665703 | validation: 2.6773831074579006]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2434380237856577		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 3.2434380237856577 | validation: 2.693520743392646]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231085134532819		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 3.231085134532819 | validation: 2.70081728135976]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225868084142788		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 3.225868084142788 | validation: 2.6749688616924256]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182029939734527		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 3.2182029939734527 | validation: 2.6849487521942597]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2262191412719368		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 3.2262191412719368 | validation: 2.6704682305197944]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2176507062134063		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 3.2176507062134063 | validation: 2.672721844434179]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2202604077175554		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 3.2202604077175554 | validation: 2.684444315601287]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2209285876227405		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 3.2209285876227405 | validation: 2.684738773653347]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2149206629284555		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 3.2149206629284555 | validation: 2.664919757223511]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2172662284404305		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 3.2172662284404305 | validation: 2.6992815470482663]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228013373325281		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 3.228013373325281 | validation: 2.6750471276959162]
	TIME [epoch: 11.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227927037843317		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 3.227927037843317 | validation: 2.676186225247908]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222321654405683		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 3.222321654405683 | validation: 2.6691014663642667]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199656957228315		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 3.2199656957228315 | validation: 2.6779436431772923]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219552333162165		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 3.219552333162165 | validation: 2.6720827398946545]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219969154743941		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 3.219969154743941 | validation: 2.67830813990874]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22151198492293		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 3.22151198492293 | validation: 2.6743219350685075]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199374872411526		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 3.2199374872411526 | validation: 2.673600611672252]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2238094433683098		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 3.2238094433683098 | validation: 2.664616598013899]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2162029745350087		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 3.2162029745350087 | validation: 2.6723912116812416]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2196710602119416		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 3.2196710602119416 | validation: 2.677060688095329]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2222900005023782		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 3.2222900005023782 | validation: 2.6732701692904164]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2169236555118594		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 3.2169236555118594 | validation: 2.6770359082214736]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218819153951666		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 3.218819153951666 | validation: 2.6823345784556576]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2227999691415397		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 3.2227999691415397 | validation: 2.6780920312278313]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232423817799358		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 3.232423817799358 | validation: 2.672452054651937]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2247578628645597		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 3.2247578628645597 | validation: 2.6904312890275786]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2243388737277234		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 3.2243388737277234 | validation: 2.6695758156482157]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217216718977371		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 3.217216718977371 | validation: 2.667314797111321]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217688309462537		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 3.217688309462537 | validation: 2.677042812478108]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2179235314229637		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 3.2179235314229637 | validation: 2.673507747764168]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2191026170460884		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 3.2191026170460884 | validation: 2.6694473999161548]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2239080191137974		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 3.2239080191137974 | validation: 2.6888208786280297]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2350497241304907		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 3.2350497241304907 | validation: 2.6910302269928406]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.236371937648279		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 3.236371937648279 | validation: 2.6772086532566743]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2192192509371345		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 3.2192192509371345 | validation: 2.676317413457351]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218132935941891		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 3.218132935941891 | validation: 2.680856126214237]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.226906392511499		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 3.226906392511499 | validation: 2.6682331152724625]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221780464329044		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 3.221780464329044 | validation: 2.6719879048026765]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2185200080450667		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 3.2185200080450667 | validation: 2.6680636526635797]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2189778153676967		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 3.2189778153676967 | validation: 2.6735162985216]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2239679220133017		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 3.2239679220133017 | validation: 2.6866086711350334]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2191124075054094		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 3.2191124075054094 | validation: 2.6712957742259937]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220467463810987		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 3.220467463810987 | validation: 2.6938032532146945]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250633902574742		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 3.250633902574742 | validation: 2.684744447128685]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222669969860418		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 3.222669969860418 | validation: 2.673676040291137]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220463923866335		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 3.220463923866335 | validation: 2.675153708696777]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2164004108754187		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 3.2164004108754187 | validation: 2.6760517967227795]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182725804099706		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 3.2182725804099706 | validation: 2.6782504896237063]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2166627304448987		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 3.2166627304448987 | validation: 2.666918574891696]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2188384420480496		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 3.2188384420480496 | validation: 2.673228190573691]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2143778933328826		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 3.2143778933328826 | validation: 2.6771813282999575]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2212071348743407		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 3.2212071348743407 | validation: 2.675651746555125]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218529576411867		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 3.218529576411867 | validation: 2.6645310759783447]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130263651267477		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 3.2130263651267477 | validation: 2.6780799050554083]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2206118398462693		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 3.2206118398462693 | validation: 2.673940556934084]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2191739771759806		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 3.2191739771759806 | validation: 2.6702467148841356]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2214261755404827		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 3.2214261755404827 | validation: 2.6778571613104827]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2224047523592754		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 3.2224047523592754 | validation: 2.664352727872869]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217484038096945		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 3.217484038096945 | validation: 2.669377376040665]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219293032693108		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 3.219293032693108 | validation: 2.683467827535363]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220162740709343		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 3.220162740709343 | validation: 2.6704422387056126]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2231419005777773		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 3.2231419005777773 | validation: 2.668790274254472]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2212232435098356		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 3.2212232435098356 | validation: 2.6899314669843637]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220204715668804		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 3.220204715668804 | validation: 2.670993491874944]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155798276893393		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 3.2155798276893393 | validation: 2.6724151741643936]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2148075334156765		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 3.2148075334156765 | validation: 2.6799346490287643]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2221217118114662		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 3.2221217118114662 | validation: 2.6684485317717406]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2162690362803112		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 3.2162690362803112 | validation: 2.6649298884109482]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2138678162349907		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 3.2138678162349907 | validation: 2.6742062087447454]
	TIME [epoch: 11.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217209480598826		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 3.217209480598826 | validation: 2.6603457766047747]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1093.pth
	Model improved!!!
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217027687716743		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 3.217027687716743 | validation: 2.672468982304082]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217700850428705		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 3.217700850428705 | validation: 2.672146997066722]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130025360202468		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 3.2130025360202468 | validation: 2.6699956079655793]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21794569191392		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 3.21794569191392 | validation: 2.666006292432021]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219654634103387		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 3.219654634103387 | validation: 2.6780130927273227]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223639102028484		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 3.223639102028484 | validation: 2.6610767398832924]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221513194713996		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 3.221513194713996 | validation: 2.6738928054608095]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2234652130600505		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 3.2234652130600505 | validation: 2.69236308748262]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.228926764799159		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 3.228926764799159 | validation: 2.6792679126319263]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2226503128313957		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 3.2226503128313957 | validation: 2.6653852067565142]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2197522697607237		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 3.2197522697607237 | validation: 2.6692015014078994]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214223534609291		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 3.214223534609291 | validation: 2.6696002328311885]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2154613405071673		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 3.2154613405071673 | validation: 2.6702848783074775]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217235459358471		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 3.217235459358471 | validation: 2.6724647834339077]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2170524439627437		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 3.2170524439627437 | validation: 2.6706310239408446]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119718446633154		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 3.2119718446633154 | validation: 2.6619182773323455]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182026338101686		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 3.2182026338101686 | validation: 2.6774071953286556]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221378008826074		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 3.221378008826074 | validation: 2.666670660974124]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2181075428551638		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 3.2181075428551638 | validation: 2.6664552691914056]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2133255322761123		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 3.2133255322761123 | validation: 2.6682883767351604]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216553214076857		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 3.216553214076857 | validation: 2.6669267542934807]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219909777292725		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 3.219909777292725 | validation: 2.6796328857617375]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21970698910394		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 3.21970698910394 | validation: 2.6748919359773247]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2188011300727246		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 3.2188011300727246 | validation: 2.674914446025094]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2180531609697463		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 3.2180531609697463 | validation: 2.6710305197539577]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2186585138334607		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 3.2186585138334607 | validation: 2.6657346524861634]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212721416797591		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 3.212721416797591 | validation: 2.6674350843301204]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213986508059265		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 3.213986508059265 | validation: 2.669662818966626]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221557325717719		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 3.221557325717719 | validation: 2.66595088958532]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2247392953925136		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 3.2247392953925136 | validation: 2.682153102756802]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234627505123		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 3.234627505123 | validation: 2.6859275388668347]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221971387125452		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 3.221971387125452 | validation: 2.6652807569327557]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2170838926307113		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 3.2170838926307113 | validation: 2.6687312682546622]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216901043889248		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 3.216901043889248 | validation: 2.6656315129493975]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217959344588734		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 3.217959344588734 | validation: 2.665278102075735]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2152561456555113		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 3.2152561456555113 | validation: 2.6689063494622816]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2173289511476133		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 3.2173289511476133 | validation: 2.679575888009938]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218086559102003		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 3.218086559102003 | validation: 2.6637123863849026]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2171298514920004		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 3.2171298514920004 | validation: 2.679647369776834]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2197652084354282		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 3.2197652084354282 | validation: 2.6675249715620293]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2168031570886466		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 3.2168031570886466 | validation: 2.6742621976041803]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216167076843097		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 3.216167076843097 | validation: 2.675226057064387]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215797333118454		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 3.215797333118454 | validation: 2.663353829490406]
	TIME [epoch: 11.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211277032935401		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 3.211277032935401 | validation: 2.663246608042984]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2147815967481015		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 3.2147815967481015 | validation: 2.665695786530707]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216203624566141		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 3.216203624566141 | validation: 2.6756629067131423]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215262331825942		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 3.215262331825942 | validation: 2.672134364096869]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124388987775094		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 3.2124388987775094 | validation: 2.6645303130096134]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216182809135506		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 3.216182809135506 | validation: 2.6809890173971787]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214437982912755		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 3.214437982912755 | validation: 2.6646494641794782]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2166697837147185		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 3.2166697837147185 | validation: 2.666632634259751]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217702361033805		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 3.217702361033805 | validation: 2.673176170816343]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213134110499313		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 3.213134110499313 | validation: 2.6658922932448137]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21513641142802		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 3.21513641142802 | validation: 2.680794946593405]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215708599357597		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 3.215708599357597 | validation: 2.667785100533797]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2181885858372814		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 3.2181885858372814 | validation: 2.688841610144841]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.234260475764617		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 3.234260475764617 | validation: 2.689986471618437]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220182441995919		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 3.220182441995919 | validation: 2.6682299151615796]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220318753382265		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 3.220318753382265 | validation: 2.6661278803599293]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216105374232936		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 3.216105374232936 | validation: 2.6752107664696485]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2221446570970693		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 3.2221446570970693 | validation: 2.6783556062325147]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2332907417464596		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 3.2332907417464596 | validation: 2.6948973978244406]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2236848236033633		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 3.2236848236033633 | validation: 2.6757628310417507]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214440152501323		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 3.214440152501323 | validation: 2.665576295503551]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2269875132789916		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 3.2269875132789916 | validation: 2.6888921053900243]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2413396992023484		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 3.2413396992023484 | validation: 2.6790415336103917]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221835646943222		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 3.221835646943222 | validation: 2.669463167921529]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216807283914481		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 3.216807283914481 | validation: 2.669765966468595]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211574508954688		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 3.211574508954688 | validation: 2.668850898402228]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218682074404269		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 3.218682074404269 | validation: 2.678191776481373]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2202847359309623		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 3.2202847359309623 | validation: 2.666531719470921]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214808924897024		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 3.214808924897024 | validation: 2.6660224216880146]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217178297391384		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 3.217178297391384 | validation: 2.667769121967084]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2197804637454164		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 3.2197804637454164 | validation: 2.666425837678046]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2201663665285523		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 3.2201663665285523 | validation: 2.6765351004405242]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2144570772540115		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 3.2144570772540115 | validation: 2.6688164164630166]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2159113056429742		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 3.2159113056429742 | validation: 2.6685916289308693]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2170590468331954		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 3.2170590468331954 | validation: 2.6728313948344966]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225037796296273		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 3.225037796296273 | validation: 2.6758443789980664]
	TIME [epoch: 11.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2194330711959553		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 3.2194330711959553 | validation: 2.6647566959572804]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2165926258907254		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 3.2165926258907254 | validation: 2.6698824583121494]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2221895663835602		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 3.2221895663835602 | validation: 2.6692460046759745]
	TIME [epoch: 11.6 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220503308218202		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 3.220503308218202 | validation: 2.6636144391214573]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2141014636779155		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 3.2141014636779155 | validation: 2.6717591747108287]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2157355448856735		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 3.2157355448856735 | validation: 2.665596116739775]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129297720470498		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 3.2129297720470498 | validation: 2.668201870342354]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130686187739936		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 3.2130686187739936 | validation: 2.6753258463777922]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2197648892988835		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 3.2197648892988835 | validation: 2.6846418402812025]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227329846875894		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 3.227329846875894 | validation: 2.673146017192696]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2134224304711037		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 3.2134224304711037 | validation: 2.676643778005419]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155704393250426		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 3.2155704393250426 | validation: 2.6814362155899762]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.224898910229097		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 3.224898910229097 | validation: 2.6733910077821776]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2165631048077143		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 3.2165631048077143 | validation: 2.6830486732012435]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219382922366248		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 3.219382922366248 | validation: 2.664264925530864]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217637759199852		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 3.217637759199852 | validation: 2.6667797673996807]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215172964347363		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 3.215172964347363 | validation: 2.672082252839572]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199505359193896		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 3.2199505359193896 | validation: 2.6652142310372335]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117080100706135		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 3.2117080100706135 | validation: 2.6812045285101136]
	TIME [epoch: 11.6 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2223738859205326		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 3.2223738859205326 | validation: 2.6691194002302097]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217249661637125		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 3.217249661637125 | validation: 2.66352227199582]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209628341461505		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 3.209628341461505 | validation: 2.6676389111258847]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2136767406101634		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 3.2136767406101634 | validation: 2.676825127067944]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199988408480404		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 3.2199988408480404 | validation: 2.6871117703895346]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2223527940354537		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 3.2223527940354537 | validation: 2.6692553855615295]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2157771588195736		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 3.2157771588195736 | validation: 2.68593047194825]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2285056926398665		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 3.2285056926398665 | validation: 2.6783163587901244]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111019078591383		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 3.2111019078591383 | validation: 2.6631549146952187]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2132589051473452		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 3.2132589051473452 | validation: 2.6662590925313046]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215804946628877		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 3.215804946628877 | validation: 2.681137152703582]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2181659390925157		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 3.2181659390925157 | validation: 2.6725782616169345]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2186962666835646		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 3.2186962666835646 | validation: 2.668203362769897]
	TIME [epoch: 11.6 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213400406665748		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 3.213400406665748 | validation: 2.6680071773767593]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215119126546817		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 3.215119126546817 | validation: 2.6760384522396827]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219147752428819		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 3.219147752428819 | validation: 2.6675600720067347]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118556390848227		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 3.2118556390848227 | validation: 2.6645235010252133]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2147773381817446		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 3.2147773381817446 | validation: 2.6706714521012542]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2133772483650196		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 3.2133772483650196 | validation: 2.678069122040565]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2191349619526384		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 3.2191349619526384 | validation: 2.665251413637483]
	TIME [epoch: 11.6 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2178608628717953		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 3.2178608628717953 | validation: 2.6763147787749064]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2244774356833443		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 3.2244774356833443 | validation: 2.681050073516981]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225860729204015		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 3.225860729204015 | validation: 2.6681206634554546]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122445584560935		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 3.2122445584560935 | validation: 2.6675278415696995]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108357549803346		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 3.2108357549803346 | validation: 2.668897868352052]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212050758066686		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 3.212050758066686 | validation: 2.673590843454826]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218651640435386		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 3.218651640435386 | validation: 2.675611136925411]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21573820303826		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 3.21573820303826 | validation: 2.6623741744865352]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215312509286363		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 3.215312509286363 | validation: 2.6750464286904903]
	TIME [epoch: 11.6 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211485005020371		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 3.211485005020371 | validation: 2.667727462654318]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2147097116644323		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 3.2147097116644323 | validation: 2.66849896253575]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215405472266805		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 3.215405472266805 | validation: 2.677047753198191]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.22663434752779		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 3.22663434752779 | validation: 2.6774147224186033]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222081356343516		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 3.222081356343516 | validation: 2.6763927596952612]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2165650351407007		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 3.2165650351407007 | validation: 2.6803305836065023]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218639982789471		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 3.218639982789471 | validation: 2.6652877091092684]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2158960582615324		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 3.2158960582615324 | validation: 2.6731145618072083]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213181794837014		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 3.213181794837014 | validation: 2.664175622109409]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2154791001673617		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 3.2154791001673617 | validation: 2.6741580551142943]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2199335336244608		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 3.2199335336244608 | validation: 2.6705586686435097]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2139865820835496		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 3.2139865820835496 | validation: 2.6725570511074226]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2150335009925137		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 3.2150335009925137 | validation: 2.664987583386873]
	TIME [epoch: 11.6 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2189885610214297		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 3.2189885610214297 | validation: 2.673449291255123]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211522635342686		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 3.211522635342686 | validation: 2.667265101950693]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214249402191859		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 3.214249402191859 | validation: 2.6661604259647733]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2170314543579037		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 3.2170314543579037 | validation: 2.6666090326977696]
	TIME [epoch: 11.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219379278835366		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 3.219379278835366 | validation: 2.6632065610653832]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218536456322986		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 3.218536456322986 | validation: 2.6852546524290046]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2234740588080317		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 3.2234740588080317 | validation: 2.6708781020621326]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2133231026513966		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 3.2133231026513966 | validation: 2.6774633175496843]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2164206249862612		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 3.2164206249862612 | validation: 2.6666547915917613]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2168617239679973		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 3.2168617239679973 | validation: 2.6659881788068356]
	TIME [epoch: 11.6 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214333164625923		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 3.214333164625923 | validation: 2.6666735515972415]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2163348155758027		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 3.2163348155758027 | validation: 2.6708779202385644]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111789804511677		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 3.2111789804511677 | validation: 2.6607693433657467]
	TIME [epoch: 11.6 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2127693364635355		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 3.2127693364635355 | validation: 2.6670137129083953]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216494289133836		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 3.216494289133836 | validation: 2.6623322639156015]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2162649121842826		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 3.2162649121842826 | validation: 2.6633201353050713]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2163630643791565		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 3.2163630643791565 | validation: 2.6607638186568843]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118114116965066		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 3.2118114116965066 | validation: 2.6696001543155443]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2164349383012074		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 3.2164349383012074 | validation: 2.670259332003188]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2168690487873866		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 3.2168690487873866 | validation: 2.663238828297303]
	TIME [epoch: 11.6 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214582546498233		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 3.214582546498233 | validation: 2.6634656366753977]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218179240340837		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 3.218179240340837 | validation: 2.680226079755014]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.223015796089866		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 3.223015796089866 | validation: 2.6734894620170637]
	TIME [epoch: 11.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215901284205222		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 3.215901284205222 | validation: 2.6747374595340574]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2163847283650906		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 3.2163847283650906 | validation: 2.6857029836478308]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2242805103179126		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 3.2242805103179126 | validation: 2.6913484342953233]
	TIME [epoch: 11.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217183393151902		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 3.217183393151902 | validation: 2.669267872813559]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130710317043634		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 3.2130710317043634 | validation: 2.6655092200096466]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129099836804524		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 3.2129099836804524 | validation: 2.66948131878724]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2174715939469456		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 3.2174715939469456 | validation: 2.6712002278718625]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2198317106873455		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 3.2198317106873455 | validation: 2.6691984736374]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2149829519186865		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 3.2149829519186865 | validation: 2.6763336402704403]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2237612619850577		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 3.2237612619850577 | validation: 2.6742507777767437]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129641923886023		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 3.2129641923886023 | validation: 2.6692881847084897]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21512011729017		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 3.21512011729017 | validation: 2.6682480457041766]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217770373876016		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 3.217770373876016 | validation: 2.6715630598051434]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219294979490633		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 3.219294979490633 | validation: 2.674594802014807]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220240872823518		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 3.220240872823518 | validation: 2.6699023492587934]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2139036147159583		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 3.2139036147159583 | validation: 2.665756926304597]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21384018987267		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 3.21384018987267 | validation: 2.6659940107017586]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130552911164956		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 3.2130552911164956 | validation: 2.6630807470102607]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216264881858554		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 3.216264881858554 | validation: 2.664898806599849]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221056852158754		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 3.221056852158754 | validation: 2.66846939298641]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214949477403539		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 3.214949477403539 | validation: 2.6677667300185686]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21434686422825		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 3.21434686422825 | validation: 2.6653047412316]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182986368882447		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 3.2182986368882447 | validation: 2.681352936905814]
	TIME [epoch: 11.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2319176108339285		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 3.2319176108339285 | validation: 2.668103820155085]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123500534014457		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 3.2123500534014457 | validation: 2.6767188941115627]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2151474805384606		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 3.2151474805384606 | validation: 2.6801947949691294]
	TIME [epoch: 11.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213840268471314		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 3.213840268471314 | validation: 2.6680605090479346]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215575533882304		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 3.215575533882304 | validation: 2.667685554883928]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215295020244118		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 3.215295020244118 | validation: 2.65948016271362]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1285.pth
	Model improved!!!
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122488651025334		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 3.2122488651025334 | validation: 2.66089021746574]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2145132627320194		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 3.2145132627320194 | validation: 2.6703613006562934]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2188875536871597		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 3.2188875536871597 | validation: 2.6672581822250865]
	TIME [epoch: 11.6 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2152166552301193		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 3.2152166552301193 | validation: 2.6701430339721357]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182398577105196		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 3.2182398577105196 | validation: 2.6701882624533813]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213023241267768		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 3.213023241267768 | validation: 2.667515936423009]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111070354270117		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 3.2111070354270117 | validation: 2.6620316142928293]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217423677499417		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 3.217423677499417 | validation: 2.662499901213896]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2200339207389512		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 3.2200339207389512 | validation: 2.6698716528445767]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130813458953895		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 3.2130813458953895 | validation: 2.6626368510172997]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213855649443411		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 3.213855649443411 | validation: 2.6597106727488584]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2182851571319984		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 3.2182851571319984 | validation: 2.6624324050055557]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115922841752633		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 3.2115922841752633 | validation: 2.6714644098478546]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217641922099647		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 3.217641922099647 | validation: 2.6667090238748394]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210982859877454		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 3.210982859877454 | validation: 2.6678578383147187]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123020861015945		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 3.2123020861015945 | validation: 2.6634929138518446]
	TIME [epoch: 11.6 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214466736748474		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 3.214466736748474 | validation: 2.6623622119035657]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211554791692513		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 3.211554791692513 | validation: 2.6613285703772784]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2094592864106755		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 3.2094592864106755 | validation: 2.6597934457299583]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21134054266943		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 3.21134054266943 | validation: 2.666927550924071]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155961106973545		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 3.2155961106973545 | validation: 2.66443783652174]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128170581262454		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 3.2128170581262454 | validation: 2.663107815106305]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2121580160527032		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 3.2121580160527032 | validation: 2.665746600695042]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209897585808153		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 3.209897585808153 | validation: 2.667883230243417]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216119210089233		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 3.216119210089233 | validation: 2.658173972473203]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1310.pth
	Model improved!!!
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2140562317107597		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 3.2140562317107597 | validation: 2.6655658325398663]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105592271904757		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 3.2105592271904757 | validation: 2.660790548250243]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129353570609442		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 3.2129353570609442 | validation: 2.6639619722406414]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2156291962778116		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 3.2156291962778116 | validation: 2.6627879893205106]
	TIME [epoch: 11.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2140709847623743		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 3.2140709847623743 | validation: 2.6678994402146223]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2148247461002133		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 3.2148247461002133 | validation: 2.672272941969889]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2156180447199962		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 3.2156180447199962 | validation: 2.66496584256701]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217152873264883		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 3.217152873264883 | validation: 2.674320895439049]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215357366414853		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 3.215357366414853 | validation: 2.680259575465883]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2234340943744324		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 3.2234340943744324 | validation: 2.668880165547283]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2149360796286413		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 3.2149360796286413 | validation: 2.6701030285570813]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210037497383559		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 3.210037497383559 | validation: 2.659801069694533]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106511500078385		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 3.2106511500078385 | validation: 2.6655067203036054]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115288537684026		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 3.2115288537684026 | validation: 2.677625568620922]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117637692585044		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 3.2117637692585044 | validation: 2.6719944242691898]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2173746656444524		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 3.2173746656444524 | validation: 2.6678273159946104]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210888978953763		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 3.210888978953763 | validation: 2.6594080829348976]
	TIME [epoch: 11.6 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210966185940672		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 3.210966185940672 | validation: 2.672229179344908]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2151949188908784		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 3.2151949188908784 | validation: 2.6772919977187293]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2179945766971545		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 3.2179945766971545 | validation: 2.6700153034216836]
	TIME [epoch: 11.6 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2217782193576556		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 3.2217782193576556 | validation: 2.672068775257782]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212437116099112		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 3.212437116099112 | validation: 2.6778323571973384]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21934925904614		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 3.21934925904614 | validation: 2.668501049132334]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2135679465431513		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 3.2135679465431513 | validation: 2.661349392018498]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218128061013333		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 3.218128061013333 | validation: 2.6650483285304314]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212447692174861		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 3.212447692174861 | validation: 2.6649762738513663]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208585583930295		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 3.208585583930295 | validation: 2.670658303080956]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100087293966824		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 3.2100087293966824 | validation: 2.6638406972166955]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104469364460346		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 3.2104469364460346 | validation: 2.6590079662453694]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106330199642104		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 3.2106330199642104 | validation: 2.6641041108661416]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155030605174924		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 3.2155030605174924 | validation: 2.6693608588044606]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2164988146028906		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 3.2164988146028906 | validation: 2.6664715543149518]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216388894425766		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 3.216388894425766 | validation: 2.662030217788231]
	TIME [epoch: 11.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216196775179425		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 3.216196775179425 | validation: 2.6670578625314327]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218513722526775		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 3.218513722526775 | validation: 2.680648308521347]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214249421729273		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 3.214249421729273 | validation: 2.668535840357724]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2141380550966203		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 3.2141380550966203 | validation: 2.6699536932501626]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213159764416307		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 3.213159764416307 | validation: 2.6625054317259926]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122822592382514		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 3.2122822592382514 | validation: 2.662626291698923]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2133233710150257		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 3.2133233710150257 | validation: 2.6650029778363113]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212456093634291		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 3.212456093634291 | validation: 2.6624504270669234]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125984921810145		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 3.2125984921810145 | validation: 2.663245209201562]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2138946636825136		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 3.2138946636825136 | validation: 2.661011476522448]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213031757247367		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 3.213031757247367 | validation: 2.66922310586521]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2089551820354245		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 3.2089551820354245 | validation: 2.6660294761399133]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211817135103305		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 3.211817135103305 | validation: 2.6684149321615456]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21592466079405		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 3.21592466079405 | validation: 2.671908738256893]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215678149551622		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 3.215678149551622 | validation: 2.670191852451693]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2145066711874932		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 3.2145066711874932 | validation: 2.670226740742612]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216832904069466		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 3.216832904069466 | validation: 2.672570544296403]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108047086101803		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 3.2108047086101803 | validation: 2.6689160103059226]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212415961392558		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 3.212415961392558 | validation: 2.6669593369488434]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106969642712127		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 3.2106969642712127 | validation: 2.660299925683789]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125069957003185		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 3.2125069957003185 | validation: 2.672871510246491]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212801396181744		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 3.212801396181744 | validation: 2.662419769489008]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2075084165512657		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 3.2075084165512657 | validation: 2.666997008167726]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098255551213146		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 3.2098255551213146 | validation: 2.66107262525838]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212465266074717		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 3.212465266074717 | validation: 2.66115247331691]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210299083974834		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 3.210299083974834 | validation: 2.6729476273258177]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210863308341626		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 3.210863308341626 | validation: 2.666710866579574]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111583276004065		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 3.2111583276004065 | validation: 2.6661324410819067]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2174328106127335		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 3.2174328106127335 | validation: 2.6715230253536233]
	TIME [epoch: 11.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2163367737082043		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 3.2163367737082043 | validation: 2.661081675259726]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2163289494956264		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 3.2163289494956264 | validation: 2.6590107091557185]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128431100481034		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 3.2128431100481034 | validation: 2.668910566639639]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110163676717147		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 3.2110163676717147 | validation: 2.665515764535921]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108145144258184		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 3.2108145144258184 | validation: 2.6640514915507065]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208358504261881		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 3.208358504261881 | validation: 2.657172653604132]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1378.pth
	Model improved!!!
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209679698956593		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 3.209679698956593 | validation: 2.6626936066873714]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212050170070121		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 3.212050170070121 | validation: 2.6684962071219918]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104888160176976		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 3.2104888160176976 | validation: 2.668087570950096]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117744070265664		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 3.2117744070265664 | validation: 2.6746545137022566]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2161167773752615		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 3.2161167773752615 | validation: 2.671296923068741]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214273629478724		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 3.214273629478724 | validation: 2.6581200504605316]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21083484336347		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 3.21083484336347 | validation: 2.6640925042425727]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155378077940195		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 3.2155378077940195 | validation: 2.6726554837021106]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.218328884088639		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 3.218328884088639 | validation: 2.6797442585989386]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112295903297507		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 3.2112295903297507 | validation: 2.6751187107276166]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21431291936766		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 3.21431291936766 | validation: 2.6694866053296824]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207841175519705		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 3.207841175519705 | validation: 2.660808416216219]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211979863239308		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 3.211979863239308 | validation: 2.666288337337643]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2146988273410586		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 3.2146988273410586 | validation: 2.65992467971844]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109393430676656		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 3.2109393430676656 | validation: 2.6637522829278817]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212547101401577		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 3.212547101401577 | validation: 2.653084533622908]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1394.pth
	Model improved!!!
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214621727046805		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 3.214621727046805 | validation: 2.660423108305522]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214374225652802		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 3.214374225652802 | validation: 2.6590361244254526]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107795675152966		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 3.2107795675152966 | validation: 2.668266657721657]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097895222215174		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 3.2097895222215174 | validation: 2.6644819380105775]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2094501049450654		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 3.2094501049450654 | validation: 2.6651095453098903]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210827469666397		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 3.210827469666397 | validation: 2.672116022156556]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2096971846173394		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 3.2096971846173394 | validation: 2.663042672127539]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207660071227112		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 3.207660071227112 | validation: 2.6673454225125233]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098137096536346		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 3.2098137096536346 | validation: 2.6632921849766693]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209981709599747		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 3.209981709599747 | validation: 2.6629164420469738]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117249192823927		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 3.2117249192823927 | validation: 2.65708480798442]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2088951937883174		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 3.2088951937883174 | validation: 2.6730119263535848]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213516830407018		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 3.213516830407018 | validation: 2.6671432831101742]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098551476925263		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 3.2098551476925263 | validation: 2.6651734502310225]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110197470760653		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 3.2110197470760653 | validation: 2.663928803463666]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122529863258538		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 3.2122529863258538 | validation: 2.66795618508156]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125463632439226		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 3.2125463632439226 | validation: 2.671195392497058]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126466265288327		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 3.2126466265288327 | validation: 2.6683428756991323]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111069694940433		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 3.2111069694940433 | validation: 2.65977988126572]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20993843170217		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 3.20993843170217 | validation: 2.6622944413514085]
	TIME [epoch: 11.6 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122572639357307		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 3.2122572639357307 | validation: 2.6612250928978307]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211711106850933		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 3.211711106850933 | validation: 2.6684946546487356]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123996463596507		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 3.2123996463596507 | validation: 2.66901930218754]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126580080693214		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 3.2126580080693214 | validation: 2.658954664653629]
	TIME [epoch: 11.6 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124220389430795		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 3.2124220389430795 | validation: 2.663251089663334]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129581544626387		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 3.2129581544626387 | validation: 2.6571083048136823]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2121208513114268		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 3.2121208513114268 | validation: 2.6597912901882212]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210546557765007		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 3.210546557765007 | validation: 2.6662568067826213]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128756307158928		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 3.2128756307158928 | validation: 2.6642116034109495]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2114770601910516		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 3.2114770601910516 | validation: 2.6635627478634976]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2155645120958725		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 3.2155645120958725 | validation: 2.6627514669860353]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2151411979174194		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 3.2151411979174194 | validation: 2.670155277734147]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2131632771572027		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 3.2131632771572027 | validation: 2.662456218586678]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102024725487595		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 3.2102024725487595 | validation: 2.665770973597854]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118770256399793		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 3.2118770256399793 | validation: 2.6606663301577225]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117758907312206		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 3.2117758907312206 | validation: 2.6666314346870896]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2134234625808302		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 3.2134234625808302 | validation: 2.6629481683488185]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214236848287602		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 3.214236848287602 | validation: 2.6651388613896847]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211423646406547		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 3.211423646406547 | validation: 2.6743466219411944]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103866529760667		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 3.2103866529760667 | validation: 2.663632891494998]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104601232892955		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 3.2104601232892955 | validation: 2.6665167372678185]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119210305575767		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 3.2119210305575767 | validation: 2.6611577050566035]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2090750598102984		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 3.2090750598102984 | validation: 2.6631826587180347]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209380592509341		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 3.209380592509341 | validation: 2.664582792866354]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123325056794996		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 3.2123325056794996 | validation: 2.665119088373682]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2149296178429334		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 3.2149296178429334 | validation: 2.6666403882646557]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2176833225026162		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 3.2176833225026162 | validation: 2.672203703193056]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2134332122843037		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 3.2134332122843037 | validation: 2.6723824951792525]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212328691195496		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 3.212328691195496 | validation: 2.6630068186412212]
	TIME [epoch: 11.6 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2146029565708174		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 3.2146029565708174 | validation: 2.6671127768085126]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119868701537913		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 3.2119868701537913 | validation: 2.6605118649151587]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126770303584724		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 3.2126770303584724 | validation: 2.6641416152410113]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210508754071473		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 3.210508754071473 | validation: 2.6649000069135123]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209658274078473		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 3.209658274078473 | validation: 2.6614346063478775]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211718202565245		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 3.211718202565245 | validation: 2.6585377019257566]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111076190575902		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 3.2111076190575902 | validation: 2.6638473045022604]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122881830375247		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 3.2122881830375247 | validation: 2.660835933163215]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112814627664714		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 3.2112814627664714 | validation: 2.6667738531213048]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103760967747585		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 3.2103760967747585 | validation: 2.6696523796771383]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119063102484726		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 3.2119063102484726 | validation: 2.661634241847606]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213889677558856		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 3.213889677558856 | validation: 2.6600993619498237]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213653814637743		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 3.213653814637743 | validation: 2.668007145766327]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214203372926482		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 3.214203372926482 | validation: 2.6672512408217135]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122951794492884		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 3.2122951794492884 | validation: 2.662618407904137]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126488399322035		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 3.2126488399322035 | validation: 2.6726915898637764]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092933912800645		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 3.2092933912800645 | validation: 2.6704136086747736]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124066357302734		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 3.2124066357302734 | validation: 2.6587017541983995]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2121982110291154		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 3.2121982110291154 | validation: 2.657935177923041]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119197017058987		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 3.2119197017058987 | validation: 2.6627662189906722]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210419256096076		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 3.210419256096076 | validation: 2.6619319696388186]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2141057774133794		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 3.2141057774133794 | validation: 2.669671629606972]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2141085654795503		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 3.2141085654795503 | validation: 2.661743587717536]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212782792458029		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 3.212782792458029 | validation: 2.666832880622256]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2131396948459656		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 3.2131396948459656 | validation: 2.667076485750954]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116999592684863		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 3.2116999592684863 | validation: 2.663368309447677]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126277042732228		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 3.2126277042732228 | validation: 2.67184052272094]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117651705110637		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 3.2117651705110637 | validation: 2.6675043643968457]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208590446579367		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 3.208590446579367 | validation: 2.6673516806431463]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107017915345923		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 3.2107017915345923 | validation: 2.6666192370339616]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123376112671633		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 3.2123376112671633 | validation: 2.66214197579564]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118220709086986		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 3.2118220709086986 | validation: 2.6618717861011385]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213580197582525		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 3.213580197582525 | validation: 2.6663777759825065]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214336970660837		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 3.214336970660837 | validation: 2.665992156714752]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214669652041672		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 3.214669652041672 | validation: 2.669077578620374]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.216536900698992		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 3.216536900698992 | validation: 2.660968799335095]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212396411019958		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 3.212396411019958 | validation: 2.670186005003624]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123935148217373		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 3.2123935148217373 | validation: 2.658950927250853]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2159389396558273		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 3.2159389396558273 | validation: 2.6697390123760756]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214351364326979		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 3.214351364326979 | validation: 2.664691394263288]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117019470361043		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 3.2117019470361043 | validation: 2.666666671980181]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211232760363024		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 3.211232760363024 | validation: 2.6762175293839108]
	TIME [epoch: 11.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212196863100795		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 3.212196863100795 | validation: 2.665532440926853]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208829075936551		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 3.208829075936551 | validation: 2.6629049274444356]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208965862015418		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 3.208965862015418 | validation: 2.6625197691822855]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210948942042026		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 3.210948942042026 | validation: 2.6625159279620774]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212129083580149		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 3.212129083580149 | validation: 2.6617890455108237]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2167782789440684		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 3.2167782789440684 | validation: 2.672015240546214]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215776491349712		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 3.215776491349712 | validation: 2.6703520776624226]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130862132398534		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 3.2130862132398534 | validation: 2.6656209156223736]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107359058637863		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 3.2107359058637863 | validation: 2.6710601888414436]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100800041872732		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 3.2100800041872732 | validation: 2.666318986383753]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211018257462837		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 3.211018257462837 | validation: 2.671488441504479]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21277685978135		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 3.21277685978135 | validation: 2.6798359680996384]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2174573482715116		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 3.2174573482715116 | validation: 2.6722762529052737]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2136073859276784		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 3.2136073859276784 | validation: 2.675470265597164]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212923375018437		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 3.212923375018437 | validation: 2.6687493818542167]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212687628598724		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 3.212687628598724 | validation: 2.6571252555635567]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210530812180236		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 3.210530812180236 | validation: 2.673170121421114]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211234517785455		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 3.211234517785455 | validation: 2.665631724629009]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210217791716048		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 3.210217791716048 | validation: 2.6713668813739595]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125601384816647		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 3.2125601384816647 | validation: 2.6734526135161834]
	TIME [epoch: 11.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213959796532312		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 3.213959796532312 | validation: 2.6724633435899317]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210473975835727		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 3.210473975835727 | validation: 2.6637942712851252]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207938962779673		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 3.207938962779673 | validation: 2.661998712420616]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207752373391565		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 3.207752373391565 | validation: 2.670683180962725]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122779514551265		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 3.2122779514551265 | validation: 2.667119615258626]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211029989319217		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 3.211029989319217 | validation: 2.6667012304980404]
	TIME [epoch: 11.6 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213725788849845		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 3.213725788849845 | validation: 2.67235317290072]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2136076067757235		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 3.2136076067757235 | validation: 2.6598253282096516]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209862393542592		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 3.209862393542592 | validation: 2.659832050317315]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206227352058407		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 3.206227352058407 | validation: 2.665294857810936]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214950971794335		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 3.214950971794335 | validation: 2.66903939825626]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211598692711044		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 3.211598692711044 | validation: 2.6651251130884384]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116368550546914		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 3.2116368550546914 | validation: 2.6582867385110114]
	TIME [epoch: 11.6 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21118863303873		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 3.21118863303873 | validation: 2.65574556527331]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2148933528395536		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 3.2148933528395536 | validation: 2.6694951331056904]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100016376632627		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 3.2100016376632627 | validation: 2.667664201755182]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101151556823795		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 3.2101151556823795 | validation: 2.665650960526674]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211522766521325		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 3.211522766521325 | validation: 2.667063494248798]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2074005802823344		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 3.2074005802823344 | validation: 2.6671708009605615]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123414395875725		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 3.2123414395875725 | validation: 2.669569820422684]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128976819151474		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 3.2128976819151474 | validation: 2.6674639199898524]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211553023620194		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 3.211553023620194 | validation: 2.6674710322350883]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101201254713043		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 3.2101201254713043 | validation: 2.6607554396758806]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207677134877489		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 3.207677134877489 | validation: 2.6629385750287446]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2114612998395433		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 3.2114612998395433 | validation: 2.672535375755814]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122176664378808		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 3.2122176664378808 | validation: 2.670537588068862]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2091708307607183		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 3.2091708307607183 | validation: 2.6658975223643213]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093610519548177		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 3.2093610519548177 | validation: 2.6657530187223286]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208943689822882		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 3.208943689822882 | validation: 2.663871492131526]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093129325100374		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 3.2093129325100374 | validation: 2.660128421994859]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214722168916437		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 3.214722168916437 | validation: 2.657337094778743]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211094737210068		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 3.211094737210068 | validation: 2.6591145703920325]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208528183064261		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 3.208528183064261 | validation: 2.6627774725980577]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210078508741386		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 3.210078508741386 | validation: 2.664307972024549]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209088697565359		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 3.209088697565359 | validation: 2.663428620910214]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2072507412010753		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 3.2072507412010753 | validation: 2.66475523233413]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208704805079038		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 3.208704805079038 | validation: 2.668090284129962]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209215479149712		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 3.209215479149712 | validation: 2.6622742318900037]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210355459643842		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 3.210355459643842 | validation: 2.660840347657227]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2147888429845097		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 3.2147888429845097 | validation: 2.666903372360668]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123656062625505		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 3.2123656062625505 | validation: 2.6568828286768222]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129073136392474		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 3.2129073136392474 | validation: 2.660993048633733]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2086445225109577		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 3.2086445225109577 | validation: 2.666743992843668]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2130986737961837		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 3.2130986737961837 | validation: 2.6636254943236723]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214102461469199		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 3.214102461469199 | validation: 2.6673337052217883]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2151736529027426		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 3.2151736529027426 | validation: 2.66172610696621]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093227121340004		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 3.2093227121340004 | validation: 2.667544008197644]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208872690096166		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 3.208872690096166 | validation: 2.6570853847730134]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210973500964407		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 3.210973500964407 | validation: 2.665414308306476]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207959242616787		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 3.207959242616787 | validation: 2.660779417676355]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115984956414105		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 3.2115984956414105 | validation: 2.659455406025076]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124882250417266		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 3.2124882250417266 | validation: 2.6584802114807182]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2141986058408736		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 3.2141986058408736 | validation: 2.6593627764639893]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209933758465645		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 3.209933758465645 | validation: 2.668251088071539]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209262170099392		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 3.209262170099392 | validation: 2.6610397525512988]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211376959927972		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 3.211376959927972 | validation: 2.665440481313376]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212969771080599		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 3.212969771080599 | validation: 2.671554524044895]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21226486534513		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 3.21226486534513 | validation: 2.66811122003813]
	TIME [epoch: 11.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208807524084277		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 3.208807524084277 | validation: 2.6588222154900665]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210502344368938		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 3.210502344368938 | validation: 2.6646852313599005]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111903903236083		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 3.2111903903236083 | validation: 2.664778317518409]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125736814747943		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 3.2125736814747943 | validation: 2.6618731259301778]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211511197873522		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 3.211511197873522 | validation: 2.661567792851408]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113955087289274		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 3.2113955087289274 | validation: 2.661805465422005]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098613825836995		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 3.2098613825836995 | validation: 2.667863755723007]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212692036975305		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 3.212692036975305 | validation: 2.6691019417803536]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105196452495903		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 3.2105196452495903 | validation: 2.6555931999504696]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092615554156225		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 3.2092615554156225 | validation: 2.663918386519792]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118397113729538		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 3.2118397113729538 | validation: 2.666677069685268]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128208732743295		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 3.2128208732743295 | validation: 2.6617060641754584]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111447853540613		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 3.2111447853540613 | validation: 2.6711749045889803]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108661613970426		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 3.2108661613970426 | validation: 2.6648152233028255]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20963077087375		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 3.20963077087375 | validation: 2.6671626792294227]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210281186723115		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 3.210281186723115 | validation: 2.6696870072469214]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122985266876993		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 3.2122985266876993 | validation: 2.667408786027936]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209272217372846		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 3.209272217372846 | validation: 2.6594185973954696]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207229944618536		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 3.207229944618536 | validation: 2.669212040374096]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210632681890629		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 3.210632681890629 | validation: 2.665551486671908]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214925398067307		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 3.214925398067307 | validation: 2.662302253049984]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2114787548149177		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 3.2114787548149177 | validation: 2.6649319119057573]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2114460038062775		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 3.2114460038062775 | validation: 2.6584698755977167]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126652622967167		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 3.2126652622967167 | validation: 2.6579933240109916]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210773424195926		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 3.210773424195926 | validation: 2.6625488646639535]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110474027935605		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 3.2110474027935605 | validation: 2.658523347784022]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211831754071764		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 3.211831754071764 | validation: 2.667845639384784]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118162837166144		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 3.2118162837166144 | validation: 2.6641084378058277]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105169416412913		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 3.2105169416412913 | validation: 2.66403861453854]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212157147847894		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 3.212157147847894 | validation: 2.6591968449654586]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115481938132353		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 3.2115481938132353 | validation: 2.6610051478886185]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2146467540041477		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 3.2146467540041477 | validation: 2.6625190870238997]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107100819479006		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 3.2107100819479006 | validation: 2.6574460560479727]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104108922100245		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 3.2104108922100245 | validation: 2.660993805532546]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2091836834034115		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 3.2091836834034115 | validation: 2.6637151538043757]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123105658086395		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 3.2123105658086395 | validation: 2.6674335031503427]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212569698689287		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 3.212569698689287 | validation: 2.6613828824896406]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105469018171124		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 3.2105469018171124 | validation: 2.663366550798419]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210409601345054		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 3.210409601345054 | validation: 2.665411323394784]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118516115649958		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 3.2118516115649958 | validation: 2.6641759860657035]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209373765184012		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 3.209373765184012 | validation: 2.664190934097336]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209056140745206		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 3.209056140745206 | validation: 2.671377072466256]
	TIME [epoch: 11.6 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209136490056092		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 3.209136490056092 | validation: 2.664795290192207]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110961032955023		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 3.2110961032955023 | validation: 2.670606247203195]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208787781514533		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 3.208787781514533 | validation: 2.6587503332476663]
	TIME [epoch: 11.6 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2095345123572323		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 3.2095345123572323 | validation: 2.6723659707069034]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21119487770328		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 3.21119487770328 | validation: 2.666309162284508]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208708141236182		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 3.208708141236182 | validation: 2.664669197705026]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2138522973227728		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 3.2138522973227728 | validation: 2.6729408314691074]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2072875453791476		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 3.2072875453791476 | validation: 2.6561759253390353]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2120327192176363		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 3.2120327192176363 | validation: 2.660195696968581]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109725364201034		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 3.2109725364201034 | validation: 2.6592959027343106]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110655608886285		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 3.2110655608886285 | validation: 2.6687898799310603]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109692463511563		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 3.2109692463511563 | validation: 2.669666848650313]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209874794050539		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 3.209874794050539 | validation: 2.6652057498219217]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214220740530292		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 3.214220740530292 | validation: 2.6658449284934984]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093740025114434		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 3.2093740025114434 | validation: 2.6635080893675824]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.214630329544858		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 3.214630329544858 | validation: 2.665223286414189]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092420844002856		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 3.2092420844002856 | validation: 2.6651665751421723]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2088317014631595		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 3.2088317014631595 | validation: 2.660753939138538]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209405506888122		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 3.209405506888122 | validation: 2.66792562577702]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210359760043494		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 3.210359760043494 | validation: 2.663304338404961]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116743776998815		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 3.2116743776998815 | validation: 2.664196243707969]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116258064847356		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 3.2116258064847356 | validation: 2.663362253698143]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211044214495937		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 3.211044214495937 | validation: 2.655654892437618]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211837123862411		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 3.211837123862411 | validation: 2.6645836902569466]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207659399299777		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 3.207659399299777 | validation: 2.6646732984964387]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211397594781426		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 3.211397594781426 | validation: 2.657924947166605]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107937908141677		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 3.2107937908141677 | validation: 2.6659681861561006]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115917109329066		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 3.2115917109329066 | validation: 2.660546816708436]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212545716243512		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 3.212545716243512 | validation: 2.6638704439215504]
	TIME [epoch: 11.6 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097214162679797		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 3.2097214162679797 | validation: 2.6592227209455777]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2079690931743814		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 3.2079690931743814 | validation: 2.670317623073326]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102290697737006		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 3.2102290697737006 | validation: 2.6674492677591313]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2079707430080155		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 3.2079707430080155 | validation: 2.6599198355856823]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207607910009054		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 3.207607910009054 | validation: 2.6738253138014922]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209470783711608		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 3.209470783711608 | validation: 2.654838734565171]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2078629699926817		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 3.2078629699926817 | validation: 2.6674270211011413]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20583713367426		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 3.20583713367426 | validation: 2.6657452590483373]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093107118444237		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 3.2093107118444237 | validation: 2.6618796999264185]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208154667865651		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 3.208154667865651 | validation: 2.6727642618267606]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2061672132151413		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 3.2061672132151413 | validation: 2.6631274249993453]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2144448304274524		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 3.2144448304274524 | validation: 2.668176274876501]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2121948878395283		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 3.2121948878395283 | validation: 2.6566586776291485]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209393150874878		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 3.209393150874878 | validation: 2.673207465491871]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2099708944625673		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 3.2099708944625673 | validation: 2.663219387115632]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084604450182996		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 3.2084604450182996 | validation: 2.662465468565471]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101047471084154		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 3.2101047471084154 | validation: 2.67197096232211]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211225529721179		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 3.211225529721179 | validation: 2.6704784846233953]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210906482538303		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 3.210906482538303 | validation: 2.6639029264597607]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208083365736955		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 3.208083365736955 | validation: 2.672292673207886]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112915865103204		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 3.2112915865103204 | validation: 2.6644930917009506]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2129444570451726		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 3.2129444570451726 | validation: 2.6603064781229904]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209805169108817		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 3.209805169108817 | validation: 2.6577724455914633]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2089851328858794		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 3.2089851328858794 | validation: 2.661460435336949]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212653777534572		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 3.212653777534572 | validation: 2.6674571390799406]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211022254706034		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 3.211022254706034 | validation: 2.6642261066835626]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115143944575477		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 3.2115143944575477 | validation: 2.6594328081746768]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2099335508122664		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 3.2099335508122664 | validation: 2.662283218260201]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213313374650483		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 3.213313374650483 | validation: 2.6655838201651063]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208151175836836		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 3.208151175836836 | validation: 2.6653547701904525]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.213366578685867		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 3.213366578685867 | validation: 2.6590725768514445]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209221935001308		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 3.209221935001308 | validation: 2.661306958671809]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110348399679087		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 3.2110348399679087 | validation: 2.6563105084391965]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21192297855573		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 3.21192297855573 | validation: 2.665686267039256]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104214835568015		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 3.2104214835568015 | validation: 2.6588056773907236]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102284967039023		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 3.2102284967039023 | validation: 2.664926464960887]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207461973783587		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 3.207461973783587 | validation: 2.6625746881710195]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085038150677914		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 3.2085038150677914 | validation: 2.6581910247333815]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210742398807973		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 3.210742398807973 | validation: 2.655930457638374]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210728690421491		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 3.210728690421491 | validation: 2.6602740196841173]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210863922628424		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 3.210863922628424 | validation: 2.661766211620161]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2069717336509465		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 3.2069717336509465 | validation: 2.6578032431074807]
	TIME [epoch: 11.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092304010469053		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 3.2092304010469053 | validation: 2.6564320578667653]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108156667150936		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 3.2108156667150936 | validation: 2.6641002067483224]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122449741458596		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 3.2122449741458596 | validation: 2.6680076354900826]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113351485742774		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 3.2113351485742774 | validation: 2.659096529335822]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093623424716666		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 3.2093623424716666 | validation: 2.6666294180842702]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119644384572608		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 3.2119644384572608 | validation: 2.669838262326848]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209657710431462		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 3.209657710431462 | validation: 2.660117432825314]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108661359333204		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 3.2108661359333204 | validation: 2.6575061683666252]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110166939230025		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 3.2110166939230025 | validation: 2.6577152674149107]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211849884629431		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 3.211849884629431 | validation: 2.662626599520363]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209492819779767		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 3.209492819779767 | validation: 2.659681914561377]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2132098042763624		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 3.2132098042763624 | validation: 2.6692919977483553]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209266105665187		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 3.209266105665187 | validation: 2.6705329630791574]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092126487658414		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 3.2092126487658414 | validation: 2.665097270967144]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210907960229282		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 3.210907960229282 | validation: 2.6672253383905296]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2075690582397147		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 3.2075690582397147 | validation: 2.667755161736494]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2120290865290304		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 3.2120290865290304 | validation: 2.6601405490416776]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208951314994963		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 3.208951314994963 | validation: 2.6592531251724156]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210355917335619		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 3.210355917335619 | validation: 2.667255780742016]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211453494553776		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 3.211453494553776 | validation: 2.663510716601503]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2082691531989673		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 3.2082691531989673 | validation: 2.662292253746533]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101583076400004		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 3.2101583076400004 | validation: 2.6697088704664425]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2144511164310234		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 3.2144511164310234 | validation: 2.6727594525302645]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210136812781113		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 3.210136812781113 | validation: 2.666566651175576]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20776669152355		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 3.20776669152355 | validation: 2.665207985874443]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209305019588287		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 3.209305019588287 | validation: 2.6584022273660244]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105636788299243		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 3.2105636788299243 | validation: 2.6622759591027205]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212237503561614		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 3.212237503561614 | validation: 2.65964163299475]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211316007391389		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 3.211316007391389 | validation: 2.670328029589149]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212086077493261		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 3.212086077493261 | validation: 2.6622904204653395]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2082868733291225		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 3.2082868733291225 | validation: 2.663436637056005]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209287841592538		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 3.209287841592538 | validation: 2.6614408614792535]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116499100399043		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 3.2116499100399043 | validation: 2.65191622802272]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1709.pth
	Model improved!!!
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210652941509367		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 3.210652941509367 | validation: 2.658557109509055]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207295641309652		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 3.207295641309652 | validation: 2.6690007883639857]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212772714073772		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 3.212772714073772 | validation: 2.66199531916599]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122765250122205		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 3.2122765250122205 | validation: 2.6661900334348]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209468959197574		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 3.209468959197574 | validation: 2.661084507703497]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2127007460027		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 3.2127007460027 | validation: 2.6694889666680797]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104332461839395		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 3.2104332461839395 | validation: 2.670930947619581]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2126168250646887		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 3.2126168250646887 | validation: 2.6601350610256698]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211947587392463		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 3.211947587392463 | validation: 2.6614972330176507]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084447394750257		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 3.2084447394750257 | validation: 2.66201629889711]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105236580180967		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 3.2105236580180967 | validation: 2.6522303590533864]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2115844679526404		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 3.2115844679526404 | validation: 2.6561743416335366]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207068620559995		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 3.207068620559995 | validation: 2.6674510487897742]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211586701159305		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 3.211586701159305 | validation: 2.656048234488231]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211466366537528		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 3.211466366537528 | validation: 2.6680376563906987]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103827506680105		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 3.2103827506680105 | validation: 2.661917186727098]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2074230745143124		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 3.2074230745143124 | validation: 2.6616417882935766]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21292677458608		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 3.21292677458608 | validation: 2.6602346376552766]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210331799122185		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 3.210331799122185 | validation: 2.6691056242573516]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103084786678053		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 3.2103084786678053 | validation: 2.6691372621076157]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085420016803985		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 3.2085420016803985 | validation: 2.665964003423608]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2096492666202323		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 3.2096492666202323 | validation: 2.663661801981426]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124177567563197		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 3.2124177567563197 | validation: 2.6568277834790943]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093183435557826		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 3.2093183435557826 | validation: 2.6549932185458225]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101622415042157		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 3.2101622415042157 | validation: 2.6641229377300544]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105207389294885		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 3.2105207389294885 | validation: 2.6575939930009542]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110529621450024		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 3.2110529621450024 | validation: 2.6640672958382594]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117176465203103		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 3.2117176465203103 | validation: 2.6593768532559032]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211032558544968		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 3.211032558544968 | validation: 2.6607240021359213]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104409216804326		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 3.2104409216804326 | validation: 2.663301938053261]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2104180258006325		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 3.2104180258006325 | validation: 2.658583764753762]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2069602869443594		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 3.2069602869443594 | validation: 2.6611034103234865]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2079474592315136		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 3.2079474592315136 | validation: 2.6613134219220695]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209580067756001		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 3.209580067756001 | validation: 2.6656089460582577]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2087830534257216		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 3.2087830534257216 | validation: 2.6665537826543098]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210009723639972		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 3.210009723639972 | validation: 2.6650244864338912]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2120515544163792		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 3.2120515544163792 | validation: 2.6652288979278205]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209692825160174		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 3.209692825160174 | validation: 2.668677426842677]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103820018522176		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 3.2103820018522176 | validation: 2.662231043405806]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2088197385284634		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 3.2088197385284634 | validation: 2.6648240661263136]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206409277482756		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 3.206409277482756 | validation: 2.6608855212407674]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124659393107895		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 3.2124659393107895 | validation: 2.6607469834536914]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207688290862233		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 3.207688290862233 | validation: 2.6692229971588177]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208994160677607		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 3.208994160677607 | validation: 2.663576487305878]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084430822639867		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 3.2084430822639867 | validation: 2.6727357692095643]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106583418322963		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 3.2106583418322963 | validation: 2.6649856113161947]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209086938686638		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 3.209086938686638 | validation: 2.6660489307221997]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20914981620288		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 3.20914981620288 | validation: 2.6688151780880016]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210566076922922		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 3.210566076922922 | validation: 2.662261004332356]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210019381993221		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 3.210019381993221 | validation: 2.6632725760824587]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2039933911003997		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 3.2039933911003997 | validation: 2.655018396984451]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117509413024803		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 3.2117509413024803 | validation: 2.6572850790678366]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212945908652439		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 3.212945908652439 | validation: 2.665235092423154]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110551671565752		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 3.2110551671565752 | validation: 2.6614474340141077]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2080927361201197		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 3.2080927361201197 | validation: 2.665170386944434]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2081464011201652		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 3.2081464011201652 | validation: 2.661754547630163]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208351332847632		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 3.208351332847632 | validation: 2.6589739889140356]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110996902003213		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 3.2110996902003213 | validation: 2.6593562031797946]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085859816217086		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 3.2085859816217086 | validation: 2.667961375082015]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210112768538318		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 3.210112768538318 | validation: 2.654965873269098]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209350352319456		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 3.209350352319456 | validation: 2.6585029294649347]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2093108908694044		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 3.2093108908694044 | validation: 2.6604876986166905]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208813608297139		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 3.208813608297139 | validation: 2.6562328923038936]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210555163373989		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 3.210555163373989 | validation: 2.6738282938894304]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209975952113372		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 3.209975952113372 | validation: 2.660669921282686]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102808447644433		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 3.2102808447644433 | validation: 2.657110808638338]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2076705701756127		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 3.2076705701756127 | validation: 2.6612372859166373]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109093921535465		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 3.2109093921535465 | validation: 2.672360336671277]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210558751241811		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 3.210558751241811 | validation: 2.6634032130961147]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106306260283426		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 3.2106306260283426 | validation: 2.660240105032092]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2087434749885735		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 3.2087434749885735 | validation: 2.6658081535715303]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112948852986967		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 3.2112948852986967 | validation: 2.6629574876861892]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2083336500911326		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 3.2083336500911326 | validation: 2.665118989608595]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102596581807044		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 3.2102596581807044 | validation: 2.660384596471106]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210669959506144		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 3.210669959506144 | validation: 2.6592762480240872]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208524344370511		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 3.208524344370511 | validation: 2.662313769666018]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2083976215256342		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 3.2083976215256342 | validation: 2.6704825773759278]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207113363914968		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 3.207113363914968 | validation: 2.6559528577483684]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098846686958686		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 3.2098846686958686 | validation: 2.668177005329745]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2076638209707093		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 3.2076638209707093 | validation: 2.666757427247966]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210026543302135		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 3.210026543302135 | validation: 2.659921876689474]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207627832597268		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 3.207627832597268 | validation: 2.6640698758213546]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209525765644245		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 3.209525765644245 | validation: 2.6631540785943177]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109254469645654		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 3.2109254469645654 | validation: 2.6612293250348342]
	TIME [epoch: 11.6 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208106167260953		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 3.208106167260953 | validation: 2.65424533365821]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20950450087057		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 3.20950450087057 | validation: 2.6657735023526916]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208210187291691		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 3.208210187291691 | validation: 2.6677766256748146]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211643630608471		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 3.211643630608471 | validation: 2.6609977552641406]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210361922828098		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 3.210361922828098 | validation: 2.6615217253274315]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210527843351688		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 3.210527843351688 | validation: 2.6650151764434216]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212695807264045		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 3.212695807264045 | validation: 2.66128074424627]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106873484551866		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 3.2106873484551866 | validation: 2.659723651753738]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210174626400231		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 3.210174626400231 | validation: 2.657784348904702]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084181071645825		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 3.2084181071645825 | validation: 2.6643381894109917]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2068354134711243		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 3.2068354134711243 | validation: 2.664878302742276]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210399255307286		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 3.210399255307286 | validation: 2.66189993271783]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210451920441344		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 3.210451920441344 | validation: 2.662105583168702]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209280015966187		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 3.209280015966187 | validation: 2.658955217675281]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209114931922155		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 3.209114931922155 | validation: 2.653969192923586]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2112548215541286		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 3.2112548215541286 | validation: 2.662983396297999]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100299307990046		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 3.2100299307990046 | validation: 2.661028623816951]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2131465040819602		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 3.2131465040819602 | validation: 2.6600968778364042]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097650490064478		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 3.2097650490064478 | validation: 2.6619527274076895]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097342054745224		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 3.2097342054745224 | validation: 2.655598977969139]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106224802875527		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 3.2106224802875527 | validation: 2.660946772121603]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107371796486346		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 3.2107371796486346 | validation: 2.6619710089256645]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2082636670702325		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 3.2082636670702325 | validation: 2.6609708554396114]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209803591769055		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 3.209803591769055 | validation: 2.660088409213528]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097369288566675		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 3.2097369288566675 | validation: 2.6606290749212134]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113551495094512		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 3.2113551495094512 | validation: 2.6583812293404536]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106790206284943		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 3.2106790206284943 | validation: 2.6610018062011442]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2119872156212304		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 3.2119872156212304 | validation: 2.665265941119175]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113481506457386		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 3.2113481506457386 | validation: 2.660640102685933]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124471996799455		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 3.2124471996799455 | validation: 2.6589500109593174]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092656684156364		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 3.2092656684156364 | validation: 2.6681617816369307]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2094658182112807		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 3.2094658182112807 | validation: 2.6608842821560916]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2125857455211797		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 3.2125857455211797 | validation: 2.6682156888046196]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2070536164587313		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 3.2070536164587313 | validation: 2.667986802989842]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2071352049343163		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 3.2071352049343163 | validation: 2.6658789177997955]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2078322694185024		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 3.2078322694185024 | validation: 2.6620433358068416]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2081629313198974		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 3.2081629313198974 | validation: 2.660444397678385]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109282083927972		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 3.2109282083927972 | validation: 2.668684719496215]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206054046562558		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 3.206054046562558 | validation: 2.6641076539915356]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211557987881621		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 3.211557987881621 | validation: 2.662605061360338]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209301241417616		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 3.209301241417616 | validation: 2.6584666468874363]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208887813304125		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 3.208887813304125 | validation: 2.6649278967609837]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084209154708643		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 3.2084209154708643 | validation: 2.6627474018132284]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211948316785387		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 3.211948316785387 | validation: 2.6608759298201403]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209205508874649		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 3.209205508874649 | validation: 2.6640282422757635]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100925952831956		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 3.2100925952831956 | validation: 2.6611282003968477]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209590424051571		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 3.209590424051571 | validation: 2.666212861019685]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105193377638326		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 3.2105193377638326 | validation: 2.656327387247527]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210213950544525		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 3.210213950544525 | validation: 2.6678638634829714]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2058175815574894		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 3.2058175815574894 | validation: 2.6669675809452182]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209560986229891		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 3.209560986229891 | validation: 2.6625637437403924]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2120334770678043		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 3.2120334770678043 | validation: 2.6637318323581822]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206065651621639		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 3.206065651621639 | validation: 2.6646736701812443]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209527637638252		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 3.209527637638252 | validation: 2.6610370600728346]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2116837092639487		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 3.2116837092639487 | validation: 2.6641648278905916]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208352083517913		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 3.208352083517913 | validation: 2.666808213123175]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2080423735395285		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 3.2080423735395285 | validation: 2.6689231867444723]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118427444279805		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 3.2118427444279805 | validation: 2.664083926891012]
	TIME [epoch: 11.6 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206906449464039		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 3.206906449464039 | validation: 2.65716100780043]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2072604027292115		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 3.2072604027292115 | validation: 2.6562274486827526]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212501973169789		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 3.212501973169789 | validation: 2.6637881826200362]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208389086135729		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 3.208389086135729 | validation: 2.664746288912034]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211718142540337		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 3.211718142540337 | validation: 2.6611959790327946]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20948915588601		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 3.20948915588601 | validation: 2.6569813170103704]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2079935196588005		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 3.2079935196588005 | validation: 2.66391027858417]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207125206920266		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 3.207125206920266 | validation: 2.6658917830741276]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2082868151979387		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 3.2082868151979387 | validation: 2.661909086992224]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212647213078982		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 3.212647213078982 | validation: 2.6565236862251953]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101277293415365		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 3.2101277293415365 | validation: 2.665942148262693]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211947881512291		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 3.211947881512291 | validation: 2.6650608038177346]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207655070119762		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 3.207655070119762 | validation: 2.662004769117498]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209277201225018		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 3.209277201225018 | validation: 2.667018308158905]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109950175511335		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 3.2109950175511335 | validation: 2.661994640127283]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208170222759524		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 3.208170222759524 | validation: 2.6647761818128606]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212965872331302		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 3.212965872331302 | validation: 2.6609231330597436]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2140410132724586		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 3.2140410132724586 | validation: 2.673517336169334]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212105209162176		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 3.212105209162176 | validation: 2.66417542170772]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2070528294814027		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 3.2070528294814027 | validation: 2.6565235728885046]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21015485749345		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 3.21015485749345 | validation: 2.670388945258842]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2090845991744983		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 3.2090845991744983 | validation: 2.6620321096410238]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209892213228851		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 3.209892213228851 | validation: 2.6636223453821266]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207802848686907		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 3.207802848686907 | validation: 2.6651379121206094]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110471597553185		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 3.2110471597553185 | validation: 2.658823213733786]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085580127269733		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 3.2085580127269733 | validation: 2.6614240654432404]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210501087766402		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 3.210501087766402 | validation: 2.6635198691763615]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208343681542827		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 3.208343681542827 | validation: 2.6564580665883604]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206468083420787		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 3.206468083420787 | validation: 2.658066415206985]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208728324120049		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 3.208728324120049 | validation: 2.656016275693286]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207634809609116		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 3.207634809609116 | validation: 2.663892895635257]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2096651098989932		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 3.2096651098989932 | validation: 2.652306206192275]
	TIME [epoch: 11.6 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210298551758426		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 3.210298551758426 | validation: 2.6529369831154788]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2075578459003156		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 3.2075578459003156 | validation: 2.665023776518859]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085775274652963		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 3.2085775274652963 | validation: 2.6650005032333595]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113746752897194		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 3.2113746752897194 | validation: 2.6570653225037972]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210259475784652		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 3.210259475784652 | validation: 2.6654310073239946]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208883198634052		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 3.208883198634052 | validation: 2.658678341805396]
	TIME [epoch: 11.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2095658499922024		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 3.2095658499922024 | validation: 2.659146362496144]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107641250887893		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 3.2107641250887893 | validation: 2.6691849773558354]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20883226056813		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 3.20883226056813 | validation: 2.6589757375950795]
	TIME [epoch: 11.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118846369177083		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 3.2118846369177083 | validation: 2.6577789697299523]
	TIME [epoch: 11.6 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210040635131643		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 3.210040635131643 | validation: 2.6654808352647565]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209501362382738		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 3.209501362382738 | validation: 2.6616028749951615]
	TIME [epoch: 11.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207152684654703		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 3.207152684654703 | validation: 2.6573154245174586]
	TIME [epoch: 11.6 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208410370190758		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 3.208410370190758 | validation: 2.658550893483773]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098388525378785		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 3.2098388525378785 | validation: 2.6653809153120624]
	TIME [epoch: 11.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2080577750895793		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 3.2080577750895793 | validation: 2.657933719295637]
	TIME [epoch: 11.6 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2070794172623227		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 3.2070794172623227 | validation: 2.662412245651462]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20956390805741		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 3.20956390805741 | validation: 2.6596843081377446]
	TIME [epoch: 11.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209915692303218		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 3.209915692303218 | validation: 2.6603573582912414]
	TIME [epoch: 11.6 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2060639859261517		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 3.2060639859261517 | validation: 2.6592858343266874]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208858587647407		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 3.208858587647407 | validation: 2.66663001591438]
	TIME [epoch: 11.5 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209898760688467		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 3.209898760688467 | validation: 2.655473997328684]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2099160911932727		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 3.2099160911932727 | validation: 2.6517933454780724]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r0_20240310_045143/states/model_tr_study204_1906.pth
	Model improved!!!
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085079806475334		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 3.2085079806475334 | validation: 2.6652649118989133]
	TIME [epoch: 11.5 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103912293086743		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 3.2103912293086743 | validation: 2.655614839804523]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210067786629014		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 3.210067786629014 | validation: 2.6637831655282254]
	TIME [epoch: 11.6 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207599399984134		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 3.207599399984134 | validation: 2.67083622073596]
	TIME [epoch: 11.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2127565973238985		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 3.2127565973238985 | validation: 2.661014624914616]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209434418262372		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 3.209434418262372 | validation: 2.6698176376605147]
	TIME [epoch: 11.6 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2088884807330977		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 3.2088884807330977 | validation: 2.655485868898331]
	TIME [epoch: 11.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208184819527806		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 3.208184819527806 | validation: 2.6696466618440753]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2123632531473922		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 3.2123632531473922 | validation: 2.6666118760051165]
	TIME [epoch: 11.6 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2070855985545847		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 3.2070855985545847 | validation: 2.6652539447438786]
	TIME [epoch: 11.5 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107730751091808		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 3.2107730751091808 | validation: 2.660098450328368]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2059832484654587		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 3.2059832484654587 | validation: 2.6604896140338856]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210358892590572		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 3.210358892590572 | validation: 2.6567953298733564]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21008014011707		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 3.21008014011707 | validation: 2.667082446006349]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209153557058052		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 3.209153557058052 | validation: 2.6663768135257446]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2080002276544413		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 3.2080002276544413 | validation: 2.660886401768544]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2085168146073193		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 3.2085168146073193 | validation: 2.664833489362719]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102777040036905		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 3.2102777040036905 | validation: 2.655053701268301]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210334331106096		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 3.210334331106096 | validation: 2.6545141356031565]
	TIME [epoch: 11.6 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2063800695959124		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 3.2063800695959124 | validation: 2.667330939659002]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2088919442608335		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 3.2088919442608335 | validation: 2.656904142499759]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113747295224853		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 3.2113747295224853 | validation: 2.6577752603506655]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20992365907537		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 3.20992365907537 | validation: 2.660743469012016]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2089731352608615		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 3.2089731352608615 | validation: 2.6577141381583327]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2090539699198986		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 3.2090539699198986 | validation: 2.6570960270709474]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122932961568416		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 3.2122932961568416 | validation: 2.6613528826530315]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209582060803306		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 3.209582060803306 | validation: 2.6668252265840136]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2111564274121096		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 3.2111564274121096 | validation: 2.665119672488497]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107295830520597		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 3.2107295830520597 | validation: 2.659122394821569]
	TIME [epoch: 11.6 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2127853753837003		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 3.2127853753837003 | validation: 2.6559504946004906]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209880642966769		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 3.209880642966769 | validation: 2.660725711276731]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.212211128398049		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 3.212211128398049 | validation: 2.6591459668611037]
	TIME [epoch: 11.6 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097448736667307		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 3.2097448736667307 | validation: 2.6607065712937317]
	TIME [epoch: 11.5 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2076026384248375		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 3.2076026384248375 | validation: 2.660402964162404]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20899524652027		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 3.20899524652027 | validation: 2.658491629668647]
	TIME [epoch: 11.6 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208971101826043		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 3.208971101826043 | validation: 2.6743533417029632]
	TIME [epoch: 11.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207685273560386		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 3.207685273560386 | validation: 2.6642315924592412]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209417587384188		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 3.209417587384188 | validation: 2.6574485146583324]
	TIME [epoch: 11.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2096486500476202		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 3.2096486500476202 | validation: 2.6596641934011087]
	TIME [epoch: 11.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2110058582381105		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 3.2110058582381105 | validation: 2.661362515548804]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211489250107659		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 3.211489250107659 | validation: 2.660016213305273]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208933187393181		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 3.208933187393181 | validation: 2.6646623322451894]
	TIME [epoch: 11.6 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2100192611334126		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 3.2100192611334126 | validation: 2.6616932557170823]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207443090882319		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 3.207443090882319 | validation: 2.6660842218394647]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2098117775060446		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 3.2098117775060446 | validation: 2.66161590661234]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2084268899437083		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 3.2084268899437083 | validation: 2.6579879243068625]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107854947083245		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 3.2107854947083245 | validation: 2.6626973462491623]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2090055473878683		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 3.2090055473878683 | validation: 2.6570115665197735]
	TIME [epoch: 11.6 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2106745137978328		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 3.2106745137978328 | validation: 2.6561201210344336]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.211350116565459		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 3.211350116565459 | validation: 2.662029214009115]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097173761650977		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 3.2097173761650977 | validation: 2.6574703328525766]
	TIME [epoch: 11.6 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209857916422513		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 3.209857916422513 | validation: 2.656792170038575]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103634201317552		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 3.2103634201317552 | validation: 2.657918058823869]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206832191025472		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 3.206832191025472 | validation: 2.6628252788773477]
	TIME [epoch: 11.5 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2099882591542768		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 3.2099882591542768 | validation: 2.6655338481742197]
	TIME [epoch: 11.6 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2128010067191224		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 3.2128010067191224 | validation: 2.658099262139593]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2134598817964313		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 3.2134598817964313 | validation: 2.658982632962063]
	TIME [epoch: 11.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092617358864395		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 3.2092617358864395 | validation: 2.6603760558889067]
	TIME [epoch: 11.6 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20746551730379		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 3.20746551730379 | validation: 2.659375059445796]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103438901406998		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 3.2103438901406998 | validation: 2.6659912884190895]
	TIME [epoch: 11.5 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207576135569949		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 3.207576135569949 | validation: 2.6613576015940557]
	TIME [epoch: 11.6 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2101068896007634		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 3.2101068896007634 | validation: 2.6564345849302624]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2103002892804833		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 3.2103002892804833 | validation: 2.658958216295975]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208175638653027		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 3.208175638653027 | validation: 2.6637881080317136]
	TIME [epoch: 11.6 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2105403461638162		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 3.2105403461638162 | validation: 2.6637349594771447]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2107537580501107		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 3.2107537580501107 | validation: 2.66522247492591]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2108060205049647		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 3.2108060205049647 | validation: 2.6586853141039475]
	TIME [epoch: 11.6 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2080266412013567		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 3.2080266412013567 | validation: 2.6632212110159226]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2095652329197635		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 3.2095652329197635 | validation: 2.662022686625554]
	TIME [epoch: 11.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206003293904864		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 3.206003293904864 | validation: 2.6631661551748453]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208962742535609		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 3.208962742535609 | validation: 2.6617033159351853]
	TIME [epoch: 11.6 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2062466887093573		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 3.2062466887093573 | validation: 2.6599592160529197]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.210330157921943		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 3.210330157921943 | validation: 2.66096164096688]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118479880650472		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 3.2118479880650472 | validation: 2.657427793727477]
	TIME [epoch: 11.6 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2109505417741007		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 3.2109505417741007 | validation: 2.66373586339905]
	TIME [epoch: 11.5 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.205824517022783		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 3.205824517022783 | validation: 2.658465956495387]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.20901663929318		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 3.20901663929318 | validation: 2.666635222385187]
	TIME [epoch: 11.6 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2086081055948488		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 3.2086081055948488 | validation: 2.6633693031764403]
	TIME [epoch: 11.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209955882589344		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 3.209955882589344 | validation: 2.662238421911902]
	TIME [epoch: 11.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209184224452761		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 3.209184224452761 | validation: 2.655483671909069]
	TIME [epoch: 11.6 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2081857495025474		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 3.2081857495025474 | validation: 2.6624497470062396]
	TIME [epoch: 11.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2063950156280905		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 3.2063950156280905 | validation: 2.6554286899680757]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2090122450889123		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 3.2090122450889123 | validation: 2.6617607896956375]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209093390155042		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 3.209093390155042 | validation: 2.659770750115267]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2081916662816923		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 3.2081916662816923 | validation: 2.660865231621284]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2102247787344798		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 3.2102247787344798 | validation: 2.657156779183078]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2097539704918527		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 3.2097539704918527 | validation: 2.662156091193598]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206777769812501		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 3.206777769812501 | validation: 2.6625472718928997]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2081358384187606		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 3.2081358384187606 | validation: 2.6598462248364796]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.21018518042413		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 3.21018518042413 | validation: 2.6615621321462113]
	TIME [epoch: 11.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092778102491484		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 3.2092778102491484 | validation: 2.6657928395993777]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209229842790881		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 3.209229842790881 | validation: 2.666589457209426]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2121323932211125		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 3.2121323932211125 | validation: 2.6619410108773325]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2122619111225936		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 3.2122619111225936 | validation: 2.6614234641569787]
	TIME [epoch: 11.5 sec]
Finished training in 23313.232 seconds.
