Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r1', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 528579942

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.676647454510265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.676647454510265 | validation: 7.494935725519823]
	TIME [epoch: 53.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.762532484837852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.762532484837852 | validation: 11.213539045260806]
	TIME [epoch: 8.65 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.935778572573316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.935778572573316 | validation: 9.403621751573601]
	TIME [epoch: 8.61 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.72403771195189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.72403771195189 | validation: 5.87839942384478]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.753695814661416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.753695814661416 | validation: 5.944752613681759]
	TIME [epoch: 8.59 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.737963466825354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.737963466825354 | validation: 5.643349565523712]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.610429478642127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.610429478642127 | validation: 5.578919420916098]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.417674589259859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.417674589259859 | validation: 5.398283569639148]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.304318185683995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.304318185683995 | validation: 5.151468227849225]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.29334192010113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.29334192010113 | validation: 5.373451236254716]
	TIME [epoch: 8.62 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.2608029963865075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2608029963865075 | validation: 5.514233422043967]
	TIME [epoch: 8.59 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.135777114263181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.135777114263181 | validation: 5.0616259248760755]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.051810834238962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.051810834238962 | validation: 5.666698031286504]
	TIME [epoch: 8.62 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.114013661520881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.114013661520881 | validation: 5.515174212382318]
	TIME [epoch: 8.61 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.108703798658715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.108703798658715 | validation: 5.260004954752748]
	TIME [epoch: 8.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.93745746723848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.93745746723848 | validation: 5.839993832946787]
	TIME [epoch: 8.59 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.190597651288401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.190597651288401 | validation: 5.100973791557898]
	TIME [epoch: 8.63 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8153509363262104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8153509363262104 | validation: 5.096871053225698]
	TIME [epoch: 8.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.012081523671525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.012081523671525 | validation: 5.05413958833657]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.808048022421642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.808048022421642 | validation: 4.891646554918882]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8619981114782918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8619981114782918 | validation: 4.912552828700665]
	TIME [epoch: 8.61 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6529980166789096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6529980166789096 | validation: 4.7790148754693025]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8208035048420412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8208035048420412 | validation: 4.81585166808712]
	TIME [epoch: 8.61 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7590243788541295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7590243788541295 | validation: 4.776408625977839]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6620239266870116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6620239266870116 | validation: 5.391720643119086]
	TIME [epoch: 8.61 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7199888039300695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7199888039300695 | validation: 4.768490407696802]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6493604664143384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6493604664143384 | validation: 4.749279115847287]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6529600130110325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6529600130110325 | validation: 4.917382305957037]
	TIME [epoch: 8.61 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5667526663084317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5667526663084317 | validation: 4.942993203676508]
	TIME [epoch: 8.63 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.681765059057225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.681765059057225 | validation: 4.814375082849871]
	TIME [epoch: 8.62 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6092674526623667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6092674526623667 | validation: 5.469330335653828]
	TIME [epoch: 8.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7682922436440607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7682922436440607 | validation: 4.901414771367566]
	TIME [epoch: 8.61 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.598643050127437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.598643050127437 | validation: 4.868247201072771]
	TIME [epoch: 8.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.613440985753477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.613440985753477 | validation: 4.796298951386493]
	TIME [epoch: 8.59 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.599387645678276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.599387645678276 | validation: 4.702433815117583]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.644930638184306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.644930638184306 | validation: 4.9605396449077395]
	TIME [epoch: 8.61 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6116632311893007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6116632311893007 | validation: 4.823993456074929]
	TIME [epoch: 8.59 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.555774906615725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.555774906615725 | validation: 4.694119356918872]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.608018933646638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.608018933646638 | validation: 4.666111765663108]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.602056033973409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.602056033973409 | validation: 4.977994352836546]
	TIME [epoch: 8.63 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.580488668437512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.580488668437512 | validation: 4.769248930943901]
	TIME [epoch: 8.61 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5549867231656536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5549867231656536 | validation: 4.776637253844112]
	TIME [epoch: 8.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5275211222820104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5275211222820104 | validation: 4.800897631123052]
	TIME [epoch: 8.63 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.532675933418262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.532675933418262 | validation: 4.9312525749561225]
	TIME [epoch: 8.63 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6460013042484327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6460013042484327 | validation: 4.839547849580471]
	TIME [epoch: 8.62 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4688637311002046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4688637311002046 | validation: 4.6123333082654945]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5316742843961215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5316742843961215 | validation: 4.827409622489153]
	TIME [epoch: 8.63 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.508098981105301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.508098981105301 | validation: 4.76902213710256]
	TIME [epoch: 8.62 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5108724841343664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5108724841343664 | validation: 4.6597196026751995]
	TIME [epoch: 8.62 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.482051433319209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.482051433319209 | validation: 4.7107779336867805]
	TIME [epoch: 8.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6343425868748325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6343425868748325 | validation: 4.7164684086454685]
	TIME [epoch: 8.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.429890540172058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.429890540172058 | validation: 4.844978600714652]
	TIME [epoch: 8.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5017794008585312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5017794008585312 | validation: 4.833044033311735]
	TIME [epoch: 8.63 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.557141423649342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.557141423649342 | validation: 4.673600235590748]
	TIME [epoch: 8.64 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4752801060213927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4752801060213927 | validation: 4.679804910776425]
	TIME [epoch: 8.62 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.488964435074635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488964435074635 | validation: 4.806450037545407]
	TIME [epoch: 8.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.53934441319101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.53934441319101 | validation: 4.663116347655888]
	TIME [epoch: 8.61 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4826687847474362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4826687847474362 | validation: 4.620286887619999]
	TIME [epoch: 8.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.498920993752056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.498920993752056 | validation: 4.602425567744017]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4956948090269826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4956948090269826 | validation: 4.639516832278618]
	TIME [epoch: 8.63 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.400999734805594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.400999734805594 | validation: 4.949252819384352]
	TIME [epoch: 8.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4906903741087496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4906903741087496 | validation: 4.9580753295314555]
	TIME [epoch: 8.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4399074938580703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4399074938580703 | validation: 4.549987047274826]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4825562274144253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4825562274144253 | validation: 4.686019849372816]
	TIME [epoch: 8.61 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.365476235248323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.365476235248323 | validation: 4.732274067072678]
	TIME [epoch: 8.62 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4259426927811427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4259426927811427 | validation: 4.712043244480613]
	TIME [epoch: 8.59 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.434412692671246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.434412692671246 | validation: 4.7511306881031405]
	TIME [epoch: 8.62 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4126605539042303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4126605539042303 | validation: 4.4220308781605295]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.515892220567647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.515892220567647 | validation: 2.4164119567851996]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.928100939792251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.928100939792251 | validation: 2.44581490927703]
	TIME [epoch: 8.63 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8182614069516247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8182614069516247 | validation: 2.2398475961390907]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6258625042423922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6258625042423922 | validation: 1.9890790183964562]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.510083132683591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.510083132683591 | validation: 1.8275968941616751]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4452427823695477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4452427823695477 | validation: 1.5659257521082095]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.19709082633032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.19709082633032 | validation: 1.5004010335014148]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1910233888741812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1910233888741812 | validation: 1.360692132272351]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9983874423455585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9983874423455585 | validation: 0.9613543570686403]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9730060629505161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9730060629505161 | validation: 2.429058780027297]
	TIME [epoch: 8.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.236390741492508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.236390741492508 | validation: 1.1875101988909922]
	TIME [epoch: 8.59 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9647997705690943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9647997705690943 | validation: 1.0866029646766435]
	TIME [epoch: 8.64 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9897276993422551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9897276993422551 | validation: 1.6754916428026245]
	TIME [epoch: 8.62 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2614027651900739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2614027651900739 | validation: 1.72075421205205]
	TIME [epoch: 8.59 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0473141387846272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0473141387846272 | validation: 0.9451684178977258]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0551012004158808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0551012004158808 | validation: 0.8727350868895354]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7801727939317548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7801727939317548 | validation: 0.712533539400276]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8807243215327578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8807243215327578 | validation: 0.843968648429531]
	TIME [epoch: 8.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.78927061406954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.78927061406954 | validation: 0.954844073565276]
	TIME [epoch: 8.59 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8478949000775057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8478949000775057 | validation: 0.8579413241117246]
	TIME [epoch: 8.62 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8236985088628443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8236985088628443 | validation: 0.8504970960172993]
	TIME [epoch: 8.64 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8119728857396508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8119728857396508 | validation: 0.8181562780657219]
	TIME [epoch: 8.59 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8244193428505046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8244193428505046 | validation: 0.8294919971655931]
	TIME [epoch: 8.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7751811062793876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7751811062793876 | validation: 0.7466774789260189]
	TIME [epoch: 8.62 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8254323709447803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8254323709447803 | validation: 1.1343461685695142]
	TIME [epoch: 8.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.843106939679306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.843106939679306 | validation: 0.800442109616535]
	TIME [epoch: 8.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8520155795400498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8520155795400498 | validation: 0.8177886733367764]
	TIME [epoch: 8.61 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9430650967436245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9430650967436245 | validation: 1.4582193840150333]
	TIME [epoch: 8.62 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.795128964245052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.795128964245052 | validation: 0.6244264806422415]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9689664636892855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9689664636892855 | validation: 0.691879135187136]
	TIME [epoch: 8.59 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7081356990389861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7081356990389861 | validation: 0.6748659481680286]
	TIME [epoch: 8.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8440404934150024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8440404934150024 | validation: 0.871468269746325]
	TIME [epoch: 8.62 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8417261743467732		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 0.8417261743467732 | validation: 0.6605633735048889]
	TIME [epoch: 8.59 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1073131373079101		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 1.1073131373079101 | validation: 0.680932123403305]
	TIME [epoch: 8.59 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.76632643106138		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 0.76632643106138 | validation: 0.8234513880240518]
	TIME [epoch: 8.59 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8280893370101559		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 0.8280893370101559 | validation: 0.7822718583725081]
	TIME [epoch: 8.62 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.75674952118015		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 0.75674952118015 | validation: 0.6313330798103927]
	TIME [epoch: 8.62 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8132921320506629		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 0.8132921320506629 | validation: 0.607916648499339]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.672269188780402		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 0.672269188780402 | validation: 0.9390370786214337]
	TIME [epoch: 8.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6516587915869646		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 0.6516587915869646 | validation: 0.9922444437109186]
	TIME [epoch: 8.61 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7230912271667206		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 0.7230912271667206 | validation: 0.9966783636579379]
	TIME [epoch: 8.59 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7224340334233731		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 0.7224340334233731 | validation: 0.5804360106969161]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.798918066765752		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 0.798918066765752 | validation: 0.7559889186836423]
	TIME [epoch: 8.63 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6753745017728444		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 0.6753745017728444 | validation: 0.6295263090661604]
	TIME [epoch: 8.59 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6162214719178379		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 0.6162214719178379 | validation: 0.7385453296532594]
	TIME [epoch: 8.59 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7155180644192476		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 0.7155180644192476 | validation: 0.7193179204678315]
	TIME [epoch: 8.59 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7018081114264528		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 0.7018081114264528 | validation: 0.8627037102023603]
	TIME [epoch: 8.63 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6915969061773666		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 0.6915969061773666 | validation: 0.6221265871492574]
	TIME [epoch: 8.59 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7066121304314601		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 0.7066121304314601 | validation: 0.6765663975198207]
	TIME [epoch: 8.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6789600522711149		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 0.6789600522711149 | validation: 1.2289990707962197]
	TIME [epoch: 8.58 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.693770860160339		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 0.693770860160339 | validation: 0.6208343638276994]
	TIME [epoch: 8.88 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.745882377047103		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 0.745882377047103 | validation: 0.5350489951641453]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7817016509256494		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 0.7817016509256494 | validation: 0.7118405609381033]
	TIME [epoch: 8.61 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5626282115758513		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 0.5626282115758513 | validation: 0.5877150966811698]
	TIME [epoch: 8.61 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5762692296344709		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 0.5762692296344709 | validation: 0.6019592004599004]
	TIME [epoch: 8.62 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7340353552242989		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 0.7340353552242989 | validation: 0.5590464492520315]
	TIME [epoch: 8.61 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.621103386909899		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 0.621103386909899 | validation: 0.3995775902343996]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6658784387960596		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 0.6658784387960596 | validation: 0.7595442677450668]
	TIME [epoch: 8.64 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7267663870364476		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 0.7267663870364476 | validation: 0.5239174474579804]
	TIME [epoch: 8.62 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7220551813218326		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 0.7220551813218326 | validation: 0.9293853164725524]
	TIME [epoch: 8.61 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8124874162598437		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 0.8124874162598437 | validation: 1.2014186660732595]
	TIME [epoch: 8.65 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7328089894024774		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 0.7328089894024774 | validation: 0.40317584260193023]
	TIME [epoch: 8.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9053819361367171		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 0.9053819361367171 | validation: 1.1820626063152375]
	TIME [epoch: 8.63 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7257531913863566		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 0.7257531913863566 | validation: 1.1416945002637864]
	TIME [epoch: 8.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6346379566067593		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 0.6346379566067593 | validation: 0.540901733496315]
	TIME [epoch: 8.61 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5291952930018662		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 0.5291952930018662 | validation: 0.5742604357096459]
	TIME [epoch: 8.61 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5654270573123291		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 0.5654270573123291 | validation: 0.6002607466980595]
	TIME [epoch: 8.63 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7172083080989143		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 0.7172083080989143 | validation: 0.9366785070133625]
	TIME [epoch: 8.64 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8294772963194349		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 0.8294772963194349 | validation: 0.6988021492616214]
	TIME [epoch: 8.62 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5782054497875573		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 0.5782054497875573 | validation: 0.6520751979602628]
	TIME [epoch: 8.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449134714377519		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 0.5449134714377519 | validation: 0.49897283726819874]
	TIME [epoch: 8.62 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5046327876444493		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 0.5046327876444493 | validation: 1.361707966031935]
	TIME [epoch: 8.61 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8836381326899415		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 0.8836381326899415 | validation: 1.1317934780223404]
	TIME [epoch: 8.61 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6272939389099375		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 0.6272939389099375 | validation: 0.5098795476664297]
	TIME [epoch: 8.62 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5374973302947674		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 0.5374973302947674 | validation: 0.7467633553674315]
	TIME [epoch: 8.61 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5678867278676167		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 0.5678867278676167 | validation: 0.7797363827348784]
	TIME [epoch: 8.61 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5449922570761048		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 0.5449922570761048 | validation: 0.6229463574376078]
	TIME [epoch: 8.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5488932623769507		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 0.5488932623769507 | validation: 0.4662925543782794]
	TIME [epoch: 8.68 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5392586273241198		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 0.5392586273241198 | validation: 0.5592579770710351]
	TIME [epoch: 8.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5101667407547947		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 0.5101667407547947 | validation: 0.8400235118147332]
	TIME [epoch: 8.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6408956327563221		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 0.6408956327563221 | validation: 0.5337946125724956]
	TIME [epoch: 8.59 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6005823380389345		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 0.6005823380389345 | validation: 0.7966381192891752]
	TIME [epoch: 8.62 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5201055823407582		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 0.5201055823407582 | validation: 1.1628606246894844]
	TIME [epoch: 8.61 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6206884395102895		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 0.6206884395102895 | validation: 0.7897784526299054]
	TIME [epoch: 8.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5966638157908959		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 0.5966638157908959 | validation: 0.5308531385516251]
	TIME [epoch: 8.61 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5721458528663533		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 0.5721458528663533 | validation: 0.7714829398388635]
	TIME [epoch: 8.61 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5056113424495289		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 0.5056113424495289 | validation: 0.7553776142512751]
	TIME [epoch: 8.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.592722955453121		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 0.592722955453121 | validation: 0.531160320444723]
	TIME [epoch: 8.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6885060752862202		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 0.6885060752862202 | validation: 0.7776369867227315]
	TIME [epoch: 8.61 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6155830234699261		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 0.6155830234699261 | validation: 0.5553705712011576]
	TIME [epoch: 8.63 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.61486477565818		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 0.61486477565818 | validation: 0.486744389459964]
	TIME [epoch: 8.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4464869198005824		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 0.4464869198005824 | validation: 0.7085800226306382]
	TIME [epoch: 8.61 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6492814102946209		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 0.6492814102946209 | validation: 0.44457580493688953]
	TIME [epoch: 8.59 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5316219663158327		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 0.5316219663158327 | validation: 0.4459187197020197]
	TIME [epoch: 8.63 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5148144384059117		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 0.5148144384059117 | validation: 0.52832260619904]
	TIME [epoch: 8.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4627484491831269		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 0.4627484491831269 | validation: 0.913910703404736]
	TIME [epoch: 8.61 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.518068688532031		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 0.518068688532031 | validation: 0.44862705637658634]
	TIME [epoch: 8.62 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5900963925799498		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 0.5900963925799498 | validation: 0.4195153988780818]
	TIME [epoch: 8.61 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4841993497037696		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 0.4841993497037696 | validation: 0.38993022229424146]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4843409554984667		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 0.4843409554984667 | validation: 0.40620998236519335]
	TIME [epoch: 8.58 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5218774354949882		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 0.5218774354949882 | validation: 0.6995424592683515]
	TIME [epoch: 8.63 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5771564716370443		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 0.5771564716370443 | validation: 0.7460963759650113]
	TIME [epoch: 8.59 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5215617367532895		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 0.5215617367532895 | validation: 0.3622624713709258]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46581456889708006		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 0.46581456889708006 | validation: 0.5418779037235679]
	TIME [epoch: 8.59 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49281061433011014		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 0.49281061433011014 | validation: 0.3651683038834125]
	TIME [epoch: 8.61 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5020081269096995		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 0.5020081269096995 | validation: 0.7471915957417782]
	TIME [epoch: 8.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43621079486193864		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 0.43621079486193864 | validation: 0.49501840938077313]
	TIME [epoch: 8.59 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45701587761352414		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 0.45701587761352414 | validation: 0.43954521199068197]
	TIME [epoch: 8.59 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47906161369687394		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 0.47906161369687394 | validation: 1.137934628928182]
	TIME [epoch: 8.62 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6478596015709669		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 0.6478596015709669 | validation: 0.5445452459547716]
	TIME [epoch: 8.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4406897625707293		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 0.4406897625707293 | validation: 0.6293848616346216]
	TIME [epoch: 8.59 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5288043534573516		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.5288043534573516 | validation: 0.5782169479939032]
	TIME [epoch: 8.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5360878874673555		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.5360878874673555 | validation: 0.4820798352571104]
	TIME [epoch: 8.62 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4826043098200721		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 0.4826043098200721 | validation: 0.390866306422055]
	TIME [epoch: 8.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49085136792441625		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 0.49085136792441625 | validation: 0.5700475699260815]
	TIME [epoch: 8.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.47718073610123335		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.47718073610123335 | validation: 1.0356651123358869]
	TIME [epoch: 8.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.538713069218615		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 0.538713069218615 | validation: 0.3916802960341457]
	TIME [epoch: 8.63 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4923069967451103		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 0.4923069967451103 | validation: 0.3122945516541844]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45219912515287514		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 0.45219912515287514 | validation: 0.4509421946228306]
	TIME [epoch: 8.58 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4241786881163991		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 0.4241786881163991 | validation: 0.43829178514655076]
	TIME [epoch: 8.61 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5032258794813175		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 0.5032258794813175 | validation: 0.49911778432520193]
	TIME [epoch: 8.65 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46430759201523164		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 0.46430759201523164 | validation: 0.7186586962584536]
	TIME [epoch: 8.58 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46642158317953425		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 0.46642158317953425 | validation: 0.5169979066928136]
	TIME [epoch: 8.59 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41861952438432626		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 0.41861952438432626 | validation: 0.27655025966148544]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5254656075349389		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 0.5254656075349389 | validation: 0.4132254142207088]
	TIME [epoch: 8.58 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5633950415923784		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 0.5633950415923784 | validation: 0.4444329793474866]
	TIME [epoch: 8.62 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4645096456959923		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 0.4645096456959923 | validation: 0.34156596184425336]
	TIME [epoch: 8.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4514996148873089		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.4514996148873089 | validation: 0.30424376994597463]
	TIME [epoch: 8.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4580423481693706		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 0.4580423481693706 | validation: 0.7078140513270157]
	TIME [epoch: 8.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4177747370101444		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 0.4177747370101444 | validation: 0.5481610132718098]
	TIME [epoch: 8.58 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49953092141635924		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 0.49953092141635924 | validation: 0.36902873252473745]
	TIME [epoch: 8.59 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39188717448299587		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 0.39188717448299587 | validation: 0.49813357796386865]
	TIME [epoch: 8.61 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4808615403918283		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 0.4808615403918283 | validation: 0.3040880985692732]
	TIME [epoch: 8.59 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4581794556154827		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 0.4581794556154827 | validation: 0.37589536224151787]
	TIME [epoch: 8.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.459288558098595		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.459288558098595 | validation: 0.3220246854441322]
	TIME [epoch: 8.63 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43685604815213547		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 0.43685604815213547 | validation: 0.3087313592700404]
	TIME [epoch: 8.59 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33624665975261026		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.33624665975261026 | validation: 0.4134549611807402]
	TIME [epoch: 8.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45425199323289656		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.45425199323289656 | validation: 0.3576112378329077]
	TIME [epoch: 8.58 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4949687063332385		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 0.4949687063332385 | validation: 0.47413614756789413]
	TIME [epoch: 8.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5943503191653692		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.5943503191653692 | validation: 0.3788057531082934]
	TIME [epoch: 8.61 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3938049484411712		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.3938049484411712 | validation: 0.5241597163828764]
	TIME [epoch: 8.59 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.424257033568047		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.424257033568047 | validation: 0.3407071522109606]
	TIME [epoch: 8.59 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48002874809449647		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.48002874809449647 | validation: 0.29848495260711205]
	TIME [epoch: 8.57 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42881951810081986		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.42881951810081986 | validation: 0.5082170250754916]
	TIME [epoch: 8.62 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4043540976189116		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 0.4043540976189116 | validation: 0.411680035553556]
	TIME [epoch: 8.59 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3679357907832084		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.3679357907832084 | validation: 0.5027583524317366]
	TIME [epoch: 8.59 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3768883477408331		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 0.3768883477408331 | validation: 0.6794119861556698]
	TIME [epoch: 8.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39392630108474486		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.39392630108474486 | validation: 0.3972290447382925]
	TIME [epoch: 8.61 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3580096781853311		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.3580096781853311 | validation: 0.49422160396781345]
	TIME [epoch: 8.62 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3774149353078705		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.3774149353078705 | validation: 0.3800318838279458]
	TIME [epoch: 8.61 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41651323790919326		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 0.41651323790919326 | validation: 0.5859543573684891]
	TIME [epoch: 8.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42240813007400985		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.42240813007400985 | validation: 0.2789081579831995]
	TIME [epoch: 8.59 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3435758385052264		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.3435758385052264 | validation: 0.4043977541149645]
	TIME [epoch: 8.59 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39631032348714484		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 0.39631032348714484 | validation: 0.38734859852896375]
	TIME [epoch: 8.59 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4258344488094087		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.4258344488094087 | validation: 0.26836386565910153]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5534042354041849		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.5534042354041849 | validation: 0.23434467028331707]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5269698511445619		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.5269698511445619 | validation: 0.496087627996167]
	TIME [epoch: 8.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.413044550799218		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 0.413044550799218 | validation: 0.3177191154367387]
	TIME [epoch: 8.59 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4508663023485542		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.4508663023485542 | validation: 0.5849377689621086]
	TIME [epoch: 8.62 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4456035774107394		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.4456035774107394 | validation: 0.8047753055840756]
	TIME [epoch: 8.61 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43204978199267385		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.43204978199267385 | validation: 0.34999380026030413]
	TIME [epoch: 8.59 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3789370857509808		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.3789370857509808 | validation: 0.31564966019128304]
	TIME [epoch: 8.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4029125405260944		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.4029125405260944 | validation: 0.8312022750845345]
	TIME [epoch: 8.61 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45254568304353804		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.45254568304353804 | validation: 0.6934540975976494]
	TIME [epoch: 8.61 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4313201376978138		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.4313201376978138 | validation: 0.3739787088060098]
	TIME [epoch: 8.61 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3692616992468589		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.3692616992468589 | validation: 0.2882390663099752]
	TIME [epoch: 8.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39555346378604794		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.39555346378604794 | validation: 0.29985844156143293]
	TIME [epoch: 8.62 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3220067578229072		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.3220067578229072 | validation: 1.0189187420138586]
	TIME [epoch: 8.59 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5374010694076571		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.5374010694076571 | validation: 0.3425720061423869]
	TIME [epoch: 8.59 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3174757470415953		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.3174757470415953 | validation: 0.2815052158021055]
	TIME [epoch: 8.62 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43588141182974277		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.43588141182974277 | validation: 0.5376176827443576]
	TIME [epoch: 8.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.760629245164807		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.760629245164807 | validation: 0.5246163410568803]
	TIME [epoch: 8.61 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34162033038041395		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.34162033038041395 | validation: 0.5226420145840305]
	TIME [epoch: 8.61 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4498965419999535		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 0.4498965419999535 | validation: 0.6598531652782255]
	TIME [epoch: 8.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36098870947435135		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.36098870947435135 | validation: 0.763135453869539]
	TIME [epoch: 8.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3588638223130121		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.3588638223130121 | validation: 0.35190692286754843]
	TIME [epoch: 8.64 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34109431837380566		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 0.34109431837380566 | validation: 0.39098143089902704]
	TIME [epoch: 8.58 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5112252678775964		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.5112252678775964 | validation: 0.3048161150513444]
	TIME [epoch: 8.61 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44892249992124195		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.44892249992124195 | validation: 0.34239880987006455]
	TIME [epoch: 8.61 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3657038971133483		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.3657038971133483 | validation: 0.3696715801003994]
	TIME [epoch: 8.58 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39604673677821944		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.39604673677821944 | validation: 0.5128794973806375]
	TIME [epoch: 8.65 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43920728151413035		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.43920728151413035 | validation: 0.28681255779148074]
	TIME [epoch: 8.61 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3784446597109525		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.3784446597109525 | validation: 0.20191240370353022]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34649603496799813		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.34649603496799813 | validation: 0.35205591950667514]
	TIME [epoch: 8.58 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3570366357301172		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.3570366357301172 | validation: 0.2739449875877414]
	TIME [epoch: 8.83 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30066041973855095		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.30066041973855095 | validation: 0.275574921354447]
	TIME [epoch: 8.69 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41747031167269216		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.41747031167269216 | validation: 0.3627687495038728]
	TIME [epoch: 8.59 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5463242305267529		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.5463242305267529 | validation: 0.45127194616572985]
	TIME [epoch: 8.59 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32631697698574424		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.32631697698574424 | validation: 0.18217210950806978]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3411657756962528		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.3411657756962528 | validation: 0.4247514845732837]
	TIME [epoch: 8.64 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3488456982228836		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.3488456982228836 | validation: 0.6245468405662883]
	TIME [epoch: 8.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34105525540771986		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.34105525540771986 | validation: 0.31682674006424194]
	TIME [epoch: 8.62 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35010761887618247		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.35010761887618247 | validation: 0.40754824623947933]
	TIME [epoch: 8.61 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30144320517821044		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.30144320517821044 | validation: 0.419944535188506]
	TIME [epoch: 8.64 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3898171073418976		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.3898171073418976 | validation: 0.3434723224896834]
	TIME [epoch: 8.61 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2977728821218256		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.2977728821218256 | validation: 0.20279712870179462]
	TIME [epoch: 8.61 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30241152167251106		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.30241152167251106 | validation: 0.18770849163404357]
	TIME [epoch: 8.61 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2925872073847492		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.2925872073847492 | validation: 0.29623772380640845]
	TIME [epoch: 8.65 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27608115952590023		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.27608115952590023 | validation: 0.6032757120062922]
	TIME [epoch: 8.67 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43453674260517916		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.43453674260517916 | validation: 0.1921089186738193]
	TIME [epoch: 8.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6724862348674149		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.6724862348674149 | validation: 0.30941001381348743]
	TIME [epoch: 8.61 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2898537371414385		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.2898537371414385 | validation: 0.3972494076228348]
	TIME [epoch: 8.64 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4768462744790292		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.4768462744790292 | validation: 0.777473340884762]
	TIME [epoch: 8.61 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3546827450034263		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.3546827450034263 | validation: 0.24432730305081604]
	TIME [epoch: 8.61 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34062056073982233		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.34062056073982233 | validation: 0.2658398782804934]
	TIME [epoch: 8.62 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36468879236965807		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.36468879236965807 | validation: 0.6171871360181825]
	TIME [epoch: 8.62 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7769413586534639		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.7769413586534639 | validation: 0.4761028420730956]
	TIME [epoch: 8.61 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33233301984140945		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.33233301984140945 | validation: 0.36736532837252406]
	TIME [epoch: 8.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42353724656241976		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.42353724656241976 | validation: 0.4068895083767369]
	TIME [epoch: 8.63 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32573694897052363		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.32573694897052363 | validation: 0.2804974467829076]
	TIME [epoch: 8.61 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.356647596470849		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.356647596470849 | validation: 0.3742173063263168]
	TIME [epoch: 8.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1564001998372582		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 1.1564001998372582 | validation: 0.5885351897309312]
	TIME [epoch: 8.62 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37134016971688644		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.37134016971688644 | validation: 0.2994083751271903]
	TIME [epoch: 8.62 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3974025580055279		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.3974025580055279 | validation: 0.3942232353060625]
	TIME [epoch: 8.63 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46995538835305195		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.46995538835305195 | validation: 0.3298575075394634]
	TIME [epoch: 8.59 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.44588696757673585		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.44588696757673585 | validation: 0.2912602923748847]
	TIME [epoch: 8.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31006251942368057		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.31006251942368057 | validation: 0.20885511189863915]
	TIME [epoch: 8.64 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.239832798484881		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.239832798484881 | validation: 0.2800679627977142]
	TIME [epoch: 8.67 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34558872704406496		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.34558872704406496 | validation: 0.4370584448544084]
	TIME [epoch: 8.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32851088238585896		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.32851088238585896 | validation: 0.350199643632819]
	TIME [epoch: 8.61 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4302257678098614		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.4302257678098614 | validation: 0.4172281113079923]
	TIME [epoch: 8.69 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8511584915853365		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.8511584915853365 | validation: 8.303087850093634]
	TIME [epoch: 8.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.850907124399418		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 6.850907124399418 | validation: 0.7285962404228158]
	TIME [epoch: 8.59 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3911287667802577		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.3911287667802577 | validation: 0.2818210281610487]
	TIME [epoch: 8.61 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.414395839627825		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.414395839627825 | validation: 0.3005399039014794]
	TIME [epoch: 8.63 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34411460061064403		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.34411460061064403 | validation: 0.37941910286735736]
	TIME [epoch: 8.65 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30953007300872354		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.30953007300872354 | validation: 0.654590223319848]
	TIME [epoch: 8.61 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3545890480799669		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.3545890480799669 | validation: 0.2696354836112128]
	TIME [epoch: 8.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3216814270629714		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.3216814270629714 | validation: 0.3987994956958532]
	TIME [epoch: 8.62 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2965231339441756		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.2965231339441756 | validation: 0.23541479886293049]
	TIME [epoch: 8.61 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32754789099851894		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.32754789099851894 | validation: 0.4546267658398705]
	TIME [epoch: 8.61 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27761553765351366		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.27761553765351366 | validation: 0.39986264123982473]
	TIME [epoch: 8.68 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29779903430250904		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.29779903430250904 | validation: 0.27710954756924916]
	TIME [epoch: 8.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3388797603831259		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.3388797603831259 | validation: 0.3514896821975574]
	TIME [epoch: 8.61 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36069306414802965		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.36069306414802965 | validation: 0.3495454810602133]
	TIME [epoch: 8.61 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.308157871028274		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.308157871028274 | validation: 0.40602236601359765]
	TIME [epoch: 8.62 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2699748985684655		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.2699748985684655 | validation: 0.2152443230870838]
	TIME [epoch: 8.61 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2910779941185181		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.2910779941185181 | validation: 0.3907183707594504]
	TIME [epoch: 8.61 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2863704076003307		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.2863704076003307 | validation: 0.21922816996857855]
	TIME [epoch: 8.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30671276211013593		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.30671276211013593 | validation: 0.46263449220639263]
	TIME [epoch: 8.63 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.350978249607217		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.350978249607217 | validation: 0.7019271674039143]
	TIME [epoch: 8.61 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3727186050987979		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.3727186050987979 | validation: 0.34731965157401556]
	TIME [epoch: 8.59 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30653803577114785		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.30653803577114785 | validation: 2.724300799621126]
	TIME [epoch: 8.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6193952911277882		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.6193952911277882 | validation: 0.2991860799504283]
	TIME [epoch: 8.63 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2895658645727049		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.2895658645727049 | validation: 0.33300406698257723]
	TIME [epoch: 8.65 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28375852606733376		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.28375852606733376 | validation: 0.1809073278811554]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23464513790477853		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.23464513790477853 | validation: 0.172079361120479]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2773880026793717		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.2773880026793717 | validation: 0.49763325166875116]
	TIME [epoch: 8.61 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27605509081284646		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.27605509081284646 | validation: 0.23285074828901914]
	TIME [epoch: 8.58 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3285349528479879		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.3285349528479879 | validation: 0.18213096559916112]
	TIME [epoch: 8.59 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2314311299364924		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.2314311299364924 | validation: 0.44339303602441277]
	TIME [epoch: 8.59 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29915054030706595		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.29915054030706595 | validation: 0.6458986228486014]
	TIME [epoch: 8.61 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2852067046237585		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.2852067046237585 | validation: 0.329242079390796]
	TIME [epoch: 8.58 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.275169547627213		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.275169547627213 | validation: 0.33982234269142986]
	TIME [epoch: 8.59 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3634109966401297		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.3634109966401297 | validation: 0.30768315639862587]
	TIME [epoch: 8.66 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26439013832951913		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.26439013832951913 | validation: 0.279392134970777]
	TIME [epoch: 8.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34449414024458197		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.34449414024458197 | validation: 0.187665622691298]
	TIME [epoch: 8.58 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25379411603476515		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.25379411603476515 | validation: 0.27344968207250037]
	TIME [epoch: 8.62 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34232774682072015		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.34232774682072015 | validation: 0.2622740973844091]
	TIME [epoch: 8.62 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3043664363420864		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.3043664363420864 | validation: 0.29588342402936557]
	TIME [epoch: 8.59 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6315670348974491		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.6315670348974491 | validation: 0.7230581976235384]
	TIME [epoch: 8.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40721358937418134		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.40721358937418134 | validation: 0.39619353196923685]
	TIME [epoch: 8.58 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26208775064687656		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.26208775064687656 | validation: 0.16668268464241565]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2447676066843431		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.2447676066843431 | validation: 0.39594826350383583]
	TIME [epoch: 8.64 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29447544022387695		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.29447544022387695 | validation: 0.21662206936031655]
	TIME [epoch: 8.59 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3625986745274172		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.3625986745274172 | validation: 0.15445002435284683]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22328896258299843		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.22328896258299843 | validation: 0.15240250233494196]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1975134852724278		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.1975134852724278 | validation: 0.49136489784586035]
	TIME [epoch: 8.59 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3105466185855696		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.3105466185855696 | validation: 0.3712137475813836]
	TIME [epoch: 8.59 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2737977517685116		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.2737977517685116 | validation: 0.727782368476625]
	TIME [epoch: 8.58 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3428542397648652		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.3428542397648652 | validation: 0.1997673720217543]
	TIME [epoch: 8.64 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23710111901011438		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.23710111901011438 | validation: 0.3711619271282719]
	TIME [epoch: 8.57 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28689201913770834		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.28689201913770834 | validation: 0.18875432510176837]
	TIME [epoch: 8.58 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25812189823484355		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.25812189823484355 | validation: 0.2539598038543147]
	TIME [epoch: 8.58 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28200257466591405		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.28200257466591405 | validation: 0.17252261659464452]
	TIME [epoch: 8.61 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2550919418887727		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.2550919418887727 | validation: 0.3908342843409215]
	TIME [epoch: 8.58 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32561376724039304		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.32561376724039304 | validation: 0.2774421374563868]
	TIME [epoch: 8.58 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600908429887571		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.2600908429887571 | validation: 0.1816345441393449]
	TIME [epoch: 8.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2887082426914115		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.2887082426914115 | validation: 0.2062924058932048]
	TIME [epoch: 8.59 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3271300914972645		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.3271300914972645 | validation: 0.1461859977748508]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22336907960741237		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.22336907960741237 | validation: 0.2611609516418386]
	TIME [epoch: 8.58 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717920472653988		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.2717920472653988 | validation: 0.49177884482880596]
	TIME [epoch: 8.62 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.250721264190728		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.250721264190728 | validation: 0.17569056196598098]
	TIME [epoch: 8.62 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2828567865219839		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.2828567865219839 | validation: 0.23149332728359825]
	TIME [epoch: 8.58 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27473585656669014		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.27473585656669014 | validation: 0.18544223493298106]
	TIME [epoch: 8.59 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24858470234483693		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.24858470234483693 | validation: 0.37001425747820044]
	TIME [epoch: 8.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23859638027495564		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.23859638027495564 | validation: 0.2474677797151863]
	TIME [epoch: 8.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665828772174029		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.2665828772174029 | validation: 0.2253702880634166]
	TIME [epoch: 8.58 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24513532054700948		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.24513532054700948 | validation: 0.17881317692196969]
	TIME [epoch: 8.58 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24584559535947417		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.24584559535947417 | validation: 0.3437184680742989]
	TIME [epoch: 8.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30458023273969853		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.30458023273969853 | validation: 0.30722800281409823]
	TIME [epoch: 8.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23427785565856393		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.23427785565856393 | validation: 0.17270840506249296]
	TIME [epoch: 8.58 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2856867865086387		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.2856867865086387 | validation: 0.23089922481783615]
	TIME [epoch: 8.58 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25932754529777696		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.25932754529777696 | validation: 0.2111512212236791]
	TIME [epoch: 8.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23923414507446203		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.23923414507446203 | validation: 0.18502545725930905]
	TIME [epoch: 8.59 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2678474100759701		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.2678474100759701 | validation: 0.19134911069081545]
	TIME [epoch: 8.59 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2084153081411005		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.2084153081411005 | validation: 0.2993132149753222]
	TIME [epoch: 8.59 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25628866344400836		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.25628866344400836 | validation: 0.2235445807501364]
	TIME [epoch: 8.62 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30494212561186107		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.30494212561186107 | validation: 0.20053692366488113]
	TIME [epoch: 8.63 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23683016235737755		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.23683016235737755 | validation: 0.4545138094658707]
	TIME [epoch: 8.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959456334085737		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.2959456334085737 | validation: 0.2646475143631513]
	TIME [epoch: 8.57 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21969891463260302		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.21969891463260302 | validation: 0.13549920967329065]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2101667758972078		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.2101667758972078 | validation: 0.4148790486409933]
	TIME [epoch: 8.63 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26985863560149476		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.26985863560149476 | validation: 0.22346193183168048]
	TIME [epoch: 8.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27965179819891844		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.27965179819891844 | validation: 0.17855030055679746]
	TIME [epoch: 8.59 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2720826747091064		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.2720826747091064 | validation: 0.4740061502617582]
	TIME [epoch: 8.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29171339366386856		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.29171339366386856 | validation: 0.2487049350588722]
	TIME [epoch: 8.57 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22527698414807987		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.22527698414807987 | validation: 0.19540100552382184]
	TIME [epoch: 8.58 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.187914436275857		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.187914436275857 | validation: 0.19335166682948382]
	TIME [epoch: 8.65 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21941553131940178		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.21941553131940178 | validation: 0.49970000899527456]
	TIME [epoch: 8.59 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24404704419677664		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.24404704419677664 | validation: 0.2683508899735306]
	TIME [epoch: 8.57 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24148850942338007		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.24148850942338007 | validation: 0.2774432842134925]
	TIME [epoch: 8.59 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2435641173660704		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.2435641173660704 | validation: 0.38870718481129385]
	TIME [epoch: 8.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2523410911161558		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.2523410911161558 | validation: 0.16679828786254017]
	TIME [epoch: 8.58 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18121779005040314		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.18121779005040314 | validation: 0.3368135216943158]
	TIME [epoch: 8.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20916048466926312		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.20916048466926312 | validation: 0.20324086222281346]
	TIME [epoch: 8.61 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2490455213199581		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.2490455213199581 | validation: 0.1963533744738914]
	TIME [epoch: 8.59 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21920475686035976		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.21920475686035976 | validation: 0.12616179950905346]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2063766413645595		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.2063766413645595 | validation: 0.48834388119814476]
	TIME [epoch: 8.62 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2504714624895209		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.2504714624895209 | validation: 0.6985256291616466]
	TIME [epoch: 8.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.254159874423815		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.254159874423815 | validation: 0.21855738713939038]
	TIME [epoch: 8.63 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24731732788460503		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.24731732788460503 | validation: 0.23102010522399619]
	TIME [epoch: 8.62 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21234067423541725		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.21234067423541725 | validation: 0.22942326245988504]
	TIME [epoch: 8.65 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2388306169785297		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.2388306169785297 | validation: 0.2883870991299953]
	TIME [epoch: 8.59 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21053223118532083		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.21053223118532083 | validation: 0.27149482034281297]
	TIME [epoch: 8.63 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21006011158035434		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.21006011158035434 | validation: 0.24361589313406545]
	TIME [epoch: 8.61 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21166093332932406		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.21166093332932406 | validation: 0.16440220876380027]
	TIME [epoch: 8.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20245055650997287		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.20245055650997287 | validation: 0.6650473630725413]
	TIME [epoch: 8.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29523954149342635		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.29523954149342635 | validation: 0.3186140319122901]
	TIME [epoch: 8.64 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.214149565846928		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.214149565846928 | validation: 0.14383206610943106]
	TIME [epoch: 8.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1750996634590074		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.1750996634590074 | validation: 0.256769752139387]
	TIME [epoch: 8.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19311162601032256		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.19311162601032256 | validation: 0.25264483131941906]
	TIME [epoch: 8.62 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2259859851978097		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.2259859851978097 | validation: 0.15397216599673888]
	TIME [epoch: 8.62 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17400354118218853		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.17400354118218853 | validation: 0.43019043707207477]
	TIME [epoch: 8.62 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2656018233797928		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.2656018233797928 | validation: 0.24591220397220426]
	TIME [epoch: 8.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18878680940502393		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.18878680940502393 | validation: 0.11718653932500006]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18997317073832332		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.18997317073832332 | validation: 0.2673657492120669]
	TIME [epoch: 8.63 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.272122430308957		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.272122430308957 | validation: 0.24583550526111125]
	TIME [epoch: 8.65 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23161618572024495		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.23161618572024495 | validation: 0.31988898016085904]
	TIME [epoch: 8.59 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2832606745493071		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.2832606745493071 | validation: 0.14145066844285253]
	TIME [epoch: 8.63 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21180679513700723		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.21180679513700723 | validation: 0.18296699294580238]
	TIME [epoch: 8.67 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19079424217784086		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.19079424217784086 | validation: 0.19966610656291855]
	TIME [epoch: 8.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23349296580191173		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.23349296580191173 | validation: 0.23666595171680693]
	TIME [epoch: 8.59 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2028383056689868		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.2028383056689868 | validation: 0.16560858056053823]
	TIME [epoch: 8.61 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21200381520668166		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.21200381520668166 | validation: 0.36517615455880414]
	TIME [epoch: 8.61 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18381145223299392		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.18381145223299392 | validation: 0.11126042701384724]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.260403903619731		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.260403903619731 | validation: 0.28784716766370116]
	TIME [epoch: 8.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.238970213681604		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.238970213681604 | validation: 0.21383653814802328]
	TIME [epoch: 8.61 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21461927675205716		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.21461927675205716 | validation: 0.18014009363732497]
	TIME [epoch: 8.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1822707035890238		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.1822707035890238 | validation: 0.21737932887479627]
	TIME [epoch: 8.62 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18825795744015605		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.18825795744015605 | validation: 0.3642998823866234]
	TIME [epoch: 8.62 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2195399137136628		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.2195399137136628 | validation: 0.2301799939443934]
	TIME [epoch: 8.62 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20590292847523317		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.20590292847523317 | validation: 0.23264529845195805]
	TIME [epoch: 8.59 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22598320767217447		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.22598320767217447 | validation: 0.1974794991238542]
	TIME [epoch: 8.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19687597841746465		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.19687597841746465 | validation: 0.3060571275369778]
	TIME [epoch: 8.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24865815995834173		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.24865815995834173 | validation: 0.2972871277466993]
	TIME [epoch: 8.62 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21626801423507355		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.21626801423507355 | validation: 0.15305275775241073]
	TIME [epoch: 8.59 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20363355979032352		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.20363355979032352 | validation: 0.14590206329106142]
	TIME [epoch: 8.61 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2407484264743934		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.2407484264743934 | validation: 0.18788349447871194]
	TIME [epoch: 8.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2600295821339794		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.2600295821339794 | validation: 0.2011352519727545]
	TIME [epoch: 8.62 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21694919854714323		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.21694919854714323 | validation: 0.25030203143924623]
	TIME [epoch: 8.64 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20715682678019673		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.20715682678019673 | validation: 0.221305803086107]
	TIME [epoch: 8.59 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24892002922554712		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.24892002922554712 | validation: 0.1461821382424575]
	TIME [epoch: 8.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15527098633285735		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.15527098633285735 | validation: 0.10967733650938581]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20203783525433786		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.20203783525433786 | validation: 0.16436472884496037]
	TIME [epoch: 8.59 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18570298494295062		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.18570298494295062 | validation: 0.14670893127828274]
	TIME [epoch: 8.59 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1488491814737633		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.1488491814737633 | validation: 0.1913257808001957]
	TIME [epoch: 8.61 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21620372994338227		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.21620372994338227 | validation: 0.45349775114562924]
	TIME [epoch: 8.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30110053642726		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.30110053642726 | validation: 0.2107591769777462]
	TIME [epoch: 8.59 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1681659767865491		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.1681659767865491 | validation: 0.24641875273862265]
	TIME [epoch: 8.59 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18298665781604312		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.18298665781604312 | validation: 0.21803161487194972]
	TIME [epoch: 8.61 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23440147429877273		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.23440147429877273 | validation: 0.17130044927448043]
	TIME [epoch: 8.59 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17381970886843526		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.17381970886843526 | validation: 0.3442900609850954]
	TIME [epoch: 8.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19081863689103612		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.19081863689103612 | validation: 0.29471020513869056]
	TIME [epoch: 8.59 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24097155206867776		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.24097155206867776 | validation: 0.30041213982562576]
	TIME [epoch: 8.61 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18836543674192127		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.18836543674192127 | validation: 0.22088821000237388]
	TIME [epoch: 8.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18697360959605908		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.18697360959605908 | validation: 0.21571074766907034]
	TIME [epoch: 8.59 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1765333480726743		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.1765333480726743 | validation: 0.1815453919355046]
	TIME [epoch: 8.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17529228908583863		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.17529228908583863 | validation: 0.39975958241368215]
	TIME [epoch: 8.63 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1957475761172832		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.1957475761172832 | validation: 0.17900953037332257]
	TIME [epoch: 8.62 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15860853594193394		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.15860853594193394 | validation: 0.1695665259058967]
	TIME [epoch: 8.58 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25709466169441		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.25709466169441 | validation: 0.4557647337868997]
	TIME [epoch: 8.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2128017985427272		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.2128017985427272 | validation: 0.20956246568325027]
	TIME [epoch: 8.65 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1837032728417012		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.1837032728417012 | validation: 0.15992394958835737]
	TIME [epoch: 8.58 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15909337618421163		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.15909337618421163 | validation: 0.3081517347287546]
	TIME [epoch: 8.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1783978483258836		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.1783978483258836 | validation: 0.27212415420948577]
	TIME [epoch: 8.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16812794339494477		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.16812794339494477 | validation: 0.3393766477758412]
	TIME [epoch: 8.63 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1816539304533607		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.1816539304533607 | validation: 0.14772354385447867]
	TIME [epoch: 8.59 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16413006827565382		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.16413006827565382 | validation: 0.16452257642137458]
	TIME [epoch: 8.57 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17869937420886328		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.17869937420886328 | validation: 0.18911657562774326]
	TIME [epoch: 8.61 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1795914738952476		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.1795914738952476 | validation: 0.30701197336659714]
	TIME [epoch: 8.59 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3357362521796604		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.3357362521796604 | validation: 0.20388374823765457]
	TIME [epoch: 8.57 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17485420146899852		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.17485420146899852 | validation: 0.25040681049524743]
	TIME [epoch: 8.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24701733206210416		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.24701733206210416 | validation: 0.15709445257512422]
	TIME [epoch: 8.61 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15790758847289782		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.15790758847289782 | validation: 0.12460517740197573]
	TIME [epoch: 8.64 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18305753356954466		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.18305753356954466 | validation: 0.2271412338476405]
	TIME [epoch: 8.58 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20241490178856		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.20241490178856 | validation: 0.23069649897283304]
	TIME [epoch: 8.58 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1688261199450956		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.1688261199450956 | validation: 0.12762669120580677]
	TIME [epoch: 8.61 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16219978599581059		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.16219978599581059 | validation: 0.15433614616088037]
	TIME [epoch: 8.59 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14745803632632692		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.14745803632632692 | validation: 0.12731021340959628]
	TIME [epoch: 8.58 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16123097754339766		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.16123097754339766 | validation: 0.4002507967387622]
	TIME [epoch: 8.59 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2130466012892575		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.2130466012892575 | validation: 0.12635109542601808]
	TIME [epoch: 8.62 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15975066522859033		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.15975066522859033 | validation: 0.10681971596608944]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17185344270450018		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.17185344270450018 | validation: 0.16570492012964927]
	TIME [epoch: 8.59 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19155101990367498		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.19155101990367498 | validation: 0.2654147947717945]
	TIME [epoch: 8.59 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15389947040527724		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.15389947040527724 | validation: 0.13230029595650394]
	TIME [epoch: 8.63 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15551552866812202		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.15551552866812202 | validation: 0.14071016296051814]
	TIME [epoch: 8.62 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1534456349492492		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.1534456349492492 | validation: 0.2464605629356287]
	TIME [epoch: 8.58 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21502656442753043		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.21502656442753043 | validation: 0.14854579996275458]
	TIME [epoch: 8.58 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18024198075282705		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.18024198075282705 | validation: 0.12755433075877476]
	TIME [epoch: 8.61 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20980115060012441		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.20980115060012441 | validation: 0.16191007829511928]
	TIME [epoch: 8.58 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1708753003190838		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.1708753003190838 | validation: 0.12495579392966555]
	TIME [epoch: 8.59 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18458012329120538		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.18458012329120538 | validation: 0.1842144718365164]
	TIME [epoch: 8.61 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2460519473115143		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.2460519473115143 | validation: 0.2005098506026099]
	TIME [epoch: 8.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2154939992134235		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.2154939992134235 | validation: 0.14599853787005138]
	TIME [epoch: 8.58 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15966070580784542		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.15966070580784542 | validation: 0.2021747032012139]
	TIME [epoch: 8.59 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19208337406141052		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.19208337406141052 | validation: 0.14153449576205918]
	TIME [epoch: 8.61 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14882711415519534		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.14882711415519534 | validation: 0.11139492872186674]
	TIME [epoch: 8.59 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18331510947126312		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.18331510947126312 | validation: 0.1401251360613716]
	TIME [epoch: 8.58 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18065257894423575		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.18065257894423575 | validation: 0.1499243116260371]
	TIME [epoch: 8.59 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20303194556917675		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.20303194556917675 | validation: 0.16639799743847633]
	TIME [epoch: 8.61 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16258670766093397		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.16258670766093397 | validation: 0.16880626178231417]
	TIME [epoch: 8.59 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15597741659020314		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.15597741659020314 | validation: 0.15313231931066296]
	TIME [epoch: 8.59 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18622290909431546		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.18622290909431546 | validation: 0.21272969587972232]
	TIME [epoch: 8.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17308032779326904		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.17308032779326904 | validation: 0.24577675077555977]
	TIME [epoch: 8.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14991809127736616		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.14991809127736616 | validation: 0.19160914821916009]
	TIME [epoch: 8.59 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17082660951870715		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.17082660951870715 | validation: 0.21102750284626853]
	TIME [epoch: 8.64 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15571602596237882		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.15571602596237882 | validation: 0.1096603374883936]
	TIME [epoch: 8.59 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1519444842189592		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.1519444842189592 | validation: 0.14697814698502598]
	TIME [epoch: 8.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17264877750813587		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.17264877750813587 | validation: 0.1833726497545992]
	TIME [epoch: 8.65 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21039851842229265		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.21039851842229265 | validation: 0.2945160459623365]
	TIME [epoch: 8.57 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21897668419523558		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.21897668419523558 | validation: 0.1583897770263779]
	TIME [epoch: 8.58 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14684945562309418		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.14684945562309418 | validation: 0.11660886158628385]
	TIME [epoch: 8.61 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1806393200422862		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.1806393200422862 | validation: 0.17049938898397102]
	TIME [epoch: 8.64 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13812270644816685		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.13812270644816685 | validation: 0.13401024676231035]
	TIME [epoch: 8.58 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16934355949149146		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.16934355949149146 | validation: 0.08619737946766004]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17464972030514536		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.17464972030514536 | validation: 0.09985413467311882]
	TIME [epoch: 8.61 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1655402335390928		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.1655402335390928 | validation: 0.241198130141791]
	TIME [epoch: 8.57 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14784288601913417		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.14784288601913417 | validation: 0.1315766496004943]
	TIME [epoch: 8.58 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1453953683408521		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.1453953683408521 | validation: 0.14409666209853716]
	TIME [epoch: 8.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1476426924842442		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.1476426924842442 | validation: 0.2231645390662375]
	TIME [epoch: 8.58 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20152277355099524		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.20152277355099524 | validation: 0.09121221137709412]
	TIME [epoch: 8.59 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16599379796219804		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.16599379796219804 | validation: 0.2086038355313603]
	TIME [epoch: 8.62 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17679773739988797		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.17679773739988797 | validation: 0.12778891128349906]
	TIME [epoch: 8.59 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15696164201497279		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.15696164201497279 | validation: 0.2041587733466259]
	TIME [epoch: 8.58 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1618314304538707		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.1618314304538707 | validation: 0.129155443940152]
	TIME [epoch: 8.57 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28985244556072565		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.28985244556072565 | validation: 0.3872356663054111]
	TIME [epoch: 8.58 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19965470397108742		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.19965470397108742 | validation: 0.15099404215889597]
	TIME [epoch: 8.59 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466862457579658		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.1466862457579658 | validation: 0.12186463596264195]
	TIME [epoch: 8.59 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14110842486755373		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.14110842486755373 | validation: 0.297904453835213]
	TIME [epoch: 8.58 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14484255115977843		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.14484255115977843 | validation: 0.15942827316015123]
	TIME [epoch: 8.57 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14046389111026752		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.14046389111026752 | validation: 0.1623766884433166]
	TIME [epoch: 8.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18155265627276412		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.18155265627276412 | validation: 0.21390584524265302]
	TIME [epoch: 8.58 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15755481818305592		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.15755481818305592 | validation: 0.09572190454460522]
	TIME [epoch: 8.58 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15723896343194504		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.15723896343194504 | validation: 0.3566566786038764]
	TIME [epoch: 8.57 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17055548419853178		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.17055548419853178 | validation: 0.1173765531625793]
	TIME [epoch: 8.61 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15849739570493487		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.15849739570493487 | validation: 0.22379821507374711]
	TIME [epoch: 8.58 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14609715796617398		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.14609715796617398 | validation: 0.2677260596470447]
	TIME [epoch: 8.59 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19322650498850072		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.19322650498850072 | validation: 0.10501815786040013]
	TIME [epoch: 8.62 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14171311125600208		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.14171311125600208 | validation: 0.15034810419268455]
	TIME [epoch: 8.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12125804679761878		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.12125804679761878 | validation: 0.1308709480311807]
	TIME [epoch: 8.58 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1408552933508899		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.1408552933508899 | validation: 0.0961511221919458]
	TIME [epoch: 8.58 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15507965873945967		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.15507965873945967 | validation: 0.1068409035674106]
	TIME [epoch: 8.58 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1726866476841435		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.1726866476841435 | validation: 0.10550481463977124]
	TIME [epoch: 8.59 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1520740863954027		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.1520740863954027 | validation: 0.2006035587223482]
	TIME [epoch: 8.58 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1600641200945649		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.1600641200945649 | validation: 0.08474598106393826]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_534.pth
	Model improved!!!
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12102016658563483		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.12102016658563483 | validation: 0.08904072482901706]
	TIME [epoch: 8.63 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13514821272340768		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.13514821272340768 | validation: 0.2017481580771934]
	TIME [epoch: 8.59 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22697373626111655		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.22697373626111655 | validation: 0.18253087090710496]
	TIME [epoch: 8.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15329274743904867		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.15329274743904867 | validation: 0.12291008304925222]
	TIME [epoch: 8.59 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13557581057264198		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.13557581057264198 | validation: 0.09148194545710028]
	TIME [epoch: 8.62 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14291822445598473		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.14291822445598473 | validation: 0.26185535801179693]
	TIME [epoch: 8.59 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17491661313149434		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.17491661313149434 | validation: 0.32392841108404247]
	TIME [epoch: 8.62 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16377503703915713		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.16377503703915713 | validation: 0.18024329902977357]
	TIME [epoch: 8.58 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18537807017640656		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.18537807017640656 | validation: 0.17069881297956935]
	TIME [epoch: 8.59 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17711911014613332		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.17711911014613332 | validation: 0.11634833933253419]
	TIME [epoch: 8.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13927868216366587		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.13927868216366587 | validation: 0.11828142786896925]
	TIME [epoch: 8.62 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1415584626445549		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.1415584626445549 | validation: 0.19550992604975376]
	TIME [epoch: 8.62 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13381471645110127		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.13381471645110127 | validation: 0.12503460641682324]
	TIME [epoch: 8.61 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11633793078187613		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.11633793078187613 | validation: 0.12757337065570684]
	TIME [epoch: 8.58 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15183503541285673		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.15183503541285673 | validation: 0.09994781273069636]
	TIME [epoch: 8.61 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13704275009197767		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.13704275009197767 | validation: 0.11973488442840188]
	TIME [epoch: 8.62 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16624182677536248		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.16624182677536248 | validation: 0.14157310434094256]
	TIME [epoch: 8.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13974225563092163		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.13974225563092163 | validation: 0.1080441310496186]
	TIME [epoch: 8.59 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13815663763671834		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.13815663763671834 | validation: 0.1715237572077419]
	TIME [epoch: 8.58 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15056528240944034		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.15056528240944034 | validation: 0.11949343622925643]
	TIME [epoch: 8.64 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14513835854919452		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.14513835854919452 | validation: 0.11442401137158145]
	TIME [epoch: 8.61 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14860009807845836		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.14860009807845836 | validation: 0.2589496867990086]
	TIME [epoch: 8.58 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1596572116991059		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.1596572116991059 | validation: 0.11905680920407137]
	TIME [epoch: 8.59 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1273427358258316		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.1273427358258316 | validation: 0.20852701898529302]
	TIME [epoch: 8.62 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15362966514273896		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.15362966514273896 | validation: 0.1247836737239478]
	TIME [epoch: 8.59 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14114460865981926		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.14114460865981926 | validation: 0.14561447487841334]
	TIME [epoch: 8.58 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12751853453779943		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.12751853453779943 | validation: 0.16659205704190222]
	TIME [epoch: 8.64 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1407306906689578		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.1407306906689578 | validation: 0.1734608323021719]
	TIME [epoch: 8.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16275516597793113		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.16275516597793113 | validation: 0.2661229426161252]
	TIME [epoch: 8.59 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13452440258435872		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.13452440258435872 | validation: 0.11567642747022658]
	TIME [epoch: 8.59 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13433633419580618		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.13433633419580618 | validation: 0.12802188584505475]
	TIME [epoch: 8.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12645608916206325		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.12645608916206325 | validation: 0.11936745647644217]
	TIME [epoch: 8.61 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1969696192384492		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.1969696192384492 | validation: 0.21759901370818296]
	TIME [epoch: 8.59 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14228943042751727		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.14228943042751727 | validation: 0.14036156223506346]
	TIME [epoch: 8.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12290066708049503		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.12290066708049503 | validation: 0.14517032668598817]
	TIME [epoch: 8.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14938554713639918		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.14938554713639918 | validation: 0.08662145456293316]
	TIME [epoch: 8.59 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13676309528374223		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.13676309528374223 | validation: 0.15669846736075438]
	TIME [epoch: 8.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13179493030152234		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.13179493030152234 | validation: 0.12216655393757045]
	TIME [epoch: 8.58 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1397949050738747		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.1397949050738747 | validation: 0.12629361530275934]
	TIME [epoch: 8.59 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13466944945782103		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.13466944945782103 | validation: 0.07983681715192908]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_574.pth
	Model improved!!!
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13761519203598388		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.13761519203598388 | validation: 0.18034581363652538]
	TIME [epoch: 8.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1466829805486259		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.1466829805486259 | validation: 0.10560581660942181]
	TIME [epoch: 8.58 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13553860419826708		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.13553860419826708 | validation: 0.09321949528976467]
	TIME [epoch: 8.62 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13604020252129242		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.13604020252129242 | validation: 0.17248741133590362]
	TIME [epoch: 8.62 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12002229950086203		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.12002229950086203 | validation: 0.11829506678795515]
	TIME [epoch: 8.58 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11363348064841645		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.11363348064841645 | validation: 0.2849664507275791]
	TIME [epoch: 8.58 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.290483665784256		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.290483665784256 | validation: 0.08319300482018155]
	TIME [epoch: 8.59 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09702498775540244		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.09702498775540244 | validation: 0.08379954657452549]
	TIME [epoch: 8.62 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10528369515829879		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.10528369515829879 | validation: 0.09335159696501572]
	TIME [epoch: 8.59 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12928799236562294		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.12928799236562294 | validation: 0.1252179909719608]
	TIME [epoch: 8.59 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12449567014037136		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.12449567014037136 | validation: 0.07712324365820483]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10180789957833905		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.10180789957833905 | validation: 0.13197882566857097]
	TIME [epoch: 8.61 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10102382511115664		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.10102382511115664 | validation: 0.12655508761844914]
	TIME [epoch: 8.58 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11320894386989896		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.11320894386989896 | validation: 0.16301507060829412]
	TIME [epoch: 8.59 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11595590186885466		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.11595590186885466 | validation: 0.08615844553939359]
	TIME [epoch: 8.59 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12702327433170896		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.12702327433170896 | validation: 0.07510242684751191]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1544758969508558		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.1544758969508558 | validation: 0.2568014228686901]
	TIME [epoch: 8.61 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1525294577465186		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.1525294577465186 | validation: 0.09326488241033216]
	TIME [epoch: 8.61 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1326963291016546		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.1326963291016546 | validation: 0.1041967253392459]
	TIME [epoch: 8.64 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10617314628681554		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.10617314628681554 | validation: 0.10386535976269695]
	TIME [epoch: 8.61 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14234289717663579		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.14234289717663579 | validation: 0.11385025015941018]
	TIME [epoch: 8.61 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13182699853740387		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.13182699853740387 | validation: 0.18255917619003265]
	TIME [epoch: 8.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13530383380634436		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.13530383380634436 | validation: 0.1887314905894383]
	TIME [epoch: 8.63 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14502469442280413		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.14502469442280413 | validation: 0.15786133892147144]
	TIME [epoch: 8.61 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15355263282554896		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.15355263282554896 | validation: 0.1347513703697999]
	TIME [epoch: 8.62 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14166076221077603		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.14166076221077603 | validation: 0.1990085185932321]
	TIME [epoch: 8.66 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1402606141321205		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.1402606141321205 | validation: 0.10666114137003865]
	TIME [epoch: 8.63 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11763385710860616		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.11763385710860616 | validation: 0.09812966755628412]
	TIME [epoch: 8.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10243962907076835		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.10243962907076835 | validation: 0.12662795650073447]
	TIME [epoch: 8.61 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12811904951272718		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.12811904951272718 | validation: 0.11968102404494851]
	TIME [epoch: 8.65 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11368856773037621		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.11368856773037621 | validation: 0.09758536817884003]
	TIME [epoch: 8.61 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14708089646154873		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.14708089646154873 | validation: 0.13976645701781815]
	TIME [epoch: 8.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13698052801976943		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.13698052801976943 | validation: 0.20643994731177026]
	TIME [epoch: 8.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1433614377863679		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.1433614377863679 | validation: 0.16254048218731895]
	TIME [epoch: 8.61 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1452676880411586		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.1452676880411586 | validation: 0.08804536099970747]
	TIME [epoch: 8.63 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13902337681116284		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.13902337681116284 | validation: 0.09686338055703551]
	TIME [epoch: 8.65 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11568109069625114		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.11568109069625114 | validation: 0.18526398174831887]
	TIME [epoch: 8.59 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10509966643712705		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.10509966643712705 | validation: 0.19341495800610845]
	TIME [epoch: 8.59 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13682716487526422		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.13682716487526422 | validation: 0.21202153086173048]
	TIME [epoch: 8.63 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11743233988964157		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.11743233988964157 | validation: 0.08356339869836982]
	TIME [epoch: 8.59 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10062858494921392		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.10062858494921392 | validation: 0.15190241922447711]
	TIME [epoch: 8.61 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12851226677053668		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.12851226677053668 | validation: 0.15347046777501624]
	TIME [epoch: 8.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1293316823770428		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.1293316823770428 | validation: 0.0777920880427066]
	TIME [epoch: 8.62 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12121172969466018		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.12121172969466018 | validation: 0.08744582233171969]
	TIME [epoch: 8.65 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10962053078377895		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.10962053078377895 | validation: 0.23520310778787773]
	TIME [epoch: 8.61 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11181333826568304		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.11181333826568304 | validation: 0.10908402445373261]
	TIME [epoch: 8.61 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1140442399103567		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.1140442399103567 | validation: 0.1179308178421826]
	TIME [epoch: 8.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.168547692443973		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.168547692443973 | validation: 0.07591957051224596]
	TIME [epoch: 8.59 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10668705136985453		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.10668705136985453 | validation: 0.08644814012640578]
	TIME [epoch: 8.61 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12380240610497913		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.12380240610497913 | validation: 0.18947551260719217]
	TIME [epoch: 8.62 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1797637048883866		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.1797637048883866 | validation: 0.12521054842764287]
	TIME [epoch: 8.62 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.102681343983795		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.102681343983795 | validation: 0.08155980714707683]
	TIME [epoch: 8.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10117586209874793		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.10117586209874793 | validation: 0.08299443235520529]
	TIME [epoch: 8.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096433824627262		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.096433824627262 | validation: 0.2039822320652898]
	TIME [epoch: 8.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1320741074101204		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.1320741074101204 | validation: 0.13064552199236568]
	TIME [epoch: 8.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10710785771137528		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.10710785771137528 | validation: 0.09241028548180741]
	TIME [epoch: 8.61 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10555364174728994		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.10555364174728994 | validation: 0.08365626966674186]
	TIME [epoch: 8.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11030391783535269		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.11030391783535269 | validation: 0.205139550905602]
	TIME [epoch: 8.67 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11390093116165309		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.11390093116165309 | validation: 0.09826401921875585]
	TIME [epoch: 8.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13481573419663306		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.13481573419663306 | validation: 0.13601586184055098]
	TIME [epoch: 8.58 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12599189213953915		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.12599189213953915 | validation: 0.0738950070307321]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10761707426301866		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.10761707426301866 | validation: 0.11090719296554477]
	TIME [epoch: 8.62 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.113938776182767		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.113938776182767 | validation: 0.21929918055107378]
	TIME [epoch: 8.59 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1243591891180253		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.1243591891180253 | validation: 0.10957603541845676]
	TIME [epoch: 8.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12573391525460526		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.12573391525460526 | validation: 0.09748908643734958]
	TIME [epoch: 8.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11235055448006763		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.11235055448006763 | validation: 0.0710894079317613]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11062366269824415		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.11062366269824415 | validation: 0.09610320691357427]
	TIME [epoch: 8.59 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09793123964365517		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.09793123964365517 | validation: 0.07011107792480689]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11118739829751541		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.11118739829751541 | validation: 0.1263144646297787]
	TIME [epoch: 8.59 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1251461777420344		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.1251461777420344 | validation: 0.2212788614978384]
	TIME [epoch: 8.58 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11591359373062819		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.11591359373062819 | validation: 0.14885845029350367]
	TIME [epoch: 8.58 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11558486627698791		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.11558486627698791 | validation: 0.07844820928325205]
	TIME [epoch: 8.57 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10270594567308067		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.10270594567308067 | validation: 0.12075759441845843]
	TIME [epoch: 8.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11451573252380934		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.11451573252380934 | validation: 0.06993650305212959]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09074669995807022		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.09074669995807022 | validation: 0.13735242753537547]
	TIME [epoch: 8.57 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11708227989086051		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.11708227989086051 | validation: 0.07581959264937382]
	TIME [epoch: 8.57 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11568376501007493		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.11568376501007493 | validation: 0.07677291222243571]
	TIME [epoch: 8.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08642377963313799		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.08642377963313799 | validation: 0.09546458128787039]
	TIME [epoch: 8.58 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1015610985313408		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.1015610985313408 | validation: 0.09641770862657857]
	TIME [epoch: 8.57 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10460092747298584		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.10460092747298584 | validation: 0.10352036421631565]
	TIME [epoch: 8.62 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10381015222662575		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.10381015222662575 | validation: 0.09783103469569106]
	TIME [epoch: 8.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10505350781674323		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.10505350781674323 | validation: 0.07326628754231286]
	TIME [epoch: 8.56 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09403042115217905		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.09403042115217905 | validation: 0.14446581988276158]
	TIME [epoch: 8.58 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10038701159703414		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.10038701159703414 | validation: 0.0802076349644199]
	TIME [epoch: 8.61 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11403830239451271		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.11403830239451271 | validation: 0.07368151147455608]
	TIME [epoch: 8.59 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10606218141621764		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.10606218141621764 | validation: 0.08340446973685758]
	TIME [epoch: 8.56 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09473227989805397		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.09473227989805397 | validation: 0.12013745814281228]
	TIME [epoch: 8.58 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09105195196509516		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.09105195196509516 | validation: 0.07882260759754]
	TIME [epoch: 8.58 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10359556098876048		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.10359556098876048 | validation: 0.1020200493382103]
	TIME [epoch: 8.61 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09661624514522829		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.09661624514522829 | validation: 0.11923964100771066]
	TIME [epoch: 8.62 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09475335080419259		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.09475335080419259 | validation: 0.10460643008985722]
	TIME [epoch: 8.56 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11958895064910742		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.11958895064910742 | validation: 0.07606573774216902]
	TIME [epoch: 8.58 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09212215128315833		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.09212215128315833 | validation: 0.08913797792241585]
	TIME [epoch: 8.57 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14787922453830643		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.14787922453830643 | validation: 0.17973202281149508]
	TIME [epoch: 8.59 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11259352416351534		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.11259352416351534 | validation: 0.11379480188291632]
	TIME [epoch: 8.57 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09306149246919701		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.09306149246919701 | validation: 0.2027323895353882]
	TIME [epoch: 8.62 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1741996214289833		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.1741996214289833 | validation: 0.06269570135941178]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08158051994748135		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.08158051994748135 | validation: 0.08296548186185293]
	TIME [epoch: 8.55 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10653417658593974		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.10653417658593974 | validation: 0.09549968843382334]
	TIME [epoch: 8.57 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12011219279310323		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.12011219279310323 | validation: 0.10693298815570379]
	TIME [epoch: 8.59 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10360483765034609		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.10360483765034609 | validation: 0.09673951418683638]
	TIME [epoch: 8.58 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08314688247286202		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.08314688247286202 | validation: 0.06415866396826578]
	TIME [epoch: 8.59 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08345793882769094		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.08345793882769094 | validation: 0.07415853178621314]
	TIME [epoch: 8.57 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10018825955981711		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.10018825955981711 | validation: 0.10292525390487392]
	TIME [epoch: 8.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08976491104829132		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.08976491104829132 | validation: 0.11046450444120551]
	TIME [epoch: 8.56 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09676490662369804		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.09676490662369804 | validation: 0.10621502449224593]
	TIME [epoch: 8.57 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16314082438955446		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.16314082438955446 | validation: 0.10531180606250143]
	TIME [epoch: 8.57 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09185527563767462		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.09185527563767462 | validation: 0.07945170474820343]
	TIME [epoch: 8.59 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07820850169637676		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.07820850169637676 | validation: 0.06873723401153176]
	TIME [epoch: 8.62 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11059402715662567		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.11059402715662567 | validation: 0.1226303353642743]
	TIME [epoch: 8.59 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08847259992896082		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.08847259992896082 | validation: 0.0727679332370194]
	TIME [epoch: 8.57 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08092168388886965		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.08092168388886965 | validation: 0.07572303794685648]
	TIME [epoch: 8.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07742347264571324		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.07742347264571324 | validation: 0.06603951859444636]
	TIME [epoch: 8.57 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18974530873496892		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.18974530873496892 | validation: 0.10595563472629338]
	TIME [epoch: 8.58 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10006762778858243		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.10006762778858243 | validation: 0.0615131242877628]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_689.pth
	Model improved!!!
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09028325769509397		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.09028325769509397 | validation: 0.07848281661032508]
	TIME [epoch: 8.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06863472488435149		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.06863472488435149 | validation: 0.10026054981432203]
	TIME [epoch: 8.58 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1205863754116846		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.1205863754116846 | validation: 0.13141943366425496]
	TIME [epoch: 8.57 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08383413377940527		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.08383413377940527 | validation: 0.06718860743304486]
	TIME [epoch: 8.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1255992933806149		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.1255992933806149 | validation: 0.05379648526736992]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_694.pth
	Model improved!!!
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10669619482289053		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.10669619482289053 | validation: 0.13525717641096857]
	TIME [epoch: 8.59 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08218567973212494		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.08218567973212494 | validation: 0.08617728541639695]
	TIME [epoch: 8.57 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19846328347930248		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.19846328347930248 | validation: 0.11358337217778972]
	TIME [epoch: 8.59 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11102770930993819		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.11102770930993819 | validation: 0.1563869191891708]
	TIME [epoch: 8.58 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09381284340654465		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.09381284340654465 | validation: 0.0750490740172596]
	TIME [epoch: 8.57 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11082125496880549		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.11082125496880549 | validation: 0.05257838172953683]
	TIME [epoch: 8.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0834461212016245		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.0834461212016245 | validation: 0.06768592462542003]
	TIME [epoch: 8.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08036995971860528		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.08036995971860528 | validation: 0.08418669028575114]
	TIME [epoch: 8.57 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09814240920852352		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.09814240920852352 | validation: 0.12824743897223112]
	TIME [epoch: 8.59 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09229959704908945		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.09229959704908945 | validation: 0.11804287017597123]
	TIME [epoch: 8.61 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19486158747208113		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.19486158747208113 | validation: 0.06269825936891844]
	TIME [epoch: 8.59 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10302218920440472		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.10302218920440472 | validation: 0.13445592574833917]
	TIME [epoch: 8.57 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10886116472344502		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.10886116472344502 | validation: 0.1604725945037864]
	TIME [epoch: 8.57 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0992393877530142		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.0992393877530142 | validation: 0.0755463406369653]
	TIME [epoch: 8.58 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09933104147623391		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.09933104147623391 | validation: 0.08554869136892448]
	TIME [epoch: 8.59 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09356928420783894		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.09356928420783894 | validation: 0.0843686787208334]
	TIME [epoch: 8.64 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07952827371133567		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.07952827371133567 | validation: 0.07075002714930725]
	TIME [epoch: 8.57 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09856717452372657		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.09856717452372657 | validation: 0.08821194232825379]
	TIME [epoch: 8.58 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07974006420057252		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.07974006420057252 | validation: 0.1270722403114488]
	TIME [epoch: 8.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1092679098167236		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.1092679098167236 | validation: 0.04750891551803296]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_714.pth
	Model improved!!!
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08243399525610373		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.08243399525610373 | validation: 0.06512166264315507]
	TIME [epoch: 8.63 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07441585288318078		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.07441585288318078 | validation: 0.10038308493255153]
	TIME [epoch: 8.66 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18126129899400004		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.18126129899400004 | validation: 0.06730967174054978]
	TIME [epoch: 8.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08553032392283848		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.08553032392283848 | validation: 0.09301422819854144]
	TIME [epoch: 8.59 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0935758774030854		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.0935758774030854 | validation: 0.11654273699367412]
	TIME [epoch: 8.61 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09477707251535557		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.09477707251535557 | validation: 0.08888585301292598]
	TIME [epoch: 8.59 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07384339448595077		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.07384339448595077 | validation: 0.10007767155027728]
	TIME [epoch: 8.63 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08031142572041469		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.08031142572041469 | validation: 0.10229645386557898]
	TIME [epoch: 8.61 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07417885730984901		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.07417885730984901 | validation: 0.09781906537530816]
	TIME [epoch: 8.59 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10399947123859077		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.10399947123859077 | validation: 0.06180900999638732]
	TIME [epoch: 8.62 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10314793800371576		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.10314793800371576 | validation: 0.05427588599299245]
	TIME [epoch: 8.61 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08275565636481645		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.08275565636481645 | validation: 0.06083690856309955]
	TIME [epoch: 8.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19103041454840833		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.19103041454840833 | validation: 0.21279149128748004]
	TIME [epoch: 8.61 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11581963014029566		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.11581963014029566 | validation: 0.06479654993991459]
	TIME [epoch: 8.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07166612838327213		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.07166612838327213 | validation: 0.04959002432717624]
	TIME [epoch: 8.66 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094469247322148		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.07094469247322148 | validation: 0.08174648212455395]
	TIME [epoch: 8.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07543769159387861		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.07543769159387861 | validation: 0.05577695922913704]
	TIME [epoch: 8.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06942987786728197		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.06942987786728197 | validation: 0.07575917210558883]
	TIME [epoch: 8.61 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477720065006501		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.06477720065006501 | validation: 0.062197509561877855]
	TIME [epoch: 8.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06998242265120297		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.06998242265120297 | validation: 0.054457035561924674]
	TIME [epoch: 8.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08327434207919972		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.08327434207919972 | validation: 0.09516676414933078]
	TIME [epoch: 8.61 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08130149479047034		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.08130149479047034 | validation: 0.0647935145301746]
	TIME [epoch: 8.63 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07833551650105369		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.07833551650105369 | validation: 0.09464825185949008]
	TIME [epoch: 8.59 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08780515724043761		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.08780515724043761 | validation: 0.05256929925548613]
	TIME [epoch: 8.61 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08009498603210274		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.08009498603210274 | validation: 0.09621853052964366]
	TIME [epoch: 8.59 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07954116121948648		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.07954116121948648 | validation: 0.08578297351187258]
	TIME [epoch: 8.64 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07204090775811514		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.07204090775811514 | validation: 0.09178644513937041]
	TIME [epoch: 8.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07692519044376962		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.07692519044376962 | validation: 0.10374369145222602]
	TIME [epoch: 8.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11007075753550696		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.11007075753550696 | validation: 0.10359328189335539]
	TIME [epoch: 8.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11972496913596879		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.11972496913596879 | validation: 0.14102113493670992]
	TIME [epoch: 8.62 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06488048348736314		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.06488048348736314 | validation: 0.06334664194057786]
	TIME [epoch: 8.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05258718712663206		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.05258718712663206 | validation: 0.05724751785359293]
	TIME [epoch: 8.61 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07045217977930857		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.07045217977930857 | validation: 0.07618449671367655]
	TIME [epoch: 8.64 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058735865170403564		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.058735865170403564 | validation: 0.13446527989984927]
	TIME [epoch: 8.63 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23855868017395507		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.23855868017395507 | validation: 0.06847017180018289]
	TIME [epoch: 8.58 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06564342967112233		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.06564342967112233 | validation: 0.08166112141574935]
	TIME [epoch: 8.59 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0626126318595332		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.0626126318595332 | validation: 0.0886536288437412]
	TIME [epoch: 8.67 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654884718044905		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.0654884718044905 | validation: 0.16104173111497916]
	TIME [epoch: 8.61 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09744090057645496		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.09744090057645496 | validation: 0.06967994717307438]
	TIME [epoch: 8.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08759114340839781		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.08759114340839781 | validation: 0.09020806207153076]
	TIME [epoch: 8.61 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08134455980657533		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.08134455980657533 | validation: 0.07451748882959146]
	TIME [epoch: 8.62 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08015816787544969		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.08015816787544969 | validation: 0.06034247433152356]
	TIME [epoch: 8.62 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16703229878267203		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.16703229878267203 | validation: 0.0974323848422031]
	TIME [epoch: 8.64 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11425004523293962		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.11425004523293962 | validation: 0.18842866710575937]
	TIME [epoch: 8.59 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07088795714511184		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.07088795714511184 | validation: 0.11738882026911668]
	TIME [epoch: 8.61 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08077499557543137		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.08077499557543137 | validation: 0.16410746482025945]
	TIME [epoch: 8.59 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16117029532818408		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.16117029532818408 | validation: 0.08342674367152178]
	TIME [epoch: 8.64 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642833640704644		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.0642833640704644 | validation: 0.03406147728333135]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_762.pth
	Model improved!!!
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04861425584313082		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.04861425584313082 | validation: 0.08054600855738311]
	TIME [epoch: 8.59 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07767518484288358		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.07767518484288358 | validation: 0.11027715248692552]
	TIME [epoch: 8.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07609014950388933		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.07609014950388933 | validation: 0.032805966863792474]
	TIME [epoch: 8.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_765.pth
	Model improved!!!
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062419682549202674		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.062419682549202674 | validation: 0.10021591593621658]
	TIME [epoch: 8.59 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06796235896455978		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.06796235896455978 | validation: 0.05982496723861619]
	TIME [epoch: 8.62 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06238318501296397		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.06238318501296397 | validation: 0.0533261844942218]
	TIME [epoch: 8.58 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08140125723644222		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.08140125723644222 | validation: 0.07034668328215972]
	TIME [epoch: 8.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10108549156992704		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.10108549156992704 | validation: 0.06845060185708979]
	TIME [epoch: 8.59 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05436034083098683		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.05436034083098683 | validation: 0.07554842465206987]
	TIME [epoch: 8.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10268562118978049		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.10268562118978049 | validation: 0.05777489541263638]
	TIME [epoch: 8.58 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08462685192717159		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.08462685192717159 | validation: 0.04902913882190632]
	TIME [epoch: 8.59 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0479751102908529		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.0479751102908529 | validation: 0.08740354797905697]
	TIME [epoch: 8.61 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07184937507563174		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.07184937507563174 | validation: 0.049163629760678285]
	TIME [epoch: 8.62 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16683372959947326		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.16683372959947326 | validation: 0.2135008289854993]
	TIME [epoch: 8.61 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19579467873626008		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.19579467873626008 | validation: 0.1014664314754152]
	TIME [epoch: 8.58 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06301748170990913		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.06301748170990913 | validation: 0.03581029634887016]
	TIME [epoch: 8.59 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06571317174793417		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.06571317174793417 | validation: 0.08163093491459661]
	TIME [epoch: 8.59 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.120057213536968		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.120057213536968 | validation: 0.0800712987788822]
	TIME [epoch: 8.58 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09177548499440732		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.09177548499440732 | validation: 0.1986572818084238]
	TIME [epoch: 8.58 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1773766609876924		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.1773766609876924 | validation: 0.08029339646011288]
	TIME [epoch: 8.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0831972381776214		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.0831972381776214 | validation: 0.05233512529537565]
	TIME [epoch: 8.59 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05682770497646607		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.05682770497646607 | validation: 0.04262120572395264]
	TIME [epoch: 8.59 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655156973895927		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.05655156973895927 | validation: 0.05587410847541447]
	TIME [epoch: 8.58 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07432017010744701		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.07432017010744701 | validation: 0.07804431871491714]
	TIME [epoch: 8.61 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07206640659450246		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.07206640659450246 | validation: 0.1261708678729083]
	TIME [epoch: 8.58 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11534010764547353		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.11534010764547353 | validation: 0.03452765879551037]
	TIME [epoch: 8.58 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05534927255502177		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.05534927255502177 | validation: 0.06482811581487423]
	TIME [epoch: 8.58 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07016204350021056		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.07016204350021056 | validation: 0.1039389204560558]
	TIME [epoch: 8.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08436447128832174		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.08436447128832174 | validation: 0.06641097974542085]
	TIME [epoch: 8.59 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06425689933005405		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.06425689933005405 | validation: 0.07309979195966895]
	TIME [epoch: 8.59 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043157737393081916		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.043157737393081916 | validation: 0.04224873193749141]
	TIME [epoch: 8.58 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0655257862317899		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.0655257862317899 | validation: 0.07169579227171458]
	TIME [epoch: 8.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09326949163096711		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.09326949163096711 | validation: 0.08030583954558257]
	TIME [epoch: 8.58 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08751687285756513		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.08751687285756513 | validation: 0.07945823602720897]
	TIME [epoch: 8.59 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0672850461386941		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.0672850461386941 | validation: 0.06579978187017063]
	TIME [epoch: 8.59 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07988599067760183		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.07988599067760183 | validation: 0.06197655906453272]
	TIME [epoch: 8.61 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07084449785188368		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.07084449785188368 | validation: 0.049644335975794915]
	TIME [epoch: 8.58 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05965731970237907		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.05965731970237907 | validation: 0.07549778018239359]
	TIME [epoch: 8.58 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720545933285916		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.0720545933285916 | validation: 0.05708468993943612]
	TIME [epoch: 8.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07789281745047731		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.07789281745047731 | validation: 0.06265866935763875]
	TIME [epoch: 8.59 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07413884365497694		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.07413884365497694 | validation: 0.06860963363822974]
	TIME [epoch: 8.59 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05783833771088391		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.05783833771088391 | validation: 0.08856474223281396]
	TIME [epoch: 8.58 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440843001249566		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.06440843001249566 | validation: 0.09358157884073068]
	TIME [epoch: 8.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08186753669553956		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.08186753669553956 | validation: 0.15863215895858113]
	TIME [epoch: 8.61 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07571638519641367		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.07571638519641367 | validation: 0.12241870107245761]
	TIME [epoch: 8.61 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08068613339763502		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.08068613339763502 | validation: 0.16987018174245036]
	TIME [epoch: 8.58 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06712656489126187		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.06712656489126187 | validation: 0.05014741636445173]
	TIME [epoch: 8.58 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06169613315997896		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.06169613315997896 | validation: 0.07149459088484948]
	TIME [epoch: 8.62 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0546966200160251		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.0546966200160251 | validation: 0.042951180072774334]
	TIME [epoch: 8.61 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12225739724746243		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.12225739724746243 | validation: 0.05433681369900162]
	TIME [epoch: 8.56 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06172876368502239		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.06172876368502239 | validation: 0.06470273525075482]
	TIME [epoch: 8.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05758951368720181		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.05758951368720181 | validation: 0.039017136212106056]
	TIME [epoch: 8.58 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0642280466226712		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.0642280466226712 | validation: 0.06543646547897145]
	TIME [epoch: 8.63 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06326955097389761		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.06326955097389761 | validation: 0.04805475002552278]
	TIME [epoch: 8.59 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05851169307871951		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.05851169307871951 | validation: 0.08773608623608575]
	TIME [epoch: 8.59 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723132551037204		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.0723132551037204 | validation: 0.08395185514747955]
	TIME [epoch: 8.58 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06761976158067766		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.06761976158067766 | validation: 0.07623900226473446]
	TIME [epoch: 8.59 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07337318846499837		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.07337318846499837 | validation: 0.0518849759607201]
	TIME [epoch: 8.58 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0749250782865897		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.0749250782865897 | validation: 0.08270917560505012]
	TIME [epoch: 8.62 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0637026537962307		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.0637026537962307 | validation: 0.04672908067207091]
	TIME [epoch: 8.57 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07251799136834616		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.07251799136834616 | validation: 0.07020344766068308]
	TIME [epoch: 8.59 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05346080325258307		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.05346080325258307 | validation: 0.06528415900570847]
	TIME [epoch: 8.61 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07700168457964021		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.07700168457964021 | validation: 0.04962972224419493]
	TIME [epoch: 8.62 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06961481194758098		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.06961481194758098 | validation: 0.08876215818691399]
	TIME [epoch: 8.58 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105633629393405		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.06105633629393405 | validation: 0.06367927368843113]
	TIME [epoch: 8.57 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358195210460615		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.06358195210460615 | validation: 0.07228537962297985]
	TIME [epoch: 8.59 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07770510130417296		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.07770510130417296 | validation: 0.07526817748588878]
	TIME [epoch: 8.59 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0610930926072201		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.0610930926072201 | validation: 0.14386012656225894]
	TIME [epoch: 8.58 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14385180720834342		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.14385180720834342 | validation: 0.2078094313920854]
	TIME [epoch: 8.58 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20943036039477966		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.20943036039477966 | validation: 0.06210084877707159]
	TIME [epoch: 8.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05649410105605844		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.05649410105605844 | validation: 0.04159425749669999]
	TIME [epoch: 8.59 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046459225546815766		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.046459225546815766 | validation: 0.0439857139236237]
	TIME [epoch: 8.57 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057349271643982236		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.057349271643982236 | validation: 0.09244709522268067]
	TIME [epoch: 8.58 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06548447856760188		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.06548447856760188 | validation: 0.06632249995011799]
	TIME [epoch: 8.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07557726332834347		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.07557726332834347 | validation: 0.06605595112589494]
	TIME [epoch: 8.58 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06746385098304737		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.06746385098304737 | validation: 0.05632186053217343]
	TIME [epoch: 8.58 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06491498306109526		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.06491498306109526 | validation: 0.06135467798851735]
	TIME [epoch: 8.58 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09189164168450667		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.09189164168450667 | validation: 0.09131843347311722]
	TIME [epoch: 8.61 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05198916995233386		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.05198916995233386 | validation: 0.049598327421739856]
	TIME [epoch: 8.62 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06771412159000735		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.06771412159000735 | validation: 0.06430441530460634]
	TIME [epoch: 8.61 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07387386913854588		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.07387386913854588 | validation: 0.05103033560281784]
	TIME [epoch: 8.56 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06126976421574317		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.06126976421574317 | validation: 0.06635353065293763]
	TIME [epoch: 8.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07008815857332619		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.07008815857332619 | validation: 0.04145620367255676]
	TIME [epoch: 8.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06249572623659873		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.06249572623659873 | validation: 0.07377010295603556]
	TIME [epoch: 8.59 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06559202517662786		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.06559202517662786 | validation: 0.07412051792976984]
	TIME [epoch: 8.58 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10526690964585077		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.10526690964585077 | validation: 0.0598822069807019]
	TIME [epoch: 8.62 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0777709218112689		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.0777709218112689 | validation: 0.06204392706606296]
	TIME [epoch: 8.58 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06761038809418793		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.06761038809418793 | validation: 0.05414432310051152]
	TIME [epoch: 8.58 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05806484932779068		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.05806484932779068 | validation: 0.08093356929529194]
	TIME [epoch: 8.58 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05939131116788415		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.05939131116788415 | validation: 0.08867307386575535]
	TIME [epoch: 8.61 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229670681685516		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.06229670681685516 | validation: 0.06666834109984707]
	TIME [epoch: 8.59 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07751948902097884		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.07751948902097884 | validation: 0.06795814996031967]
	TIME [epoch: 8.57 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727958938502966		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.07727958938502966 | validation: 0.08522243094338247]
	TIME [epoch: 8.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358972774863768		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.06358972774863768 | validation: 0.06362082840272519]
	TIME [epoch: 8.59 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1303867473456526		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.1303867473456526 | validation: 0.05069223936348335]
	TIME [epoch: 8.58 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16392795245555505		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.16392795245555505 | validation: 0.13515846942400123]
	TIME [epoch: 8.59 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41276582791428795		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.41276582791428795 | validation: 1.1834379978901772]
	TIME [epoch: 8.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3289226394726542		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.3289226394726542 | validation: 0.09687767316549623]
	TIME [epoch: 8.59 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07768865449247948		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.07768865449247948 | validation: 0.16404624221445518]
	TIME [epoch: 8.58 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.27374892349563196		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.27374892349563196 | validation: 0.11679310945478233]
	TIME [epoch: 8.58 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05761584738933503		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.05761584738933503 | validation: 0.06712139392303423]
	TIME [epoch: 8.65 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05725342676794261		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.05725342676794261 | validation: 0.07706364095455485]
	TIME [epoch: 8.59 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07296227207888571		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.07296227207888571 | validation: 0.035677511815839155]
	TIME [epoch: 8.58 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08955532636197733		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.08955532636197733 | validation: 0.05639051153023837]
	TIME [epoch: 8.57 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07774586926192288		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.07774586926192288 | validation: 0.08874774621789933]
	TIME [epoch: 8.63 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07206234696396965		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.07206234696396965 | validation: 0.041184059064640205]
	TIME [epoch: 8.62 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07289339673669352		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.07289339673669352 | validation: 0.07048021684447116]
	TIME [epoch: 8.57 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07014028988509842		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.07014028988509842 | validation: 0.06456832784563905]
	TIME [epoch: 8.58 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06381672937865987		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.06381672937865987 | validation: 0.06265211692345951]
	TIME [epoch: 8.61 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06274541863807322		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.06274541863807322 | validation: 0.07955578084612706]
	TIME [epoch: 8.62 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07025451785727137		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.07025451785727137 | validation: 0.05012497986650774]
	TIME [epoch: 8.58 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06479725638121296		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.06479725638121296 | validation: 0.06543502386833985]
	TIME [epoch: 8.57 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645620333539598		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.0645620333539598 | validation: 0.07459119122014646]
	TIME [epoch: 8.61 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05721597242354979		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.05721597242354979 | validation: 0.04395599503775078]
	TIME [epoch: 8.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06808241867024237		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.06808241867024237 | validation: 0.050224016130294744]
	TIME [epoch: 8.64 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07939404910586356		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.07939404910586356 | validation: 0.1323801723043617]
	TIME [epoch: 8.57 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07418813963766309		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.07418813963766309 | validation: 0.04414884532253564]
	TIME [epoch: 8.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058601426738520555		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.058601426738520555 | validation: 0.10178325749812421]
	TIME [epoch: 8.58 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1258033713344955		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.1258033713344955 | validation: 0.04143675861658697]
	TIME [epoch: 8.59 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04821913565156169		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.04821913565156169 | validation: 0.04382743873467884]
	TIME [epoch: 8.59 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07953358867788354		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.07953358867788354 | validation: 0.080707806244703]
	TIME [epoch: 8.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059393788293235675		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.059393788293235675 | validation: 0.152871650218861]
	TIME [epoch: 8.59 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06771731451716499		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.06771731451716499 | validation: 0.0790469233705273]
	TIME [epoch: 8.59 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07626030366023659		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.07626030366023659 | validation: 0.1916517240460033]
	TIME [epoch: 8.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06344077793960669		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.06344077793960669 | validation: 0.08176149894242603]
	TIME [epoch: 8.58 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06635720245828644		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.06635720245828644 | validation: 0.06462855958697415]
	TIME [epoch: 8.58 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037103627202428366		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.037103627202428366 | validation: 0.05760588163012469]
	TIME [epoch: 8.59 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0525400921530265		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.0525400921530265 | validation: 0.059302215145905446]
	TIME [epoch: 8.61 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06953817030458362		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.06953817030458362 | validation: 0.055652721901469866]
	TIME [epoch: 8.58 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05291297637949176		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.05291297637949176 | validation: 0.08309296304091293]
	TIME [epoch: 8.63 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06214792487290086		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.06214792487290086 | validation: 0.1677123307223804]
	TIME [epoch: 8.57 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08608773405101712		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.08608773405101712 | validation: 0.05727338461877163]
	TIME [epoch: 8.58 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05858446972722835		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.05858446972722835 | validation: 0.07395267353194343]
	TIME [epoch: 8.58 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921332439653412		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.0921332439653412 | validation: 0.0827372725170753]
	TIME [epoch: 8.58 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07690807145630409		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.07690807145630409 | validation: 0.04372124243680253]
	TIME [epoch: 8.58 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06833165380928365		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.06833165380928365 | validation: 0.05787451829854595]
	TIME [epoch: 8.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05355438686238655		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.05355438686238655 | validation: 0.05560540162146306]
	TIME [epoch: 8.58 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07600559515917475		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.07600559515917475 | validation: 0.09292068972187409]
	TIME [epoch: 8.56 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07256586494674847		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.07256586494674847 | validation: 0.044557957028535336]
	TIME [epoch: 8.58 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07505118773936399		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.07505118773936399 | validation: 0.07436185262143236]
	TIME [epoch: 8.59 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07014764672683552		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.07014764672683552 | validation: 0.05862774063959376]
	TIME [epoch: 8.58 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055453061393538595		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.055453061393538595 | validation: 0.06512990106984348]
	TIME [epoch: 8.57 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06578445699630496		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.06578445699630496 | validation: 0.08575948864191996]
	TIME [epoch: 8.58 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05939824477299168		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.05939824477299168 | validation: 0.06955984805227704]
	TIME [epoch: 8.59 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481917206924611		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.10481917206924611 | validation: 0.06448455763800791]
	TIME [epoch: 8.59 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07345303932604426		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.07345303932604426 | validation: 0.056374725947200784]
	TIME [epoch: 8.63 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07991177655042998		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.07991177655042998 | validation: 0.03202297358170639]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_909.pth
	Model improved!!!
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04249274173378091		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.04249274173378091 | validation: 0.11709787735438679]
	TIME [epoch: 8.58 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32712200712652734		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.32712200712652734 | validation: 0.21842435103187416]
	TIME [epoch: 8.57 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09770083763306811		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.09770083763306811 | validation: 0.05357091205048487]
	TIME [epoch: 8.62 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13581514643233988		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.13581514643233988 | validation: 0.056827640906433705]
	TIME [epoch: 8.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871798022568057		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.05871798022568057 | validation: 0.04513677763233265]
	TIME [epoch: 8.56 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20946474755812444		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.20946474755812444 | validation: 0.06163850105816462]
	TIME [epoch: 8.57 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24101396364430783		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.24101396364430783 | validation: 0.7189500650843161]
	TIME [epoch: 8.56 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21063407685264304		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.21063407685264304 | validation: 0.056760078995571096]
	TIME [epoch: 8.59 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22251889197270924		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.22251889197270924 | validation: 0.11595419029184802]
	TIME [epoch: 8.61 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09841819391447049		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.09841819391447049 | validation: 0.09946241998745955]
	TIME [epoch: 8.55 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0729349749753541		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.0729349749753541 | validation: 0.027458686903524532]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_920.pth
	Model improved!!!
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05272005811578565		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.05272005811578565 | validation: 0.047426267732077726]
	TIME [epoch: 8.58 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04804546146797124		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.04804546146797124 | validation: 0.03310148931391339]
	TIME [epoch: 8.56 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05232368620609541		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.05232368620609541 | validation: 0.039289822526210216]
	TIME [epoch: 8.59 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039007052738818035		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.039007052738818035 | validation: 0.05454516291532217]
	TIME [epoch: 8.58 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04358326993179399		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.04358326993179399 | validation: 0.1232922342778402]
	TIME [epoch: 8.57 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08042400070605615		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.08042400070605615 | validation: 0.0855272837577479]
	TIME [epoch: 8.57 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04090886087771484		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.04090886087771484 | validation: 0.05773308459026674]
	TIME [epoch: 8.57 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06526923730556675		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.06526923730556675 | validation: 0.027617251985745238]
	TIME [epoch: 8.57 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03993872149961964		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.03993872149961964 | validation: 0.049062168657821315]
	TIME [epoch: 8.59 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0557626799749116		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.0557626799749116 | validation: 0.04434431262622701]
	TIME [epoch: 8.56 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06309289167854222		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.06309289167854222 | validation: 0.051011114413363395]
	TIME [epoch: 8.58 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0422180301528023		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.0422180301528023 | validation: 0.07673956790747936]
	TIME [epoch: 8.57 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09731076815012336		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.09731076815012336 | validation: 0.04812940225504524]
	TIME [epoch: 8.59 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046909396690580675		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.046909396690580675 | validation: 0.05616926077660081]
	TIME [epoch: 8.57 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1347767603334334		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.1347767603334334 | validation: 0.0694184960223503]
	TIME [epoch: 8.56 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06925910641334235		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.06925910641334235 | validation: 0.04139232766948684]
	TIME [epoch: 8.58 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07426976721073364		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.07426976721073364 | validation: 0.05846165358837007]
	TIME [epoch: 8.58 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04822948838250891		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.04822948838250891 | validation: 0.05884145413217336]
	TIME [epoch: 8.56 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05780676739093168		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.05780676739093168 | validation: 0.06987530688453716]
	TIME [epoch: 8.57 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06493203716617421		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.06493203716617421 | validation: 0.026268986330446324]
	TIME [epoch: 8.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_940.pth
	Model improved!!!
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04955050332554355		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.04955050332554355 | validation: 0.04597877139905878]
	TIME [epoch: 8.56 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042228442546185026		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.042228442546185026 | validation: 0.03634307853025281]
	TIME [epoch: 8.57 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05175921195971226		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.05175921195971226 | validation: 0.06997726143581265]
	TIME [epoch: 8.56 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05677980192994168		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.05677980192994168 | validation: 0.11457632507037013]
	TIME [epoch: 8.59 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695395120832781		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.0695395120832781 | validation: 0.22739861488587032]
	TIME [epoch: 8.56 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11565979769879167		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.11565979769879167 | validation: 0.06242568868828932]
	TIME [epoch: 8.56 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055439991998700734		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.055439991998700734 | validation: 0.29888513317305165]
	TIME [epoch: 8.57 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15322041152207855		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.15322041152207855 | validation: 0.09078640642860641]
	TIME [epoch: 8.59 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06093076301318756		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.06093076301318756 | validation: 0.050924532840218154]
	TIME [epoch: 8.57 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04686258317571766		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.04686258317571766 | validation: 0.052104396614642376]
	TIME [epoch: 8.56 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05306320636111524		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.05306320636111524 | validation: 0.034339889385262806]
	TIME [epoch: 8.58 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05024477092219907		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.05024477092219907 | validation: 0.06191508995023935]
	TIME [epoch: 8.58 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04941700112552099		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.04941700112552099 | validation: 0.0734030424149856]
	TIME [epoch: 8.57 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051719425292623813		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.051719425292623813 | validation: 0.04994197091238549]
	TIME [epoch: 8.56 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06223208103386875		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.06223208103386875 | validation: 0.07012992267840902]
	TIME [epoch: 8.56 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056196209068420155		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.056196209068420155 | validation: 0.054822575276890634]
	TIME [epoch: 8.59 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463748962401898		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.06463748962401898 | validation: 0.06820800613326303]
	TIME [epoch: 8.57 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06037339422765783		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.06037339422765783 | validation: 0.06867370766570398]
	TIME [epoch: 8.57 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07875470621512966		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.07875470621512966 | validation: 0.10578758442182007]
	TIME [epoch: 8.57 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08018263406045117		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.08018263406045117 | validation: 0.06500452935578903]
	TIME [epoch: 8.58 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07242940962130409		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.07242940962130409 | validation: 0.0808663741254665]
	TIME [epoch: 8.57 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08177209567278282		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.08177209567278282 | validation: 0.09030201874637989]
	TIME [epoch: 8.56 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09333832318176641		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.09333832318176641 | validation: 0.0648184241712853]
	TIME [epoch: 8.58 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07190237902781273		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.07190237902781273 | validation: 0.05187990554770035]
	TIME [epoch: 8.58 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06319255639998148		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.06319255639998148 | validation: 0.07682893546182731]
	TIME [epoch: 8.57 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06833469377361283		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.06833469377361283 | validation: 0.07934595615301193]
	TIME [epoch: 8.57 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08777994537274643		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.08777994537274643 | validation: 0.077794819507966]
	TIME [epoch: 8.59 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08844960904449381		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.08844960904449381 | validation: 0.08554332450468217]
	TIME [epoch: 8.57 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07107899700342815		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.07107899700342815 | validation: 0.0740394016208967]
	TIME [epoch: 8.61 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0720697929928802		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.0720697929928802 | validation: 0.06769941288006928]
	TIME [epoch: 8.58 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17618144810375833		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.17618144810375833 | validation: 0.15107727155814288]
	TIME [epoch: 8.58 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08069571378274712		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.08069571378274712 | validation: 0.055408241278744455]
	TIME [epoch: 8.61 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04954882467990259		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.04954882467990259 | validation: 0.03559139045466422]
	TIME [epoch: 8.57 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04586775437415872		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.04586775437415872 | validation: 0.05711513068968905]
	TIME [epoch: 8.56 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09764682688278391		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.09764682688278391 | validation: 0.16396482219134279]
	TIME [epoch: 8.58 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1565736691460788		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.1565736691460788 | validation: 0.06956321218246223]
	TIME [epoch: 8.57 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03979779057873038		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.03979779057873038 | validation: 0.035160706729594336]
	TIME [epoch: 8.58 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09877796919577449		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.09877796919577449 | validation: 0.039869368083147554]
	TIME [epoch: 8.56 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05425503549639701		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.05425503549639701 | validation: 0.08254076574689764]
	TIME [epoch: 8.58 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717596546217224		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.0717596546217224 | validation: 0.05704163934449573]
	TIME [epoch: 8.61 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06509294651695181		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.06509294651695181 | validation: 0.04957309729137184]
	TIME [epoch: 8.56 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05713891734574439		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.05713891734574439 | validation: 0.048488741317914155]
	TIME [epoch: 8.56 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04335374435303638		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.04335374435303638 | validation: 0.06422800666673054]
	TIME [epoch: 8.59 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06694855601536671		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.06694855601536671 | validation: 0.048334033572546536]
	TIME [epoch: 8.57 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05771967178221419		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.05771967178221419 | validation: 0.05672186639666594]
	TIME [epoch: 8.56 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06365014188399482		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.06365014188399482 | validation: 0.08578199495634684]
	TIME [epoch: 8.57 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06613333207949974		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.06613333207949974 | validation: 0.0653057745428075]
	TIME [epoch: 8.59 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05566488768739861		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.05566488768739861 | validation: 0.07120637894201445]
	TIME [epoch: 8.61 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0651543575035544		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.0651543575035544 | validation: 0.06283603190172883]
	TIME [epoch: 8.57 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08078034856323248		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.08078034856323248 | validation: 0.08831362072797497]
	TIME [epoch: 8.55 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07902589592177428		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.07902589592177428 | validation: 0.07182862785238955]
	TIME [epoch: 8.58 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055602281250853536		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.055602281250853536 | validation: 0.08170838808571615]
	TIME [epoch: 8.56 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11290476090176797		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.11290476090176797 | validation: 0.06029373782530005]
	TIME [epoch: 8.57 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06367440616854596		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.06367440616854596 | validation: 0.07534395194741816]
	TIME [epoch: 8.57 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07966112013886112		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.07966112013886112 | validation: 0.03366064044260203]
	TIME [epoch: 8.58 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05241848826741633		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.05241848826741633 | validation: 0.0750199322598267]
	TIME [epoch: 8.57 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057157916498675174		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.057157916498675174 | validation: 0.05607142136169213]
	TIME [epoch: 8.56 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05916850494328394		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.05916850494328394 | validation: 0.07337947375897785]
	TIME [epoch: 8.58 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07668221163620129		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.07668221163620129 | validation: 0.06067667305163589]
	TIME [epoch: 8.56 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07672483696620763		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.07672483696620763 | validation: 0.08518435634318768]
	TIME [epoch: 8.57 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914598335088015		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.06914598335088015 | validation: 0.04757747787968414]
	TIME [epoch: 8.56 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05915421655315696		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.05915421655315696 | validation: 0.025117046016800405]
	TIME [epoch: 8.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1002.pth
	Model improved!!!
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055774224957265826		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.055774224957265826 | validation: 0.0499097631113964]
	TIME [epoch: 8.59 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06612963134242605		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.06612963134242605 | validation: 0.06637882160374767]
	TIME [epoch: 8.56 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0835868349127654		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.0835868349127654 | validation: 0.06056771755964103]
	TIME [epoch: 8.57 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06777745382465676		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.06777745382465676 | validation: 0.05826944523488834]
	TIME [epoch: 8.59 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497110876093784		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.06497110876093784 | validation: 0.045374125349610044]
	TIME [epoch: 8.56 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04945158223966982		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.04945158223966982 | validation: 0.05664082280969679]
	TIME [epoch: 8.57 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05486687467545678		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.05486687467545678 | validation: 0.04671117111613371]
	TIME [epoch: 8.56 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04434299929411477		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.04434299929411477 | validation: 0.04367597200397561]
	TIME [epoch: 8.59 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565266452968177		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.0565266452968177 | validation: 0.05113672847643971]
	TIME [epoch: 8.57 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05546451006751553		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.05546451006751553 | validation: 0.05915179680772833]
	TIME [epoch: 8.58 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06291362001833503		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.06291362001833503 | validation: 0.05260892916191272]
	TIME [epoch: 8.57 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053317869338484744		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.053317869338484744 | validation: 0.056273565910928414]
	TIME [epoch: 8.59 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05783633894804759		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.05783633894804759 | validation: 0.10578924627365027]
	TIME [epoch: 8.57 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05558009436025896		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.05558009436025896 | validation: 0.056214006170676914]
	TIME [epoch: 8.56 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05297595454270539		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.05297595454270539 | validation: 0.06865511017132285]
	TIME [epoch: 8.57 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05262380625358293		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.05262380625358293 | validation: 0.059806116359792015]
	TIME [epoch: 8.58 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05152234478330072		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.05152234478330072 | validation: 0.060329112131928396]
	TIME [epoch: 8.56 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04352697093711695		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.04352697093711695 | validation: 0.03726041630392496]
	TIME [epoch: 8.57 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049736551015504005		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.049736551015504005 | validation: 0.055944006462456675]
	TIME [epoch: 8.59 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06413147956387806		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.06413147956387806 | validation: 0.06418044711438328]
	TIME [epoch: 8.62 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05933092202001085		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.05933092202001085 | validation: 0.10092648353905098]
	TIME [epoch: 8.56 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13309856662997		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.13309856662997 | validation: 0.027618349216726252]
	TIME [epoch: 8.55 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03773573375824381		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.03773573375824381 | validation: 0.04532942844045061]
	TIME [epoch: 8.59 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07095561970920533		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.07095561970920533 | validation: 0.127181734005478]
	TIME [epoch: 8.57 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05888066716512384		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.05888066716512384 | validation: 0.0729282488913518]
	TIME [epoch: 8.62 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07298138701148763		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.07298138701148763 | validation: 0.048862220383194016]
	TIME [epoch: 8.57 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07927353195722125		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.07927353195722125 | validation: 0.0538394608237757]
	TIME [epoch: 8.57 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0558938471025849		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.0558938471025849 | validation: 0.05445284772978934]
	TIME [epoch: 8.57 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045063762570271365		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.045063762570271365 | validation: 0.03292659530847648]
	TIME [epoch: 8.56 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09709936380149795		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.09709936380149795 | validation: 0.08283152198973541]
	TIME [epoch: 8.57 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060611585837369544		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.060611585837369544 | validation: 0.0558363473230742]
	TIME [epoch: 8.57 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03667713698793513		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.03667713698793513 | validation: 0.04985389911202327]
	TIME [epoch: 8.56 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046621871144509754		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.046621871144509754 | validation: 0.03394180319091768]
	TIME [epoch: 8.58 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03982322575479853		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.03982322575479853 | validation: 0.03428335124447171]
	TIME [epoch: 8.59 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08668495392085247		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.08668495392085247 | validation: 0.1139825326563163]
	TIME [epoch: 8.57 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04924311676801551		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.04924311676801551 | validation: 0.04097082256486624]
	TIME [epoch: 8.54 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06147813701503028		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.06147813701503028 | validation: 0.06932882757550982]
	TIME [epoch: 8.55 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10633600585373762		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.10633600585373762 | validation: 0.06790740800672207]
	TIME [epoch: 8.55 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04469675340633705		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.04469675340633705 | validation: 0.05341869797140321]
	TIME [epoch: 8.59 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046719469232024774		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.046719469232024774 | validation: 0.03414844662483814]
	TIME [epoch: 8.56 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04638974745150277		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.04638974745150277 | validation: 0.06106707139556461]
	TIME [epoch: 8.56 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06274608163973036		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.06274608163973036 | validation: 0.041991553895180514]
	TIME [epoch: 8.55 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049249558437784016		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.049249558437784016 | validation: 0.04465995440531396]
	TIME [epoch: 8.59 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054758934579835127		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.054758934579835127 | validation: 0.06235050357527536]
	TIME [epoch: 8.57 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358590910454123		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.06358590910454123 | validation: 0.061747000163311486]
	TIME [epoch: 8.58 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07187947889852837		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.07187947889852837 | validation: 0.11265587951757641]
	TIME [epoch: 8.61 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04974929811162039		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.04974929811162039 | validation: 0.057947484121881]
	TIME [epoch: 8.59 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04544297277781257		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.04544297277781257 | validation: 0.032494669853176616]
	TIME [epoch: 8.55 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05014983150774904		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.05014983150774904 | validation: 0.049000294516515365]
	TIME [epoch: 8.55 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048574827492298675		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.048574827492298675 | validation: 0.03881704517553767]
	TIME [epoch: 8.57 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033925790372930406		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.033925790372930406 | validation: 0.037330753842775795]
	TIME [epoch: 8.56 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037464535281369		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.037464535281369 | validation: 0.04537088893545094]
	TIME [epoch: 8.57 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10074765963688984		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.10074765963688984 | validation: 0.02639980956088158]
	TIME [epoch: 8.57 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030134840741533043		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.030134840741533043 | validation: 0.041836428194276756]
	TIME [epoch: 8.59 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03710234963842637		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.03710234963842637 | validation: 0.03218166888183843]
	TIME [epoch: 8.56 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048089380026446284		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.048089380026446284 | validation: 0.051534161515311164]
	TIME [epoch: 8.56 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05279214847603677		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.05279214847603677 | validation: 0.048646690682898695]
	TIME [epoch: 8.56 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04473571184738436		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.04473571184738436 | validation: 0.04043665768015248]
	TIME [epoch: 8.59 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051435361705216454		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.051435361705216454 | validation: 0.0619564024394941]
	TIME [epoch: 8.57 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04607339250036912		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.04607339250036912 | validation: 0.04452716022426181]
	TIME [epoch: 8.57 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05003908356515237		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.05003908356515237 | validation: 0.04512231039791765]
	TIME [epoch: 8.57 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04375497527462531		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.04375497527462531 | validation: 0.04564599894159371]
	TIME [epoch: 8.58 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05307173555372332		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.05307173555372332 | validation: 0.05475175210859774]
	TIME [epoch: 8.56 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04403056891859769		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.04403056891859769 | validation: 0.04438416366906806]
	TIME [epoch: 8.56 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04348806374974663		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.04348806374974663 | validation: 0.04522052359988084]
	TIME [epoch: 8.56 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.041612808108627844		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.041612808108627844 | validation: 0.05450981830359143]
	TIME [epoch: 8.58 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042985543526313105		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.042985543526313105 | validation: 0.0408502320805388]
	TIME [epoch: 8.56 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03847705604138254		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.03847705604138254 | validation: 0.03417283599473387]
	TIME [epoch: 8.55 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05625059696020944		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.05625059696020944 | validation: 0.039185171037715835]
	TIME [epoch: 8.56 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043079046165788115		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.043079046165788115 | validation: 0.027064771117687098]
	TIME [epoch: 8.58 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04045406569422057		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.04045406569422057 | validation: 0.03229470952545368]
	TIME [epoch: 8.56 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03978861090877981		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.03978861090877981 | validation: 0.06335208077109475]
	TIME [epoch: 8.54 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05665661424826498		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.05665661424826498 | validation: 0.04283553097671179]
	TIME [epoch: 8.59 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062346908009156765		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.062346908009156765 | validation: 0.05785491995712819]
	TIME [epoch: 8.61 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0581991794044416		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.0581991794044416 | validation: 0.05342206688711383]
	TIME [epoch: 8.56 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07884196089199243		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.07884196089199243 | validation: 0.06973942485379679]
	TIME [epoch: 8.55 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06758124384615966		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.06758124384615966 | validation: 0.05707169830877336]
	TIME [epoch: 8.57 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07455113913684437		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.07455113913684437 | validation: 0.07266788752237122]
	TIME [epoch: 8.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07097773560406992		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.07097773560406992 | validation: 0.05682758023674546]
	TIME [epoch: 8.59 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0606525058119811		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.0606525058119811 | validation: 0.0582389727606419]
	TIME [epoch: 8.55 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674188563618643		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.05674188563618643 | validation: 0.0713802613366735]
	TIME [epoch: 8.56 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07067941802854479		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.07067941802854479 | validation: 0.0621574271087692]
	TIME [epoch: 8.56 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0625227771166481		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.0625227771166481 | validation: 0.06466830762631275]
	TIME [epoch: 8.55 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07105519685579374		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.07105519685579374 | validation: 0.08215265374227529]
	TIME [epoch: 8.59 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06356243243577343		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.06356243243577343 | validation: 0.063048376294909]
	TIME [epoch: 8.61 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05255076184025137		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.05255076184025137 | validation: 0.051179024663487775]
	TIME [epoch: 8.55 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054612871591301106		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.054612871591301106 | validation: 0.04680722993050784]
	TIME [epoch: 8.55 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049951786896735455		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.049951786896735455 | validation: 0.04627814991349788]
	TIME [epoch: 8.56 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053011648549666765		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.053011648549666765 | validation: 0.0458097356715283]
	TIME [epoch: 8.58 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03669394058086492		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.03669394058086492 | validation: 0.044242987269625514]
	TIME [epoch: 8.56 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04193183302395016		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.04193183302395016 | validation: 0.028496768687271534]
	TIME [epoch: 8.55 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04326429877117325		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.04326429877117325 | validation: 0.04597459345217914]
	TIME [epoch: 8.58 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05744686947992964		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.05744686947992964 | validation: 0.049899223934592216]
	TIME [epoch: 8.62 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048673574997852416		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.048673574997852416 | validation: 0.041417294222948826]
	TIME [epoch: 8.55 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039715738173005215		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.039715738173005215 | validation: 0.06398600782778066]
	TIME [epoch: 8.56 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903288819841941		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.05903288819841941 | validation: 0.17884491657711754]
	TIME [epoch: 8.56 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18564570179340173		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.18564570179340173 | validation: 0.033054684906701076]
	TIME [epoch: 8.59 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058625734896932694		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.058625734896932694 | validation: 0.10304235235655829]
	TIME [epoch: 8.56 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04847988230965704		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.04847988230965704 | validation: 0.03544896746352334]
	TIME [epoch: 8.57 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04088980406341687		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.04088980406341687 | validation: 0.03394564871357969]
	TIME [epoch: 8.56 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032795962065655694		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.032795962065655694 | validation: 0.0454271365369901]
	TIME [epoch: 8.59 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030974986813614457		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.030974986813614457 | validation: 0.03842544853942402]
	TIME [epoch: 8.57 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04825209341065792		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.04825209341065792 | validation: 0.060925449022138534]
	TIME [epoch: 8.57 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05398823103786532		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.05398823103786532 | validation: 0.054922037279323]
	TIME [epoch: 8.56 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04529896672110081		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.04529896672110081 | validation: 0.03859368296089529]
	TIME [epoch: 8.57 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07956922670329933		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.07956922670329933 | validation: 0.07446372326622558]
	TIME [epoch: 8.56 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04992480952963052		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.04992480952963052 | validation: 0.04049119594880692]
	TIME [epoch: 8.56 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024277456757229237		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.024277456757229237 | validation: 0.016718666862321048]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1110.pth
	Model improved!!!
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03312618741739763		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.03312618741739763 | validation: 0.06828001795535918]
	TIME [epoch: 8.57 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09833164545114458		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.09833164545114458 | validation: 0.049996057289857676]
	TIME [epoch: 8.56 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03370973189965901		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.03370973189965901 | validation: 0.02254867285517371]
	TIME [epoch: 8.56 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04266467528546146		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.04266467528546146 | validation: 0.04556174912820797]
	TIME [epoch: 8.59 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0848597463486559		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.0848597463486559 | validation: 0.059765693554524255]
	TIME [epoch: 8.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05870780091998058		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.05870780091998058 | validation: 0.04368497393923603]
	TIME [epoch: 8.58 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04138799648745339		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.04138799648745339 | validation: 0.03306693220513929]
	TIME [epoch: 8.56 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.045450785704570076		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.045450785704570076 | validation: 0.04426489216529359]
	TIME [epoch: 8.58 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.044845702685057436		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.044845702685057436 | validation: 0.03907243725273786]
	TIME [epoch: 8.57 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04845147508663294		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.04845147508663294 | validation: 0.03481830697703786]
	TIME [epoch: 8.56 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05155410730046097		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.05155410730046097 | validation: 0.053132711150451165]
	TIME [epoch: 8.57 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04408649970652271		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.04408649970652271 | validation: 0.02446108854698019]
	TIME [epoch: 8.58 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035271725924472454		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.035271725924472454 | validation: 0.031240335665695555]
	TIME [epoch: 8.57 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04309557973676137		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.04309557973676137 | validation: 0.03651143613434371]
	TIME [epoch: 8.56 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04376580244055796		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.04376580244055796 | validation: 0.06767135237831595]
	TIME [epoch: 8.56 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03804430314803259		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.03804430314803259 | validation: 0.03386327680026965]
	TIME [epoch: 8.58 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02896660965175577		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.02896660965175577 | validation: 0.0340539345436688]
	TIME [epoch: 8.56 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06172960604896934		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.06172960604896934 | validation: 0.02812281724313448]
	TIME [epoch: 8.56 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03381245386000943		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.03381245386000943 | validation: 0.04192239580899447]
	TIME [epoch: 8.56 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030846050419774552		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.030846050419774552 | validation: 0.04736481449867129]
	TIME [epoch: 8.58 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029629114770646097		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.029629114770646097 | validation: 0.02913305506870159]
	TIME [epoch: 8.56 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04244821886552186		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.04244821886552186 | validation: 0.07098909508988147]
	TIME [epoch: 8.56 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10560669744504066		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.10560669744504066 | validation: 0.027173254252939517]
	TIME [epoch: 8.57 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03453405697317627		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.03453405697317627 | validation: 0.024369291402516237]
	TIME [epoch: 8.58 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036882880876493065		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.036882880876493065 | validation: 0.08784751914048967]
	TIME [epoch: 8.55 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04748742559094184		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.04748742559094184 | validation: 0.018367931141928435]
	TIME [epoch: 8.57 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0387943733638008		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.0387943733638008 | validation: 0.0422760097969356]
	TIME [epoch: 8.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04234704444231292		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.04234704444231292 | validation: 0.05745893900022728]
	TIME [epoch: 8.62 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08536751144240524		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.08536751144240524 | validation: 0.045610481368179884]
	TIME [epoch: 8.55 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03812054304606358		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.03812054304606358 | validation: 0.032421721442341817]
	TIME [epoch: 8.55 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036433957810104486		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.036433957810104486 | validation: 0.03491712938408939]
	TIME [epoch: 8.57 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03050882950607465		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.03050882950607465 | validation: 0.02975848862753744]
	TIME [epoch: 8.61 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03822103873984331		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.03822103873984331 | validation: 0.04613551601433272]
	TIME [epoch: 8.58 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05555112399885531		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.05555112399885531 | validation: 0.0298611063469856]
	TIME [epoch: 8.55 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030422855405546363		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.030422855405546363 | validation: 0.03608984705695447]
	TIME [epoch: 8.57 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032147964885992766		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.032147964885992766 | validation: 0.046902242339136174]
	TIME [epoch: 8.55 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037791182635857554		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.037791182635857554 | validation: 0.024005173005526168]
	TIME [epoch: 8.57 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0466218518153278		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.0466218518153278 | validation: 0.02757754484087528]
	TIME [epoch: 8.57 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039935027855055254		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.039935027855055254 | validation: 0.05127783991833844]
	TIME [epoch: 8.62 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05145079462673967		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.05145079462673967 | validation: 0.036093958267008376]
	TIME [epoch: 8.57 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031214283307356743		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.031214283307356743 | validation: 0.03063145664567614]
	TIME [epoch: 8.55 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05907928952018382		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.05907928952018382 | validation: 0.055254894223057995]
	TIME [epoch: 8.55 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0665047217519446		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.0665047217519446 | validation: 0.05128811573028975]
	TIME [epoch: 8.58 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027999575980919435		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.027999575980919435 | validation: 0.031262129676853476]
	TIME [epoch: 8.56 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02864440152780041		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.02864440152780041 | validation: 0.027282509879521938]
	TIME [epoch: 8.57 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030891812600911804		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.030891812600911804 | validation: 0.03219642368542018]
	TIME [epoch: 8.57 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.048390420644432365		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.048390420644432365 | validation: 0.03900936592366473]
	TIME [epoch: 8.57 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03740764400219412		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.03740764400219412 | validation: 0.04227118353220247]
	TIME [epoch: 8.57 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03157124663988338		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.03157124663988338 | validation: 0.03303866291932728]
	TIME [epoch: 8.56 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03801732548872277		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.03801732548872277 | validation: 0.04209056833582109]
	TIME [epoch: 8.56 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0505789119810124		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.0505789119810124 | validation: 0.07230366297394084]
	TIME [epoch: 8.63 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1395918506069877		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.1395918506069877 | validation: 0.030047930587337537]
	TIME [epoch: 8.58 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03886404985025741		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.03886404985025741 | validation: 0.08432304877929693]
	TIME [epoch: 8.54 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055246416518694566		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.055246416518694566 | validation: 0.02362142030779237]
	TIME [epoch: 8.56 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03094274747392415		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.03094274747392415 | validation: 0.02762546851976434]
	TIME [epoch: 8.57 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028414125498521698		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.028414125498521698 | validation: 0.02714699628777895]
	TIME [epoch: 8.56 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04476049023850994		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.04476049023850994 | validation: 0.033753717760504516]
	TIME [epoch: 8.56 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029058402263922117		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.029058402263922117 | validation: 0.026638108876561276]
	TIME [epoch: 8.58 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032408815283886325		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.032408815283886325 | validation: 0.04980190122951958]
	TIME [epoch: 8.56 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050414760941693046		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.050414760941693046 | validation: 0.032232423130123825]
	TIME [epoch: 8.56 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04557485387886515		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.04557485387886515 | validation: 0.04566766046592055]
	TIME [epoch: 8.56 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03672666497990444		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.03672666497990444 | validation: 0.036789242534669864]
	TIME [epoch: 8.58 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04792634400848356		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.04792634400848356 | validation: 0.04622971492463332]
	TIME [epoch: 8.61 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03628245471475295		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.03628245471475295 | validation: 0.052891194281667414]
	TIME [epoch: 8.58 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03996701759255113		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.03996701759255113 | validation: 0.01155160707150495]
	TIME [epoch: 8.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1175.pth
	Model improved!!!
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02054627308850101		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.02054627308850101 | validation: 0.03000695393095947]
	TIME [epoch: 8.61 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03093175986585211		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.03093175986585211 | validation: 0.034545807257397046]
	TIME [epoch: 8.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07430308158340966		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.07430308158340966 | validation: 0.09470373314434954]
	TIME [epoch: 8.59 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07427423883195845		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.07427423883195845 | validation: 0.040981477197386124]
	TIME [epoch: 8.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04164108261272666		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.04164108261272666 | validation: 0.04068618135673068]
	TIME [epoch: 8.61 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04832134006543341		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.04832134006543341 | validation: 0.049503843448807386]
	TIME [epoch: 8.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02448695476505374		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.02448695476505374 | validation: 0.03390716521571674]
	TIME [epoch: 8.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037424536850598614		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.037424536850598614 | validation: 0.03949808525447728]
	TIME [epoch: 8.59 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03923471051953907		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.03923471051953907 | validation: 0.03417729993459001]
	TIME [epoch: 8.62 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023897358288294895		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.023897358288294895 | validation: 0.024115132701991154]
	TIME [epoch: 8.62 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01871201853457041		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.01871201853457041 | validation: 0.022220862870412986]
	TIME [epoch: 8.59 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021657070025370408		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.021657070025370408 | validation: 0.021207890212220307]
	TIME [epoch: 8.58 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03805103968828		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.03805103968828 | validation: 0.04885755055995335]
	TIME [epoch: 8.61 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0396372409688084		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.0396372409688084 | validation: 0.041482530251621255]
	TIME [epoch: 8.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04594021153487786		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.04594021153487786 | validation: 0.0422020518703381]
	TIME [epoch: 8.61 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03926392517094661		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.03926392517094661 | validation: 0.027832398466398435]
	TIME [epoch: 8.58 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022746959527018166		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.022746959527018166 | validation: 0.029161101814471468]
	TIME [epoch: 8.64 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031896894701514286		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.031896894701514286 | validation: 0.04086826499039744]
	TIME [epoch: 8.59 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04855625429729344		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.04855625429729344 | validation: 0.04286040244213257]
	TIME [epoch: 8.59 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03679932949299847		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.03679932949299847 | validation: 0.032909946548008606]
	TIME [epoch: 8.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0396750501009248		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.0396750501009248 | validation: 0.01948798490742793]
	TIME [epoch: 8.68 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035742104942124445		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.035742104942124445 | validation: 0.028876946652447805]
	TIME [epoch: 8.59 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03191715418322559		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.03191715418322559 | validation: 0.037688203092271985]
	TIME [epoch: 8.58 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03615109837983571		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.03615109837983571 | validation: 0.026938744857805313]
	TIME [epoch: 8.59 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.033210006946089485		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.033210006946089485 | validation: 0.03658405376295855]
	TIME [epoch: 8.64 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02983729281221028		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.02983729281221028 | validation: 0.029151013810369795]
	TIME [epoch: 8.64 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040954351806922154		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.040954351806922154 | validation: 0.034937273692830645]
	TIME [epoch: 8.58 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034643522073221356		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.034643522073221356 | validation: 0.0331615905247744]
	TIME [epoch: 8.61 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03606440957440366		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.03606440957440366 | validation: 0.034309834238425325]
	TIME [epoch: 8.59 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02888984789957682		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.02888984789957682 | validation: 0.028227296563685993]
	TIME [epoch: 8.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030570090711180116		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.030570090711180116 | validation: 0.02236707772172266]
	TIME [epoch: 8.59 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024300605378701733		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.024300605378701733 | validation: 0.03292442908097783]
	TIME [epoch: 8.61 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02050643264387256		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.02050643264387256 | validation: 0.015862674079180666]
	TIME [epoch: 8.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028195621835207057		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.028195621835207057 | validation: 0.026654867074602073]
	TIME [epoch: 8.64 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02842367724531374		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.02842367724531374 | validation: 0.019282455304466047]
	TIME [epoch: 8.64 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030661239825605785		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.030661239825605785 | validation: 0.02317274675198835]
	TIME [epoch: 8.6 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029297734580467954		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.029297734580467954 | validation: 0.04163381727287346]
	TIME [epoch: 8.58 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05561044946787121		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.05561044946787121 | validation: 0.05309130856366151]
	TIME [epoch: 8.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028137443589587113		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.028137443589587113 | validation: 0.03274665262360807]
	TIME [epoch: 8.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020718635613800728		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.020718635613800728 | validation: 0.021829979030366306]
	TIME [epoch: 8.62 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034065292520768765		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.034065292520768765 | validation: 0.04082080769515215]
	TIME [epoch: 8.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02877464436903216		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.02877464436903216 | validation: 0.03398077126173133]
	TIME [epoch: 8.62 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02612896875986479		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.02612896875986479 | validation: 0.03443665596418197]
	TIME [epoch: 8.66 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027311027651176416		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.027311027651176416 | validation: 0.017844238606233225]
	TIME [epoch: 8.61 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04369459102670854		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.04369459102670854 | validation: 0.028717044756353248]
	TIME [epoch: 8.58 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03305023907759943		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.03305023907759943 | validation: 0.030119680288979194]
	TIME [epoch: 8.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028050622395379525		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.028050622395379525 | validation: 0.023933973179755205]
	TIME [epoch: 8.59 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020594640984631964		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.020594640984631964 | validation: 0.02347265520269482]
	TIME [epoch: 8.63 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02552337937961994		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.02552337937961994 | validation: 0.016854949921500825]
	TIME [epoch: 8.59 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026828484148550897		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.026828484148550897 | validation: 0.03321669554866595]
	TIME [epoch: 8.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02293261604950181		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.02293261604950181 | validation: 0.019935179233175417]
	TIME [epoch: 8.61 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02663779945110299		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.02663779945110299 | validation: 0.034255709691216905]
	TIME [epoch: 8.62 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025959893060106654		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.025959893060106654 | validation: 0.0359098640152479]
	TIME [epoch: 8.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022488261276091975		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.022488261276091975 | validation: 0.017164695522986894]
	TIME [epoch: 8.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024293908619936164		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.024293908619936164 | validation: 0.018842629618295623]
	TIME [epoch: 8.61 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02333283226311126		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.02333283226311126 | validation: 0.04065398259515347]
	TIME [epoch: 8.59 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05879463030018145		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.05879463030018145 | validation: 0.04442470601153009]
	TIME [epoch: 8.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03674232141499607		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.03674232141499607 | validation: 0.035444364213519194]
	TIME [epoch: 8.61 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02450322742956397		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.02450322742956397 | validation: 0.030266110396963877]
	TIME [epoch: 8.68 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03617247656973303		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.03617247656973303 | validation: 0.04075302539543092]
	TIME [epoch: 8.62 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0384507133533962		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.0384507133533962 | validation: 0.038161670898214026]
	TIME [epoch: 8.57 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03976918625324104		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.03976918625324104 | validation: 0.04525528643257215]
	TIME [epoch: 8.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04893221496985244		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.04893221496985244 | validation: 0.06443792610668471]
	TIME [epoch: 8.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051347835934779026		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.051347835934779026 | validation: 0.04180148303684228]
	TIME [epoch: 8.6 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04818129460200578		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.04818129460200578 | validation: 0.05247462207875178]
	TIME [epoch: 8.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04161165509582844		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.04161165509582844 | validation: 0.04378087602071616]
	TIME [epoch: 8.59 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.043732370826604194		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.043732370826604194 | validation: 0.030587036392172386]
	TIME [epoch: 8.62 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.042898077996126084		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.042898077996126084 | validation: 0.034175024769600576]
	TIME [epoch: 8.59 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03888076530631921		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.03888076530631921 | validation: 0.04128470110615324]
	TIME [epoch: 8.59 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04357812703837455		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.04357812703837455 | validation: 0.048337404090287195]
	TIME [epoch: 8.59 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054232828205598695		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.054232828205598695 | validation: 0.03546155757255383]
	TIME [epoch: 8.61 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047568715188145504		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.047568715188145504 | validation: 0.060593065383428193]
	TIME [epoch: 8.59 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057428544949054805		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.057428544949054805 | validation: 0.04435962586270818]
	TIME [epoch: 8.58 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07707361363537588		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.07707361363537588 | validation: 0.10230356154133485]
	TIME [epoch: 8.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15073849192119967		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.15073849192119967 | validation: 0.16445084731253998]
	TIME [epoch: 8.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07031036990250593		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.07031036990250593 | validation: 0.02562005383029259]
	TIME [epoch: 8.59 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02491234142024884		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.02491234142024884 | validation: 0.03872859272059236]
	TIME [epoch: 8.58 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05495439905084171		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.05495439905084171 | validation: 0.039079548464245356]
	TIME [epoch: 8.66 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022619671765235206		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.022619671765235206 | validation: 0.030659689452114558]
	TIME [epoch: 8.64 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030288109385700385		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.030288109385700385 | validation: 0.02547568381676178]
	TIME [epoch: 8.58 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025954054286645906		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.025954054286645906 | validation: 0.04365891091487666]
	TIME [epoch: 8.59 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0866125991585825		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.0866125991585825 | validation: 0.214310365032026]
	TIME [epoch: 8.65 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16908954644800736		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.16908954644800736 | validation: 0.12758160701549487]
	TIME [epoch: 8.64 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12204026498170768		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.12204026498170768 | validation: 0.043427083562848454]
	TIME [epoch: 8.58 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03395039827152206		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.03395039827152206 | validation: 0.03406760504720016]
	TIME [epoch: 8.57 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036658054197031026		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.036658054197031026 | validation: 0.029591496982585182]
	TIME [epoch: 8.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023856226709204197		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.023856226709204197 | validation: 0.03137438116988413]
	TIME [epoch: 8.61 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026543423226477496		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.026543423226477496 | validation: 0.034939491517495015]
	TIME [epoch: 8.65 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02566147419545437		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.02566147419545437 | validation: 0.03549985914690073]
	TIME [epoch: 8.58 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02229575132036438		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.02229575132036438 | validation: 0.03004516126352877]
	TIME [epoch: 8.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03330377933935338		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.03330377933935338 | validation: 0.022971604321452236]
	TIME [epoch: 8.58 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023009451303119828		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.023009451303119828 | validation: 0.034157333628076034]
	TIME [epoch: 8.58 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03899986871762718		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.03899986871762718 | validation: 0.06439697390761769]
	TIME [epoch: 8.61 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035144537505534826		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.035144537505534826 | validation: 0.04541937125415833]
	TIME [epoch: 8.66 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02798176146131301		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.02798176146131301 | validation: 0.03090970204147219]
	TIME [epoch: 8.57 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021865631533824596		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.021865631533824596 | validation: 0.029423869632901067]
	TIME [epoch: 8.58 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028279893507058274		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.028279893507058274 | validation: 0.03756465973550653]
	TIME [epoch: 8.59 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028925594607703543		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.028925594607703543 | validation: 0.01566859166142238]
	TIME [epoch: 8.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028902648483255494		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.028902648483255494 | validation: 0.04115146948652501]
	TIME [epoch: 8.58 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05623562516796317		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.05623562516796317 | validation: 0.02878958278792866]
	TIME [epoch: 8.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028787751587602235		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.028787751587602235 | validation: 0.019860534117497337]
	TIME [epoch: 8.61 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025407557274760538		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.025407557274760538 | validation: 0.021647700040955394]
	TIME [epoch: 8.59 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025377709592239672		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.025377709592239672 | validation: 0.038703255299557295]
	TIME [epoch: 8.59 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04398650895054331		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.04398650895054331 | validation: 0.05116390087014988]
	TIME [epoch: 8.59 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040953796025719615		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.040953796025719615 | validation: 0.03531229420442005]
	TIME [epoch: 8.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029349323747525025		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.029349323747525025 | validation: 0.026701924599733896]
	TIME [epoch: 8.6 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02297755052567343		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.02297755052567343 | validation: 0.02626256956354993]
	TIME [epoch: 8.57 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.034090446894373926		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.034090446894373926 | validation: 0.029236607650306494]
	TIME [epoch: 8.59 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035609959908345444		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.035609959908345444 | validation: 0.02237293429293297]
	TIME [epoch: 8.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023857944289916555		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.023857944289916555 | validation: 0.021455008684188176]
	TIME [epoch: 8.59 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02964930291521577		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.02964930291521577 | validation: 0.019017640094481005]
	TIME [epoch: 8.59 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024344425701849675		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.024344425701849675 | validation: 0.030753215241842942]
	TIME [epoch: 8.63 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02115635647076396		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.02115635647076396 | validation: 0.03543131288546017]
	TIME [epoch: 8.61 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02112003141418282		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.02112003141418282 | validation: 0.02821382591680804]
	TIME [epoch: 8.58 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023389092875085473		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.023389092875085473 | validation: 0.047831081733404515]
	TIME [epoch: 8.58 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08248000399293945		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.08248000399293945 | validation: 0.11410531492882206]
	TIME [epoch: 8.58 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09566136938929613		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.09566136938929613 | validation: 0.09393072865432879]
	TIME [epoch: 8.61 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07300010977085572		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.07300010977085572 | validation: 0.05735489095943417]
	TIME [epoch: 8.58 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05093402876428839		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.05093402876428839 | validation: 0.0516851375092467]
	TIME [epoch: 8.58 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056376301066768816		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.056376301066768816 | validation: 0.038041033140808776]
	TIME [epoch: 8.59 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02880679192877364		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.02880679192877364 | validation: 0.03816211269327152]
	TIME [epoch: 8.61 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04839095142975454		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.04839095142975454 | validation: 0.032330942283425354]
	TIME [epoch: 8.59 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03809975144716849		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.03809975144716849 | validation: 0.03983679888053377]
	TIME [epoch: 8.58 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037321113113175985		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.037321113113175985 | validation: 0.02901885352305984]
	TIME [epoch: 8.58 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026256366957624566		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.026256366957624566 | validation: 0.043751142007634435]
	TIME [epoch: 8.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03116874294224259		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.03116874294224259 | validation: 0.025134474147205155]
	TIME [epoch: 8.58 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020670281474831843		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.020670281474831843 | validation: 0.02880540901330196]
	TIME [epoch: 8.59 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028457482676850443		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.028457482676850443 | validation: 0.02841673779610386]
	TIME [epoch: 8.59 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026228588670055526		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.026228588670055526 | validation: 0.0264275741423824]
	TIME [epoch: 8.6 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03798034118264098		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.03798034118264098 | validation: 0.04696449261119311]
	TIME [epoch: 8.58 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04830532428974711		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.04830532428974711 | validation: 0.04281544624679928]
	TIME [epoch: 8.58 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037600097940452056		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.037600097940452056 | validation: 0.04763022876770766]
	TIME [epoch: 8.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040940389892344525		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.040940389892344525 | validation: 0.029389216548139734]
	TIME [epoch: 8.58 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0341040253113038		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.0341040253113038 | validation: 0.029177586230190747]
	TIME [epoch: 8.58 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02597901231106506		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.02597901231106506 | validation: 0.021800583634650414]
	TIME [epoch: 8.63 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026801177671454922		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.026801177671454922 | validation: 0.027299926816391436]
	TIME [epoch: 8.62 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027465673462923924		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.027465673462923924 | validation: 0.03763181911389916]
	TIME [epoch: 8.57 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02942166421123187		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.02942166421123187 | validation: 0.0218613243059009]
	TIME [epoch: 8.58 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0322417997550044		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.0322417997550044 | validation: 0.03266333466127714]
	TIME [epoch: 8.62 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03332068033326492		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.03332068033326492 | validation: 0.03494612444166081]
	TIME [epoch: 8.63 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02826972775322382		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.02826972775322382 | validation: 0.029506915481109824]
	TIME [epoch: 8.56 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02347038409525039		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.02347038409525039 | validation: 0.05031346227247397]
	TIME [epoch: 8.57 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03264720695440008		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.03264720695440008 | validation: 0.03569501373600839]
	TIME [epoch: 8.58 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03153362803708885		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.03153362803708885 | validation: 0.03438237737335209]
	TIME [epoch: 8.61 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02672801883094162		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.02672801883094162 | validation: 0.03154332082585193]
	TIME [epoch: 8.58 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02928964526252849		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.02928964526252849 | validation: 0.03727183760704421]
	TIME [epoch: 8.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06672275607238418		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.06672275607238418 | validation: 0.030431968602558063]
	TIME [epoch: 8.63 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028027340363850274		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.028027340363850274 | validation: 0.06282886904951267]
	TIME [epoch: 8.58 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03776156983373471		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.03776156983373471 | validation: 0.030311564785417175]
	TIME [epoch: 8.58 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022317098901634032		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.022317098901634032 | validation: 0.022300376504918146]
	TIME [epoch: 8.57 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018737201205393357		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.018737201205393357 | validation: 0.026645508850380924]
	TIME [epoch: 8.58 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025681580703754443		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.025681580703754443 | validation: 0.0254098828839753]
	TIME [epoch: 8.6 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02194980657100417		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.02194980657100417 | validation: 0.025739850570899468]
	TIME [epoch: 8.59 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02202040489245834		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.02202040489245834 | validation: 0.019191800255178634]
	TIME [epoch: 8.63 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018919693571107742		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.018919693571107742 | validation: 0.034983701901687404]
	TIME [epoch: 8.58 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031192394672963274		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.031192394672963274 | validation: 0.042778350767809524]
	TIME [epoch: 8.58 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03143229869949832		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.03143229869949832 | validation: 0.03095220864897126]
	TIME [epoch: 8.56 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0335128756975706		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.0335128756975706 | validation: 0.04406015845673765]
	TIME [epoch: 8.58 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04028853080236444		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.04028853080236444 | validation: 0.031124026121567144]
	TIME [epoch: 8.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04467654271727535		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.04467654271727535 | validation: 0.03525090592335878]
	TIME [epoch: 8.57 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030066463972802427		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.030066463972802427 | validation: 0.021475768890788335]
	TIME [epoch: 8.58 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02191632821956608		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.02191632821956608 | validation: 0.026116484566381423]
	TIME [epoch: 8.57 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025863371581815998		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.025863371581815998 | validation: 0.02153929699264603]
	TIME [epoch: 8.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03515125848810404		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.03515125848810404 | validation: 0.06646356595556911]
	TIME [epoch: 8.58 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06618738748343375		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.06618738748343375 | validation: 0.06176290772980071]
	TIME [epoch: 8.58 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03837623503960286		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.03837623503960286 | validation: 0.0210706057781413]
	TIME [epoch: 8.58 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02061450557349051		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.02061450557349051 | validation: 0.02153933655779205]
	TIME [epoch: 8.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03265664781465179		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.03265664781465179 | validation: 0.035346669336166536]
	TIME [epoch: 8.58 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01809344659634825		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.01809344659634825 | validation: 0.014632154053524858]
	TIME [epoch: 8.56 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015726620827063956		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.015726620827063956 | validation: 0.02844522061326322]
	TIME [epoch: 8.62 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017748822207424065		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.017748822207424065 | validation: 0.03719716380474323]
	TIME [epoch: 8.63 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022883517874956027		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.022883517874956027 | validation: 0.018317888334242353]
	TIME [epoch: 8.57 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026037373050629524		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.026037373050629524 | validation: 0.02889603631677247]
	TIME [epoch: 8.57 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022151563289372744		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.022151563289372744 | validation: 0.028297086249433286]
	TIME [epoch: 8.58 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022992625190187004		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.022992625190187004 | validation: 0.01884715940807887]
	TIME [epoch: 8.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02650109208966182		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.02650109208966182 | validation: 0.024768027123224207]
	TIME [epoch: 8.58 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014304857585914455		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.014304857585914455 | validation: 0.016124642442835763]
	TIME [epoch: 8.58 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015426559265974128		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.015426559265974128 | validation: 0.028759920201811028]
	TIME [epoch: 8.59 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025320621480574023		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.025320621480574023 | validation: 0.02459514332061558]
	TIME [epoch: 8.59 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020007642213578824		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.020007642213578824 | validation: 0.017217548598770137]
	TIME [epoch: 8.58 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03300409116945588		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.03300409116945588 | validation: 0.02919842131827441]
	TIME [epoch: 8.59 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030414845993863786		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.030414845993863786 | validation: 0.01770575274146475]
	TIME [epoch: 8.59 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03162870456245509		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.03162870456245509 | validation: 0.02101310746979534]
	TIME [epoch: 8.59 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02416921465270122		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.02416921465270122 | validation: 0.020844415201668687]
	TIME [epoch: 8.58 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02366959274124327		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.02366959274124327 | validation: 0.02020392771986932]
	TIME [epoch: 8.58 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024909728955100824		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.024909728955100824 | validation: 0.030980817313511384]
	TIME [epoch: 8.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027168409031895102		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.027168409031895102 | validation: 0.03863299181805581]
	TIME [epoch: 8.59 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02497393236439323		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.02497393236439323 | validation: 0.031047649300604163]
	TIME [epoch: 8.58 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030477503395513222		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.030477503395513222 | validation: 0.057172350534144545]
	TIME [epoch: 8.58 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07229636021143075		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.07229636021143075 | validation: 0.05312629394006515]
	TIME [epoch: 8.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032655313971961614		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.032655313971961614 | validation: 0.02463098345830354]
	TIME [epoch: 8.58 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02039741958031554		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.02039741958031554 | validation: 0.023785980233959874]
	TIME [epoch: 8.58 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016155297298825713		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.016155297298825713 | validation: 0.025990901703574633]
	TIME [epoch: 8.58 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030005792311137165		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.030005792311137165 | validation: 0.026647861454942974]
	TIME [epoch: 8.59 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02313900435874277		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.02313900435874277 | validation: 0.013661458390905263]
	TIME [epoch: 8.58 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021868727834869567		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.021868727834869567 | validation: 0.019888362950165592]
	TIME [epoch: 8.59 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020637032332651177		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.020637032332651177 | validation: 0.02510846662147887]
	TIME [epoch: 8.62 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032159635051210035		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.032159635051210035 | validation: 0.05515616463648876]
	TIME [epoch: 8.58 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05592627055719479		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.05592627055719479 | validation: 0.04096705247536513]
	TIME [epoch: 8.57 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06112647248981305		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.06112647248981305 | validation: 0.03682336009673793]
	TIME [epoch: 8.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028658509848651627		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.028658509848651627 | validation: 0.030964541741850135]
	TIME [epoch: 8.63 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02080743957449638		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.02080743957449638 | validation: 0.028595879247447043]
	TIME [epoch: 8.59 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029993819167694346		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.029993819167694346 | validation: 0.03403096604852649]
	TIME [epoch: 8.56 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.027777149796226492		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.027777149796226492 | validation: 0.022741673504598745]
	TIME [epoch: 8.57 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0169423426969549		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.0169423426969549 | validation: 0.017967043974157673]
	TIME [epoch: 8.57 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024008494542001248		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.024008494542001248 | validation: 0.018176144071777874]
	TIME [epoch: 8.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018074462376336087		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.018074462376336087 | validation: 0.0208583807214374]
	TIME [epoch: 8.58 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015386998732613965		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.015386998732613965 | validation: 0.02721893855376531]
	TIME [epoch: 8.57 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020909909656251377		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.020909909656251377 | validation: 0.0270221604568311]
	TIME [epoch: 8.63 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03118381716381981		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.03118381716381981 | validation: 0.04292141769617484]
	TIME [epoch: 8.61 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024094599112012168		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.024094599112012168 | validation: 0.03252894051952545]
	TIME [epoch: 8.57 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02257133673961048		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.02257133673961048 | validation: 0.0158377987428488]
	TIME [epoch: 8.57 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021071301525134326		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.021071301525134326 | validation: 0.02447432791305911]
	TIME [epoch: 8.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028418540927150397		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.028418540927150397 | validation: 0.03896839493815384]
	TIME [epoch: 8.59 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02655463809700696		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.02655463809700696 | validation: 0.021737224942225245]
	TIME [epoch: 8.57 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021257961374671806		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.021257961374671806 | validation: 0.028496922286636875]
	TIME [epoch: 8.57 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01929335168521917		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.01929335168521917 | validation: 0.022879389144257647]
	TIME [epoch: 8.59 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018615497536350174		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.018615497536350174 | validation: 0.019841704671288415]
	TIME [epoch: 8.59 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018560983950468523		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.018560983950468523 | validation: 0.01899650795776592]
	TIME [epoch: 8.61 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020461952611573627		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.020461952611573627 | validation: 0.026325887232713868]
	TIME [epoch: 8.57 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020426342347246766		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.020426342347246766 | validation: 0.018264075077602953]
	TIME [epoch: 8.58 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028634769491773043		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.028634769491773043 | validation: 0.02990946121271062]
	TIME [epoch: 8.56 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025211874747048092		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.025211874747048092 | validation: 0.044372094960199344]
	TIME [epoch: 8.58 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023161945563919133		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.023161945563919133 | validation: 0.02795932693028281]
	TIME [epoch: 8.57 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012755690507363544		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.012755690507363544 | validation: 0.01310980418296961]
	TIME [epoch: 8.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021139408200213546		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.021139408200213546 | validation: 0.02266796781932189]
	TIME [epoch: 8.57 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022634204562508274		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.022634204562508274 | validation: 0.02249055115539377]
	TIME [epoch: 8.57 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02228306226289265		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.02228306226289265 | validation: 0.01959284460670362]
	TIME [epoch: 8.58 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021165265156770884		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.021165265156770884 | validation: 0.014720866736014027]
	TIME [epoch: 8.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024456435471016513		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.024456435471016513 | validation: 0.026770799207356356]
	TIME [epoch: 8.58 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026053404246289165		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.026053404246289165 | validation: 0.026343567377718306]
	TIME [epoch: 8.58 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0207862146720694		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.0207862146720694 | validation: 0.01979760096522679]
	TIME [epoch: 8.59 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025161159483195545		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.025161159483195545 | validation: 0.02662140604642778]
	TIME [epoch: 8.65 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026810530762222486		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.026810530762222486 | validation: 0.03598100738242785]
	TIME [epoch: 8.57 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022744011962318705		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.022744011962318705 | validation: 0.02172490876729701]
	TIME [epoch: 8.57 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.037959739317187484		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.037959739317187484 | validation: 0.05506892897320159]
	TIME [epoch: 8.58 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04382239216921312		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.04382239216921312 | validation: 0.03644621497253839]
	TIME [epoch: 8.59 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02606645116932637		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.02606645116932637 | validation: 0.032281295753538206]
	TIME [epoch: 8.58 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03047623165001495		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.03047623165001495 | validation: 0.043622689533120214]
	TIME [epoch: 8.58 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04799434691923549		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.04799434691923549 | validation: 0.028305236693050753]
	TIME [epoch: 8.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030050136723545486		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.030050136723545486 | validation: 0.025444339644314796]
	TIME [epoch: 8.58 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020595054871405137		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.020595054871405137 | validation: 0.011336901343160507]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1417.pth
	Model improved!!!
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01775306330503302		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.01775306330503302 | validation: 0.011828546660982188]
	TIME [epoch: 8.57 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018566905551923224		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.018566905551923224 | validation: 0.022476422825349552]
	TIME [epoch: 8.59 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016343831040886457		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.016343831040886457 | validation: 0.02991848088646494]
	TIME [epoch: 8.57 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0233307051840065		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.0233307051840065 | validation: 0.023474903325036822]
	TIME [epoch: 8.59 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02296834965600918		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.02296834965600918 | validation: 0.025110793113430917]
	TIME [epoch: 8.57 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025459757607484118		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.025459757607484118 | validation: 0.03307511696393367]
	TIME [epoch: 8.58 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020762814686989296		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.020762814686989296 | validation: 0.033042638322336025]
	TIME [epoch: 8.57 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024695859058990723		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.024695859058990723 | validation: 0.02955604774815509]
	TIME [epoch: 8.58 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032723804228071356		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.032723804228071356 | validation: 0.021306488162709525]
	TIME [epoch: 8.63 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02359664850964697		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.02359664850964697 | validation: 0.02469239424821542]
	TIME [epoch: 8.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01993718070011676		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.01993718070011676 | validation: 0.02624519455493414]
	TIME [epoch: 8.57 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018788088186339057		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.018788088186339057 | validation: 0.015996250182810902]
	TIME [epoch: 8.57 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023275636029529277		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.023275636029529277 | validation: 0.023054875804126657]
	TIME [epoch: 8.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024356039115844826		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.024356039115844826 | validation: 0.022050793718009845]
	TIME [epoch: 8.63 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01815208574696065		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.01815208574696065 | validation: 0.027066124097144845]
	TIME [epoch: 8.57 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01996138278643448		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.01996138278643448 | validation: 0.015403818236981575]
	TIME [epoch: 8.56 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04911195691419649		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.04911195691419649 | validation: 0.07218825117013791]
	TIME [epoch: 8.57 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716261990384807		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.0716261990384807 | validation: 0.073973216724916]
	TIME [epoch: 8.62 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07956068967845684		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.07956068967845684 | validation: 0.059683201028593924]
	TIME [epoch: 8.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03040748333885491		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.03040748333885491 | validation: 0.03377388224621983]
	TIME [epoch: 8.55 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.040657291522852655		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.040657291522852655 | validation: 0.05345663611915057]
	TIME [epoch: 8.56 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.036187393878763595		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.036187393878763595 | validation: 0.03383003806402606]
	TIME [epoch: 8.58 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021352965288490313		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.021352965288490313 | validation: 0.0287461715263663]
	TIME [epoch: 8.58 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019490883322483523		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.019490883322483523 | validation: 0.0329561483915564]
	TIME [epoch: 8.62 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031218225350990846		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.031218225350990846 | validation: 0.03477855140861865]
	TIME [epoch: 8.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023297618226443984		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.023297618226443984 | validation: 0.014848273546595847]
	TIME [epoch: 8.55 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02911730443903667		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.02911730443903667 | validation: 0.02126370816665661]
	TIME [epoch: 8.56 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01630172408019598		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.01630172408019598 | validation: 0.02346497476026603]
	TIME [epoch: 8.55 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021957430175725497		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.021957430175725497 | validation: 0.02092767886494372]
	TIME [epoch: 8.59 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02365823395248105		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.02365823395248105 | validation: 0.016181397600630247]
	TIME [epoch: 8.58 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014655496613529323		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.014655496613529323 | validation: 0.03082455392503855]
	TIME [epoch: 8.57 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02169082069323935		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.02169082069323935 | validation: 0.025247591895854606]
	TIME [epoch: 8.57 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02639963645633257		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.02639963645633257 | validation: 0.025575575097712026]
	TIME [epoch: 8.58 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020670905159947364		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.020670905159947364 | validation: 0.01468386178296649]
	TIME [epoch: 8.58 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017964235766850058		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.017964235766850058 | validation: 0.025062295708406117]
	TIME [epoch: 8.56 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019855424689406445		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.019855424689406445 | validation: 0.015391868876911107]
	TIME [epoch: 8.57 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01950986133022159		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.01950986133022159 | validation: 0.023351669347752832]
	TIME [epoch: 8.58 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015762507408694743		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.015762507408694743 | validation: 0.019460438568616043]
	TIME [epoch: 8.61 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017000351590267995		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.017000351590267995 | validation: 0.026035931189091418]
	TIME [epoch: 8.59 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020761365944941754		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.020761365944941754 | validation: 0.012042753277646031]
	TIME [epoch: 8.55 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01959997098525785		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.01959997098525785 | validation: 0.021949417491278787]
	TIME [epoch: 8.59 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02402936953030217		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.02402936953030217 | validation: 0.022238724669462966]
	TIME [epoch: 8.57 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01767184768650707		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.01767184768650707 | validation: 0.030059356441280105]
	TIME [epoch: 8.56 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01980583624986889		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.01980583624986889 | validation: 0.014744822982688342]
	TIME [epoch: 8.57 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017974585089475963		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.017974585089475963 | validation: 0.024927022666285825]
	TIME [epoch: 8.57 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01838633797616076		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.01838633797616076 | validation: 0.02258163542750016]
	TIME [epoch: 8.57 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03966646475934886		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.03966646475934886 | validation: 0.053668451803205564]
	TIME [epoch: 8.56 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062172539393639016		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.062172539393639016 | validation: 0.04493125440492006]
	TIME [epoch: 8.59 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.039247363854649345		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.039247363854649345 | validation: 0.04935322459315015]
	TIME [epoch: 8.57 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05869586582369739		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.05869586582369739 | validation: 0.054407180749367685]
	TIME [epoch: 8.57 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03297841784134144		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.03297841784134144 | validation: 0.020711126684217238]
	TIME [epoch: 8.56 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02013969221550293		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.02013969221550293 | validation: 0.020986005581127842]
	TIME [epoch: 8.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013829814604457435		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.013829814604457435 | validation: 0.021370049025743163]
	TIME [epoch: 8.57 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01521706017651667		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.01521706017651667 | validation: 0.019168451152808397]
	TIME [epoch: 8.57 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020791520090561285		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.020791520090561285 | validation: 0.024615992086296175]
	TIME [epoch: 8.57 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03455027129861452		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.03455027129861452 | validation: 0.047212458995878864]
	TIME [epoch: 8.59 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03594853453046172		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.03594853453046172 | validation: 0.03463000329452033]
	TIME [epoch: 8.57 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.035670068926253934		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.035670068926253934 | validation: 0.0321523510362825]
	TIME [epoch: 8.57 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.038757263769265186		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.038757263769265186 | validation: 0.0546157528315641]
	TIME [epoch: 8.62 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04748232344137356		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.04748232344137356 | validation: 0.036470875889953035]
	TIME [epoch: 8.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021055596387191157		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.021055596387191157 | validation: 0.015741610673201574]
	TIME [epoch: 8.56 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019509945882983735		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.019509945882983735 | validation: 0.02662451620724085]
	TIME [epoch: 8.56 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01851787668975423		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.01851787668975423 | validation: 0.03032279061386808]
	TIME [epoch: 8.59 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022431936814382523		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.022431936814382523 | validation: 0.026114502302982796]
	TIME [epoch: 8.63 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02421885367437348		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.02421885367437348 | validation: 0.027202728163087546]
	TIME [epoch: 8.55 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029446137940911915		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.029446137940911915 | validation: 0.02541060258692665]
	TIME [epoch: 8.56 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022884865257858013		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.022884865257858013 | validation: 0.01952075785137069]
	TIME [epoch: 8.58 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01655613688198631		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.01655613688198631 | validation: 0.02149988508254785]
	TIME [epoch: 8.58 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018616276561056144		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.018616276561056144 | validation: 0.024314679858325895]
	TIME [epoch: 8.59 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02203670799078499		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.02203670799078499 | validation: 0.02231681076564041]
	TIME [epoch: 8.62 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022487803688509524		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.022487803688509524 | validation: 0.03489626652377491]
	TIME [epoch: 8.56 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028877600751082304		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.028877600751082304 | validation: 0.032786579786703074]
	TIME [epoch: 8.58 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02698199710216374		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.02698199710216374 | validation: 0.025753081198737832]
	TIME [epoch: 8.58 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022227117889496755		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.022227117889496755 | validation: 0.01926182519392796]
	TIME [epoch: 8.57 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02237661924289309		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.02237661924289309 | validation: 0.027297152666774863]
	TIME [epoch: 8.57 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017453967836386895		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.017453967836386895 | validation: 0.021888731542795727]
	TIME [epoch: 8.59 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0161438070103814		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.0161438070103814 | validation: 0.025345372798169376]
	TIME [epoch: 8.6 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019817873235304723		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.019817873235304723 | validation: 0.015599348989970181]
	TIME [epoch: 8.61 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014562872148727923		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.014562872148727923 | validation: 0.02908072351779781]
	TIME [epoch: 8.57 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013373061728873089		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.013373061728873089 | validation: 0.022410165511273054]
	TIME [epoch: 8.56 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014863369183540956		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.014863369183540956 | validation: 0.016942824462269985]
	TIME [epoch: 8.57 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019336378362332454		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.019336378362332454 | validation: 0.015028707510169997]
	TIME [epoch: 8.58 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016717414752479412		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.016717414752479412 | validation: 0.017366786369404124]
	TIME [epoch: 8.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01483040454751324		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.01483040454751324 | validation: 0.016947517013966733]
	TIME [epoch: 8.58 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022419159363447808		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.022419159363447808 | validation: 0.027484681917930572]
	TIME [epoch: 8.58 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019129866302387992		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.019129866302387992 | validation: 0.020193311550080997]
	TIME [epoch: 8.57 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021676932603190813		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.021676932603190813 | validation: 0.03312728524552321]
	TIME [epoch: 8.61 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0217328044342334		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.0217328044342334 | validation: 0.023813025686098915]
	TIME [epoch: 8.58 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0158007914837737		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.0158007914837737 | validation: 0.017865505821646015]
	TIME [epoch: 8.59 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02000952738201634		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.02000952738201634 | validation: 0.018192149774657308]
	TIME [epoch: 8.59 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020091068910283436		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.020091068910283436 | validation: 0.02500836008520658]
	TIME [epoch: 8.68 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0194042758939935		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.0194042758939935 | validation: 0.025076088396967997]
	TIME [epoch: 8.58 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025069227324825565		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.025069227324825565 | validation: 0.03472482361124254]
	TIME [epoch: 8.57 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024510444863905384		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.024510444863905384 | validation: 0.029934014282322032]
	TIME [epoch: 8.58 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01801820281346716		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.01801820281346716 | validation: 0.020649593565882064]
	TIME [epoch: 8.61 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028468914147917735		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.028468914147917735 | validation: 0.038842014732160424]
	TIME [epoch: 8.57 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.03327136777765618		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.03327136777765618 | validation: 0.02614263462321961]
	TIME [epoch: 8.59 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02626717652374177		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.02626717652374177 | validation: 0.01581685275524888]
	TIME [epoch: 8.59 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019848179974283363		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.019848179974283363 | validation: 0.024680570478296537]
	TIME [epoch: 8.61 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024434814798617453		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.024434814798617453 | validation: 0.01684795662824082]
	TIME [epoch: 8.59 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015470012750199432		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.015470012750199432 | validation: 0.014746046235455713]
	TIME [epoch: 8.59 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02459268753137176		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.02459268753137176 | validation: 0.023285336374371076]
	TIME [epoch: 8.61 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019356470583917238		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.019356470583917238 | validation: 0.01558330687445717]
	TIME [epoch: 8.6 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021515139311935952		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.021515139311935952 | validation: 0.00819866204780553]
	TIME [epoch: 8.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1521.pth
	Model improved!!!
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017928605376595796		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.017928605376595796 | validation: 0.021610040823469904]
	TIME [epoch: 8.55 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024432443287984714		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.024432443287984714 | validation: 0.021786660084711054]
	TIME [epoch: 8.58 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021197344755310713		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.021197344755310713 | validation: 0.02572533521346433]
	TIME [epoch: 8.56 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022566561837276983		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.022566561837276983 | validation: 0.013706624188847539]
	TIME [epoch: 8.56 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02518976550667832		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.02518976550667832 | validation: 0.014336070286013611]
	TIME [epoch: 8.56 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023212961578339887		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.023212961578339887 | validation: 0.027040524028065515]
	TIME [epoch: 8.57 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020040115948019153		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.020040115948019153 | validation: 0.018000668966435124]
	TIME [epoch: 8.56 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015410631281232035		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.015410631281232035 | validation: 0.02322673711636062]
	TIME [epoch: 8.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024692821288389587		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.024692821288389587 | validation: 0.019530073304784675]
	TIME [epoch: 8.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01839401411376203		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.01839401411376203 | validation: 0.01730870007258164]
	TIME [epoch: 8.58 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01303091542416685		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.01303091542416685 | validation: 0.025777457165193366]
	TIME [epoch: 8.55 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018245045178963477		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.018245045178963477 | validation: 0.014244160006733769]
	TIME [epoch: 8.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01712268856289705		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.01712268856289705 | validation: 0.02305199740690932]
	TIME [epoch: 8.61 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016128456128567125		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.016128456128567125 | validation: 0.02159865422102855]
	TIME [epoch: 8.58 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024676673726621624		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.024676673726621624 | validation: 0.03185139292146889]
	TIME [epoch: 8.57 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0391509086149245		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.0391509086149245 | validation: 0.0293065246472502]
	TIME [epoch: 8.57 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02923972184813107		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.02923972184813107 | validation: 0.03766768813756888]
	TIME [epoch: 8.57 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020555921395838186		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.020555921395838186 | validation: 0.016221235989594626]
	TIME [epoch: 8.6 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02375691943222346		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.02375691943222346 | validation: 0.022699238940129023]
	TIME [epoch: 8.61 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018345969610398343		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.018345969610398343 | validation: 0.020846451633774306]
	TIME [epoch: 8.55 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025205171317836072		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.025205171317836072 | validation: 0.021817037374501757]
	TIME [epoch: 8.55 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019338598287812196		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.019338598287812196 | validation: 0.01829540653582195]
	TIME [epoch: 8.57 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019984096813128835		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.019984096813128835 | validation: 0.01774863577748635]
	TIME [epoch: 8.56 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024398736836941236		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.024398736836941236 | validation: 0.022719196485682727]
	TIME [epoch: 8.56 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024751191419519224		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.024751191419519224 | validation: 0.025451699513218202]
	TIME [epoch: 8.57 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020790480274083922		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.020790480274083922 | validation: 0.02494810110869216]
	TIME [epoch: 8.56 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017555095143930714		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.017555095143930714 | validation: 0.021298904979523137]
	TIME [epoch: 8.56 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017025225627177475		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.017025225627177475 | validation: 0.02310983125273759]
	TIME [epoch: 8.55 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02544331782007287		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.02544331782007287 | validation: 0.017763071114257928]
	TIME [epoch: 8.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026636619140763745		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.026636619140763745 | validation: 0.030710491309811138]
	TIME [epoch: 8.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.032809668474731685		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.032809668474731685 | validation: 0.02263422643828511]
	TIME [epoch: 8.55 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025203283723196183		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.025203283723196183 | validation: 0.023350566330112933]
	TIME [epoch: 8.54 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028021064385991373		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.028021064385991373 | validation: 0.01941444331921597]
	TIME [epoch: 8.58 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02646256152796503		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.02646256152796503 | validation: 0.022090822299518274]
	TIME [epoch: 8.56 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026685945711862075		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.026685945711862075 | validation: 0.03857802688823087]
	TIME [epoch: 8.56 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028229954504733357		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.028229954504733357 | validation: 0.032429671678670946]
	TIME [epoch: 8.56 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02399524168736606		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.02399524168736606 | validation: 0.023604382994254443]
	TIME [epoch: 8.59 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024388915005362468		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.024388915005362468 | validation: 0.014022184968059313]
	TIME [epoch: 8.56 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02376830051362739		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.02376830051362739 | validation: 0.02958788447342409]
	TIME [epoch: 8.57 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022687986767644136		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.022687986767644136 | validation: 0.027396145580855586]
	TIME [epoch: 8.56 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0273108749355211		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.0273108749355211 | validation: 0.037807445070618936]
	TIME [epoch: 8.58 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029275735327116293		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.029275735327116293 | validation: 0.03686966082384306]
	TIME [epoch: 8.56 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026063850160629138		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.026063850160629138 | validation: 0.020836367091266694]
	TIME [epoch: 8.56 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019945667588369135		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.019945667588369135 | validation: 0.024750108879748076]
	TIME [epoch: 8.55 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0205854796614197		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.0205854796614197 | validation: 0.015626358288924204]
	TIME [epoch: 8.59 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01610811364952288		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.01610811364952288 | validation: 0.02474127345701438]
	TIME [epoch: 8.59 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02043411966006514		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.02043411966006514 | validation: 0.02606130406487643]
	TIME [epoch: 8.6 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019821042116484687		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.019821042116484687 | validation: 0.015291396604602063]
	TIME [epoch: 8.55 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013393438904117963		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.013393438904117963 | validation: 0.02142826238551389]
	TIME [epoch: 8.57 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01598815614536943		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.01598815614536943 | validation: 0.021629582054141568]
	TIME [epoch: 8.56 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02054118591631058		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.02054118591631058 | validation: 0.023852249228232883]
	TIME [epoch: 8.56 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015120706199366691		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.015120706199366691 | validation: 0.017014637488663224]
	TIME [epoch: 8.56 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016739665554280952		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.016739665554280952 | validation: 0.02488202094027145]
	TIME [epoch: 8.57 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018446988725022408		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.018446988725022408 | validation: 0.015418022224564083]
	TIME [epoch: 8.56 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020741013182267842		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.020741013182267842 | validation: 0.026565721717980773]
	TIME [epoch: 8.57 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016273361488145656		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.016273361488145656 | validation: 0.02145363679109719]
	TIME [epoch: 8.57 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021703862492046654		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.021703862492046654 | validation: 0.017863397188595392]
	TIME [epoch: 8.58 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.025089223187971316		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.025089223187971316 | validation: 0.02506571101090552]
	TIME [epoch: 8.56 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023750708688583984		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.023750708688583984 | validation: 0.020064595101087084]
	TIME [epoch: 8.56 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018796203351060935		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.018796203351060935 | validation: 0.026374023452914886]
	TIME [epoch: 8.58 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01988029009717604		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.01988029009717604 | validation: 0.022889121213197472]
	TIME [epoch: 8.56 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01961468547261286		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.01961468547261286 | validation: 0.018984866641686263]
	TIME [epoch: 8.55 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02202847834719876		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.02202847834719876 | validation: 0.027745116211184737]
	TIME [epoch: 8.56 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022027257135662056		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.022027257135662056 | validation: 0.01812547243388476]
	TIME [epoch: 8.57 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01613139422180849		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.01613139422180849 | validation: 0.02034839554736439]
	TIME [epoch: 8.56 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016446071600886056		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.016446071600886056 | validation: 0.02008788248913872]
	TIME [epoch: 8.56 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020899279487957945		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.020899279487957945 | validation: 0.014516276496729721]
	TIME [epoch: 8.56 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01802098448231938		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.01802098448231938 | validation: 0.02437956745329167]
	TIME [epoch: 8.63 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017420360750796747		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.017420360750796747 | validation: 0.018557643357865722]
	TIME [epoch: 8.58 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01930500205544814		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.01930500205544814 | validation: 0.01862555614649613]
	TIME [epoch: 8.55 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021182447308040624		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.021182447308040624 | validation: 0.02190247859843812]
	TIME [epoch: 8.56 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017469767195688927		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.017469767195688927 | validation: 0.014763257662738448]
	TIME [epoch: 8.59 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017174927788653253		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.017174927788653253 | validation: 0.02364768932389105]
	TIME [epoch: 8.62 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01711380198964316		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.01711380198964316 | validation: 0.020819634163057044]
	TIME [epoch: 8.57 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017656738206527314		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.017656738206527314 | validation: 0.013662363636150318]
	TIME [epoch: 8.55 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013970158688308063		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.013970158688308063 | validation: 0.015632359958951278]
	TIME [epoch: 8.58 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01564820786393007		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.01564820786393007 | validation: 0.01383083053177629]
	TIME [epoch: 8.57 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01450615119825704		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.01450615119825704 | validation: 0.015685325099992327]
	TIME [epoch: 8.61 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019497778889583574		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.019497778889583574 | validation: 0.028469532140285633]
	TIME [epoch: 8.59 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017592144033788122		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.017592144033788122 | validation: 0.01609439130218332]
	TIME [epoch: 8.57 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015733176367935118		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.015733176367935118 | validation: 0.015844483277503582]
	TIME [epoch: 8.56 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016460962871657516		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.016460962871657516 | validation: 0.01602506818293422]
	TIME [epoch: 8.56 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016177591584997073		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.016177591584997073 | validation: 0.021832711140621193]
	TIME [epoch: 8.57 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021168579012780454		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.021168579012780454 | validation: 0.015516952770612963]
	TIME [epoch: 8.58 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016511684212834842		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.016511684212834842 | validation: 0.01632544006391927]
	TIME [epoch: 8.58 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017156001021314655		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.017156001021314655 | validation: 0.012988010148101302]
	TIME [epoch: 8.6 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01404356481776218		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.01404356481776218 | validation: 0.01455945856433804]
	TIME [epoch: 8.58 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01903002444381603		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.01903002444381603 | validation: 0.015276640407113184]
	TIME [epoch: 8.55 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01982515302971762		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.01982515302971762 | validation: 0.0325560875158524]
	TIME [epoch: 8.56 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016329792910833408		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.016329792910833408 | validation: 0.022257624816805936]
	TIME [epoch: 8.56 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016021109773322696		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.016021109773322696 | validation: 0.01630683895304141]
	TIME [epoch: 8.58 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020771453692087025		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.020771453692087025 | validation: 0.022082294523365017]
	TIME [epoch: 8.57 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01965170463647399		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.01965170463647399 | validation: 0.014830713605349027]
	TIME [epoch: 8.56 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023278464045828045		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.023278464045828045 | validation: 0.02374865825939948]
	TIME [epoch: 8.56 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014952531408921133		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.014952531408921133 | validation: 0.01691644329237926]
	TIME [epoch: 8.59 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02479508483732789		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.02479508483732789 | validation: 0.02662234850370105]
	TIME [epoch: 8.57 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023291929125366376		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.023291929125366376 | validation: 0.014961012762102677]
	TIME [epoch: 8.56 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014691336991534012		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.014691336991534012 | validation: 0.02258879339283855]
	TIME [epoch: 8.57 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013526508289331007		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.013526508289331007 | validation: 0.018416930534469373]
	TIME [epoch: 8.58 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01930294751481377		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.01930294751481377 | validation: 0.022325054074634205]
	TIME [epoch: 8.57 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017411262953186055		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.017411262953186055 | validation: 0.023384557764220874]
	TIME [epoch: 8.57 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012942649447772575		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.012942649447772575 | validation: 0.012889581468581402]
	TIME [epoch: 8.56 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018378285560167948		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.018378285560167948 | validation: 0.02715547773714349]
	TIME [epoch: 8.58 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01851124986591643		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.01851124986591643 | validation: 0.01714622629983099]
	TIME [epoch: 8.57 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015476158272334974		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.015476158272334974 | validation: 0.01435351649141304]
	TIME [epoch: 8.56 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01566336658927477		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.01566336658927477 | validation: 0.026228318165894104]
	TIME [epoch: 8.56 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016800063639320142		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.016800063639320142 | validation: 0.02321909848738274]
	TIME [epoch: 8.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017230250328142703		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.017230250328142703 | validation: 0.019698804608176513]
	TIME [epoch: 8.62 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015376576583707441		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.015376576583707441 | validation: 0.011831556224827788]
	TIME [epoch: 8.55 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015471263214981452		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.015471263214981452 | validation: 0.023913952183853344]
	TIME [epoch: 8.57 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016468348521470038		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.016468348521470038 | validation: 0.011376490993365292]
	TIME [epoch: 8.58 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016523953626408468		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.016523953626408468 | validation: 0.019628661225029043]
	TIME [epoch: 8.57 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01325371655431416		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.01325371655431416 | validation: 0.009543495108931661]
	TIME [epoch: 8.55 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018048821343892622		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.018048821343892622 | validation: 0.007679061245654653]
	TIME [epoch: 8.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1635.pth
	Model improved!!!
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020707980125975786		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.020707980125975786 | validation: 0.028792898855009776]
	TIME [epoch: 8.56 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013632688346503372		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.013632688346503372 | validation: 0.015831593615237425]
	TIME [epoch: 8.56 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014709014582620172		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.014709014582620172 | validation: 0.01897114384008232]
	TIME [epoch: 8.56 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018295012946663792		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.018295012946663792 | validation: 0.029509122588764432]
	TIME [epoch: 8.58 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016645987988743147		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.016645987988743147 | validation: 0.024820768833515708]
	TIME [epoch: 8.55 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022135724335827216		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.022135724335827216 | validation: 0.01840129414519207]
	TIME [epoch: 8.56 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017751720374767695		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.017751720374767695 | validation: 0.017526718419313175]
	TIME [epoch: 8.56 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01390715340629665		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.01390715340629665 | validation: 0.027615135278868094]
	TIME [epoch: 8.58 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01648957624614782		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.01648957624614782 | validation: 0.02202942448293544]
	TIME [epoch: 8.56 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01805065615374622		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.01805065615374622 | validation: 0.016059263956633485]
	TIME [epoch: 8.56 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019107106648270745		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.019107106648270745 | validation: 0.023411595324567026]
	TIME [epoch: 8.56 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012196136887164335		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.012196136887164335 | validation: 0.02256562153350962]
	TIME [epoch: 8.58 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015036467780157065		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.015036467780157065 | validation: 0.017655918982991244]
	TIME [epoch: 8.57 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01598284508815375		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.01598284508815375 | validation: 0.021729313001621748]
	TIME [epoch: 8.55 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017666736268999738		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.017666736268999738 | validation: 0.015267613793015326]
	TIME [epoch: 8.56 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01632347157559761		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.01632347157559761 | validation: 0.019846729677139387]
	TIME [epoch: 8.58 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016515880892945596		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.016515880892945596 | validation: 0.018636513394039787]
	TIME [epoch: 8.6 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013940287434023363		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.013940287434023363 | validation: 0.016416964119319883]
	TIME [epoch: 8.58 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016404388047633042		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.016404388047633042 | validation: 0.020861791256013444]
	TIME [epoch: 8.55 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016561812607771214		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.016561812607771214 | validation: 0.022837703102607288]
	TIME [epoch: 8.58 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01806933357154616		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.01806933357154616 | validation: 0.01977555872319986]
	TIME [epoch: 8.55 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015855574601035177		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.015855574601035177 | validation: 0.016649736498986566]
	TIME [epoch: 8.59 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019452675135170495		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.019452675135170495 | validation: 0.018685048453361466]
	TIME [epoch: 8.61 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01882351812380424		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.01882351812380424 | validation: 0.017660364000279913]
	TIME [epoch: 8.57 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01690940291273218		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.01690940291273218 | validation: 0.01610710840417151]
	TIME [epoch: 8.55 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0180038151158673		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.0180038151158673 | validation: 0.018809052831312217]
	TIME [epoch: 8.56 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014746749842551421		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.014746749842551421 | validation: 0.013091451955391154]
	TIME [epoch: 8.57 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01762198235380958		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.01762198235380958 | validation: 0.011033096101362641]
	TIME [epoch: 8.61 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016123096961245427		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.016123096961245427 | validation: 0.01964754408909372]
	TIME [epoch: 8.58 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01850598190863907		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.01850598190863907 | validation: 0.027914472688379006]
	TIME [epoch: 8.55 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01737684303555213		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.01737684303555213 | validation: 0.013965101828212562]
	TIME [epoch: 8.58 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020906713696912414		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.020906713696912414 | validation: 0.01741907291791773]
	TIME [epoch: 8.56 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017232979994625024		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.017232979994625024 | validation: 0.01625901048388381]
	TIME [epoch: 8.56 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020687543490880107		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.020687543490880107 | validation: 0.02915104253926383]
	TIME [epoch: 8.56 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02224679505049846		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.02224679505049846 | validation: 0.02259371953899698]
	TIME [epoch: 8.58 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01624830996996218		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.01624830996996218 | validation: 0.02252927776448663]
	TIME [epoch: 8.55 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016364582229386658		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.016364582229386658 | validation: 0.020826878267850738]
	TIME [epoch: 8.57 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014076622619901951		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.014076622619901951 | validation: 0.017232285708698895]
	TIME [epoch: 8.56 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017312811735729728		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.017312811735729728 | validation: 0.019588684107255578]
	TIME [epoch: 8.59 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018511936839384367		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.018511936839384367 | validation: 0.03091889849608844]
	TIME [epoch: 8.61 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016091555323994994		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.016091555323994994 | validation: 0.020518786657488523]
	TIME [epoch: 8.56 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017236789750729224		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.017236789750729224 | validation: 0.021694880572383696]
	TIME [epoch: 8.55 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017902365050905623		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.017902365050905623 | validation: 0.006810515040576205]
	TIME [epoch: 8.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1678.pth
	Model improved!!!
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01442419787392916		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.01442419787392916 | validation: 0.015608527699514494]
	TIME [epoch: 8.56 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015713910704198652		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.015713910704198652 | validation: 0.027837378283869268]
	TIME [epoch: 8.56 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022311807401764177		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.022311807401764177 | validation: 0.01985393378646831]
	TIME [epoch: 8.56 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015491893143333732		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.015491893143333732 | validation: 0.021397090710630323]
	TIME [epoch: 8.58 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024472182905143917		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.024472182905143917 | validation: 0.026256869894226067]
	TIME [epoch: 8.56 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02846363253996013		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.02846363253996013 | validation: 0.01892748321267597]
	TIME [epoch: 8.56 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02376204808965962		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.02376204808965962 | validation: 0.015104869018419743]
	TIME [epoch: 8.57 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02053531439135664		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.02053531439135664 | validation: 0.017969132222972705]
	TIME [epoch: 8.57 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.022254068502779365		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.022254068502779365 | validation: 0.028962849761818905]
	TIME [epoch: 8.56 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029175526111607786		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.029175526111607786 | validation: 0.03392447965991403]
	TIME [epoch: 8.56 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030129167530532696		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.030129167530532696 | validation: 0.02181825726336674]
	TIME [epoch: 8.58 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02517032683046756		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.02517032683046756 | validation: 0.02629760936924722]
	TIME [epoch: 8.56 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026831661804629297		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.026831661804629297 | validation: 0.028618253517491508]
	TIME [epoch: 8.55 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.030336532492995606		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.030336532492995606 | validation: 0.029726588891993706]
	TIME [epoch: 8.56 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02768498353920746		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.02768498353920746 | validation: 0.02559119325229928]
	TIME [epoch: 8.58 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02404744568602788		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.02404744568602788 | validation: 0.028361411428727383]
	TIME [epoch: 8.57 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02242429121331497		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.02242429121331497 | validation: 0.025732105115209826]
	TIME [epoch: 8.55 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029075813095185005		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.029075813095185005 | validation: 0.026272710148354233]
	TIME [epoch: 8.56 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.031217584005373396		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.031217584005373396 | validation: 0.0223861562103772]
	TIME [epoch: 8.57 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026347884409028834		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.026347884409028834 | validation: 0.02816160552238664]
	TIME [epoch: 8.59 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02379707068848525		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.02379707068848525 | validation: 0.010378255467610138]
	TIME [epoch: 8.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01895995167288862		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.01895995167288862 | validation: 0.02160783420538423]
	TIME [epoch: 8.55 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01826220574310506		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.01826220574310506 | validation: 0.016234279808449274]
	TIME [epoch: 8.57 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023678397555300143		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.023678397555300143 | validation: 0.018365750334623236]
	TIME [epoch: 8.56 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01711896894546576		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.01711896894546576 | validation: 0.016950595543071167]
	TIME [epoch: 8.57 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015180285440123592		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.015180285440123592 | validation: 0.0180392000552272]
	TIME [epoch: 8.54 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01516335330332708		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.01516335330332708 | validation: 0.01721021736354893]
	TIME [epoch: 8.54 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011516427946147245		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.011516427946147245 | validation: 0.010803228489300383]
	TIME [epoch: 8.53 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014439144615094329		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.014439144615094329 | validation: 0.02412453493203753]
	TIME [epoch: 8.53 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01885547321986372		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.01885547321986372 | validation: 0.02481207779135913]
	TIME [epoch: 8.53 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018821296871977925		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.018821296871977925 | validation: 0.0224900913181948]
	TIME [epoch: 8.55 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01766552685974591		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.01766552685974591 | validation: 0.02492608671125615]
	TIME [epoch: 8.53 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018042602057581413		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.018042602057581413 | validation: 0.02251186618493156]
	TIME [epoch: 8.53 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018597268990558146		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.018597268990558146 | validation: 0.02181276808485203]
	TIME [epoch: 8.54 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019769832658866192		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.019769832658866192 | validation: 0.023932020372444514]
	TIME [epoch: 8.54 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01385005120059864		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.01385005120059864 | validation: 0.018049907965747247]
	TIME [epoch: 8.53 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016425927042021376		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.016425927042021376 | validation: 0.01389563427851598]
	TIME [epoch: 8.52 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014346392252576556		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.014346392252576556 | validation: 0.01376534542992239]
	TIME [epoch: 8.55 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013597229965853233		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.013597229965853233 | validation: 0.014424405190504853]
	TIME [epoch: 8.53 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014724063324757095		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.014724063324757095 | validation: 0.016400311410353703]
	TIME [epoch: 8.52 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019355349114237207		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.019355349114237207 | validation: 0.02359886744153781]
	TIME [epoch: 8.53 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01432808302841471		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.01432808302841471 | validation: 0.011013001784741707]
	TIME [epoch: 8.55 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018662636959847843		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.018662636959847843 | validation: 0.01991132442252089]
	TIME [epoch: 8.53 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01651511194237517		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.01651511194237517 | validation: 0.02427658530130082]
	TIME [epoch: 8.53 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01736499870598739		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.01736499870598739 | validation: 0.024486115103207844]
	TIME [epoch: 8.53 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019132354127063038		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.019132354127063038 | validation: 0.017194856035344857]
	TIME [epoch: 8.55 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016043662732148106		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.016043662732148106 | validation: 0.010105188911850119]
	TIME [epoch: 8.54 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014765270543308034		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.014765270543308034 | validation: 0.014580312429460309]
	TIME [epoch: 8.53 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017075051292953104		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.017075051292953104 | validation: 0.012904455442182999]
	TIME [epoch: 8.52 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01929456910176634		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.01929456910176634 | validation: 0.020982585080588236]
	TIME [epoch: 8.55 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016824816468786915		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.016824816468786915 | validation: 0.022873354153738396]
	TIME [epoch: 8.53 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021148861318355736		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.021148861318355736 | validation: 0.017327455827421602]
	TIME [epoch: 8.53 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016956529601188812		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.016956529601188812 | validation: 0.018195430678243474]
	TIME [epoch: 8.53 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0168077203917907		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.0168077203917907 | validation: 0.018453068283008946]
	TIME [epoch: 8.55 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015367524143724937		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.015367524143724937 | validation: 0.010883404727448571]
	TIME [epoch: 8.53 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012902154323416246		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.012902154323416246 | validation: 0.015786775202315487]
	TIME [epoch: 8.53 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01734385799029265		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.01734385799029265 | validation: 0.022113942389845362]
	TIME [epoch: 8.53 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01674651741929447		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.01674651741929447 | validation: 0.021390735541469523]
	TIME [epoch: 8.55 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019327553024632373		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.019327553024632373 | validation: 0.0197459926777906]
	TIME [epoch: 8.53 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016133853404449595		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.016133853404449595 | validation: 0.01999754844932782]
	TIME [epoch: 8.52 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016952211629480178		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.016952211629480178 | validation: 0.019644173119503776]
	TIME [epoch: 8.53 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010256624805623903		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.010256624805623903 | validation: 0.016102302680980608]
	TIME [epoch: 8.55 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016503256409285533		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.016503256409285533 | validation: 0.020760364489757738]
	TIME [epoch: 8.53 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015475542089278408		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.015475542089278408 | validation: 0.016582052852593232]
	TIME [epoch: 8.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011884677158783573		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.011884677158783573 | validation: 0.025582843456494784]
	TIME [epoch: 8.53 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01665723915951699		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.01665723915951699 | validation: 0.020705497644544393]
	TIME [epoch: 8.54 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01621365218088889		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.01621365218088889 | validation: 0.0178659949623014]
	TIME [epoch: 8.54 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014977495320773703		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.014977495320773703 | validation: 0.008626002085133571]
	TIME [epoch: 8.52 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017476617738661396		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.017476617738661396 | validation: 0.021311500528933335]
	TIME [epoch: 8.53 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015007562695148491		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.015007562695148491 | validation: 0.010535774831380856]
	TIME [epoch: 8.54 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011314399447990453		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.011314399447990453 | validation: 0.013629305817120487]
	TIME [epoch: 8.53 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019819690289168683		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.019819690289168683 | validation: 0.025743840023659575]
	TIME [epoch: 8.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014718001344842954		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.014718001344842954 | validation: 0.018089542966782383]
	TIME [epoch: 8.55 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01604846030968615		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.01604846030968615 | validation: 0.016882047124964855]
	TIME [epoch: 8.53 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014773649478728623		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.014773649478728623 | validation: 0.01388412518821901]
	TIME [epoch: 8.53 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012367915722987623		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.012367915722987623 | validation: 0.015947086568524085]
	TIME [epoch: 8.53 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013961252955690867		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.013961252955690867 | validation: 0.01146382337340155]
	TIME [epoch: 8.55 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016531540509345195		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.016531540509345195 | validation: 0.010559832665149914]
	TIME [epoch: 8.52 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014230955941269576		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.014230955941269576 | validation: 0.018399168691103078]
	TIME [epoch: 8.53 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018795678424480232		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.018795678424480232 | validation: 0.027374856936642683]
	TIME [epoch: 8.52 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020019612717193054		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.020019612717193054 | validation: 0.022628091431677867]
	TIME [epoch: 8.55 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01966338122724393		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.01966338122724393 | validation: 0.019623216655065664]
	TIME [epoch: 8.53 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016792684531238663		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.016792684531238663 | validation: 0.016417256616006924]
	TIME [epoch: 8.53 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017066435448767247		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.017066435448767247 | validation: 0.021623486878498174]
	TIME [epoch: 8.54 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01512232720432298		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.01512232720432298 | validation: 0.012789724534904364]
	TIME [epoch: 8.55 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014379905396373785		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.014379905396373785 | validation: 0.022248942639067876]
	TIME [epoch: 8.53 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013133468590848518		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.013133468590848518 | validation: 0.026055221558401884]
	TIME [epoch: 8.53 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016430599001502563		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.016430599001502563 | validation: 0.02153033973009913]
	TIME [epoch: 8.53 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019528019664873573		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.019528019664873573 | validation: 0.02152459807000088]
	TIME [epoch: 8.55 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015914167316617628		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.015914167316617628 | validation: 0.017225586010376492]
	TIME [epoch: 8.53 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018596410493857907		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.018596410493857907 | validation: 0.02176760670071128]
	TIME [epoch: 8.53 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016731773126412795		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.016731773126412795 | validation: 0.01634527927221034]
	TIME [epoch: 8.53 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02021831679084396		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.02021831679084396 | validation: 0.022050596817766423]
	TIME [epoch: 8.55 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017125686158357162		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.017125686158357162 | validation: 0.02813020661759496]
	TIME [epoch: 8.53 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0159455043482986		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.0159455043482986 | validation: 0.02508783995456884]
	TIME [epoch: 8.52 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01834376851292165		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.01834376851292165 | validation: 0.01851974103937523]
	TIME [epoch: 8.53 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01724767768108217		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.01724767768108217 | validation: 0.021302025446203115]
	TIME [epoch: 8.54 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.028358486144389933		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.028358486144389933 | validation: 0.026015526245505828]
	TIME [epoch: 8.53 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020507878033676808		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.020507878033676808 | validation: 0.039735852797375716]
	TIME [epoch: 8.53 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02453094011999096		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.02453094011999096 | validation: 0.02441031879053905]
	TIME [epoch: 8.54 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026357687449778282		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.026357687449778282 | validation: 0.02787465530005533]
	TIME [epoch: 8.54 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.029372527680472632		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.029372527680472632 | validation: 0.024457477690370485]
	TIME [epoch: 8.52 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02775336319036147		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.02775336319036147 | validation: 0.020349296056734037]
	TIME [epoch: 8.53 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018163954727475236		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.018163954727475236 | validation: 0.015287892159969374]
	TIME [epoch: 8.55 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016609783591544695		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.016609783591544695 | validation: 0.01999902079257937]
	TIME [epoch: 8.53 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015413173358426593		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.015413173358426593 | validation: 0.02715551530375379]
	TIME [epoch: 8.54 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015458495812393369		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.015458495812393369 | validation: 0.018261014861319372]
	TIME [epoch: 8.52 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016196986113949173		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.016196986113949173 | validation: 0.02287448188958572]
	TIME [epoch: 8.55 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01361376521895823		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.01361376521895823 | validation: 0.02466503907251294]
	TIME [epoch: 8.53 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01629589885903436		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.01629589885903436 | validation: 0.012995770821578118]
	TIME [epoch: 8.53 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01640891471824759		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.01640891471824759 | validation: 0.02507794564307037]
	TIME [epoch: 8.53 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01844359578377361		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.01844359578377361 | validation: 0.019436852964590245]
	TIME [epoch: 8.55 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018965941499112272		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.018965941499112272 | validation: 0.013237270637214877]
	TIME [epoch: 8.53 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023467123583901767		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.023467123583901767 | validation: 0.025773705020591745]
	TIME [epoch: 8.53 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.020054162126495335		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.020054162126495335 | validation: 0.01926581638869614]
	TIME [epoch: 8.52 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015171821807742033		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.015171821807742033 | validation: 0.018715062781319333]
	TIME [epoch: 8.55 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01413721065007877		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.01413721065007877 | validation: 0.02242185121333408]
	TIME [epoch: 8.53 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013084305305361279		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.013084305305361279 | validation: 0.016486979780702436]
	TIME [epoch: 8.54 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01694242460396548		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.01694242460396548 | validation: 0.026238352400525092]
	TIME [epoch: 8.53 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017533409462986618		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.017533409462986618 | validation: 0.027647478214232416]
	TIME [epoch: 8.55 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017673261304841002		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.017673261304841002 | validation: 0.01975727481628695]
	TIME [epoch: 8.53 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014226493442311952		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.014226493442311952 | validation: 0.02463404633037464]
	TIME [epoch: 8.52 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01823351357694425		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.01823351357694425 | validation: 0.02340233280181578]
	TIME [epoch: 8.53 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016800852386555924		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.016800852386555924 | validation: 0.016104028391621904]
	TIME [epoch: 8.55 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016093233994958267		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.016093233994958267 | validation: 0.021067951178165248]
	TIME [epoch: 8.53 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015238134300537961		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.015238134300537961 | validation: 0.030369294378422215]
	TIME [epoch: 8.53 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014530732687035013		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.014530732687035013 | validation: 0.024468696074631868]
	TIME [epoch: 8.53 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018840093565512285		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.018840093565512285 | validation: 0.018243672490341954]
	TIME [epoch: 8.55 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016450095797109272		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.016450095797109272 | validation: 0.016501420664152167]
	TIME [epoch: 8.53 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014925221536958572		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.014925221536958572 | validation: 0.018122386655996005]
	TIME [epoch: 8.53 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01446791192147289		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.01446791192147289 | validation: 0.01938898994530981]
	TIME [epoch: 8.54 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014903413226909242		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.014903413226909242 | validation: 0.015920238831409292]
	TIME [epoch: 8.55 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011418098808025523		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.011418098808025523 | validation: 0.01657649015895891]
	TIME [epoch: 8.52 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015777634263211417		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.015777634263211417 | validation: 0.013862941552684265]
	TIME [epoch: 8.53 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015682230335214938		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.015682230335214938 | validation: 0.019011771804218563]
	TIME [epoch: 8.55 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014761835118858355		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.014761835118858355 | validation: 0.011299434224226615]
	TIME [epoch: 8.53 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017160932681216275		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.017160932681216275 | validation: 0.0147291824234065]
	TIME [epoch: 8.53 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013877843790055527		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.013877843790055527 | validation: 0.01308054193590816]
	TIME [epoch: 8.54 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01829329186380975		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.01829329186380975 | validation: 0.0196233908219818]
	TIME [epoch: 8.55 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018176723411711733		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.018176723411711733 | validation: 0.015335330644092607]
	TIME [epoch: 8.53 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01524772956791251		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.01524772956791251 | validation: 0.018555566348979695]
	TIME [epoch: 8.53 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01595093385730485		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.01595093385730485 | validation: 0.033121534973241766]
	TIME [epoch: 8.53 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.024203243334388266		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.024203243334388266 | validation: 0.026739774165545564]
	TIME [epoch: 8.55 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016531876182190715		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.016531876182190715 | validation: 0.018026523559499713]
	TIME [epoch: 8.53 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018136727880802738		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.018136727880802738 | validation: 0.0259902202157174]
	TIME [epoch: 8.52 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014653755351148535		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.014653755351148535 | validation: 0.02065612964267737]
	TIME [epoch: 8.53 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016236713100743805		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.016236713100743805 | validation: 0.031463833203979864]
	TIME [epoch: 8.55 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021251279129812527		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.021251279129812527 | validation: 0.024536731571832244]
	TIME [epoch: 8.54 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023245681149235725		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.023245681149235725 | validation: 0.025630786881701846]
	TIME [epoch: 8.53 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.026136144387705312		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.026136144387705312 | validation: 0.021219841355400514]
	TIME [epoch: 8.53 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021187448811224578		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.021187448811224578 | validation: 0.010506879160789864]
	TIME [epoch: 8.55 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018180905651864483		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.018180905651864483 | validation: 0.02526027097854558]
	TIME [epoch: 8.53 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019799813505210984		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.019799813505210984 | validation: 0.024843448720037548]
	TIME [epoch: 8.53 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016441655635599243		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.016441655635599243 | validation: 0.023497918796003582]
	TIME [epoch: 8.53 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015253949229700043		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.015253949229700043 | validation: 0.027823415013164553]
	TIME [epoch: 8.55 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014586224950753826		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.014586224950753826 | validation: 0.01930791887401759]
	TIME [epoch: 8.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018980585949883277		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.018980585949883277 | validation: 0.018733433168098817]
	TIME [epoch: 8.52 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01767031351691528		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.01767031351691528 | validation: 0.024764558876252552]
	TIME [epoch: 8.53 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013912178193583483		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.013912178193583483 | validation: 0.030493855525162008]
	TIME [epoch: 8.55 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019469908916681048		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.019469908916681048 | validation: 0.01748908377466288]
	TIME [epoch: 8.52 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021913401538131587		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.021913401538131587 | validation: 0.0231294129216647]
	TIME [epoch: 8.52 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023931482604128536		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.023931482604128536 | validation: 0.02950501563594737]
	TIME [epoch: 8.54 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01999029836347173		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.01999029836347173 | validation: 0.01593508399350746]
	TIME [epoch: 8.55 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015431378157007087		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.015431378157007087 | validation: 0.02203958310751319]
	TIME [epoch: 8.53 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014362048436656788		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.014362048436656788 | validation: 0.014328359231109178]
	TIME [epoch: 8.53 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014299571529304028		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.014299571529304028 | validation: 0.0176196272437964]
	TIME [epoch: 8.55 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013370343505910163		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.013370343505910163 | validation: 0.015512281691534596]
	TIME [epoch: 8.53 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016549412656492075		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.016549412656492075 | validation: 0.01985388453494989]
	TIME [epoch: 8.53 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01407304857485818		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.01407304857485818 | validation: 0.017697229270544814]
	TIME [epoch: 8.53 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01555544721110937		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.01555544721110937 | validation: 0.01764481664419926]
	TIME [epoch: 8.55 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011269798473737328		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.011269798473737328 | validation: 0.008006905150993308]
	TIME [epoch: 8.53 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015186845482125797		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.015186845482125797 | validation: 0.016593842626986304]
	TIME [epoch: 8.53 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01636924688699523		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.01636924688699523 | validation: 0.013976452501498397]
	TIME [epoch: 8.53 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0140040370520071		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.0140040370520071 | validation: 0.01670651967912784]
	TIME [epoch: 8.55 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017790404708190037		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.017790404708190037 | validation: 0.01744131784739371]
	TIME [epoch: 8.53 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012291916271579554		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.012291916271579554 | validation: 0.016562456759624755]
	TIME [epoch: 8.53 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010476783437193087		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.010476783437193087 | validation: 0.02096951292234759]
	TIME [epoch: 8.53 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014976919954849528		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.014976919954849528 | validation: 0.008827842891694502]
	TIME [epoch: 8.56 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015626081300228696		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.015626081300228696 | validation: 0.020659035247008278]
	TIME [epoch: 8.55 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014556661295406443		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.014556661295406443 | validation: 0.020950386919294843]
	TIME [epoch: 8.53 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013908077685548987		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.013908077685548987 | validation: 0.02654204771554279]
	TIME [epoch: 8.54 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017163060584486398		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.017163060584486398 | validation: 0.023753966867526736]
	TIME [epoch: 8.56 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01646507233603315		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.01646507233603315 | validation: 0.013956024633497417]
	TIME [epoch: 8.55 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018255721688611313		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.018255721688611313 | validation: 0.015880804672758427]
	TIME [epoch: 8.54 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017297953864777112		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.017297953864777112 | validation: 0.016910619044767615]
	TIME [epoch: 8.54 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014640347784361674		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.014640347784361674 | validation: 0.015887113519024432]
	TIME [epoch: 8.57 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0167667210683913		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.0167667210683913 | validation: 0.015726846340320306]
	TIME [epoch: 8.53 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013665479010612418		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.013665479010612418 | validation: 0.020011518609897104]
	TIME [epoch: 8.53 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017773057200546907		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.017773057200546907 | validation: 0.023045606924601954]
	TIME [epoch: 8.54 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019122416716665775		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.019122416716665775 | validation: 0.01982806046247504]
	TIME [epoch: 8.56 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016128625609094328		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.016128625609094328 | validation: 0.018584789822277698]
	TIME [epoch: 8.53 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013562128692136901		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.013562128692136901 | validation: 0.01339021478507624]
	TIME [epoch: 8.54 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015636367973653666		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.015636367973653666 | validation: 0.01760010138771497]
	TIME [epoch: 8.54 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016393033169692824		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.016393033169692824 | validation: 0.012875465340312902]
	TIME [epoch: 8.55 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014481558861149633		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.014481558861149633 | validation: 0.021034642356338284]
	TIME [epoch: 8.53 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015555677406021397		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.015555677406021397 | validation: 0.01769397022367138]
	TIME [epoch: 8.54 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01373665446871269		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.01373665446871269 | validation: 0.027506936655085686]
	TIME [epoch: 8.55 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019879668462277397		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.019879668462277397 | validation: 0.01630028040376099]
	TIME [epoch: 8.54 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013621978143359536		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.013621978143359536 | validation: 0.01482579804195102]
	TIME [epoch: 8.54 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017828464752903957		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.017828464752903957 | validation: 0.0185669203610975]
	TIME [epoch: 8.55 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01602560615924887		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.01602560615924887 | validation: 0.02121380591329831]
	TIME [epoch: 8.56 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013178423688713845		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.013178423688713845 | validation: 0.021696476376840128]
	TIME [epoch: 8.54 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013085877708461693		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.013085877708461693 | validation: 0.012644404803986643]
	TIME [epoch: 8.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01742965822261245		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.01742965822261245 | validation: 0.019434270758068507]
	TIME [epoch: 8.55 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013388400798493799		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.013388400798493799 | validation: 0.027424355552038447]
	TIME [epoch: 8.56 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014838584258699708		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.014838584258699708 | validation: 0.017679340513885734]
	TIME [epoch: 8.55 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013340203211873333		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.013340203211873333 | validation: 0.02171016441220572]
	TIME [epoch: 8.53 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014526463646943715		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.014526463646943715 | validation: 0.019043118001277365]
	TIME [epoch: 8.53 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013430726718674447		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.013430726718674447 | validation: 0.019360730594820234]
	TIME [epoch: 8.55 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01552466235291598		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.01552466235291598 | validation: 0.01428237549022372]
	TIME [epoch: 8.54 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014820106491376508		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.014820106491376508 | validation: 0.026364234183565052]
	TIME [epoch: 8.53 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01475178231793991		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.01475178231793991 | validation: 0.01271689840629381]
	TIME [epoch: 8.53 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015650833408030224		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.015650833408030224 | validation: 0.01803952917022313]
	TIME [epoch: 8.55 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014375544242439831		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.014375544242439831 | validation: 0.022516686426732203]
	TIME [epoch: 8.54 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016239243291510174		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.016239243291510174 | validation: 0.02042025430588922]
	TIME [epoch: 8.53 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015061780077339923		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.015061780077339923 | validation: 0.013437591256161204]
	TIME [epoch: 8.54 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019303861020696946		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.019303861020696946 | validation: 0.013216271240539786]
	TIME [epoch: 8.56 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012136967437651632		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.012136967437651632 | validation: 0.017050834295897044]
	TIME [epoch: 8.53 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013510466315337985		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.013510466315337985 | validation: 0.020639483347824453]
	TIME [epoch: 8.53 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012666430778451306		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.012666430778451306 | validation: 0.021111290519801283]
	TIME [epoch: 8.53 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018232289887890198		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.018232289887890198 | validation: 0.01047400370941692]
	TIME [epoch: 8.55 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017807337270005906		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.017807337270005906 | validation: 0.018169963488368954]
	TIME [epoch: 8.53 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01636947561378236		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.01636947561378236 | validation: 0.021970519275983133]
	TIME [epoch: 8.54 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012236299289279906		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.012236299289279906 | validation: 0.020748051594019087]
	TIME [epoch: 8.54 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014825033051749273		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.014825033051749273 | validation: 0.015625592829985102]
	TIME [epoch: 8.54 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013224145052850283		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.013224145052850283 | validation: 0.021413595868633478]
	TIME [epoch: 8.53 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012066418877592303		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.012066418877592303 | validation: 0.015072749378243114]
	TIME [epoch: 8.53 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01843454029891947		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.01843454029891947 | validation: 0.012997768623232856]
	TIME [epoch: 8.56 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01440168229106709		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.01440168229106709 | validation: 0.015473496616601646]
	TIME [epoch: 8.54 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012273386409846454		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.012273386409846454 | validation: 0.01764074861668977]
	TIME [epoch: 8.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01328546591881315		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.01328546591881315 | validation: 0.021127063181171506]
	TIME [epoch: 8.53 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015592803389239476		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.015592803389239476 | validation: 0.013924571631965366]
	TIME [epoch: 8.55 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016221984518348713		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.016221984518348713 | validation: 0.014391101825518483]
	TIME [epoch: 8.53 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01863615212605714		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.01863615212605714 | validation: 0.014829097887653585]
	TIME [epoch: 8.53 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01816397437579203		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.01816397437579203 | validation: 0.028294329220827974]
	TIME [epoch: 8.53 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014791574386060147		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.014791574386060147 | validation: 0.019815040776782596]
	TIME [epoch: 8.55 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014988161789106755		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.014988161789106755 | validation: 0.008433779889620876]
	TIME [epoch: 8.53 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01706256746975862		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.01706256746975862 | validation: 0.014177587847701718]
	TIME [epoch: 8.53 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014462882651737823		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.014462882651737823 | validation: 0.023351085077244135]
	TIME [epoch: 8.53 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015140064682758709		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.015140064682758709 | validation: 0.021587667852634426]
	TIME [epoch: 8.55 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016783841848439392		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.016783841848439392 | validation: 0.012581416964354351]
	TIME [epoch: 8.54 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017263269301796173		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.017263269301796173 | validation: 0.00727006947447166]
	TIME [epoch: 8.53 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01880585720934686		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.01880585720934686 | validation: 0.01877925935511779]
	TIME [epoch: 8.54 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013277713117099165		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.013277713117099165 | validation: 0.02749191184309143]
	TIME [epoch: 8.55 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015064718285614445		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.015064718285614445 | validation: 0.017533744516610144]
	TIME [epoch: 8.54 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014425392722986508		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.014425392722986508 | validation: 0.019303125460657808]
	TIME [epoch: 8.53 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015204456442477449		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.015204456442477449 | validation: 0.005718569496977757]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1925.pth
	Model improved!!!
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01992692143120497		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.01992692143120497 | validation: 0.010428535082748469]
	TIME [epoch: 8.55 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.008338455226005228		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.008338455226005228 | validation: 0.01779735147237635]
	TIME [epoch: 8.53 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016795278382015978		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.016795278382015978 | validation: 0.026070042073922703]
	TIME [epoch: 8.53 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013809434311363564		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.013809434311363564 | validation: 0.008613149889202918]
	TIME [epoch: 8.53 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015669496224084162		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.015669496224084162 | validation: 0.01598625103640569]
	TIME [epoch: 8.55 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01029573591252092		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.01029573591252092 | validation: 0.02037902202495038]
	TIME [epoch: 8.53 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.00839253372287015		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.00839253372287015 | validation: 0.019636958830107708]
	TIME [epoch: 8.53 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015979767691235602		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.015979767691235602 | validation: 0.029585049315735763]
	TIME [epoch: 8.54 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018283436346665665		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.018283436346665665 | validation: 0.015433777877425838]
	TIME [epoch: 8.54 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01606127977702672		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.01606127977702672 | validation: 0.023408997157466638]
	TIME [epoch: 8.53 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016819534215217834		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.016819534215217834 | validation: 0.0235326941540585]
	TIME [epoch: 8.53 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01122117553302016		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.01122117553302016 | validation: 0.017698851948787033]
	TIME [epoch: 8.55 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0144736254573684		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.0144736254573684 | validation: 0.02526744996491912]
	TIME [epoch: 8.53 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010526289258824081		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.010526289258824081 | validation: 0.01671734801632164]
	TIME [epoch: 8.53 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0172361112199365		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.0172361112199365 | validation: 0.018340121713613638]
	TIME [epoch: 8.54 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015365344810439645		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.015365344810439645 | validation: 0.02022886662319457]
	TIME [epoch: 8.55 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017550020558340658		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.017550020558340658 | validation: 0.0142879167405589]
	TIME [epoch: 8.53 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015940493840660236		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.015940493840660236 | validation: 0.028325381933009056]
	TIME [epoch: 8.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016100606774467622		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.016100606774467622 | validation: 0.01839119072052838]
	TIME [epoch: 8.53 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01900873876245845		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.01900873876245845 | validation: 0.018827426465934025]
	TIME [epoch: 8.55 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01482892893714213		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.01482892893714213 | validation: 0.010499517006071421]
	TIME [epoch: 8.53 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.010112449935820634		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.010112449935820634 | validation: 0.0211149779550561]
	TIME [epoch: 8.53 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01809101963586677		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.01809101963586677 | validation: 0.02737228371502458]
	TIME [epoch: 8.53 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015470419449326733		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.015470419449326733 | validation: 0.021570705170510174]
	TIME [epoch: 8.55 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012780728605643355		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.012780728605643355 | validation: 0.026577148259520914]
	TIME [epoch: 8.53 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013032172813284917		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.013032172813284917 | validation: 0.019723125021181426]
	TIME [epoch: 8.54 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015581507548094915		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.015581507548094915 | validation: 0.017744920230251]
	TIME [epoch: 8.54 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014176200404497432		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.014176200404497432 | validation: 0.024892312287399514]
	TIME [epoch: 8.56 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019881993529354998		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.019881993529354998 | validation: 0.0215386251019984]
	TIME [epoch: 8.54 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01901299735318727		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.01901299735318727 | validation: 0.01468674295223106]
	TIME [epoch: 8.53 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.02151163975754239		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.02151163975754239 | validation: 0.024362907312805614]
	TIME [epoch: 8.52 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.023322479976030257		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.023322479976030257 | validation: 0.019987705986639202]
	TIME [epoch: 8.55 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019684815659071524		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.019684815659071524 | validation: 0.031667174968439335]
	TIME [epoch: 8.53 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019893854030346363		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.019893854030346363 | validation: 0.01600359543827804]
	TIME [epoch: 8.53 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016627954155864228		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.016627954155864228 | validation: 0.016173392550487314]
	TIME [epoch: 8.53 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01846615725519502		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.01846615725519502 | validation: 0.021627481353271586]
	TIME [epoch: 8.55 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012604960395200907		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.012604960395200907 | validation: 0.021868802407778436]
	TIME [epoch: 8.53 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014116862894055832		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.014116862894055832 | validation: 0.016363707741436626]
	TIME [epoch: 8.52 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012999449655572107		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.012999449655572107 | validation: 0.024658629631398032]
	TIME [epoch: 8.54 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01173622474725568		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.01173622474725568 | validation: 0.01884935716609538]
	TIME [epoch: 8.54 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013649763136043958		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.013649763136043958 | validation: 0.01609312400600203]
	TIME [epoch: 8.53 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015965606465145922		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.015965606465145922 | validation: 0.017497196292773506]
	TIME [epoch: 8.53 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014639885130426463		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.014639885130426463 | validation: 0.01790784850381746]
	TIME [epoch: 8.55 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01471966644967344		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.01471966644967344 | validation: 0.019432284475251825]
	TIME [epoch: 8.54 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01670368656991807		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.01670368656991807 | validation: 0.01422202785143022]
	TIME [epoch: 8.53 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015434219664493385		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.015434219664493385 | validation: 0.01865602324252528]
	TIME [epoch: 8.54 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01696779688651121		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.01696779688651121 | validation: 0.01897808005339247]
	TIME [epoch: 8.55 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015958844608637647		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.015958844608637647 | validation: 0.025664907136101242]
	TIME [epoch: 8.54 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014867528785773585		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.014867528785773585 | validation: 0.02474442061832082]
	TIME [epoch: 8.53 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013260107200232052		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.013260107200232052 | validation: 0.01655197386198454]
	TIME [epoch: 8.53 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018298001169697348		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.018298001169697348 | validation: 0.016927734269112205]
	TIME [epoch: 8.55 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015665603385443864		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.015665603385443864 | validation: 0.010583844362394469]
	TIME [epoch: 8.53 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013382670385011782		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.013382670385011782 | validation: 0.018452266022702075]
	TIME [epoch: 8.53 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.012976779684433254		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.012976779684433254 | validation: 0.024607628383349064]
	TIME [epoch: 8.53 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016730997245263498		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.016730997245263498 | validation: 0.02315914695787372]
	TIME [epoch: 8.55 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.021222993710330457		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.021222993710330457 | validation: 0.018303124338936962]
	TIME [epoch: 8.53 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01950737246018013		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.01950737246018013 | validation: 0.014072024942996026]
	TIME [epoch: 8.53 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.017062344199675953		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.017062344199675953 | validation: 0.016679490119344876]
	TIME [epoch: 8.53 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.013272080996859753		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.013272080996859753 | validation: 0.018849114008573992]
	TIME [epoch: 8.55 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01359826049829258		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.01359826049829258 | validation: 0.019455305819958156]
	TIME [epoch: 8.53 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.019537356773405228		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.019537356773405228 | validation: 0.019878602541181938]
	TIME [epoch: 8.53 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01627336757836033		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.01627336757836033 | validation: 0.015568211408504439]
	TIME [epoch: 8.53 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015640276891257826		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.015640276891257826 | validation: 0.013643119836051413]
	TIME [epoch: 8.56 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.011503722578318401		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.011503722578318401 | validation: 0.020729294324935317]
	TIME [epoch: 8.53 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014931819509637987		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.014931819509637987 | validation: 0.012154453460099168]
	TIME [epoch: 8.53 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.01786273662922044		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.01786273662922044 | validation: 0.015124690873529679]
	TIME [epoch: 8.54 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.018730588760772094		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.018730588760772094 | validation: 0.010753674814221832]
	TIME [epoch: 8.55 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016653769529735858		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.016653769529735858 | validation: 0.005539239794834933]
	TIME [epoch: 8.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240219_203402/states/model_tr_study204_1993.pth
	Model improved!!!
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014174129718635011		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.014174129718635011 | validation: 0.01584569575511732]
	TIME [epoch: 8.53 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015907784487837234		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.015907784487837234 | validation: 0.024474646807685834]
	TIME [epoch: 8.55 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.014130037836532994		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.014130037836532994 | validation: 0.007728710446641004]
	TIME [epoch: 8.54 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016871552030883398		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.016871552030883398 | validation: 0.011209052382002744]
	TIME [epoch: 8.53 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015336633849329845		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.015336633849329845 | validation: 0.020772242854272174]
	TIME [epoch: 8.53 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.016839538484065407		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.016839538484065407 | validation: 0.01446387217242394]
	TIME [epoch: 8.55 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.015768914348017124		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.015768914348017124 | validation: 0.020113251350538063]
	TIME [epoch: 8.54 sec]
Finished training in 17314.079 seconds.
