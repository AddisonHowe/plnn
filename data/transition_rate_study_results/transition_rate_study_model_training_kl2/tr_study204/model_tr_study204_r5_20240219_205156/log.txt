Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r5', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2335010862

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.444544787101114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.444544787101114 | validation: 9.776508760067369]
	TIME [epoch: 53.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.979357918451429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.979357918451429 | validation: 8.292431745305258]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.787437903581859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.787437903581859 | validation: 7.630256207915171]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.541942068515965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.541942068515965 | validation: 6.305924464231527]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.752265863540675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.752265863540675 | validation: 5.522055512329082]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.073549375287615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.073549375287615 | validation: 5.2310290519678215]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.129695561982546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.129695561982546 | validation: 5.086744553619857]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.596738838849186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.596738838849186 | validation: 4.806111614707476]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.500589165473182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.500589165473182 | validation: 4.763123263157322]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.484174844492325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.484174844492325 | validation: 5.364550049331644]
	TIME [epoch: 8.42 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.491982412644426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.491982412644426 | validation: 4.440357644465553]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.125857713481165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.125857713481165 | validation: 5.217558943372978]
	TIME [epoch: 8.42 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.347912755652128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.347912755652128 | validation: 4.833000808984927]
	TIME [epoch: 8.42 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.089965513988956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.089965513988956 | validation: 5.816180727247174]
	TIME [epoch: 8.42 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.999829528584526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.999829528584526 | validation: 4.964867850314649]
	TIME [epoch: 8.44 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7657476679277906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7657476679277906 | validation: 5.261731213322536]
	TIME [epoch: 8.42 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7269264180146613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7269264180146613 | validation: 4.52900218906355]
	TIME [epoch: 8.41 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.65450352014673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.65450352014673 | validation: 4.9585153761795056]
	TIME [epoch: 8.42 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7352777948788245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7352777948788245 | validation: 4.083786818969736]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5140739911964105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5140739911964105 | validation: 4.286410445879055]
	TIME [epoch: 8.42 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4105232857939947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4105232857939947 | validation: 5.438507913736425]
	TIME [epoch: 8.42 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.623547135718694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.623547135718694 | validation: 4.207228674562034]
	TIME [epoch: 8.42 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.321211741287106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.321211741287106 | validation: 5.450346551834722]
	TIME [epoch: 8.43 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6628650599114843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6628650599114843 | validation: 3.8663589650120684]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1960120996152286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1960120996152286 | validation: 3.7420382214581043]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1992078732054026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1992078732054026 | validation: 4.5751731740860535]
	TIME [epoch: 8.42 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.089111308600679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.089111308600679 | validation: 3.5730781010634525]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2324044334161863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2324044334161863 | validation: 3.8690165155626084]
	TIME [epoch: 8.42 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5178798493054506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5178798493054506 | validation: 3.659733489835296]
	TIME [epoch: 8.41 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0529399312299796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0529399312299796 | validation: 3.937582776005254]
	TIME [epoch: 8.42 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1684854622470113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1684854622470113 | validation: 3.577031068205774]
	TIME [epoch: 8.45 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8790895265384187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8790895265384187 | validation: 3.8127756404587125]
	TIME [epoch: 8.43 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.005774134709714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.005774134709714 | validation: 3.855704834801973]
	TIME [epoch: 8.42 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.91210395711358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.91210395711358 | validation: 5.653558664410468]
	TIME [epoch: 8.42 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.473845619179696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.473845619179696 | validation: 3.603062884025368]
	TIME [epoch: 8.43 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.873357021200536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.873357021200536 | validation: 4.138557657122231]
	TIME [epoch: 8.43 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0695543341297937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0695543341297937 | validation: 3.388568702866621]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7746083782238293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7746083782238293 | validation: 3.4570027166370925]
	TIME [epoch: 8.42 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8513940785796157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8513940785796157 | validation: 3.648370291276361]
	TIME [epoch: 8.42 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3825545067568363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3825545067568363 | validation: 3.7392618560857827]
	TIME [epoch: 8.43 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1466667947601046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1466667947601046 | validation: 3.5652713178204087]
	TIME [epoch: 8.42 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9019659028822886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9019659028822886 | validation: 3.724636708144118]
	TIME [epoch: 8.42 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8449658517387757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8449658517387757 | validation: 3.652966929019952]
	TIME [epoch: 8.42 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0110124021586224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0110124021586224 | validation: 3.6986829292823113]
	TIME [epoch: 8.44 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8245245073800405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8245245073800405 | validation: 4.15161815072371]
	TIME [epoch: 8.42 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.979056117967544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.979056117967544 | validation: 3.890196715987014]
	TIME [epoch: 8.42 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.901723412782548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.901723412782548 | validation: 3.511867950592026]
	TIME [epoch: 8.44 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.855020641093758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.855020641093758 | validation: 3.962116208527505]
	TIME [epoch: 8.45 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.756149646203334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.756149646203334 | validation: 3.7158061055006266]
	TIME [epoch: 8.43 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.91098578436273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.91098578436273 | validation: 3.519286785133642]
	TIME [epoch: 8.42 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1689964460421907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1689964460421907 | validation: 3.9859462364545113]
	TIME [epoch: 8.41 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.738810405062205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.738810405062205 | validation: 3.3612648423724765]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6701648638034126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6701648638034126 | validation: 3.2643008789466297]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6965826145552567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6965826145552567 | validation: 3.474694540045074]
	TIME [epoch: 8.42 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.684808773605939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.684808773605939 | validation: 3.7838867552763786]
	TIME [epoch: 8.42 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.679060524002124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.679060524002124 | validation: 3.423823607409918]
	TIME [epoch: 8.44 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5907492069602878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5907492069602878 | validation: 3.4247625133407036]
	TIME [epoch: 8.43 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7706313002976835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7706313002976835 | validation: 3.5980238916109624]
	TIME [epoch: 8.42 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.696935634393848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.696935634393848 | validation: 3.249034216415585]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.62143614401148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.62143614401148 | validation: 3.6051356412719686]
	TIME [epoch: 8.45 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.580861818035943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.580861818035943 | validation: 3.5877420704031473]
	TIME [epoch: 8.43 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5644169778226265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5644169778226265 | validation: 3.5019004577678805]
	TIME [epoch: 8.43 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.97617504901267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.97617504901267 | validation: 3.2190695487869467]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.482048509300312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.482048509300312 | validation: 3.4368401832062716]
	TIME [epoch: 8.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.610905516602918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.610905516602918 | validation: 3.22756186503318]
	TIME [epoch: 8.44 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.485316968552508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.485316968552508 | validation: 3.328788543383852]
	TIME [epoch: 8.43 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5848001097461486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5848001097461486 | validation: 3.294903294607934]
	TIME [epoch: 8.42 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6255430347457085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6255430347457085 | validation: 3.3165759401559636]
	TIME [epoch: 8.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5676223628689274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5676223628689274 | validation: 3.209066328557941]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5241075893972806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5241075893972806 | validation: 3.3544472826188176]
	TIME [epoch: 8.42 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5377976645994047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5377976645994047 | validation: 3.4788425926649493]
	TIME [epoch: 8.42 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4935128341122086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4935128341122086 | validation: 3.327590381996794]
	TIME [epoch: 8.44 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.459535260411706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.459535260411706 | validation: 3.2335515769459535]
	TIME [epoch: 8.44 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.489454852740524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.489454852740524 | validation: 3.607447571735732]
	TIME [epoch: 8.42 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.627359987222287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.627359987222287 | validation: 3.388138157438908]
	TIME [epoch: 8.43 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.529979579004242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.529979579004242 | validation: 3.344406082418029]
	TIME [epoch: 8.44 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.511660386560766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.511660386560766 | validation: 3.2363515205690843]
	TIME [epoch: 8.44 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4634499239653858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4634499239653858 | validation: 3.496588071930826]
	TIME [epoch: 8.42 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5100794281271073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5100794281271073 | validation: 3.1924142153324935]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.528967670513418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.528967670513418 | validation: 3.3653391002724256]
	TIME [epoch: 8.43 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6271986211423126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6271986211423126 | validation: 3.3174538272701515]
	TIME [epoch: 8.45 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.443805851665143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.443805851665143 | validation: 3.4814903297804367]
	TIME [epoch: 8.43 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.755838771142573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.755838771142573 | validation: 3.164678033970503]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.46523835158716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.46523835158716 | validation: 3.2407985946619435]
	TIME [epoch: 8.43 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5068594360459695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5068594360459695 | validation: 3.298535414109101]
	TIME [epoch: 8.45 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4156991073974874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4156991073974874 | validation: 3.1959733289053895]
	TIME [epoch: 8.43 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3758751321495617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3758751321495617 | validation: 3.489304403513506]
	TIME [epoch: 8.43 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5250471781573935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5250471781573935 | validation: 3.2011870880331843]
	TIME [epoch: 8.43 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.503599122280268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.503599122280268 | validation: 3.7264704931324566]
	TIME [epoch: 8.46 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4673440671703846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4673440671703846 | validation: 3.366186257806047]
	TIME [epoch: 8.44 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4552100725921058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4552100725921058 | validation: 3.7062499328055454]
	TIME [epoch: 8.43 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.530901261666691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.530901261666691 | validation: 3.2349757071834873]
	TIME [epoch: 8.43 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.536716826634317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.536716826634317 | validation: 3.165109527554672]
	TIME [epoch: 8.45 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.609472011848862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.609472011848862 | validation: 3.3027066466635358]
	TIME [epoch: 8.43 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.69820567496737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.69820567496737 | validation: 3.337935278506592]
	TIME [epoch: 8.42 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4690318589985103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4690318589985103 | validation: 3.6456919401895016]
	TIME [epoch: 8.43 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5174625822389913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5174625822389913 | validation: 3.1321611826356937]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4561976323346513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4561976323346513 | validation: 3.1655319283050067]
	TIME [epoch: 8.42 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.459487526756749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.459487526756749 | validation: 3.198754715517191]
	TIME [epoch: 8.42 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.419552508705574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.419552508705574 | validation: 3.236725672412474]
	TIME [epoch: 8.41 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.524728426762895		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 2.524728426762895 | validation: 3.176122634076484]
	TIME [epoch: 8.44 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.452718730220448		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 2.452718730220448 | validation: 3.3518678514714395]
	TIME [epoch: 8.43 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.462522193726712		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 2.462522193726712 | validation: 3.14522145948459]
	TIME [epoch: 8.42 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.417819372211942		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 2.417819372211942 | validation: 3.3640348694782674]
	TIME [epoch: 8.42 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.411354276794563		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 2.411354276794563 | validation: 3.641895452328234]
	TIME [epoch: 8.44 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5020923005876767		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 2.5020923005876767 | validation: 3.159783937280565]
	TIME [epoch: 8.41 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4141849941071145		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 2.4141849941071145 | validation: 3.3303693739487192]
	TIME [epoch: 8.43 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4480700052906608		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 2.4480700052906608 | validation: 3.122397487147639]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.460604307516044		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 2.460604307516044 | validation: 3.148196482260361]
	TIME [epoch: 8.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3837577440043636		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 2.3837577440043636 | validation: 3.1654927262896777]
	TIME [epoch: 8.43 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3891398771035255		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 2.3891398771035255 | validation: 3.2116515628429823]
	TIME [epoch: 8.43 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5495755389744352		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 2.5495755389744352 | validation: 3.226853951822778]
	TIME [epoch: 8.44 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.412853508052561		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 2.412853508052561 | validation: 3.1082876179274628]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4412913648363435		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 2.4412913648363435 | validation: 3.1749211727700253]
	TIME [epoch: 8.44 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.378785173386331		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 2.378785173386331 | validation: 3.3036757482607655]
	TIME [epoch: 8.43 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.394423981330138		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 2.394423981330138 | validation: 3.0606139464391546]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5670336458890715		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 2.5670336458890715 | validation: 3.5297490329850723]
	TIME [epoch: 8.45 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4752662106735372		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 2.4752662106735372 | validation: 3.1679810921418063]
	TIME [epoch: 8.44 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.392695429271865		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 2.392695429271865 | validation: 3.254281774060974]
	TIME [epoch: 8.42 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4121235076197243		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 2.4121235076197243 | validation: 3.353995045047248]
	TIME [epoch: 8.42 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.375106918829274		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 2.375106918829274 | validation: 3.172550035137486]
	TIME [epoch: 8.43 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3489496354765818		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 2.3489496354765818 | validation: 3.5647912486286293]
	TIME [epoch: 8.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.382462218006103		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 2.382462218006103 | validation: 3.3440315130155205]
	TIME [epoch: 8.42 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.432269797581353		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 2.432269797581353 | validation: 3.1520181311638806]
	TIME [epoch: 8.42 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.362480569786192		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 2.362480569786192 | validation: 3.087163983624771]
	TIME [epoch: 8.43 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.323388549416932		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 2.323388549416932 | validation: 3.0745858356853777]
	TIME [epoch: 8.45 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3480436416046766		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 2.3480436416046766 | validation: 3.250623354914818]
	TIME [epoch: 8.43 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.346890570269811		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 2.346890570269811 | validation: 3.025705544715139]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.342955053690256		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 2.342955053690256 | validation: 3.550211244424869]
	TIME [epoch: 8.42 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4178312132337547		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 2.4178312132337547 | validation: 3.0908701845932764]
	TIME [epoch: 8.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.306538885432148		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 2.306538885432148 | validation: 3.0683333866233395]
	TIME [epoch: 8.43 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.308395525440005		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 2.308395525440005 | validation: 3.0375467918716543]
	TIME [epoch: 8.43 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3218404868990863		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 2.3218404868990863 | validation: 3.7286639403535045]
	TIME [epoch: 8.42 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.434393586952867		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 2.434393586952867 | validation: 3.0843989727283265]
	TIME [epoch: 8.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3705634705466396		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 2.3705634705466396 | validation: 3.1041754800945935]
	TIME [epoch: 8.42 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3646559606529465		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 2.3646559606529465 | validation: 3.0805353830761453]
	TIME [epoch: 8.41 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.351594649487514		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 2.351594649487514 | validation: 3.107759137829154]
	TIME [epoch: 8.42 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3618062896988996		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 2.3618062896988996 | validation: 3.0287024134525455]
	TIME [epoch: 8.45 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3285953438301594		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 2.3285953438301594 | validation: 3.111312124025277]
	TIME [epoch: 8.42 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3070579255451964		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 2.3070579255451964 | validation: 3.379497361636276]
	TIME [epoch: 8.42 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3529948513054904		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 2.3529948513054904 | validation: 3.0885364178077337]
	TIME [epoch: 8.42 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.427997802890011		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 2.427997802890011 | validation: 3.2400581870786382]
	TIME [epoch: 8.45 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3878226546506696		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 2.3878226546506696 | validation: 3.09661723003771]
	TIME [epoch: 8.43 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2448278995669706		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 2.2448278995669706 | validation: 3.156897418975444]
	TIME [epoch: 8.43 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3429050764221127		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 2.3429050764221127 | validation: 3.1867116551136374]
	TIME [epoch: 8.42 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3425168622755055		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 2.3425168622755055 | validation: 3.4119887671123217]
	TIME [epoch: 8.45 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3676556769340156		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 2.3676556769340156 | validation: 3.2775074834924824]
	TIME [epoch: 8.43 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3709256076692653		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 2.3709256076692653 | validation: 3.128623813685376]
	TIME [epoch: 8.42 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.282771486570174		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 2.282771486570174 | validation: 3.0439803913411554]
	TIME [epoch: 8.42 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4952281632764874		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 2.4952281632764874 | validation: 3.20097230727988]
	TIME [epoch: 8.42 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2439880513285018		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 2.2439880513285018 | validation: 3.0844657523342613]
	TIME [epoch: 8.44 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3285214428520797		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 2.3285214428520797 | validation: 2.9931670683586757]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2390556763874203		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 2.2390556763874203 | validation: 3.0984746397353975]
	TIME [epoch: 8.42 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2564407035403535		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 2.2564407035403535 | validation: 3.0506435918461516]
	TIME [epoch: 8.42 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.245957277970594		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 2.245957277970594 | validation: 3.0882256181421956]
	TIME [epoch: 8.45 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3642178584601927		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 2.3642178584601927 | validation: 3.1111767171088287]
	TIME [epoch: 8.43 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.285862804492631		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 2.285862804492631 | validation: 3.1311125097271324]
	TIME [epoch: 8.43 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3541438660259635		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 2.3541438660259635 | validation: 3.079201133254449]
	TIME [epoch: 8.43 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2539395954898658		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 2.2539395954898658 | validation: 3.1336958748267087]
	TIME [epoch: 8.45 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.258882404689099		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 2.258882404689099 | validation: 3.1395151197139857]
	TIME [epoch: 8.43 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3053509966051715		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 2.3053509966051715 | validation: 3.4450783969145586]
	TIME [epoch: 8.42 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3332192352212284		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 2.3332192352212284 | validation: 3.122671371165122]
	TIME [epoch: 8.42 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2154030566321503		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 2.2154030566321503 | validation: 2.990801428888231]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2519308010920946		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 2.2519308010920946 | validation: 3.1421087770752893]
	TIME [epoch: 8.44 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.319204019885985		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 2.319204019885985 | validation: 3.0841321798036816]
	TIME [epoch: 8.43 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.209885791642075		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 2.209885791642075 | validation: 3.0027296689916194]
	TIME [epoch: 8.42 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2791148962291587		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 2.2791148962291587 | validation: 3.2827633769184232]
	TIME [epoch: 8.45 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2695067983383517		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 2.2695067983383517 | validation: 2.9724901433179935]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2930544704797624		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 2.2930544704797624 | validation: 2.985482240292074]
	TIME [epoch: 8.43 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1785367898393333		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 2.1785367898393333 | validation: 3.0962020015039275]
	TIME [epoch: 8.42 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.235972077851747		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 2.235972077851747 | validation: 3.0914987963879823]
	TIME [epoch: 8.45 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3673135259689095		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 2.3673135259689095 | validation: 3.06482243666646]
	TIME [epoch: 8.43 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3022173685394636		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 2.3022173685394636 | validation: 3.222027228572361]
	TIME [epoch: 8.42 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.226042994365578		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 2.226042994365578 | validation: 3.020210229238013]
	TIME [epoch: 8.44 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2147870347029404		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 2.2147870347029404 | validation: 2.9992979872198813]
	TIME [epoch: 8.45 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.283772596060724		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 2.283772596060724 | validation: 3.153726336909743]
	TIME [epoch: 8.43 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.28297306031398		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 2.28297306031398 | validation: 3.050804517614755]
	TIME [epoch: 8.42 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.238996856759216		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 2.238996856759216 | validation: 3.2086202674089472]
	TIME [epoch: 8.43 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2315791683294197		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 2.2315791683294197 | validation: 2.9380157416449166]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2204788618224955		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 2.2204788618224955 | validation: 3.0817215523027457]
	TIME [epoch: 8.43 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.365546490598109		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 2.365546490598109 | validation: 3.1024235814182126]
	TIME [epoch: 8.43 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2281431768917956		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 2.2281431768917956 | validation: 3.2606444988209122]
	TIME [epoch: 8.43 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.209303025925428		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 2.209303025925428 | validation: 2.9885750193189953]
	TIME [epoch: 8.45 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2622564425227143		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 2.2622564425227143 | validation: 2.984547522835265]
	TIME [epoch: 8.44 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2741627682326127		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 2.2741627682326127 | validation: 3.1698385715856494]
	TIME [epoch: 8.42 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2802036808146107		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 2.2802036808146107 | validation: 2.967725751939866]
	TIME [epoch: 8.43 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.236390309162707		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 2.236390309162707 | validation: 2.963349325904085]
	TIME [epoch: 8.43 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2720680154892694		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 2.2720680154892694 | validation: 3.0517064094800634]
	TIME [epoch: 8.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.302080677855296		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 2.302080677855296 | validation: 3.048081081148963]
	TIME [epoch: 8.43 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2547646323011494		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 2.2547646323011494 | validation: 3.1007704751719776]
	TIME [epoch: 8.43 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.279805126506066		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 2.279805126506066 | validation: 3.044736315043762]
	TIME [epoch: 8.43 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.305273878607427		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 2.305273878607427 | validation: 3.1007338405142173]
	TIME [epoch: 8.45 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.332463811074188		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 2.332463811074188 | validation: 3.1925760850845704]
	TIME [epoch: 8.43 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.205518747441892		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 2.205518747441892 | validation: 3.2249655361835377]
	TIME [epoch: 8.43 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2761842785254576		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 2.2761842785254576 | validation: 3.0350661789194877]
	TIME [epoch: 8.43 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1829776333728157		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 2.1829776333728157 | validation: 3.012038376038645]
	TIME [epoch: 8.44 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.217244884336533		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 2.217244884336533 | validation: 2.977730719997017]
	TIME [epoch: 8.42 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2164984078006906		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 2.2164984078006906 | validation: 3.208974778285273]
	TIME [epoch: 8.42 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2216635625865537		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 2.2216635625865537 | validation: 3.0128392090567315]
	TIME [epoch: 8.42 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.213923974245163		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 2.213923974245163 | validation: 3.074673769320985]
	TIME [epoch: 8.45 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.22276692750445		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 2.22276692750445 | validation: 3.013325891790346]
	TIME [epoch: 8.43 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1873672773633865		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 2.1873672773633865 | validation: 3.0935839693090017]
	TIME [epoch: 8.42 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2778972595169016		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 2.2778972595169016 | validation: 3.0323045934415926]
	TIME [epoch: 8.42 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2445085806251868		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 2.2445085806251868 | validation: 2.9677952736801476]
	TIME [epoch: 8.45 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2138379703777966		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 2.2138379703777966 | validation: 3.0699987430899167]
	TIME [epoch: 8.42 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.237463800408052		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 2.237463800408052 | validation: 2.934335568051365]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1960025892772377		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 2.1960025892772377 | validation: 3.0133693548529727]
	TIME [epoch: 8.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1796696040431316		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 2.1796696040431316 | validation: 2.935277286992248]
	TIME [epoch: 8.44 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1687412962250074		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 2.1687412962250074 | validation: 2.945072493582006]
	TIME [epoch: 8.43 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2450818999961015		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 2.2450818999961015 | validation: 3.0407952531391915]
	TIME [epoch: 8.42 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.263981404829271		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 2.263981404829271 | validation: 3.1413172515906505]
	TIME [epoch: 8.42 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2603903333683464		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 2.2603903333683464 | validation: 2.9451350673387138]
	TIME [epoch: 8.45 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2490797177272115		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 2.2490797177272115 | validation: 3.1728861255033465]
	TIME [epoch: 8.43 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2809027257008454		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 2.2809027257008454 | validation: 3.025773946088188]
	TIME [epoch: 8.42 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1786326798314675		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 2.1786326798314675 | validation: 3.0844335089180817]
	TIME [epoch: 8.42 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1849043610321557		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 2.1849043610321557 | validation: 2.909732355976689]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1171266323523894		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 2.1171266323523894 | validation: 2.929819411006296]
	TIME [epoch: 8.44 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.158743792549108		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 2.158743792549108 | validation: 2.9787971963425393]
	TIME [epoch: 8.43 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.200485817176567		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 2.200485817176567 | validation: 2.98969953352231]
	TIME [epoch: 8.42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.173739329444752		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 2.173739329444752 | validation: 3.102972947943118]
	TIME [epoch: 8.43 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.19300537261194		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 2.19300537261194 | validation: 3.1231197736140874]
	TIME [epoch: 8.44 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2102544760952303		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 2.2102544760952303 | validation: 3.0233570854096206]
	TIME [epoch: 8.43 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.217016053408392		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 2.217016053408392 | validation: 3.0532908945388204]
	TIME [epoch: 8.43 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1498897721686006		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 2.1498897721686006 | validation: 2.926805090173696]
	TIME [epoch: 8.43 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1653784381307233		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 2.1653784381307233 | validation: 3.0836067293473404]
	TIME [epoch: 8.44 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.231124091147426		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 2.231124091147426 | validation: 3.268006646432319]
	TIME [epoch: 8.43 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1804056060075867		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 2.1804056060075867 | validation: 2.9505235846055635]
	TIME [epoch: 8.43 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2227852687069616		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 2.2227852687069616 | validation: 3.0277345287700155]
	TIME [epoch: 8.43 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.219961118229012		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 2.219961118229012 | validation: 3.2551617191032864]
	TIME [epoch: 8.45 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.229855797341438		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 2.229855797341438 | validation: 2.923429563957372]
	TIME [epoch: 8.42 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.221541677682841		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 2.221541677682841 | validation: 3.027586828255112]
	TIME [epoch: 8.43 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1601717422475577		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 2.1601717422475577 | validation: 3.0231090340645923]
	TIME [epoch: 8.43 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1985870825928346		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 2.1985870825928346 | validation: 3.004276555037274]
	TIME [epoch: 8.45 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1333567073079864		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 2.1333567073079864 | validation: 2.993201428360358]
	TIME [epoch: 8.43 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1636467398316475		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 2.1636467398316475 | validation: 2.9474810347395834]
	TIME [epoch: 8.43 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7679469718935787		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 2.7679469718935787 | validation: 3.1899281790048803]
	TIME [epoch: 8.43 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.568382533376208		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 3.568382533376208 | validation: 3.5182362883192573]
	TIME [epoch: 8.46 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.7443157296075054		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 2.7443157296075054 | validation: 3.076245634621128]
	TIME [epoch: 8.44 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.16536668952031		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 2.16536668952031 | validation: 2.982459088070243]
	TIME [epoch: 8.43 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.130706078599718		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 2.130706078599718 | validation: 3.305678817086833]
	TIME [epoch: 8.44 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.487825762969872		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 2.487825762969872 | validation: 3.0353855816999094]
	TIME [epoch: 8.44 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1432663420125593		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 2.1432663420125593 | validation: 2.9329686034698996]
	TIME [epoch: 8.43 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1435947193927984		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 2.1435947193927984 | validation: 2.9220261135981107]
	TIME [epoch: 8.44 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1221875405012574		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 2.1221875405012574 | validation: 2.924325697941916]
	TIME [epoch: 8.42 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5994022830320067		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 2.5994022830320067 | validation: 2.995252840061773]
	TIME [epoch: 8.44 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.294811485430868		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 2.294811485430868 | validation: 3.116405255675269]
	TIME [epoch: 8.42 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1638912792674896		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 2.1638912792674896 | validation: 2.93175741878131]
	TIME [epoch: 8.42 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.279988937434619		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 2.279988937434619 | validation: 2.974889279496163]
	TIME [epoch: 8.42 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1198887391687444		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 2.1198887391687444 | validation: 3.058941221150576]
	TIME [epoch: 8.45 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1737344383001673		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 2.1737344383001673 | validation: 3.030636888029328]
	TIME [epoch: 8.44 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1339475604749127		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 2.1339475604749127 | validation: 3.0556538872270567]
	TIME [epoch: 8.43 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1608145478527225		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 2.1608145478527225 | validation: 3.139020981370783]
	TIME [epoch: 8.43 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.128746428608589		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 2.128746428608589 | validation: 2.995058341490296]
	TIME [epoch: 8.43 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.190391111081703		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 2.190391111081703 | validation: 3.0194485644406224]
	TIME [epoch: 8.45 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.151946565438524		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 2.151946565438524 | validation: 2.9530646635244504]
	TIME [epoch: 8.43 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.149445662285043		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 2.149445662285043 | validation: 3.0157587050741417]
	TIME [epoch: 8.42 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2703713255232785		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 2.2703713255232785 | validation: 3.072744329775051]
	TIME [epoch: 8.43 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.124373896353507		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 2.124373896353507 | validation: 2.9716940073039737]
	TIME [epoch: 8.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.386089188773545		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 2.386089188773545 | validation: 3.0439982229476374]
	TIME [epoch: 8.43 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.145091187042541		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 2.145091187042541 | validation: 2.9844739196679884]
	TIME [epoch: 8.44 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1091297588527853		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 2.1091297588527853 | validation: 2.940042666715682]
	TIME [epoch: 8.43 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1408167295091536		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 2.1408167295091536 | validation: 3.0780005519321834]
	TIME [epoch: 8.46 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.178596267864367		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 2.178596267864367 | validation: 2.99687702073384]
	TIME [epoch: 8.43 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1299541251939695		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 2.1299541251939695 | validation: 3.036578594605733]
	TIME [epoch: 8.44 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1893468532703144		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 2.1893468532703144 | validation: 3.0336215324934726]
	TIME [epoch: 8.43 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.195221995540733		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 2.195221995540733 | validation: 2.8824208098174537]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1495193991730113		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 2.1495193991730113 | validation: 2.9145528709409696]
	TIME [epoch: 8.43 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9659314055767974		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 2.9659314055767974 | validation: 2.8674872027704015]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.332004937040318		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 2.332004937040318 | validation: 3.0267942452437997]
	TIME [epoch: 8.43 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.211133245044957		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 2.211133245044957 | validation: 3.0316048941501794]
	TIME [epoch: 8.46 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2392547062181194		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 2.2392547062181194 | validation: 3.0401447796255034]
	TIME [epoch: 8.44 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.181751642688519		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 2.181751642688519 | validation: 2.910079336609054]
	TIME [epoch: 8.44 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1879294487878975		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 2.1879294487878975 | validation: 2.935108304520327]
	TIME [epoch: 8.44 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1361652211234787		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 2.1361652211234787 | validation: 2.9402679877392117]
	TIME [epoch: 8.45 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2104428458268095		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 2.2104428458268095 | validation: 2.974997354522081]
	TIME [epoch: 8.44 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.113247324658205		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 2.113247324658205 | validation: 2.887632500267296]
	TIME [epoch: 8.43 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.132932058404835		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 2.132932058404835 | validation: 2.9339407506716286]
	TIME [epoch: 8.43 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1252302811557358		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 2.1252302811557358 | validation: 2.9845340822224284]
	TIME [epoch: 8.45 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2143070932905204		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 2.2143070932905204 | validation: 3.0098503690856857]
	TIME [epoch: 8.44 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.330883916523759		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 2.330883916523759 | validation: 3.0195452270461747]
	TIME [epoch: 8.43 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6367225512343873		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 2.6367225512343873 | validation: 6.065170135307019]
	TIME [epoch: 8.43 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.615752681015666		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 2.615752681015666 | validation: 2.978780539357089]
	TIME [epoch: 8.44 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.151480548676025		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 2.151480548676025 | validation: 3.015077518857148]
	TIME [epoch: 8.44 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3456889008908117		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 2.3456889008908117 | validation: 2.9862600521863576]
	TIME [epoch: 8.44 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.159285331003743		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 2.159285331003743 | validation: 3.136689280963429]
	TIME [epoch: 8.43 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.183736122186054		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 2.183736122186054 | validation: 2.9801505141579385]
	TIME [epoch: 8.44 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2614330205106277		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 2.2614330205106277 | validation: 3.0298264687750844]
	TIME [epoch: 8.45 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2585077197665546		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 2.2585077197665546 | validation: 2.953116863720667]
	TIME [epoch: 8.44 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.165251346216416		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 2.165251346216416 | validation: 3.0621961435067795]
	TIME [epoch: 8.44 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1496404622982093		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 2.1496404622982093 | validation: 3.168993244517214]
	TIME [epoch: 8.43 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1693662971863668		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 2.1693662971863668 | validation: 3.016371308098827]
	TIME [epoch: 8.46 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6451110252701087		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 2.6451110252701087 | validation: 2.9136943237239437]
	TIME [epoch: 8.43 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1875711545321344		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 2.1875711545321344 | validation: 2.904709866464369]
	TIME [epoch: 8.44 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0975572851220936		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 2.0975572851220936 | validation: 3.799682725849072]
	TIME [epoch: 8.43 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4133679992591577		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 2.4133679992591577 | validation: 2.98077283260384]
	TIME [epoch: 8.45 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.20809153310035		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 2.20809153310035 | validation: 2.951442716880904]
	TIME [epoch: 8.43 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2014412123724947		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 2.2014412123724947 | validation: 3.0818556710665757]
	TIME [epoch: 8.42 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2311137331321236		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 2.2311137331321236 | validation: 2.9406625504233737]
	TIME [epoch: 8.43 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5864499926640456		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 2.5864499926640456 | validation: 3.256369232971375]
	TIME [epoch: 8.45 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.242911983108051		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 2.242911983108051 | validation: 3.03029627062472]
	TIME [epoch: 8.43 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.149485146718881		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 2.149485146718881 | validation: 2.9220208314845006]
	TIME [epoch: 8.42 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.148414618985741		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 2.148414618985741 | validation: 2.969220410038223]
	TIME [epoch: 8.42 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.215616352181565		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 2.215616352181565 | validation: 2.9311308835480436]
	TIME [epoch: 8.44 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2710046682663174		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 2.2710046682663174 | validation: 2.971791469957069]
	TIME [epoch: 8.43 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1948772235648084		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 2.1948772235648084 | validation: 3.1439308193798468]
	TIME [epoch: 8.42 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.204358899426848		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 2.204358899426848 | validation: 3.102935530252511]
	TIME [epoch: 8.43 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.21551756681935		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 2.21551756681935 | validation: 2.9579591837316723]
	TIME [epoch: 8.45 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3550405491745487		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 2.3550405491745487 | validation: 2.9428986983235155]
	TIME [epoch: 8.44 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1921982935403634		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 2.1921982935403634 | validation: 3.004539648621286]
	TIME [epoch: 8.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3097681951304394		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 2.3097681951304394 | validation: 3.1660184971426384]
	TIME [epoch: 8.42 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.139104307069189		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 2.139104307069189 | validation: 2.9433738821547033]
	TIME [epoch: 8.44 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1434491882650075		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 2.1434491882650075 | validation: 2.8742205402783374]
	TIME [epoch: 8.43 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.203414448808983		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 2.203414448808983 | validation: 2.9418629747238807]
	TIME [epoch: 8.42 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3844349473659014		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 2.3844349473659014 | validation: 3.0367525479828474]
	TIME [epoch: 8.43 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2401767150181775		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 2.2401767150181775 | validation: 3.035988119441563]
	TIME [epoch: 8.44 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.228728749563407		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 2.228728749563407 | validation: 2.994349797130522]
	TIME [epoch: 8.44 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.179739106838089		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 2.179739106838089 | validation: 2.9493639333138137]
	TIME [epoch: 8.43 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2009826150215286		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 2.2009826150215286 | validation: 3.077518435926632]
	TIME [epoch: 8.42 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2811963457421927		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 2.2811963457421927 | validation: 2.979298432312711]
	TIME [epoch: 8.43 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.226917729008136		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 2.226917729008136 | validation: 3.1199046875131886]
	TIME [epoch: 8.44 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2594259092303273		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 2.2594259092303273 | validation: 3.093649958359266]
	TIME [epoch: 8.43 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.186418023054528		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 2.186418023054528 | validation: 2.9872089872470378]
	TIME [epoch: 8.42 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1798662147648633		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 2.1798662147648633 | validation: 2.962419356536013]
	TIME [epoch: 8.44 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2228573841638744		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 2.2228573841638744 | validation: 3.0581105956169985]
	TIME [epoch: 8.46 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.201740079542		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 2.201740079542 | validation: 3.051777383105513]
	TIME [epoch: 8.43 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.372380305110051		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 2.372380305110051 | validation: 3.106199688814443]
	TIME [epoch: 8.43 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2399371468886584		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 2.2399371468886584 | validation: 2.9465941951338035]
	TIME [epoch: 8.44 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.421756347285188		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 2.421756347285188 | validation: 3.839002952374549]
	TIME [epoch: 8.45 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.281513769260158		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 2.281513769260158 | validation: 3.2786899234153637]
	TIME [epoch: 8.44 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.270459498026799		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 2.270459498026799 | validation: 2.976387008279289]
	TIME [epoch: 8.43 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.239179123648449		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 2.239179123648449 | validation: 2.9750205239537313]
	TIME [epoch: 8.43 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1994841419728166		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 2.1994841419728166 | validation: 2.9639901142393112]
	TIME [epoch: 8.46 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.13196100775201		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 2.13196100775201 | validation: 2.972271179878901]
	TIME [epoch: 8.44 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2219284520322686		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 2.2219284520322686 | validation: 3.136947995476886]
	TIME [epoch: 8.42 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2546556746666773		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 2.2546556746666773 | validation: 2.9737213615195204]
	TIME [epoch: 8.43 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.192740450943774		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 2.192740450943774 | validation: 2.9135941400320515]
	TIME [epoch: 8.45 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.4675398989553923		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 2.4675398989553923 | validation: 3.000410794045206]
	TIME [epoch: 8.44 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1911625195362685		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 2.1911625195362685 | validation: 2.9899329157447774]
	TIME [epoch: 8.43 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.192036417842975		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 2.192036417842975 | validation: 2.9606372812936605]
	TIME [epoch: 8.43 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.200041804429785		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 2.200041804429785 | validation: 2.9491244009525257]
	TIME [epoch: 8.45 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2897081982012084		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 2.2897081982012084 | validation: 2.959283917887267]
	TIME [epoch: 8.43 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2625826958479758		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 2.2625826958479758 | validation: 3.2521768747466675]
	TIME [epoch: 8.43 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.273840941713478		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 2.273840941713478 | validation: 3.0086327259116525]
	TIME [epoch: 8.42 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1880429304139843		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 2.1880429304139843 | validation: 3.183391765859616]
	TIME [epoch: 8.44 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.388320655826559		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 2.388320655826559 | validation: 5.510329563787478]
	TIME [epoch: 8.44 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0900510817497464		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 3.0900510817497464 | validation: 2.987813488154604]
	TIME [epoch: 8.43 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3611411948110392		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 2.3611411948110392 | validation: 3.0048700224219878]
	TIME [epoch: 8.43 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1905689967958777		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 2.1905689967958777 | validation: 2.9652387338618253]
	TIME [epoch: 8.43 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.239573998536092		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 3.239573998536092 | validation: 3.058613537705765]
	TIME [epoch: 8.45 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9606241936400157		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 2.9606241936400157 | validation: 2.989841541563419]
	TIME [epoch: 8.43 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2440186394388446		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 2.2440186394388446 | validation: 2.9911161532599344]
	TIME [epoch: 8.42 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2197630323487645		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 2.2197630323487645 | validation: 3.014248058088995]
	TIME [epoch: 8.43 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.224197154045489		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 2.224197154045489 | validation: 3.2690385187773314]
	TIME [epoch: 8.45 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.3040013526251175		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 2.3040013526251175 | validation: 2.9927045243067427]
	TIME [epoch: 8.43 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1298224019745953		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 2.1298224019745953 | validation: 2.957096541932874]
	TIME [epoch: 8.42 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.284187885654889		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 2.284187885654889 | validation: 2.9551988377416967]
	TIME [epoch: 8.43 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.203651396922209		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 2.203651396922209 | validation: 2.9378003094451]
	TIME [epoch: 8.44 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.412282425439621		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 2.412282425439621 | validation: 2.974347346773098]
	TIME [epoch: 8.43 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.321608324763779		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 2.321608324763779 | validation: 3.006123986657041]
	TIME [epoch: 8.42 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1122199917889026		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 2.1122199917889026 | validation: 2.983090413768708]
	TIME [epoch: 8.42 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2165597324079083		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 2.2165597324079083 | validation: 3.0912358914943905]
	TIME [epoch: 8.44 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.187867983639086		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 2.187867983639086 | validation: 2.987533991507184]
	TIME [epoch: 8.42 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1712618871454317		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 2.1712618871454317 | validation: 3.118068514151343]
	TIME [epoch: 8.41 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.232852325325959		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 2.232852325325959 | validation: 3.495582603278482]
	TIME [epoch: 8.41 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2548368522512816		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 2.2548368522512816 | validation: 2.9562775835375747]
	TIME [epoch: 8.44 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.197969183884669		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 2.197969183884669 | validation: 3.0183824393938403]
	TIME [epoch: 8.41 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2990727764288925		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 2.2990727764288925 | validation: 3.2049079423568445]
	TIME [epoch: 8.42 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.2799391758742305		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 2.2799391758742305 | validation: 3.0056796280448697]
	TIME [epoch: 8.42 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5731772424967283		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 2.5731772424967283 | validation: 2.9815428103015456]
	TIME [epoch: 8.44 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.529805301637672		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 2.529805301637672 | validation: 2.9188721213587607]
	TIME [epoch: 8.42 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.511520533646935		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 2.511520533646935 | validation: 2.9861009018740794]
	TIME [epoch: 8.43 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.8864809981000277		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 2.8864809981000277 | validation: 5.812412671164344]
	TIME [epoch: 8.42 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.0786539480132564		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 3.0786539480132564 | validation: 3.6779277968667285]
	TIME [epoch: 8.44 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.661624424704777		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 2.661624424704777 | validation: 4.3693295348022385]
	TIME [epoch: 8.43 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.5527774756660526		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 2.5527774756660526 | validation: 2.9781911157458945]
	TIME [epoch: 8.42 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0806305841824226		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 2.0806305841824226 | validation: 2.676575184165316]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.848009913625313		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 1.848009913625313 | validation: 2.3533702814065594]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.769302228782817		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 1.769302228782817 | validation: 2.2345201989038417]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.720523252514504		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 1.720523252514504 | validation: 2.0819624079614405]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6207967687545324		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 1.6207967687545324 | validation: 1.9501173828333598]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.437233535365494		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 2.437233535365494 | validation: 3.2047856613012913]
	TIME [epoch: 8.45 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1974169572884668		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 2.1974169572884668 | validation: 1.9525594328857974]
	TIME [epoch: 8.43 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6158449554849263		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 1.6158449554849263 | validation: 1.934228472623754]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5357864960788883		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 1.5357864960788883 | validation: 1.7350685332238611]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.00957857527006		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 3.00957857527006 | validation: 2.2108257672473837]
	TIME [epoch: 8.45 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5949315364631935		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 1.5949315364631935 | validation: 1.735823720746947]
	TIME [epoch: 8.42 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.452507728730407		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 1.452507728730407 | validation: 1.8884616403065877]
	TIME [epoch: 8.43 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3809559482774165		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 1.3809559482774165 | validation: 1.5747066335741042]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5602359168596127		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 1.5602359168596127 | validation: 1.8685848658121138]
	TIME [epoch: 8.44 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.4021531974586892		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 1.4021531974586892 | validation: 1.7088591126002588]
	TIME [epoch: 8.44 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3343766716359642		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 1.3343766716359642 | validation: 1.7106168616133361]
	TIME [epoch: 8.43 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3043607732631846		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 1.3043607732631846 | validation: 1.5081885124222238]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3030674586548583		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 1.3030674586548583 | validation: 1.6730132467783978]
	TIME [epoch: 8.44 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.6961573341573213		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 1.6961573341573213 | validation: 1.5602095583466462]
	TIME [epoch: 8.44 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.296574146273234		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 1.296574146273234 | validation: 1.6413760219878832]
	TIME [epoch: 8.43 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3690095794980894		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 1.3690095794980894 | validation: 1.5720528223964552]
	TIME [epoch: 8.44 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.35315879830641		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 1.35315879830641 | validation: 1.384688902591698]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.249379269790121		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 1.249379269790121 | validation: 1.478190375588468]
	TIME [epoch: 8.45 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3168890217529765		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 1.3168890217529765 | validation: 1.4337228820888643]
	TIME [epoch: 8.42 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2917781886332511		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 1.2917781886332511 | validation: 1.3693859301130744]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2774738809257722		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 1.2774738809257722 | validation: 1.8443372246706702]
	TIME [epoch: 8.42 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3113449480722204		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 1.3113449480722204 | validation: 1.5045497964530168]
	TIME [epoch: 8.44 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3179955536376284		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 1.3179955536376284 | validation: 1.6360088844386569]
	TIME [epoch: 8.42 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3316535815692578		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 1.3316535815692578 | validation: 1.3997133378199156]
	TIME [epoch: 8.42 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2391823398039754		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 1.2391823398039754 | validation: 1.5100053146115984]
	TIME [epoch: 8.42 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.75992740430353		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 8.75992740430353 | validation: 10.670189187841999]
	TIME [epoch: 8.44 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.011973895910984		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 11.011973895910984 | validation: 11.074521439791141]
	TIME [epoch: 8.41 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.243713443740564		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 11.243713443740564 | validation: 11.068424467888523]
	TIME [epoch: 8.41 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 11.193864773830095		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 11.193864773830095 | validation: 11.374037495024126]
	TIME [epoch: 8.41 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.37200304976857		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 10.37200304976857 | validation: 8.414683094063445]
	TIME [epoch: 8.43 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 8.908859463217341		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 8.908859463217341 | validation: 10.1741007914284]
	TIME [epoch: 8.42 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 7.057964592209942		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 7.057964592209942 | validation: 2.894015672974048]
	TIME [epoch: 8.42 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.583078701683879		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 1.583078701683879 | validation: 1.4481153453751787]
	TIME [epoch: 8.42 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3499200758500531		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 1.3499200758500531 | validation: 1.4672347916963935]
	TIME [epoch: 8.44 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2764690837950479		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 1.2764690837950479 | validation: 1.5336548061937385]
	TIME [epoch: 8.42 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2557513880716706		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 1.2557513880716706 | validation: 1.5382494498081405]
	TIME [epoch: 8.42 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2384277653806117		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 1.2384277653806117 | validation: 1.3542730187448677]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.251450727824286		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 1.251450727824286 | validation: 1.6008350570256642]
	TIME [epoch: 8.44 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.255212809440352		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 1.255212809440352 | validation: 1.5353635597522308]
	TIME [epoch: 8.42 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2428336367097477		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 1.2428336367097477 | validation: 1.2629175124364667]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1965482839228738		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 1.1965482839228738 | validation: 1.266658624995564]
	TIME [epoch: 8.44 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2482253253761462		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 1.2482253253761462 | validation: 1.37916187606793]
	TIME [epoch: 8.42 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2185338982110374		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 1.2185338982110374 | validation: 1.5641608007620866]
	TIME [epoch: 8.42 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2849494143580737		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 1.2849494143580737 | validation: 1.5876273598473225]
	TIME [epoch: 8.42 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.206379080397826		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 1.206379080397826 | validation: 1.3125655533218743]
	TIME [epoch: 8.44 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.20960268373293		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 1.20960268373293 | validation: 1.3127461912894742]
	TIME [epoch: 8.42 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.193867095897154		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 1.193867095897154 | validation: 1.2984649850029784]
	TIME [epoch: 8.42 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1812254372578157		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 1.1812254372578157 | validation: 1.4682575265974873]
	TIME [epoch: 8.42 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1989421424988431		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 1.1989421424988431 | validation: 1.184006006593746]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_429.pth
	Model improved!!!
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.137572836197235		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 1.137572836197235 | validation: 1.204712460351402]
	TIME [epoch: 8.43 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.3228318551503095		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 1.3228318551503095 | validation: 1.2656346295835652]
	TIME [epoch: 8.42 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1320605087974938		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 1.1320605087974938 | validation: 1.1785675760124779]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1502187349264237		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 1.1502187349264237 | validation: 1.2047630708580512]
	TIME [epoch: 8.45 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2060883635748822		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 1.2060883635748822 | validation: 1.1173944949509855]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.095981948167332		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 1.095981948167332 | validation: 1.020528799984115]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0634216305367385		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 1.0634216305367385 | validation: 0.975039160151889]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0761925885116777		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 1.0761925885116777 | validation: 1.0532733458562076]
	TIME [epoch: 8.45 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2442484848226383		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 1.2442484848226383 | validation: 1.395336358322548]
	TIME [epoch: 8.43 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.1393382846825937		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 1.1393382846825937 | validation: 0.9345782709294675]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0707184480141723		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 1.0707184480141723 | validation: 1.0001758747849847]
	TIME [epoch: 8.44 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0814609164868043		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 1.0814609164868043 | validation: 1.0351462867156078]
	TIME [epoch: 8.45 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0253117421501334		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 1.0253117421501334 | validation: 0.8977467938513723]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.005459245882204		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 1.005459245882204 | validation: 0.8093014591537939]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9403867426017267		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.9403867426017267 | validation: 1.0846067890385758]
	TIME [epoch: 8.44 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9687452101883494		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.9687452101883494 | validation: 0.8191077052119125]
	TIME [epoch: 8.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.979170970030928		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.979170970030928 | validation: 0.7022002527237929]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2984646487709806		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 1.2984646487709806 | validation: 1.3064514869966461]
	TIME [epoch: 8.44 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.188948669505463		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 1.188948669505463 | validation: 0.6997648114483539]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7961836062372926		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.7961836062372926 | validation: 0.7975940888212204]
	TIME [epoch: 8.43 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7679607817125795		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.7679607817125795 | validation: 0.5918089683490406]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7045549579342637		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.7045549579342637 | validation: 0.7214604011588974]
	TIME [epoch: 8.42 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.270177496023522		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 1.270177496023522 | validation: 1.842792450452789]
	TIME [epoch: 8.45 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6358592145088986		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 2.6358592145088986 | validation: 2.674708223497306]
	TIME [epoch: 8.43 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.525945451355326		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 2.525945451355326 | validation: 2.6442251140323227]
	TIME [epoch: 8.43 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1586635279125312		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 3.1586635279125312 | validation: 3.5501926008510045]
	TIME [epoch: 8.43 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.690525972012997		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 4.690525972012997 | validation: 5.786498502897734]
	TIME [epoch: 8.44 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.6046986246353985		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 5.6046986246353985 | validation: 5.129052803160478]
	TIME [epoch: 8.43 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.225924925262939		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 5.225924925262939 | validation: 4.693384699181486]
	TIME [epoch: 8.42 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.625472003500434		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 2.625472003500434 | validation: 1.0370954087981794]
	TIME [epoch: 8.42 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0779219376863207		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 1.0779219376863207 | validation: 0.8055093250451941]
	TIME [epoch: 8.44 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8978735192943412		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.8978735192943412 | validation: 0.7238066720492026]
	TIME [epoch: 8.43 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.74018290175966		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.74018290175966 | validation: 0.7130255601048604]
	TIME [epoch: 8.43 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.687740707742524		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.687740707742524 | validation: 0.5983388827156928]
	TIME [epoch: 8.42 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.662523540649576		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.662523540649576 | validation: 0.607580103510474]
	TIME [epoch: 8.44 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6681474091935025		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.6681474091935025 | validation: 0.5106735187427014]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5788790855250536		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.5788790855250536 | validation: 0.5508900585735592]
	TIME [epoch: 8.42 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5876306305635615		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.5876306305635615 | validation: 0.48963238288259536]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.627054753252325		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.627054753252325 | validation: 0.5578481213707653]
	TIME [epoch: 8.44 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6135837444765226		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.6135837444765226 | validation: 0.5844686396954755]
	TIME [epoch: 8.43 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5931167225997052		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.5931167225997052 | validation: 0.480933293421501]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5427368630685987		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.5427368630685987 | validation: 0.5058643186297187]
	TIME [epoch: 8.46 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.051577696797		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 1.051577696797 | validation: 3.0250522187879807]
	TIME [epoch: 8.44 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4791761088123883		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 3.4791761088123883 | validation: 3.3617070623396677]
	TIME [epoch: 8.43 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.9574724896846574		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 2.9574724896846574 | validation: 4.407147220601534]
	TIME [epoch: 8.44 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5992829478578963		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 3.5992829478578963 | validation: 3.9414091580729496]
	TIME [epoch: 8.45 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7702996134226145		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 3.7702996134226145 | validation: 4.778410925882945]
	TIME [epoch: 8.43 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5869192840382715		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 3.5869192840382715 | validation: 2.7687150232683457]
	TIME [epoch: 8.42 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.6599884101107074		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 2.6599884101107074 | validation: 3.8320084136690493]
	TIME [epoch: 8.44 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.6046095899011		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 4.6046095899011 | validation: 3.7310233613744535]
	TIME [epoch: 8.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.075495052422282		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 4.075495052422282 | validation: 4.726531144977249]
	TIME [epoch: 8.44 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.0901888863686455		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 4.0901888863686455 | validation: 4.2083170652649144]
	TIME [epoch: 8.43 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.059096231218719		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 3.059096231218719 | validation: 1.667464970959112]
	TIME [epoch: 8.42 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7526871186159902		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 3.7526871186159902 | validation: 2.855359051665716]
	TIME [epoch: 8.43 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5363606472250182		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 1.5363606472250182 | validation: 1.5061456384149983]
	TIME [epoch: 8.43 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.079687481740704		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 2.079687481740704 | validation: 1.543089567507797]
	TIME [epoch: 8.43 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2155617517758377		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 1.2155617517758377 | validation: 0.5682136849053001]
	TIME [epoch: 8.42 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6085276303000522		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.6085276303000522 | validation: 0.4128964181160801]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r5_20240219_205156/states/model_tr_study204_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7833939135778408		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.7833939135778408 | validation: 1.6732445058605414]
	TIME [epoch: 8.43 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8516780343391992		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 1.8516780343391992 | validation: 1.9432119404822448]
	TIME [epoch: 8.43 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.1459794729288015		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 2.1459794729288015 | validation: 1.8990110855387605]
	TIME [epoch: 8.43 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.15243145690681		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 2.15243145690681 | validation: 2.3799930529959026]
	TIME [epoch: 8.45 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7372106473104174		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 3.7372106473104174 | validation: 4.5616970118617735]
	TIME [epoch: 8.42 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.841443485060202		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 3.841443485060202 | validation: 3.190570212144799]
	TIME [epoch: 8.42 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.575977537391724		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 4.575977537391724 | validation: 5.288448258574672]
	TIME [epoch: 8.43 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.153365570384992		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 6.153365570384992 | validation: 5.831938938015982]
	TIME [epoch: 8.45 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.179714819042132		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 5.179714819042132 | validation: 3.807836629125906]
	TIME [epoch: 8.43 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.1635959286163704		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 3.1635959286163704 | validation: 2.3458522841551686]
	TIME [epoch: 8.43 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.18500182644381		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 3.18500182644381 | validation: 2.7749189646667025]
	TIME [epoch: 8.43 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3451109368730707		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 3.3451109368730707 | validation: 3.241497363798891]
	TIME [epoch: 8.45 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5550308083640827		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 3.5550308083640827 | validation: 3.3026442029083]
	TIME [epoch: 8.43 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.459374824562816		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 3.459374824562816 | validation: 4.507053721743291]
	TIME [epoch: 8.44 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.1984918467501515		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 4.1984918467501515 | validation: 3.7396824178602697]
	TIME [epoch: 8.44 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.266891398782269		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 4.266891398782269 | validation: 4.890727053761667]
	TIME [epoch: 8.45 sec]
EPOCH 504/2000:
	Training over batches...
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.05
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.025
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.0125
Encountered nan in loss. Reverting update and performing model surgery.
	New model confinement_factor: 0.00625
ERROR:
Encountered nan in loss and reached the maximum number of model alterations: 4.
