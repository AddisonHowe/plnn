Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r1', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2128210791

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.241521411140656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.241521411140656 | validation: 12.539371530242287]
	TIME [epoch: 97.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.545063923402699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.545063923402699 | validation: 10.566116700305574]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.753728406674322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.753728406674322 | validation: 7.097720171067246]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.40974733637429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.40974733637429 | validation: 8.708193183322079]
	TIME [epoch: 11.5 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.417825262823098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.417825262823098 | validation: 6.8310293887294256]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.218565843763386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.218565843763386 | validation: 6.469076049964285]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.76683274476593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.76683274476593 | validation: 7.528164086807077]
	TIME [epoch: 11.6 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.063083981921337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.063083981921337 | validation: 6.340937481043779]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.314417103018086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.314417103018086 | validation: 6.174563641929959]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.213830123883185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.213830123883185 | validation: 6.152691296923267]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.206619024322954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.206619024322954 | validation: 6.431165132856839]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.17150980460832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.17150980460832 | validation: 6.17655557482984]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.172300416026778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.172300416026778 | validation: 6.099767600459538]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.170971036096487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.170971036096487 | validation: 5.976933163001272]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0525890394808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0525890394808 | validation: 6.120688051145753]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.062141517979357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.062141517979357 | validation: 6.775870729535423]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.160363137883742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.160363137883742 | validation: 6.068040805016387]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.03247783718199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.03247783718199 | validation: 5.903341985528914]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.070549581728869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.070549581728869 | validation: 6.880903775293667]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.205132211071339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.205132211071339 | validation: 6.351089557771216]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.983720329818792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.983720329818792 | validation: 5.880366399804952]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.763703037579845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.763703037579845 | validation: 7.068489595186491]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.146775854174301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.146775854174301 | validation: 6.234910885589759]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.182386760750136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.182386760750136 | validation: 5.908884258689897]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.741422612596114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.741422612596114 | validation: 5.928598245192847]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.950622929755486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.950622929755486 | validation: 6.281520356758533]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.949156266179707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.949156266179707 | validation: 5.87307174828747]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.847723745845209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.847723745845209 | validation: 6.187428713692007]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.053886870556724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.053886870556724 | validation: 5.826284345239288]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.824184107735246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.824184107735246 | validation: 6.0035345358306005]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8002467617471165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8002467617471165 | validation: 5.809235584170725]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.936555962980625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.936555962980625 | validation: 5.805894323905625]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.372979127391356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.372979127391356 | validation: 6.414307133613979]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.002475336703812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.002475336703812 | validation: 6.172971513699113]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.93927988835608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.93927988835608 | validation: 5.889330588624855]
	TIME [epoch: 11.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.740303059910576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.740303059910576 | validation: 6.7306273673107455]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.196058022998012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.196058022998012 | validation: 5.993430112804939]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8337898707268385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8337898707268385 | validation: 5.758839313770936]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.659232118484676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.659232118484676 | validation: 6.066518468363069]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.692130463091167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.692130463091167 | validation: 5.784103935414705]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.86478036434572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.86478036434572 | validation: 5.938774448316058]
	TIME [epoch: 11.5 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.770959396404603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.770959396404603 | validation: 5.779387064559678]
	TIME [epoch: 11.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.670105098015474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.670105098015474 | validation: 6.116370346590407]
	TIME [epoch: 11.5 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.818742151655421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.818742151655421 | validation: 6.003753898917164]
	TIME [epoch: 11.5 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.758436281982849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.758436281982849 | validation: 5.804378747332091]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.716146194767155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.716146194767155 | validation: 5.706646550147745]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.496404865103093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.496404865103093 | validation: 5.656354892428715]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.854635115749056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.854635115749056 | validation: 5.603426533427828]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.655353796481972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.655353796481972 | validation: 5.9020161578498564]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6624184288875785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6624184288875785 | validation: 6.070123789274422]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.658658784219896		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.658658784219896 | validation: 5.776775452975344]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.785714714808935		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.785714714808935 | validation: 5.737152505806721]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.498463078055003		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.498463078055003 | validation: 6.23307389980389]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941764622037107		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.941764622037107 | validation: 5.955189203670653]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.470612177010485		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.470612177010485 | validation: 5.77606376663246]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.868250181433216		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.868250181433216 | validation: 5.659046654763213]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.757901058575612		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.757901058575612 | validation: 5.8314596343798035]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.589749778151427		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.589749778151427 | validation: 5.713996441815009]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.602107016816356		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.602107016816356 | validation: 5.571897561392909]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4522846599741595		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.4522846599741595 | validation: 4.740583139000645]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8925811378194908		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.8925811378194908 | validation: 4.459387748946146]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.854834093968906		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.854834093968906 | validation: 4.543538946745839]
	TIME [epoch: 11.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480733296450922		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.480733296450922 | validation: 5.391524852398755]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8770246646480615		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.8770246646480615 | validation: 5.243542588135977]
	TIME [epoch: 11.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5961877780109432		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.5961877780109432 | validation: 4.542605768605007]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1625632369328436		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.1625632369328436 | validation: 4.048818185135514]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.926159547002498		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.926159547002498 | validation: 4.0223335698902645]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.928987003000548		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.928987003000548 | validation: 4.424279151727298]
	TIME [epoch: 11.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1036149456114583		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.1036149456114583 | validation: 4.061746339398727]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9846254560854586		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.9846254560854586 | validation: 4.248550770131297]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.870476244548902		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.870476244548902 | validation: 4.169349055144092]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801005427074273		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.801005427074273 | validation: 4.365679081174942]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.899040554827735		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.899040554827735 | validation: 4.032771127975987]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8255162710286683		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.8255162710286683 | validation: 3.9804464714435865]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.917326062623107		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.917326062623107 | validation: 3.8131307467134707]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6622528221584902		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.6622528221584902 | validation: 4.059576793489689]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9706542038120043		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.9706542038120043 | validation: 3.9774643682146893]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.773086371095092		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.773086371095092 | validation: 3.977972545646438]
	TIME [epoch: 11.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.857206429907412		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.857206429907412 | validation: 3.8421288966263063]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.555776792600427		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.555776792600427 | validation: 4.012585583742365]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7543486058719577		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.7543486058719577 | validation: 3.7717454522108205]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9318516396265073		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.9318516396265073 | validation: 4.317665624948307]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.835471815807732		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.835471815807732 | validation: 4.2043915032009895]
	TIME [epoch: 11.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.703839328729388		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.703839328729388 | validation: 3.9446875530279772]
	TIME [epoch: 11.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7186829940887316		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.7186829940887316 | validation: 3.9560709162513947]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7639258688861084		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.7639258688861084 | validation: 3.6643450095431986]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506047505681102		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.506047505681102 | validation: 4.15822195587324]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8198988784216787		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.8198988784216787 | validation: 4.193040374036904]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8312406777247823		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.8312406777247823 | validation: 3.7344445844637892]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6419796079931257		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.6419796079931257 | validation: 4.007657281440768]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.639498771385133		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.639498771385133 | validation: 4.640303713530417]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8795252888449188		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.8795252888449188 | validation: 4.287878616278916]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.651789374349381		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.651789374349381 | validation: 3.6923760054249444]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.772593740823026		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.772593740823026 | validation: 3.7422996072288797]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5485610815299338		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.5485610815299338 | validation: 3.8400266875436877]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6629955469913322		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.6629955469913322 | validation: 3.841946358031738]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5139060324474247		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.5139060324474247 | validation: 4.747672431402841]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.94470562028603		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.94470562028603 | validation: 3.7051826511117816]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.408411660359867		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.408411660359867 | validation: 3.769124465294534]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4854873075792776		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.4854873075792776 | validation: 4.3011699911197345]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.670014188456433		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.670014188456433 | validation: 3.877845240376924]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6032719877330517		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.6032719877330517 | validation: 3.638492899369705]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.411124011930544		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.411124011930544 | validation: 4.124606816260643]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.666492757940979		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.666492757940979 | validation: 4.088346897116208]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6683045901280193		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.6683045901280193 | validation: 3.7587268571200294]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.491897033830843		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.491897033830843 | validation: 4.067395802731425]
	TIME [epoch: 11.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7480897700056524		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.7480897700056524 | validation: 3.8755518751834654]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6234735594114857		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.6234735594114857 | validation: 3.760552302215641]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5347062384582832		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.5347062384582832 | validation: 3.7380466710098]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.471803922349187		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.471803922349187 | validation: 4.089115311808483]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.446055845323592		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.446055845323592 | validation: 3.391291171842943]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5904843923612106		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.5904843923612106 | validation: 3.630009052630823]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4625018981258355		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 2.4625018981258355 | validation: 3.773786592084348]
	TIME [epoch: 11.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4753152057768832		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.4753152057768832 | validation: 4.232277538784753]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.773704176176218		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.773704176176218 | validation: 3.4932303469451615]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8268685340983835		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.8268685340983835 | validation: 3.7422303460931623]
	TIME [epoch: 11.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6458915524525706		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.6458915524525706 | validation: 3.741179680623793]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4929004287776744		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.4929004287776744 | validation: 3.6211821111330704]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3786920089388013		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.3786920089388013 | validation: 3.74062902631012]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.382517615761029		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.382517615761029 | validation: 3.9479192505674536]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.466173245538153		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.466173245538153 | validation: 3.854118060579949]
	TIME [epoch: 11.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5676933537773525		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 2.5676933537773525 | validation: 3.576664879547314]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2775132349027754		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.2775132349027754 | validation: 3.472923636674102]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2649086944928505		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.2649086944928505 | validation: 3.317857955499793]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.171604149972476		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.171604149972476 | validation: 3.4038083626254156]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2316729647906515		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.2316729647906515 | validation: 2.6710967235576404]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9133848098347848		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.9133848098347848 | validation: 2.31084564713996]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6039554086186179		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.6039554086186179 | validation: 1.315979021232973]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2142062556314805		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.2142062556314805 | validation: 2.5837279300281124]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7572862645420098		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.7572862645420098 | validation: 4.021604368892855]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6877022732217553		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.6877022732217553 | validation: 1.4034870588781696]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6979494452998223		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.6979494452998223 | validation: 1.951857166139875]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8126368319563368		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.8126368319563368 | validation: 1.10410736103875]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.176602537083515		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.176602537083515 | validation: 1.6721776614775103]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2608375931011957		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.2608375931011957 | validation: 1.0192823916405893]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0430584630666646		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.0430584630666646 | validation: 1.88192494502484]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3280564211025947		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3280564211025947 | validation: 1.4186634558788018]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3067051041223214		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3067051041223214 | validation: 1.6077120804439282]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158354810627944		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.158354810627944 | validation: 1.1020939789067614]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144947720175868		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.144947720175868 | validation: 0.9891771715866997]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0440603614998798		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.0440603614998798 | validation: 1.0254390544661955]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9904314429891063		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.9904314429891063 | validation: 1.0912955524982135]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.391670263971807		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.391670263971807 | validation: 0.8822670278630895]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2323746544867724		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2323746544867724 | validation: 1.7281272610863994]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.667844098305023		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.667844098305023 | validation: 1.4161727499788195]
	TIME [epoch: 11.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2321174640205348		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.2321174640205348 | validation: 1.2977791549718205]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590169486701437		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.0590169486701437 | validation: 1.4511336376614865]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4129433993429075		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.4129433993429075 | validation: 0.86916435386621]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8573670656598201		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.8573670656598201 | validation: 0.7393743680013978]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.119544975021278		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.119544975021278 | validation: 0.9297328939070539]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1198065021983683		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.1198065021983683 | validation: 0.852941808422806]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0849445605866541		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.0849445605866541 | validation: 0.855675298965141]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4774461054603418		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.4774461054603418 | validation: 1.4133791788437002]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0654158104425213		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0654158104425213 | validation: 1.0470069473620338]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0358724902912213		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.0358724902912213 | validation: 0.8189532226857256]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.980452785797714		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.980452785797714 | validation: 1.3547436787499607]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0158257016177803		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.0158257016177803 | validation: 0.6884403009412051]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0537315678089296		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0537315678089296 | validation: 1.021067475269157]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9106627024194971		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.9106627024194971 | validation: 0.8035164800718967]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0390984046656824		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.0390984046656824 | validation: 0.6561985276230908]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721309242605129		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8721309242605129 | validation: 1.0753204825129838]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1353182236661807		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.1353182236661807 | validation: 0.9145505126570487]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409124930512242		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8409124930512242 | validation: 0.8125369620538325]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525615789818879		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.7525615789818879 | validation: 0.9856554642007822]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8811122410663097		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.8811122410663097 | validation: 0.9894050673135205]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615440441272624		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.7615440441272624 | validation: 0.6406026026554932]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7995669074581286		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.7995669074581286 | validation: 0.7172752382507587]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179290330372964		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.8179290330372964 | validation: 0.9454169287025898]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990373200890615		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.7990373200890615 | validation: 0.6281180715439052]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771739886521392		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.8771739886521392 | validation: 0.8535992065793246]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814782441463751		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.814782441463751 | validation: 1.0742260972230937]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1966233305854808		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.1966233305854808 | validation: 0.9855294656068924]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9630216945168444		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.9630216945168444 | validation: 0.6548409311456177]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1775833361426806		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.1775833361426806 | validation: 0.6946599485213952]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295287472857382		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.0295287472857382 | validation: 0.7475486359503388]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1261730851550724		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.1261730851550724 | validation: 0.7028987417335623]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8525763873659329		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.8525763873659329 | validation: 0.7467505834707393]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.973332888770204		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.973332888770204 | validation: 0.9775040405817441]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486633132753261		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7486633132753261 | validation: 0.8542940401229919]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206004952562548		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7206004952562548 | validation: 0.7085584701732536]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7452376184149799		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.7452376184149799 | validation: 0.7021636988726965]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728597450003438		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.7728597450003438 | validation: 1.3629314803737649]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9139831470077497		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.9139831470077497 | validation: 1.6410643685492627]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0269300339361296		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.0269300339361296 | validation: 0.8699047779484468]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163366638070812		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7163366638070812 | validation: 0.5989401753787592]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.69300711996998		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.69300711996998 | validation: 0.6272494646263287]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7384087285924197		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.7384087285924197 | validation: 0.710007830487407]
	TIME [epoch: 11.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6618921375127453		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.6618921375127453 | validation: 0.7194252812658078]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301648578238402		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6301648578238402 | validation: 0.5930011970747939]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1097176199980097		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.1097176199980097 | validation: 1.02902633477768]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281767232539662		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7281767232539662 | validation: 0.9290413666542371]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966318645185204		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7966318645185204 | validation: 1.3394148752191855]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9495551202035809		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9495551202035809 | validation: 0.627614818713851]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6925752921864936		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.6925752921864936 | validation: 0.6696606991955193]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8716067628620441		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.8716067628620441 | validation: 0.6447912885679964]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.799436576615333		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.799436576615333 | validation: 0.6592901266521457]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0138323553141353		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.0138323553141353 | validation: 1.059784559471358]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582696064236947		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7582696064236947 | validation: 1.3724759755056204]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8658252422447728		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8658252422447728 | validation: 0.596455302961847]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6672945356026678		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6672945356026678 | validation: 0.7518687712428251]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771016912803202		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.6771016912803202 | validation: 0.9145725173462216]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275907546028257		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8275907546028257 | validation: 0.8326028861133378]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0748164376768703		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.0748164376768703 | validation: 1.002297618630489]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.75583507236834		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.75583507236834 | validation: 0.6185494379440347]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857615713762002		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6857615713762002 | validation: 0.7522256570367933]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3127705817551447		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.3127705817551447 | validation: 0.8656075392791297]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.67364365379603		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.67364365379603 | validation: 0.8640114429271148]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6753236865113156		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6753236865113156 | validation: 0.7514093096051386]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011788840306626		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6011788840306626 | validation: 0.7674908656251691]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6278664841394916		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6278664841394916 | validation: 0.5778409512459268]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997908838661539		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5997908838661539 | validation: 0.7749634225643252]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643982882446117		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.6643982882446117 | validation: 0.7426249483281033]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6624541997068307		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.6624541997068307 | validation: 0.7932813166900968]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179192626047447		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.6179192626047447 | validation: 0.7339891356214117]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897870360573403		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5897870360573403 | validation: 1.0276519428977617]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620887293957415		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.620887293957415 | validation: 0.9164121690053156]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7178092458772111		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7178092458772111 | validation: 0.46072341611667]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5951243762952263		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5951243762952263 | validation: 0.6874476192154603]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7223689211962594		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.7223689211962594 | validation: 0.5846537236363444]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488000387671779		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.5488000387671779 | validation: 0.6897091412427822]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155373783553187		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.5155373783553187 | validation: 0.7237491533361867]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7540484656145798		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7540484656145798 | validation: 1.0190250117686832]
	TIME [epoch: 11.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.856384818327274		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.856384818327274 | validation: 0.5181330426212567]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396018006157788		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.5396018006157788 | validation: 0.45886614292526495]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289740328780986		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.5289740328780986 | validation: 0.7936570315916412]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7367862392131467		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7367862392131467 | validation: 0.788442197529454]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542686168495282		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.542686168495282 | validation: 0.8720732998651552]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6572502987103594		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.6572502987103594 | validation: 0.5125955489162137]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8222125399275027		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8222125399275027 | validation: 0.6082198480053915]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693683431428445		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7693683431428445 | validation: 0.6488056808576488]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66505410733555		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.66505410733555 | validation: 0.627710580942202]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6007457420564296		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6007457420564296 | validation: 0.4121309800215099]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284496743172515		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6284496743172515 | validation: 0.4092947151511359]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5349332035950728		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.5349332035950728 | validation: 0.5442499938841955]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161144066395724		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.5161144066395724 | validation: 0.37375631011911725]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4887330801118459		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.4887330801118459 | validation: 0.41883741603628266]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028761587969936		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7028761587969936 | validation: 0.4424892346272366]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4987636607328421		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.4987636607328421 | validation: 0.48023184729553764]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44385275754847775		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.44385275754847775 | validation: 0.7844495626256551]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090774385585592		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.6090774385585592 | validation: 1.3478795022743963]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885617413297139		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7885617413297139 | validation: 0.5010461708334509]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862656258481912		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5862656258481912 | validation: 0.4902896191356899]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5509474410152906		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5509474410152906 | validation: 0.6374389887801234]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49840831348761405		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.49840831348761405 | validation: 0.9456913235176819]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7466083235457961		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.7466083235457961 | validation: 0.7631470929252506]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5041348701826235		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.5041348701826235 | validation: 0.5403628499119372]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928980126260909		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.4928980126260909 | validation: 0.5184276829502243]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4996096989853798		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.4996096989853798 | validation: 0.6870789663203166]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4925722445829502		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.4925722445829502 | validation: 0.41739749377079477]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4322830470845368		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.4322830470845368 | validation: 0.40539488515892774]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49886416516789683		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.49886416516789683 | validation: 0.3109060889105445]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375318082242981		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.4375318082242981 | validation: 0.35603371201198214]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47694352340156765		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.47694352340156765 | validation: 0.38653215069286473]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48505835532299774		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.48505835532299774 | validation: 0.8686641047151621]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587275999190965		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.587275999190965 | validation: 0.37469127592237117]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5706441685375219		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.5706441685375219 | validation: 1.1219706536149485]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8830067078120332		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8830067078120332 | validation: 0.46466073785422984]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111536318941391		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5111536318941391 | validation: 0.405638315629559]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077971220269695		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5077971220269695 | validation: 0.42613092121800605]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527536652895902		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.527536652895902 | validation: 0.44516466598555793]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38333103130851587		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.38333103130851587 | validation: 0.45050341850793163]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5970675495970353		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.5970675495970353 | validation: 0.3159239413109756]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7801329118753575		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7801329118753575 | validation: 0.9327942317116752]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6622010553628551		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6622010553628551 | validation: 0.31721602794381626]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117530542479892		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5117530542479892 | validation: 0.2845283971834109]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626917285323542		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.5626917285323542 | validation: 0.38948170710265173]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761993776201965		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5761993776201965 | validation: 0.4207268271089302]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006473137870003		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6006473137870003 | validation: 0.472787744710954]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39538843232123483		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.39538843232123483 | validation: 0.4760630505086587]
	TIME [epoch: 11.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846790264756729		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5846790264756729 | validation: 0.31378132834241057]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474909092601443		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5474909092601443 | validation: 0.39106102741293086]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526187434081274		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.4526187434081274 | validation: 0.4610636627305365]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888442315988834		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.4888442315988834 | validation: 0.48384732531227337]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727397252830203		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.4727397252830203 | validation: 0.43096767321909085]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299220588259749		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.4299220588259749 | validation: 0.6143162607949785]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4735254404896097		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.4735254404896097 | validation: 0.5929868015278522]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5793885003750987		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5793885003750987 | validation: 0.4575294566577241]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47546394036300677		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.47546394036300677 | validation: 0.9121262065201021]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004808856947916		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6004808856947916 | validation: 0.3321871131452322]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421772149683845		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.3421772149683845 | validation: 0.396388918518697]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40646441568924674		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.40646441568924674 | validation: 0.6322914604665111]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565771286576614		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.565771286576614 | validation: 0.414275931067423]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340576024401357		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.4340576024401357 | validation: 0.3144723457568337]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058032052563001		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.4058032052563001 | validation: 0.3341459602290513]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574484471061009		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.3574484471061009 | validation: 0.3676365915719886]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957833835159902		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3957833835159902 | validation: 0.43106180038214953]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45128536771063715		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.45128536771063715 | validation: 0.5969998897296085]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037000685697635		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4037000685697635 | validation: 0.32410849443294537]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857712391154841		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.4857712391154841 | validation: 0.49042464239625433]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053293375866357		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.4053293375866357 | validation: 0.6952268371704571]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4591655889004248		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.4591655889004248 | validation: 0.656545870079616]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46438611597452323		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.46438611597452323 | validation: 0.39775697416927047]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38391978529969406		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.38391978529969406 | validation: 0.8775057932184174]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6590096781089021		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6590096781089021 | validation: 0.42949370886222277]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4858012325289871		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.4858012325289871 | validation: 0.5981775530656286]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4515832824430037		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4515832824430037 | validation: 0.4106473244663456]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521451394682068		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5521451394682068 | validation: 0.5344891537716072]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.448677235086136		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.448677235086136 | validation: 0.2904202561352732]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3588006522604931		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3588006522604931 | validation: 0.836790563453587]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49518771182196697		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.49518771182196697 | validation: 0.7849841181235385]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042668429676245		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5042668429676245 | validation: 1.1272065840174808]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293896635871363		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6293896635871363 | validation: 0.378678742755253]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36823897128700556		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.36823897128700556 | validation: 0.39678530412106455]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43578359477723094		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.43578359477723094 | validation: 0.3623857675213471]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39410832416469377		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.39410832416469377 | validation: 0.2676928896616707]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749002439539161		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5749002439539161 | validation: 0.397839320562142]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.363243071045545		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.363243071045545 | validation: 0.2740558959029027]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39374279152475156		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.39374279152475156 | validation: 0.28354163249394]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31113404576364345		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.31113404576364345 | validation: 0.3308211055364393]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036419694766369		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.4036419694766369 | validation: 0.3382558904887861]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005155618467642		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.4005155618467642 | validation: 0.3667437915118045]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38712480899863744		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.38712480899863744 | validation: 0.3469024546083611]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652955021453869		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.3652955021453869 | validation: 0.3497940483176636]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39385584468895185		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.39385584468895185 | validation: 0.44985068775177584]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5132863340719924		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5132863340719924 | validation: 0.3488357154864737]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498691592584905		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3498691592584905 | validation: 0.33095096202894264]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49028890855442225		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.49028890855442225 | validation: 0.5945650227675299]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40363857837870626		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.40363857837870626 | validation: 0.23375672276680853]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171779681993354		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5171779681993354 | validation: 0.3176550580933102]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41793904767135254		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.41793904767135254 | validation: 0.38123337694134035]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892354409855219		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3892354409855219 | validation: 0.3102320837457766]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32895793604685675		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.32895793604685675 | validation: 0.31404692099839837]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590388753261095		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.4590388753261095 | validation: 0.6073326745468386]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49022103005033135		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.49022103005033135 | validation: 0.3098411545458655]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44380915767231		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.44380915767231 | validation: 0.2776596006301066]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31215655586985264		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.31215655586985264 | validation: 0.27962476839608325]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33975083577385523		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.33975083577385523 | validation: 0.540930036671152]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415265063490604		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4415265063490604 | validation: 0.47703974624976164]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926152135441314		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3926152135441314 | validation: 0.6602882079452558]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42534759285232004		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.42534759285232004 | validation: 0.4753810699275331]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976088391587229		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4976088391587229 | validation: 0.25922406478034515]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2905094472504069		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2905094472504069 | validation: 0.34909206702697815]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964542330263291		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2964542330263291 | validation: 0.42353112196284254]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4587650604846081		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4587650604846081 | validation: 0.3967296399695416]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43819001105995936		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.43819001105995936 | validation: 0.3916280278339584]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3458628547719402		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3458628547719402 | validation: 0.3772818284227241]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36608262030254823		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.36608262030254823 | validation: 0.37324940868335915]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3552168031300842		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3552168031300842 | validation: 0.24594496917607445]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4840256359714144		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.4840256359714144 | validation: 0.2601353924339098]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36627464759727324		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.36627464759727324 | validation: 0.29796864674774864]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713362324249714		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.3713362324249714 | validation: 0.4452042862739719]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3389147562942534		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.3389147562942534 | validation: 0.39092969166928754]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30790544417495314		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.30790544417495314 | validation: 0.37076187009831174]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195242902433195		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3195242902433195 | validation: 0.30851229477860914]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427816200424467		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.3427816200424467 | validation: 0.20549955238363127]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32931404713500156		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.32931404713500156 | validation: 0.44351528723966127]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077802805326168		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.3077802805326168 | validation: 0.34240652377119146]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850045917784182		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2850045917784182 | validation: 0.36821036300174453]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30562221183688165		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.30562221183688165 | validation: 0.38716972253822735]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36753069407492867		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.36753069407492867 | validation: 0.2504881391646805]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37928930002772154		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.37928930002772154 | validation: 0.21598311785292132]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28880348251438104		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.28880348251438104 | validation: 0.747164463778011]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955892545670805		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5955892545670805 | validation: 0.2556127776402907]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47087221223179937		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.47087221223179937 | validation: 0.2810429952072978]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500123514947447		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.500123514947447 | validation: 0.36170019049294583]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3295357215728583		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.3295357215728583 | validation: 0.41343693829522465]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35311239679246154		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.35311239679246154 | validation: 0.37540852544474035]
	TIME [epoch: 11.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3440543312201535		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3440543312201535 | validation: 0.25085063536739777]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315149020202602		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.315149020202602 | validation: 0.43019749383552297]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6912565349510514		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6912565349510514 | validation: 0.5722641436980884]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4279294306587293		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4279294306587293 | validation: 0.2336634057229172]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483588593755552		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3483588593755552 | validation: 0.4759492327319735]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468188313948567		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.4468188313948567 | validation: 0.38404905703021114]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32913308297950694		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.32913308297950694 | validation: 0.48311503749167883]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231240424825963		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.4231240424825963 | validation: 0.19852691576100698]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2791244806572239		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2791244806572239 | validation: 0.2935777857169328]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3139160853495567		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3139160853495567 | validation: 0.22767670703073173]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308870084662709		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.308870084662709 | validation: 1.0611651012518197]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770950019729009		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5770950019729009 | validation: 0.33316560297180153]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877553467713683		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2877553467713683 | validation: 0.19259604962011767]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336309562677423		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3336309562677423 | validation: 0.27348946407512364]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640153897400173		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2640153897400173 | validation: 0.35312758121971877]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032464283899133		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.3032464283899133 | validation: 0.5917245785960822]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4160621735929486		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.4160621735929486 | validation: 0.5196411541319769]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39975700727281677		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.39975700727281677 | validation: 0.26335613956124226]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35808517044856686		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.35808517044856686 | validation: 0.32376112539562835]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350107280781062		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.350107280781062 | validation: 0.25148760830874156]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886865400269202		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.2886865400269202 | validation: 0.2532558751473149]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27545337100807366		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.27545337100807366 | validation: 0.5173302838650661]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376859414859752		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.376859414859752 | validation: 0.20525826325800023]
	TIME [epoch: 11.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698015850363813		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2698015850363813 | validation: 0.2961744742946999]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39415296161835		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.39415296161835 | validation: 0.2728898718059241]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897527410991596		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.3897527410991596 | validation: 0.19160426425664057]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33943231283768827		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.33943231283768827 | validation: 0.6077999787565534]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454168061681384		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5454168061681384 | validation: 0.2286511491434996]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756687277808999		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2756687277808999 | validation: 0.32624050331774657]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4778511541755091		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4778511541755091 | validation: 0.40061750342466873]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632348077748799		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3632348077748799 | validation: 1.1632650734974848]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5951924823986772		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5951924823986772 | validation: 0.24259356281608185]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958922438384521		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2958922438384521 | validation: 0.2618067706281699]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3249161302145903		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.3249161302145903 | validation: 0.3306951952358713]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632200126249094		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3632200126249094 | validation: 0.28794227953349905]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343590934556192		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3343590934556192 | validation: 0.4654960529199248]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34422658849138943		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.34422658849138943 | validation: 0.2178254402415486]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27031598330584555		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.27031598330584555 | validation: 0.2699364714215926]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25615782396226094		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.25615782396226094 | validation: 0.32946267809741714]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38813226088872216		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.38813226088872216 | validation: 0.3293845636548987]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28044922582533877		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.28044922582533877 | validation: 0.21814808798341162]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785898170824933		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.2785898170824933 | validation: 0.2157089740695376]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24781213224887744		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.24781213224887744 | validation: 0.24281978221777714]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26634496649111544		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.26634496649111544 | validation: 0.23340901314137302]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24145219452031086		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.24145219452031086 | validation: 0.4013474823755215]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974752470009318		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.3974752470009318 | validation: 0.7251198005631264]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117827312917205		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5117827312917205 | validation: 0.21063278654217257]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35071796142717104		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.35071796142717104 | validation: 0.2665925045918913]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48978797665338575		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.48978797665338575 | validation: 0.5737019083832865]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678998085501389		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.4678998085501389 | validation: 0.3788640552038703]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3312903244564783		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3312903244564783 | validation: 0.2810059862849492]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28425553016142946		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.28425553016142946 | validation: 0.29004018219606403]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839781797494865		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.2839781797494865 | validation: 0.3027981019426467]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28226663289289383		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.28226663289289383 | validation: 0.2911936735566409]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718058036098695		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.2718058036098695 | validation: 0.30412401393204136]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42911607507536387		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.42911607507536387 | validation: 0.4084275640738628]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3456046189151079		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.3456046189151079 | validation: 0.2659610971481786]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26068274304212735		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.26068274304212735 | validation: 0.19162786798971554]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.246586668387814		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.246586668387814 | validation: 0.3672535250569491]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309256162323281		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2309256162323281 | validation: 0.28707619254765737]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26147748576205937		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.26147748576205937 | validation: 0.45639257585977816]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2990319441242446		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.2990319441242446 | validation: 0.22328254216861418]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587675027557335		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2587675027557335 | validation: 0.2892849080825403]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20713239921221183		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.20713239921221183 | validation: 0.5313841670831755]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45437096971045976		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.45437096971045976 | validation: 0.297845799148795]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3956295265833445		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3956295265833445 | validation: 0.3855571284718356]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446703953347167		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.3446703953347167 | validation: 0.1741206846944113]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2840686476735638		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2840686476735638 | validation: 0.30838121935674095]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2424650472779801		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.2424650472779801 | validation: 0.3148149392204042]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26693583129613274		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.26693583129613274 | validation: 0.23780367862096363]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27576449300116224		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.27576449300116224 | validation: 0.5395238934920795]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41674453158445146		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.41674453158445146 | validation: 0.2743174320725937]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474521736876366		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3474521736876366 | validation: 0.2978911348803783]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23816947727806562		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23816947727806562 | validation: 0.18395782627665508]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32084956022792854		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.32084956022792854 | validation: 0.2989414153612102]
	TIME [epoch: 11.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25903534753904944		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.25903534753904944 | validation: 0.42333206456586153]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594430854289645		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3594430854289645 | validation: 0.24342883942130214]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911268602597538		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2911268602597538 | validation: 0.36831595109301546]
	TIME [epoch: 11.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844403355131092		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3844403355131092 | validation: 0.7798747658804942]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4910411104005217		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.4910411104005217 | validation: 0.3971446573917053]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28984141287444354		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.28984141287444354 | validation: 0.37073434089808444]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27742528205916234		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.27742528205916234 | validation: 0.3341257232397326]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22917821318927056		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.22917821318927056 | validation: 0.35571281882481876]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31474873876913656		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.31474873876913656 | validation: 0.24740785843258578]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.313698690160571		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.313698690160571 | validation: 0.23047955165595832]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23552161533980326		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.23552161533980326 | validation: 0.16998599536233427]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26051197647895963		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.26051197647895963 | validation: 0.2946752135467008]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835263511623436		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.2835263511623436 | validation: 0.18692117683745457]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24360702791018163		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.24360702791018163 | validation: 0.22479521907892155]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4485629682276931		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4485629682276931 | validation: 0.18672999006758376]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26347409176092773		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.26347409176092773 | validation: 0.4430515078363858]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2763864041917422		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2763864041917422 | validation: 0.20774737669795357]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20517306808809		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.20517306808809 | validation: 0.17296985807092724]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625155758933619		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2625155758933619 | validation: 0.21456053799332345]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3523210678062589		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3523210678062589 | validation: 0.7239896249698563]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41164353248342533		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.41164353248342533 | validation: 0.5269489909114198]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3741346576853468		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.3741346576853468 | validation: 0.2319466179291189]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33492741781153057		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.33492741781153057 | validation: 0.3245925384576209]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553836940792539		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2553836940792539 | validation: 0.210282194165012]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274468992383658		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.274468992383658 | validation: 0.3877401414857254]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29401646533792714		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.29401646533792714 | validation: 0.16660253650831372]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2216079684524811		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.2216079684524811 | validation: 0.17852021832657233]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23729629269726804		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.23729629269726804 | validation: 0.3193810199352685]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2577500589867606		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.2577500589867606 | validation: 0.2649553052443879]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675272790311534		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.2675272790311534 | validation: 0.2511762200195235]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272730858251515		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.272730858251515 | validation: 0.3024346362942285]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31586309811525815		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.31586309811525815 | validation: 0.4901517105684109]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32480706260125314		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.32480706260125314 | validation: 0.26108912479769536]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30039974740000897		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.30039974740000897 | validation: 0.2088483369123019]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2369419415218235		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2369419415218235 | validation: 0.26767946904459755]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22030739324183835		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.22030739324183835 | validation: 0.13999681153525814]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2728564025420947		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.2728564025420947 | validation: 0.14770030635670472]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23912288918690783		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.23912288918690783 | validation: 0.4346895877954809]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3665286490862951		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.3665286490862951 | validation: 0.39479882848517583]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25880821219612743		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.25880821219612743 | validation: 0.2808216836852847]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670978203450085		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.2670978203450085 | validation: 0.36520846703865145]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907794386691806		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2907794386691806 | validation: 0.1743459073096802]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19197323149943438		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.19197323149943438 | validation: 0.27040764468799255]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987045289156504		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2987045289156504 | validation: 0.24833384219969573]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259754901266497		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.259754901266497 | validation: 0.19477102403689783]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19387319395410232		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.19387319395410232 | validation: 0.16549760829161478]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19284406571525134		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.19284406571525134 | validation: 0.289369883842635]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32036280292516317		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.32036280292516317 | validation: 0.24349161912784575]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22109200271808602		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.22109200271808602 | validation: 0.22951245916840493]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28650352049083994		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.28650352049083994 | validation: 0.1733427674740011]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638737325988645		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2638737325988645 | validation: 0.39028114982846634]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28536232654021765		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.28536232654021765 | validation: 0.2668786082646063]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782455971657509		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2782455971657509 | validation: 0.2715737492905083]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23784591607552988		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.23784591607552988 | validation: 0.20859749620163698]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297375801042846		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.2297375801042846 | validation: 0.18410858078015566]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20431560520973166		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.20431560520973166 | validation: 0.19958554609171203]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977990006859411		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1977990006859411 | validation: 0.19328498319631648]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18463154709028898		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.18463154709028898 | validation: 0.6627448675591827]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609820186552568		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.4609820186552568 | validation: 0.24336887250008774]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22735641342869642		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.22735641342869642 | validation: 0.22513396210926367]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22770128172920287		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.22770128172920287 | validation: 0.2699030674971802]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065576188712961		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.2065576188712961 | validation: 0.16589156950588244]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168546819009131		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2168546819009131 | validation: 0.19389776741358808]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25170810837007274		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.25170810837007274 | validation: 0.2716339988172484]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26585095478302145		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.26585095478302145 | validation: 0.1818840064964808]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23210156704495882		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.23210156704495882 | validation: 0.2027265128549412]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22676421694725415		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.22676421694725415 | validation: 0.20321680167177242]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204532883154786		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.204532883154786 | validation: 0.20187150519229563]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550125004170456		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2550125004170456 | validation: 0.2520494452463313]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21265271566800503		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.21265271566800503 | validation: 0.168023514366376]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23843812956896404		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.23843812956896404 | validation: 0.4120318004413325]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24252202638598272		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.24252202638598272 | validation: 0.325405663553012]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740119197168459		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.2740119197168459 | validation: 0.4372967047826175]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747578830345339		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2747578830345339 | validation: 0.16082398485466676]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18947744787836235		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.18947744787836235 | validation: 0.17121486137047776]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23035239660759324		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.23035239660759324 | validation: 0.26421840290606624]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22759146713845285		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.22759146713845285 | validation: 0.38714625857823903]
	TIME [epoch: 11.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308033047529844		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.308033047529844 | validation: 0.23248877846243057]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20965093700637918		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.20965093700637918 | validation: 0.3133786924259032]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.336528634627692		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.336528634627692 | validation: 0.3370366596515356]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28811289381806304		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.28811289381806304 | validation: 0.18812664389867173]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1877726714060502		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1877726714060502 | validation: 0.22779005198140387]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957638213131105		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1957638213131105 | validation: 0.1765338839146823]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18142182885053693		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.18142182885053693 | validation: 0.15983432170237383]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20881817493618854		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.20881817493618854 | validation: 0.20466020257806855]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22795823406999335		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.22795823406999335 | validation: 0.31779023898980685]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24093624421616422		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.24093624421616422 | validation: 0.22060269400522659]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22617907228026973		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.22617907228026973 | validation: 0.1944274701432606]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24368034946211886		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.24368034946211886 | validation: 0.2270674165876395]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27203794446779905		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.27203794446779905 | validation: 0.1848860270855581]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142414129508015		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2142414129508015 | validation: 0.25724289344904383]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301141901248663		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2301141901248663 | validation: 0.18885743362309892]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24182256306222158		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.24182256306222158 | validation: 0.27811143304209773]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24806072550622554		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24806072550622554 | validation: 0.2283994121576696]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24515709758339466		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.24515709758339466 | validation: 0.18268502507594458]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27407870282052726		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.27407870282052726 | validation: 0.226045765219543]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133679847421558		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2133679847421558 | validation: 0.17149807354286778]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19174572001178766		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.19174572001178766 | validation: 0.17620280431902088]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20529477242950298		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.20529477242950298 | validation: 0.4325856471185856]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2990187391988696		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2990187391988696 | validation: 0.18142493054953654]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21045135673580517		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.21045135673580517 | validation: 0.21357538323290765]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23093083269452003		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.23093083269452003 | validation: 0.22636122181017826]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357852855875806		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.2357852855875806 | validation: 0.21110213044246098]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.205351392831787		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.205351392831787 | validation: 0.3242525673540852]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251773054511638		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2251773054511638 | validation: 0.3028905731448075]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20905657643003345		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.20905657643003345 | validation: 0.30902839980208696]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857388807220405		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2857388807220405 | validation: 0.43741294521508733]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230250044378231		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2230250044378231 | validation: 0.29610678232091814]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461159076786728		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2461159076786728 | validation: 0.1485529959984166]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1971706701075457		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1971706701075457 | validation: 0.16161114689414574]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22709478058728724		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.22709478058728724 | validation: 0.19208791817858747]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21790571400003608		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.21790571400003608 | validation: 0.20391712964862352]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19589695139400734		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.19589695139400734 | validation: 0.21687383256447398]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21655289441370873		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.21655289441370873 | validation: 0.2755481559988795]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22190641451732418		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.22190641451732418 | validation: 0.39100284409247194]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.230271752145097		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.230271752145097 | validation: 0.19843409583708088]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20416964510679955		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.20416964510679955 | validation: 0.20309263753162976]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19469837144921415		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.19469837144921415 | validation: 0.19850728313645977]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1882869266471742		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.1882869266471742 | validation: 0.16005707562230193]
	TIME [epoch: 11.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15728434309547004		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.15728434309547004 | validation: 0.16760662218009803]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1952655551088206		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.1952655551088206 | validation: 0.2225768998465038]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20763653053276948		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.20763653053276948 | validation: 0.19980774854949093]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611052189034166		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2611052189034166 | validation: 0.17103158993390416]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19519269485686805		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.19519269485686805 | validation: 0.16159391694437414]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18516681041903155		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.18516681041903155 | validation: 0.19658729652773724]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19836274804639945		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.19836274804639945 | validation: 0.21860184925619527]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309657335544959		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2309657335544959 | validation: 0.3614130143094771]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26162503094702927		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.26162503094702927 | validation: 0.18490148332931003]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20772173619093853		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.20772173619093853 | validation: 0.22693594918489424]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19765179733080296		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.19765179733080296 | validation: 0.22722976663672886]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27567216598869476		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.27567216598869476 | validation: 0.17181993139330973]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142411752263676		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.21142411752263676 | validation: 0.1829039829392657]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17874925650162826		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.17874925650162826 | validation: 0.20451740239831506]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21058045354165575		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.21058045354165575 | validation: 0.2427340058934023]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060589258345045		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.2060589258345045 | validation: 0.27461887615546415]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19878064794658007		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.19878064794658007 | validation: 0.1824217330255827]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205303033288964		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.2205303033288964 | validation: 0.14422727093371487]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18132336147062944		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.18132336147062944 | validation: 0.21245509078992414]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21394839230178136		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.21394839230178136 | validation: 0.2005930938314974]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22574892999219362		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.22574892999219362 | validation: 0.15928832334110468]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16476957694257838		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.16476957694257838 | validation: 0.2019467986404192]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20657333994853355		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.20657333994853355 | validation: 0.35810646696368426]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23518862602061846		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.23518862602061846 | validation: 0.25540791675451396]
	TIME [epoch: 11.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22558287185381576		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.22558287185381576 | validation: 0.11895065348411998]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690553207921861		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1690553207921861 | validation: 0.2982267816550825]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22064595789662644		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.22064595789662644 | validation: 0.271325502874168]
	TIME [epoch: 11.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.256985275595819		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.256985275595819 | validation: 0.2993872676241018]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2271131986214751		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2271131986214751 | validation: 0.12172046319666156]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17703774877252174		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.17703774877252174 | validation: 0.19897715705182994]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2193821833030234		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.2193821833030234 | validation: 0.20436364620040223]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1787333861719733		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.1787333861719733 | validation: 0.21462971294526434]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21496846619702137		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.21496846619702137 | validation: 0.15634157160995668]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23662987355192677		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.23662987355192677 | validation: 0.27955817733219995]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21267786741685846		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.21267786741685846 | validation: 0.17472617758522485]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19803409547811396		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.19803409547811396 | validation: 0.12156526794706317]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838597048780926		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.1838597048780926 | validation: 0.12540756354752064]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17822781851209785		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.17822781851209785 | validation: 0.5970545826777464]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38683843746545427		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.38683843746545427 | validation: 0.20371987511176323]
	TIME [epoch: 11.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22828568879712258		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.22828568879712258 | validation: 0.13035147976274344]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20437099011748924		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.20437099011748924 | validation: 0.15692420434334628]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17130859762575212		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.17130859762575212 | validation: 0.285556946444128]
	TIME [epoch: 11.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955830819663775		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1955830819663775 | validation: 0.3696567089557655]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604828099271042		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.2604828099271042 | validation: 0.1621290216659979]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18830576292133452		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.18830576292133452 | validation: 0.17099707878355297]
	TIME [epoch: 11.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18525498026424703		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.18525498026424703 | validation: 0.19355036536948544]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18920635869945102		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.18920635869945102 | validation: 0.1436496597246814]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23070205688949882		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.23070205688949882 | validation: 0.25843526799716793]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738417716589979		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2738417716589979 | validation: 0.3631971746945306]
	TIME [epoch: 11.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22492362428705898		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.22492362428705898 | validation: 0.3250961714588433]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2495170902834676		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2495170902834676 | validation: 0.24602014822890161]
	TIME [epoch: 11.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20351760744770714		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.20351760744770714 | validation: 0.21615021618664254]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17118402367440863		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.17118402367440863 | validation: 0.20822191532580106]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2447304040176415		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.2447304040176415 | validation: 0.1803028224472009]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25443349551827177		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.25443349551827177 | validation: 0.17170738141479105]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18263415734238045		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.18263415734238045 | validation: 0.1725906247263118]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20378562324640612		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.20378562324640612 | validation: 0.12680809477075997]
	TIME [epoch: 11.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15977519262244633		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.15977519262244633 | validation: 0.16925021321394706]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18716906599326433		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.18716906599326433 | validation: 0.16730636001892266]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21312738994070413		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.21312738994070413 | validation: 0.1609027532852084]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19145814387196303		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.19145814387196303 | validation: 0.17209431649303103]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551266070206595		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1551266070206595 | validation: 0.18652179547595027]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17303613281794		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.17303613281794 | validation: 0.1163823253095004]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15424170975744153		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15424170975744153 | validation: 0.19126891766850176]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22161811848524096		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.22161811848524096 | validation: 0.4610771107128269]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30937837066299245		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.30937837066299245 | validation: 0.21380895903782363]
	TIME [epoch: 11.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20288111275047518		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.20288111275047518 | validation: 0.23473230380630053]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35176517782187244		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.35176517782187244 | validation: 0.1534275650080245]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1851511509629244		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1851511509629244 | validation: 0.3430032487457028]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27138753723423775		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.27138753723423775 | validation: 0.215204124577185]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21744740722585978		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.21744740722585978 | validation: 0.13773542233695177]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17332340396869667		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.17332340396869667 | validation: 0.17545622341478997]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18249838560667966		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.18249838560667966 | validation: 0.24586506235694416]
	TIME [epoch: 11.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19274150296627673		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.19274150296627673 | validation: 0.16828187790312205]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484809347064036		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.1484809347064036 | validation: 0.14804321606005563]
	TIME [epoch: 11.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16406171079789392		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.16406171079789392 | validation: 0.1699136078221931]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001967092136876		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.2001967092136876 | validation: 0.14446595256306366]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084696805691715		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.20084696805691715 | validation: 0.1450438693296851]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18147721478924156		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.18147721478924156 | validation: 0.20031293250978377]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19007665197246001		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.19007665197246001 | validation: 0.21323044633124447]
	TIME [epoch: 11.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15843975266251992		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.15843975266251992 | validation: 0.1388944537739042]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15254159604306844		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.15254159604306844 | validation: 0.1637171064411954]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735133204822995		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.1735133204822995 | validation: 0.18176645914879194]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16588116395572072		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.16588116395572072 | validation: 0.13605474350827815]
	TIME [epoch: 11.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630512637676374		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.1630512637676374 | validation: 0.1827726407280015]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820633565317007		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.1820633565317007 | validation: 0.20911018094143735]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20231006952040795		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.20231006952040795 | validation: 0.2003039185498219]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21822485482309306		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.21822485482309306 | validation: 0.13258502776194703]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19195002590442264		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.19195002590442264 | validation: 0.20201177024602626]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2458223840673066		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.2458223840673066 | validation: 0.2492520242292663]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163689660149593		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2163689660149593 | validation: 0.18647174413716794]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201803527651709		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.201803527651709 | validation: 0.14872621855053741]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19675663253533346		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.19675663253533346 | validation: 0.16818877051268813]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025741951044483		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.2025741951044483 | validation: 0.18967420689949357]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17567347295935792		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.17567347295935792 | validation: 0.27569336100929226]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2111524503617278		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2111524503617278 | validation: 0.20068995704189432]
	TIME [epoch: 11.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18653890634098655		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.18653890634098655 | validation: 0.19171782026092893]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075346039977248		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2075346039977248 | validation: 0.24082880912061208]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047253380810952		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2047253380810952 | validation: 0.17484189698008534]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18204566668729869		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.18204566668729869 | validation: 0.19632883980375973]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19681486466367507		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.19681486466367507 | validation: 0.2630717709193274]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19703177708806335		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.19703177708806335 | validation: 0.18402738008683692]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18078066763096606		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.18078066763096606 | validation: 0.1519541295193585]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375236257543043		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15375236257543043 | validation: 0.14409653889904958]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786356865372763		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1786356865372763 | validation: 0.18090832174381516]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631832362767039		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.1631832362767039 | validation: 0.18670557773103863]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15843063445166747		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.15843063445166747 | validation: 0.14396419520256462]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1709103340284123		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.1709103340284123 | validation: 0.1632575481830535]
	TIME [epoch: 11.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20746321694069686		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.20746321694069686 | validation: 0.2582443545303375]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535620233023836		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2535620233023836 | validation: 0.24031077232317147]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752781702959528		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.18752781702959528 | validation: 0.1830985001348352]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711272710669793		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1711272710669793 | validation: 0.13877804434431734]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792105073557014		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.1792105073557014 | validation: 0.13639542883720637]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16855511841113785		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.16855511841113785 | validation: 0.1535187466866214]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15444131132983333		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.15444131132983333 | validation: 0.1443933603651075]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1864243917072569		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1864243917072569 | validation: 0.14013158122089933]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15404684903139845		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.15404684903139845 | validation: 0.261385274192102]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21235334144665732		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.21235334144665732 | validation: 0.14440148787863946]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638509391302486		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.13638509391302486 | validation: 0.208223898698014]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19542156068925592		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.19542156068925592 | validation: 0.12325513683293483]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15057960965975964		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.15057960965975964 | validation: 0.14852554066073448]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620395936620867		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1620395936620867 | validation: 0.17873854973539757]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15497500969483013		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.15497500969483013 | validation: 0.12459198004747345]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340309970270123		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.16340309970270123 | validation: 0.1624891869604781]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17267071527549513		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.17267071527549513 | validation: 0.2024465723631127]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18464088247013036		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.18464088247013036 | validation: 0.14688331985465655]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17522207752757593		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.17522207752757593 | validation: 0.14385009936061724]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18442274264020575		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.18442274264020575 | validation: 0.2241082949490227]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18687337117037833		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.18687337117037833 | validation: 0.13169276429905066]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390222050922187		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.16390222050922187 | validation: 0.21582589298344934]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854383901502354		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1854383901502354 | validation: 0.176885115242637]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747194031653772		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1747194031653772 | validation: 0.21023083542602977]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675872785763673		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1675872785763673 | validation: 0.2036568777030559]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19005130503131082		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.19005130503131082 | validation: 0.184787531171143]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16170241907405802		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.16170241907405802 | validation: 0.15711222426356908]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15433374801887426		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.15433374801887426 | validation: 0.1603406840278852]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17014473498261148		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.17014473498261148 | validation: 0.12739008619111647]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19035599015490595		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.19035599015490595 | validation: 0.19237720626926458]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16717281670879824		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.16717281670879824 | validation: 0.19354900280197895]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890510999621839		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.1890510999621839 | validation: 0.13788268417342972]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1725445931860479		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.1725445931860479 | validation: 0.19385468414412052]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18353017178301834		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.18353017178301834 | validation: 0.1934364964831128]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21307201683369792		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.21307201683369792 | validation: 0.19921223590238912]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16354481063766432		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.16354481063766432 | validation: 0.13959932900478492]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582961449042437		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.1582961449042437 | validation: 0.1419333838009165]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14315740872479335		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14315740872479335 | validation: 0.12685245516056765]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215090488311519		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.215090488311519 | validation: 0.18681321744881238]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16138658805026607		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.16138658805026607 | validation: 0.17581486339654642]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15855820336001644		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15855820336001644 | validation: 0.16891398103169505]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16480322446751067		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.16480322446751067 | validation: 0.15352758366827113]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13974289588397226		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.13974289588397226 | validation: 0.1395407278970699]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15805836592110348		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.15805836592110348 | validation: 0.1411030163295115]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16198419010072151		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.16198419010072151 | validation: 0.19176418262276643]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17200370382666436		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.17200370382666436 | validation: 0.1931970498040814]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16781111670123314		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.16781111670123314 | validation: 0.13109101694913416]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17129377896213882		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.17129377896213882 | validation: 0.22688352953660917]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19279891952972844		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.19279891952972844 | validation: 0.10704182713378]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15915287618614146		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.15915287618614146 | validation: 0.14729719318145315]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16553495288075137		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.16553495288075137 | validation: 0.1332577164691746]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677551232428482		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.14677551232428482 | validation: 0.1450606415659514]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1693298305010184		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1693298305010184 | validation: 0.16465156180625243]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14705656001127054		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.14705656001127054 | validation: 0.11997288714775622]
	TIME [epoch: 11.5 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14627529258145439		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.14627529258145439 | validation: 0.15917481354687862]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19810504069156842		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.19810504069156842 | validation: 0.24507836683302076]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18645260143144782		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.18645260143144782 | validation: 0.21546354001836143]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767159016517451		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.1767159016517451 | validation: 0.16197621246022106]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15644733320395227		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.15644733320395227 | validation: 0.1270031378187425]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14585490053508757		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.14585490053508757 | validation: 0.17559971073381145]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133108080939113		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.17133108080939113 | validation: 0.1294033271607606]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14823793862042944		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.14823793862042944 | validation: 0.15672055044020622]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17047229205208414		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.17047229205208414 | validation: 0.1824224571917786]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3104738292462267		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.3104738292462267 | validation: 0.3690331253482391]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21945510687399258		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.21945510687399258 | validation: 0.15667905561332063]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18478653119771593		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.18478653119771593 | validation: 0.13434196109561852]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433613296969271		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.1433613296969271 | validation: 0.14131529051400507]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616738164014579		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1616738164014579 | validation: 0.1798273519332537]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393827663655304		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2393827663655304 | validation: 0.1411359338941006]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25562102576548074		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.25562102576548074 | validation: 0.23904826936433105]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15503561389299034		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15503561389299034 | validation: 0.12088013902640779]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12529315002073277		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.12529315002073277 | validation: 0.13723981307785746]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14353536682297274		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.14353536682297274 | validation: 0.18137326622874292]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573195438360065		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.17573195438360065 | validation: 0.12197373999097011]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.169365233014712		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.169365233014712 | validation: 0.14064310168331545]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13679220013720592		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.13679220013720592 | validation: 0.1379354112350621]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756882106784438		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.13756882106784438 | validation: 0.196898356728632]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27160880726654224		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.27160880726654224 | validation: 0.1313406033913189]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16946220846891596		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.16946220846891596 | validation: 0.1301787540069995]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560245041171858		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.1560245041171858 | validation: 0.15949718213096079]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480781141657662		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1480781141657662 | validation: 0.12848620591008791]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12996929598545703		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.12996929598545703 | validation: 0.13564262196321786]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1477106452259673		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1477106452259673 | validation: 0.1433957228245623]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152469365902867		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.152469365902867 | validation: 0.1892499557011054]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15456844901448316		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15456844901448316 | validation: 0.12342736778776373]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331971021030929		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1331971021030929 | validation: 0.12473588489127643]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15414720181333785		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15414720181333785 | validation: 0.14758918426169934]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389687635188224		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.1389687635188224 | validation: 0.1869195036043579]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15897058751068593		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.15897058751068593 | validation: 0.13509215399331775]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250005465799961		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.14250005465799961 | validation: 0.13705783968259908]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361867787119046		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1361867787119046 | validation: 0.12982903172797255]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13538255149136966		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.13538255149136966 | validation: 0.22089164131455633]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21111037684985196		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.21111037684985196 | validation: 0.15854755329573206]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614897022666668		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1614897022666668 | validation: 0.14247624183158522]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15358775128210994		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.15358775128210994 | validation: 0.13031712653401487]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15352038255142295		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15352038255142295 | validation: 0.12626003402633912]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066005527842935		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.15066005527842935 | validation: 0.12721708131440276]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14508636890423957		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.14508636890423957 | validation: 0.11276124774004342]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13561812764933806		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.13561812764933806 | validation: 0.18135420385288548]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595165174043467		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.1595165174043467 | validation: 0.14184208849258734]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867100320860854		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14867100320860854 | validation: 0.17886286421256514]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18089458957983914		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.18089458957983914 | validation: 0.1755452842584169]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312279466826347		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.14312279466826347 | validation: 0.24906534495158955]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20785749124457942		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.20785749124457942 | validation: 0.1824357610341552]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14795820319273273		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.14795820319273273 | validation: 0.12690713973274548]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13955770067484363		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.13955770067484363 | validation: 0.18611973366332066]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17440855718694587		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.17440855718694587 | validation: 0.18790925725743057]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17643609626258347		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.17643609626258347 | validation: 0.19119529089868503]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16136226685518357		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.16136226685518357 | validation: 0.239154002837567]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15453477949042704		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.15453477949042704 | validation: 0.1343921793866109]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13526917757245382		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.13526917757245382 | validation: 0.17494192950590765]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15234758021719744		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.15234758021719744 | validation: 0.15770768503317711]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16602534844863637		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.16602534844863637 | validation: 0.11746034977020706]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15512999192676036		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.15512999192676036 | validation: 0.1322839794740626]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398451260075584		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.14398451260075584 | validation: 0.12869259666299965]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16419083208987195		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.16419083208987195 | validation: 0.14441080915109164]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436938547498338		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1436938547498338 | validation: 0.12542117679885365]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14383933056989695		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.14383933056989695 | validation: 0.17127945160167485]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981750843579025		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.1981750843579025 | validation: 0.13403768580810713]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310289825954622		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.1310289825954622 | validation: 0.15216892197153709]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998948539841813		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.13998948539841813 | validation: 0.13730324872489763]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675710285749989		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.15675710285749989 | validation: 0.1715456355117913]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15507617740062976		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.15507617740062976 | validation: 0.1592926253381771]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16576525004552434		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.16576525004552434 | validation: 0.17431117805961271]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16651607431383864		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.16651607431383864 | validation: 0.13014304105823488]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12790638097325457		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.12790638097325457 | validation: 0.14595448251300802]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18342955066799627		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.18342955066799627 | validation: 0.2175729541114364]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17206321261041654		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.17206321261041654 | validation: 0.19846235072559354]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17214580373046426		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.17214580373046426 | validation: 0.1263552042994869]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13583694415002967		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.13583694415002967 | validation: 0.1620489602103738]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14644557638001177		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.14644557638001177 | validation: 0.13859697012118397]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19191860303709785		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.19191860303709785 | validation: 0.15601573980300373]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080188691975692		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.14080188691975692 | validation: 0.11908583856960465]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868765107715787		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.14868765107715787 | validation: 0.14760924904057923]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389360400903069		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1389360400903069 | validation: 0.11657462072457658]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13150899994508503		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.13150899994508503 | validation: 0.14558084235702193]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349963601983583		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1349963601983583 | validation: 0.12899623599077972]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809263084262225		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.14809263084262225 | validation: 0.1557376507259419]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14292540690428407		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.14292540690428407 | validation: 0.12126679480438579]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239697540359286		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.14239697540359286 | validation: 0.1367529886277969]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14556971511635058		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.14556971511635058 | validation: 0.1177261790565786]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243389177510468		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.14243389177510468 | validation: 0.14980250433057316]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14588617632001438		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.14588617632001438 | validation: 0.10951302619195519]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384436824497409		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.12384436824497409 | validation: 0.10685533217875769]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13474467181933386		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.13474467181933386 | validation: 0.13340504701043598]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421302206072825		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1421302206072825 | validation: 0.16037150658444504]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15179944246572866		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.15179944246572866 | validation: 0.11635129082118935]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12852893527333203		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.12852893527333203 | validation: 0.1244051757839716]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630168536358892		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.14630168536358892 | validation: 0.1593676522255296]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809029813277552		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.14809029813277552 | validation: 0.12670713076900383]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13981161492427133		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.13981161492427133 | validation: 0.12483100167301762]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175568039596993		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.15175568039596993 | validation: 0.22481522697696832]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16507312656984474		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.16507312656984474 | validation: 0.14305288552758957]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861381456595403		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.12861381456595403 | validation: 0.12344927359742323]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14922786816723033		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.14922786816723033 | validation: 0.15080535979475032]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15770098839971586		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15770098839971586 | validation: 0.15317891053218316]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13103021579714205		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.13103021579714205 | validation: 0.16491251803942916]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16063259736632382		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.16063259736632382 | validation: 0.13853304861936563]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12972543932536504		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.12972543932536504 | validation: 0.11496390223809304]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255401844816306		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1255401844816306 | validation: 0.11291463465983449]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925852402073947		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.11925852402073947 | validation: 0.13029056462813693]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044037120694877		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.14044037120694877 | validation: 0.13380542654986027]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13123051155461518		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.13123051155461518 | validation: 0.14055798202985265]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15312238454371857		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.15312238454371857 | validation: 0.11901477731218772]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13426861480507363		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.13426861480507363 | validation: 0.1723775448038967]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830282055746216		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.14830282055746216 | validation: 0.1122833884283758]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384190088353503		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.1384190088353503 | validation: 0.16900429234352646]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011333980083248		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.16011333980083248 | validation: 0.11637036034510045]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187606823534996		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.187606823534996 | validation: 0.12276481241261693]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238064806586644		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.1238064806586644 | validation: 0.12281748995165234]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096576876884434		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.14096576876884434 | validation: 0.12745433222853558]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401264785502934		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.13401264785502934 | validation: 0.12627095176725514]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16996002784987221		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.16996002784987221 | validation: 0.20146966730554197]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871216823270958		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.17871216823270958 | validation: 0.14388813181463972]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14534103992460323		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.14534103992460323 | validation: 0.1541064721585127]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500403898710434		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.14500403898710434 | validation: 0.12718735462827518]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14418496701576639		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.14418496701576639 | validation: 0.185360633645351]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004185411251145		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.15004185411251145 | validation: 0.16561698946660117]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774812011452571		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1774812011452571 | validation: 0.15737975994907427]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522983577274855		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.1522983577274855 | validation: 0.1736282564175045]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739912813344739		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.1739912813344739 | validation: 0.1490767800542182]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343619544779216		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.15343619544779216 | validation: 0.11975961489443077]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000188274319547		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.14000188274319547 | validation: 0.15489305043912047]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337223231506004		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.1337223231506004 | validation: 0.10726874570788762]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12068483429872504		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.12068483429872504 | validation: 0.1121181570824119]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112813034341742		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.13112813034341742 | validation: 0.1381224466670184]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14438591685851754		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.14438591685851754 | validation: 0.18870888665476393]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677756349182977		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.14677756349182977 | validation: 0.137418765121135]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14335683587223563		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.14335683587223563 | validation: 0.13568383289481634]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12344468049465528		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.12344468049465528 | validation: 0.14456943140332298]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411260472910806		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1411260472910806 | validation: 0.14513478406717464]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14629377937687		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.14629377937687 | validation: 0.10323165492420291]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13665256334167675		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.13665256334167675 | validation: 0.13150425444718894]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488185691849822		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.1488185691849822 | validation: 0.11492363019277865]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1284599209635794		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1284599209635794 | validation: 0.09673266024529699]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_854.pth
	Model improved!!!
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175507327503569		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.11175507327503569 | validation: 0.10088648472557217]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12759309626512774		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.12759309626512774 | validation: 0.14118742861650665]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483692286466863		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.15483692286466863 | validation: 0.114615597599816]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290299019430833		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.1290299019430833 | validation: 0.1181247893966551]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329850283638172		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.1329850283638172 | validation: 0.2184165096673953]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18658802187894694		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.18658802187894694 | validation: 0.1433687433530183]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13900564648168373		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.13900564648168373 | validation: 0.1613465319448787]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159043853474048		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.16159043853474048 | validation: 0.11508333668997071]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12710456429464667		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.12710456429464667 | validation: 0.11785069548618599]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12262929309532111		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.12262929309532111 | validation: 0.13632181109057595]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739848947893614		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.12739848947893614 | validation: 0.12943156938296735]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634681400175834		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.14634681400175834 | validation: 0.11744833827045348]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726178167860316		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.12726178167860316 | validation: 0.10561552424236924]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11973330303167957		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.11973330303167957 | validation: 0.14993892990030208]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276552421073623		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.1276552421073623 | validation: 0.12580793307957222]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13483656255042797		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.13483656255042797 | validation: 0.12642722817585036]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449704618166214		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.1449704618166214 | validation: 0.1311388319515623]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301405137436229		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.13301405137436229 | validation: 0.21402980744275382]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17053270516107233		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.17053270516107233 | validation: 0.13337752975130132]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12825568774291668		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.12825568774291668 | validation: 0.12134271915716621]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14267690837098884		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.14267690837098884 | validation: 0.12033214440189988]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356172772733363		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.1356172772733363 | validation: 0.1257816775118663]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14290246408538185		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.14290246408538185 | validation: 0.1502737473558408]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13314409393255433		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.13314409393255433 | validation: 0.1377672521071051]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387592621917242		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1387592621917242 | validation: 0.11542125030177496]
	TIME [epoch: 11.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286902345808282		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.13286902345808282 | validation: 0.1297337033251986]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304262393222319		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.1304262393222319 | validation: 0.1453707060608987]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005890467033372		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.14005890467033372 | validation: 0.13319093495321987]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228335571853086		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.15228335571853086 | validation: 0.14653838722516033]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12839645034369007		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.12839645034369007 | validation: 0.12519847265312575]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12671644303414867		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.12671644303414867 | validation: 0.11373631200903042]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292026343724773		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.1292026343724773 | validation: 0.10984045560681055]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1132480406899461		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1132480406899461 | validation: 0.12191440054288812]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.122374206213084		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.122374206213084 | validation: 0.1609487191403552]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15571692719212116		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.15571692719212116 | validation: 0.11248405588525659]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364783494288545		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.15364783494288545 | validation: 0.1681191437648256]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14258110334878168		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.14258110334878168 | validation: 0.19798093078277734]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192175744674571		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2192175744674571 | validation: 0.1666373164254742]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833250127035587		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.13833250127035587 | validation: 0.17429139943585134]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841425881556983		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.14841425881556983 | validation: 0.10148064998578628]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12968828405867128		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.12968828405867128 | validation: 0.10464598112646627]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182502644318476		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.12182502644318476 | validation: 0.13935920341880775]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13129833436841215		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.13129833436841215 | validation: 0.11448539091009226]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238718594446106		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.1238718594446106 | validation: 0.1080581446475079]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427358428614468		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.12427358428614468 | validation: 0.10915973409410512]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307211710576889		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.1307211710576889 | validation: 0.14373519880546975]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250988360350585		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.1250988360350585 | validation: 0.11518189295732191]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13184792993919112		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.13184792993919112 | validation: 0.11326384241049255]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12720911411288072		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.12720911411288072 | validation: 0.11968443672670386]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559417827300114		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.1559417827300114 | validation: 0.1081506994307967]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172590891114661		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.1172590891114661 | validation: 0.12279409548722768]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141749502131444		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.141749502131444 | validation: 0.12379894270884474]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1366273640177066		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.1366273640177066 | validation: 0.12421449749126218]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12970178700177945		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.12970178700177945 | validation: 0.103137110273963]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488480337168336		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11488480337168336 | validation: 0.11955142142841094]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010392516791117		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.13010392516791117 | validation: 0.10910013113987589]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443242501961417		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.12443242501961417 | validation: 0.21947578739769236]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1932133530896416		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.1932133530896416 | validation: 0.13348767702259276]
	TIME [epoch: 11.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13489092844941103		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.13489092844941103 | validation: 0.13950158145278774]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640009023219732		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.13640009023219732 | validation: 0.15901841976072384]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19139537366083587		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.19139537366083587 | validation: 0.145362281942745]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13760774358333258		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.13760774358333258 | validation: 0.15541304143201207]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14659873132642276		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.14659873132642276 | validation: 0.137259878863124]
	TIME [epoch: 11.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13123732953625755		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.13123732953625755 | validation: 0.14207016275523188]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13097528063624891		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.13097528063624891 | validation: 0.11617150744865391]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298281397484674		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.1298281397484674 | validation: 0.10514190814957455]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12106481931646103		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.12106481931646103 | validation: 0.11281706275187695]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663716940192699		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.11663716940192699 | validation: 0.13059399349017323]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343789428442193		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.1343789428442193 | validation: 0.1295687147480998]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541142860489395		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.1541142860489395 | validation: 0.12450615062958197]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12503856275475772		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.12503856275475772 | validation: 0.1523888830362102]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361182546668958		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.1361182546668958 | validation: 0.14721463021082787]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686738982357723		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.1686738982357723 | validation: 0.12040893838485918]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490906338942786		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.11490906338942786 | validation: 0.11358720077479634]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11660171241625852		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.11660171241625852 | validation: 0.11952341710246103]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11280100142941633		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.11280100142941633 | validation: 0.10516298509838375]
	TIME [epoch: 11.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11454195234233236		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.11454195234233236 | validation: 0.1259050529775746]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12497265638615235		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.12497265638615235 | validation: 0.13454072573670142]
	TIME [epoch: 11.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14789626463611136		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.14789626463611136 | validation: 0.1276419521330773]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11613869825812907		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.11613869825812907 | validation: 0.1342411803372022]
	TIME [epoch: 11.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12277267530490765		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.12277267530490765 | validation: 0.11416193448566343]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11340290835018466		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.11340290835018466 | validation: 0.11156069595732047]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049545125264344		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.12049545125264344 | validation: 0.11746964608492451]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11662867739868066		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.11662867739868066 | validation: 0.10551695005258313]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11319579705418302		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.11319579705418302 | validation: 0.12097830580860175]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315242087249207		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1315242087249207 | validation: 0.17391591359461053]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16352456782240204		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.16352456782240204 | validation: 0.14816264779933508]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539043796755764		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.12539043796755764 | validation: 0.11530817631121423]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13277241049579191		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.13277241049579191 | validation: 0.11971174236646004]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793445220544299		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.11793445220544299 | validation: 0.12181134688869659]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1220633144407576		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.1220633144407576 | validation: 0.13996286672430688]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093265256296455		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.12093265256296455 | validation: 0.13687439805217932]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113122635414756		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.13113122635414756 | validation: 0.09898185168387973]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11646475091765682		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.11646475091765682 | validation: 0.1259810582125859]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12837249585114965		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12837249585114965 | validation: 0.14050753778163372]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363617933020055		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1363617933020055 | validation: 0.11245326673986071]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925035043867852		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.11925035043867852 | validation: 0.11224911106067172]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461331758735262		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.11461331758735262 | validation: 0.1271260639510946]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11960663296313326		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.11960663296313326 | validation: 0.10257874708184851]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11906079076189464		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.11906079076189464 | validation: 0.12979781393476958]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194675887832499		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1194675887832499 | validation: 0.11530611913937158]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255480098945414		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.1255480098945414 | validation: 0.12562717054745842]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14314786861072237		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.14314786861072237 | validation: 0.12318700073860032]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13038722948156192		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.13038722948156192 | validation: 0.14811610234656247]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14030924371939243		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.14030924371939243 | validation: 0.10990099298558434]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12775918838843342		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.12775918838843342 | validation: 0.14113805814350686]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727188033065068		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.11727188033065068 | validation: 0.0941748240424787]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_961.pth
	Model improved!!!
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1310867152869256		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1310867152869256 | validation: 0.1387079545395329]
	TIME [epoch: 11.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14339699161326439		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.14339699161326439 | validation: 0.12178710879084577]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292500022549779		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1292500022549779 | validation: 0.1267051745112778]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11498639635967955		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.11498639635967955 | validation: 0.11670788681495577]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11818104575685126		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.11818104575685126 | validation: 0.1095040883110223]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448348399522845		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.11448348399522845 | validation: 0.11418545214511606]
	TIME [epoch: 11.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12145877751747873		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.12145877751747873 | validation: 0.11414884266787852]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13756574171839817		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.13756574171839817 | validation: 0.12801348702376786]
	TIME [epoch: 11.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268854777275932		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1268854777275932 | validation: 0.11922445123366256]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209614539031855		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.1209614539031855 | validation: 0.12106632966168715]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13057399284476445		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.13057399284476445 | validation: 0.09676752389987027]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12076610533714771		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.12076610533714771 | validation: 0.12866051128371203]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12783600050074512		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.12783600050074512 | validation: 0.11866619541246262]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243885865748383		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.1243885865748383 | validation: 0.13643905737838313]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539880236363		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.12539880236363 | validation: 0.14750178085627105]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12457241469083631		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.12457241469083631 | validation: 0.11677618829210981]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144871383420986		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.13144871383420986 | validation: 0.11249787005708786]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634867644028957		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.11634867644028957 | validation: 0.1133149365034637]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138813161956584		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1138813161956584 | validation: 0.10484938976402934]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11327023412963774		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.11327023412963774 | validation: 0.11303894984743453]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11602020648266953		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.11602020648266953 | validation: 0.10864538348117724]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11387781551993569		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.11387781551993569 | validation: 0.1252178187780055]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342492176037627		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.1342492176037627 | validation: 0.14097766413469734]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004942366090044		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.13004942366090044 | validation: 0.11704250399341519]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13268525059868636		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.13268525059868636 | validation: 0.11066378408957853]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153891310605791		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.12153891310605791 | validation: 0.11751244388930308]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303251166920072		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.12303251166920072 | validation: 0.11865643456206451]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16378537533861148		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.16378537533861148 | validation: 0.14062387876478014]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13033549240723705		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.13033549240723705 | validation: 0.1313008315690936]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327427336897526		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.1327427336897526 | validation: 0.12014034849647967]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241292632809441		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.1241292632809441 | validation: 0.16962386850142686]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692016511410404		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.1692016511410404 | validation: 0.13545101499662768]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12870371668712546		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.12870371668712546 | validation: 0.12290884606737366]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712435536943908		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.11712435536943908 | validation: 0.11679847545246246]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11575658353301466		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.11575658353301466 | validation: 0.10131545613005644]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11693438611635017		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.11693438611635017 | validation: 0.137512691907485]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919197119324333		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.12919197119324333 | validation: 0.11415559704956466]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11746135322389055		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.11746135322389055 | validation: 0.11225726332674901]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113111911662171		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.11113111911662171 | validation: 0.11990640836254596]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287173593625519		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.11287173593625519 | validation: 0.09433916161428903]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360300264064771		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.1360300264064771 | validation: 0.13116997809793118]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027727251978937		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.12027727251978937 | validation: 0.11613037921538613]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12479040140782618		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.12479040140782618 | validation: 0.11868876583656635]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12291315910038828		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.12291315910038828 | validation: 0.12924939782046813]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848091606504845		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.13848091606504845 | validation: 0.13281428020685246]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13268064988657424		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.13268064988657424 | validation: 0.10043635731703593]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438295158909457		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.12438295158909457 | validation: 0.11882922129700367]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1233646236101865		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1233646236101865 | validation: 0.10627968142876444]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12096820764960224		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.12096820764960224 | validation: 0.10342941666896435]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688306997395592		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.11688306997395592 | validation: 0.12521822613922345]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536217768926808		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.12536217768926808 | validation: 0.13012029204919487]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709574794444688		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.11709574794444688 | validation: 0.12439296109436652]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503511291130214		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.11503511291130214 | validation: 0.11591801766052807]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12155067292722643		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.12155067292722643 | validation: 0.1484274190841145]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342959385950143		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.1342959385950143 | validation: 0.13612231358160565]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13684404372796974		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.13684404372796974 | validation: 0.11308350124342013]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469331174218684		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.12469331174218684 | validation: 0.10981655785827321]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11743609552445233		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.11743609552445233 | validation: 0.10650142833296457]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315686371451003		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1315686371451003 | validation: 0.16099254878181274]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799914449696282		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.13799914449696282 | validation: 0.1339737483359838]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13885449985773443		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.13885449985773443 | validation: 0.15717336395574844]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321590594718256		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.1321590594718256 | validation: 0.11103826764718709]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182142059401725		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.1182142059401725 | validation: 0.13307533774182284]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293272889514964		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.12293272889514964 | validation: 0.10520352727862939]
	TIME [epoch: 11.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11701512550835415		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.11701512550835415 | validation: 0.11323691345188003]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12293496381388405		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.12293496381388405 | validation: 0.1460108877247158]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13112966814488644		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.13112966814488644 | validation: 0.12644222971644775]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11767393064510612		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.11767393064510612 | validation: 0.10148467973860893]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14847744655782955		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.14847744655782955 | validation: 0.13862905680638704]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13146151562715125		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.13146151562715125 | validation: 0.19540547768323943]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17953645264507287		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.17953645264507287 | validation: 0.11509987177110985]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11403811065097602		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.11403811065097602 | validation: 0.10559463436910188]
	TIME [epoch: 11.6 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10931429890114834		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.10931429890114834 | validation: 0.1020001240623599]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11172758439373294		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.11172758439373294 | validation: 0.10684988071848767]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106505414725729		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.11106505414725729 | validation: 0.10699384611270657]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405994970411817		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.11405994970411817 | validation: 0.1075864523009657]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114683398201615		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.1114683398201615 | validation: 0.1267762855252608]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019034234094705		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.12019034234094705 | validation: 0.11551832376114739]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887431356297964		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.10887431356297964 | validation: 0.11325572312168458]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106975751809348		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.11106975751809348 | validation: 0.11194032335455126]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10979883272057761		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.10979883272057761 | validation: 0.1408479104323684]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199759706231332		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.13199759706231332 | validation: 0.11309047442680813]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209391669837152		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.11209391669837152 | validation: 0.10545671986963732]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131322730984717		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.1131322730984717 | validation: 0.11079677787000869]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11859244354509367		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.11859244354509367 | validation: 0.10942940751578874]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10833414156058202		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.10833414156058202 | validation: 0.11552274347199681]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11222977528273866		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.11222977528273866 | validation: 0.11202999127886472]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712544554601739		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.11712544554601739 | validation: 0.10498286772223121]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726148836314945		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.11726148836314945 | validation: 0.11420219938338157]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619539124610313		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.12619539124610313 | validation: 0.10155501949358949]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950789362892124		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.10950789362892124 | validation: 0.11735504478580432]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336153503653459		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.1336153503653459 | validation: 0.12139522698061445]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070013593944125		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.12070013593944125 | validation: 0.1103162024160763]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11491529247799992		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.11491529247799992 | validation: 0.1277242587733807]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024723070492174		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.12024723070492174 | validation: 0.12234375224020273]
	TIME [epoch: 11.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12266295369309083		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.12266295369309083 | validation: 0.11911428433104355]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582260952541795		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.11582260952541795 | validation: 0.10674442471211308]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790686362852683		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.11790686362852683 | validation: 0.12001361710518031]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11473157203122725		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.11473157203122725 | validation: 0.1280980840557937]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12805508488382977		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.12805508488382977 | validation: 0.13601214097662948]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13159327504137938		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.13159327504137938 | validation: 0.10887469700057852]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820584782523265		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.13820584782523265 | validation: 0.11962316382878103]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423025353787218		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.12423025353787218 | validation: 0.1315004853425318]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12665004507175054		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.12665004507175054 | validation: 0.10933433610034961]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079607801293275		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1079607801293275 | validation: 0.10120640218282105]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10719704439934467		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.10719704439934467 | validation: 0.10877208857710963]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13324642538630205		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.13324642538630205 | validation: 0.1624026539870466]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084308985334832		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.15084308985334832 | validation: 0.15659632444577246]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14663835510359327		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.14663835510359327 | validation: 0.10798574130703649]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148406820843428		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1148406820843428 | validation: 0.10919824402940392]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1204412964549373		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.1204412964549373 | validation: 0.11237441787843405]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057231396653873		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.11057231396653873 | validation: 0.1079855649936125]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095917651346066		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.1095917651346066 | validation: 0.10416520367190239]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11912482827068177		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.11912482827068177 | validation: 0.11961804578846721]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278861107483163		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.15278861107483163 | validation: 0.14746747282689873]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14085664328339095		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.14085664328339095 | validation: 0.11414429469417403]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316213159277303		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.12316213159277303 | validation: 0.10423044158844694]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11407381457592336		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.11407381457592336 | validation: 0.11235929372348262]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11171243745886877		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.11171243745886877 | validation: 0.10389198866750947]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11824198727367587		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.11824198727367587 | validation: 0.11385749165661377]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428983083463631		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.12428983083463631 | validation: 0.10332834199243766]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11254578222108577		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.11254578222108577 | validation: 0.11113417113444526]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11447960929215314		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.11447960929215314 | validation: 0.10670652366204224]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11828890743215398		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.11828890743215398 | validation: 0.10860934029860879]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11584803768316768		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.11584803768316768 | validation: 0.09898404927765672]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11516035114529762		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.11516035114529762 | validation: 0.09827480009046374]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11498025115103115		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.11498025115103115 | validation: 0.1050217106116957]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077634050555906		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.1077634050555906 | validation: 0.0987267146020741]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11681916937243184		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.11681916937243184 | validation: 0.12203846866763017]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374379862289012		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.11374379862289012 | validation: 0.10769426528556157]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11422793353249114		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.11422793353249114 | validation: 0.13434158830415072]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12863056330028197		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.12863056330028197 | validation: 0.128228460995017]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342648625147678		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.1342648625147678 | validation: 0.13728779487829168]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13464951771072065		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.13464951771072065 | validation: 0.11649651887082811]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850920020906813		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.11850920020906813 | validation: 0.12730266105260665]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844634557944689		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.11844634557944689 | validation: 0.09878749603734843]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802299145911828		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.10802299145911828 | validation: 0.1193137561887805]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11648055561001322		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11648055561001322 | validation: 0.12001339676086155]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348499598373203		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.11348499598373203 | validation: 0.10362082078360466]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11930100287152964		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.11930100287152964 | validation: 0.10782152760697544]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138333006739009		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.1138333006739009 | validation: 0.11000686030786405]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356684637989588		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.11356684637989588 | validation: 0.11604833550689071]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11879950594347367		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.11879950594347367 | validation: 0.0972183119783342]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501952893237113		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.11501952893237113 | validation: 0.1228468922830639]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205666051553482		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1205666051553482 | validation: 0.10416086421547449]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709992046573004		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.10709992046573004 | validation: 0.10837130464473999]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168615807210423		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.1168615807210423 | validation: 0.11221019409152845]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11243010389485		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.11243010389485 | validation: 0.11505793416587075]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11543193455107656		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.11543193455107656 | validation: 0.10812691188329179]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522228954534418		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.11522228954534418 | validation: 0.11422501837556098]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237144286414856		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.12237144286414856 | validation: 0.10553833142182031]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11486195369269624		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.11486195369269624 | validation: 0.11369566507278193]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222703544711848		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.1222703544711848 | validation: 0.13249497569089128]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412014790191059		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.1412014790191059 | validation: 0.11655191853808423]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832073649330845		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.10832073649330845 | validation: 0.10433333274653159]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10733667595152081		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.10733667595152081 | validation: 0.10444964159093824]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044198651526999		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.11044198651526999 | validation: 0.11066518310671583]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131703885421649		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.1131703885421649 | validation: 0.12244127137096891]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11957564281666541		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.11957564281666541 | validation: 0.11017854614114]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12111756105995536		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.12111756105995536 | validation: 0.10799714428099298]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963899630742542		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.10963899630742542 | validation: 0.10506715538938913]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096855654868026		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.11096855654868026 | validation: 0.10310510361307816]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11293140302588782		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.11293140302588782 | validation: 0.12387324813860996]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12497350750145217		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.12497350750145217 | validation: 0.1001394174265129]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11642957642400256		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.11642957642400256 | validation: 0.10060797068475066]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126859452765074		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.11126859452765074 | validation: 0.11446301549526666]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212214356386256		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.11212214356386256 | validation: 0.12265512597393773]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13610396885535894		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.13610396885535894 | validation: 0.10485535368863136]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457975326648548		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.11457975326648548 | validation: 0.10059787055351657]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065498678165241		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.1065498678165241 | validation: 0.10252116838157366]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060560672492716		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.11060560672492716 | validation: 0.11412917985208867]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12057543953916974		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.12057543953916974 | validation: 0.11759853496914628]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869758283772336		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.11869758283772336 | validation: 0.1173099329487463]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10946364195829732		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.10946364195829732 | validation: 0.10693568614309612]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11208267655001394		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.11208267655001394 | validation: 0.10732888894458331]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10653399594466488		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.10653399594466488 | validation: 0.12421764778990166]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13629972171119797		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.13629972171119797 | validation: 0.13151291862710043]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121743372180187		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.121743372180187 | validation: 0.10732223513290884]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11174002926435125		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.11174002926435125 | validation: 0.1008269863980064]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715002343373986		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.10715002343373986 | validation: 0.10205969716310609]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172671967470704		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.1172671967470704 | validation: 0.11596406692570739]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11611910843060741		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.11611910843060741 | validation: 0.10103338272224122]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384943770531509		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.10384943770531509 | validation: 0.11448757632310116]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11534328572805193		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.11534328572805193 | validation: 0.10883367720556753]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061746062186117		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.11061746062186117 | validation: 0.11923937848468341]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11771567349015977		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.11771567349015977 | validation: 0.12712201063757625]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857500531494096		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.11857500531494096 | validation: 0.10004447847146378]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11404820364547075		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.11404820364547075 | validation: 0.10740229397336384]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690555856526019		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.11690555856526019 | validation: 0.10332569896576983]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117570214677912		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.1117570214677912 | validation: 0.09630985484139858]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869625091335153		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.10869625091335153 | validation: 0.11288731372497557]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325849712884119		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.1325849712884119 | validation: 0.1190171954182512]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11860064772326946		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.11860064772326946 | validation: 0.12175060638341964]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12587464795238354		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.12587464795238354 | validation: 0.10774969494577871]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11398909644879422		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.11398909644879422 | validation: 0.09857278485320362]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095097539689398		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.1095097539689398 | validation: 0.10613060732139779]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573932376767456		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.10573932376767456 | validation: 0.11013888377555685]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11324319912275202		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.11324319912275202 | validation: 0.09937418904296692]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385915177467542		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.10385915177467542 | validation: 0.10571323422888629]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890524030016585		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.10890524030016585 | validation: 0.10813044370026105]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385158877519595		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.11385158877519595 | validation: 0.11084167712115693]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468647800963376		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.12468647800963376 | validation: 0.10426394024022283]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11742589154691413		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.11742589154691413 | validation: 0.12534114196355287]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12098508398434611		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.12098508398434611 | validation: 0.12969455019623646]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669275681426193		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.12669275681426193 | validation: 0.1053059142655557]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565974521395671		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.10565974521395671 | validation: 0.10905656583737491]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10955282555311552		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.10955282555311552 | validation: 0.09966280389822277]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11697694043704313		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.11697694043704313 | validation: 0.10491652155090295]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12272452715044407		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.12272452715044407 | validation: 0.11722513568535024]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015775441323198		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.12015775441323198 | validation: 0.12203545313601004]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11026074364288634		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.11026074364288634 | validation: 0.11411891436967368]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142729493028336		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.11142729493028336 | validation: 0.10073028954264863]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233471157489824		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.11233471157489824 | validation: 0.10940285904708344]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329015735787353		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.10329015735787353 | validation: 0.10408699565813105]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682603554877267		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.10682603554877267 | validation: 0.10885466036243706]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168243816024269		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.11168243816024269 | validation: 0.09818518431683852]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10761431864676464		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.10761431864676464 | validation: 0.10243740431839825]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11490948046629437		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.11490948046629437 | validation: 0.11394974527143191]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10988752241735913		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.10988752241735913 | validation: 0.10203206230816952]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10186789563312199		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.10186789563312199 | validation: 0.10360537731509496]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773861360562306		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.10773861360562306 | validation: 0.0995557924307542]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559269003066601		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.10559269003066601 | validation: 0.09954847546471905]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11777832696382487		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.11777832696382487 | validation: 0.1119398566811058]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11875039456984136		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.11875039456984136 | validation: 0.10609480110435883]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11082795717671072		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.11082795717671072 | validation: 0.10774329324778059]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401318146439766		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.11401318146439766 | validation: 0.11133566285189118]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625333204229436		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.12625333204229436 | validation: 0.10624341656757048]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11075613444945384		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.11075613444945384 | validation: 0.10973872004995067]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11245488187773109		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.11245488187773109 | validation: 0.10917621853186639]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11990211122864855		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.11990211122864855 | validation: 0.1116278891191359]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12168707596862616		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.12168707596862616 | validation: 0.09507183775212193]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10641891620117175		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.10641891620117175 | validation: 0.09931497103267344]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454675738903375		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.10454675738903375 | validation: 0.10377035145784344]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047809613033573		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.11047809613033573 | validation: 0.10000454353390614]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11848361930377961		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.11848361930377961 | validation: 0.1163640899280075]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227958633061728		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.1227958633061728 | validation: 0.10775342932011278]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452279294464503		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.10452279294464503 | validation: 0.09849880593228039]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586564522279976		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.10586564522279976 | validation: 0.11564460210373785]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987901756097957		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.11987901756097957 | validation: 0.0996466000854793]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027682941717173		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.11027682941717173 | validation: 0.10067062183073036]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898420422933093		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.10898420422933093 | validation: 0.10036424796586016]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819530702172551		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.10819530702172551 | validation: 0.10506987126936329]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091760655649147		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.1091760655649147 | validation: 0.10791547697485028]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773523603931515		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.10773523603931515 | validation: 0.09797557528491473]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11344974529824993		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.11344974529824993 | validation: 0.11235845218011381]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156360827025424		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.11156360827025424 | validation: 0.10652553601538733]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736513755202212		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.10736513755202212 | validation: 0.09119285458226382]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1208.pth
	Model improved!!!
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934514712282078		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.10934514712282078 | validation: 0.10924038243535161]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159882809698034		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.1159882809698034 | validation: 0.10846095898766443]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11672973811982543		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.11672973811982543 | validation: 0.1113106310186039]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11229462036886888		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.11229462036886888 | validation: 0.1367863526608592]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469182073480001		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.12469182073480001 | validation: 0.12038550507899984]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291093640713006		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.11291093640713006 | validation: 0.10959266001115492]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133894221052719		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.11133894221052719 | validation: 0.10125871630047492]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227973031380462		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.11227973031380462 | validation: 0.11465863029650944]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11219066968888322		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.11219066968888322 | validation: 0.09896539326879729]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10483724522931659		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.10483724522931659 | validation: 0.10544313427253638]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10606567710562957		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.10606567710562957 | validation: 0.1002274768325648]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066545254214468		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.1066545254214468 | validation: 0.10199711309767517]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671523095033672		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.10671523095033672 | validation: 0.1041551052294128]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10795734036641695		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.10795734036641695 | validation: 0.10997953193103019]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11173752129734085		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.11173752129734085 | validation: 0.11387509387521892]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645204666851042		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.11645204666851042 | validation: 0.1049119349248289]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10877246324972911		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.10877246324972911 | validation: 0.09660635650448474]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460068215324773		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.10460068215324773 | validation: 0.0986023420223669]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987999838132452		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.10987999838132452 | validation: 0.10622034064028082]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246180147290111		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.11246180147290111 | validation: 0.1023231803401003]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10582715507851889		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.10582715507851889 | validation: 0.09715429553475717]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10473233362421822		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.10473233362421822 | validation: 0.10515675816382421]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149437321191095		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.11149437321191095 | validation: 0.10416149257039839]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11130571703272088		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.11130571703272088 | validation: 0.10794083763053934]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11066017412351835		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.11066017412351835 | validation: 0.09536041473957417]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10355670667789979		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10355670667789979 | validation: 0.09136505086551171]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057916970363955		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.11057916970363955 | validation: 0.11480511899674305]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147319582926194		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.1147319582926194 | validation: 0.11059942556795661]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124174720896684		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1124174720896684 | validation: 0.11054473935262926]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789171793025681		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.10789171793025681 | validation: 0.10433540171862403]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11032862203482527		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.11032862203482527 | validation: 0.11516450138414847]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11136709985020696		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.11136709985020696 | validation: 0.10354890032797293]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10540662511734537		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.10540662511734537 | validation: 0.10220769803210257]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825610100754846		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.10825610100754846 | validation: 0.09596107362031328]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412351597251986		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.10412351597251986 | validation: 0.10211144943674856]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747312539520473		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.11747312539520473 | validation: 0.10034879035774058]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604606204673231		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.10604606204673231 | validation: 0.11159588271181617]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621240586165441		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.10621240586165441 | validation: 0.09673721431649858]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10476935137002193		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.10476935137002193 | validation: 0.09611648559685837]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11001820665565983		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.11001820665565983 | validation: 0.10250290801091119]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070901480252357		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.1070901480252357 | validation: 0.09216393228476989]
	TIME [epoch: 11.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185625843325861		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.10185625843325861 | validation: 0.0925984460261978]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10440765337827917		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.10440765337827917 | validation: 0.10260411443162738]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11739112017918474		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.11739112017918474 | validation: 0.11958912124573706]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910510860392198		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.11910510860392198 | validation: 0.10311666134519039]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665267391410603		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.10665267391410603 | validation: 0.09814755463367794]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165305207199692		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.10165305207199692 | validation: 0.10922378131669648]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623181630781836		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.10623181630781836 | validation: 0.0962275406294698]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356321797226517		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.10356321797226517 | validation: 0.09828074467395403]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11210525753640438		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.11210525753640438 | validation: 0.10753425984457593]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11137924783844987		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.11137924783844987 | validation: 0.10515903681282658]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11060560362420412		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.11060560362420412 | validation: 0.09793838147191394]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381752934616771		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.10381752934616771 | validation: 0.10707111051606806]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11816825536268877		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.11816825536268877 | validation: 0.10544621486958927]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10427209894000247		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.10427209894000247 | validation: 0.10165150280147528]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220992615021758		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.11220992615021758 | validation: 0.11608097078334019]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430128771545773		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.10430128771545773 | validation: 0.1107692549354516]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793698871462049		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.10793698871462049 | validation: 0.09994047782065332]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261209789607369		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.10261209789607369 | validation: 0.10538275947922511]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11311698073009405		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.11311698073009405 | validation: 0.11738922841484929]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987132946248923		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.10987132946248923 | validation: 0.10841768010804767]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054703661632273		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.11054703661632273 | validation: 0.1108276516842847]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10768537242140129		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.10768537242140129 | validation: 0.10456570509026382]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070122469844971		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.1070122469844971 | validation: 0.10002875296218715]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198362630508805		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.10198362630508805 | validation: 0.10305808979431376]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10731052547824596		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.10731052547824596 | validation: 0.0963660669240198]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912163479361568		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.10912163479361568 | validation: 0.09319804966975533]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10533889875469486		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.10533889875469486 | validation: 0.09456115414114588]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10964704677989916		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.10964704677989916 | validation: 0.09986262569940295]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350143921361495		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.10350143921361495 | validation: 0.09582559589393476]
	TIME [epoch: 11.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104953052551881		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.104953052551881 | validation: 0.09233108463487298]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251990040467432		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.10251990040467432 | validation: 0.09622626916263848]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460968815633533		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.10460968815633533 | validation: 0.0976375841927937]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11891652073912057		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.11891652073912057 | validation: 0.1262049477814663]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478556314670122		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.12478556314670122 | validation: 0.10614847322846238]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581165200141597		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.11581165200141597 | validation: 0.10094385530207749]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11085988834915023		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.11085988834915023 | validation: 0.12220728302540407]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562606984592814		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.10562606984592814 | validation: 0.1051195175233433]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730211270283548		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.10730211270283548 | validation: 0.10007205542368602]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187714064880627		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.11187714064880627 | validation: 0.10276708682619595]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10719590816155225		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.10719590816155225 | validation: 0.0996623482031234]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11253862042832018		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.11253862042832018 | validation: 0.11064947734113746]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862447225165611		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.10862447225165611 | validation: 0.10629903068581248]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187523446450944		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.1187523446450944 | validation: 0.11405091269244448]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10941002599300632		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.10941002599300632 | validation: 0.11608016543923202]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1187922686314764		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.1187922686314764 | validation: 0.10899728409012299]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957206128303504		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.10957206128303504 | validation: 0.09841480575203704]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425234518765931		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.10425234518765931 | validation: 0.10414111224281898]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201484276539564		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.11201484276539564 | validation: 0.10949020858835841]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11219237770214055		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.11219237770214055 | validation: 0.10853220923067823]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671831703882671		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.10671831703882671 | validation: 0.10541411562853574]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10626798789137368		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.10626798789137368 | validation: 0.10251544173898135]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619740046868501		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.11619740046868501 | validation: 0.1083654154101868]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616907853620333		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.10616907853620333 | validation: 0.10694044068006578]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311236105437437		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.10311236105437437 | validation: 0.10186140005432893]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152768081091225		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.10152768081091225 | validation: 0.10331318151310004]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114687414813614		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.1114687414813614 | validation: 0.09853105893073817]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376376674896198		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.10376376674896198 | validation: 0.10002774582859963]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10626585671019705		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.10626585671019705 | validation: 0.10669207278639803]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11181416229576646		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.11181416229576646 | validation: 0.10643856855346602]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10803119864688779		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.10803119864688779 | validation: 0.1047569111453226]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11282345709031968		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.11282345709031968 | validation: 0.10203635668119047]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044429712270185		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.10044429712270185 | validation: 0.09297684083758849]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737862496365932		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.10737862496365932 | validation: 0.11238550329589217]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687793498444341		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.10687793498444341 | validation: 0.08834783093471192]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1313.pth
	Model improved!!!
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445725659511948		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.10445725659511948 | validation: 0.09242673651394474]
	TIME [epoch: 11.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038562404381642		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.1038562404381642 | validation: 0.09732391777802449]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10778960610012481		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.10778960610012481 | validation: 0.09549647532959071]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040665937888442		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.1040665937888442 | validation: 0.10155977448011232]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391655712374558		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.10391655712374558 | validation: 0.09574311008435298]
	TIME [epoch: 11.6 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023668413830902		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.10023668413830902 | validation: 0.09845485725707416]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040932522161106		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.1040932522161106 | validation: 0.09363030905840582]
	TIME [epoch: 11.6 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09940870364628593		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.09940870364628593 | validation: 0.1056062276958623]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546737634917144		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.10546737634917144 | validation: 0.0994255048104409]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036854620875354		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.1036854620875354 | validation: 0.09888204275961376]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10321186662510275		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.10321186662510275 | validation: 0.10161697671542502]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038466152663504		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.1038466152663504 | validation: 0.09329355481761314]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037143852642422		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.1037143852642422 | validation: 0.09351504400282144]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104427486593123		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.1104427486593123 | validation: 0.10021545145584336]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620287885093066		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.10620287885093066 | validation: 0.10329663674107448]
	TIME [epoch: 11.6 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10055161646969188		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.10055161646969188 | validation: 0.09146129449405029]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391450448340062		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.10391450448340062 | validation: 0.10169542675716381]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559784693065236		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.10559784693065236 | validation: 0.08799412696415226]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1331.pth
	Model improved!!!
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141081180615152		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.10141081180615152 | validation: 0.10514974324480808]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713032050493215		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.10713032050493215 | validation: 0.10183625999399012]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173241550197812		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.10173241550197812 | validation: 0.10306302669930385]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469679555009889		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.10469679555009889 | validation: 0.09615526588848994]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108161130653741		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.10108161130653741 | validation: 0.10688723122622701]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10250676191352207		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.10250676191352207 | validation: 0.10347051386825334]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11270647196523344		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.11270647196523344 | validation: 0.10398200534588158]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539852832230046		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.10539852832230046 | validation: 0.10466197466570723]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031552962181414		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.1031552962181414 | validation: 0.09939044730565236]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022306772307354		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.1022306772307354 | validation: 0.0907832556201934]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408597087928156		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.10408597087928156 | validation: 0.11068389664128311]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227749930436242		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.10227749930436242 | validation: 0.10509974807713236]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465795433253622		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.10465795433253622 | validation: 0.10535866929100511]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036824681317245		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.1036824681317245 | validation: 0.09817575050219418]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10089042708560972		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.10089042708560972 | validation: 0.09949876398472657]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295665495849426		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.10295665495849426 | validation: 0.09598277505710968]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584708062746966		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.10584708062746966 | validation: 0.10221945015658068]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411090161641508		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.10411090161641508 | validation: 0.10854648597311989]
	TIME [epoch: 11.6 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106029730544213		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.1106029730544213 | validation: 0.09886508960283685]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940519348813708		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.10940519348813708 | validation: 0.11016077392253262]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10987111054346663		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.10987111054346663 | validation: 0.10694128993884024]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1074079841517239		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.1074079841517239 | validation: 0.10529786388050724]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10446183417609471		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.10446183417609471 | validation: 0.11585313340604382]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434588995438667		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.11434588995438667 | validation: 0.10657187780634729]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861398254393843		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.10861398254393843 | validation: 0.10541786547381396]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10746387879649197		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.10746387879649197 | validation: 0.09537182446889705]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10231569775323848		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.10231569775323848 | validation: 0.09373626211665574]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10755348433284748		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.10755348433284748 | validation: 0.08687076323708555]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1359.pth
	Model improved!!!
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331517413788566		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.10331517413788566 | validation: 0.10246282359282746]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10846197915258513		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.10846197915258513 | validation: 0.1094572663112097]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052524906993222		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.11052524906993222 | validation: 0.10862301082996528]
	TIME [epoch: 11.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695859564733201		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.10695859564733201 | validation: 0.10469958226664675]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950475290607561		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.10950475290607561 | validation: 0.10109611865690113]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1074035308138567		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.1074035308138567 | validation: 0.10505121241445661]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119624255626336		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.10119624255626336 | validation: 0.1000862363034316]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020416308274574		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.1020416308274574 | validation: 0.09197096725123573]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10399815946092397		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.10399815946092397 | validation: 0.09065826893198142]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357640926227932		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.10357640926227932 | validation: 0.09717799338225738]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09853038751005366		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.09853038751005366 | validation: 0.09126662468942896]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269673590246403		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.10269673590246403 | validation: 0.10101626038661204]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10634444579425552		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.10634444579425552 | validation: 0.0986127272152246]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241465485616777		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.10241465485616777 | validation: 0.0932995284417342]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726654385380516		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.10726654385380516 | validation: 0.0983980804063195]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10492647314512686		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.10492647314512686 | validation: 0.09666648098443373]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10602431922043619		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.10602431922043619 | validation: 0.10442148206254903]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11299383932031687		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.11299383932031687 | validation: 0.11084263406537412]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10938020130189376		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.10938020130189376 | validation: 0.0953416669950509]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10421383107316326		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.10421383107316326 | validation: 0.1042009544306072]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10937282119102676		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.10937282119102676 | validation: 0.10142068702351434]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10532669182011889		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.10532669182011889 | validation: 0.0906467353611691]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063434577214664		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.10063434577214664 | validation: 0.09689741140594936]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10240900474123939		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.10240900474123939 | validation: 0.10149932522978132]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069874492740077		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.10069874492740077 | validation: 0.10759508050156916]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042562712849101		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.10042562712849101 | validation: 0.10767214197390855]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10437130039493937		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.10437130039493937 | validation: 0.10581534574526337]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507548566579347		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.10507548566579347 | validation: 0.09251009169501749]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10004488679185197		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.10004488679185197 | validation: 0.09773188636787458]
	TIME [epoch: 11.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385303739085362		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.10385303739085362 | validation: 0.0999706474161075]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442941952881636		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.10442941952881636 | validation: 0.09386275467291597]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985234335751562		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.09985234335751562 | validation: 0.09210988107674706]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10306225258078763		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.10306225258078763 | validation: 0.09199553969168252]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10115332962891024		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.10115332962891024 | validation: 0.09923567093169734]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09970605696668342		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.09970605696668342 | validation: 0.08868252137929357]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09962763731624216		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.09962763731624216 | validation: 0.09790227451114997]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506541664747987		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.10506541664747987 | validation: 0.11176403155007394]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364105136039789		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.10364105136039789 | validation: 0.09836341985876587]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033892833849246		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.11033892833849246 | validation: 0.10177645466868995]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170016088065887		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.11170016088065887 | validation: 0.10938392664753684]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11108162661700584		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.11108162661700584 | validation: 0.114132763924876]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11099050329062957		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.11099050329062957 | validation: 0.10760631827267694]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663885959540534		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.10663885959540534 | validation: 0.0935573124089277]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10617548867104706		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.10617548867104706 | validation: 0.10416764324493563]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100890483087555		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.1100890483087555 | validation: 0.09702318784911769]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991844580652152		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.09991844580652152 | validation: 0.09708572554209037]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10361497231240416		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.10361497231240416 | validation: 0.10370530044491394]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11424419378631594		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.11424419378631594 | validation: 0.1012396868018292]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293744151634512		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.10293744151634512 | validation: 0.0986278022030534]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10126018006562075		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.10126018006562075 | validation: 0.0897626467928977]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09896822067693689		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.09896822067693689 | validation: 0.09801642554719205]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10261639119793611		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.10261639119793611 | validation: 0.09976171972878736]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10301224775142066		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.10301224775142066 | validation: 0.09850851283044097]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425952514793933		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.10425952514793933 | validation: 0.1008209627661322]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108148753568438		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.108148753568438 | validation: 0.10123882438633793]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1030700501808551		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.1030700501808551 | validation: 0.0994879505469758]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393284680239848		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.10393284680239848 | validation: 0.09860737930877025]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647641508456593		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.10647641508456593 | validation: 0.10014751080296973]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10120547087517137		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.10120547087517137 | validation: 0.10681507258476307]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329126077158937		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.10329126077158937 | validation: 0.0985005335395574]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699739619195328		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.10699739619195328 | validation: 0.10571120898208893]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442866053213494		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.10442866053213494 | validation: 0.10192381240837144]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10759562603460249		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.10759562603460249 | validation: 0.10805903547195941]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10716622944879647		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.10716622944879647 | validation: 0.10154389159812607]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10561783103400373		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.10561783103400373 | validation: 0.10315346810321417]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122523415820328		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.10122523415820328 | validation: 0.09869003797568444]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477416724079223		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.10477416724079223 | validation: 0.09748190706953092]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10668754729285179		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.10668754729285179 | validation: 0.10217885970412197]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108488949287597		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.108488949287597 | validation: 0.10960144912572187]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715479026677412		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.10715479026677412 | validation: 0.09866144126074175]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10648004413443862		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.10648004413443862 | validation: 0.09188449552512422]
	TIME [epoch: 11.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004672844366005		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.1004672844366005 | validation: 0.0937413885081676]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260255538110363		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.10260255538110363 | validation: 0.10445172708556001]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10536945134699525		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.10536945134699525 | validation: 0.09682259183248172]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585462985269424		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.10585462985269424 | validation: 0.1014102868001347]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811494381679435		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.10811494381679435 | validation: 0.09740494284219008]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247324789128535		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.10247324789128535 | validation: 0.10392792557303995]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10133922227039546		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.10133922227039546 | validation: 0.09241839573532389]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10124317772937688		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.10124317772937688 | validation: 0.09273893577514666]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164069312095025		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.10164069312095025 | validation: 0.10387772184806256]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10361558239686815		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.10361558239686815 | validation: 0.09362992551218177]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060096635199536		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.1060096635199536 | validation: 0.09508750261757978]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10483610014697699		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.10483610014697699 | validation: 0.093143217718975]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241955164324301		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.10241955164324301 | validation: 0.10046635996032038]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331536970524302		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.10331536970524302 | validation: 0.09668704528923637]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403137923996372		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.10403137923996372 | validation: 0.09645852522903374]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380960303907934		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.10380960303907934 | validation: 0.10176441940226541]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10208343418985918		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.10208343418985918 | validation: 0.10783734343446653]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10619752720018698		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.10619752720018698 | validation: 0.10935928808340759]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305727775755923		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.10305727775755923 | validation: 0.09933004383236303]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709472157593787		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.10709472157593787 | validation: 0.10313461067732961]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10827802098261577		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.10827802098261577 | validation: 0.10003563683567673]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10761685299961464		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.10761685299961464 | validation: 0.10399723506669575]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131350588112435		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.1131350588112435 | validation: 0.10198214045604304]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083450500320413		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.11083450500320413 | validation: 0.10365126219078608]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360494084555795		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.10360494084555795 | validation: 0.09513125510933339]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10739711539256035		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.10739711539256035 | validation: 0.09908103211090659]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654118606506639		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.10654118606506639 | validation: 0.10293449433882536]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508335145034622		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.10508335145034622 | validation: 0.1059336908573009]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355994011852678		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.11355994011852678 | validation: 0.09453785738305247]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397493110145935		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.10397493110145935 | validation: 0.09761481359981977]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10275517310263727		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.10275517310263727 | validation: 0.0915046608468883]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09978094953758439		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.09978094953758439 | validation: 0.09140776577232067]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050950300308689		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.10050950300308689 | validation: 0.10087425630226672]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073470218365496		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.11073470218365496 | validation: 0.10230768795476226]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10717855162035847		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.10717855162035847 | validation: 0.10826118605228349]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10252280198964726		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.10252280198964726 | validation: 0.10159718333329998]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10126706198135361		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.10126706198135361 | validation: 0.09883962626230287]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10283748661729969		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.10283748661729969 | validation: 0.10214118949080737]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020993235486464		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.1020993235486464 | validation: 0.09446085217666386]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163248697059553		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.10163248697059553 | validation: 0.09344565482704752]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10022205764207089		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.10022205764207089 | validation: 0.09455767260561579]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716767690141544		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.09716767690141544 | validation: 0.1037795127832327]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10280802736935009		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.10280802736935009 | validation: 0.10203822772147778]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232390984960237		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.10232390984960237 | validation: 0.08820212118296976]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162772525970393		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.10162772525970393 | validation: 0.09357527660837851]
	TIME [epoch: 11.6 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10420580942408852		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.10420580942408852 | validation: 0.09771537146325705]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11202386943858608		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.11202386943858608 | validation: 0.10711943814689195]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10822718618732856		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.10822718618732856 | validation: 0.09753534120662917]
	TIME [epoch: 11.6 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790279976115535		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.09790279976115535 | validation: 0.08377795732806322]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1479.pth
	Model improved!!!
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10009335858601061		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.10009335858601061 | validation: 0.09649327025736217]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10723860704946107		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.10723860704946107 | validation: 0.09569653717635344]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683902174228574		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.10683902174228574 | validation: 0.09761208574974001]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892246647813109		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.09892246647813109 | validation: 0.09549113926968578]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10707112921135524		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.10707112921135524 | validation: 0.10308117106783439]
	TIME [epoch: 11.6 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336999054869081		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.10336999054869081 | validation: 0.0969544387215242]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10368550413541952		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.10368550413541952 | validation: 0.09624698256650445]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1026341147463011		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.1026341147463011 | validation: 0.10344613121092891]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10680996633240064		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.10680996633240064 | validation: 0.09752269460550722]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431024106101291		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.10431024106101291 | validation: 0.10522496956426693]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762453614917514		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.09762453614917514 | validation: 0.10383975421014782]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019177830247501		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.1019177830247501 | validation: 0.08942257122996086]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160545664760423		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.10160545664760423 | validation: 0.09471182834708604]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222549328734871		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.10222549328734871 | validation: 0.09635367358037619]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070090776084961		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.10070090776084961 | validation: 0.0985265213019558]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236182679652689		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.10236182679652689 | validation: 0.09882947568570132]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249149872663899		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.10249149872663899 | validation: 0.09533890340915317]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173361126656016		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.10173361126656016 | validation: 0.09915396392980277]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345029477874468		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.10345029477874468 | validation: 0.09733578508024165]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293648224929097		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.10293648224929097 | validation: 0.102989883667641]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10277032402050315		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.10277032402050315 | validation: 0.10025568763125328]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1041026076852654		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.1041026076852654 | validation: 0.0925038830305133]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933681807234958		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.09933681807234958 | validation: 0.0938367995432748]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011779435142265		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.10011779435142265 | validation: 0.10388309469402066]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09746779740982803		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09746779740982803 | validation: 0.09904735770072119]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258663174052234		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.10258663174052234 | validation: 0.1014528604838185]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10284760673285448		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.10284760673285448 | validation: 0.10018949472393414]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114793314912231		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.10114793314912231 | validation: 0.0913749998134967]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223442886978955		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.10223442886978955 | validation: 0.0917462748024753]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113430145381687		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.10113430145381687 | validation: 0.09856309774568184]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10399387997342086		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.10399387997342086 | validation: 0.10394314525587042]
	TIME [epoch: 11.6 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09969185001812597		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.09969185001812597 | validation: 0.1001060250400565]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10278344503590958		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.10278344503590958 | validation: 0.10107757930619787]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566128023655298		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.10566128023655298 | validation: 0.09680457209272227]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146885273532673		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.10146885273532673 | validation: 0.09946171300929649]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025059322342444		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1025059322342444 | validation: 0.09770426408118413]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10610402517004125		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.10610402517004125 | validation: 0.104288850311402]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604391806543864		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.10604391806543864 | validation: 0.10007219436097677]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330700703720255		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.10330700703720255 | validation: 0.10195278285354718]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10350489889841785		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.10350489889841785 | validation: 0.1035337144100592]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357360120897433		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.10357360120897433 | validation: 0.09628227551741404]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10298094556824722		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.10298094556824722 | validation: 0.0995120565044925]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10107134760755423		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.10107134760755423 | validation: 0.0928621117892436]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422048679406812		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.10422048679406812 | validation: 0.10353034615643134]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10453287640465567		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.10453287640465567 | validation: 0.09818746612879553]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043513974823806		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.1043513974823806 | validation: 0.10149197412266509]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195496554919213		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.10195496554919213 | validation: 0.10717917227945996]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452825390704684		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.10452825390704684 | validation: 0.10295253738713146]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111447705916496		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.10111447705916496 | validation: 0.10198717535350497]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10449344560773507		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.10449344560773507 | validation: 0.0987612194305801]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181866209625338		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.10181866209625338 | validation: 0.1056587808098009]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544277152009159		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.10544277152009159 | validation: 0.09274724190607797]
	TIME [epoch: 11.6 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881865854017134		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.10881865854017134 | validation: 0.09680639143056194]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409074523186704		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.10409074523186704 | validation: 0.10436114133830766]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109472473345203		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.10109472473345203 | validation: 0.1038503825463027]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09995483567883234		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.09995483567883234 | validation: 0.099772163327779]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081771390296605		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.1081771390296605 | validation: 0.0993282642417643]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10822376024135859		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.10822376024135859 | validation: 0.098265510222743]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10286174103954474		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.10286174103954474 | validation: 0.09708424078305111]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293332559026402		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.10293332559026402 | validation: 0.09922899277460417]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996341130068721		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.0996341130068721 | validation: 0.09115343165005527]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037854800435812		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.1037854800435812 | validation: 0.10898150108114664]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951284815131861		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.09951284815131861 | validation: 0.09777219923492032]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965164185861298		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.0965164185861298 | validation: 0.09581655005247507]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507190129742244		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.10507190129742244 | validation: 0.09993487115717609]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10822116135429379		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.10822116135429379 | validation: 0.09613670990098383]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10041918448120626		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.10041918448120626 | validation: 0.09754960296692321]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030754862827326		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.10030754862827326 | validation: 0.10167107930927906]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103519067316749		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.103519067316749 | validation: 0.09962810241402181]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10146205992196994		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.10146205992196994 | validation: 0.10296999657688559]
	TIME [epoch: 11.6 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049689816129964		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.10049689816129964 | validation: 0.09818228101408248]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013980964777331		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.1013980964777331 | validation: 0.10094408376085491]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10392548317729722		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.10392548317729722 | validation: 0.09478945432300315]
	TIME [epoch: 11.6 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915471710076868		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.10915471710076868 | validation: 0.10073822341711897]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10285302869567078		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.10285302869567078 | validation: 0.09738743173343703]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204540437441584		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.10204540437441584 | validation: 0.0993062908792016]
	TIME [epoch: 11.6 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10453418056572897		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.10453418056572897 | validation: 0.10719700259671566]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878759957475062		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.10878759957475062 | validation: 0.11701482755953489]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926793501519416		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.10926793501519416 | validation: 0.11245049184528658]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11182154687365561		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.11182154687365561 | validation: 0.11171643471295237]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10729208988564197		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.10729208988564197 | validation: 0.09968814746025534]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10252065864326829		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.10252065864326829 | validation: 0.09398769169602648]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1026936569660941		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.1026936569660941 | validation: 0.0928035249854062]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424147880091855		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.10424147880091855 | validation: 0.10045906956483172]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10257769974031539		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.10257769974031539 | validation: 0.10276871291362745]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443497750477576		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.10443497750477576 | validation: 0.09790206723563859]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422530866448249		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.10422530866448249 | validation: 0.10018701565883534]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10553144020638229		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.10553144020638229 | validation: 0.09059456008975791]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050599450634166		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.1050599450634166 | validation: 0.09288651105583526]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199683217297636		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.10199683217297636 | validation: 0.09438274292350399]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568013792523741		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.10568013792523741 | validation: 0.09248503147795215]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752645869409126		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.10752645869409126 | validation: 0.10184130470648958]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1008182438219353		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.1008182438219353 | validation: 0.09951013488069897]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10287339794210891		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.10287339794210891 | validation: 0.09815428275598242]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905246081464839		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.09905246081464839 | validation: 0.10149738014928346]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044897424173854		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.10044897424173854 | validation: 0.09857104493655715]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10243486952719957		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.10243486952719957 | validation: 0.10269658055774511]
	TIME [epoch: 11.6 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10276023240445056		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.10276023240445056 | validation: 0.0955879849312045]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171041559265685		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.10171041559265685 | validation: 0.10144730009229747]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10266787958582349		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.10266787958582349 | validation: 0.0964453927104631]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09905532623549276		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.09905532623549276 | validation: 0.09327014092628413]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370512412864205		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.10370512412864205 | validation: 0.09684381591884926]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460242714483967		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.10460242714483967 | validation: 0.09771920512133957]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482916416190638		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.10482916416190638 | validation: 0.0896765648762658]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10239547266066451		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.10239547266066451 | validation: 0.08393647753042088]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09917013996502966		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.09917013996502966 | validation: 0.09775056399676413]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10464974014213903		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.10464974014213903 | validation: 0.09516041262130073]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10551369058251446		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.10551369058251446 | validation: 0.10539154980329134]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770022265604462		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.10770022265604462 | validation: 0.09587352259033781]
	TIME [epoch: 11.6 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10303920265984873		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.10303920265984873 | validation: 0.09872492777712141]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10371548917014084		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.10371548917014084 | validation: 0.0908831468909202]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010322588234113		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.1010322588234113 | validation: 0.09881030712711071]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543458270970629		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.10543458270970629 | validation: 0.09610258353433913]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10545739886263093		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.10545739886263093 | validation: 0.10274539357329569]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037148021632142		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.10037148021632142 | validation: 0.09243500878786844]
	TIME [epoch: 11.6 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471995894234595		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.10471995894234595 | validation: 0.09824292454309083]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141138635606296		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.10141138635606296 | validation: 0.10605926275330976]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09997361223750223		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.09997361223750223 | validation: 0.0962054961218084]
	TIME [epoch: 11.6 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10066814587071658		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.10066814587071658 | validation: 0.09662481192251506]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233800916032271		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.10233800916032271 | validation: 0.09446244572484337]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180761203788855		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.10180761203788855 | validation: 0.09792888371916877]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10387236354251186		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.10387236354251186 | validation: 0.10732840672440812]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11079533339131417		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.11079533339131417 | validation: 0.09684398456582613]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099123147503147		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.1099123147503147 | validation: 0.10329149143116649]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809103942520555		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.10809103942520555 | validation: 0.10213224647442357]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10686292913161974		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.10686292913161974 | validation: 0.09749404992616102]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10297853556112012		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.10297853556112012 | validation: 0.09431017313418305]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967127885006843		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.0967127885006843 | validation: 0.09284040621718323]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122445243519568		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.10122445243519568 | validation: 0.1047233247523085]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006300149400191		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.1006300149400191 | validation: 0.08994376615103915]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993820916862359		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.09993820916862359 | validation: 0.09368775536363741]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0997319712407694		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0997319712407694 | validation: 0.1001885671366673]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10264994070819553		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.10264994070819553 | validation: 0.10285344505119742]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542086872841341		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.10542086872841341 | validation: 0.093645240335146]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056023528534312		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.10056023528534312 | validation: 0.10227620167129034]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021523712403688		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.1021523712403688 | validation: 0.0964120534201554]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435886320259138		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.10435886320259138 | validation: 0.09424200378599934]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486967250780972		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.10486967250780972 | validation: 0.1000312520716528]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046961241770952		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.10046961241770952 | validation: 0.09601042106529974]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362631741068801		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.10362631741068801 | validation: 0.09614320245344216]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037306188208202		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.1037306188208202 | validation: 0.1014332304522094]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10215152189107753		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.10215152189107753 | validation: 0.0967208934838255]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10062933970102789		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.10062933970102789 | validation: 0.10749967482747604]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070813150793498		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.10070813150793498 | validation: 0.09283911638893645]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10556255400191339		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.10556255400191339 | validation: 0.09909555397042126]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10252083370778045		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.10252083370778045 | validation: 0.08825509625818119]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09807410399280293		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.09807410399280293 | validation: 0.09426125078929143]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855428288258773		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.09855428288258773 | validation: 0.08716338677684753]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290776950072347		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.10290776950072347 | validation: 0.09931417722901245]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409378060093492		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.10409378060093492 | validation: 0.10391200208290252]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178135276432078		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.10178135276432078 | validation: 0.09734168572555632]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320578404773052		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.10320578404773052 | validation: 0.10507599611458243]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09956744842428064		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.09956744842428064 | validation: 0.10144928893839614]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09588373250190796		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.09588373250190796 | validation: 0.0970956214234461]
	TIME [epoch: 11.6 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10177938469949607		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.10177938469949607 | validation: 0.09249889329746572]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210106838637717		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.10210106838637717 | validation: 0.09547210007728106]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10008594045823012		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.10008594045823012 | validation: 0.09461273734889478]
	TIME [epoch: 11.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10273347607706337		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.10273347607706337 | validation: 0.09596206463314033]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993148508958771		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.09993148508958771 | validation: 0.09571386584202626]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10045637894855305		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.10045637894855305 | validation: 0.10196329778919654]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992699414699223		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0992699414699223 | validation: 0.09702790330610522]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09931577503650746		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.09931577503650746 | validation: 0.09966790162743157]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10456291347655997		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.10456291347655997 | validation: 0.09968290191058868]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09936620093729336		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.09936620093729336 | validation: 0.09209664282238912]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502533466751162		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.09502533466751162 | validation: 0.09447930794662034]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09614920846120589		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.09614920846120589 | validation: 0.0948561596835147]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09936754716352347		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.09936754716352347 | validation: 0.10046993521777652]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238105826802195		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.10238105826802195 | validation: 0.09557160599264894]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038107551604363		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.1038107551604363 | validation: 0.10074082972142176]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849112547650167		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.09849112547650167 | validation: 0.09302604492030007]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09783782298202474		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.09783782298202474 | validation: 0.08991376766303648]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09983741677488472		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.09983741677488472 | validation: 0.0971220998183723]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994264436292874		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.09994264436292874 | validation: 0.10116732044339873]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10177110338782991		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.10177110338782991 | validation: 0.0970511305479148]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203373645278595		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.10203373645278595 | validation: 0.09094850443154869]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020434151742034		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.1020434151742034 | validation: 0.097710182354656]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390624733487555		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.10390624733487555 | validation: 0.10201178296883866]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454571466117978		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.10454571466117978 | validation: 0.10085399142538957]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10225665739378809		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.10225665739378809 | validation: 0.09185396148122121]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10228328572293563		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.10228328572293563 | validation: 0.1035525843652876]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10321885109393288		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.10321885109393288 | validation: 0.09862543523051955]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10192125798811166		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.10192125798811166 | validation: 0.10238021890714948]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958708819971682		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.09958708819971682 | validation: 0.09831113401584572]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924022471921		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.09924022471921 | validation: 0.09951350207481935]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10333959214247637		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.10333959214247637 | validation: 0.10223607066250413]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10183099066047921		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.10183099066047921 | validation: 0.09960108338359142]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565845981830012		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.10565845981830012 | validation: 0.10856258199965346]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184299078014059		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.10184299078014059 | validation: 0.09516834674954977]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998062322516396		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.09998062322516396 | validation: 0.1003620632445163]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546847941776126		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.10546847941776126 | validation: 0.09739122882073774]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10287916397194771		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.10287916397194771 | validation: 0.0982402243669557]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10463498481954406		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.10463498481954406 | validation: 0.10229525622563695]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09928030706641447		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.09928030706641447 | validation: 0.09163657969483346]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10644253385285508		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.10644253385285508 | validation: 0.09468285603854153]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893792953532728		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.09893792953532728 | validation: 0.09266069912898775]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10280044744155163		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.10280044744155163 | validation: 0.09532468981406655]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114028290498901		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.10114028290498901 | validation: 0.10253403619146545]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099978964669748		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.099978964669748 | validation: 0.1049270366673497]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10394240835870805		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.10394240835870805 | validation: 0.09447533711148381]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119138169393951		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.10119138169393951 | validation: 0.09988568232103989]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039753022030475		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.1039753022030475 | validation: 0.09972086241664413]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356885438222277		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.10356885438222277 | validation: 0.10999208962083987]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10132130814981426		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.10132130814981426 | validation: 0.10085002452890124]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176485721427463		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.10176485721427463 | validation: 0.09282943982575365]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506869433154792		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.10506869433154792 | validation: 0.09898568414043672]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332595115772408		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.10332595115772408 | validation: 0.0960427029120747]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023710939308398		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.1023710939308398 | validation: 0.10087311559359752]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442184895797069		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.10442184895797069 | validation: 0.09660092009124441]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926964050988599		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.09926964050988599 | validation: 0.09631219025023988]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10091247598506023		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.10091247598506023 | validation: 0.09410031838124167]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061637243126037		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.10061637243126037 | validation: 0.09551159051903932]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10123535180804863		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.10123535180804863 | validation: 0.10166799416527968]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049669157298426		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.10049669157298426 | validation: 0.10268740172121786]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316934145063328		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.10316934145063328 | validation: 0.09533035571949422]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063664694446967		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.10063664694446967 | validation: 0.09709448479220945]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09863014493193212		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.09863014493193212 | validation: 0.09864397148168486]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099593256137722		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.099593256137722 | validation: 0.09546183929980406]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996952652862484		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.09996952652862484 | validation: 0.0912927061384204]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10109942473189312		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.10109942473189312 | validation: 0.10502712906038192]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713974146208465		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.09713974146208465 | validation: 0.09418492684904056]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629362503876933		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.09629362503876933 | validation: 0.09173763058888237]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082465050672856		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.10082465050672856 | validation: 0.0825687563316833]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r1_20240310_045134/states/model_tr_study204_1701.pth
	Model improved!!!
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09843161792840918		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.09843161792840918 | validation: 0.09370078490281912]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211100258055476		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.10211100258055476 | validation: 0.09485880692704861]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10128728563165512		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.10128728563165512 | validation: 0.09826944720006417]
	TIME [epoch: 11.6 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10358374888922557		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.10358374888922557 | validation: 0.09528831851276916]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09941670410767886		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.09941670410767886 | validation: 0.09249714826364062]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10243681018891933		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.10243681018891933 | validation: 0.10040329570755173]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1028598552351086		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.1028598552351086 | validation: 0.0984005495067122]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037155961222477		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.10037155961222477 | validation: 0.10146889358469194]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10560261204970449		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.10560261204970449 | validation: 0.10291837936382374]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772903095649402		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.09772903095649402 | validation: 0.09534151841048095]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114880756476616		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.10114880756476616 | validation: 0.09852562196108192]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086168355704675		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.10086168355704675 | validation: 0.09936446491504454]
	TIME [epoch: 11.6 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211240009858946		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.10211240009858946 | validation: 0.09858860370641072]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248940947628335		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.10248940947628335 | validation: 0.09392665820212419]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075590315541656		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.10075590315541656 | validation: 0.09285143171712672]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10326470957345385		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.10326470957345385 | validation: 0.09527090292463117]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031192350526433		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.1031192350526433 | validation: 0.099525199242842]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116602005882186		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.10116602005882186 | validation: 0.10097122392606105]
	TIME [epoch: 11.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1025965722785131		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.1025965722785131 | validation: 0.09516905721887618]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09940852424740015		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.09940852424740015 | validation: 0.0922333455960071]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10231203331124922		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.10231203331124922 | validation: 0.09665809601444457]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342886776236544		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.10342886776236544 | validation: 0.10417824501536407]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09950320329157494		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.09950320329157494 | validation: 0.09794117430192432]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573962184829076		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.10573962184829076 | validation: 0.08895786113283789]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195158549344635		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.10195158549344635 | validation: 0.08618030619590605]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681577926728771		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.09681577926728771 | validation: 0.09455403513358274]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031742688850182		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.1031742688850182 | validation: 0.09390746234837971]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409651871996528		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.10409651871996528 | validation: 0.10183717111081197]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10106373288917198		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.10106373288917198 | validation: 0.10038299549163349]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10112162984926087		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.10112162984926087 | validation: 0.0966053759541454]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10144588287715034		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.10144588287715034 | validation: 0.09050486711969985]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10073569386929226		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.10073569386929226 | validation: 0.09711603942165505]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10227124020442939		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.10227124020442939 | validation: 0.09479412977260097]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10444362536671897		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.10444362536671897 | validation: 0.08735509808183185]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09795462318137706		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.09795462318137706 | validation: 0.09692741373610067]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0978956050846066		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.0978956050846066 | validation: 0.09839970881278161]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09707464918490931		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.09707464918490931 | validation: 0.10064328328775422]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09879520054401078		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.09879520054401078 | validation: 0.08739549609335712]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09980710229675321		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.09980710229675321 | validation: 0.09060270701690785]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10043492618629027		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.10043492618629027 | validation: 0.09955573844917445]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034604631950572		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.10034604631950572 | validation: 0.09357303150569289]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020325969762954		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.1020325969762954 | validation: 0.09285070589006868]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199987530224838		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.10199987530224838 | validation: 0.0921436979053609]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113815684545753		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.10113815684545753 | validation: 0.09731954542143077]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985928353774658		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.0985928353774658 | validation: 0.10102819800869942]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09970855365979246		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.09970855365979246 | validation: 0.10260755757925821]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874251084899967		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.09874251084899967 | validation: 0.09426035642168257]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035573849216384		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.1035573849216384 | validation: 0.09817463671002759]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426382818590788		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.10426382818590788 | validation: 0.09246246749847935]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232708217592919		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.10232708217592919 | validation: 0.09458409939222168]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10177724801968568		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.10177724801968568 | validation: 0.09899010444073682]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122923619159235		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.10122923619159235 | validation: 0.09578911444658587]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10150415384045318		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.10150415384045318 | validation: 0.10337222586270692]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631808943496867		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.09631808943496867 | validation: 0.09130242439490222]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211168458167635		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.10211168458167635 | validation: 0.0884885438110944]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775750842056312		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.09775750842056312 | validation: 0.09320045355728389]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10345815965254823		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.10345815965254823 | validation: 0.1065140177612349]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308991930479126		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.10308991930479126 | validation: 0.0960028680574539]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060068258553433		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.10060068258553433 | validation: 0.09798356737671743]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10334738488343781		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.10334738488343781 | validation: 0.09608129726512094]
	TIME [epoch: 11.6 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09927174939499088		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.09927174939499088 | validation: 0.08978151867942337]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875197845544288		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.09875197845544288 | validation: 0.10067492388137396]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991163959596289		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.09991163959596289 | validation: 0.09798840196323098]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935414468602469		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.09935414468602469 | validation: 0.09548249076962258]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416980040248969		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.10416980040248969 | validation: 0.10405726274155949]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10143166871557216		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.10143166871557216 | validation: 0.08995892276000281]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016683223594057		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.1016683223594057 | validation: 0.09942253971624068]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09973513344660054		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.09973513344660054 | validation: 0.10576666773559038]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044897580987924		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.10044897580987924 | validation: 0.09384527432031417]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011299834546882		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.1011299834546882 | validation: 0.09368139403789989]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10022274534512848		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.10022274534512848 | validation: 0.09984993428215853]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925841669425062		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.09925841669425062 | validation: 0.09774385454921479]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10116185938063778		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.10116185938063778 | validation: 0.09700095782077497]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10265013381573151		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.10265013381573151 | validation: 0.08991904812907647]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134860330539719		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.10134860330539719 | validation: 0.09788269609560508]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1007728927807434		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.1007728927807434 | validation: 0.10058506004527164]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291703522279587		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.10291703522279587 | validation: 0.10947743782209707]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10155508576789549		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.10155508576789549 | validation: 0.10033038045063464]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973993170593743		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.0973993170593743 | validation: 0.09453879839424394]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10094948284014132		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.10094948284014132 | validation: 0.09229707120819511]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176178296653206		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.10176178296653206 | validation: 0.09071779169201973]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10157220787584022		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.10157220787584022 | validation: 0.09948809373531908]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10053807868252465		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.10053807868252465 | validation: 0.10345139587065776]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014412280043825		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.1014412280043825 | validation: 0.09818751162041171]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290469171917095		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.10290469171917095 | validation: 0.09639283643054598]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012973665279128		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.1012973665279128 | validation: 0.10049339896565218]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053936021688125		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.1053936021688125 | validation: 0.08769848549255838]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300138803795508		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.10300138803795508 | validation: 0.10286747294260774]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070675639493229		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.10070675639493229 | validation: 0.09895865846379692]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09645312784675801		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.09645312784675801 | validation: 0.09012567858271094]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016355108503694		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.10016355108503694 | validation: 0.10356489022151742]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10205416406759972		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.10205416406759972 | validation: 0.10257675221420223]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246760301138237		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.10246760301138237 | validation: 0.09564891017325819]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10745753376613847		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.10745753376613847 | validation: 0.09856640484817089]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294812435747971		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.10294812435747971 | validation: 0.1078736689903678]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09910657377356358		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.09910657377356358 | validation: 0.1035888686224683]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111286343348844		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.10111286343348844 | validation: 0.09093295604613306]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09934714135211688		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.09934714135211688 | validation: 0.09766063528414871]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09835442925705222		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.09835442925705222 | validation: 0.10342293589998729]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631378060825252		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.09631378060825252 | validation: 0.09342791008465146]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336380661720548		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.10336380661720548 | validation: 0.10250656588568934]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10264428846602436		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.10264428846602436 | validation: 0.09668634378248438]
	TIME [epoch: 11.6 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10523933547441641		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.10523933547441641 | validation: 0.09020313041155063]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09775699440290983		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.09775699440290983 | validation: 0.09426630901900268]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09817356120335		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.09817356120335 | validation: 0.08313357430003133]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0989237294363926		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.0989237294363926 | validation: 0.09068592483666686]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844834277517438		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.09844834277517438 | validation: 0.0932973577296825]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742007121627469		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.09742007121627469 | validation: 0.09314989808216419]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035725798761143		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.10035725798761143 | validation: 0.09601087764998202]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09803568191491374		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.09803568191491374 | validation: 0.08932657999617505]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10029896821636258		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.10029896821636258 | validation: 0.10107493757673341]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804088608371023		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.09804088608371023 | validation: 0.09794781374335232]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10161280386217494		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.10161280386217494 | validation: 0.09302299663583796]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691036213872103		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.09691036213872103 | validation: 0.09639360204826009]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659741178709583		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.09659741178709583 | validation: 0.1059312712341531]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09768804006698761		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.09768804006698761 | validation: 0.10055633736572947]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110434647599868		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.10110434647599868 | validation: 0.09469716729621917]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893664211799588		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.09893664211799588 | validation: 0.10395783798748384]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216479891696821		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.10216479891696821 | validation: 0.09943473035153112]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09955301309808236		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.09955301309808236 | validation: 0.09465903955368997]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017999365218502		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.10017999365218502 | validation: 0.10040769110087454]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316251307525152		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.10316251307525152 | validation: 0.10145491387629699]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357578465443071		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.10357578465443071 | validation: 0.09353622730535265]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10009994365723154		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.10009994365723154 | validation: 0.10253908123506218]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09810990278154405		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.09810990278154405 | validation: 0.1013745487801408]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09791146212408183		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.09791146212408183 | validation: 0.10037599996974596]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0987041642638929		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.0987041642638929 | validation: 0.10106430331209733]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119476775977371		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.10119476775977371 | validation: 0.09118953859547026]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985193690349733		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0985193690349733 | validation: 0.09268595559120382]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620906533271227		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.09620906533271227 | validation: 0.09680173547567901]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09922077732431922		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.09922077732431922 | validation: 0.09173878944376107]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765591297959819		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.09765591297959819 | validation: 0.09868401348502844]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893673802633327		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.09893673802633327 | validation: 0.0967996121380596]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10171368118776147		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.10171368118776147 | validation: 0.09644522262363221]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087101731906337		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.10087101731906337 | validation: 0.09998342405413173]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09951318079635649		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.09951318079635649 | validation: 0.09688756845580297]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818566455960946		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.09818566455960946 | validation: 0.08749053200501766]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111781437016809		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.10111781437016809 | validation: 0.1073789389628799]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347724455381666		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.10347724455381666 | validation: 0.10103246556791697]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659349019852842		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.10659349019852842 | validation: 0.09112971107087635]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356552828156872		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.10356552828156872 | validation: 0.0988291252988784]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10190492474158067		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.10190492474158067 | validation: 0.0938717016514132]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214739727916947		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.10214739727916947 | validation: 0.0958592950531967]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042600627312949		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.10042600627312949 | validation: 0.09596574008516182]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403549274326042		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.10403549274326042 | validation: 0.09449883571180515]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10209562699744036		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.10209562699744036 | validation: 0.09379467925499518]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10158922143749874		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.10158922143749874 | validation: 0.09775505045121655]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422970192484554		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.10422970192484554 | validation: 0.0964271607710813]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180319954058063		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.10180319954058063 | validation: 0.08914256074899467]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509777607955132		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.09509777607955132 | validation: 0.10691862583918864]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641119006143276		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.09641119006143276 | validation: 0.09809827708906568]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09645822423916522		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.09645822423916522 | validation: 0.09029174553071348]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050889928923462		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.10050889928923462 | validation: 0.09855614508202258]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09976094014815698		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.09976094014815698 | validation: 0.0975828481530462]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178188863435009		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.10178188863435009 | validation: 0.08844447185656872]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710337851075551		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.09710337851075551 | validation: 0.0962086990131026]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10117259566412587		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.10117259566412587 | validation: 0.09453360804183725]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10020180791841025		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.10020180791841025 | validation: 0.09407860531226632]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102495619700029		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.10102495619700029 | validation: 0.09427465986265982]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214535053910583		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.10214535053910583 | validation: 0.09324969238901823]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037555006315357		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.10037555006315357 | validation: 0.09574577714267234]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10461873133261207		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.10461873133261207 | validation: 0.08869573614689447]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10431275532047651		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.10431275532047651 | validation: 0.09582410270163927]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262769879653985		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.10262769879653985 | validation: 0.09437395882692716]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499090979543425		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.10499090979543425 | validation: 0.09637669290404853]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09897076067876318		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.09897076067876318 | validation: 0.0864011690195351]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134607698579896		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.10134607698579896 | validation: 0.10124488013718352]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233106724012105		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.10233106724012105 | validation: 0.0936797192166172]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975728927461047		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.09975728927461047 | validation: 0.09547240329220985]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736908091310045		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.09736908091310045 | validation: 0.09853587772773896]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562086025444055		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.10562086025444055 | validation: 0.09116566527289649]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09943268088493457		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.09943268088493457 | validation: 0.09742728146375168]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998448463664847		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.09998448463664847 | validation: 0.08687383299172101]
	TIME [epoch: 11.6 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09974242707350284		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.09974242707350284 | validation: 0.09436533666058099]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09901452270038447		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.09901452270038447 | validation: 0.10058343804871964]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184024600014373		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.10184024600014373 | validation: 0.09949426126755312]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019111171357672		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.10019111171357672 | validation: 0.09613896300647358]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10058306607607786		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.10058306607607786 | validation: 0.0865373321525513]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975360858115456		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.09975360858115456 | validation: 0.0980854242407542]
	TIME [epoch: 11.6 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097242639894722		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.097242639894722 | validation: 0.10573506345333304]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10410041695653006		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.10410041695653006 | validation: 0.09593515993619497]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914302867225805		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.09914302867225805 | validation: 0.0966547556143858]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10060938237230452		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.10060938237230452 | validation: 0.08691302941977884]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299022871455933		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.10299022871455933 | validation: 0.09204331943764879]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293032030821594		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.10293032030821594 | validation: 0.0928008568270856]
	TIME [epoch: 11.6 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131743900925767		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.10131743900925767 | validation: 0.09873582312361315]
	TIME [epoch: 11.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09745499254997972		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.09745499254997972 | validation: 0.10793203488059686]
	TIME [epoch: 11.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10302043989889062		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.10302043989889062 | validation: 0.09362606182164862]
	TIME [epoch: 11.5 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09938173336681341		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.09938173336681341 | validation: 0.08960769218244312]
	TIME [epoch: 11.5 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10247043445178994		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.10247043445178994 | validation: 0.10282494945891946]
	TIME [epoch: 11.5 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839778569483607		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.09839778569483607 | validation: 0.1006239217227202]
	TIME [epoch: 11.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912097438619341		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.09912097438619341 | validation: 0.1031012245195303]
	TIME [epoch: 11.5 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09802724967007133		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.09802724967007133 | validation: 0.10483216756987272]
	TIME [epoch: 11.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178791603041541		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.10178791603041541 | validation: 0.0969090439550575]
	TIME [epoch: 11.6 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097326714049833		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.10097326714049833 | validation: 0.10357394072987199]
	TIME [epoch: 11.5 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908740458123039		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.09908740458123039 | validation: 0.09848862023412021]
	TIME [epoch: 11.5 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09941612614111794		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.09941612614111794 | validation: 0.09218204134486475]
	TIME [epoch: 11.6 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10235082597659746		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.10235082597659746 | validation: 0.10104892088343881]
	TIME [epoch: 11.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050109800409995		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.10050109800409995 | validation: 0.09601501032532554]
	TIME [epoch: 11.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214780350731542		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.10214780350731542 | validation: 0.09872297638630662]
	TIME [epoch: 11.6 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10057625544385207		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.10057625544385207 | validation: 0.0961522538659323]
	TIME [epoch: 11.5 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10101145299801578		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.10101145299801578 | validation: 0.08738425756605185]
	TIME [epoch: 11.5 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09980118240557875		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.09980118240557875 | validation: 0.1013394266925754]
	TIME [epoch: 11.6 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237698419229718		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.10237698419229718 | validation: 0.09662454335776838]
	TIME [epoch: 11.5 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10259763012250049		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.10259763012250049 | validation: 0.10052289574649342]
	TIME [epoch: 11.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009752831453265		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.1009752831453265 | validation: 0.09523090526809945]
	TIME [epoch: 11.6 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052266485338962		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.10052266485338962 | validation: 0.0968140453545338]
	TIME [epoch: 11.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09921493430169216		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.09921493430169216 | validation: 0.09923965506679266]
	TIME [epoch: 11.5 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102756859462744		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.102756859462744 | validation: 0.09678754456644488]
	TIME [epoch: 11.6 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000557687802837		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.10000557687802837 | validation: 0.09598899674703093]
	TIME [epoch: 11.5 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237600024662011		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.10237600024662011 | validation: 0.09217311872139419]
	TIME [epoch: 11.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09922905111945968		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.09922905111945968 | validation: 0.0919255932365493]
	TIME [epoch: 11.6 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354079156107535		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.10354079156107535 | validation: 0.09629915943273404]
	TIME [epoch: 11.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017011296113814		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.1017011296113814 | validation: 0.09045855653546771]
	TIME [epoch: 11.5 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10236237141600478		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.10236237141600478 | validation: 0.09827982643364451]
	TIME [epoch: 11.6 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030147504667972		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.10030147504667972 | validation: 0.09723348740795927]
	TIME [epoch: 11.5 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10120038847194282		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.10120038847194282 | validation: 0.09610728962230194]
	TIME [epoch: 11.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984690452837414		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.0984690452837414 | validation: 0.09204067082162806]
	TIME [epoch: 11.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114188874512939		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.10114188874512939 | validation: 0.09944942445472699]
	TIME [epoch: 11.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10450838077137242		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.10450838077137242 | validation: 0.10301910910131155]
	TIME [epoch: 11.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10520970516006922		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.10520970516006922 | validation: 0.09430170563249769]
	TIME [epoch: 11.6 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596494337266205		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.10596494337266205 | validation: 0.10412524241188287]
	TIME [epoch: 11.5 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10232261195773228		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.10232261195773228 | validation: 0.0936258769604483]
	TIME [epoch: 11.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241895572804358		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.10241895572804358 | validation: 0.08960403675751952]
	TIME [epoch: 11.5 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10681013861641427		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.10681013861641427 | validation: 0.0997187497965151]
	TIME [epoch: 11.5 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889675016058377		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.09889675016058377 | validation: 0.09836720464523896]
	TIME [epoch: 11.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200059382416803		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.10200059382416803 | validation: 0.0959407395214179]
	TIME [epoch: 11.6 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222541872391806		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.10222541872391806 | validation: 0.10040812412240976]
	TIME [epoch: 11.5 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710389823520214		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.09710389823520214 | validation: 0.09268830545352554]
	TIME [epoch: 11.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185779725205843		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.10185779725205843 | validation: 0.09529772460868881]
	TIME [epoch: 11.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991519811888667		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.0991519811888667 | validation: 0.08580134938680933]
	TIME [epoch: 11.5 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09837355103305669		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.09837355103305669 | validation: 0.09750543262203593]
	TIME [epoch: 11.5 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991440063903105		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.09991440063903105 | validation: 0.09766229226756912]
	TIME [epoch: 11.5 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09755062593238886		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.09755062593238886 | validation: 0.1007877235434241]
	TIME [epoch: 11.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051128380192284		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.10051128380192284 | validation: 0.09149613529444876]
	TIME [epoch: 11.5 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09656185378748873		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.09656185378748873 | validation: 0.098220468417595]
	TIME [epoch: 11.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09698501204763085		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.09698501204763085 | validation: 0.09905010204575064]
	TIME [epoch: 11.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004359005002036		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.1004359005002036 | validation: 0.09011788703571963]
	TIME [epoch: 11.6 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10312419806628706		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.10312419806628706 | validation: 0.10384978776340381]
	TIME [epoch: 11.5 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031106119006347		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.1031106119006347 | validation: 0.09261681698709377]
	TIME [epoch: 11.5 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09887569930766975		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.09887569930766975 | validation: 0.09751883571464343]
	TIME [epoch: 11.6 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10135211565750923		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.10135211565750923 | validation: 0.09377026144028947]
	TIME [epoch: 11.5 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10157611603513078		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.10157611603513078 | validation: 0.0941442438462486]
	TIME [epoch: 11.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10383131968659023		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.10383131968659023 | validation: 0.09374149091919218]
	TIME [epoch: 11.6 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167695052836628		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.10167695052836628 | validation: 0.09502865356323077]
	TIME [epoch: 11.5 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100154290131255		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.100154290131255 | validation: 0.0941262459531798]
	TIME [epoch: 11.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09961287678965443		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.09961287678965443 | validation: 0.1014822050270714]
	TIME [epoch: 11.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10135497318137136		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.10135497318137136 | validation: 0.08779016153581028]
	TIME [epoch: 11.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09866633171247371		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.09866633171247371 | validation: 0.08708998362203872]
	TIME [epoch: 11.5 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097178179799252		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.10097178179799252 | validation: 0.09125062727446377]
	TIME [epoch: 11.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916691910430858		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.09916691910430858 | validation: 0.08928944105757665]
	TIME [epoch: 11.5 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878587780243535		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.09878587780243535 | validation: 0.09995733840890463]
	TIME [epoch: 11.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982076123165168		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.09982076123165168 | validation: 0.09857896279312836]
	TIME [epoch: 11.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09641540405358752		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.09641540405358752 | validation: 0.08855890632830772]
	TIME [epoch: 11.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011725040179001		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.1011725040179001 | validation: 0.09526628719780926]
	TIME [epoch: 11.5 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10378041451320669		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.10378041451320669 | validation: 0.09852033848215655]
	TIME [epoch: 11.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246736890825509		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.10246736890825509 | validation: 0.09713327779014001]
	TIME [epoch: 11.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048205778228972		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.10048205778228972 | validation: 0.09834212010683895]
	TIME [epoch: 11.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188984725826843		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.10188984725826843 | validation: 0.0977733731318947]
	TIME [epoch: 11.6 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906018665349371		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.09906018665349371 | validation: 0.09557130209185694]
	TIME [epoch: 11.5 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992607200743783		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.09992607200743783 | validation: 0.09693415979081438]
	TIME [epoch: 11.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09774308433338662		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.09774308433338662 | validation: 0.0908665704902477]
	TIME [epoch: 11.6 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489186916129659		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.10489186916129659 | validation: 0.09548595187237144]
	TIME [epoch: 11.5 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134454966727977		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.10134454966727977 | validation: 0.09879294981821085]
	TIME [epoch: 11.5 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09846455258597935		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.09846455258597935 | validation: 0.10346360771510012]
	TIME [epoch: 11.6 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038088589653156		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.10038088589653156 | validation: 0.09275304769698942]
	TIME [epoch: 11.5 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10043828080430775		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.10043828080430775 | validation: 0.10806641829990823]
	TIME [epoch: 11.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990982343921915		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.0990982343921915 | validation: 0.09661016265053275]
	TIME [epoch: 11.5 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999758099502686		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0999758099502686 | validation: 0.09314776060913073]
	TIME [epoch: 11.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967954424102618		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.0967954424102618 | validation: 0.09190068371380723]
	TIME [epoch: 11.5 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09840155837083239		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.09840155837083239 | validation: 0.10033412127407683]
	TIME [epoch: 11.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10044889439873196		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.10044889439873196 | validation: 0.09235689448188893]
	TIME [epoch: 11.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003645669674283		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.10003645669674283 | validation: 0.09253492429250786]
	TIME [epoch: 11.5 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063370460859977		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.10063370460859977 | validation: 0.0950028323379183]
	TIME [epoch: 11.6 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10125250270234926		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.10125250270234926 | validation: 0.09905976089303285]
	TIME [epoch: 11.5 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893983121823477		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.09893983121823477 | validation: 0.09268041195424362]
	TIME [epoch: 11.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09725216213604387		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.09725216213604387 | validation: 0.09437195769202095]
	TIME [epoch: 11.5 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939491519484896		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.09939491519484896 | validation: 0.09864494642317898]
	TIME [epoch: 11.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695326089752801		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.09695326089752801 | validation: 0.09975434193369763]
	TIME [epoch: 11.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10217063057840593		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.10217063057840593 | validation: 0.10053253102354298]
	TIME [epoch: 11.6 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0996423490214661		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.0996423490214661 | validation: 0.10326310007734595]
	TIME [epoch: 11.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10015815541558748		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.10015815541558748 | validation: 0.09734590026809613]
	TIME [epoch: 11.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10061526041522396		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.10061526041522396 | validation: 0.10127600429477233]
	TIME [epoch: 11.6 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10094551037050398		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.10094551037050398 | validation: 0.09191429361441192]
	TIME [epoch: 11.6 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09745346382607847		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.09745346382607847 | validation: 0.09949523385033686]
	TIME [epoch: 11.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004475175954231		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.1004475175954231 | validation: 0.08654239329605914]
	TIME [epoch: 11.6 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09911248747884828		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.09911248747884828 | validation: 0.09807083201047234]
	TIME [epoch: 11.5 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09892460565616049		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.09892460565616049 | validation: 0.09630618029174066]
	TIME [epoch: 11.5 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042998960593319		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.10042998960593319 | validation: 0.09823049036162498]
	TIME [epoch: 11.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09957948653532384		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.09957948653532384 | validation: 0.09939418807262819]
	TIME [epoch: 11.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0967878516541486		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.0967878516541486 | validation: 0.08859494779569989]
	TIME [epoch: 11.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10015191404348221		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.10015191404348221 | validation: 0.09183217528224112]
	TIME [epoch: 11.6 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127228925055148		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.10127228925055148 | validation: 0.09650330463634132]
	TIME [epoch: 11.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048416466490118		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.10048416466490118 | validation: 0.08909114750044747]
	TIME [epoch: 11.5 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033912745367413		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.10033912745367413 | validation: 0.09888876491931914]
	TIME [epoch: 11.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035010099313567		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.10035010099313567 | validation: 0.09792380223783342]
	TIME [epoch: 11.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102546602914873		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.10102546602914873 | validation: 0.09504578015932479]
	TIME [epoch: 11.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993751125876953		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.09993751125876953 | validation: 0.1042648918589047]
	TIME [epoch: 11.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09926244834571948		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.09926244834571948 | validation: 0.08914800686612222]
	TIME [epoch: 11.5 sec]
Finished training in 23290.416 seconds.
