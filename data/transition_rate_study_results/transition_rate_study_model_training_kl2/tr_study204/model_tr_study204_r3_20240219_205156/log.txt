Args:
Namespace(name='model_tr_study204', outdir='out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3', training_data='data/transition_rate_studies/tr_study204/tr_study204_training/r3', validation_data='data/transition_rate_studies/tr_study204/tr_study204_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.075, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2796205583

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/10] avg loss: 10.781265406529347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.781265406529347 | validation: 10.840740134592657]
	TIME [epoch: 53.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/10] avg loss: 9.45599200227333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.45599200227333 | validation: 7.362027256026668]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.886061629008973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.886061629008973 | validation: 8.112462000784502]
	TIME [epoch: 8.47 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 10/10] avg loss: 6.155690921551687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.155690921551687 | validation: 6.560628954991876]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/10] avg loss: 5.397930933231306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.397930933231306 | validation: 5.680488908713115]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.899193535432522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.899193535432522 | validation: 5.9629115670560235]
	TIME [epoch: 8.44 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.842434987656898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.842434987656898 | validation: 5.764184831954768]
	TIME [epoch: 8.47 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.770714580907237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.770714580907237 | validation: 5.3316664944661945]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.50570093367728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.50570093367728 | validation: 6.02323662463454]
	TIME [epoch: 8.44 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.592411218913826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.592411218913826 | validation: 5.079917292675901]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.41188549925195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.41188549925195 | validation: 4.884752538742404]
	TIME [epoch: 8.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.279133030794802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.279133030794802 | validation: 4.876587975354214]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.17782093283739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.17782093283739 | validation: 5.636844346182029]
	TIME [epoch: 8.44 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.183073089318658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.183073089318658 | validation: 5.295004791385622]
	TIME [epoch: 8.47 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.201515168451105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.201515168451105 | validation: 4.762141260567886]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9830295113253578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9830295113253578 | validation: 4.639865719707451]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.941322081298696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.941322081298696 | validation: 4.671532625428588]
	TIME [epoch: 8.44 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.003235447681921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.003235447681921 | validation: 4.855605973265297]
	TIME [epoch: 8.46 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8506787147640695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8506787147640695 | validation: 5.999779371019249]
	TIME [epoch: 8.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.9254831239008197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9254831239008197 | validation: 4.6610155854985535]
	TIME [epoch: 8.44 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8729036461190467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8729036461190467 | validation: 4.5844475141403045]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.75362973775846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.75362973775846 | validation: 5.097872249847246]
	TIME [epoch: 8.46 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7998210870684446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7998210870684446 | validation: 4.928588222965118]
	TIME [epoch: 8.44 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8115969277350645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8115969277350645 | validation: 4.54702076598604]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.7504838240861282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7504838240861282 | validation: 4.647127447978088]
	TIME [epoch: 8.48 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.784960678776808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.784960678776808 | validation: 4.723306505742923]
	TIME [epoch: 8.45 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.764615103639116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.764615103639116 | validation: 4.4224800747445645]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.637506435598914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.637506435598914 | validation: 4.6236198177064765]
	TIME [epoch: 8.43 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5763398288748727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5763398288748727 | validation: 5.713583248789103]
	TIME [epoch: 8.46 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.8576168621356453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8576168621356453 | validation: 4.347415814745485]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5876975412681738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5876975412681738 | validation: 4.470374652351016]
	TIME [epoch: 8.43 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.658357095358845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.658357095358845 | validation: 4.351527607548851]
	TIME [epoch: 8.45 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6029979216693606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6029979216693606 | validation: 4.367394323227893]
	TIME [epoch: 8.46 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6323405654696352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6323405654696352 | validation: 4.36378704278201]
	TIME [epoch: 8.44 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5545489364384806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5545489364384806 | validation: 4.680762818223986]
	TIME [epoch: 8.44 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.722301549997854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.722301549997854 | validation: 4.346771855679129]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.600657973285293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.600657973285293 | validation: 4.251874356236006]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5623630626915945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5623630626915945 | validation: 4.6834642443682775]
	TIME [epoch: 8.44 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.6257950270991897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6257950270991897 | validation: 4.420862782330592]
	TIME [epoch: 8.44 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5383465946761836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5383465946761836 | validation: 4.281941287548406]
	TIME [epoch: 8.46 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5337987881339514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5337987881339514 | validation: 4.282266389707813]
	TIME [epoch: 8.44 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.549623521009713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.549623521009713 | validation: 4.300552082421789]
	TIME [epoch: 8.43 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4989158394170516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4989158394170516 | validation: 4.226512780994863]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4530272753758156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4530272753758156 | validation: 4.443578495225673]
	TIME [epoch: 8.46 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5518832509989244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5518832509989244 | validation: 4.29571723345633]
	TIME [epoch: 8.44 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4437042192126777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4437042192126777 | validation: 4.350388302237337]
	TIME [epoch: 8.43 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5319171577155815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5319171577155815 | validation: 4.399472219040643]
	TIME [epoch: 8.44 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4217130082533123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4217130082533123 | validation: 4.417375287236157]
	TIME [epoch: 8.46 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.599843529025872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.599843529025872 | validation: 4.2255321838798725]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4311496195176368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4311496195176368 | validation: 4.308173774610502]
	TIME [epoch: 8.45 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.569093714472482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.569093714472482 | validation: 4.293518961717822]
	TIME [epoch: 8.45 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.433638174349748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.433638174349748 | validation: 4.19646380884717]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5134815683880602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5134815683880602 | validation: 4.167373551503368]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.603882831155256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.603882831155256 | validation: 4.667902305076218]
	TIME [epoch: 8.44 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4802761626442282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4802761626442282 | validation: 4.471672512597414]
	TIME [epoch: 8.46 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4402033598878945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4402033598878945 | validation: 4.41465046204046]
	TIME [epoch: 8.44 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4058963275480423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4058963275480423 | validation: 4.214417461552517]
	TIME [epoch: 8.44 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4377006324382173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4377006324382173 | validation: 4.2136996217014815]
	TIME [epoch: 8.44 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3935259445606176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3935259445606176 | validation: 4.163551572919754]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 10/10] avg loss: 4.031221597257895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.031221597257895 | validation: 4.272440776993491]
	TIME [epoch: 8.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4153513093627055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4153513093627055 | validation: 4.263176683671255]
	TIME [epoch: 8.43 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3684096085259285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3684096085259285 | validation: 4.753067280675188]
	TIME [epoch: 8.44 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4256360203300935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4256360203300935 | validation: 4.2155254311673]
	TIME [epoch: 8.45 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.2868601437459133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2868601437459133 | validation: 4.3995832219958055]
	TIME [epoch: 8.43 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.4838051876776275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4838051876776275 | validation: 4.4329308816365725]
	TIME [epoch: 8.43 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3354525934166652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3354525934166652 | validation: 4.555939428428108]
	TIME [epoch: 8.46 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5114227404647878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5114227404647878 | validation: 4.334555575329006]
	TIME [epoch: 8.44 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.39580515761032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.39580515761032 | validation: 4.2211115200914815]
	TIME [epoch: 8.43 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.429884404208611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.429884404208611 | validation: 4.171332568041278]
	TIME [epoch: 8.44 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.349796807253951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.349796807253951 | validation: 4.239639685956414]
	TIME [epoch: 8.46 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3315726247489876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3315726247489876 | validation: 4.213065072848879]
	TIME [epoch: 8.44 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.374769803110035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.374769803110035 | validation: 4.531766111202378]
	TIME [epoch: 8.43 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.388488068967348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.388488068967348 | validation: 4.135106691355878]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3694849690153603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3694849690153603 | validation: 4.417065269745492]
	TIME [epoch: 8.46 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.350986129047027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.350986129047027 | validation: 4.1323391192685985]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3543518449424945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3543518449424945 | validation: 4.222196147248502]
	TIME [epoch: 8.43 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3124383203754193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3124383203754193 | validation: 4.15334426916939]
	TIME [epoch: 8.45 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.3292770503301234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3292770503301234 | validation: 4.133395268765753]
	TIME [epoch: 8.45 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.355731661120069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.355731661120069 | validation: 4.116177693652157]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/10] avg loss: 3.5333611195070533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5333611195070533 | validation: 3.431164277068728]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 10/10] avg loss: 2.0939596819037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0939596819037 | validation: 2.7128063375165468]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.8892389645118695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8892389645118695 | validation: 2.9636435872491242]
	TIME [epoch: 8.45 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.7264423390142092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7264423390142092 | validation: 2.923748369452836]
	TIME [epoch: 8.44 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5756245933381443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5756245933381443 | validation: 3.0479354146395705]
	TIME [epoch: 8.44 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.5292375171491694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5292375171491694 | validation: 2.246883624249204]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.2267901580882374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2267901580882374 | validation: 1.5284321509390142]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.287281230176572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.287281230176572 | validation: 1.2962501906423145]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/10] avg loss: 1.0099644337935871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0099644337935871 | validation: 1.0406459403020487]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8990213356221259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8990213356221259 | validation: 1.4841174024122952]
	TIME [epoch: 8.46 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9198499941659021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9198499941659021 | validation: 1.0296688765264448]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8437284967781554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8437284967781554 | validation: 0.9614393662796207]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8350577492656133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8350577492656133 | validation: 1.0045236833482512]
	TIME [epoch: 8.46 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7917401757850899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7917401757850899 | validation: 1.6576110126868278]
	TIME [epoch: 8.44 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.9764384154614701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9764384154614701 | validation: 0.7799901851295398]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7580045095956357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7580045095956357 | validation: 0.8258313990677466]
	TIME [epoch: 8.43 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7813747813163687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7813747813163687 | validation: 0.6618612641675665]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7493783812856437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7493783812856437 | validation: 0.8405887138617308]
	TIME [epoch: 8.44 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6515206118099208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6515206118099208 | validation: 0.627934337810637]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6660062127203192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6660062127203192 | validation: 0.5028794195374375]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8543411009514541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8543411009514541 | validation: 0.6693553832300534]
	TIME [epoch: 8.46 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7609231102387926		[learning rate: 0.0099673]
	Learning Rate: 0.00996733
	LOSS [training: 0.7609231102387926 | validation: 0.5209122940827572]
	TIME [epoch: 8.43 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7143964268533441		[learning rate: 0.0099312]
	Learning Rate: 0.00993116
	LOSS [training: 0.7143964268533441 | validation: 0.6593515065123885]
	TIME [epoch: 8.43 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7208888220201094		[learning rate: 0.0098951]
	Learning Rate: 0.00989512
	LOSS [training: 0.7208888220201094 | validation: 0.7171478486733863]
	TIME [epoch: 8.43 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7096459527097073		[learning rate: 0.0098592]
	Learning Rate: 0.00985921
	LOSS [training: 0.7096459527097073 | validation: 0.7670108396701802]
	TIME [epoch: 8.46 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.741640843996506		[learning rate: 0.0098234]
	Learning Rate: 0.00982343
	LOSS [training: 0.741640843996506 | validation: 0.648367723056284]
	TIME [epoch: 8.43 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7750475686146364		[learning rate: 0.0097878]
	Learning Rate: 0.00978778
	LOSS [training: 0.7750475686146364 | validation: 0.6230663213336363]
	TIME [epoch: 8.43 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6482691741521538		[learning rate: 0.0097523]
	Learning Rate: 0.00975226
	LOSS [training: 0.6482691741521538 | validation: 0.8749398778642363]
	TIME [epoch: 8.44 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6518966945880911		[learning rate: 0.0097169]
	Learning Rate: 0.00971687
	LOSS [training: 0.6518966945880911 | validation: 0.4755186859035197]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6331092836708161		[learning rate: 0.0096816]
	Learning Rate: 0.0096816
	LOSS [training: 0.6331092836708161 | validation: 0.6108100715697447]
	TIME [epoch: 8.43 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7224576525367615		[learning rate: 0.0096465]
	Learning Rate: 0.00964647
	LOSS [training: 0.7224576525367615 | validation: 0.8454452497410769]
	TIME [epoch: 8.43 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6777012411885357		[learning rate: 0.0096115]
	Learning Rate: 0.00961146
	LOSS [training: 0.6777012411885357 | validation: 0.4841221179336651]
	TIME [epoch: 8.46 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7717712697235848		[learning rate: 0.0095766]
	Learning Rate: 0.00957658
	LOSS [training: 0.7717712697235848 | validation: 0.8442946609020174]
	TIME [epoch: 8.43 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6181553045625825		[learning rate: 0.0095418]
	Learning Rate: 0.00954183
	LOSS [training: 0.6181553045625825 | validation: 0.5587599705147119]
	TIME [epoch: 8.43 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6344286862537072		[learning rate: 0.0095072]
	Learning Rate: 0.0095072
	LOSS [training: 0.6344286862537072 | validation: 0.8126537704429082]
	TIME [epoch: 8.43 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8850205149312185		[learning rate: 0.0094727]
	Learning Rate: 0.0094727
	LOSS [training: 0.8850205149312185 | validation: 0.5919587162173962]
	TIME [epoch: 8.46 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5379416823162255		[learning rate: 0.0094383]
	Learning Rate: 0.00943832
	LOSS [training: 0.5379416823162255 | validation: 0.901181990290721]
	TIME [epoch: 8.43 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5732745061818748		[learning rate: 0.0094041]
	Learning Rate: 0.00940407
	LOSS [training: 0.5732745061818748 | validation: 1.1644422444481732]
	TIME [epoch: 8.43 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6413486009351164		[learning rate: 0.0093699]
	Learning Rate: 0.00936994
	LOSS [training: 0.6413486009351164 | validation: 0.6577260840159187]
	TIME [epoch: 8.44 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6138715544442634		[learning rate: 0.0093359]
	Learning Rate: 0.00933594
	LOSS [training: 0.6138715544442634 | validation: 0.49803833715530305]
	TIME [epoch: 8.46 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5996176659430621		[learning rate: 0.0093021]
	Learning Rate: 0.00930206
	LOSS [training: 0.5996176659430621 | validation: 0.905348061427091]
	TIME [epoch: 8.43 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6021684260700787		[learning rate: 0.0092683]
	Learning Rate: 0.0092683
	LOSS [training: 0.6021684260700787 | validation: 1.45103817722832]
	TIME [epoch: 8.44 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.7128488989995391		[learning rate: 0.0092347]
	Learning Rate: 0.00923466
	LOSS [training: 0.7128488989995391 | validation: 0.724844603929643]
	TIME [epoch: 8.44 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.671815489541419		[learning rate: 0.0092011]
	Learning Rate: 0.00920115
	LOSS [training: 0.671815489541419 | validation: 1.001985032911943]
	TIME [epoch: 8.45 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5922693958736707		[learning rate: 0.0091678]
	Learning Rate: 0.00916776
	LOSS [training: 0.5922693958736707 | validation: 0.6414703968887918]
	TIME [epoch: 8.43 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5216034063857695		[learning rate: 0.0091345]
	Learning Rate: 0.00913449
	LOSS [training: 0.5216034063857695 | validation: 0.8317733485894944]
	TIME [epoch: 8.43 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6272426728250567		[learning rate: 0.0091013]
	Learning Rate: 0.00910134
	LOSS [training: 0.6272426728250567 | validation: 0.47588305620485116]
	TIME [epoch: 8.45 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.638910357775906		[learning rate: 0.0090683]
	Learning Rate: 0.00906831
	LOSS [training: 0.638910357775906 | validation: 0.4407053536134574]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6528084277292836		[learning rate: 0.0090354]
	Learning Rate: 0.0090354
	LOSS [training: 0.6528084277292836 | validation: 0.46758520388877445]
	TIME [epoch: 8.43 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5756262135520042		[learning rate: 0.0090026]
	Learning Rate: 0.00900261
	LOSS [training: 0.5756262135520042 | validation: 0.6088574398235936]
	TIME [epoch: 8.42 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5620419921924857		[learning rate: 0.0089699]
	Learning Rate: 0.00896994
	LOSS [training: 0.5620419921924857 | validation: 0.6372484225294512]
	TIME [epoch: 8.46 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5743090639533773		[learning rate: 0.0089374]
	Learning Rate: 0.00893739
	LOSS [training: 0.5743090639533773 | validation: 1.0204682480316327]
	TIME [epoch: 8.43 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5598814817984923		[learning rate: 0.008905]
	Learning Rate: 0.00890495
	LOSS [training: 0.5598814817984923 | validation: 0.5451617617799602]
	TIME [epoch: 8.43 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5153451415953628		[learning rate: 0.0088726]
	Learning Rate: 0.00887263
	LOSS [training: 0.5153451415953628 | validation: 0.797652664587497]
	TIME [epoch: 8.43 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5570946728239369		[learning rate: 0.0088404]
	Learning Rate: 0.00884044
	LOSS [training: 0.5570946728239369 | validation: 0.9068097850100509]
	TIME [epoch: 8.45 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5582522343207487		[learning rate: 0.0088084]
	Learning Rate: 0.00880835
	LOSS [training: 0.5582522343207487 | validation: 0.5814928148050403]
	TIME [epoch: 8.42 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6851997388547492		[learning rate: 0.0087764]
	Learning Rate: 0.00877639
	LOSS [training: 0.6851997388547492 | validation: 0.7579766733387931]
	TIME [epoch: 8.43 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5256247893908387		[learning rate: 0.0087445]
	Learning Rate: 0.00874454
	LOSS [training: 0.5256247893908387 | validation: 0.6649349750151238]
	TIME [epoch: 8.44 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5465842470368975		[learning rate: 0.0087128]
	Learning Rate: 0.0087128
	LOSS [training: 0.5465842470368975 | validation: 0.38618145585330554]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4717241307908836		[learning rate: 0.0086812]
	Learning Rate: 0.00868118
	LOSS [training: 0.4717241307908836 | validation: 0.7988191073939693]
	TIME [epoch: 8.43 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6435974163433379		[learning rate: 0.0086497]
	Learning Rate: 0.00864968
	LOSS [training: 0.6435974163433379 | validation: 1.0070601300169617]
	TIME [epoch: 8.42 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8042888855006376		[learning rate: 0.0086183]
	Learning Rate: 0.00861829
	LOSS [training: 0.8042888855006376 | validation: 0.9759314451024149]
	TIME [epoch: 8.45 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6280447791117287		[learning rate: 0.008587]
	Learning Rate: 0.00858701
	LOSS [training: 0.6280447791117287 | validation: 0.6043419897140774]
	TIME [epoch: 8.42 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5172964015101997		[learning rate: 0.0085559]
	Learning Rate: 0.00855585
	LOSS [training: 0.5172964015101997 | validation: 0.629535373965805]
	TIME [epoch: 8.43 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5276454771312397		[learning rate: 0.0085248]
	Learning Rate: 0.0085248
	LOSS [training: 0.5276454771312397 | validation: 0.5491765469216062]
	TIME [epoch: 8.42 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5845009761096852		[learning rate: 0.0084939]
	Learning Rate: 0.00849386
	LOSS [training: 0.5845009761096852 | validation: 1.3017512809344565]
	TIME [epoch: 8.45 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6190727981017192		[learning rate: 0.008463]
	Learning Rate: 0.00846304
	LOSS [training: 0.6190727981017192 | validation: 0.6907337455972133]
	TIME [epoch: 8.42 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5850813274429527		[learning rate: 0.0084323]
	Learning Rate: 0.00843233
	LOSS [training: 0.5850813274429527 | validation: 0.4815298475690105]
	TIME [epoch: 8.42 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5561466831745732		[learning rate: 0.0084017]
	Learning Rate: 0.00840172
	LOSS [training: 0.5561466831745732 | validation: 0.9163211009977821]
	TIME [epoch: 8.43 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6419386788481343		[learning rate: 0.0083712]
	Learning Rate: 0.00837123
	LOSS [training: 0.6419386788481343 | validation: 0.522918336732584]
	TIME [epoch: 8.45 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6284477341337735		[learning rate: 0.0083409]
	Learning Rate: 0.00834085
	LOSS [training: 0.6284477341337735 | validation: 1.4876068511458729]
	TIME [epoch: 8.43 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5873855059373447		[learning rate: 0.0083106]
	Learning Rate: 0.00831059
	LOSS [training: 0.5873855059373447 | validation: 0.32285836405070056]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5742898324898127		[learning rate: 0.0082804]
	Learning Rate: 0.00828043
	LOSS [training: 0.5742898324898127 | validation: 1.043143371626796]
	TIME [epoch: 8.43 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.8411791156267526		[learning rate: 0.0082504]
	Learning Rate: 0.00825037
	LOSS [training: 0.8411791156267526 | validation: 0.5157249175726574]
	TIME [epoch: 8.43 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5317829718396336		[learning rate: 0.0082204]
	Learning Rate: 0.00822043
	LOSS [training: 0.5317829718396336 | validation: 0.8937942988814153]
	TIME [epoch: 8.43 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5588036056747924		[learning rate: 0.0081906]
	Learning Rate: 0.0081906
	LOSS [training: 0.5588036056747924 | validation: 0.37121036825608844]
	TIME [epoch: 8.42 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.463649958232972		[learning rate: 0.0081609]
	Learning Rate: 0.00816088
	LOSS [training: 0.463649958232972 | validation: 0.38657215359952296]
	TIME [epoch: 8.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5185268498152023		[learning rate: 0.0081313]
	Learning Rate: 0.00813126
	LOSS [training: 0.5185268498152023 | validation: 0.6517362821808008]
	TIME [epoch: 8.42 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45837957330897855		[learning rate: 0.0081018]
	Learning Rate: 0.00810175
	LOSS [training: 0.45837957330897855 | validation: 0.4489544841636074]
	TIME [epoch: 8.42 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5168185203932664		[learning rate: 0.0080724]
	Learning Rate: 0.00807235
	LOSS [training: 0.5168185203932664 | validation: 0.9864767679427613]
	TIME [epoch: 8.42 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4870489304025819		[learning rate: 0.0080431]
	Learning Rate: 0.00804305
	LOSS [training: 0.4870489304025819 | validation: 0.5216593729975216]
	TIME [epoch: 8.44 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5346722836545853		[learning rate: 0.0080139]
	Learning Rate: 0.00801387
	LOSS [training: 0.5346722836545853 | validation: 0.5663849143170592]
	TIME [epoch: 8.42 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5228766248350795		[learning rate: 0.0079848]
	Learning Rate: 0.00798478
	LOSS [training: 0.5228766248350795 | validation: 0.43800069377444295]
	TIME [epoch: 8.42 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.49941504442280615		[learning rate: 0.0079558]
	Learning Rate: 0.00795581
	LOSS [training: 0.49941504442280615 | validation: 0.7463989688234308]
	TIME [epoch: 8.42 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5676400182202708		[learning rate: 0.0079269]
	Learning Rate: 0.00792693
	LOSS [training: 0.5676400182202708 | validation: 0.878469833006548]
	TIME [epoch: 8.44 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.563656952836358		[learning rate: 0.0078982]
	Learning Rate: 0.00789817
	LOSS [training: 0.563656952836358 | validation: 0.9140834631946773]
	TIME [epoch: 8.42 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5374099923129775		[learning rate: 0.0078695]
	Learning Rate: 0.0078695
	LOSS [training: 0.5374099923129775 | validation: 1.561722811178655]
	TIME [epoch: 8.42 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.761310821443234		[learning rate: 0.0078409]
	Learning Rate: 0.00784094
	LOSS [training: 0.761310821443234 | validation: 0.47502264950448947]
	TIME [epoch: 8.42 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4941497319402168		[learning rate: 0.0078125]
	Learning Rate: 0.00781249
	LOSS [training: 0.4941497319402168 | validation: 0.2935932302001446]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4549485430602333		[learning rate: 0.0077841]
	Learning Rate: 0.00778414
	LOSS [training: 0.4549485430602333 | validation: 0.5629168831899903]
	TIME [epoch: 8.43 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5169599252145253		[learning rate: 0.0077559]
	Learning Rate: 0.00775589
	LOSS [training: 0.5169599252145253 | validation: 0.4167752713580035]
	TIME [epoch: 8.43 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4487320634717329		[learning rate: 0.0077277]
	Learning Rate: 0.00772774
	LOSS [training: 0.4487320634717329 | validation: 0.29099709950857644]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6341707927583533		[learning rate: 0.0076997]
	Learning Rate: 0.0076997
	LOSS [training: 0.6341707927583533 | validation: 1.1498135864687866]
	TIME [epoch: 8.43 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5084892839357316		[learning rate: 0.0076718]
	Learning Rate: 0.00767176
	LOSS [training: 0.5084892839357316 | validation: 0.4446643892562313]
	TIME [epoch: 8.43 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4679409065284766		[learning rate: 0.0076439]
	Learning Rate: 0.00764391
	LOSS [training: 0.4679409065284766 | validation: 0.5193317633830208]
	TIME [epoch: 8.42 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42822786734059654		[learning rate: 0.0076162]
	Learning Rate: 0.00761617
	LOSS [training: 0.42822786734059654 | validation: 0.3123419254848559]
	TIME [epoch: 8.45 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5373467065329863		[learning rate: 0.0075885]
	Learning Rate: 0.00758853
	LOSS [training: 0.5373467065329863 | validation: 0.4444642016501637]
	TIME [epoch: 8.42 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.393002026043147		[learning rate: 0.007561]
	Learning Rate: 0.00756099
	LOSS [training: 0.393002026043147 | validation: 0.4562400451663343]
	TIME [epoch: 8.42 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4935488247817582		[learning rate: 0.0075336]
	Learning Rate: 0.00753356
	LOSS [training: 0.4935488247817582 | validation: 0.5830731643912879]
	TIME [epoch: 8.42 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46672138152721365		[learning rate: 0.0075062]
	Learning Rate: 0.00750622
	LOSS [training: 0.46672138152721365 | validation: 0.28791761825289686]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.48122480693843367		[learning rate: 0.007479]
	Learning Rate: 0.00747897
	LOSS [training: 0.48122480693843367 | validation: 0.30064628912569014]
	TIME [epoch: 8.44 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.452806495948945		[learning rate: 0.0074518]
	Learning Rate: 0.00745183
	LOSS [training: 0.452806495948945 | validation: 0.47016991776428657]
	TIME [epoch: 8.43 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5174469409416311		[learning rate: 0.0074248]
	Learning Rate: 0.00742479
	LOSS [training: 0.5174469409416311 | validation: 0.42970795101201187]
	TIME [epoch: 8.45 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4942357079376828		[learning rate: 0.0073978]
	Learning Rate: 0.00739784
	LOSS [training: 0.4942357079376828 | validation: 0.38920589766401964]
	TIME [epoch: 8.45 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4116341678396095		[learning rate: 0.007371]
	Learning Rate: 0.007371
	LOSS [training: 0.4116341678396095 | validation: 0.384992478000418]
	TIME [epoch: 8.44 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4024525797660048		[learning rate: 0.0073442]
	Learning Rate: 0.00734425
	LOSS [training: 0.4024525797660048 | validation: 0.45567657662524896]
	TIME [epoch: 8.44 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4306889704473663		[learning rate: 0.0073176]
	Learning Rate: 0.0073176
	LOSS [training: 0.4306889704473663 | validation: 0.42615218485636014]
	TIME [epoch: 8.46 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5097612661676847		[learning rate: 0.007291]
	Learning Rate: 0.00729104
	LOSS [training: 0.5097612661676847 | validation: 0.41412796449889333]
	TIME [epoch: 8.44 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4830930773318197		[learning rate: 0.0072646]
	Learning Rate: 0.00726458
	LOSS [training: 0.4830930773318197 | validation: 0.6739595038297967]
	TIME [epoch: 8.43 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5936913757523464		[learning rate: 0.0072382]
	Learning Rate: 0.00723822
	LOSS [training: 0.5936913757523464 | validation: 0.5606143665899883]
	TIME [epoch: 8.43 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5028648135015008		[learning rate: 0.0072119]
	Learning Rate: 0.00721195
	LOSS [training: 0.5028648135015008 | validation: 0.5823109423025846]
	TIME [epoch: 8.46 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6376447907576857		[learning rate: 0.0071858]
	Learning Rate: 0.00718578
	LOSS [training: 0.6376447907576857 | validation: 0.6794635906647782]
	TIME [epoch: 8.44 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4317572639685536		[learning rate: 0.0071597]
	Learning Rate: 0.0071597
	LOSS [training: 0.4317572639685536 | validation: 0.3232613366453144]
	TIME [epoch: 8.43 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4864265406780371		[learning rate: 0.0071337]
	Learning Rate: 0.00713371
	LOSS [training: 0.4864265406780371 | validation: 0.3378084601485844]
	TIME [epoch: 8.44 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.344364598679529		[learning rate: 0.0071078]
	Learning Rate: 0.00710783
	LOSS [training: 0.344364598679529 | validation: 0.9092539394511004]
	TIME [epoch: 8.46 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5223298902104154		[learning rate: 0.007082]
	Learning Rate: 0.00708203
	LOSS [training: 0.5223298902104154 | validation: 0.4008180917265487]
	TIME [epoch: 8.43 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42275251591939494		[learning rate: 0.0070563]
	Learning Rate: 0.00705633
	LOSS [training: 0.42275251591939494 | validation: 0.417370349226564]
	TIME [epoch: 8.43 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.526099007170763		[learning rate: 0.0070307]
	Learning Rate: 0.00703072
	LOSS [training: 0.526099007170763 | validation: 0.45232209635938075]
	TIME [epoch: 8.44 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4310340918415042		[learning rate: 0.0070052]
	Learning Rate: 0.00700521
	LOSS [training: 0.4310340918415042 | validation: 0.6151676289675527]
	TIME [epoch: 8.46 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4812194381764165		[learning rate: 0.0069798]
	Learning Rate: 0.00697979
	LOSS [training: 0.4812194381764165 | validation: 0.429086634243962]
	TIME [epoch: 8.44 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3698123682947262		[learning rate: 0.0069545]
	Learning Rate: 0.00695446
	LOSS [training: 0.3698123682947262 | validation: 0.6866730736414733]
	TIME [epoch: 8.43 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4960050217087219		[learning rate: 0.0069292]
	Learning Rate: 0.00692922
	LOSS [training: 0.4960050217087219 | validation: 0.689052260659414]
	TIME [epoch: 8.46 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5104971018004604		[learning rate: 0.0069041]
	Learning Rate: 0.00690407
	LOSS [training: 0.5104971018004604 | validation: 0.33785125568812313]
	TIME [epoch: 8.44 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4556991418176605		[learning rate: 0.006879]
	Learning Rate: 0.00687902
	LOSS [training: 0.4556991418176605 | validation: 0.5661586293711233]
	TIME [epoch: 8.43 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5056919330172686		[learning rate: 0.0068541]
	Learning Rate: 0.00685405
	LOSS [training: 0.5056919330172686 | validation: 0.28349939159360726]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3718854478823092		[learning rate: 0.0068292]
	Learning Rate: 0.00682918
	LOSS [training: 0.3718854478823092 | validation: 0.524213924862462]
	TIME [epoch: 8.47 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4421401540106717		[learning rate: 0.0068044]
	Learning Rate: 0.00680439
	LOSS [training: 0.4421401540106717 | validation: 0.3530609051469419]
	TIME [epoch: 8.44 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39578195715395714		[learning rate: 0.0067797]
	Learning Rate: 0.0067797
	LOSS [training: 0.39578195715395714 | validation: 0.42542850658586273]
	TIME [epoch: 8.44 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4152060312641491		[learning rate: 0.0067551]
	Learning Rate: 0.0067551
	LOSS [training: 0.4152060312641491 | validation: 0.504373898735538]
	TIME [epoch: 8.44 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38367757373050554		[learning rate: 0.0067306]
	Learning Rate: 0.00673058
	LOSS [training: 0.38367757373050554 | validation: 0.39181708599804754]
	TIME [epoch: 8.46 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4579550985524983		[learning rate: 0.0067062]
	Learning Rate: 0.00670616
	LOSS [training: 0.4579550985524983 | validation: 0.5961151758834576]
	TIME [epoch: 8.44 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5015173066857329		[learning rate: 0.0066818]
	Learning Rate: 0.00668182
	LOSS [training: 0.5015173066857329 | validation: 1.3816539706796895]
	TIME [epoch: 8.44 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.6154814385635963		[learning rate: 0.0066576]
	Learning Rate: 0.00665757
	LOSS [training: 0.6154814385635963 | validation: 0.6506016540637303]
	TIME [epoch: 8.43 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3915594617432762		[learning rate: 0.0066334]
	Learning Rate: 0.00663341
	LOSS [training: 0.3915594617432762 | validation: 0.8291570156782473]
	TIME [epoch: 8.47 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4686474279280525		[learning rate: 0.0066093]
	Learning Rate: 0.00660934
	LOSS [training: 0.4686474279280525 | validation: 0.5041828602163917]
	TIME [epoch: 8.45 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3803560622568442		[learning rate: 0.0065854]
	Learning Rate: 0.00658535
	LOSS [training: 0.3803560622568442 | validation: 0.4766502096160175]
	TIME [epoch: 8.44 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33264131309186185		[learning rate: 0.0065615]
	Learning Rate: 0.00656145
	LOSS [training: 0.33264131309186185 | validation: 0.6814269521069138]
	TIME [epoch: 8.45 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5273110873013884		[learning rate: 0.0065376]
	Learning Rate: 0.00653764
	LOSS [training: 0.5273110873013884 | validation: 1.1201556840643316]
	TIME [epoch: 8.45 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4220388125025905		[learning rate: 0.0065139]
	Learning Rate: 0.00651392
	LOSS [training: 0.4220388125025905 | validation: 0.5851650835230828]
	TIME [epoch: 8.44 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4295381993524999		[learning rate: 0.0064903]
	Learning Rate: 0.00649028
	LOSS [training: 0.4295381993524999 | validation: 0.4405356183354711]
	TIME [epoch: 8.44 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42832752790892004		[learning rate: 0.0064667]
	Learning Rate: 0.00646672
	LOSS [training: 0.42832752790892004 | validation: 0.42101333193763657]
	TIME [epoch: 8.46 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4243257864357692		[learning rate: 0.0064433]
	Learning Rate: 0.00644325
	LOSS [training: 0.4243257864357692 | validation: 0.25065617279750046]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34673933089370285		[learning rate: 0.0064199]
	Learning Rate: 0.00641987
	LOSS [training: 0.34673933089370285 | validation: 0.521711760562325]
	TIME [epoch: 8.44 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5227305646477708		[learning rate: 0.0063966]
	Learning Rate: 0.00639657
	LOSS [training: 0.5227305646477708 | validation: 0.3660831947776839]
	TIME [epoch: 8.44 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3632383093151136		[learning rate: 0.0063734]
	Learning Rate: 0.00637336
	LOSS [training: 0.3632383093151136 | validation: 0.26047761733200664]
	TIME [epoch: 8.47 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3921880026300239		[learning rate: 0.0063502]
	Learning Rate: 0.00635023
	LOSS [training: 0.3921880026300239 | validation: 0.7037480085623039]
	TIME [epoch: 8.44 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43298215826277514		[learning rate: 0.0063272]
	Learning Rate: 0.00632718
	LOSS [training: 0.43298215826277514 | validation: 0.3991188230838793]
	TIME [epoch: 8.43 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4344352209860121		[learning rate: 0.0063042]
	Learning Rate: 0.00630422
	LOSS [training: 0.4344352209860121 | validation: 0.4503534055788959]
	TIME [epoch: 8.44 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3797157414246094		[learning rate: 0.0062813]
	Learning Rate: 0.00628134
	LOSS [training: 0.3797157414246094 | validation: 0.2575060522364496]
	TIME [epoch: 8.46 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3790015294531258		[learning rate: 0.0062585]
	Learning Rate: 0.00625855
	LOSS [training: 0.3790015294531258 | validation: 0.2878183319785918]
	TIME [epoch: 8.44 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4317191991098002		[learning rate: 0.0062358]
	Learning Rate: 0.00623584
	LOSS [training: 0.4317191991098002 | validation: 0.581972422970423]
	TIME [epoch: 8.43 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38211693025543053		[learning rate: 0.0062132]
	Learning Rate: 0.00621321
	LOSS [training: 0.38211693025543053 | validation: 0.6498644122308131]
	TIME [epoch: 8.45 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3826344713702222		[learning rate: 0.0061907]
	Learning Rate: 0.00619066
	LOSS [training: 0.3826344713702222 | validation: 0.266169281593452]
	TIME [epoch: 8.45 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3561513845670761		[learning rate: 0.0061682]
	Learning Rate: 0.00616819
	LOSS [training: 0.3561513845670761 | validation: 0.34553348150556096]
	TIME [epoch: 8.44 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40672061075021954		[learning rate: 0.0061458]
	Learning Rate: 0.00614581
	LOSS [training: 0.40672061075021954 | validation: 0.3750050628207985]
	TIME [epoch: 8.44 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4267314374651073		[learning rate: 0.0061235]
	Learning Rate: 0.0061235
	LOSS [training: 0.4267314374651073 | validation: 0.23003453505174998]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37614285329298697		[learning rate: 0.0061013]
	Learning Rate: 0.00610128
	LOSS [training: 0.37614285329298697 | validation: 0.33065903644632577]
	TIME [epoch: 8.44 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.364846420997169		[learning rate: 0.0060791]
	Learning Rate: 0.00607914
	LOSS [training: 0.364846420997169 | validation: 0.9373073074582834]
	TIME [epoch: 8.44 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4922999657517602		[learning rate: 0.0060571]
	Learning Rate: 0.00605708
	LOSS [training: 0.4922999657517602 | validation: 0.2731389776439934]
	TIME [epoch: 8.43 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28176841849156575		[learning rate: 0.0060351]
	Learning Rate: 0.0060351
	LOSS [training: 0.28176841849156575 | validation: 0.5578829209554601]
	TIME [epoch: 8.46 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42044264299506695		[learning rate: 0.0060132]
	Learning Rate: 0.00601319
	LOSS [training: 0.42044264299506695 | validation: 1.1843162161579226]
	TIME [epoch: 8.43 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4091672006693491		[learning rate: 0.0059914]
	Learning Rate: 0.00599137
	LOSS [training: 0.4091672006693491 | validation: 0.4360293170090764]
	TIME [epoch: 8.44 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.335001403256261		[learning rate: 0.0059696]
	Learning Rate: 0.00596963
	LOSS [training: 0.335001403256261 | validation: 0.33769018579725657]
	TIME [epoch: 8.44 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38297567920101716		[learning rate: 0.005948]
	Learning Rate: 0.00594797
	LOSS [training: 0.38297567920101716 | validation: 0.34435452970783464]
	TIME [epoch: 8.45 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.43619180626119414		[learning rate: 0.0059264]
	Learning Rate: 0.00592638
	LOSS [training: 0.43619180626119414 | validation: 0.40226272620582654]
	TIME [epoch: 8.44 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.42464011165176185		[learning rate: 0.0059049]
	Learning Rate: 0.00590487
	LOSS [training: 0.42464011165176185 | validation: 0.5023965682263352]
	TIME [epoch: 8.44 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.45133595732201337		[learning rate: 0.0058834]
	Learning Rate: 0.00588344
	LOSS [training: 0.45133595732201337 | validation: 0.42408252411320335]
	TIME [epoch: 8.44 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38114440473340216		[learning rate: 0.0058621]
	Learning Rate: 0.00586209
	LOSS [training: 0.38114440473340216 | validation: 0.3713226648150706]
	TIME [epoch: 8.46 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36680301559359235		[learning rate: 0.0058408]
	Learning Rate: 0.00584082
	LOSS [training: 0.36680301559359235 | validation: 1.0394851488823844]
	TIME [epoch: 8.44 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4707481504792185		[learning rate: 0.0058196]
	Learning Rate: 0.00581962
	LOSS [training: 0.4707481504792185 | validation: 0.4823232959750928]
	TIME [epoch: 8.44 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33740171098458854		[learning rate: 0.0057985]
	Learning Rate: 0.0057985
	LOSS [training: 0.33740171098458854 | validation: 0.3373134238167621]
	TIME [epoch: 8.46 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35682668580152727		[learning rate: 0.0057775]
	Learning Rate: 0.00577746
	LOSS [training: 0.35682668580152727 | validation: 0.4997017873889885]
	TIME [epoch: 8.44 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4205268417412989		[learning rate: 0.0057565]
	Learning Rate: 0.00575649
	LOSS [training: 0.4205268417412989 | validation: 0.41050186426423346]
	TIME [epoch: 8.43 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38084479577821123		[learning rate: 0.0057356]
	Learning Rate: 0.0057356
	LOSS [training: 0.38084479577821123 | validation: 0.6001305489561461]
	TIME [epoch: 8.43 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40456540990338186		[learning rate: 0.0057148]
	Learning Rate: 0.00571479
	LOSS [training: 0.40456540990338186 | validation: 0.2634625737546378]
	TIME [epoch: 8.47 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39648649326579816		[learning rate: 0.005694]
	Learning Rate: 0.00569405
	LOSS [training: 0.39648649326579816 | validation: 0.26587188612014084]
	TIME [epoch: 8.44 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4606722025819037		[learning rate: 0.0056734]
	Learning Rate: 0.00567338
	LOSS [training: 0.4606722025819037 | validation: 0.21480227830417487]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4088368655284492		[learning rate: 0.0056528]
	Learning Rate: 0.00565279
	LOSS [training: 0.4088368655284492 | validation: 1.0600441880115978]
	TIME [epoch: 8.44 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38822589101110117		[learning rate: 0.0056323]
	Learning Rate: 0.00563228
	LOSS [training: 0.38822589101110117 | validation: 0.48240249659034706]
	TIME [epoch: 8.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3801655329152892		[learning rate: 0.0056118]
	Learning Rate: 0.00561184
	LOSS [training: 0.3801655329152892 | validation: 0.8312588655563737]
	TIME [epoch: 8.44 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4258097774901624		[learning rate: 0.0055915]
	Learning Rate: 0.00559147
	LOSS [training: 0.4258097774901624 | validation: 0.6095291645407225]
	TIME [epoch: 8.44 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.5199315666023754		[learning rate: 0.0055712]
	Learning Rate: 0.00557118
	LOSS [training: 0.5199315666023754 | validation: 0.4286844887947072]
	TIME [epoch: 8.45 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.39116709417415885		[learning rate: 0.005551]
	Learning Rate: 0.00555096
	LOSS [training: 0.39116709417415885 | validation: 0.20828007776214788]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3290055966558885		[learning rate: 0.0055308]
	Learning Rate: 0.00553082
	LOSS [training: 0.3290055966558885 | validation: 0.2660305937384592]
	TIME [epoch: 8.44 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.337875550215446		[learning rate: 0.0055107]
	Learning Rate: 0.00551075
	LOSS [training: 0.337875550215446 | validation: 1.061876292661013]
	TIME [epoch: 8.43 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.38309835883357196		[learning rate: 0.0054907]
	Learning Rate: 0.00549075
	LOSS [training: 0.38309835883357196 | validation: 0.5882441970348978]
	TIME [epoch: 8.46 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.392106795832194		[learning rate: 0.0054708]
	Learning Rate: 0.00547082
	LOSS [training: 0.392106795832194 | validation: 0.4959326052843382]
	TIME [epoch: 8.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.4372167747980139		[learning rate: 0.005451]
	Learning Rate: 0.00545097
	LOSS [training: 0.4372167747980139 | validation: 0.8236223921328174]
	TIME [epoch: 8.43 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3464408676038719		[learning rate: 0.0054312]
	Learning Rate: 0.00543119
	LOSS [training: 0.3464408676038719 | validation: 0.3426351717424534]
	TIME [epoch: 8.43 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34978584319066014		[learning rate: 0.0054115]
	Learning Rate: 0.00541148
	LOSS [training: 0.34978584319066014 | validation: 0.5433714490824422]
	TIME [epoch: 8.46 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3937628870065445		[learning rate: 0.0053918]
	Learning Rate: 0.00539184
	LOSS [training: 0.3937628870065445 | validation: 0.44350150130695487]
	TIME [epoch: 8.43 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3205885710714507		[learning rate: 0.0053723]
	Learning Rate: 0.00537227
	LOSS [training: 0.3205885710714507 | validation: 0.3142930352777925]
	TIME [epoch: 8.43 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46267477518969535		[learning rate: 0.0053528]
	Learning Rate: 0.00535277
	LOSS [training: 0.46267477518969535 | validation: 0.667355204049938]
	TIME [epoch: 8.44 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3365045036322896		[learning rate: 0.0053333]
	Learning Rate: 0.00533335
	LOSS [training: 0.3365045036322896 | validation: 0.5475581175653155]
	TIME [epoch: 8.45 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3313865557085397		[learning rate: 0.005314]
	Learning Rate: 0.00531399
	LOSS [training: 0.3313865557085397 | validation: 0.5769814863356776]
	TIME [epoch: 8.43 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32120113437757974		[learning rate: 0.0052947]
	Learning Rate: 0.00529471
	LOSS [training: 0.32120113437757974 | validation: 0.24436335291938996]
	TIME [epoch: 8.42 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3156459568494828		[learning rate: 0.0052755]
	Learning Rate: 0.00527549
	LOSS [training: 0.3156459568494828 | validation: 0.2914300454493614]
	TIME [epoch: 8.43 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3530883381974046		[learning rate: 0.0052563]
	Learning Rate: 0.00525635
	LOSS [training: 0.3530883381974046 | validation: 0.38693980156595054]
	TIME [epoch: 8.44 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33324575419204094		[learning rate: 0.0052373]
	Learning Rate: 0.00523727
	LOSS [training: 0.33324575419204094 | validation: 0.29392621917746997]
	TIME [epoch: 8.43 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2959368008367134		[learning rate: 0.0052183]
	Learning Rate: 0.00521827
	LOSS [training: 0.2959368008367134 | validation: 0.257580896935241]
	TIME [epoch: 8.43 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34361281200463245		[learning rate: 0.0051993]
	Learning Rate: 0.00519933
	LOSS [training: 0.34361281200463245 | validation: 0.2699545858335981]
	TIME [epoch: 8.45 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32323817086917106		[learning rate: 0.0051805]
	Learning Rate: 0.00518046
	LOSS [training: 0.32323817086917106 | validation: 0.37131518051796497]
	TIME [epoch: 8.43 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36814964416089546		[learning rate: 0.0051617]
	Learning Rate: 0.00516166
	LOSS [training: 0.36814964416089546 | validation: 0.34639414796937157]
	TIME [epoch: 8.43 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34132461671822323		[learning rate: 0.0051429]
	Learning Rate: 0.00514293
	LOSS [training: 0.34132461671822323 | validation: 0.26723841426858175]
	TIME [epoch: 8.43 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.40759197517311846		[learning rate: 0.0051243]
	Learning Rate: 0.00512426
	LOSS [training: 0.40759197517311846 | validation: 0.37093479054078504]
	TIME [epoch: 8.46 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.33805364151507816		[learning rate: 0.0051057]
	Learning Rate: 0.00510567
	LOSS [training: 0.33805364151507816 | validation: 0.3618301078142993]
	TIME [epoch: 8.43 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34526057745270655		[learning rate: 0.0050871]
	Learning Rate: 0.00508714
	LOSS [training: 0.34526057745270655 | validation: 0.8448860011954618]
	TIME [epoch: 8.43 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.41938593153563986		[learning rate: 0.0050687]
	Learning Rate: 0.00506868
	LOSS [training: 0.41938593153563986 | validation: 0.3161162166456364]
	TIME [epoch: 8.43 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3543398995755086		[learning rate: 0.0050503]
	Learning Rate: 0.00505028
	LOSS [training: 0.3543398995755086 | validation: 0.3468650990142926]
	TIME [epoch: 8.45 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3172139969821953		[learning rate: 0.005032]
	Learning Rate: 0.00503196
	LOSS [training: 0.3172139969821953 | validation: 0.4088275808555173]
	TIME [epoch: 8.43 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3829973323426067		[learning rate: 0.0050137]
	Learning Rate: 0.00501369
	LOSS [training: 0.3829973323426067 | validation: 0.9489435661733028]
	TIME [epoch: 8.43 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3992547550704594		[learning rate: 0.0049955]
	Learning Rate: 0.0049955
	LOSS [training: 0.3992547550704594 | validation: 0.2578591216813056]
	TIME [epoch: 8.44 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2811243711365208		[learning rate: 0.0049774]
	Learning Rate: 0.00497737
	LOSS [training: 0.2811243711365208 | validation: 0.8132249011421492]
	TIME [epoch: 8.44 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34063949865733684		[learning rate: 0.0049593]
	Learning Rate: 0.00495931
	LOSS [training: 0.34063949865733684 | validation: 0.4277433510196088]
	TIME [epoch: 8.43 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3161598829306817		[learning rate: 0.0049413]
	Learning Rate: 0.00494131
	LOSS [training: 0.3161598829306817 | validation: 0.36328927530985855]
	TIME [epoch: 8.42 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.34394746867395676		[learning rate: 0.0049234]
	Learning Rate: 0.00492338
	LOSS [training: 0.34394746867395676 | validation: 0.3010349227652511]
	TIME [epoch: 8.45 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30389113493266634		[learning rate: 0.0049055]
	Learning Rate: 0.00490551
	LOSS [training: 0.30389113493266634 | validation: 0.21567652248520197]
	TIME [epoch: 8.43 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2948851150268967		[learning rate: 0.0048877]
	Learning Rate: 0.00488771
	LOSS [training: 0.2948851150268967 | validation: 0.2597665644561239]
	TIME [epoch: 8.43 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31467826045021496		[learning rate: 0.00487]
	Learning Rate: 0.00486997
	LOSS [training: 0.31467826045021496 | validation: 0.27804763045161535]
	TIME [epoch: 8.43 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3754096167683913		[learning rate: 0.0048523]
	Learning Rate: 0.0048523
	LOSS [training: 0.3754096167683913 | validation: 0.411181591036072]
	TIME [epoch: 8.45 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35003816940432947		[learning rate: 0.0048347]
	Learning Rate: 0.00483469
	LOSS [training: 0.35003816940432947 | validation: 0.5644021170652176]
	TIME [epoch: 8.43 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3421173529776347		[learning rate: 0.0048171]
	Learning Rate: 0.00481714
	LOSS [training: 0.3421173529776347 | validation: 0.20963907659968967]
	TIME [epoch: 8.42 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2940534347152819		[learning rate: 0.0047997]
	Learning Rate: 0.00479966
	LOSS [training: 0.2940534347152819 | validation: 0.4306257287469538]
	TIME [epoch: 8.43 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.37072968808047435		[learning rate: 0.0047822]
	Learning Rate: 0.00478224
	LOSS [training: 0.37072968808047435 | validation: 0.2686437041830826]
	TIME [epoch: 8.45 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2880502673646245		[learning rate: 0.0047649]
	Learning Rate: 0.00476489
	LOSS [training: 0.2880502673646245 | validation: 0.23235807553270532]
	TIME [epoch: 8.43 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29055786673229056		[learning rate: 0.0047476]
	Learning Rate: 0.00474759
	LOSS [training: 0.29055786673229056 | validation: 0.23756357442679418]
	TIME [epoch: 8.43 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32805707165688663		[learning rate: 0.0047304]
	Learning Rate: 0.00473037
	LOSS [training: 0.32805707165688663 | validation: 0.6189054461248371]
	TIME [epoch: 8.44 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3682713608465543		[learning rate: 0.0047132]
	Learning Rate: 0.0047132
	LOSS [training: 0.3682713608465543 | validation: 0.2626029220164021]
	TIME [epoch: 8.44 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3201581726955339		[learning rate: 0.0046961]
	Learning Rate: 0.00469609
	LOSS [training: 0.3201581726955339 | validation: 0.2613875450098705]
	TIME [epoch: 8.43 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302542528722191		[learning rate: 0.0046791]
	Learning Rate: 0.00467905
	LOSS [training: 0.302542528722191 | validation: 0.3615480783059462]
	TIME [epoch: 8.42 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31994587358175497		[learning rate: 0.0046621]
	Learning Rate: 0.00466207
	LOSS [training: 0.31994587358175497 | validation: 0.20891715036383923]
	TIME [epoch: 8.44 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3643534764251788		[learning rate: 0.0046452]
	Learning Rate: 0.00464515
	LOSS [training: 0.3643534764251788 | validation: 0.3697436786802903]
	TIME [epoch: 8.43 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.36799159757354494		[learning rate: 0.0046283]
	Learning Rate: 0.0046283
	LOSS [training: 0.36799159757354494 | validation: 0.21392451209428426]
	TIME [epoch: 8.43 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3091283548230094		[learning rate: 0.0046115]
	Learning Rate: 0.0046115
	LOSS [training: 0.3091283548230094 | validation: 0.2873648662688524]
	TIME [epoch: 8.43 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30476133017461543		[learning rate: 0.0045948]
	Learning Rate: 0.00459476
	LOSS [training: 0.30476133017461543 | validation: 0.45158040172284936]
	TIME [epoch: 8.45 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3417368301314595		[learning rate: 0.0045781]
	Learning Rate: 0.00457809
	LOSS [training: 0.3417368301314595 | validation: 0.2770910334872532]
	TIME [epoch: 8.43 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30596952387365517		[learning rate: 0.0045615]
	Learning Rate: 0.00456148
	LOSS [training: 0.30596952387365517 | validation: 0.2764399826614507]
	TIME [epoch: 8.42 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.321020272129129		[learning rate: 0.0045449]
	Learning Rate: 0.00454492
	LOSS [training: 0.321020272129129 | validation: 0.5293217873386412]
	TIME [epoch: 8.42 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3196571703252219		[learning rate: 0.0045284]
	Learning Rate: 0.00452843
	LOSS [training: 0.3196571703252219 | validation: 0.3141211085736893]
	TIME [epoch: 8.45 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2797339437704826		[learning rate: 0.004512]
	Learning Rate: 0.00451199
	LOSS [training: 0.2797339437704826 | validation: 0.3126398594033063]
	TIME [epoch: 8.43 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3158457614322633		[learning rate: 0.0044956]
	Learning Rate: 0.00449562
	LOSS [training: 0.3158457614322633 | validation: 0.44623656167858766]
	TIME [epoch: 8.42 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3850619244923493		[learning rate: 0.0044793]
	Learning Rate: 0.0044793
	LOSS [training: 0.3850619244923493 | validation: 0.4519389060265159]
	TIME [epoch: 8.44 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28857253641255765		[learning rate: 0.004463]
	Learning Rate: 0.00446305
	LOSS [training: 0.28857253641255765 | validation: 0.17778249461783596]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_322.pth
	Model improved!!!
EPOCH 323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.248579839292369		[learning rate: 0.0044469]
	Learning Rate: 0.00444685
	LOSS [training: 0.248579839292369 | validation: 0.27860380992576894]
	TIME [epoch: 8.43 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25970331441896954		[learning rate: 0.0044307]
	Learning Rate: 0.00443071
	LOSS [training: 0.25970331441896954 | validation: 0.1745362042587238]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3798563814430485		[learning rate: 0.0044146]
	Learning Rate: 0.00441463
	LOSS [training: 0.3798563814430485 | validation: 0.3494483149035978]
	TIME [epoch: 8.45 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2683596122328151		[learning rate: 0.0043986]
	Learning Rate: 0.00439861
	LOSS [training: 0.2683596122328151 | validation: 0.2329953797514062]
	TIME [epoch: 8.44 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2680833574578322		[learning rate: 0.0043827]
	Learning Rate: 0.00438265
	LOSS [training: 0.2680833574578322 | validation: 0.7157542968939171]
	TIME [epoch: 8.42 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.298194123949335		[learning rate: 0.0043667]
	Learning Rate: 0.00436675
	LOSS [training: 0.298194123949335 | validation: 0.2575468281734139]
	TIME [epoch: 8.43 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.35581532279469974		[learning rate: 0.0043509]
	Learning Rate: 0.0043509
	LOSS [training: 0.35581532279469974 | validation: 0.24720987586964188]
	TIME [epoch: 8.45 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.247624687728991		[learning rate: 0.0043351]
	Learning Rate: 0.00433511
	LOSS [training: 0.247624687728991 | validation: 0.2538818021558551]
	TIME [epoch: 8.43 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2527817290240194		[learning rate: 0.0043194]
	Learning Rate: 0.00431938
	LOSS [training: 0.2527817290240194 | validation: 0.2647613671153881]
	TIME [epoch: 8.43 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21596313890400118		[learning rate: 0.0043037]
	Learning Rate: 0.0043037
	LOSS [training: 0.21596313890400118 | validation: 0.24145397567550222]
	TIME [epoch: 8.43 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3291114770117597		[learning rate: 0.0042881]
	Learning Rate: 0.00428808
	LOSS [training: 0.3291114770117597 | validation: 0.7779676391407708]
	TIME [epoch: 8.46 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.28055629477775385		[learning rate: 0.0042725]
	Learning Rate: 0.00427252
	LOSS [training: 0.28055629477775385 | validation: 0.1390551428943217]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2665469437578757		[learning rate: 0.004257]
	Learning Rate: 0.00425702
	LOSS [training: 0.2665469437578757 | validation: 0.3485107953821571]
	TIME [epoch: 8.43 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2717016193536316		[learning rate: 0.0042416]
	Learning Rate: 0.00424157
	LOSS [training: 0.2717016193536316 | validation: 0.25864968372771313]
	TIME [epoch: 8.45 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25524680551759704		[learning rate: 0.0042262]
	Learning Rate: 0.00422617
	LOSS [training: 0.25524680551759704 | validation: 0.3002468018867523]
	TIME [epoch: 8.45 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2706444864718834		[learning rate: 0.0042108]
	Learning Rate: 0.00421084
	LOSS [training: 0.2706444864718834 | validation: 0.19742543149961728]
	TIME [epoch: 8.43 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.302556904071374		[learning rate: 0.0041956]
	Learning Rate: 0.00419556
	LOSS [training: 0.302556904071374 | validation: 0.33685280976753174]
	TIME [epoch: 8.43 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25567654332592515		[learning rate: 0.0041803]
	Learning Rate: 0.00418033
	LOSS [training: 0.25567654332592515 | validation: 0.5676299133878421]
	TIME [epoch: 8.46 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3620250141333151		[learning rate: 0.0041652]
	Learning Rate: 0.00416516
	LOSS [training: 0.3620250141333151 | validation: 0.2741858305289016]
	TIME [epoch: 8.45 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29190455034088103		[learning rate: 0.00415]
	Learning Rate: 0.00415004
	LOSS [training: 0.29190455034088103 | validation: 0.34288202559494624]
	TIME [epoch: 8.44 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24704300015182254		[learning rate: 0.004135]
	Learning Rate: 0.00413498
	LOSS [training: 0.24704300015182254 | validation: 0.16691854014292273]
	TIME [epoch: 8.44 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20903052237736355		[learning rate: 0.00412]
	Learning Rate: 0.00411998
	LOSS [training: 0.20903052237736355 | validation: 0.2095742253574593]
	TIME [epoch: 8.46 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2657745340601215		[learning rate: 0.004105]
	Learning Rate: 0.00410502
	LOSS [training: 0.2657745340601215 | validation: 0.34307219709349357]
	TIME [epoch: 8.44 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2702804422652247		[learning rate: 0.0040901]
	Learning Rate: 0.00409013
	LOSS [training: 0.2702804422652247 | validation: 0.20178278300552693]
	TIME [epoch: 8.43 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23935426194130321		[learning rate: 0.0040753]
	Learning Rate: 0.00407528
	LOSS [training: 0.23935426194130321 | validation: 0.36458880176665054]
	TIME [epoch: 8.43 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26513666086577964		[learning rate: 0.0040605]
	Learning Rate: 0.00406049
	LOSS [training: 0.26513666086577964 | validation: 0.2529468769131823]
	TIME [epoch: 8.45 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2643249582360339		[learning rate: 0.0040458]
	Learning Rate: 0.00404576
	LOSS [training: 0.2643249582360339 | validation: 0.24299269777091015]
	TIME [epoch: 8.44 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24795313899374247		[learning rate: 0.0040311]
	Learning Rate: 0.00403108
	LOSS [training: 0.24795313899374247 | validation: 0.2554141607167907]
	TIME [epoch: 8.43 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2792026809915057		[learning rate: 0.0040164]
	Learning Rate: 0.00401645
	LOSS [training: 0.2792026809915057 | validation: 0.22197593789802553]
	TIME [epoch: 8.46 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23974456304784136		[learning rate: 0.0040019]
	Learning Rate: 0.00400187
	LOSS [training: 0.23974456304784136 | validation: 0.3601649947406984]
	TIME [epoch: 8.45 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29733483532760785		[learning rate: 0.0039873]
	Learning Rate: 0.00398735
	LOSS [training: 0.29733483532760785 | validation: 0.5646159212897297]
	TIME [epoch: 8.44 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3149908146678315		[learning rate: 0.0039729]
	Learning Rate: 0.00397288
	LOSS [training: 0.3149908146678315 | validation: 0.18451520467013877]
	TIME [epoch: 8.43 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3142450599210594		[learning rate: 0.0039585]
	Learning Rate: 0.00395846
	LOSS [training: 0.3142450599210594 | validation: 0.3046811181330957]
	TIME [epoch: 8.45 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23621210522748437		[learning rate: 0.0039441]
	Learning Rate: 0.00394409
	LOSS [training: 0.23621210522748437 | validation: 0.39740598764660395]
	TIME [epoch: 8.44 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25696985759409235		[learning rate: 0.0039298]
	Learning Rate: 0.00392978
	LOSS [training: 0.25696985759409235 | validation: 0.2791975296726444]
	TIME [epoch: 8.43 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29135734025712184		[learning rate: 0.0039155]
	Learning Rate: 0.00391552
	LOSS [training: 0.29135734025712184 | validation: 0.18589595712683826]
	TIME [epoch: 8.44 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20475645738563336		[learning rate: 0.0039013]
	Learning Rate: 0.00390131
	LOSS [training: 0.20475645738563336 | validation: 0.20897405470787167]
	TIME [epoch: 8.45 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24873838243141652		[learning rate: 0.0038872]
	Learning Rate: 0.00388715
	LOSS [training: 0.24873838243141652 | validation: 0.20663905555205575]
	TIME [epoch: 8.44 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.29484169765475365		[learning rate: 0.003873]
	Learning Rate: 0.00387305
	LOSS [training: 0.29484169765475365 | validation: 0.48963581196885575]
	TIME [epoch: 8.44 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23706285681913575		[learning rate: 0.003859]
	Learning Rate: 0.00385899
	LOSS [training: 0.23706285681913575 | validation: 0.2753120801297752]
	TIME [epoch: 8.43 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2963499488425487		[learning rate: 0.003845]
	Learning Rate: 0.00384499
	LOSS [training: 0.2963499488425487 | validation: 0.19293920394202854]
	TIME [epoch: 8.46 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25781444710144524		[learning rate: 0.003831]
	Learning Rate: 0.00383103
	LOSS [training: 0.25781444710144524 | validation: 0.22796946866479117]
	TIME [epoch: 8.44 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25050568850139066		[learning rate: 0.0038171]
	Learning Rate: 0.00381713
	LOSS [training: 0.25050568850139066 | validation: 0.3018255447187703]
	TIME [epoch: 8.43 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25106237735295217		[learning rate: 0.0038033]
	Learning Rate: 0.00380328
	LOSS [training: 0.25106237735295217 | validation: 0.25947040078779815]
	TIME [epoch: 8.45 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2747907705031768		[learning rate: 0.0037895]
	Learning Rate: 0.00378947
	LOSS [training: 0.2747907705031768 | validation: 0.17621751155019563]
	TIME [epoch: 8.45 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21913676066164212		[learning rate: 0.0037757]
	Learning Rate: 0.00377572
	LOSS [training: 0.21913676066164212 | validation: 0.4924947993802278]
	TIME [epoch: 8.44 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2636099102585419		[learning rate: 0.003762]
	Learning Rate: 0.00376202
	LOSS [training: 0.2636099102585419 | validation: 0.18533938360067967]
	TIME [epoch: 8.43 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22142930523730583		[learning rate: 0.0037484]
	Learning Rate: 0.00374837
	LOSS [training: 0.22142930523730583 | validation: 0.2282098188985674]
	TIME [epoch: 8.45 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21056806607848824		[learning rate: 0.0037348]
	Learning Rate: 0.00373476
	LOSS [training: 0.21056806607848824 | validation: 0.16799112829312868]
	TIME [epoch: 8.44 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.46868789082994883		[learning rate: 0.0037212]
	Learning Rate: 0.00372121
	LOSS [training: 0.46868789082994883 | validation: 0.18158748141506673]
	TIME [epoch: 8.44 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18832868074670567		[learning rate: 0.0037077]
	Learning Rate: 0.00370771
	LOSS [training: 0.18832868074670567 | validation: 0.2413494039271323]
	TIME [epoch: 8.42 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.32891457539342567		[learning rate: 0.0036943]
	Learning Rate: 0.00369425
	LOSS [training: 0.32891457539342567 | validation: 0.22896205794041868]
	TIME [epoch: 8.45 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22020576363379982		[learning rate: 0.0036808]
	Learning Rate: 0.00368084
	LOSS [training: 0.22020576363379982 | validation: 0.21617423882826997]
	TIME [epoch: 8.44 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2446415985342291		[learning rate: 0.0036675]
	Learning Rate: 0.00366749
	LOSS [training: 0.2446415985342291 | validation: 0.4182370396634625]
	TIME [epoch: 8.43 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24636151060118977		[learning rate: 0.0036542]
	Learning Rate: 0.00365418
	LOSS [training: 0.24636151060118977 | validation: 0.24422033297918228]
	TIME [epoch: 8.43 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2270819905030399		[learning rate: 0.0036409]
	Learning Rate: 0.00364092
	LOSS [training: 0.2270819905030399 | validation: 0.15084257068775905]
	TIME [epoch: 8.46 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2473347420982468		[learning rate: 0.0036277]
	Learning Rate: 0.0036277
	LOSS [training: 0.2473347420982468 | validation: 0.3963468505690576]
	TIME [epoch: 8.44 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22460678555541583		[learning rate: 0.0036145]
	Learning Rate: 0.00361454
	LOSS [training: 0.22460678555541583 | validation: 0.2667437435232367]
	TIME [epoch: 8.44 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25913742756452957		[learning rate: 0.0036014]
	Learning Rate: 0.00360142
	LOSS [training: 0.25913742756452957 | validation: 0.183222274207756]
	TIME [epoch: 8.48 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1873274786451124		[learning rate: 0.0035883]
	Learning Rate: 0.00358835
	LOSS [training: 0.1873274786451124 | validation: 0.26025105256757386]
	TIME [epoch: 8.45 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3005310489961292		[learning rate: 0.0035753]
	Learning Rate: 0.00357533
	LOSS [training: 0.3005310489961292 | validation: 0.2366880601646813]
	TIME [epoch: 8.43 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.25332417315414724		[learning rate: 0.0035624]
	Learning Rate: 0.00356235
	LOSS [training: 0.25332417315414724 | validation: 0.39485336402187665]
	TIME [epoch: 8.43 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2900588506665779		[learning rate: 0.0035494]
	Learning Rate: 0.00354942
	LOSS [training: 0.2900588506665779 | validation: 0.11778585526598719]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21427248217120742		[learning rate: 0.0035365]
	Learning Rate: 0.00353654
	LOSS [training: 0.21427248217120742 | validation: 0.32631186747849406]
	TIME [epoch: 8.44 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.31273715534596225		[learning rate: 0.0035237]
	Learning Rate: 0.00352371
	LOSS [training: 0.31273715534596225 | validation: 0.38031518450627866]
	TIME [epoch: 8.44 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1844587891141786		[learning rate: 0.0035109]
	Learning Rate: 0.00351092
	LOSS [training: 0.1844587891141786 | validation: 0.2847606718829505]
	TIME [epoch: 8.44 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.249758655937377		[learning rate: 0.0034982]
	Learning Rate: 0.00349818
	LOSS [training: 0.249758655937377 | validation: 0.23518264163633157]
	TIME [epoch: 8.47 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2096223682303092		[learning rate: 0.0034855]
	Learning Rate: 0.00348548
	LOSS [training: 0.2096223682303092 | validation: 0.13364594220985337]
	TIME [epoch: 8.44 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22340138063266796		[learning rate: 0.0034728]
	Learning Rate: 0.00347284
	LOSS [training: 0.22340138063266796 | validation: 0.18275708984778127]
	TIME [epoch: 8.43 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2055441706636036		[learning rate: 0.0034602]
	Learning Rate: 0.00346023
	LOSS [training: 0.2055441706636036 | validation: 0.33149627203240006]
	TIME [epoch: 8.43 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2045475024621751		[learning rate: 0.0034477]
	Learning Rate: 0.00344767
	LOSS [training: 0.2045475024621751 | validation: 0.17058567206831532]
	TIME [epoch: 8.45 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19674304513684385		[learning rate: 0.0034352]
	Learning Rate: 0.00343516
	LOSS [training: 0.19674304513684385 | validation: 0.16219495784464932]
	TIME [epoch: 8.44 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2090805827850782		[learning rate: 0.0034227]
	Learning Rate: 0.0034227
	LOSS [training: 0.2090805827850782 | validation: 0.20055128778729397]
	TIME [epoch: 8.43 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24547698082078093		[learning rate: 0.0034103]
	Learning Rate: 0.00341028
	LOSS [training: 0.24547698082078093 | validation: 0.22588587869799487]
	TIME [epoch: 8.43 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18354245642885242		[learning rate: 0.0033979]
	Learning Rate: 0.0033979
	LOSS [training: 0.18354245642885242 | validation: 0.3970805859279696]
	TIME [epoch: 8.45 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3079542556128933		[learning rate: 0.0033856]
	Learning Rate: 0.00338557
	LOSS [training: 0.3079542556128933 | validation: 0.1718831916191839]
	TIME [epoch: 8.44 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20395817770170704		[learning rate: 0.0033733]
	Learning Rate: 0.00337328
	LOSS [training: 0.20395817770170704 | validation: 0.26415044063871584]
	TIME [epoch: 8.42 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21341112574341534		[learning rate: 0.003361]
	Learning Rate: 0.00336104
	LOSS [training: 0.21341112574341534 | validation: 0.3771484795570149]
	TIME [epoch: 8.46 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2075331891724334		[learning rate: 0.0033488]
	Learning Rate: 0.00334884
	LOSS [training: 0.2075331891724334 | validation: 0.2678063127583658]
	TIME [epoch: 8.44 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19529157123960666		[learning rate: 0.0033367]
	Learning Rate: 0.00333669
	LOSS [training: 0.19529157123960666 | validation: 0.2839845231458632]
	TIME [epoch: 8.43 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26910119213043515		[learning rate: 0.0033246]
	Learning Rate: 0.00332458
	LOSS [training: 0.26910119213043515 | validation: 0.22404443909683158]
	TIME [epoch: 8.43 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2223946968856377		[learning rate: 0.0033125]
	Learning Rate: 0.00331252
	LOSS [training: 0.2223946968856377 | validation: 0.2565591116305122]
	TIME [epoch: 8.46 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19421866847704033		[learning rate: 0.0033005]
	Learning Rate: 0.00330049
	LOSS [training: 0.19421866847704033 | validation: 0.22095710426951076]
	TIME [epoch: 8.43 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1933154032322014		[learning rate: 0.0032885]
	Learning Rate: 0.00328852
	LOSS [training: 0.1933154032322014 | validation: 0.3976114216572028]
	TIME [epoch: 8.43 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2661640313541669		[learning rate: 0.0032766]
	Learning Rate: 0.00327658
	LOSS [training: 0.2661640313541669 | validation: 0.3533678089660602]
	TIME [epoch: 8.44 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22988556110255987		[learning rate: 0.0032647]
	Learning Rate: 0.00326469
	LOSS [training: 0.22988556110255987 | validation: 0.2465565071071219]
	TIME [epoch: 8.46 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23178809501234535		[learning rate: 0.0032528]
	Learning Rate: 0.00325284
	LOSS [training: 0.23178809501234535 | validation: 0.18713628115011433]
	TIME [epoch: 8.43 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21285458066210702		[learning rate: 0.003241]
	Learning Rate: 0.00324104
	LOSS [training: 0.21285458066210702 | validation: 0.24890762522056908]
	TIME [epoch: 8.43 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2169849416807436		[learning rate: 0.0032293]
	Learning Rate: 0.00322928
	LOSS [training: 0.2169849416807436 | validation: 0.2069019734337861]
	TIME [epoch: 8.46 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2278345229852528		[learning rate: 0.0032176]
	Learning Rate: 0.00321756
	LOSS [training: 0.2278345229852528 | validation: 0.13721319847415403]
	TIME [epoch: 8.43 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1666434983285418		[learning rate: 0.0032059]
	Learning Rate: 0.00320588
	LOSS [training: 0.1666434983285418 | validation: 0.2650969509821327]
	TIME [epoch: 8.44 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20393313137570143		[learning rate: 0.0031942]
	Learning Rate: 0.00319425
	LOSS [training: 0.20393313137570143 | validation: 0.36605146562992275]
	TIME [epoch: 8.43 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19804809503540824		[learning rate: 0.0031827]
	Learning Rate: 0.00318265
	LOSS [training: 0.19804809503540824 | validation: 0.16270637956803607]
	TIME [epoch: 8.46 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24123346233194062		[learning rate: 0.0031711]
	Learning Rate: 0.0031711
	LOSS [training: 0.24123346233194062 | validation: 0.3221147290451518]
	TIME [epoch: 8.43 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24414247035550524		[learning rate: 0.0031596]
	Learning Rate: 0.0031596
	LOSS [training: 0.24414247035550524 | validation: 0.25273869640451596]
	TIME [epoch: 8.43 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21865925146638904		[learning rate: 0.0031481]
	Learning Rate: 0.00314813
	LOSS [training: 0.21865925146638904 | validation: 0.35832717999367253]
	TIME [epoch: 8.46 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22449517198770202		[learning rate: 0.0031367]
	Learning Rate: 0.00313671
	LOSS [training: 0.22449517198770202 | validation: 0.2190471307320926]
	TIME [epoch: 8.44 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21193712903546258		[learning rate: 0.0031253]
	Learning Rate: 0.00312532
	LOSS [training: 0.21193712903546258 | validation: 0.28396266676374876]
	TIME [epoch: 8.44 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2056916671062312		[learning rate: 0.003114]
	Learning Rate: 0.00311398
	LOSS [training: 0.2056916671062312 | validation: 0.2773242479419423]
	TIME [epoch: 8.43 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22330298047036928		[learning rate: 0.0031027]
	Learning Rate: 0.00310268
	LOSS [training: 0.22330298047036928 | validation: 0.1357552309483344]
	TIME [epoch: 8.45 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21360796751277594		[learning rate: 0.0030914]
	Learning Rate: 0.00309142
	LOSS [training: 0.21360796751277594 | validation: 0.2411175734620757]
	TIME [epoch: 8.43 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.3328861820646404		[learning rate: 0.0030802]
	Learning Rate: 0.0030802
	LOSS [training: 0.3328861820646404 | validation: 0.22122761824177595]
	TIME [epoch: 8.43 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20598455067105026		[learning rate: 0.003069]
	Learning Rate: 0.00306902
	LOSS [training: 0.20598455067105026 | validation: 0.17036451844524286]
	TIME [epoch: 8.45 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21942038070379727		[learning rate: 0.0030579]
	Learning Rate: 0.00305788
	LOSS [training: 0.21942038070379727 | validation: 0.282145546414986]
	TIME [epoch: 8.44 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21581110794506236		[learning rate: 0.0030468]
	Learning Rate: 0.00304679
	LOSS [training: 0.21581110794506236 | validation: 0.19094901156736294]
	TIME [epoch: 8.44 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19044164300654493		[learning rate: 0.0030357]
	Learning Rate: 0.00303573
	LOSS [training: 0.19044164300654493 | validation: 0.1798376133877097]
	TIME [epoch: 8.43 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.233530155815226		[learning rate: 0.0030247]
	Learning Rate: 0.00302471
	LOSS [training: 0.233530155815226 | validation: 0.13826662752740126]
	TIME [epoch: 8.46 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24972632717902607		[learning rate: 0.0030137]
	Learning Rate: 0.00301374
	LOSS [training: 0.24972632717902607 | validation: 0.465301468468779]
	TIME [epoch: 8.44 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2218503677087904		[learning rate: 0.0030028]
	Learning Rate: 0.0030028
	LOSS [training: 0.2218503677087904 | validation: 0.19134119629193558]
	TIME [epoch: 8.43 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18222799813756424		[learning rate: 0.0029919]
	Learning Rate: 0.0029919
	LOSS [training: 0.18222799813756424 | validation: 0.3812058360579935]
	TIME [epoch: 8.44 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1892228626344242		[learning rate: 0.002981]
	Learning Rate: 0.00298104
	LOSS [training: 0.1892228626344242 | validation: 0.44706932426294166]
	TIME [epoch: 8.46 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2426613241891201		[learning rate: 0.0029702]
	Learning Rate: 0.00297023
	LOSS [training: 0.2426613241891201 | validation: 0.3004004892987231]
	TIME [epoch: 8.43 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16921293003339183		[learning rate: 0.0029594]
	Learning Rate: 0.00295945
	LOSS [training: 0.16921293003339183 | validation: 0.24237381173152034]
	TIME [epoch: 8.44 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20477700652123385		[learning rate: 0.0029487]
	Learning Rate: 0.00294871
	LOSS [training: 0.20477700652123385 | validation: 0.31744129529281]
	TIME [epoch: 8.46 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19587381146167337		[learning rate: 0.002938]
	Learning Rate: 0.00293801
	LOSS [training: 0.19587381146167337 | validation: 0.3042999267213501]
	TIME [epoch: 8.44 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20233866639886813		[learning rate: 0.0029273]
	Learning Rate: 0.00292734
	LOSS [training: 0.20233866639886813 | validation: 0.19953392105895895]
	TIME [epoch: 8.44 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18349830472032264		[learning rate: 0.0029167]
	Learning Rate: 0.00291672
	LOSS [training: 0.18349830472032264 | validation: 0.28531548336313817]
	TIME [epoch: 8.44 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19946254765118018		[learning rate: 0.0029061]
	Learning Rate: 0.00290614
	LOSS [training: 0.19946254765118018 | validation: 0.1240424849728895]
	TIME [epoch: 8.45 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19383496470218672		[learning rate: 0.0028956]
	Learning Rate: 0.00289559
	LOSS [training: 0.19383496470218672 | validation: 0.15008066428552014]
	TIME [epoch: 8.43 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20206477691693564		[learning rate: 0.0028851]
	Learning Rate: 0.00288508
	LOSS [training: 0.20206477691693564 | validation: 0.19280042669131603]
	TIME [epoch: 8.43 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22859358136407767		[learning rate: 0.0028746]
	Learning Rate: 0.00287461
	LOSS [training: 0.22859358136407767 | validation: 0.36642924984302305]
	TIME [epoch: 8.46 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21220317156132978		[learning rate: 0.0028642]
	Learning Rate: 0.00286418
	LOSS [training: 0.21220317156132978 | validation: 0.25069760444359124]
	TIME [epoch: 8.44 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2178846226753101		[learning rate: 0.0028538]
	Learning Rate: 0.00285378
	LOSS [training: 0.2178846226753101 | validation: 0.19054838267835839]
	TIME [epoch: 8.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.23884832887137555		[learning rate: 0.0028434]
	Learning Rate: 0.00284343
	LOSS [training: 0.23884832887137555 | validation: 0.20719513524368854]
	TIME [epoch: 8.43 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16841427114220403		[learning rate: 0.0028331]
	Learning Rate: 0.00283311
	LOSS [training: 0.16841427114220403 | validation: 0.14797638906269894]
	TIME [epoch: 8.46 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20836141841837447		[learning rate: 0.0028228]
	Learning Rate: 0.00282283
	LOSS [training: 0.20836141841837447 | validation: 0.31346268295570084]
	TIME [epoch: 8.43 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1983580357353833		[learning rate: 0.0028126]
	Learning Rate: 0.00281258
	LOSS [training: 0.1983580357353833 | validation: 0.12241977234368764]
	TIME [epoch: 8.44 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16214746070957203		[learning rate: 0.0028024]
	Learning Rate: 0.00280238
	LOSS [training: 0.16214746070957203 | validation: 0.18675210989447596]
	TIME [epoch: 8.46 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24432999106665437		[learning rate: 0.0027922]
	Learning Rate: 0.00279221
	LOSS [training: 0.24432999106665437 | validation: 0.133178531910436]
	TIME [epoch: 8.45 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16518687955949668		[learning rate: 0.0027821]
	Learning Rate: 0.00278207
	LOSS [training: 0.16518687955949668 | validation: 0.19165260310246512]
	TIME [epoch: 8.43 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18527680112515743		[learning rate: 0.002772]
	Learning Rate: 0.00277198
	LOSS [training: 0.18527680112515743 | validation: 0.240472965769654]
	TIME [epoch: 8.43 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21094758713110062		[learning rate: 0.0027619]
	Learning Rate: 0.00276192
	LOSS [training: 0.21094758713110062 | validation: 0.16875613136438178]
	TIME [epoch: 8.46 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15959978813553297		[learning rate: 0.0027519]
	Learning Rate: 0.00275189
	LOSS [training: 0.15959978813553297 | validation: 0.17931419212558972]
	TIME [epoch: 8.44 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21241018562030503		[learning rate: 0.0027419]
	Learning Rate: 0.00274191
	LOSS [training: 0.21241018562030503 | validation: 0.32772129177629716]
	TIME [epoch: 8.43 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19807787299400084		[learning rate: 0.002732]
	Learning Rate: 0.00273196
	LOSS [training: 0.19807787299400084 | validation: 0.22509272767557612]
	TIME [epoch: 8.45 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.26144771340188255		[learning rate: 0.002722]
	Learning Rate: 0.00272204
	LOSS [training: 0.26144771340188255 | validation: 0.21493940584364699]
	TIME [epoch: 8.44 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2195923888919467		[learning rate: 0.0027122]
	Learning Rate: 0.00271216
	LOSS [training: 0.2195923888919467 | validation: 0.2245593600796964]
	TIME [epoch: 8.43 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15421487202841583		[learning rate: 0.0027023]
	Learning Rate: 0.00270232
	LOSS [training: 0.15421487202841583 | validation: 0.1630287212490169]
	TIME [epoch: 8.43 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19158581538621766		[learning rate: 0.0026925]
	Learning Rate: 0.00269251
	LOSS [training: 0.19158581538621766 | validation: 0.19037063548302574]
	TIME [epoch: 8.46 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1850020697990431		[learning rate: 0.0026827]
	Learning Rate: 0.00268274
	LOSS [training: 0.1850020697990431 | validation: 0.15965333063786197]
	TIME [epoch: 8.44 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18255530320868912		[learning rate: 0.002673]
	Learning Rate: 0.00267301
	LOSS [training: 0.18255530320868912 | validation: 0.19317026531072234]
	TIME [epoch: 8.42 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2382740884161419		[learning rate: 0.0026633]
	Learning Rate: 0.00266331
	LOSS [training: 0.2382740884161419 | validation: 0.33765499563209966]
	TIME [epoch: 8.43 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21198827848401508		[learning rate: 0.0026536]
	Learning Rate: 0.00265364
	LOSS [training: 0.21198827848401508 | validation: 0.1385073993974806]
	TIME [epoch: 8.45 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17268537232864076		[learning rate: 0.002644]
	Learning Rate: 0.00264401
	LOSS [training: 0.17268537232864076 | validation: 0.1668234731136413]
	TIME [epoch: 8.43 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1956113281139795		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.1956113281139795 | validation: 0.18367162460608255]
	TIME [epoch: 8.44 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.177046501745858		[learning rate: 0.0026249]
	Learning Rate: 0.00262485
	LOSS [training: 0.177046501745858 | validation: 0.23262466044915847]
	TIME [epoch: 8.46 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22043916600516072		[learning rate: 0.0026153]
	Learning Rate: 0.00261533
	LOSS [training: 0.22043916600516072 | validation: 0.18006307448452655]
	TIME [epoch: 8.44 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16149881123108248		[learning rate: 0.0026058]
	Learning Rate: 0.00260584
	LOSS [training: 0.16149881123108248 | validation: 0.26198998587406763]
	TIME [epoch: 8.43 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22818234604486004		[learning rate: 0.0025964]
	Learning Rate: 0.00259638
	LOSS [training: 0.22818234604486004 | validation: 0.23874786884246935]
	TIME [epoch: 8.43 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1620946951670127		[learning rate: 0.002587]
	Learning Rate: 0.00258696
	LOSS [training: 0.1620946951670127 | validation: 0.32120545210636]
	TIME [epoch: 8.46 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.20052686526902944		[learning rate: 0.0025776]
	Learning Rate: 0.00257757
	LOSS [training: 0.20052686526902944 | validation: 0.24569761381000987]
	TIME [epoch: 8.43 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18488159259119147		[learning rate: 0.0025682]
	Learning Rate: 0.00256822
	LOSS [training: 0.18488159259119147 | validation: 0.17649518540953488]
	TIME [epoch: 8.43 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15222607568036176		[learning rate: 0.0025589]
	Learning Rate: 0.0025589
	LOSS [training: 0.15222607568036176 | validation: 0.11973749883289303]
	TIME [epoch: 8.43 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15431906595825634		[learning rate: 0.0025496]
	Learning Rate: 0.00254961
	LOSS [training: 0.15431906595825634 | validation: 0.14389523313441605]
	TIME [epoch: 8.43 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18578138563774935		[learning rate: 0.0025404]
	Learning Rate: 0.00254036
	LOSS [training: 0.18578138563774935 | validation: 0.18828380532436517]
	TIME [epoch: 8.42 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1849070584273444		[learning rate: 0.0025311]
	Learning Rate: 0.00253114
	LOSS [training: 0.1849070584273444 | validation: 0.14089925476867185]
	TIME [epoch: 8.43 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22202046187794072		[learning rate: 0.002522]
	Learning Rate: 0.00252195
	LOSS [training: 0.22202046187794072 | validation: 0.27734243360761035]
	TIME [epoch: 8.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1889897650153493		[learning rate: 0.0025128]
	Learning Rate: 0.0025128
	LOSS [training: 0.1889897650153493 | validation: 0.20290706714948542]
	TIME [epoch: 8.42 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17064424312961904		[learning rate: 0.0025037]
	Learning Rate: 0.00250368
	LOSS [training: 0.17064424312961904 | validation: 0.18323933219919564]
	TIME [epoch: 8.42 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15703463841616055		[learning rate: 0.0024946]
	Learning Rate: 0.00249459
	LOSS [training: 0.15703463841616055 | validation: 0.1797526655739272]
	TIME [epoch: 8.43 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18232797682049337		[learning rate: 0.0024855]
	Learning Rate: 0.00248554
	LOSS [training: 0.18232797682049337 | validation: 0.16753970870076906]
	TIME [epoch: 8.44 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17418106513106663		[learning rate: 0.0024765]
	Learning Rate: 0.00247652
	LOSS [training: 0.17418106513106663 | validation: 0.13091922899684305]
	TIME [epoch: 8.42 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922480033101114		[learning rate: 0.0024675]
	Learning Rate: 0.00246753
	LOSS [training: 0.1922480033101114 | validation: 0.18491643307735323]
	TIME [epoch: 8.43 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15881530896838203		[learning rate: 0.0024586]
	Learning Rate: 0.00245858
	LOSS [training: 0.15881530896838203 | validation: 0.23292862942822234]
	TIME [epoch: 8.45 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22519458062007783		[learning rate: 0.0024497]
	Learning Rate: 0.00244966
	LOSS [training: 0.22519458062007783 | validation: 0.19753625120914337]
	TIME [epoch: 8.43 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1512910503949532		[learning rate: 0.0024408]
	Learning Rate: 0.00244077
	LOSS [training: 0.1512910503949532 | validation: 0.15340966104901943]
	TIME [epoch: 8.44 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16113746750389776		[learning rate: 0.0024319]
	Learning Rate: 0.00243191
	LOSS [training: 0.16113746750389776 | validation: 0.13672792262539943]
	TIME [epoch: 8.43 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2014437328385045		[learning rate: 0.0024231]
	Learning Rate: 0.00242308
	LOSS [training: 0.2014437328385045 | validation: 0.32249026693738697]
	TIME [epoch: 8.46 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18581558635829695		[learning rate: 0.0024143]
	Learning Rate: 0.00241429
	LOSS [training: 0.18581558635829695 | validation: 0.2650282042573339]
	TIME [epoch: 8.42 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16973867054685696		[learning rate: 0.0024055]
	Learning Rate: 0.00240553
	LOSS [training: 0.16973867054685696 | validation: 0.15957173231185756]
	TIME [epoch: 8.42 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2712517185051007		[learning rate: 0.0023968]
	Learning Rate: 0.0023968
	LOSS [training: 0.2712517185051007 | validation: 0.1263016495008617]
	TIME [epoch: 8.44 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16926812703502908		[learning rate: 0.0023881]
	Learning Rate: 0.0023881
	LOSS [training: 0.16926812703502908 | validation: 0.2909879214003549]
	TIME [epoch: 8.43 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.24518155547267367		[learning rate: 0.0023794]
	Learning Rate: 0.00237943
	LOSS [training: 0.24518155547267367 | validation: 0.2023304896022774]
	TIME [epoch: 8.43 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1565770659689371		[learning rate: 0.0023708]
	Learning Rate: 0.0023708
	LOSS [training: 0.1565770659689371 | validation: 0.1551857643913768]
	TIME [epoch: 8.43 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19262715291515012		[learning rate: 0.0023622]
	Learning Rate: 0.0023622
	LOSS [training: 0.19262715291515012 | validation: 0.2711448386787556]
	TIME [epoch: 8.46 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18105170266108553		[learning rate: 0.0023536]
	Learning Rate: 0.00235362
	LOSS [training: 0.18105170266108553 | validation: 0.1890695938370437]
	TIME [epoch: 8.43 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16598667510855042		[learning rate: 0.0023451]
	Learning Rate: 0.00234508
	LOSS [training: 0.16598667510855042 | validation: 0.24892251013633726]
	TIME [epoch: 8.42 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15555626617872279		[learning rate: 0.0023366]
	Learning Rate: 0.00233657
	LOSS [training: 0.15555626617872279 | validation: 0.19848607433228446]
	TIME [epoch: 8.43 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16062008491329885		[learning rate: 0.0023281]
	Learning Rate: 0.00232809
	LOSS [training: 0.16062008491329885 | validation: 0.2329831520843974]
	TIME [epoch: 8.45 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18045923776370967		[learning rate: 0.0023196]
	Learning Rate: 0.00231964
	LOSS [training: 0.18045923776370967 | validation: 0.14319711560310994]
	TIME [epoch: 8.43 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13287127599837936		[learning rate: 0.0023112]
	Learning Rate: 0.00231122
	LOSS [training: 0.13287127599837936 | validation: 0.22932006339338218]
	TIME [epoch: 8.42 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18986143859653845		[learning rate: 0.0023028]
	Learning Rate: 0.00230284
	LOSS [training: 0.18986143859653845 | validation: 0.2691677204791101]
	TIME [epoch: 8.45 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.2030644328658826		[learning rate: 0.0022945]
	Learning Rate: 0.00229448
	LOSS [training: 0.2030644328658826 | validation: 0.1508949654498193]
	TIME [epoch: 8.44 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18958500416130059		[learning rate: 0.0022862]
	Learning Rate: 0.00228615
	LOSS [training: 0.18958500416130059 | validation: 0.31499357169486847]
	TIME [epoch: 8.45 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18007518278641405		[learning rate: 0.0022779]
	Learning Rate: 0.00227786
	LOSS [training: 0.18007518278641405 | validation: 0.2667948613492217]
	TIME [epoch: 8.45 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1385055494244222		[learning rate: 0.0022696]
	Learning Rate: 0.00226959
	LOSS [training: 0.1385055494244222 | validation: 0.13735630137218452]
	TIME [epoch: 8.46 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14717165766089896		[learning rate: 0.0022614]
	Learning Rate: 0.00226135
	LOSS [training: 0.14717165766089896 | validation: 0.20341783116649528]
	TIME [epoch: 8.45 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18880476794516526		[learning rate: 0.0022531]
	Learning Rate: 0.00225315
	LOSS [training: 0.18880476794516526 | validation: 0.20836877415718594]
	TIME [epoch: 8.44 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1737858314223357		[learning rate: 0.002245]
	Learning Rate: 0.00224497
	LOSS [training: 0.1737858314223357 | validation: 0.15088176407374518]
	TIME [epoch: 8.47 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.21130063416600936		[learning rate: 0.0022368]
	Learning Rate: 0.00223682
	LOSS [training: 0.21130063416600936 | validation: 0.18381851302725588]
	TIME [epoch: 8.45 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1730828937452164		[learning rate: 0.0022287]
	Learning Rate: 0.00222871
	LOSS [training: 0.1730828937452164 | validation: 0.201882856027149]
	TIME [epoch: 8.44 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16444737801601467		[learning rate: 0.0022206]
	Learning Rate: 0.00222062
	LOSS [training: 0.16444737801601467 | validation: 0.1725819003015664]
	TIME [epoch: 8.44 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15506676985070847		[learning rate: 0.0022126]
	Learning Rate: 0.00221256
	LOSS [training: 0.15506676985070847 | validation: 0.15625568092780176]
	TIME [epoch: 8.47 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19560036691154717		[learning rate: 0.0022045]
	Learning Rate: 0.00220453
	LOSS [training: 0.19560036691154717 | validation: 0.32478294383054707]
	TIME [epoch: 8.44 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16355178872605053		[learning rate: 0.0021965]
	Learning Rate: 0.00219653
	LOSS [training: 0.16355178872605053 | validation: 0.13160673665977463]
	TIME [epoch: 8.44 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1507610820575649		[learning rate: 0.0021886]
	Learning Rate: 0.00218856
	LOSS [training: 0.1507610820575649 | validation: 0.23590490350382023]
	TIME [epoch: 8.47 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22639872069943912		[learning rate: 0.0021806]
	Learning Rate: 0.00218061
	LOSS [training: 0.22639872069943912 | validation: 0.14331716522970372]
	TIME [epoch: 8.45 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16634667782648913		[learning rate: 0.0021727]
	Learning Rate: 0.0021727
	LOSS [training: 0.16634667782648913 | validation: 0.11289008414696616]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16523676398847692		[learning rate: 0.0021648]
	Learning Rate: 0.00216482
	LOSS [training: 0.16523676398847692 | validation: 0.17991795677655087]
	TIME [epoch: 8.46 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13976372222951658		[learning rate: 0.002157]
	Learning Rate: 0.00215696
	LOSS [training: 0.13976372222951658 | validation: 0.14494645374570916]
	TIME [epoch: 8.48 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14175727151635453		[learning rate: 0.0021491]
	Learning Rate: 0.00214913
	LOSS [training: 0.14175727151635453 | validation: 0.12653249437813854]
	TIME [epoch: 8.45 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1611355481583803		[learning rate: 0.0021413]
	Learning Rate: 0.00214133
	LOSS [training: 0.1611355481583803 | validation: 0.1463952675391331]
	TIME [epoch: 8.45 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13193592178969385		[learning rate: 0.0021336]
	Learning Rate: 0.00213356
	LOSS [training: 0.13193592178969385 | validation: 0.12847712028820618]
	TIME [epoch: 8.46 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16509389734538646		[learning rate: 0.0021258]
	Learning Rate: 0.00212582
	LOSS [training: 0.16509389734538646 | validation: 0.15175527542256173]
	TIME [epoch: 8.48 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15809154400403003		[learning rate: 0.0021181]
	Learning Rate: 0.0021181
	LOSS [training: 0.15809154400403003 | validation: 0.16283540578691735]
	TIME [epoch: 8.44 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1439764977002755		[learning rate: 0.0021104]
	Learning Rate: 0.00211042
	LOSS [training: 0.1439764977002755 | validation: 0.13219941616738595]
	TIME [epoch: 8.44 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16250601192136488		[learning rate: 0.0021028]
	Learning Rate: 0.00210276
	LOSS [training: 0.16250601192136488 | validation: 0.16064085945072154]
	TIME [epoch: 8.46 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18700945270696456		[learning rate: 0.0020951]
	Learning Rate: 0.00209513
	LOSS [training: 0.18700945270696456 | validation: 0.21372657659000915]
	TIME [epoch: 8.45 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1779354084072713		[learning rate: 0.0020875]
	Learning Rate: 0.00208752
	LOSS [training: 0.1779354084072713 | validation: 0.1002115878987441]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12812188560334364		[learning rate: 0.0020799]
	Learning Rate: 0.00207995
	LOSS [training: 0.12812188560334364 | validation: 0.2048708414633464]
	TIME [epoch: 8.44 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14310849084923752		[learning rate: 0.0020724]
	Learning Rate: 0.0020724
	LOSS [training: 0.14310849084923752 | validation: 0.20866774431551235]
	TIME [epoch: 8.46 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16792980481693331		[learning rate: 0.0020649]
	Learning Rate: 0.00206488
	LOSS [training: 0.16792980481693331 | validation: 0.23454502881801415]
	TIME [epoch: 8.44 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1729913531182709		[learning rate: 0.0020574]
	Learning Rate: 0.00205739
	LOSS [training: 0.1729913531182709 | validation: 0.19347499710666896]
	TIME [epoch: 8.43 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.136954356198845		[learning rate: 0.0020499]
	Learning Rate: 0.00204992
	LOSS [training: 0.136954356198845 | validation: 0.1289896554678926]
	TIME [epoch: 8.46 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16730726625556996		[learning rate: 0.0020425]
	Learning Rate: 0.00204248
	LOSS [training: 0.16730726625556996 | validation: 0.15706685400216594]
	TIME [epoch: 8.45 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16004123576115786		[learning rate: 0.0020351]
	Learning Rate: 0.00203507
	LOSS [training: 0.16004123576115786 | validation: 0.1732580876504388]
	TIME [epoch: 8.44 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17540992309771095		[learning rate: 0.0020277]
	Learning Rate: 0.00202768
	LOSS [training: 0.17540992309771095 | validation: 0.14653173846425588]
	TIME [epoch: 8.44 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14261943362188678		[learning rate: 0.0020203]
	Learning Rate: 0.00202032
	LOSS [training: 0.14261943362188678 | validation: 0.1511857270026662]
	TIME [epoch: 8.46 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1545770703926995		[learning rate: 0.002013]
	Learning Rate: 0.00201299
	LOSS [training: 0.1545770703926995 | validation: 0.1228217065040181]
	TIME [epoch: 8.44 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.30896262665282864		[learning rate: 0.0020057]
	Learning Rate: 0.00200569
	LOSS [training: 0.30896262665282864 | validation: 0.15506896845816442]
	TIME [epoch: 8.44 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14577546868429547		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.14577546868429547 | validation: 0.1577549474990604]
	TIME [epoch: 8.45 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18334373292829134		[learning rate: 0.0019912]
	Learning Rate: 0.00199116
	LOSS [training: 0.18334373292829134 | validation: 0.15842654123896158]
	TIME [epoch: 8.46 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19794083362973264		[learning rate: 0.0019839]
	Learning Rate: 0.00198393
	LOSS [training: 0.19794083362973264 | validation: 0.246614625637198]
	TIME [epoch: 8.44 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14168478171156731		[learning rate: 0.0019767]
	Learning Rate: 0.00197673
	LOSS [training: 0.14168478171156731 | validation: 0.2858139464430306]
	TIME [epoch: 8.44 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16180245709100052		[learning rate: 0.0019696]
	Learning Rate: 0.00196956
	LOSS [training: 0.16180245709100052 | validation: 0.15868960224759487]
	TIME [epoch: 8.46 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16121321182566742		[learning rate: 0.0019624]
	Learning Rate: 0.00196241
	LOSS [training: 0.16121321182566742 | validation: 0.12996278112075427]
	TIME [epoch: 8.44 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14932988366331543		[learning rate: 0.0019553]
	Learning Rate: 0.00195529
	LOSS [training: 0.14932988366331543 | validation: 0.26532546647373145]
	TIME [epoch: 8.44 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12426960763925488		[learning rate: 0.0019482]
	Learning Rate: 0.00194819
	LOSS [training: 0.12426960763925488 | validation: 0.1761931845118576]
	TIME [epoch: 8.44 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17808243877784308		[learning rate: 0.0019411]
	Learning Rate: 0.00194112
	LOSS [training: 0.17808243877784308 | validation: 0.24547314611122162]
	TIME [epoch: 8.45 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17162602625407777		[learning rate: 0.0019341]
	Learning Rate: 0.00193408
	LOSS [training: 0.17162602625407777 | validation: 0.13101519193844038]
	TIME [epoch: 8.44 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16929210074163792		[learning rate: 0.0019271]
	Learning Rate: 0.00192706
	LOSS [training: 0.16929210074163792 | validation: 0.16829589908669557]
	TIME [epoch: 8.44 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15338664719278347		[learning rate: 0.0019201]
	Learning Rate: 0.00192006
	LOSS [training: 0.15338664719278347 | validation: 0.26924774064405155]
	TIME [epoch: 8.46 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1182815657737389		[learning rate: 0.0019131]
	Learning Rate: 0.0019131
	LOSS [training: 0.1182815657737389 | validation: 0.12053471382741159]
	TIME [epoch: 8.44 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.22100070363373128		[learning rate: 0.0019062]
	Learning Rate: 0.00190615
	LOSS [training: 0.22100070363373128 | validation: 0.14336255708181492]
	TIME [epoch: 8.44 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16430782320282628		[learning rate: 0.0018992]
	Learning Rate: 0.00189924
	LOSS [training: 0.16430782320282628 | validation: 0.15060252720645903]
	TIME [epoch: 8.43 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1603721538120946		[learning rate: 0.0018923]
	Learning Rate: 0.00189234
	LOSS [training: 0.1603721538120946 | validation: 0.6051115960026036]
	TIME [epoch: 8.46 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19033321367916678		[learning rate: 0.0018855]
	Learning Rate: 0.00188548
	LOSS [training: 0.19033321367916678 | validation: 0.21634455865213711]
	TIME [epoch: 8.44 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12741678906744033		[learning rate: 0.0018786]
	Learning Rate: 0.00187863
	LOSS [training: 0.12741678906744033 | validation: 0.15968330093600927]
	TIME [epoch: 8.44 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13364269749364016		[learning rate: 0.0018718]
	Learning Rate: 0.00187182
	LOSS [training: 0.13364269749364016 | validation: 0.15758293904925488]
	TIME [epoch: 8.46 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1598653070612126		[learning rate: 0.001865]
	Learning Rate: 0.00186502
	LOSS [training: 0.1598653070612126 | validation: 0.24419233328679268]
	TIME [epoch: 8.45 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18343896605854237		[learning rate: 0.0018583]
	Learning Rate: 0.00185825
	LOSS [training: 0.18343896605854237 | validation: 0.24610173972768323]
	TIME [epoch: 8.44 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15158003441892656		[learning rate: 0.0018515]
	Learning Rate: 0.00185151
	LOSS [training: 0.15158003441892656 | validation: 0.14482444338179595]
	TIME [epoch: 8.43 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13541992301115474		[learning rate: 0.0018448]
	Learning Rate: 0.00184479
	LOSS [training: 0.13541992301115474 | validation: 0.11878323984301581]
	TIME [epoch: 8.47 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13995740269123802		[learning rate: 0.0018381]
	Learning Rate: 0.0018381
	LOSS [training: 0.13995740269123802 | validation: 0.29721948307709156]
	TIME [epoch: 8.44 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14594366426585934		[learning rate: 0.0018314]
	Learning Rate: 0.00183143
	LOSS [training: 0.14594366426585934 | validation: 0.1283911243988305]
	TIME [epoch: 8.44 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14390058410154596		[learning rate: 0.0018248]
	Learning Rate: 0.00182478
	LOSS [training: 0.14390058410154596 | validation: 0.17682224746085629]
	TIME [epoch: 8.45 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15292174576682901		[learning rate: 0.0018182]
	Learning Rate: 0.00181816
	LOSS [training: 0.15292174576682901 | validation: 0.1599000298409919]
	TIME [epoch: 8.45 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15401791150420266		[learning rate: 0.0018116]
	Learning Rate: 0.00181156
	LOSS [training: 0.15401791150420266 | validation: 0.1367000455672519]
	TIME [epoch: 8.44 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1569962921641119		[learning rate: 0.001805]
	Learning Rate: 0.00180499
	LOSS [training: 0.1569962921641119 | validation: 0.11927464376149746]
	TIME [epoch: 8.44 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13366085627407615		[learning rate: 0.0017984]
	Learning Rate: 0.00179844
	LOSS [training: 0.13366085627407615 | validation: 0.2079901633732072]
	TIME [epoch: 8.46 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14217745150779576		[learning rate: 0.0017919]
	Learning Rate: 0.00179191
	LOSS [training: 0.14217745150779576 | validation: 0.16943060547115352]
	TIME [epoch: 8.44 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13449999433407644		[learning rate: 0.0017854]
	Learning Rate: 0.00178541
	LOSS [training: 0.13449999433407644 | validation: 0.14977926118637797]
	TIME [epoch: 8.44 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12778049239337863		[learning rate: 0.0017789]
	Learning Rate: 0.00177893
	LOSS [training: 0.12778049239337863 | validation: 0.1749296408697122]
	TIME [epoch: 8.45 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13155518799795166		[learning rate: 0.0017725]
	Learning Rate: 0.00177247
	LOSS [training: 0.13155518799795166 | validation: 0.13000882288341195]
	TIME [epoch: 8.45 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17819619438537737		[learning rate: 0.001766]
	Learning Rate: 0.00176604
	LOSS [training: 0.17819619438537737 | validation: 0.17318846368705132]
	TIME [epoch: 8.44 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15008864736755095		[learning rate: 0.0017596]
	Learning Rate: 0.00175963
	LOSS [training: 0.15008864736755095 | validation: 0.18117393941715487]
	TIME [epoch: 8.43 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1578057119105024		[learning rate: 0.0017532]
	Learning Rate: 0.00175324
	LOSS [training: 0.1578057119105024 | validation: 0.2666165854432362]
	TIME [epoch: 8.46 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15506248158994732		[learning rate: 0.0017469]
	Learning Rate: 0.00174688
	LOSS [training: 0.15506248158994732 | validation: 0.1674724770649412]
	TIME [epoch: 8.44 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1502262379094495		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.1502262379094495 | validation: 0.11106984765586575]
	TIME [epoch: 8.44 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12156234647628054		[learning rate: 0.0017342]
	Learning Rate: 0.00173422
	LOSS [training: 0.12156234647628054 | validation: 0.17850273587153972]
	TIME [epoch: 8.44 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1559862098502772		[learning rate: 0.0017279]
	Learning Rate: 0.00172793
	LOSS [training: 0.1559862098502772 | validation: 0.11293454197358009]
	TIME [epoch: 8.47 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.163572880301728		[learning rate: 0.0017217]
	Learning Rate: 0.00172166
	LOSS [training: 0.163572880301728 | validation: 0.18826190937879989]
	TIME [epoch: 8.44 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15305457199448397		[learning rate: 0.0017154]
	Learning Rate: 0.00171541
	LOSS [training: 0.15305457199448397 | validation: 0.23721243784232515]
	TIME [epoch: 8.44 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17121616920434413		[learning rate: 0.0017092]
	Learning Rate: 0.00170919
	LOSS [training: 0.17121616920434413 | validation: 0.19771170867939658]
	TIME [epoch: 8.46 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16110874657747684		[learning rate: 0.001703]
	Learning Rate: 0.00170298
	LOSS [training: 0.16110874657747684 | validation: 0.1297221234606212]
	TIME [epoch: 8.44 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15965012996641886		[learning rate: 0.0016968]
	Learning Rate: 0.0016968
	LOSS [training: 0.15965012996641886 | validation: 0.18742470973702946]
	TIME [epoch: 8.44 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11703041398332206		[learning rate: 0.0016906]
	Learning Rate: 0.00169065
	LOSS [training: 0.11703041398332206 | validation: 0.14224589858755957]
	TIME [epoch: 8.44 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15660005337686286		[learning rate: 0.0016845]
	Learning Rate: 0.00168451
	LOSS [training: 0.15660005337686286 | validation: 0.1695164350786133]
	TIME [epoch: 8.46 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1542755216358852		[learning rate: 0.0016784]
	Learning Rate: 0.0016784
	LOSS [training: 0.1542755216358852 | validation: 0.13183239281761747]
	TIME [epoch: 8.44 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1487503669627846		[learning rate: 0.0016723]
	Learning Rate: 0.00167231
	LOSS [training: 0.1487503669627846 | validation: 0.12920848485309017]
	TIME [epoch: 8.43 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15326489869404064		[learning rate: 0.0016662]
	Learning Rate: 0.00166624
	LOSS [training: 0.15326489869404064 | validation: 0.14813896658675915]
	TIME [epoch: 8.45 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1302187864603451		[learning rate: 0.0016602]
	Learning Rate: 0.00166019
	LOSS [training: 0.1302187864603451 | validation: 0.1844369163529146]
	TIME [epoch: 8.45 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13780812187531263		[learning rate: 0.0016542]
	Learning Rate: 0.00165417
	LOSS [training: 0.13780812187531263 | validation: 0.17367799813672447]
	TIME [epoch: 8.44 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15691691594247642		[learning rate: 0.0016482]
	Learning Rate: 0.00164816
	LOSS [training: 0.15691691594247642 | validation: 0.1636271274502908]
	TIME [epoch: 8.43 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1289881899192012		[learning rate: 0.0016422]
	Learning Rate: 0.00164218
	LOSS [training: 0.1289881899192012 | validation: 0.17447025078590284]
	TIME [epoch: 8.46 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13647274510052607		[learning rate: 0.0016362]
	Learning Rate: 0.00163622
	LOSS [training: 0.13647274510052607 | validation: 0.16929549232279828]
	TIME [epoch: 8.44 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18263414334750985		[learning rate: 0.0016303]
	Learning Rate: 0.00163028
	LOSS [training: 0.18263414334750985 | validation: 0.10132797003423949]
	TIME [epoch: 8.43 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1115866624825104		[learning rate: 0.0016244]
	Learning Rate: 0.00162437
	LOSS [training: 0.1115866624825104 | validation: 0.15669841491749587]
	TIME [epoch: 8.44 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1250456419788089		[learning rate: 0.0016185]
	Learning Rate: 0.00161847
	LOSS [training: 0.1250456419788089 | validation: 0.13550634801965705]
	TIME [epoch: 8.45 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17302854165679413		[learning rate: 0.0016126]
	Learning Rate: 0.0016126
	LOSS [training: 0.17302854165679413 | validation: 0.12144951896525122]
	TIME [epoch: 8.44 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1657835548903393		[learning rate: 0.0016067]
	Learning Rate: 0.00160675
	LOSS [training: 0.1657835548903393 | validation: 0.1714275748854233]
	TIME [epoch: 8.44 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13916022392004485		[learning rate: 0.0016009]
	Learning Rate: 0.00160092
	LOSS [training: 0.13916022392004485 | validation: 0.11177442864916498]
	TIME [epoch: 8.46 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12745226471911067		[learning rate: 0.0015951]
	Learning Rate: 0.00159511
	LOSS [training: 0.12745226471911067 | validation: 0.15645943521658384]
	TIME [epoch: 8.44 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14676884958723427		[learning rate: 0.0015893]
	Learning Rate: 0.00158932
	LOSS [training: 0.14676884958723427 | validation: 0.1626127312475379]
	TIME [epoch: 8.44 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12027700614722633		[learning rate: 0.0015835]
	Learning Rate: 0.00158355
	LOSS [training: 0.12027700614722633 | validation: 0.27207649830894687]
	TIME [epoch: 8.44 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14223113009101152		[learning rate: 0.0015778]
	Learning Rate: 0.0015778
	LOSS [training: 0.14223113009101152 | validation: 0.1156616344169091]
	TIME [epoch: 8.45 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12122679809471763		[learning rate: 0.0015721]
	Learning Rate: 0.00157208
	LOSS [training: 0.12122679809471763 | validation: 0.133488351927157]
	TIME [epoch: 8.44 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13091447617929935		[learning rate: 0.0015664]
	Learning Rate: 0.00156637
	LOSS [training: 0.13091447617929935 | validation: 0.20351816252116467]
	TIME [epoch: 8.43 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15394709584211425		[learning rate: 0.0015607]
	Learning Rate: 0.00156069
	LOSS [training: 0.15394709584211425 | validation: 0.09406319712071468]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13172672949612954		[learning rate: 0.001555]
	Learning Rate: 0.00155502
	LOSS [training: 0.13172672949612954 | validation: 0.12322275850075023]
	TIME [epoch: 8.44 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12278058293343357		[learning rate: 0.0015494]
	Learning Rate: 0.00154938
	LOSS [training: 0.12278058293343357 | validation: 0.12210804020633124]
	TIME [epoch: 8.43 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1448233546954031		[learning rate: 0.0015438]
	Learning Rate: 0.00154376
	LOSS [training: 0.1448233546954031 | validation: 0.14771032897424707]
	TIME [epoch: 8.44 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11951148893274958		[learning rate: 0.0015382]
	Learning Rate: 0.00153815
	LOSS [training: 0.11951148893274958 | validation: 0.09243395370096907]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11896610327486974		[learning rate: 0.0015326]
	Learning Rate: 0.00153257
	LOSS [training: 0.11896610327486974 | validation: 0.1420881586098413]
	TIME [epoch: 8.44 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1223251369290611		[learning rate: 0.001527]
	Learning Rate: 0.00152701
	LOSS [training: 0.1223251369290611 | validation: 0.10858505397113627]
	TIME [epoch: 8.43 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10413115482244797		[learning rate: 0.0015215]
	Learning Rate: 0.00152147
	LOSS [training: 0.10413115482244797 | validation: 0.09159346044711861]
	TIME [epoch: 8.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10712317119399106		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.10712317119399106 | validation: 0.20218670380638573]
	TIME [epoch: 8.44 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12693025970667732		[learning rate: 0.0015104]
	Learning Rate: 0.00151045
	LOSS [training: 0.12693025970667732 | validation: 0.13101643685014142]
	TIME [epoch: 8.43 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.18665831601032937		[learning rate: 0.001505]
	Learning Rate: 0.00150496
	LOSS [training: 0.18665831601032937 | validation: 0.18648730490362414]
	TIME [epoch: 8.44 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16783650403134565		[learning rate: 0.0014995]
	Learning Rate: 0.0014995
	LOSS [training: 0.16783650403134565 | validation: 0.4436652727086951]
	TIME [epoch: 8.46 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1532339291257939		[learning rate: 0.0014941]
	Learning Rate: 0.00149406
	LOSS [training: 0.1532339291257939 | validation: 0.13792072236734784]
	TIME [epoch: 8.44 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12571727444231798		[learning rate: 0.0014886]
	Learning Rate: 0.00148864
	LOSS [training: 0.12571727444231798 | validation: 0.2611466594243554]
	TIME [epoch: 8.44 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15841613632804305		[learning rate: 0.0014832]
	Learning Rate: 0.00148324
	LOSS [training: 0.15841613632804305 | validation: 0.2061319150249935]
	TIME [epoch: 8.45 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1771706982242196		[learning rate: 0.0014779]
	Learning Rate: 0.00147785
	LOSS [training: 0.1771706982242196 | validation: 0.15514735725782752]
	TIME [epoch: 8.44 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15600493085232586		[learning rate: 0.0014725]
	Learning Rate: 0.00147249
	LOSS [training: 0.15600493085232586 | validation: 0.17839519708260948]
	TIME [epoch: 8.44 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12050997942281447		[learning rate: 0.0014671]
	Learning Rate: 0.00146715
	LOSS [training: 0.12050997942281447 | validation: 0.14600051937102088]
	TIME [epoch: 8.43 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11715714469318828		[learning rate: 0.0014618]
	Learning Rate: 0.00146182
	LOSS [training: 0.11715714469318828 | validation: 0.15167382888400693]
	TIME [epoch: 8.47 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.19809863200369396		[learning rate: 0.0014565]
	Learning Rate: 0.00145652
	LOSS [training: 0.19809863200369396 | validation: 0.180949109157728]
	TIME [epoch: 8.44 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10252532146782514		[learning rate: 0.0014512]
	Learning Rate: 0.00145123
	LOSS [training: 0.10252532146782514 | validation: 0.10909846207696447]
	TIME [epoch: 8.44 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16133537411950755		[learning rate: 0.001446]
	Learning Rate: 0.00144597
	LOSS [training: 0.16133537411950755 | validation: 0.31372574691995586]
	TIME [epoch: 8.45 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14266219194119265		[learning rate: 0.0014407]
	Learning Rate: 0.00144072
	LOSS [training: 0.14266219194119265 | validation: 0.11469496488727204]
	TIME [epoch: 8.45 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12203040200214714		[learning rate: 0.0014355]
	Learning Rate: 0.00143549
	LOSS [training: 0.12203040200214714 | validation: 0.12457938193709678]
	TIME [epoch: 8.44 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1288602223502936		[learning rate: 0.0014303]
	Learning Rate: 0.00143028
	LOSS [training: 0.1288602223502936 | validation: 0.21366358881384745]
	TIME [epoch: 8.44 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1317920803851663		[learning rate: 0.0014251]
	Learning Rate: 0.00142509
	LOSS [training: 0.1317920803851663 | validation: 0.1407615687225528]
	TIME [epoch: 8.46 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11227462053234201		[learning rate: 0.0014199]
	Learning Rate: 0.00141992
	LOSS [training: 0.11227462053234201 | validation: 0.09497094800949257]
	TIME [epoch: 8.44 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10558051756998817		[learning rate: 0.0014148]
	Learning Rate: 0.00141476
	LOSS [training: 0.10558051756998817 | validation: 0.11157090000932546]
	TIME [epoch: 8.44 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14556830539572432		[learning rate: 0.0014096]
	Learning Rate: 0.00140963
	LOSS [training: 0.14556830539572432 | validation: 0.1391956628985524]
	TIME [epoch: 8.44 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1257617519430313		[learning rate: 0.0014045]
	Learning Rate: 0.00140451
	LOSS [training: 0.1257617519430313 | validation: 0.152674641251329]
	TIME [epoch: 8.46 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12146396164471904		[learning rate: 0.0013994]
	Learning Rate: 0.00139942
	LOSS [training: 0.12146396164471904 | validation: 0.14309832605367195]
	TIME [epoch: 8.44 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539092041571727		[learning rate: 0.0013943]
	Learning Rate: 0.00139434
	LOSS [training: 0.11539092041571727 | validation: 0.13100000795967315]
	TIME [epoch: 8.44 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13271495510325237		[learning rate: 0.0013893]
	Learning Rate: 0.00138928
	LOSS [training: 0.13271495510325237 | validation: 0.1753850876334753]
	TIME [epoch: 8.46 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13942549451512576		[learning rate: 0.0013842]
	Learning Rate: 0.00138424
	LOSS [training: 0.13942549451512576 | validation: 0.15111956662054396]
	TIME [epoch: 8.45 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10511497188569803		[learning rate: 0.0013792]
	Learning Rate: 0.00137921
	LOSS [training: 0.10511497188569803 | validation: 0.16320414091781016]
	TIME [epoch: 8.43 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364879250152624		[learning rate: 0.0013742]
	Learning Rate: 0.00137421
	LOSS [training: 0.1364879250152624 | validation: 0.17207619817456804]
	TIME [epoch: 8.44 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13797612110479596		[learning rate: 0.0013692]
	Learning Rate: 0.00136922
	LOSS [training: 0.13797612110479596 | validation: 0.1297081706470888]
	TIME [epoch: 8.46 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17894863265567373		[learning rate: 0.0013643]
	Learning Rate: 0.00136425
	LOSS [training: 0.17894863265567373 | validation: 0.13846890986658195]
	TIME [epoch: 8.44 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13835941600545038		[learning rate: 0.0013593]
	Learning Rate: 0.0013593
	LOSS [training: 0.13835941600545038 | validation: 0.1931320133723993]
	TIME [epoch: 8.44 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1382660954165782		[learning rate: 0.0013544]
	Learning Rate: 0.00135437
	LOSS [training: 0.1382660954165782 | validation: 0.09231517964298033]
	TIME [epoch: 8.45 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12522098173059215		[learning rate: 0.0013495]
	Learning Rate: 0.00134945
	LOSS [training: 0.12522098173059215 | validation: 0.11905314146639522]
	TIME [epoch: 8.45 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11649287051950952		[learning rate: 0.0013446]
	Learning Rate: 0.00134456
	LOSS [training: 0.11649287051950952 | validation: 0.12225054479207142]
	TIME [epoch: 8.44 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13466725213404185		[learning rate: 0.0013397]
	Learning Rate: 0.00133968
	LOSS [training: 0.13466725213404185 | validation: 0.1916107393788591]
	TIME [epoch: 8.44 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.189736510732961		[learning rate: 0.0013348]
	Learning Rate: 0.00133481
	LOSS [training: 0.189736510732961 | validation: 0.15652638170612598]
	TIME [epoch: 8.46 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13276545833407413		[learning rate: 0.00133]
	Learning Rate: 0.00132997
	LOSS [training: 0.13276545833407413 | validation: 0.14626195923655957]
	TIME [epoch: 8.44 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11020466296582734		[learning rate: 0.0013251]
	Learning Rate: 0.00132514
	LOSS [training: 0.11020466296582734 | validation: 0.13566435983105785]
	TIME [epoch: 8.44 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1334309831623268		[learning rate: 0.0013203]
	Learning Rate: 0.00132034
	LOSS [training: 0.1334309831623268 | validation: 0.17276713068820193]
	TIME [epoch: 8.44 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11903807452943467		[learning rate: 0.0013155]
	Learning Rate: 0.00131554
	LOSS [training: 0.11903807452943467 | validation: 0.10713883886111857]
	TIME [epoch: 8.45 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12153631217071939		[learning rate: 0.0013108]
	Learning Rate: 0.00131077
	LOSS [training: 0.12153631217071939 | validation: 0.1479684423569793]
	TIME [epoch: 8.43 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1354369801353964		[learning rate: 0.001306]
	Learning Rate: 0.00130601
	LOSS [training: 0.1354369801353964 | validation: 0.15906702806333817]
	TIME [epoch: 8.44 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12519584864078054		[learning rate: 0.0013013]
	Learning Rate: 0.00130127
	LOSS [training: 0.12519584864078054 | validation: 0.3153329766112857]
	TIME [epoch: 8.46 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1550464186448918		[learning rate: 0.0012966]
	Learning Rate: 0.00129655
	LOSS [training: 0.1550464186448918 | validation: 0.10345874302149734]
	TIME [epoch: 8.44 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11742766168137209		[learning rate: 0.0012918]
	Learning Rate: 0.00129185
	LOSS [training: 0.11742766168137209 | validation: 0.13281212172387238]
	TIME [epoch: 8.43 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1922203458126019		[learning rate: 0.0012872]
	Learning Rate: 0.00128716
	LOSS [training: 0.1922203458126019 | validation: 0.09419574508621771]
	TIME [epoch: 8.44 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.130277189279612		[learning rate: 0.0012825]
	Learning Rate: 0.00128249
	LOSS [training: 0.130277189279612 | validation: 0.10758629135020945]
	TIME [epoch: 8.46 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09524146097977246		[learning rate: 0.0012778]
	Learning Rate: 0.00127783
	LOSS [training: 0.09524146097977246 | validation: 0.12012451853721418]
	TIME [epoch: 8.44 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10449377900171111		[learning rate: 0.0012732]
	Learning Rate: 0.00127319
	LOSS [training: 0.10449377900171111 | validation: 0.16078880422308978]
	TIME [epoch: 8.43 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14658704888954363		[learning rate: 0.0012686]
	Learning Rate: 0.00126857
	LOSS [training: 0.14658704888954363 | validation: 0.1681917713733564]
	TIME [epoch: 8.46 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1825324929842905		[learning rate: 0.001264]
	Learning Rate: 0.00126397
	LOSS [training: 0.1825324929842905 | validation: 0.1306019450919058]
	TIME [epoch: 8.44 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11833528614971019		[learning rate: 0.0012594]
	Learning Rate: 0.00125938
	LOSS [training: 0.11833528614971019 | validation: 0.15821744552100997]
	TIME [epoch: 8.43 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1364918013489402		[learning rate: 0.0012548]
	Learning Rate: 0.00125481
	LOSS [training: 0.1364918013489402 | validation: 0.12710873658143976]
	TIME [epoch: 8.44 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11935049391914121		[learning rate: 0.0012503]
	Learning Rate: 0.00125026
	LOSS [training: 0.11935049391914121 | validation: 0.13059126481906236]
	TIME [epoch: 8.46 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10548966278542167		[learning rate: 0.0012457]
	Learning Rate: 0.00124572
	LOSS [training: 0.10548966278542167 | validation: 0.18580528090510937]
	TIME [epoch: 8.44 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12676700491082404		[learning rate: 0.0012412]
	Learning Rate: 0.0012412
	LOSS [training: 0.12676700491082404 | validation: 0.09507725502819832]
	TIME [epoch: 8.43 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11397366178310811		[learning rate: 0.0012367]
	Learning Rate: 0.0012367
	LOSS [training: 0.11397366178310811 | validation: 0.12163380695897363]
	TIME [epoch: 8.45 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12576208620599733		[learning rate: 0.0012322]
	Learning Rate: 0.00123221
	LOSS [training: 0.12576208620599733 | validation: 0.1045215605459337]
	TIME [epoch: 8.44 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11582516216541541		[learning rate: 0.0012277]
	Learning Rate: 0.00122774
	LOSS [training: 0.11582516216541541 | validation: 0.18370721121594039]
	TIME [epoch: 8.43 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14502501526444875		[learning rate: 0.0012233]
	Learning Rate: 0.00122328
	LOSS [training: 0.14502501526444875 | validation: 0.0943629965375149]
	TIME [epoch: 8.44 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10875530199505719		[learning rate: 0.0012188]
	Learning Rate: 0.00121884
	LOSS [training: 0.10875530199505719 | validation: 0.15133572268679707]
	TIME [epoch: 8.46 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12277076347035365		[learning rate: 0.0012144]
	Learning Rate: 0.00121442
	LOSS [training: 0.12277076347035365 | validation: 0.11762332598385114]
	TIME [epoch: 8.43 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1442346951381749		[learning rate: 0.00121]
	Learning Rate: 0.00121001
	LOSS [training: 0.1442346951381749 | validation: 0.15281409077312216]
	TIME [epoch: 8.43 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11393957517770077		[learning rate: 0.0012056]
	Learning Rate: 0.00120562
	LOSS [training: 0.11393957517770077 | validation: 0.10160756601704292]
	TIME [epoch: 8.44 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11001636958384423		[learning rate: 0.0012012]
	Learning Rate: 0.00120125
	LOSS [training: 0.11001636958384423 | validation: 0.10011329943245688]
	TIME [epoch: 8.45 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13755715459055085		[learning rate: 0.0011969]
	Learning Rate: 0.00119689
	LOSS [training: 0.13755715459055085 | validation: 0.13337942646490464]
	TIME [epoch: 8.44 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1073108676303908		[learning rate: 0.0011925]
	Learning Rate: 0.00119254
	LOSS [training: 0.1073108676303908 | validation: 0.18463018335707349]
	TIME [epoch: 8.43 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15444236722055635		[learning rate: 0.0011882]
	Learning Rate: 0.00118821
	LOSS [training: 0.15444236722055635 | validation: 0.1208680248538464]
	TIME [epoch: 8.46 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10625421374453181		[learning rate: 0.0011839]
	Learning Rate: 0.0011839
	LOSS [training: 0.10625421374453181 | validation: 0.14433181571734005]
	TIME [epoch: 8.44 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14116254179421184		[learning rate: 0.0011796]
	Learning Rate: 0.00117961
	LOSS [training: 0.14116254179421184 | validation: 0.09052468822354255]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09245366700500238		[learning rate: 0.0011753]
	Learning Rate: 0.00117532
	LOSS [training: 0.09245366700500238 | validation: 0.10807942569961312]
	TIME [epoch: 8.45 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12225153969736528		[learning rate: 0.0011711]
	Learning Rate: 0.00117106
	LOSS [training: 0.12225153969736528 | validation: 0.09558606699299974]
	TIME [epoch: 8.45 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10244017747188623		[learning rate: 0.0011668]
	Learning Rate: 0.00116681
	LOSS [training: 0.10244017747188623 | validation: 0.11785175003207293]
	TIME [epoch: 8.43 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12326787962098659		[learning rate: 0.0011626]
	Learning Rate: 0.00116258
	LOSS [training: 0.12326787962098659 | validation: 0.2070239358069857]
	TIME [epoch: 8.44 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15041380602145368		[learning rate: 0.0011584]
	Learning Rate: 0.00115836
	LOSS [training: 0.15041380602145368 | validation: 0.1407331562620162]
	TIME [epoch: 8.46 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13429392923666328		[learning rate: 0.0011542]
	Learning Rate: 0.00115415
	LOSS [training: 0.13429392923666328 | validation: 0.14454257200886178]
	TIME [epoch: 8.44 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14806292625019565		[learning rate: 0.00115]
	Learning Rate: 0.00114996
	LOSS [training: 0.14806292625019565 | validation: 0.17894511587990522]
	TIME [epoch: 8.44 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13223575639914695		[learning rate: 0.0011458]
	Learning Rate: 0.00114579
	LOSS [training: 0.13223575639914695 | validation: 0.1769827655211112]
	TIME [epoch: 8.43 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13007673011464135		[learning rate: 0.0011416]
	Learning Rate: 0.00114163
	LOSS [training: 0.13007673011464135 | validation: 0.18679378540589625]
	TIME [epoch: 8.46 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11452766135856703		[learning rate: 0.0011375]
	Learning Rate: 0.00113749
	LOSS [training: 0.11452766135856703 | validation: 0.15017986153133087]
	TIME [epoch: 8.43 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15073283763916906		[learning rate: 0.0011334]
	Learning Rate: 0.00113336
	LOSS [training: 0.15073283763916906 | validation: 0.1665849347465363]
	TIME [epoch: 8.43 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11124582839418191		[learning rate: 0.0011292]
	Learning Rate: 0.00112925
	LOSS [training: 0.11124582839418191 | validation: 0.1544439637402522]
	TIME [epoch: 8.46 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1100239784884228		[learning rate: 0.0011252]
	Learning Rate: 0.00112515
	LOSS [training: 0.1100239784884228 | validation: 0.12800704863796314]
	TIME [epoch: 8.44 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10107352029388324		[learning rate: 0.0011211]
	Learning Rate: 0.00112107
	LOSS [training: 0.10107352029388324 | validation: 0.14883167048273171]
	TIME [epoch: 8.44 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12120225675557639		[learning rate: 0.001117]
	Learning Rate: 0.001117
	LOSS [training: 0.12120225675557639 | validation: 0.17096971093338864]
	TIME [epoch: 8.44 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12295529044142521		[learning rate: 0.0011129]
	Learning Rate: 0.00111295
	LOSS [training: 0.12295529044142521 | validation: 0.14518010569740414]
	TIME [epoch: 8.46 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13183895470585552		[learning rate: 0.0011089]
	Learning Rate: 0.00110891
	LOSS [training: 0.13183895470585552 | validation: 0.1599025401598312]
	TIME [epoch: 8.43 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12362973593210155		[learning rate: 0.0011049]
	Learning Rate: 0.00110488
	LOSS [training: 0.12362973593210155 | validation: 0.23967769103451586]
	TIME [epoch: 8.44 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14742813304459024		[learning rate: 0.0011009]
	Learning Rate: 0.00110087
	LOSS [training: 0.14742813304459024 | validation: 0.16721081406497926]
	TIME [epoch: 8.45 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11811187100232912		[learning rate: 0.0010969]
	Learning Rate: 0.00109688
	LOSS [training: 0.11811187100232912 | validation: 0.20144920880108114]
	TIME [epoch: 8.45 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13067246738734467		[learning rate: 0.0010929]
	Learning Rate: 0.0010929
	LOSS [training: 0.13067246738734467 | validation: 0.11167659612623922]
	TIME [epoch: 8.44 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11350999296629143		[learning rate: 0.0010889]
	Learning Rate: 0.00108893
	LOSS [training: 0.11350999296629143 | validation: 0.14460017219703164]
	TIME [epoch: 8.44 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12103560783774321		[learning rate: 0.001085]
	Learning Rate: 0.00108498
	LOSS [training: 0.12103560783774321 | validation: 0.09388828615848942]
	TIME [epoch: 8.46 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10561852877427194		[learning rate: 0.001081]
	Learning Rate: 0.00108104
	LOSS [training: 0.10561852877427194 | validation: 0.14211680148666908]
	TIME [epoch: 8.44 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1190487134856135		[learning rate: 0.0010771]
	Learning Rate: 0.00107712
	LOSS [training: 0.1190487134856135 | validation: 0.11066312024450277]
	TIME [epoch: 8.44 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.103741109668625		[learning rate: 0.0010732]
	Learning Rate: 0.00107321
	LOSS [training: 0.103741109668625 | validation: 0.1390001857630402]
	TIME [epoch: 8.45 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1108632767929183		[learning rate: 0.0010693]
	Learning Rate: 0.00106931
	LOSS [training: 0.1108632767929183 | validation: 0.0922143207528992]
	TIME [epoch: 8.46 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10163805900488816		[learning rate: 0.0010654]
	Learning Rate: 0.00106543
	LOSS [training: 0.10163805900488816 | validation: 0.12278804865860163]
	TIME [epoch: 8.43 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1353910488731945		[learning rate: 0.0010616]
	Learning Rate: 0.00106157
	LOSS [training: 0.1353910488731945 | validation: 0.13859216478086253]
	TIME [epoch: 8.44 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11114717794262123		[learning rate: 0.0010577]
	Learning Rate: 0.00105771
	LOSS [training: 0.11114717794262123 | validation: 0.10604589513058682]
	TIME [epoch: 8.46 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11275984352697115		[learning rate: 0.0010539]
	Learning Rate: 0.00105388
	LOSS [training: 0.11275984352697115 | validation: 0.08601266282974362]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12888357399689918		[learning rate: 0.0010501]
	Learning Rate: 0.00105005
	LOSS [training: 0.12888357399689918 | validation: 0.17447420709056338]
	TIME [epoch: 8.44 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13617517783350805		[learning rate: 0.0010462]
	Learning Rate: 0.00104624
	LOSS [training: 0.13617517783350805 | validation: 0.09330087994291959]
	TIME [epoch: 8.43 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0931391489851377		[learning rate: 0.0010424]
	Learning Rate: 0.00104244
	LOSS [training: 0.0931391489851377 | validation: 0.1448593827507689]
	TIME [epoch: 8.46 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09946819342553652		[learning rate: 0.0010387]
	Learning Rate: 0.00103866
	LOSS [training: 0.09946819342553652 | validation: 0.16694644776061188]
	TIME [epoch: 8.44 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.15036989764895967		[learning rate: 0.0010349]
	Learning Rate: 0.00103489
	LOSS [training: 0.15036989764895967 | validation: 0.11379472847913426]
	TIME [epoch: 8.43 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10840052166752814		[learning rate: 0.0010311]
	Learning Rate: 0.00103114
	LOSS [training: 0.10840052166752814 | validation: 0.11801282874807041]
	TIME [epoch: 8.45 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11078433428696359		[learning rate: 0.0010274]
	Learning Rate: 0.00102739
	LOSS [training: 0.11078433428696359 | validation: 0.12737248834471399]
	TIME [epoch: 8.44 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11666216687224303		[learning rate: 0.0010237]
	Learning Rate: 0.00102367
	LOSS [training: 0.11666216687224303 | validation: 0.14918606221262543]
	TIME [epoch: 8.44 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10962833885702464		[learning rate: 0.00102]
	Learning Rate: 0.00101995
	LOSS [training: 0.10962833885702464 | validation: 0.13428968498577254]
	TIME [epoch: 8.43 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10449077448209412		[learning rate: 0.0010162]
	Learning Rate: 0.00101625
	LOSS [training: 0.10449077448209412 | validation: 0.17098838064722852]
	TIME [epoch: 8.46 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11575281725007147		[learning rate: 0.0010126]
	Learning Rate: 0.00101256
	LOSS [training: 0.11575281725007147 | validation: 0.10984640071900666]
	TIME [epoch: 8.44 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11539409266514855		[learning rate: 0.0010089]
	Learning Rate: 0.00100889
	LOSS [training: 0.11539409266514855 | validation: 0.12377211527153076]
	TIME [epoch: 8.44 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13646548097180514		[learning rate: 0.0010052]
	Learning Rate: 0.00100522
	LOSS [training: 0.13646548097180514 | validation: 0.09488589549078681]
	TIME [epoch: 8.45 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0996923745332278		[learning rate: 0.0010016]
	Learning Rate: 0.00100158
	LOSS [training: 0.0996923745332278 | validation: 0.11403001999316138]
	TIME [epoch: 8.44 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10255847861102318		[learning rate: 0.00099794]
	Learning Rate: 0.000997942
	LOSS [training: 0.10255847861102318 | validation: 0.10048225575770797]
	TIME [epoch: 8.44 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10895988270883439		[learning rate: 0.00099432]
	Learning Rate: 0.00099432
	LOSS [training: 0.10895988270883439 | validation: 0.09925693237189291]
	TIME [epoch: 8.44 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0925031951263475		[learning rate: 0.00099071]
	Learning Rate: 0.000990712
	LOSS [training: 0.0925031951263475 | validation: 0.12521261242027243]
	TIME [epoch: 8.46 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10507082198712143		[learning rate: 0.00098712]
	Learning Rate: 0.000987116
	LOSS [training: 0.10507082198712143 | validation: 0.12259609284507883]
	TIME [epoch: 8.43 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10481220479203124		[learning rate: 0.00098353]
	Learning Rate: 0.000983534
	LOSS [training: 0.10481220479203124 | validation: 0.10566928196471417]
	TIME [epoch: 8.44 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08618066696211767		[learning rate: 0.00097996]
	Learning Rate: 0.000979965
	LOSS [training: 0.08618066696211767 | validation: 0.10350341492192736]
	TIME [epoch: 8.44 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1069553481068273		[learning rate: 0.00097641]
	Learning Rate: 0.000976409
	LOSS [training: 0.1069553481068273 | validation: 0.0918054132129813]
	TIME [epoch: 8.45 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1071148389054835		[learning rate: 0.00097287]
	Learning Rate: 0.000972865
	LOSS [training: 0.1071148389054835 | validation: 0.1481134855571359]
	TIME [epoch: 8.43 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12947247563278824		[learning rate: 0.00096933]
	Learning Rate: 0.000969335
	LOSS [training: 0.12947247563278824 | validation: 0.10228973619640595]
	TIME [epoch: 8.43 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10325829313535842		[learning rate: 0.00096582]
	Learning Rate: 0.000965817
	LOSS [training: 0.10325829313535842 | validation: 0.08824311964482412]
	TIME [epoch: 8.46 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09316981099348787		[learning rate: 0.00096231]
	Learning Rate: 0.000962312
	LOSS [training: 0.09316981099348787 | validation: 0.08900646630422675]
	TIME [epoch: 8.43 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11094027995106721		[learning rate: 0.00095882]
	Learning Rate: 0.00095882
	LOSS [training: 0.11094027995106721 | validation: 0.09439926897290497]
	TIME [epoch: 8.43 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10123698166056014		[learning rate: 0.00095534]
	Learning Rate: 0.00095534
	LOSS [training: 0.10123698166056014 | validation: 0.09575720132495484]
	TIME [epoch: 8.44 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11246221123100053		[learning rate: 0.00095187]
	Learning Rate: 0.000951873
	LOSS [training: 0.11246221123100053 | validation: 0.10639121327859154]
	TIME [epoch: 8.46 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09323159681751163		[learning rate: 0.00094842]
	Learning Rate: 0.000948419
	LOSS [training: 0.09323159681751163 | validation: 0.10686927706713109]
	TIME [epoch: 8.43 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09930773727439557		[learning rate: 0.00094498]
	Learning Rate: 0.000944977
	LOSS [training: 0.09930773727439557 | validation: 0.1424934126671582]
	TIME [epoch: 8.44 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10782397115580485		[learning rate: 0.00094155]
	Learning Rate: 0.000941547
	LOSS [training: 0.10782397115580485 | validation: 0.1855222844200321]
	TIME [epoch: 8.46 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12092608708172423		[learning rate: 0.00093813]
	Learning Rate: 0.00093813
	LOSS [training: 0.12092608708172423 | validation: 0.13073311061440365]
	TIME [epoch: 8.44 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1074200987326639		[learning rate: 0.00093473]
	Learning Rate: 0.000934726
	LOSS [training: 0.1074200987326639 | validation: 0.1151537297376333]
	TIME [epoch: 8.44 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.13203416005137752		[learning rate: 0.00093133]
	Learning Rate: 0.000931334
	LOSS [training: 0.13203416005137752 | validation: 0.156954366695759]
	TIME [epoch: 8.43 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09923337690709365		[learning rate: 0.00092795]
	Learning Rate: 0.000927954
	LOSS [training: 0.09923337690709365 | validation: 0.1543309496849186]
	TIME [epoch: 8.46 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14297624200949335		[learning rate: 0.00092459]
	Learning Rate: 0.000924586
	LOSS [training: 0.14297624200949335 | validation: 0.09182909292061898]
	TIME [epoch: 8.43 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09464464313446753		[learning rate: 0.00092123]
	Learning Rate: 0.000921231
	LOSS [training: 0.09464464313446753 | validation: 0.13327898121722587]
	TIME [epoch: 8.43 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09207079323124064		[learning rate: 0.00091789]
	Learning Rate: 0.000917888
	LOSS [training: 0.09207079323124064 | validation: 0.14254059889772813]
	TIME [epoch: 8.46 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12084327661250216		[learning rate: 0.00091456]
	Learning Rate: 0.000914556
	LOSS [training: 0.12084327661250216 | validation: 0.12638701873342822]
	TIME [epoch: 8.44 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1041302847324822		[learning rate: 0.00091124]
	Learning Rate: 0.000911237
	LOSS [training: 0.1041302847324822 | validation: 0.09793394032741265]
	TIME [epoch: 8.43 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11168378650238989		[learning rate: 0.00090793]
	Learning Rate: 0.000907931
	LOSS [training: 0.11168378650238989 | validation: 0.11641842761006306]
	TIME [epoch: 8.43 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11437447446110945		[learning rate: 0.00090464]
	Learning Rate: 0.000904636
	LOSS [training: 0.11437447446110945 | validation: 0.13973447628838317]
	TIME [epoch: 8.45 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10447715473447354		[learning rate: 0.00090135]
	Learning Rate: 0.000901353
	LOSS [training: 0.10447715473447354 | validation: 0.09662754504654403]
	TIME [epoch: 8.44 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10983118690007879		[learning rate: 0.00089808]
	Learning Rate: 0.000898082
	LOSS [training: 0.10983118690007879 | validation: 0.11217188827438467]
	TIME [epoch: 8.43 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10731292289270958		[learning rate: 0.00089482]
	Learning Rate: 0.000894822
	LOSS [training: 0.10731292289270958 | validation: 0.12372114509508784]
	TIME [epoch: 8.44 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11300068621193068		[learning rate: 0.00089157]
	Learning Rate: 0.000891575
	LOSS [training: 0.11300068621193068 | validation: 0.12437092135315818]
	TIME [epoch: 8.45 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10313639758216073		[learning rate: 0.00088834]
	Learning Rate: 0.000888339
	LOSS [training: 0.10313639758216073 | validation: 0.13691532509068424]
	TIME [epoch: 8.43 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12291740919172282		[learning rate: 0.00088512]
	Learning Rate: 0.000885116
	LOSS [training: 0.12291740919172282 | validation: 0.11565643141998318]
	TIME [epoch: 8.43 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08973033403018912		[learning rate: 0.0008819]
	Learning Rate: 0.000881903
	LOSS [training: 0.08973033403018912 | validation: 0.1288937021806382]
	TIME [epoch: 8.45 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11691340464551878		[learning rate: 0.0008787]
	Learning Rate: 0.000878703
	LOSS [training: 0.11691340464551878 | validation: 0.11422993535767026]
	TIME [epoch: 8.44 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11656214746623608		[learning rate: 0.00087551]
	Learning Rate: 0.000875514
	LOSS [training: 0.11656214746623608 | validation: 0.11622117374283258]
	TIME [epoch: 8.43 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10357372154832523		[learning rate: 0.00087234]
	Learning Rate: 0.000872337
	LOSS [training: 0.10357372154832523 | validation: 0.1328828950888569]
	TIME [epoch: 8.43 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09983629045170606		[learning rate: 0.00086917]
	Learning Rate: 0.000869171
	LOSS [training: 0.09983629045170606 | validation: 0.11974540809654612]
	TIME [epoch: 8.45 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09439069467985094		[learning rate: 0.00086602]
	Learning Rate: 0.000866017
	LOSS [training: 0.09439069467985094 | validation: 0.1686224784554407]
	TIME [epoch: 8.43 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09959572163734097		[learning rate: 0.00086287]
	Learning Rate: 0.000862874
	LOSS [training: 0.09959572163734097 | validation: 0.10384422352402164]
	TIME [epoch: 8.43 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0912695234290782		[learning rate: 0.00085974]
	Learning Rate: 0.000859743
	LOSS [training: 0.0912695234290782 | validation: 0.10064747789511688]
	TIME [epoch: 8.45 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10617669509953102		[learning rate: 0.00085662]
	Learning Rate: 0.000856623
	LOSS [training: 0.10617669509953102 | validation: 0.08727265492070674]
	TIME [epoch: 8.44 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12007880845577248		[learning rate: 0.00085351]
	Learning Rate: 0.000853514
	LOSS [training: 0.12007880845577248 | validation: 0.0965249115235472]
	TIME [epoch: 8.42 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09938952884033293		[learning rate: 0.00085042]
	Learning Rate: 0.000850416
	LOSS [training: 0.09938952884033293 | validation: 0.09376773761692922]
	TIME [epoch: 8.43 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11890221964851584		[learning rate: 0.00084733]
	Learning Rate: 0.00084733
	LOSS [training: 0.11890221964851584 | validation: 0.12342071403615411]
	TIME [epoch: 8.45 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10283927353269258		[learning rate: 0.00084426]
	Learning Rate: 0.000844255
	LOSS [training: 0.10283927353269258 | validation: 0.09504276939901087]
	TIME [epoch: 8.43 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11767415783164084		[learning rate: 0.00084119]
	Learning Rate: 0.000841191
	LOSS [training: 0.11767415783164084 | validation: 0.08817165751768277]
	TIME [epoch: 8.43 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11331369577113423		[learning rate: 0.00083814]
	Learning Rate: 0.000838139
	LOSS [training: 0.11331369577113423 | validation: 0.10410580338572253]
	TIME [epoch: 8.45 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11346913083063812		[learning rate: 0.0008351]
	Learning Rate: 0.000835097
	LOSS [training: 0.11346913083063812 | validation: 0.14392961185616526]
	TIME [epoch: 8.43 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10701655039266662		[learning rate: 0.00083207]
	Learning Rate: 0.000832066
	LOSS [training: 0.10701655039266662 | validation: 0.08550671311361605]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09281617068293292		[learning rate: 0.00082905]
	Learning Rate: 0.000829046
	LOSS [training: 0.09281617068293292 | validation: 0.07713573426856665]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09616127200396495		[learning rate: 0.00082604]
	Learning Rate: 0.000826038
	LOSS [training: 0.09616127200396495 | validation: 0.1007673006033924]
	TIME [epoch: 8.46 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12059480146352874		[learning rate: 0.00082304]
	Learning Rate: 0.00082304
	LOSS [training: 0.12059480146352874 | validation: 0.1165848655501337]
	TIME [epoch: 8.43 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08858746832262024		[learning rate: 0.00082005]
	Learning Rate: 0.000820053
	LOSS [training: 0.08858746832262024 | validation: 0.12162198117907369]
	TIME [epoch: 8.43 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09624877800224121		[learning rate: 0.00081708]
	Learning Rate: 0.000817077
	LOSS [training: 0.09624877800224121 | validation: 0.1171732031978383]
	TIME [epoch: 8.43 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10469117530518834		[learning rate: 0.00081411]
	Learning Rate: 0.000814112
	LOSS [training: 0.10469117530518834 | validation: 0.18434358019829378]
	TIME [epoch: 8.45 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09558789278488464		[learning rate: 0.00081116]
	Learning Rate: 0.000811158
	LOSS [training: 0.09558789278488464 | validation: 0.08848310771976142]
	TIME [epoch: 8.43 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09243461480354723		[learning rate: 0.00080821]
	Learning Rate: 0.000808214
	LOSS [training: 0.09243461480354723 | validation: 0.09703449491402699]
	TIME [epoch: 8.43 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09867460278076676		[learning rate: 0.00080528]
	Learning Rate: 0.000805281
	LOSS [training: 0.09867460278076676 | validation: 0.14164622430630636]
	TIME [epoch: 8.46 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.14989666353748085		[learning rate: 0.00080236]
	Learning Rate: 0.000802358
	LOSS [training: 0.14989666353748085 | validation: 0.15357656257778335]
	TIME [epoch: 8.44 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10768812974449157		[learning rate: 0.00079945]
	Learning Rate: 0.000799447
	LOSS [training: 0.10768812974449157 | validation: 0.15099342972884905]
	TIME [epoch: 8.43 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11340631179380352		[learning rate: 0.00079655]
	Learning Rate: 0.000796545
	LOSS [training: 0.11340631179380352 | validation: 0.10368562483406564]
	TIME [epoch: 8.43 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1151884511964258		[learning rate: 0.00079365]
	Learning Rate: 0.000793655
	LOSS [training: 0.1151884511964258 | validation: 0.10723977092508835]
	TIME [epoch: 8.46 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09241355306623675		[learning rate: 0.00079077]
	Learning Rate: 0.000790775
	LOSS [training: 0.09241355306623675 | validation: 0.09215750428755932]
	TIME [epoch: 8.43 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09151551737484645		[learning rate: 0.0007879]
	Learning Rate: 0.000787905
	LOSS [training: 0.09151551737484645 | validation: 0.09878510794960624]
	TIME [epoch: 8.43 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09075759631818424		[learning rate: 0.00078505]
	Learning Rate: 0.000785045
	LOSS [training: 0.09075759631818424 | validation: 0.13721762672260884]
	TIME [epoch: 8.44 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08033496355930232		[learning rate: 0.0007822]
	Learning Rate: 0.000782196
	LOSS [training: 0.08033496355930232 | validation: 0.10729933014166688]
	TIME [epoch: 8.44 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12379719258271804		[learning rate: 0.00077936]
	Learning Rate: 0.000779358
	LOSS [training: 0.12379719258271804 | validation: 0.11653026749394528]
	TIME [epoch: 8.43 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1022315732249978		[learning rate: 0.00077653]
	Learning Rate: 0.000776529
	LOSS [training: 0.1022315732249978 | validation: 0.08229176679880847]
	TIME [epoch: 8.43 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12901110070614857		[learning rate: 0.00077371]
	Learning Rate: 0.000773711
	LOSS [training: 0.12901110070614857 | validation: 0.09346865721065549]
	TIME [epoch: 8.45 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09828799728387493		[learning rate: 0.0007709]
	Learning Rate: 0.000770903
	LOSS [training: 0.09828799728387493 | validation: 0.11579906898554923]
	TIME [epoch: 8.43 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09570301436389651		[learning rate: 0.00076811]
	Learning Rate: 0.000768106
	LOSS [training: 0.09570301436389651 | validation: 0.07452923936039219]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_806.pth
	Model improved!!!
EPOCH 807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08616511282192647		[learning rate: 0.00076532]
	Learning Rate: 0.000765318
	LOSS [training: 0.08616511282192647 | validation: 0.11786968198869642]
	TIME [epoch: 8.44 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11397953549680664		[learning rate: 0.00076254]
	Learning Rate: 0.000762541
	LOSS [training: 0.11397953549680664 | validation: 0.11870688958727266]
	TIME [epoch: 8.45 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09893128454735993		[learning rate: 0.00075977]
	Learning Rate: 0.000759774
	LOSS [training: 0.09893128454735993 | validation: 0.09024864365920733]
	TIME [epoch: 8.43 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09714359731447351		[learning rate: 0.00075702]
	Learning Rate: 0.000757016
	LOSS [training: 0.09714359731447351 | validation: 0.10562640017122034]
	TIME [epoch: 8.43 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09122132966229313		[learning rate: 0.00075427]
	Learning Rate: 0.000754269
	LOSS [training: 0.09122132966229313 | validation: 0.12741735801711007]
	TIME [epoch: 8.45 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08304412699898975		[learning rate: 0.00075153]
	Learning Rate: 0.000751532
	LOSS [training: 0.08304412699898975 | validation: 0.17430408839487432]
	TIME [epoch: 8.43 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10460409568897773		[learning rate: 0.0007488]
	Learning Rate: 0.000748804
	LOSS [training: 0.10460409568897773 | validation: 0.089076627369989]
	TIME [epoch: 8.43 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10723931861059499		[learning rate: 0.00074609]
	Learning Rate: 0.000746087
	LOSS [training: 0.10723931861059499 | validation: 0.19845085776131008]
	TIME [epoch: 8.44 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09593678182644115		[learning rate: 0.00074338]
	Learning Rate: 0.000743379
	LOSS [training: 0.09593678182644115 | validation: 0.08113904979356286]
	TIME [epoch: 8.44 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09808080564428791		[learning rate: 0.00074068]
	Learning Rate: 0.000740682
	LOSS [training: 0.09808080564428791 | validation: 0.08834542675909973]
	TIME [epoch: 8.44 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10527936274855772		[learning rate: 0.00073799]
	Learning Rate: 0.000737994
	LOSS [training: 0.10527936274855772 | validation: 0.09533576855452502]
	TIME [epoch: 8.42 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10624011841477259		[learning rate: 0.00073532]
	Learning Rate: 0.000735315
	LOSS [training: 0.10624011841477259 | validation: 0.13966001147657808]
	TIME [epoch: 8.45 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12370665624334816		[learning rate: 0.00073265]
	Learning Rate: 0.000732647
	LOSS [training: 0.12370665624334816 | validation: 0.1313218931527134]
	TIME [epoch: 8.43 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11489648042674708		[learning rate: 0.00072999]
	Learning Rate: 0.000729988
	LOSS [training: 0.11489648042674708 | validation: 0.12164752249093899]
	TIME [epoch: 8.43 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10184378354466783		[learning rate: 0.00072734]
	Learning Rate: 0.000727339
	LOSS [training: 0.10184378354466783 | validation: 0.10226710889776153]
	TIME [epoch: 8.43 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.095246051701665		[learning rate: 0.0007247]
	Learning Rate: 0.000724699
	LOSS [training: 0.095246051701665 | validation: 0.08492830655696595]
	TIME [epoch: 8.45 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10043842752257555		[learning rate: 0.00072207]
	Learning Rate: 0.000722069
	LOSS [training: 0.10043842752257555 | validation: 0.08885982918948811]
	TIME [epoch: 8.42 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09166186118799152		[learning rate: 0.00071945]
	Learning Rate: 0.000719449
	LOSS [training: 0.09166186118799152 | validation: 0.12174420751642456]
	TIME [epoch: 8.42 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10116272265319817		[learning rate: 0.00071684]
	Learning Rate: 0.000716838
	LOSS [training: 0.10116272265319817 | validation: 0.08507892364468889]
	TIME [epoch: 8.45 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08343854897389798		[learning rate: 0.00071424]
	Learning Rate: 0.000714237
	LOSS [training: 0.08343854897389798 | validation: 0.09840409687123203]
	TIME [epoch: 8.43 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10365611454912163		[learning rate: 0.00071164]
	Learning Rate: 0.000711645
	LOSS [training: 0.10365611454912163 | validation: 0.09461112153582926]
	TIME [epoch: 8.43 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08173945757445367		[learning rate: 0.00070906]
	Learning Rate: 0.000709062
	LOSS [training: 0.08173945757445367 | validation: 0.0793923256441732]
	TIME [epoch: 8.42 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09153232442454001		[learning rate: 0.00070649]
	Learning Rate: 0.000706489
	LOSS [training: 0.09153232442454001 | validation: 0.12682025180312623]
	TIME [epoch: 8.45 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12343627687975363		[learning rate: 0.00070392]
	Learning Rate: 0.000703925
	LOSS [training: 0.12343627687975363 | validation: 0.08865978465238744]
	TIME [epoch: 8.43 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09665729972889428		[learning rate: 0.00070137]
	Learning Rate: 0.00070137
	LOSS [training: 0.09665729972889428 | validation: 0.1159588636541751]
	TIME [epoch: 8.43 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08449712456664361		[learning rate: 0.00069883]
	Learning Rate: 0.000698825
	LOSS [training: 0.08449712456664361 | validation: 0.10635289855132761]
	TIME [epoch: 8.44 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10774603875603203		[learning rate: 0.00069629]
	Learning Rate: 0.000696289
	LOSS [training: 0.10774603875603203 | validation: 0.1820858830658783]
	TIME [epoch: 8.44 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1042436465906285		[learning rate: 0.00069376]
	Learning Rate: 0.000693762
	LOSS [training: 0.1042436465906285 | validation: 0.08254666996484353]
	TIME [epoch: 8.43 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08676468653821898		[learning rate: 0.00069124]
	Learning Rate: 0.000691244
	LOSS [training: 0.08676468653821898 | validation: 0.09962388551688106]
	TIME [epoch: 8.43 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09205461081790861		[learning rate: 0.00068874]
	Learning Rate: 0.000688736
	LOSS [training: 0.09205461081790861 | validation: 0.09118364733606316]
	TIME [epoch: 8.45 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09515168854358304		[learning rate: 0.00068624]
	Learning Rate: 0.000686236
	LOSS [training: 0.09515168854358304 | validation: 0.14824100218865802]
	TIME [epoch: 8.43 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08768664815444734		[learning rate: 0.00068375]
	Learning Rate: 0.000683746
	LOSS [training: 0.08768664815444734 | validation: 0.08963393265714217]
	TIME [epoch: 8.43 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09031611655272057		[learning rate: 0.00068126]
	Learning Rate: 0.000681265
	LOSS [training: 0.09031611655272057 | validation: 0.1048157021271332]
	TIME [epoch: 8.43 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08876191406883069		[learning rate: 0.00067879]
	Learning Rate: 0.000678792
	LOSS [training: 0.08876191406883069 | validation: 0.1049138661697104]
	TIME [epoch: 8.45 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1055975010466281		[learning rate: 0.00067633]
	Learning Rate: 0.000676329
	LOSS [training: 0.1055975010466281 | validation: 0.07537510707149261]
	TIME [epoch: 8.44 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09160764167755756		[learning rate: 0.00067387]
	Learning Rate: 0.000673874
	LOSS [training: 0.09160764167755756 | validation: 0.18596611401123947]
	TIME [epoch: 8.43 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10959637362849425		[learning rate: 0.00067143]
	Learning Rate: 0.000671429
	LOSS [training: 0.10959637362849425 | validation: 0.08122764965432878]
	TIME [epoch: 8.45 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07906982985310254		[learning rate: 0.00066899]
	Learning Rate: 0.000668992
	LOSS [training: 0.07906982985310254 | validation: 0.09115831261307253]
	TIME [epoch: 8.43 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09054278398207102		[learning rate: 0.00066656]
	Learning Rate: 0.000666564
	LOSS [training: 0.09054278398207102 | validation: 0.07286921160830541]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796539747395003		[learning rate: 0.00066415]
	Learning Rate: 0.000664145
	LOSS [training: 0.0796539747395003 | validation: 0.10913306905110842]
	TIME [epoch: 8.43 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09204510083547254		[learning rate: 0.00066174]
	Learning Rate: 0.000661735
	LOSS [training: 0.09204510083547254 | validation: 0.09800105130317216]
	TIME [epoch: 8.45 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08483736363776785		[learning rate: 0.00065933]
	Learning Rate: 0.000659334
	LOSS [training: 0.08483736363776785 | validation: 0.09155116293851298]
	TIME [epoch: 8.42 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08009167231013754		[learning rate: 0.00065694]
	Learning Rate: 0.000656941
	LOSS [training: 0.08009167231013754 | validation: 0.10764210137754254]
	TIME [epoch: 8.42 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07602504371798291		[learning rate: 0.00065456]
	Learning Rate: 0.000654557
	LOSS [training: 0.07602504371798291 | validation: 0.08498935279454259]
	TIME [epoch: 8.44 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08627815820542428		[learning rate: 0.00065218]
	Learning Rate: 0.000652182
	LOSS [training: 0.08627815820542428 | validation: 0.07496157652612855]
	TIME [epoch: 8.43 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0916314215043116		[learning rate: 0.00064981]
	Learning Rate: 0.000649815
	LOSS [training: 0.0916314215043116 | validation: 0.0954315819001588]
	TIME [epoch: 8.42 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09657228212890656		[learning rate: 0.00064746]
	Learning Rate: 0.000647456
	LOSS [training: 0.09657228212890656 | validation: 0.12554249275115847]
	TIME [epoch: 8.43 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09451167286109324		[learning rate: 0.00064511]
	Learning Rate: 0.000645107
	LOSS [training: 0.09451167286109324 | validation: 0.09429356465838153]
	TIME [epoch: 8.45 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08090371957133403		[learning rate: 0.00064277]
	Learning Rate: 0.000642766
	LOSS [training: 0.08090371957133403 | validation: 0.20388988805626018]
	TIME [epoch: 8.42 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.12039564397504363		[learning rate: 0.00064043]
	Learning Rate: 0.000640433
	LOSS [training: 0.12039564397504363 | validation: 0.07481034380475478]
	TIME [epoch: 8.42 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10583859241941171		[learning rate: 0.00063811]
	Learning Rate: 0.000638109
	LOSS [training: 0.10583859241941171 | validation: 0.12755738921122076]
	TIME [epoch: 8.43 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08784953149567913		[learning rate: 0.00063579]
	Learning Rate: 0.000635793
	LOSS [training: 0.08784953149567913 | validation: 0.09325430585960362]
	TIME [epoch: 8.45 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09372428442158018		[learning rate: 0.00063349]
	Learning Rate: 0.000633486
	LOSS [training: 0.09372428442158018 | validation: 0.10436313105267413]
	TIME [epoch: 8.42 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1157802048836706		[learning rate: 0.00063119]
	Learning Rate: 0.000631187
	LOSS [training: 0.1157802048836706 | validation: 0.08131132563586911]
	TIME [epoch: 8.42 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1388397252508418		[learning rate: 0.0006289]
	Learning Rate: 0.000628896
	LOSS [training: 0.1388397252508418 | validation: 0.1272650360695023]
	TIME [epoch: 8.44 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1016554330613785		[learning rate: 0.00062661]
	Learning Rate: 0.000626614
	LOSS [training: 0.1016554330613785 | validation: 0.10893742144336171]
	TIME [epoch: 8.42 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08398384449804616		[learning rate: 0.00062434]
	Learning Rate: 0.00062434
	LOSS [training: 0.08398384449804616 | validation: 0.08232810050850276]
	TIME [epoch: 8.42 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08649778825826018		[learning rate: 0.00062207]
	Learning Rate: 0.000622074
	LOSS [training: 0.08649778825826018 | validation: 0.19226003040791528]
	TIME [epoch: 8.43 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10878542217417442		[learning rate: 0.00061982]
	Learning Rate: 0.000619816
	LOSS [training: 0.10878542217417442 | validation: 0.0918705081837401]
	TIME [epoch: 8.44 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10308023017970902		[learning rate: 0.00061757]
	Learning Rate: 0.000617567
	LOSS [training: 0.10308023017970902 | validation: 0.10596300099404367]
	TIME [epoch: 8.42 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10663590852186669		[learning rate: 0.00061533]
	Learning Rate: 0.000615326
	LOSS [training: 0.10663590852186669 | validation: 0.1697018296863626]
	TIME [epoch: 8.42 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10817885856412876		[learning rate: 0.00061309]
	Learning Rate: 0.000613093
	LOSS [training: 0.10817885856412876 | validation: 0.09083465257733449]
	TIME [epoch: 8.45 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08422666527813291		[learning rate: 0.00061087]
	Learning Rate: 0.000610868
	LOSS [training: 0.08422666527813291 | validation: 0.10368323123957057]
	TIME [epoch: 8.43 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08132449764215235		[learning rate: 0.00060865]
	Learning Rate: 0.000608651
	LOSS [training: 0.08132449764215235 | validation: 0.10236026038144547]
	TIME [epoch: 8.42 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08999108918110005		[learning rate: 0.00060644]
	Learning Rate: 0.000606442
	LOSS [training: 0.08999108918110005 | validation: 0.09055417076732421]
	TIME [epoch: 8.43 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10081310459509887		[learning rate: 0.00060424]
	Learning Rate: 0.000604242
	LOSS [training: 0.10081310459509887 | validation: 0.09530273899343586]
	TIME [epoch: 8.44 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08165187873627515		[learning rate: 0.00060205]
	Learning Rate: 0.000602049
	LOSS [training: 0.08165187873627515 | validation: 0.09077373164277727]
	TIME [epoch: 8.43 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10317335831921173		[learning rate: 0.00059986]
	Learning Rate: 0.000599864
	LOSS [training: 0.10317335831921173 | validation: 0.1260201247583058]
	TIME [epoch: 8.42 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09559430759707394		[learning rate: 0.00059769]
	Learning Rate: 0.000597687
	LOSS [training: 0.09559430759707394 | validation: 0.09050742364014418]
	TIME [epoch: 8.44 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07944799700997641		[learning rate: 0.00059552]
	Learning Rate: 0.000595518
	LOSS [training: 0.07944799700997641 | validation: 0.08511858229703691]
	TIME [epoch: 8.43 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07900898901508664		[learning rate: 0.00059336]
	Learning Rate: 0.000593357
	LOSS [training: 0.07900898901508664 | validation: 0.08652396261755449]
	TIME [epoch: 8.43 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08747825954073356		[learning rate: 0.0005912]
	Learning Rate: 0.000591203
	LOSS [training: 0.08747825954073356 | validation: 0.10845935459837175]
	TIME [epoch: 8.43 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09149600322895932		[learning rate: 0.00058906]
	Learning Rate: 0.000589058
	LOSS [training: 0.09149600322895932 | validation: 0.09284411441399518]
	TIME [epoch: 8.45 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.092103597123652		[learning rate: 0.00058692]
	Learning Rate: 0.00058692
	LOSS [training: 0.092103597123652 | validation: 0.0750586911463746]
	TIME [epoch: 8.43 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09539907890663384		[learning rate: 0.00058479]
	Learning Rate: 0.00058479
	LOSS [training: 0.09539907890663384 | validation: 0.09863004490259264]
	TIME [epoch: 8.43 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08967949290541949		[learning rate: 0.00058267]
	Learning Rate: 0.000582668
	LOSS [training: 0.08967949290541949 | validation: 0.08867886504970515]
	TIME [epoch: 8.43 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09231104848691382		[learning rate: 0.00058055]
	Learning Rate: 0.000580553
	LOSS [training: 0.09231104848691382 | validation: 0.08042699742780368]
	TIME [epoch: 8.45 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09050272618001734		[learning rate: 0.00057845]
	Learning Rate: 0.000578446
	LOSS [training: 0.09050272618001734 | validation: 0.10889933899217666]
	TIME [epoch: 8.43 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1150875406720108		[learning rate: 0.00057635]
	Learning Rate: 0.000576347
	LOSS [training: 0.1150875406720108 | validation: 0.1552569072481036]
	TIME [epoch: 8.43 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10035957165331018		[learning rate: 0.00057426]
	Learning Rate: 0.000574256
	LOSS [training: 0.10035957165331018 | validation: 0.08435577262519939]
	TIME [epoch: 8.44 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08899568634780622		[learning rate: 0.00057217]
	Learning Rate: 0.000572172
	LOSS [training: 0.08899568634780622 | validation: 0.0769548602825916]
	TIME [epoch: 8.42 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909852302824231		[learning rate: 0.0005701]
	Learning Rate: 0.000570095
	LOSS [training: 0.0909852302824231 | validation: 0.10011424094016026]
	TIME [epoch: 8.43 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08017066891871873		[learning rate: 0.00056803]
	Learning Rate: 0.000568026
	LOSS [training: 0.08017066891871873 | validation: 0.07940016600648966]
	TIME [epoch: 8.44 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08051163083094277		[learning rate: 0.00056596]
	Learning Rate: 0.000565965
	LOSS [training: 0.08051163083094277 | validation: 0.08403132098199204]
	TIME [epoch: 8.44 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0971230738581506		[learning rate: 0.00056391]
	Learning Rate: 0.000563911
	LOSS [training: 0.0971230738581506 | validation: 0.12969201806921565]
	TIME [epoch: 8.43 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08833644997990163		[learning rate: 0.00056186]
	Learning Rate: 0.000561864
	LOSS [training: 0.08833644997990163 | validation: 0.10092246283928835]
	TIME [epoch: 8.43 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07208033441654316		[learning rate: 0.00055983]
	Learning Rate: 0.000559825
	LOSS [training: 0.07208033441654316 | validation: 0.07794890778848385]
	TIME [epoch: 8.44 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1054455143388748		[learning rate: 0.00055779]
	Learning Rate: 0.000557794
	LOSS [training: 0.1054455143388748 | validation: 0.14707325866047685]
	TIME [epoch: 8.44 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.16487157082285117		[learning rate: 0.00055577]
	Learning Rate: 0.00055577
	LOSS [training: 0.16487157082285117 | validation: 0.22462230439977446]
	TIME [epoch: 8.43 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.17264092710966053		[learning rate: 0.00055375]
	Learning Rate: 0.000553753
	LOSS [training: 0.17264092710966053 | validation: 0.29363279736888287]
	TIME [epoch: 8.42 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11654249744339892		[learning rate: 0.00055174]
	Learning Rate: 0.000551743
	LOSS [training: 0.11654249744339892 | validation: 0.09447857900321276]
	TIME [epoch: 8.45 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.096277110734853		[learning rate: 0.00054974]
	Learning Rate: 0.000549741
	LOSS [training: 0.096277110734853 | validation: 0.08467359346494234]
	TIME [epoch: 8.42 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0876720777757734		[learning rate: 0.00054775]
	Learning Rate: 0.000547746
	LOSS [training: 0.0876720777757734 | validation: 0.07444343371101571]
	TIME [epoch: 8.43 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08128566043122173		[learning rate: 0.00054576]
	Learning Rate: 0.000545758
	LOSS [training: 0.08128566043122173 | validation: 0.07185362889227669]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_900.pth
	Model improved!!!
EPOCH 901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06816678391512335		[learning rate: 0.00054378]
	Learning Rate: 0.000543777
	LOSS [training: 0.06816678391512335 | validation: 0.07715065943311539]
	TIME [epoch: 8.43 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07555342650118578		[learning rate: 0.0005418]
	Learning Rate: 0.000541804
	LOSS [training: 0.07555342650118578 | validation: 0.08548073840583177]
	TIME [epoch: 8.43 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0909604196731055		[learning rate: 0.00053984]
	Learning Rate: 0.000539838
	LOSS [training: 0.0909604196731055 | validation: 0.09824694305770573]
	TIME [epoch: 8.43 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0823507826315754		[learning rate: 0.00053788]
	Learning Rate: 0.000537879
	LOSS [training: 0.0823507826315754 | validation: 0.10864768290588254]
	TIME [epoch: 8.46 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08967922369238054		[learning rate: 0.00053593]
	Learning Rate: 0.000535926
	LOSS [training: 0.08967922369238054 | validation: 0.08702959920438541]
	TIME [epoch: 8.42 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07864412454867739		[learning rate: 0.00053398]
	Learning Rate: 0.000533982
	LOSS [training: 0.07864412454867739 | validation: 0.07208307433472017]
	TIME [epoch: 8.43 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07218864124365748		[learning rate: 0.00053204]
	Learning Rate: 0.000532044
	LOSS [training: 0.07218864124365748 | validation: 0.061850884573126715]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07672366011341883		[learning rate: 0.00053011]
	Learning Rate: 0.000530113
	LOSS [training: 0.07672366011341883 | validation: 0.10023121279786254]
	TIME [epoch: 8.44 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08630463962965813		[learning rate: 0.00052819]
	Learning Rate: 0.000528189
	LOSS [training: 0.08630463962965813 | validation: 0.06971078184004477]
	TIME [epoch: 8.42 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06865311392450194		[learning rate: 0.00052627]
	Learning Rate: 0.000526272
	LOSS [training: 0.06865311392450194 | validation: 0.09818566136728442]
	TIME [epoch: 8.43 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09441381421741518		[learning rate: 0.00052436]
	Learning Rate: 0.000524362
	LOSS [training: 0.09441381421741518 | validation: 0.07473380495010036]
	TIME [epoch: 8.45 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.075059854239232		[learning rate: 0.00052246]
	Learning Rate: 0.00052246
	LOSS [training: 0.075059854239232 | validation: 0.07119186284303378]
	TIME [epoch: 8.42 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08147515412109962		[learning rate: 0.00052056]
	Learning Rate: 0.000520563
	LOSS [training: 0.08147515412109962 | validation: 0.08472800279737305]
	TIME [epoch: 8.43 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08387918952519596		[learning rate: 0.00051867]
	Learning Rate: 0.000518674
	LOSS [training: 0.08387918952519596 | validation: 0.07291900033235234]
	TIME [epoch: 8.43 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09024274531688262		[learning rate: 0.00051679]
	Learning Rate: 0.000516792
	LOSS [training: 0.09024274531688262 | validation: 0.10569359203483095]
	TIME [epoch: 8.44 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08980680478102439		[learning rate: 0.00051492]
	Learning Rate: 0.000514917
	LOSS [training: 0.08980680478102439 | validation: 0.08773961995874105]
	TIME [epoch: 8.42 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07679760352650075		[learning rate: 0.00051305]
	Learning Rate: 0.000513048
	LOSS [training: 0.07679760352650075 | validation: 0.08244998321633622]
	TIME [epoch: 8.43 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09515181415471603		[learning rate: 0.00051119]
	Learning Rate: 0.000511186
	LOSS [training: 0.09515181415471603 | validation: 0.08540767050311054]
	TIME [epoch: 8.45 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07349213414407199		[learning rate: 0.00050933]
	Learning Rate: 0.000509331
	LOSS [training: 0.07349213414407199 | validation: 0.08627063870304905]
	TIME [epoch: 8.42 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08604430504958643		[learning rate: 0.00050748]
	Learning Rate: 0.000507483
	LOSS [training: 0.08604430504958643 | validation: 0.0954260010589796]
	TIME [epoch: 8.43 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08923427295456465		[learning rate: 0.00050564]
	Learning Rate: 0.000505641
	LOSS [training: 0.08923427295456465 | validation: 0.1026328684202714]
	TIME [epoch: 8.43 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08281861554057393		[learning rate: 0.00050381]
	Learning Rate: 0.000503806
	LOSS [training: 0.08281861554057393 | validation: 0.08534321073626648]
	TIME [epoch: 8.44 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07935456381178238		[learning rate: 0.00050198]
	Learning Rate: 0.000501977
	LOSS [training: 0.07935456381178238 | validation: 0.0725209441276902]
	TIME [epoch: 8.42 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09188531595790184		[learning rate: 0.00050016]
	Learning Rate: 0.000500156
	LOSS [training: 0.09188531595790184 | validation: 0.061862985671827575]
	TIME [epoch: 8.43 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06622159335120882		[learning rate: 0.00049834]
	Learning Rate: 0.000498341
	LOSS [training: 0.06622159335120882 | validation: 0.06922223362861127]
	TIME [epoch: 8.44 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07169293491778142		[learning rate: 0.00049653]
	Learning Rate: 0.000496532
	LOSS [training: 0.07169293491778142 | validation: 0.11201673280121036]
	TIME [epoch: 8.44 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09023039215748843		[learning rate: 0.00049473]
	Learning Rate: 0.00049473
	LOSS [training: 0.09023039215748843 | validation: 0.09567476711161596]
	TIME [epoch: 8.43 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0831991766718851		[learning rate: 0.00049293]
	Learning Rate: 0.000492935
	LOSS [training: 0.0831991766718851 | validation: 0.08580066713323777]
	TIME [epoch: 8.43 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0778850237612909		[learning rate: 0.00049115]
	Learning Rate: 0.000491146
	LOSS [training: 0.0778850237612909 | validation: 0.08611786392437501]
	TIME [epoch: 8.45 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07727060289913593		[learning rate: 0.00048936]
	Learning Rate: 0.000489364
	LOSS [training: 0.07727060289913593 | validation: 0.08342565887668893]
	TIME [epoch: 8.42 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08223363556457791		[learning rate: 0.00048759]
	Learning Rate: 0.000487588
	LOSS [training: 0.08223363556457791 | validation: 0.098518560931923]
	TIME [epoch: 8.42 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07808726614152842		[learning rate: 0.00048582]
	Learning Rate: 0.000485818
	LOSS [training: 0.07808726614152842 | validation: 0.11008729954054688]
	TIME [epoch: 8.44 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0854478256943513		[learning rate: 0.00048406]
	Learning Rate: 0.000484055
	LOSS [training: 0.0854478256943513 | validation: 0.07275151817292533]
	TIME [epoch: 8.44 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08217215098601512		[learning rate: 0.0004823]
	Learning Rate: 0.000482298
	LOSS [training: 0.08217215098601512 | validation: 0.12597729237184213]
	TIME [epoch: 8.42 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.11051486394258074		[learning rate: 0.00048055]
	Learning Rate: 0.000480548
	LOSS [training: 0.11051486394258074 | validation: 0.1340289159138593]
	TIME [epoch: 8.42 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08201237445626028		[learning rate: 0.0004788]
	Learning Rate: 0.000478804
	LOSS [training: 0.08201237445626028 | validation: 0.07676303231105278]
	TIME [epoch: 8.45 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07285707745701196		[learning rate: 0.00047707]
	Learning Rate: 0.000477067
	LOSS [training: 0.07285707745701196 | validation: 0.0889525601523945]
	TIME [epoch: 8.42 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08975368833036267		[learning rate: 0.00047534]
	Learning Rate: 0.000475335
	LOSS [training: 0.08975368833036267 | validation: 0.06323749570890005]
	TIME [epoch: 8.43 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0726119424644868		[learning rate: 0.00047361]
	Learning Rate: 0.00047361
	LOSS [training: 0.0726119424644868 | validation: 0.10251720895567527]
	TIME [epoch: 8.43 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10913133588238721		[learning rate: 0.00047189]
	Learning Rate: 0.000471891
	LOSS [training: 0.10913133588238721 | validation: 0.09084626337891225]
	TIME [epoch: 8.44 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0921663677922762		[learning rate: 0.00047018]
	Learning Rate: 0.000470179
	LOSS [training: 0.0921663677922762 | validation: 0.09020202580746588]
	TIME [epoch: 8.43 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08352085212968494		[learning rate: 0.00046847]
	Learning Rate: 0.000468473
	LOSS [training: 0.08352085212968494 | validation: 0.08383139954906896]
	TIME [epoch: 8.43 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06535874591842632		[learning rate: 0.00046677]
	Learning Rate: 0.000466773
	LOSS [training: 0.06535874591842632 | validation: 0.06723608656002936]
	TIME [epoch: 8.45 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07248535054676303		[learning rate: 0.00046508]
	Learning Rate: 0.000465079
	LOSS [training: 0.07248535054676303 | validation: 0.07330899774085768]
	TIME [epoch: 8.43 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0960782221783287		[learning rate: 0.00046339]
	Learning Rate: 0.000463391
	LOSS [training: 0.0960782221783287 | validation: 0.11454340603671359]
	TIME [epoch: 8.43 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07943364757930124		[learning rate: 0.00046171]
	Learning Rate: 0.000461709
	LOSS [training: 0.07943364757930124 | validation: 0.07459531521064193]
	TIME [epoch: 8.43 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08714819158306347		[learning rate: 0.00046003]
	Learning Rate: 0.000460034
	LOSS [training: 0.08714819158306347 | validation: 0.12200822747356571]
	TIME [epoch: 8.45 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09949679219103838		[learning rate: 0.00045836]
	Learning Rate: 0.000458364
	LOSS [training: 0.09949679219103838 | validation: 0.12067408434172036]
	TIME [epoch: 8.42 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08555859931933447		[learning rate: 0.0004567]
	Learning Rate: 0.000456701
	LOSS [training: 0.08555859931933447 | validation: 0.10620161449068767]
	TIME [epoch: 8.42 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.076712691606198		[learning rate: 0.00045504]
	Learning Rate: 0.000455043
	LOSS [training: 0.076712691606198 | validation: 0.09545656076342185]
	TIME [epoch: 8.45 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07884849310655742		[learning rate: 0.00045339]
	Learning Rate: 0.000453392
	LOSS [training: 0.07884849310655742 | validation: 0.09201559368467305]
	TIME [epoch: 8.42 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08220932268954788		[learning rate: 0.00045175]
	Learning Rate: 0.000451746
	LOSS [training: 0.08220932268954788 | validation: 0.1018521595855675]
	TIME [epoch: 8.42 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08818241470229547		[learning rate: 0.00045011]
	Learning Rate: 0.000450107
	LOSS [training: 0.08818241470229547 | validation: 0.11957752187688253]
	TIME [epoch: 8.42 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08682867010242924		[learning rate: 0.00044847]
	Learning Rate: 0.000448474
	LOSS [training: 0.08682867010242924 | validation: 0.08416515783767778]
	TIME [epoch: 8.45 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08849713367809924		[learning rate: 0.00044685]
	Learning Rate: 0.000446846
	LOSS [training: 0.08849713367809924 | validation: 0.0983608123785587]
	TIME [epoch: 8.42 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07958190683043447		[learning rate: 0.00044522]
	Learning Rate: 0.000445224
	LOSS [training: 0.07958190683043447 | validation: 0.11134505722125279]
	TIME [epoch: 8.42 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07545878470398314		[learning rate: 0.00044361]
	Learning Rate: 0.000443609
	LOSS [training: 0.07545878470398314 | validation: 0.07998291141054333]
	TIME [epoch: 8.44 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07125519634701963		[learning rate: 0.000442]
	Learning Rate: 0.000441999
	LOSS [training: 0.07125519634701963 | validation: 0.07242502305192673]
	TIME [epoch: 8.42 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1026460211219489		[learning rate: 0.00044039]
	Learning Rate: 0.000440395
	LOSS [training: 0.1026460211219489 | validation: 0.0787614154188844]
	TIME [epoch: 8.43 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07886492188422815		[learning rate: 0.0004388]
	Learning Rate: 0.000438797
	LOSS [training: 0.07886492188422815 | validation: 0.12400089379145285]
	TIME [epoch: 8.43 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08291784183985597		[learning rate: 0.0004372]
	Learning Rate: 0.000437204
	LOSS [training: 0.08291784183985597 | validation: 0.06823663266349335]
	TIME [epoch: 8.44 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08276138296978308		[learning rate: 0.00043562]
	Learning Rate: 0.000435617
	LOSS [training: 0.08276138296978308 | validation: 0.06981207198961008]
	TIME [epoch: 8.43 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07555513207121292		[learning rate: 0.00043404]
	Learning Rate: 0.000434037
	LOSS [training: 0.07555513207121292 | validation: 0.08231431250564178]
	TIME [epoch: 8.42 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07668429794452684		[learning rate: 0.00043246]
	Learning Rate: 0.000432461
	LOSS [training: 0.07668429794452684 | validation: 0.10993332253698383]
	TIME [epoch: 8.43 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0722595618699207		[learning rate: 0.00043089]
	Learning Rate: 0.000430892
	LOSS [training: 0.0722595618699207 | validation: 0.12227509432869096]
	TIME [epoch: 8.45 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09373142106756438		[learning rate: 0.00042933]
	Learning Rate: 0.000429328
	LOSS [training: 0.09373142106756438 | validation: 0.18449455645030793]
	TIME [epoch: 8.43 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08735331200651555		[learning rate: 0.00042777]
	Learning Rate: 0.00042777
	LOSS [training: 0.08735331200651555 | validation: 0.07464626296416914]
	TIME [epoch: 8.43 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07814260674886603		[learning rate: 0.00042622]
	Learning Rate: 0.000426218
	LOSS [training: 0.07814260674886603 | validation: 0.08790147556634023]
	TIME [epoch: 8.44 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08379251556800241		[learning rate: 0.00042467]
	Learning Rate: 0.000424671
	LOSS [training: 0.08379251556800241 | validation: 0.08273367177327869]
	TIME [epoch: 8.42 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08172752461338031		[learning rate: 0.00042313]
	Learning Rate: 0.00042313
	LOSS [training: 0.08172752461338031 | validation: 0.0987728740609556]
	TIME [epoch: 8.43 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07520238938808782		[learning rate: 0.00042159]
	Learning Rate: 0.000421594
	LOSS [training: 0.07520238938808782 | validation: 0.07987805053424314]
	TIME [epoch: 8.43 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07636859584240556		[learning rate: 0.00042006]
	Learning Rate: 0.000420064
	LOSS [training: 0.07636859584240556 | validation: 0.0730633139966245]
	TIME [epoch: 8.45 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07325937364123994		[learning rate: 0.00041854]
	Learning Rate: 0.00041854
	LOSS [training: 0.07325937364123994 | validation: 0.09913563672268977]
	TIME [epoch: 8.43 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07353241830355617		[learning rate: 0.00041702]
	Learning Rate: 0.000417021
	LOSS [training: 0.07353241830355617 | validation: 0.08309230353599545]
	TIME [epoch: 8.43 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0635829320967973		[learning rate: 0.00041551]
	Learning Rate: 0.000415508
	LOSS [training: 0.0635829320967973 | validation: 0.11569274421933931]
	TIME [epoch: 8.45 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09287568154177217		[learning rate: 0.000414]
	Learning Rate: 0.000414
	LOSS [training: 0.09287568154177217 | validation: 0.09643822133858745]
	TIME [epoch: 8.43 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07780270330085788		[learning rate: 0.0004125]
	Learning Rate: 0.000412497
	LOSS [training: 0.07780270330085788 | validation: 0.08440618275073064]
	TIME [epoch: 8.43 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723585538978822		[learning rate: 0.000411]
	Learning Rate: 0.000411
	LOSS [training: 0.0723585538978822 | validation: 0.1075663353607389]
	TIME [epoch: 8.42 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08564092033039132		[learning rate: 0.00040951]
	Learning Rate: 0.000409509
	LOSS [training: 0.08564092033039132 | validation: 0.08153294546691589]
	TIME [epoch: 8.45 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07780331602728015		[learning rate: 0.00040802]
	Learning Rate: 0.000408023
	LOSS [training: 0.07780331602728015 | validation: 0.09046992253176686]
	TIME [epoch: 8.42 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07524909699821383		[learning rate: 0.00040654]
	Learning Rate: 0.000406542
	LOSS [training: 0.07524909699821383 | validation: 0.08598283490995964]
	TIME [epoch: 8.42 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07336666725878946		[learning rate: 0.00040507]
	Learning Rate: 0.000405067
	LOSS [training: 0.07336666725878946 | validation: 0.10875637385740333]
	TIME [epoch: 8.44 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661541601658309		[learning rate: 0.0004036]
	Learning Rate: 0.000403597
	LOSS [training: 0.07661541601658309 | validation: 0.07948583667137854]
	TIME [epoch: 8.43 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07996548927494743		[learning rate: 0.00040213]
	Learning Rate: 0.000402132
	LOSS [training: 0.07996548927494743 | validation: 0.10301069321359989]
	TIME [epoch: 8.43 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0717673305085116		[learning rate: 0.00040067]
	Learning Rate: 0.000400672
	LOSS [training: 0.0717673305085116 | validation: 0.07335476095293496]
	TIME [epoch: 8.42 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07473752256648611		[learning rate: 0.00039922]
	Learning Rate: 0.000399218
	LOSS [training: 0.07473752256648611 | validation: 0.1228466172076692]
	TIME [epoch: 8.46 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07379544211573429		[learning rate: 0.00039777]
	Learning Rate: 0.00039777
	LOSS [training: 0.07379544211573429 | validation: 0.06763125473997436]
	TIME [epoch: 8.43 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08128902872584491		[learning rate: 0.00039633]
	Learning Rate: 0.000396326
	LOSS [training: 0.08128902872584491 | validation: 0.07861086975738765]
	TIME [epoch: 8.43 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07925173346143248		[learning rate: 0.00039489]
	Learning Rate: 0.000394888
	LOSS [training: 0.07925173346143248 | validation: 0.0888410328310623]
	TIME [epoch: 8.43 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0638176036164652		[learning rate: 0.00039345]
	Learning Rate: 0.000393455
	LOSS [training: 0.0638176036164652 | validation: 0.08208217470575388]
	TIME [epoch: 8.44 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08185828360734257		[learning rate: 0.00039203]
	Learning Rate: 0.000392027
	LOSS [training: 0.08185828360734257 | validation: 0.12213733992374429]
	TIME [epoch: 8.43 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07135118403300714		[learning rate: 0.0003906]
	Learning Rate: 0.000390604
	LOSS [training: 0.07135118403300714 | validation: 0.08482149829895325]
	TIME [epoch: 8.42 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06708663419179493		[learning rate: 0.00038919]
	Learning Rate: 0.000389187
	LOSS [training: 0.06708663419179493 | validation: 0.07266965128764025]
	TIME [epoch: 8.45 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06499007661893189		[learning rate: 0.00038777]
	Learning Rate: 0.000387774
	LOSS [training: 0.06499007661893189 | validation: 0.0766763122946317]
	TIME [epoch: 8.42 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0871306303627683		[learning rate: 0.00038637]
	Learning Rate: 0.000386367
	LOSS [training: 0.0871306303627683 | validation: 0.09230362925529448]
	TIME [epoch: 8.43 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08145174094798838		[learning rate: 0.00038496]
	Learning Rate: 0.000384965
	LOSS [training: 0.08145174094798838 | validation: 0.08725196734215548]
	TIME [epoch: 8.43 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08084309051700603		[learning rate: 0.00038357]
	Learning Rate: 0.000383568
	LOSS [training: 0.08084309051700603 | validation: 0.09101469502582665]
	TIME [epoch: 8.45 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609439638636887		[learning rate: 0.00038218]
	Learning Rate: 0.000382176
	LOSS [training: 0.06609439638636887 | validation: 0.08369344055179373]
	TIME [epoch: 8.42 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06463873681303137		[learning rate: 0.00038079]
	Learning Rate: 0.000380789
	LOSS [training: 0.06463873681303137 | validation: 0.08339077564286848]
	TIME [epoch: 8.43 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08118375067079713		[learning rate: 0.00037941]
	Learning Rate: 0.000379407
	LOSS [training: 0.08118375067079713 | validation: 0.09875442723952743]
	TIME [epoch: 8.45 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0861961609972056		[learning rate: 0.00037803]
	Learning Rate: 0.00037803
	LOSS [training: 0.0861961609972056 | validation: 0.09143434117894697]
	TIME [epoch: 8.42 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0736677646166309		[learning rate: 0.00037666]
	Learning Rate: 0.000376658
	LOSS [training: 0.0736677646166309 | validation: 0.09132586160536649]
	TIME [epoch: 8.42 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07149652438827234		[learning rate: 0.00037529]
	Learning Rate: 0.000375291
	LOSS [training: 0.07149652438827234 | validation: 0.07819804936708387]
	TIME [epoch: 8.43 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07870043686962211		[learning rate: 0.00037393]
	Learning Rate: 0.000373929
	LOSS [training: 0.07870043686962211 | validation: 0.06796413111042669]
	TIME [epoch: 8.45 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07113545496158594		[learning rate: 0.00037257]
	Learning Rate: 0.000372572
	LOSS [training: 0.07113545496158594 | validation: 0.10837760742212607]
	TIME [epoch: 8.43 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08058711698657009		[learning rate: 0.00037122]
	Learning Rate: 0.00037122
	LOSS [training: 0.08058711698657009 | validation: 0.10186195604548148]
	TIME [epoch: 8.42 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834671074048407		[learning rate: 0.00036987]
	Learning Rate: 0.000369873
	LOSS [training: 0.06834671074048407 | validation: 0.07736680876056198]
	TIME [epoch: 8.44 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059750806705839446		[learning rate: 0.00036853]
	Learning Rate: 0.000368531
	LOSS [training: 0.059750806705839446 | validation: 0.09576492925391998]
	TIME [epoch: 8.43 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06486780676646589		[learning rate: 0.00036719]
	Learning Rate: 0.000367193
	LOSS [training: 0.06486780676646589 | validation: 0.09948621897590482]
	TIME [epoch: 8.43 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07576717643080495		[learning rate: 0.00036586]
	Learning Rate: 0.000365861
	LOSS [training: 0.07576717643080495 | validation: 0.06446295456392123]
	TIME [epoch: 8.42 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07383352756695923		[learning rate: 0.00036453]
	Learning Rate: 0.000364533
	LOSS [training: 0.07383352756695923 | validation: 0.07345629414278558]
	TIME [epoch: 8.45 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684437938283194		[learning rate: 0.00036321]
	Learning Rate: 0.00036321
	LOSS [training: 0.0684437938283194 | validation: 0.07466948286028655]
	TIME [epoch: 8.42 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221702299192931		[learning rate: 0.00036189]
	Learning Rate: 0.000361892
	LOSS [training: 0.07221702299192931 | validation: 0.10804158610554826]
	TIME [epoch: 8.42 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07804055038318342		[learning rate: 0.00036058]
	Learning Rate: 0.000360579
	LOSS [training: 0.07804055038318342 | validation: 0.09938137207075652]
	TIME [epoch: 8.43 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07277575815782991		[learning rate: 0.00035927]
	Learning Rate: 0.00035927
	LOSS [training: 0.07277575815782991 | validation: 0.09690048352142139]
	TIME [epoch: 8.44 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07104849767690753		[learning rate: 0.00035797]
	Learning Rate: 0.000357966
	LOSS [training: 0.07104849767690753 | validation: 0.060831944326436654]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1016.pth
	Model improved!!!
EPOCH 1017/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.077513753932173		[learning rate: 0.00035667]
	Learning Rate: 0.000356667
	LOSS [training: 0.077513753932173 | validation: 0.08721196792496926]
	TIME [epoch: 8.42 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07524076796015969		[learning rate: 0.00035537]
	Learning Rate: 0.000355373
	LOSS [training: 0.07524076796015969 | validation: 0.08678268601841048]
	TIME [epoch: 8.44 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06835369994542745		[learning rate: 0.00035408]
	Learning Rate: 0.000354083
	LOSS [training: 0.06835369994542745 | validation: 0.08585154030299827]
	TIME [epoch: 8.41 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08547474439339221		[learning rate: 0.0003528]
	Learning Rate: 0.000352798
	LOSS [training: 0.08547474439339221 | validation: 0.07562911126887914]
	TIME [epoch: 8.42 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07225468319763403		[learning rate: 0.00035152]
	Learning Rate: 0.000351518
	LOSS [training: 0.07225468319763403 | validation: 0.07351815545768463]
	TIME [epoch: 8.43 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06813464771079042		[learning rate: 0.00035024]
	Learning Rate: 0.000350242
	LOSS [training: 0.06813464771079042 | validation: 0.07234689996196184]
	TIME [epoch: 8.43 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07231843942970417		[learning rate: 0.00034897]
	Learning Rate: 0.000348971
	LOSS [training: 0.07231843942970417 | validation: 0.06627305688452555]
	TIME [epoch: 8.42 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09823225041182321		[learning rate: 0.0003477]
	Learning Rate: 0.000347705
	LOSS [training: 0.09823225041182321 | validation: 0.27000259932366005]
	TIME [epoch: 8.41 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10909855815663358		[learning rate: 0.00034644]
	Learning Rate: 0.000346443
	LOSS [training: 0.10909855815663358 | validation: 0.09652067492953598]
	TIME [epoch: 8.44 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10787567808838919		[learning rate: 0.00034519]
	Learning Rate: 0.000345186
	LOSS [training: 0.10787567808838919 | validation: 0.10797024804675036]
	TIME [epoch: 8.42 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07906194599378627		[learning rate: 0.00034393]
	Learning Rate: 0.000343933
	LOSS [training: 0.07906194599378627 | validation: 0.17136357559117846]
	TIME [epoch: 8.42 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10349429532515433		[learning rate: 0.00034268]
	Learning Rate: 0.000342685
	LOSS [training: 0.10349429532515433 | validation: 0.08267862607176205]
	TIME [epoch: 8.42 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07435962725893142		[learning rate: 0.00034144]
	Learning Rate: 0.000341441
	LOSS [training: 0.07435962725893142 | validation: 0.11321714201413272]
	TIME [epoch: 8.44 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08621560198832842		[learning rate: 0.0003402]
	Learning Rate: 0.000340202
	LOSS [training: 0.08621560198832842 | validation: 0.0704051585035171]
	TIME [epoch: 8.42 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06809676240519502		[learning rate: 0.00033897]
	Learning Rate: 0.000338967
	LOSS [training: 0.06809676240519502 | validation: 0.09156156516817388]
	TIME [epoch: 8.42 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0843111707873981		[learning rate: 0.00033774]
	Learning Rate: 0.000337737
	LOSS [training: 0.0843111707873981 | validation: 0.05897431161967352]
	TIME [epoch: 8.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1032.pth
	Model improved!!!
EPOCH 1033/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06524130786202822		[learning rate: 0.00033651]
	Learning Rate: 0.000336512
	LOSS [training: 0.06524130786202822 | validation: 0.07495734805746027]
	TIME [epoch: 8.42 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08854836556811971		[learning rate: 0.00033529]
	Learning Rate: 0.00033529
	LOSS [training: 0.08854836556811971 | validation: 0.07269934345026895]
	TIME [epoch: 8.42 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0743401610401071		[learning rate: 0.00033407]
	Learning Rate: 0.000334074
	LOSS [training: 0.0743401610401071 | validation: 0.10530902339763445]
	TIME [epoch: 8.42 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07729683434075715		[learning rate: 0.00033286]
	Learning Rate: 0.000332861
	LOSS [training: 0.07729683434075715 | validation: 0.07755142000929816]
	TIME [epoch: 8.44 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07392064454104716		[learning rate: 0.00033165]
	Learning Rate: 0.000331653
	LOSS [training: 0.07392064454104716 | validation: 0.0705002407539819]
	TIME [epoch: 8.43 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08995623380920995		[learning rate: 0.00033045]
	Learning Rate: 0.00033045
	LOSS [training: 0.08995623380920995 | validation: 0.07390240029855227]
	TIME [epoch: 8.41 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08713621719220094		[learning rate: 0.00032925]
	Learning Rate: 0.00032925
	LOSS [training: 0.08713621719220094 | validation: 0.09334527232743957]
	TIME [epoch: 8.43 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06957815685580093		[learning rate: 0.00032806]
	Learning Rate: 0.000328056
	LOSS [training: 0.06957815685580093 | validation: 0.06735438922699422]
	TIME [epoch: 8.43 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07342803096948644		[learning rate: 0.00032686]
	Learning Rate: 0.000326865
	LOSS [training: 0.07342803096948644 | validation: 0.06784558133994448]
	TIME [epoch: 8.42 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415823154450459		[learning rate: 0.00032568]
	Learning Rate: 0.000325679
	LOSS [training: 0.06415823154450459 | validation: 0.08070129494937453]
	TIME [epoch: 8.42 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07902025904370416		[learning rate: 0.0003245]
	Learning Rate: 0.000324497
	LOSS [training: 0.07902025904370416 | validation: 0.09037311369380505]
	TIME [epoch: 8.44 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06633458294095684		[learning rate: 0.00032332]
	Learning Rate: 0.000323319
	LOSS [training: 0.06633458294095684 | validation: 0.07317269858256316]
	TIME [epoch: 8.42 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06973413344889043		[learning rate: 0.00032215]
	Learning Rate: 0.000322146
	LOSS [training: 0.06973413344889043 | validation: 0.07217897168977949]
	TIME [epoch: 8.42 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08443939581570471		[learning rate: 0.00032098]
	Learning Rate: 0.000320977
	LOSS [training: 0.08443939581570471 | validation: 0.06053070478387533]
	TIME [epoch: 8.42 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08257419842505767		[learning rate: 0.00031981]
	Learning Rate: 0.000319812
	LOSS [training: 0.08257419842505767 | validation: 0.07837318336255221]
	TIME [epoch: 8.43 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06999500364794181		[learning rate: 0.00031865]
	Learning Rate: 0.000318651
	LOSS [training: 0.06999500364794181 | validation: 0.07640626494363997]
	TIME [epoch: 8.41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07864866192709033		[learning rate: 0.0003175]
	Learning Rate: 0.000317495
	LOSS [training: 0.07864866192709033 | validation: 0.05872231865489344]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1049.pth
	Model improved!!!
EPOCH 1050/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06721682584037972		[learning rate: 0.00031634]
	Learning Rate: 0.000316343
	LOSS [training: 0.06721682584037972 | validation: 0.07657834188288679]
	TIME [epoch: 8.44 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07884903682744036		[learning rate: 0.00031519]
	Learning Rate: 0.000315195
	LOSS [training: 0.07884903682744036 | validation: 0.07073593231254235]
	TIME [epoch: 8.42 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0744760711314861		[learning rate: 0.00031405]
	Learning Rate: 0.000314051
	LOSS [training: 0.0744760711314861 | validation: 0.0748139640913093]
	TIME [epoch: 8.42 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0779193080637977		[learning rate: 0.00031291]
	Learning Rate: 0.000312911
	LOSS [training: 0.0779193080637977 | validation: 0.09428498646284444]
	TIME [epoch: 8.42 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06427844859611904		[learning rate: 0.00031178]
	Learning Rate: 0.000311776
	LOSS [training: 0.06427844859611904 | validation: 0.07935087396705166]
	TIME [epoch: 8.43 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657142882395294		[learning rate: 0.00031064]
	Learning Rate: 0.000310644
	LOSS [training: 0.0657142882395294 | validation: 0.11059093040891839]
	TIME [epoch: 8.42 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07915857799844768		[learning rate: 0.00030952]
	Learning Rate: 0.000309517
	LOSS [training: 0.07915857799844768 | validation: 0.103479197242136]
	TIME [epoch: 8.41 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09185198444848007		[learning rate: 0.00030839]
	Learning Rate: 0.000308394
	LOSS [training: 0.09185198444848007 | validation: 0.08356544879091628]
	TIME [epoch: 8.44 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07940450497096885		[learning rate: 0.00030727]
	Learning Rate: 0.000307274
	LOSS [training: 0.07940450497096885 | validation: 0.08161454881637804]
	TIME [epoch: 8.42 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06980776933793326		[learning rate: 0.00030616]
	Learning Rate: 0.000306159
	LOSS [training: 0.06980776933793326 | validation: 0.09168425956869893]
	TIME [epoch: 8.42 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0756354459489193		[learning rate: 0.00030505]
	Learning Rate: 0.000305048
	LOSS [training: 0.0756354459489193 | validation: 0.07669995357961336]
	TIME [epoch: 8.43 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07683818451074136		[learning rate: 0.00030394]
	Learning Rate: 0.000303941
	LOSS [training: 0.07683818451074136 | validation: 0.07874876363926968]
	TIME [epoch: 8.44 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07207112109483602		[learning rate: 0.00030284]
	Learning Rate: 0.000302838
	LOSS [training: 0.07207112109483602 | validation: 0.06963826528586842]
	TIME [epoch: 8.42 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0701274024091734		[learning rate: 0.00030174]
	Learning Rate: 0.000301739
	LOSS [training: 0.0701274024091734 | validation: 0.05786781132095556]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07724229703350477		[learning rate: 0.00030064]
	Learning Rate: 0.000300644
	LOSS [training: 0.07724229703350477 | validation: 0.0697468230751569]
	TIME [epoch: 8.45 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06854114492857011		[learning rate: 0.00029955]
	Learning Rate: 0.000299553
	LOSS [training: 0.06854114492857011 | validation: 0.07936367485261898]
	TIME [epoch: 8.43 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06914083305056742		[learning rate: 0.00029847]
	Learning Rate: 0.000298466
	LOSS [training: 0.06914083305056742 | validation: 0.09906845457454197]
	TIME [epoch: 8.42 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07041522351008936		[learning rate: 0.00029738]
	Learning Rate: 0.000297383
	LOSS [training: 0.07041522351008936 | validation: 0.10719284589841353]
	TIME [epoch: 8.43 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07112026604632225		[learning rate: 0.0002963]
	Learning Rate: 0.000296304
	LOSS [training: 0.07112026604632225 | validation: 0.08731118505169069]
	TIME [epoch: 8.46 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07026541705270739		[learning rate: 0.00029523]
	Learning Rate: 0.000295228
	LOSS [training: 0.07026541705270739 | validation: 0.07938404900557149]
	TIME [epoch: 8.44 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08415859565903637		[learning rate: 0.00029416]
	Learning Rate: 0.000294157
	LOSS [training: 0.08415859565903637 | validation: 0.08057916330354939]
	TIME [epoch: 8.44 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07867832446016956		[learning rate: 0.00029309]
	Learning Rate: 0.000293089
	LOSS [training: 0.07867832446016956 | validation: 0.0886841717132461]
	TIME [epoch: 8.43 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07374001249356874		[learning rate: 0.00029203]
	Learning Rate: 0.000292026
	LOSS [training: 0.07374001249356874 | validation: 0.05989501101827935]
	TIME [epoch: 8.43 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0628241136988423		[learning rate: 0.00029097]
	Learning Rate: 0.000290966
	LOSS [training: 0.0628241136988423 | validation: 0.0754801209916617]
	TIME [epoch: 8.42 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06901896746831314		[learning rate: 0.00028991]
	Learning Rate: 0.00028991
	LOSS [training: 0.06901896746831314 | validation: 0.05470453495708619]
	TIME [epoch: 8.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1074.pth
	Model improved!!!
EPOCH 1075/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06034257560910654		[learning rate: 0.00028886]
	Learning Rate: 0.000288858
	LOSS [training: 0.06034257560910654 | validation: 0.06948947610533242]
	TIME [epoch: 8.46 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060651657160765995		[learning rate: 0.00028781]
	Learning Rate: 0.00028781
	LOSS [training: 0.060651657160765995 | validation: 0.0989609952386395]
	TIME [epoch: 8.43 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07884251887071117		[learning rate: 0.00028677]
	Learning Rate: 0.000286765
	LOSS [training: 0.07884251887071117 | validation: 0.08857397739390707]
	TIME [epoch: 8.43 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07599474076663977		[learning rate: 0.00028572]
	Learning Rate: 0.000285724
	LOSS [training: 0.07599474076663977 | validation: 0.07584705323046904]
	TIME [epoch: 8.43 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0796718062722803		[learning rate: 0.00028469]
	Learning Rate: 0.000284688
	LOSS [training: 0.0796718062722803 | validation: 0.1378149718446925]
	TIME [epoch: 8.45 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07351987166165361		[learning rate: 0.00028365]
	Learning Rate: 0.000283654
	LOSS [training: 0.07351987166165361 | validation: 0.11250110903209438]
	TIME [epoch: 8.43 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07980585928990983		[learning rate: 0.00028263]
	Learning Rate: 0.000282625
	LOSS [training: 0.07980585928990983 | validation: 0.05759204343123107]
	TIME [epoch: 8.43 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07014855973558466		[learning rate: 0.0002816]
	Learning Rate: 0.000281599
	LOSS [training: 0.07014855973558466 | validation: 0.06958491486495023]
	TIME [epoch: 8.44 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06292791325988598		[learning rate: 0.00028058]
	Learning Rate: 0.000280577
	LOSS [training: 0.06292791325988598 | validation: 0.0768519032321892]
	TIME [epoch: 8.44 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08516454826466946		[learning rate: 0.00027956]
	Learning Rate: 0.000279559
	LOSS [training: 0.08516454826466946 | validation: 0.11067316584836759]
	TIME [epoch: 8.43 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08104868616899708		[learning rate: 0.00027854]
	Learning Rate: 0.000278545
	LOSS [training: 0.08104868616899708 | validation: 0.07117325568716641]
	TIME [epoch: 8.43 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251880190924324		[learning rate: 0.00027753]
	Learning Rate: 0.000277534
	LOSS [training: 0.06251880190924324 | validation: 0.06774996575308065]
	TIME [epoch: 8.46 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0723881389426572		[learning rate: 0.00027653]
	Learning Rate: 0.000276527
	LOSS [training: 0.0723881389426572 | validation: 0.06321722106419542]
	TIME [epoch: 8.43 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06586292344754904		[learning rate: 0.00027552]
	Learning Rate: 0.000275523
	LOSS [training: 0.06586292344754904 | validation: 0.09756093423916287]
	TIME [epoch: 8.43 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07288276815367209		[learning rate: 0.00027452]
	Learning Rate: 0.000274523
	LOSS [training: 0.07288276815367209 | validation: 0.0673142548747829]
	TIME [epoch: 8.44 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07052978804069229		[learning rate: 0.00027353]
	Learning Rate: 0.000273527
	LOSS [training: 0.07052978804069229 | validation: 0.10006180953706281]
	TIME [epoch: 8.45 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07226326413082558		[learning rate: 0.00027253]
	Learning Rate: 0.000272534
	LOSS [training: 0.07226326413082558 | validation: 0.07818651733930172]
	TIME [epoch: 8.43 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06248480976154541		[learning rate: 0.00027155]
	Learning Rate: 0.000271545
	LOSS [training: 0.06248480976154541 | validation: 0.07829851643110072]
	TIME [epoch: 8.43 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06770829778207574		[learning rate: 0.00027056]
	Learning Rate: 0.00027056
	LOSS [training: 0.06770829778207574 | validation: 0.08079272734199329]
	TIME [epoch: 8.45 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0730210647001113		[learning rate: 0.00026958]
	Learning Rate: 0.000269578
	LOSS [training: 0.0730210647001113 | validation: 0.06501444425735048]
	TIME [epoch: 8.43 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0661072497676876		[learning rate: 0.0002686]
	Learning Rate: 0.0002686
	LOSS [training: 0.0661072497676876 | validation: 0.07615398610766097]
	TIME [epoch: 8.43 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06619522927900037		[learning rate: 0.00026762]
	Learning Rate: 0.000267625
	LOSS [training: 0.06619522927900037 | validation: 0.07694826280542712]
	TIME [epoch: 8.43 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06611209200982271		[learning rate: 0.00026665]
	Learning Rate: 0.000266654
	LOSS [training: 0.06611209200982271 | validation: 0.08461555231261061]
	TIME [epoch: 8.46 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06779280385663423		[learning rate: 0.00026569]
	Learning Rate: 0.000265686
	LOSS [training: 0.06779280385663423 | validation: 0.09998131702530011]
	TIME [epoch: 8.43 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06791353747579609		[learning rate: 0.00026472]
	Learning Rate: 0.000264722
	LOSS [training: 0.06791353747579609 | validation: 0.0715450158077718]
	TIME [epoch: 8.43 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07194607022533608		[learning rate: 0.00026376]
	Learning Rate: 0.000263761
	LOSS [training: 0.07194607022533608 | validation: 0.09931093842166408]
	TIME [epoch: 8.45 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08602687386015902		[learning rate: 0.0002628]
	Learning Rate: 0.000262804
	LOSS [training: 0.08602687386015902 | validation: 0.1157760435788533]
	TIME [epoch: 8.44 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07904575178551669		[learning rate: 0.00026185]
	Learning Rate: 0.00026185
	LOSS [training: 0.07904575178551669 | validation: 0.07482965923123817]
	TIME [epoch: 8.43 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0695383625412631		[learning rate: 0.0002609]
	Learning Rate: 0.0002609
	LOSS [training: 0.0695383625412631 | validation: 0.07076451775298259]
	TIME [epoch: 8.43 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06921859207740953		[learning rate: 0.00025995]
	Learning Rate: 0.000259953
	LOSS [training: 0.06921859207740953 | validation: 0.07263977768786817]
	TIME [epoch: 8.46 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06849697738015198		[learning rate: 0.00025901]
	Learning Rate: 0.00025901
	LOSS [training: 0.06849697738015198 | validation: 0.06206431221615608]
	TIME [epoch: 8.43 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07232944069818384		[learning rate: 0.00025807]
	Learning Rate: 0.00025807
	LOSS [training: 0.07232944069818384 | validation: 0.06673939740553075]
	TIME [epoch: 8.43 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06922204658616363		[learning rate: 0.00025713]
	Learning Rate: 0.000257133
	LOSS [training: 0.06922204658616363 | validation: 0.07843719600750265]
	TIME [epoch: 8.44 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07661630332992139		[learning rate: 0.0002562]
	Learning Rate: 0.0002562
	LOSS [training: 0.07661630332992139 | validation: 0.0807867608342046]
	TIME [epoch: 8.44 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06462439242766524		[learning rate: 0.00025527]
	Learning Rate: 0.00025527
	LOSS [training: 0.06462439242766524 | validation: 0.06610515759190198]
	TIME [epoch: 8.43 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06358780701017025		[learning rate: 0.00025434]
	Learning Rate: 0.000254344
	LOSS [training: 0.06358780701017025 | validation: 0.07997690023032689]
	TIME [epoch: 8.43 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0716413478976085		[learning rate: 0.00025342]
	Learning Rate: 0.000253421
	LOSS [training: 0.0716413478976085 | validation: 0.07287229777412425]
	TIME [epoch: 8.45 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07845991556273132		[learning rate: 0.0002525]
	Learning Rate: 0.000252501
	LOSS [training: 0.07845991556273132 | validation: 0.07681756501863658]
	TIME [epoch: 8.43 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0757036122488903		[learning rate: 0.00025158]
	Learning Rate: 0.000251585
	LOSS [training: 0.0757036122488903 | validation: 0.078646754053711]
	TIME [epoch: 8.43 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07084948741445385		[learning rate: 0.00025067]
	Learning Rate: 0.000250672
	LOSS [training: 0.07084948741445385 | validation: 0.09697389429598327]
	TIME [epoch: 8.44 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0731769857918157		[learning rate: 0.00024976]
	Learning Rate: 0.000249762
	LOSS [training: 0.0731769857918157 | validation: 0.0821266868109088]
	TIME [epoch: 8.45 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08242944565397305		[learning rate: 0.00024886]
	Learning Rate: 0.000248856
	LOSS [training: 0.08242944565397305 | validation: 0.08559098608033247]
	TIME [epoch: 8.43 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0674868184345478		[learning rate: 0.00024795]
	Learning Rate: 0.000247952
	LOSS [training: 0.0674868184345478 | validation: 0.08518110435583934]
	TIME [epoch: 8.43 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07281661580006452		[learning rate: 0.00024705]
	Learning Rate: 0.000247053
	LOSS [training: 0.07281661580006452 | validation: 0.05955239702463953]
	TIME [epoch: 8.45 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06647059769394144		[learning rate: 0.00024616]
	Learning Rate: 0.000246156
	LOSS [training: 0.06647059769394144 | validation: 0.05530731547489321]
	TIME [epoch: 8.43 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0719239805826474		[learning rate: 0.00024526]
	Learning Rate: 0.000245263
	LOSS [training: 0.0719239805826474 | validation: 0.06105467787002036]
	TIME [epoch: 8.44 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874971219869638		[learning rate: 0.00024437]
	Learning Rate: 0.000244373
	LOSS [training: 0.05874971219869638 | validation: 0.06885341296740101]
	TIME [epoch: 8.43 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07260816127830981		[learning rate: 0.00024349]
	Learning Rate: 0.000243486
	LOSS [training: 0.07260816127830981 | validation: 0.056780610903870085]
	TIME [epoch: 8.46 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06651602047162662		[learning rate: 0.0002426]
	Learning Rate: 0.000242602
	LOSS [training: 0.06651602047162662 | validation: 0.07052769854557996]
	TIME [epoch: 8.44 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06103186967956985		[learning rate: 0.00024172]
	Learning Rate: 0.000241722
	LOSS [training: 0.06103186967956985 | validation: 0.06945981716221075]
	TIME [epoch: 8.43 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06431915764451697		[learning rate: 0.00024084]
	Learning Rate: 0.000240845
	LOSS [training: 0.06431915764451697 | validation: 0.08498544945203586]
	TIME [epoch: 8.46 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.10439878273358674		[learning rate: 0.00023997]
	Learning Rate: 0.000239971
	LOSS [training: 0.10439878273358674 | validation: 0.10181896076997973]
	TIME [epoch: 8.44 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.1024803085206553		[learning rate: 0.0002391]
	Learning Rate: 0.0002391
	LOSS [training: 0.1024803085206553 | validation: 0.07549892894901414]
	TIME [epoch: 8.43 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0779077076602871		[learning rate: 0.00023823]
	Learning Rate: 0.000238232
	LOSS [training: 0.0779077076602871 | validation: 0.07448396697136583]
	TIME [epoch: 8.43 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07244314725504646		[learning rate: 0.00023737]
	Learning Rate: 0.000237367
	LOSS [training: 0.07244314725504646 | validation: 0.058225746424397935]
	TIME [epoch: 8.46 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06659664162602912		[learning rate: 0.00023651]
	Learning Rate: 0.000236506
	LOSS [training: 0.06659664162602912 | validation: 0.05887511839025541]
	TIME [epoch: 8.44 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06747258304018997		[learning rate: 0.00023565]
	Learning Rate: 0.000235648
	LOSS [training: 0.06747258304018997 | validation: 0.07042368021436092]
	TIME [epoch: 8.43 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061619222879346604		[learning rate: 0.00023479]
	Learning Rate: 0.000234793
	LOSS [training: 0.061619222879346604 | validation: 0.06215592578381872]
	TIME [epoch: 8.45 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06185230101406606		[learning rate: 0.00023394]
	Learning Rate: 0.00023394
	LOSS [training: 0.06185230101406606 | validation: 0.05771213784238778]
	TIME [epoch: 8.44 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06392306508381747		[learning rate: 0.00023309]
	Learning Rate: 0.000233091
	LOSS [training: 0.06392306508381747 | validation: 0.05876074022230687]
	TIME [epoch: 8.43 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07562049558997865		[learning rate: 0.00023225]
	Learning Rate: 0.000232246
	LOSS [training: 0.07562049558997865 | validation: 0.07278611920337397]
	TIME [epoch: 8.43 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06609097106400179		[learning rate: 0.0002314]
	Learning Rate: 0.000231403
	LOSS [training: 0.06609097106400179 | validation: 0.06681823736044093]
	TIME [epoch: 8.46 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06477919021846776		[learning rate: 0.00023056]
	Learning Rate: 0.000230563
	LOSS [training: 0.06477919021846776 | validation: 0.06001859220954789]
	TIME [epoch: 8.43 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06556900079654222		[learning rate: 0.00022973]
	Learning Rate: 0.000229726
	LOSS [training: 0.06556900079654222 | validation: 0.07605408803918387]
	TIME [epoch: 8.43 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06943273625186773		[learning rate: 0.00022889]
	Learning Rate: 0.000228893
	LOSS [training: 0.06943273625186773 | validation: 0.08944367329400606]
	TIME [epoch: 8.44 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07989195278654244		[learning rate: 0.00022806]
	Learning Rate: 0.000228062
	LOSS [training: 0.07989195278654244 | validation: 0.0720351690757723]
	TIME [epoch: 8.45 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0775461218968229		[learning rate: 0.00022723]
	Learning Rate: 0.000227234
	LOSS [training: 0.0775461218968229 | validation: 0.08205140507120812]
	TIME [epoch: 8.43 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.08589303006792508		[learning rate: 0.00022641]
	Learning Rate: 0.00022641
	LOSS [training: 0.08589303006792508 | validation: 0.07175495415489413]
	TIME [epoch: 8.43 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06844523718533316		[learning rate: 0.00022559]
	Learning Rate: 0.000225588
	LOSS [training: 0.06844523718533316 | validation: 0.06593533415120727]
	TIME [epoch: 8.46 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062006663218844425		[learning rate: 0.00022477]
	Learning Rate: 0.000224769
	LOSS [training: 0.062006663218844425 | validation: 0.08218654226303344]
	TIME [epoch: 8.43 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07964022784670216		[learning rate: 0.00022395]
	Learning Rate: 0.000223954
	LOSS [training: 0.07964022784670216 | validation: 0.09162787095788005]
	TIME [epoch: 8.43 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06865194445653157		[learning rate: 0.00022314]
	Learning Rate: 0.000223141
	LOSS [training: 0.06865194445653157 | validation: 0.05904913318670287]
	TIME [epoch: 8.43 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06865956820214875		[learning rate: 0.00022233]
	Learning Rate: 0.000222331
	LOSS [training: 0.06865956820214875 | validation: 0.08300313501824781]
	TIME [epoch: 8.46 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06349908048383594		[learning rate: 0.00022152]
	Learning Rate: 0.000221524
	LOSS [training: 0.06349908048383594 | validation: 0.07696580158985107]
	TIME [epoch: 8.44 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.09698974054068832		[learning rate: 0.00022072]
	Learning Rate: 0.00022072
	LOSS [training: 0.09698974054068832 | validation: 0.10193971893316814]
	TIME [epoch: 8.44 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07307152989732682		[learning rate: 0.00021992]
	Learning Rate: 0.000219919
	LOSS [training: 0.07307152989732682 | validation: 0.08353950833414837]
	TIME [epoch: 8.45 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06366900193657142		[learning rate: 0.00021912]
	Learning Rate: 0.000219121
	LOSS [training: 0.06366900193657142 | validation: 0.06937407980929106]
	TIME [epoch: 8.44 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05973698150294312		[learning rate: 0.00021833]
	Learning Rate: 0.000218326
	LOSS [training: 0.05973698150294312 | validation: 0.075259735689575]
	TIME [epoch: 8.43 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07094576692081288		[learning rate: 0.00021753]
	Learning Rate: 0.000217534
	LOSS [training: 0.07094576692081288 | validation: 0.06617238308273005]
	TIME [epoch: 8.43 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06803992036099277		[learning rate: 0.00021674]
	Learning Rate: 0.000216744
	LOSS [training: 0.06803992036099277 | validation: 0.0832442130879904]
	TIME [epoch: 8.46 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07417498866629708		[learning rate: 0.00021596]
	Learning Rate: 0.000215958
	LOSS [training: 0.07417498866629708 | validation: 0.08652954026655478]
	TIME [epoch: 8.43 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06724259384568246		[learning rate: 0.00021517]
	Learning Rate: 0.000215174
	LOSS [training: 0.06724259384568246 | validation: 0.07174242878689495]
	TIME [epoch: 8.43 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05911889018549739		[learning rate: 0.00021439]
	Learning Rate: 0.000214393
	LOSS [training: 0.05911889018549739 | validation: 0.0703305507422991]
	TIME [epoch: 8.45 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062375726513452315		[learning rate: 0.00021361]
	Learning Rate: 0.000213615
	LOSS [training: 0.062375726513452315 | validation: 0.07504905323450771]
	TIME [epoch: 8.44 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06406589379899924		[learning rate: 0.00021284]
	Learning Rate: 0.00021284
	LOSS [training: 0.06406589379899924 | validation: 0.06970463677732044]
	TIME [epoch: 8.43 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06062415561303493		[learning rate: 0.00021207]
	Learning Rate: 0.000212067
	LOSS [training: 0.06062415561303493 | validation: 0.09466439062297921]
	TIME [epoch: 8.43 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07822024615182147		[learning rate: 0.0002113]
	Learning Rate: 0.000211298
	LOSS [training: 0.07822024615182147 | validation: 0.06334522464365136]
	TIME [epoch: 8.46 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857649070057306		[learning rate: 0.00021053]
	Learning Rate: 0.000210531
	LOSS [training: 0.06857649070057306 | validation: 0.06517218321945842]
	TIME [epoch: 8.43 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05888126484553417		[learning rate: 0.00020977]
	Learning Rate: 0.000209767
	LOSS [training: 0.05888126484553417 | validation: 0.0643040459657313]
	TIME [epoch: 8.43 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663548791793298		[learning rate: 0.00020901]
	Learning Rate: 0.000209006
	LOSS [training: 0.0663548791793298 | validation: 0.05895776794983701]
	TIME [epoch: 8.44 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055962372707519824		[learning rate: 0.00020825]
	Learning Rate: 0.000208247
	LOSS [training: 0.055962372707519824 | validation: 0.07390655407924537]
	TIME [epoch: 8.45 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06214205560809979		[learning rate: 0.00020749]
	Learning Rate: 0.000207491
	LOSS [training: 0.06214205560809979 | validation: 0.0896482840728314]
	TIME [epoch: 8.43 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07088997391305109		[learning rate: 0.00020674]
	Learning Rate: 0.000206738
	LOSS [training: 0.07088997391305109 | validation: 0.08610640268013448]
	TIME [epoch: 8.43 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07524117667528232		[learning rate: 0.00020599]
	Learning Rate: 0.000205988
	LOSS [training: 0.07524117667528232 | validation: 0.09356403434407554]
	TIME [epoch: 8.46 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07061903049153215		[learning rate: 0.00020524]
	Learning Rate: 0.000205241
	LOSS [training: 0.07061903049153215 | validation: 0.0774830749212339]
	TIME [epoch: 8.43 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07685012032364384		[learning rate: 0.0002045]
	Learning Rate: 0.000204496
	LOSS [training: 0.07685012032364384 | validation: 0.11046501209064494]
	TIME [epoch: 8.44 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06588365051789316		[learning rate: 0.00020375]
	Learning Rate: 0.000203754
	LOSS [training: 0.06588365051789316 | validation: 0.07861268151075215]
	TIME [epoch: 8.44 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060327283228262064		[learning rate: 0.00020301]
	Learning Rate: 0.000203014
	LOSS [training: 0.060327283228262064 | validation: 0.0865876377405943]
	TIME [epoch: 8.45 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0630986614583947		[learning rate: 0.00020228]
	Learning Rate: 0.000202277
	LOSS [training: 0.0630986614583947 | validation: 0.07252464557623689]
	TIME [epoch: 8.43 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06876619988771514		[learning rate: 0.00020154]
	Learning Rate: 0.000201543
	LOSS [training: 0.06876619988771514 | validation: 0.07035543664619573]
	TIME [epoch: 8.43 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06271014876330198		[learning rate: 0.00020081]
	Learning Rate: 0.000200812
	LOSS [training: 0.06271014876330198 | validation: 0.0737165201797362]
	TIME [epoch: 8.45 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06796159716142965		[learning rate: 0.00020008]
	Learning Rate: 0.000200083
	LOSS [training: 0.06796159716142965 | validation: 0.06869594314098443]
	TIME [epoch: 8.44 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07221268714090492		[learning rate: 0.00019936]
	Learning Rate: 0.000199357
	LOSS [training: 0.07221268714090492 | validation: 0.06799517972849703]
	TIME [epoch: 8.44 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07192006338760812		[learning rate: 0.00019863]
	Learning Rate: 0.000198634
	LOSS [training: 0.07192006338760812 | validation: 0.07591866898736109]
	TIME [epoch: 8.43 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06889095150882357		[learning rate: 0.00019791]
	Learning Rate: 0.000197913
	LOSS [training: 0.06889095150882357 | validation: 0.061332374687986045]
	TIME [epoch: 8.45 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06429345766269233		[learning rate: 0.00019719]
	Learning Rate: 0.000197194
	LOSS [training: 0.06429345766269233 | validation: 0.07422516930052642]
	TIME [epoch: 8.43 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062057780346579924		[learning rate: 0.00019648]
	Learning Rate: 0.000196479
	LOSS [training: 0.062057780346579924 | validation: 0.054001382957133026]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05639267858121817		[learning rate: 0.00019577]
	Learning Rate: 0.000195766
	LOSS [training: 0.05639267858121817 | validation: 0.06817546493989458]
	TIME [epoch: 8.45 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06830791522027996		[learning rate: 0.00019506]
	Learning Rate: 0.000195055
	LOSS [training: 0.06830791522027996 | validation: 0.0918224449574538]
	TIME [epoch: 8.43 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07688967648593487		[learning rate: 0.00019435]
	Learning Rate: 0.000194347
	LOSS [training: 0.07688967648593487 | validation: 0.06862641680017253]
	TIME [epoch: 8.43 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06903537001833884		[learning rate: 0.00019364]
	Learning Rate: 0.000193642
	LOSS [training: 0.06903537001833884 | validation: 0.061999397740451316]
	TIME [epoch: 8.43 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0691666913723907		[learning rate: 0.00019294]
	Learning Rate: 0.000192939
	LOSS [training: 0.0691666913723907 | validation: 0.06766519172714311]
	TIME [epoch: 8.45 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059855515098705195		[learning rate: 0.00019224]
	Learning Rate: 0.000192239
	LOSS [training: 0.059855515098705195 | validation: 0.06601422441285805]
	TIME [epoch: 8.43 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06258220089346123		[learning rate: 0.00019154]
	Learning Rate: 0.000191542
	LOSS [training: 0.06258220089346123 | validation: 0.06430989548171041]
	TIME [epoch: 8.43 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152951342810261		[learning rate: 0.00019085]
	Learning Rate: 0.000190846
	LOSS [training: 0.06152951342810261 | validation: 0.07336053921589354]
	TIME [epoch: 8.44 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07104302264927052		[learning rate: 0.00019015]
	Learning Rate: 0.000190154
	LOSS [training: 0.07104302264927052 | validation: 0.07033612534603922]
	TIME [epoch: 8.44 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056772651345787205		[learning rate: 0.00018946]
	Learning Rate: 0.000189464
	LOSS [training: 0.056772651345787205 | validation: 0.0625375692045253]
	TIME [epoch: 8.43 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05367940770545012		[learning rate: 0.00018878]
	Learning Rate: 0.000188776
	LOSS [training: 0.05367940770545012 | validation: 0.06595161427361627]
	TIME [epoch: 8.43 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06570892788088638		[learning rate: 0.00018809]
	Learning Rate: 0.000188091
	LOSS [training: 0.06570892788088638 | validation: 0.05864666501111104]
	TIME [epoch: 8.46 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06333278577085266		[learning rate: 0.00018741]
	Learning Rate: 0.000187409
	LOSS [training: 0.06333278577085266 | validation: 0.07974443017145716]
	TIME [epoch: 8.44 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07080703240878601		[learning rate: 0.00018673]
	Learning Rate: 0.000186729
	LOSS [training: 0.07080703240878601 | validation: 0.08041335410736151]
	TIME [epoch: 8.43 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07722975707711992		[learning rate: 0.00018605]
	Learning Rate: 0.000186051
	LOSS [training: 0.07722975707711992 | validation: 0.06492591699424931]
	TIME [epoch: 8.44 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0678489515042868		[learning rate: 0.00018538]
	Learning Rate: 0.000185376
	LOSS [training: 0.0678489515042868 | validation: 0.06456590875277282]
	TIME [epoch: 8.44 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06108427106613325		[learning rate: 0.0001847]
	Learning Rate: 0.000184703
	LOSS [training: 0.06108427106613325 | validation: 0.09929436715955216]
	TIME [epoch: 8.43 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06805611288765437		[learning rate: 0.00018403]
	Learning Rate: 0.000184033
	LOSS [training: 0.06805611288765437 | validation: 0.047232952638808265]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1199.pth
	Model improved!!!
EPOCH 1200/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06334823218384507		[learning rate: 0.00018336]
	Learning Rate: 0.000183365
	LOSS [training: 0.06334823218384507 | validation: 0.08922945269180066]
	TIME [epoch: 8.46 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06729468042986717		[learning rate: 0.0001827]
	Learning Rate: 0.000182699
	LOSS [training: 0.06729468042986717 | validation: 0.06261497336530053]
	TIME [epoch: 8.42 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06368980301135788		[learning rate: 0.00018204]
	Learning Rate: 0.000182036
	LOSS [training: 0.06368980301135788 | validation: 0.06732719546468982]
	TIME [epoch: 8.42 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05639290397705177		[learning rate: 0.00018138]
	Learning Rate: 0.000181376
	LOSS [training: 0.05639290397705177 | validation: 0.06651191312140403]
	TIME [epoch: 8.44 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0675780392430152		[learning rate: 0.00018072]
	Learning Rate: 0.000180717
	LOSS [training: 0.0675780392430152 | validation: 0.08756540975725122]
	TIME [epoch: 8.44 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06438231094547173		[learning rate: 0.00018006]
	Learning Rate: 0.000180062
	LOSS [training: 0.06438231094547173 | validation: 0.05473627575426636]
	TIME [epoch: 8.43 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06212000682967741		[learning rate: 0.00017941]
	Learning Rate: 0.000179408
	LOSS [training: 0.06212000682967741 | validation: 0.07106885443850816]
	TIME [epoch: 8.42 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06930248039527635		[learning rate: 0.00017876]
	Learning Rate: 0.000178757
	LOSS [training: 0.06930248039527635 | validation: 0.06705816057423233]
	TIME [epoch: 8.45 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06728160546114824		[learning rate: 0.00017811]
	Learning Rate: 0.000178108
	LOSS [training: 0.06728160546114824 | validation: 0.05861530397546774]
	TIME [epoch: 8.43 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06480331898248892		[learning rate: 0.00017746]
	Learning Rate: 0.000177462
	LOSS [training: 0.06480331898248892 | validation: 0.06799101891717213]
	TIME [epoch: 8.42 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06822587594319722		[learning rate: 0.00017682]
	Learning Rate: 0.000176818
	LOSS [training: 0.06822587594319722 | validation: 0.06589427305976267]
	TIME [epoch: 8.42 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06399677239946125		[learning rate: 0.00017618]
	Learning Rate: 0.000176176
	LOSS [training: 0.06399677239946125 | validation: 0.09153453145934402]
	TIME [epoch: 8.44 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07334285687734733		[learning rate: 0.00017554]
	Learning Rate: 0.000175537
	LOSS [training: 0.07334285687734733 | validation: 0.060736840575641014]
	TIME [epoch: 8.43 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06410820858606954		[learning rate: 0.0001749]
	Learning Rate: 0.0001749
	LOSS [training: 0.06410820858606954 | validation: 0.06786093934912643]
	TIME [epoch: 8.41 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0682214619700289		[learning rate: 0.00017427]
	Learning Rate: 0.000174265
	LOSS [training: 0.0682214619700289 | validation: 0.05939143173905564]
	TIME [epoch: 8.45 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06261808985732505		[learning rate: 0.00017363]
	Learning Rate: 0.000173633
	LOSS [training: 0.06261808985732505 | validation: 0.06942692269741937]
	TIME [epoch: 8.43 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05965067194886482		[learning rate: 0.000173]
	Learning Rate: 0.000173003
	LOSS [training: 0.05965067194886482 | validation: 0.05740272351591151]
	TIME [epoch: 8.43 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05662026918330569		[learning rate: 0.00017237]
	Learning Rate: 0.000172375
	LOSS [training: 0.05662026918330569 | validation: 0.06649320428008997]
	TIME [epoch: 8.42 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05838837318864275		[learning rate: 0.00017175]
	Learning Rate: 0.000171749
	LOSS [training: 0.05838837318864275 | validation: 0.06483889094500941]
	TIME [epoch: 8.45 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0621269874584922		[learning rate: 0.00017113]
	Learning Rate: 0.000171126
	LOSS [training: 0.0621269874584922 | validation: 0.060450767421701176]
	TIME [epoch: 8.42 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05938622985017167		[learning rate: 0.0001705]
	Learning Rate: 0.000170505
	LOSS [training: 0.05938622985017167 | validation: 0.06852726591981777]
	TIME [epoch: 8.41 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0638395026417308		[learning rate: 0.00016989]
	Learning Rate: 0.000169886
	LOSS [training: 0.0638395026417308 | validation: 0.06986611414171001]
	TIME [epoch: 8.43 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857268677974918		[learning rate: 0.00016927]
	Learning Rate: 0.00016927
	LOSS [training: 0.06857268677974918 | validation: 0.06278525676733847]
	TIME [epoch: 8.44 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06910409330011766		[learning rate: 0.00016866]
	Learning Rate: 0.000168655
	LOSS [training: 0.06910409330011766 | validation: 0.06881615072214495]
	TIME [epoch: 8.43 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06486018031875714		[learning rate: 0.00016804]
	Learning Rate: 0.000168043
	LOSS [training: 0.06486018031875714 | validation: 0.05590659662900583]
	TIME [epoch: 8.42 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06254707082633144		[learning rate: 0.00016743]
	Learning Rate: 0.000167433
	LOSS [training: 0.06254707082633144 | validation: 0.05976775718071483]
	TIME [epoch: 8.44 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0641803808081769		[learning rate: 0.00016683]
	Learning Rate: 0.000166826
	LOSS [training: 0.0641803808081769 | validation: 0.06000550013008569]
	TIME [epoch: 8.43 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06146013086905411		[learning rate: 0.00016622]
	Learning Rate: 0.00016622
	LOSS [training: 0.06146013086905411 | validation: 0.06772124979406108]
	TIME [epoch: 8.43 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385227178428857		[learning rate: 0.00016562]
	Learning Rate: 0.000165617
	LOSS [training: 0.06385227178428857 | validation: 0.07509198361477343]
	TIME [epoch: 8.45 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060354886576254575		[learning rate: 0.00016502]
	Learning Rate: 0.000165016
	LOSS [training: 0.060354886576254575 | validation: 0.07852481596395226]
	TIME [epoch: 8.44 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06541044882979259		[learning rate: 0.00016442]
	Learning Rate: 0.000164417
	LOSS [training: 0.06541044882979259 | validation: 0.06501078843258107]
	TIME [epoch: 8.43 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058245704347100434		[learning rate: 0.00016382]
	Learning Rate: 0.000163821
	LOSS [training: 0.058245704347100434 | validation: 0.07819403850583667]
	TIME [epoch: 8.43 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057127507273507384		[learning rate: 0.00016323]
	Learning Rate: 0.000163226
	LOSS [training: 0.057127507273507384 | validation: 0.06378620546670606]
	TIME [epoch: 8.45 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06739511675156037		[learning rate: 0.00016263]
	Learning Rate: 0.000162634
	LOSS [training: 0.06739511675156037 | validation: 0.07501316687992626]
	TIME [epoch: 8.43 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07244287450541365		[learning rate: 0.00016204]
	Learning Rate: 0.000162043
	LOSS [training: 0.07244287450541365 | validation: 0.07003843285350458]
	TIME [epoch: 8.43 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07200960122222735		[learning rate: 0.00016146]
	Learning Rate: 0.000161455
	LOSS [training: 0.07200960122222735 | validation: 0.07941838810650599]
	TIME [epoch: 8.42 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058404405342095476		[learning rate: 0.00016087]
	Learning Rate: 0.000160869
	LOSS [training: 0.058404405342095476 | validation: 0.059022129554658465]
	TIME [epoch: 8.45 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05893504654399236		[learning rate: 0.00016029]
	Learning Rate: 0.000160286
	LOSS [training: 0.05893504654399236 | validation: 0.05565853772598396]
	TIME [epoch: 8.43 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05473450273528733		[learning rate: 0.0001597]
	Learning Rate: 0.000159704
	LOSS [training: 0.05473450273528733 | validation: 0.06940564835566658]
	TIME [epoch: 8.43 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05915297871950059		[learning rate: 0.00015912]
	Learning Rate: 0.000159124
	LOSS [training: 0.05915297871950059 | validation: 0.07730275387679385]
	TIME [epoch: 8.45 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06945725746569328		[learning rate: 0.00015855]
	Learning Rate: 0.000158547
	LOSS [training: 0.06945725746569328 | validation: 0.06364825814739314]
	TIME [epoch: 8.43 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05863220751485132		[learning rate: 0.00015797]
	Learning Rate: 0.000157972
	LOSS [training: 0.05863220751485132 | validation: 0.053925136152641405]
	TIME [epoch: 8.43 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06806353410469		[learning rate: 0.0001574]
	Learning Rate: 0.000157398
	LOSS [training: 0.06806353410469 | validation: 0.05934897561475529]
	TIME [epoch: 8.42 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06516650631273517		[learning rate: 0.00015683]
	Learning Rate: 0.000156827
	LOSS [training: 0.06516650631273517 | validation: 0.07553533888528569]
	TIME [epoch: 8.45 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06994190258719488		[learning rate: 0.00015626]
	Learning Rate: 0.000156258
	LOSS [training: 0.06994190258719488 | validation: 0.04695142988763925]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1244.pth
	Model improved!!!
EPOCH 1245/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05891987572554765		[learning rate: 0.00015569]
	Learning Rate: 0.000155691
	LOSS [training: 0.05891987572554765 | validation: 0.06520300920613013]
	TIME [epoch: 8.43 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06072989256239668		[learning rate: 0.00015513]
	Learning Rate: 0.000155126
	LOSS [training: 0.06072989256239668 | validation: 0.059677674286510204]
	TIME [epoch: 8.44 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06793032116147339		[learning rate: 0.00015456]
	Learning Rate: 0.000154563
	LOSS [training: 0.06793032116147339 | validation: 0.06715365915617602]
	TIME [epoch: 8.43 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057777374088930876		[learning rate: 0.000154]
	Learning Rate: 0.000154002
	LOSS [training: 0.057777374088930876 | validation: 0.061713368799278544]
	TIME [epoch: 8.43 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06433812346574683		[learning rate: 0.00015344]
	Learning Rate: 0.000153443
	LOSS [training: 0.06433812346574683 | validation: 0.059202460699121634]
	TIME [epoch: 8.42 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06834663960323022		[learning rate: 0.00015289]
	Learning Rate: 0.000152886
	LOSS [training: 0.06834663960323022 | validation: 0.07553358624604976]
	TIME [epoch: 8.45 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05700176355184792		[learning rate: 0.00015233]
	Learning Rate: 0.000152331
	LOSS [training: 0.05700176355184792 | validation: 0.05754070074833218]
	TIME [epoch: 8.43 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06938212184005535		[learning rate: 0.00015178]
	Learning Rate: 0.000151779
	LOSS [training: 0.06938212184005535 | validation: 0.06434281871326882]
	TIME [epoch: 8.42 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06929800117984772		[learning rate: 0.00015123]
	Learning Rate: 0.000151228
	LOSS [training: 0.06929800117984772 | validation: 0.058344836695387474]
	TIME [epoch: 8.43 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06183638104972962		[learning rate: 0.00015068]
	Learning Rate: 0.000150679
	LOSS [training: 0.06183638104972962 | validation: 0.049197250789848636]
	TIME [epoch: 8.45 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06223232870910479		[learning rate: 0.00015013]
	Learning Rate: 0.000150132
	LOSS [training: 0.06223232870910479 | validation: 0.054806160418982446]
	TIME [epoch: 8.44 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0714072414572055		[learning rate: 0.00014959]
	Learning Rate: 0.000149587
	LOSS [training: 0.0714072414572055 | validation: 0.08323404548525354]
	TIME [epoch: 8.42 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07056064227329398		[learning rate: 0.00014904]
	Learning Rate: 0.000149044
	LOSS [training: 0.07056064227329398 | validation: 0.07109047686592787]
	TIME [epoch: 8.45 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06597631251885212		[learning rate: 0.0001485]
	Learning Rate: 0.000148504
	LOSS [training: 0.06597631251885212 | validation: 0.06468528076789914]
	TIME [epoch: 8.43 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07154839456714954		[learning rate: 0.00014796]
	Learning Rate: 0.000147965
	LOSS [training: 0.07154839456714954 | validation: 0.07666707539608901]
	TIME [epoch: 8.43 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0679834489068461		[learning rate: 0.00014743]
	Learning Rate: 0.000147428
	LOSS [training: 0.0679834489068461 | validation: 0.05976510709298199]
	TIME [epoch: 8.43 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05724488799088118		[learning rate: 0.00014689]
	Learning Rate: 0.000146893
	LOSS [training: 0.05724488799088118 | validation: 0.062278834220626744]
	TIME [epoch: 8.45 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015224170455874		[learning rate: 0.00014636]
	Learning Rate: 0.00014636
	LOSS [training: 0.06015224170455874 | validation: 0.06328103395216321]
	TIME [epoch: 8.43 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06560702825519873		[learning rate: 0.00014583]
	Learning Rate: 0.000145828
	LOSS [training: 0.06560702825519873 | validation: 0.08092991740465033]
	TIME [epoch: 8.42 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07246938302291828		[learning rate: 0.0001453]
	Learning Rate: 0.000145299
	LOSS [training: 0.07246938302291828 | validation: 0.06992214389742982]
	TIME [epoch: 8.45 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07036514060095474		[learning rate: 0.00014477]
	Learning Rate: 0.000144772
	LOSS [training: 0.07036514060095474 | validation: 0.062278517882649605]
	TIME [epoch: 8.43 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06905641206762979		[learning rate: 0.00014425]
	Learning Rate: 0.000144247
	LOSS [training: 0.06905641206762979 | validation: 0.06271330606491675]
	TIME [epoch: 8.42 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06421634901748471		[learning rate: 0.00014372]
	Learning Rate: 0.000143723
	LOSS [training: 0.06421634901748471 | validation: 0.05882573384977743]
	TIME [epoch: 8.43 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06061842527981408		[learning rate: 0.0001432]
	Learning Rate: 0.000143201
	LOSS [training: 0.06061842527981408 | validation: 0.0599334389486899]
	TIME [epoch: 8.45 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05730738262159578		[learning rate: 0.00014268]
	Learning Rate: 0.000142682
	LOSS [training: 0.05730738262159578 | validation: 0.06262665520127944]
	TIME [epoch: 8.43 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06971937719121155		[learning rate: 0.00014216]
	Learning Rate: 0.000142164
	LOSS [training: 0.06971937719121155 | validation: 0.06500092570623184]
	TIME [epoch: 8.43 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05886811643959914		[learning rate: 0.00014165]
	Learning Rate: 0.000141648
	LOSS [training: 0.05886811643959914 | validation: 0.08358554815442398]
	TIME [epoch: 8.44 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06849067237758247		[learning rate: 0.00014113]
	Learning Rate: 0.000141134
	LOSS [training: 0.06849067237758247 | validation: 0.06011539637188196]
	TIME [epoch: 8.44 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06650761255760328		[learning rate: 0.00014062]
	Learning Rate: 0.000140622
	LOSS [training: 0.06650761255760328 | validation: 0.06131630991363458]
	TIME [epoch: 8.43 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06466169371138289		[learning rate: 0.00014011]
	Learning Rate: 0.000140112
	LOSS [training: 0.06466169371138289 | validation: 0.07524131412299745]
	TIME [epoch: 8.44 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06855498349189872		[learning rate: 0.0001396]
	Learning Rate: 0.000139603
	LOSS [training: 0.06855498349189872 | validation: 0.07419561974935703]
	TIME [epoch: 8.45 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06719193290555048		[learning rate: 0.0001391]
	Learning Rate: 0.000139096
	LOSS [training: 0.06719193290555048 | validation: 0.07597143551586603]
	TIME [epoch: 8.43 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06272634731150716		[learning rate: 0.00013859]
	Learning Rate: 0.000138592
	LOSS [training: 0.06272634731150716 | validation: 0.06483688498527931]
	TIME [epoch: 8.42 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096300203732421		[learning rate: 0.00013809]
	Learning Rate: 0.000138089
	LOSS [training: 0.06096300203732421 | validation: 0.06589603165749044]
	TIME [epoch: 8.44 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06096661451935752		[learning rate: 0.00013759]
	Learning Rate: 0.000137587
	LOSS [training: 0.06096661451935752 | validation: 0.05589733124852079]
	TIME [epoch: 8.45 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06726699528850075		[learning rate: 0.00013709]
	Learning Rate: 0.000137088
	LOSS [training: 0.06726699528850075 | validation: 0.07343387974779311]
	TIME [epoch: 8.43 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07187665840599367		[learning rate: 0.00013659]
	Learning Rate: 0.000136591
	LOSS [training: 0.07187665840599367 | validation: 0.07787842998504015]
	TIME [epoch: 8.42 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05946030516006331		[learning rate: 0.00013609]
	Learning Rate: 0.000136095
	LOSS [training: 0.05946030516006331 | validation: 0.07216127285555755]
	TIME [epoch: 8.46 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07096839322885709		[learning rate: 0.0001356]
	Learning Rate: 0.000135601
	LOSS [training: 0.07096839322885709 | validation: 0.061965756535177705]
	TIME [epoch: 8.44 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06298462741432768		[learning rate: 0.00013511]
	Learning Rate: 0.000135109
	LOSS [training: 0.06298462741432768 | validation: 0.07234594136248813]
	TIME [epoch: 8.44 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06309257249657593		[learning rate: 0.00013462]
	Learning Rate: 0.000134619
	LOSS [training: 0.06309257249657593 | validation: 0.06961272650831304]
	TIME [epoch: 8.43 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05288403310477243		[learning rate: 0.00013413]
	Learning Rate: 0.00013413
	LOSS [training: 0.05288403310477243 | validation: 0.059659983625503024]
	TIME [epoch: 8.46 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06393469905614833		[learning rate: 0.00013364]
	Learning Rate: 0.000133643
	LOSS [training: 0.06393469905614833 | validation: 0.061575887967435024]
	TIME [epoch: 8.43 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06491160777735303		[learning rate: 0.00013316]
	Learning Rate: 0.000133158
	LOSS [training: 0.06491160777735303 | validation: 0.06030510490425959]
	TIME [epoch: 8.43 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06054333654500048		[learning rate: 0.00013268]
	Learning Rate: 0.000132675
	LOSS [training: 0.06054333654500048 | validation: 0.06416360031462837]
	TIME [epoch: 8.45 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06320509180909159		[learning rate: 0.00013219]
	Learning Rate: 0.000132194
	LOSS [training: 0.06320509180909159 | validation: 0.06514757925877966]
	TIME [epoch: 8.43 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05501805837221446		[learning rate: 0.00013171]
	Learning Rate: 0.000131714
	LOSS [training: 0.05501805837221446 | validation: 0.07320732821579659]
	TIME [epoch: 8.43 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07154022238413422		[learning rate: 0.00013124]
	Learning Rate: 0.000131236
	LOSS [training: 0.07154022238413422 | validation: 0.061119559090200344]
	TIME [epoch: 8.42 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06594859152163503		[learning rate: 0.00013076]
	Learning Rate: 0.00013076
	LOSS [training: 0.06594859152163503 | validation: 0.058030910168577234]
	TIME [epoch: 8.45 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06757581766341704		[learning rate: 0.00013029]
	Learning Rate: 0.000130285
	LOSS [training: 0.06757581766341704 | validation: 0.060150475888123583]
	TIME [epoch: 8.42 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05877810963267051		[learning rate: 0.00012981]
	Learning Rate: 0.000129812
	LOSS [training: 0.05877810963267051 | validation: 0.060416610246819685]
	TIME [epoch: 8.43 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06267212004542204		[learning rate: 0.00012934]
	Learning Rate: 0.000129341
	LOSS [training: 0.06267212004542204 | validation: 0.06071422599169983]
	TIME [epoch: 8.44 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05386261339008439		[learning rate: 0.00012887]
	Learning Rate: 0.000128872
	LOSS [training: 0.05386261339008439 | validation: 0.05911145597510398]
	TIME [epoch: 8.43 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05339040014373294		[learning rate: 0.0001284]
	Learning Rate: 0.000128404
	LOSS [training: 0.05339040014373294 | validation: 0.0501115450109913]
	TIME [epoch: 8.43 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06237081394306262		[learning rate: 0.00012794]
	Learning Rate: 0.000127938
	LOSS [training: 0.06237081394306262 | validation: 0.06519148450816788]
	TIME [epoch: 8.42 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07183391591203504		[learning rate: 0.00012747]
	Learning Rate: 0.000127474
	LOSS [training: 0.07183391591203504 | validation: 0.06819501658607265]
	TIME [epoch: 8.45 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055726077742019445		[learning rate: 0.00012701]
	Learning Rate: 0.000127011
	LOSS [training: 0.055726077742019445 | validation: 0.07420265848697266]
	TIME [epoch: 8.42 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06074534567365628		[learning rate: 0.00012655]
	Learning Rate: 0.00012655
	LOSS [training: 0.06074534567365628 | validation: 0.0596430448728716]
	TIME [epoch: 8.42 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06629441667107962		[learning rate: 0.00012609]
	Learning Rate: 0.000126091
	LOSS [training: 0.06629441667107962 | validation: 0.06415722374594267]
	TIME [epoch: 8.43 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060602191483418014		[learning rate: 0.00012563]
	Learning Rate: 0.000125633
	LOSS [training: 0.060602191483418014 | validation: 0.06325921894968695]
	TIME [epoch: 8.44 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056161015179409746		[learning rate: 0.00012518]
	Learning Rate: 0.000125178
	LOSS [training: 0.056161015179409746 | validation: 0.06620707721800073]
	TIME [epoch: 8.42 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060395800614556815		[learning rate: 0.00012472]
	Learning Rate: 0.000124723
	LOSS [training: 0.060395800614556815 | validation: 0.07196522391920762]
	TIME [epoch: 8.42 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053887966647762055		[learning rate: 0.00012427]
	Learning Rate: 0.000124271
	LOSS [training: 0.053887966647762055 | validation: 0.05888875785583275]
	TIME [epoch: 8.44 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06231679937769358		[learning rate: 0.00012382]
	Learning Rate: 0.00012382
	LOSS [training: 0.06231679937769358 | validation: 0.057763871229282095]
	TIME [epoch: 8.42 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06035710702818923		[learning rate: 0.00012337]
	Learning Rate: 0.00012337
	LOSS [training: 0.06035710702818923 | validation: 0.06436891651765099]
	TIME [epoch: 8.41 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054963392346975795		[learning rate: 0.00012292]
	Learning Rate: 0.000122923
	LOSS [training: 0.054963392346975795 | validation: 0.05671156218863795]
	TIME [epoch: 8.42 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06321917457630175		[learning rate: 0.00012248]
	Learning Rate: 0.000122476
	LOSS [training: 0.06321917457630175 | validation: 0.061368760386539614]
	TIME [epoch: 8.44 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06497772224038004		[learning rate: 0.00012203]
	Learning Rate: 0.000122032
	LOSS [training: 0.06497772224038004 | validation: 0.05778264580755546]
	TIME [epoch: 8.42 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057615342871560185		[learning rate: 0.00012159]
	Learning Rate: 0.000121589
	LOSS [training: 0.057615342871560185 | validation: 0.06773879298859303]
	TIME [epoch: 8.43 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06678036381440017		[learning rate: 0.00012115]
	Learning Rate: 0.000121148
	LOSS [training: 0.06678036381440017 | validation: 0.0770043979050444]
	TIME [epoch: 8.44 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06407883569321533		[learning rate: 0.00012071]
	Learning Rate: 0.000120708
	LOSS [training: 0.06407883569321533 | validation: 0.06302724276781697]
	TIME [epoch: 8.42 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05436611653593215		[learning rate: 0.00012027]
	Learning Rate: 0.00012027
	LOSS [training: 0.05436611653593215 | validation: 0.06221588589334445]
	TIME [epoch: 8.42 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06595661822522944		[learning rate: 0.00011983]
	Learning Rate: 0.000119834
	LOSS [training: 0.06595661822522944 | validation: 0.05941506153674615]
	TIME [epoch: 8.42 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06487810150729874		[learning rate: 0.0001194]
	Learning Rate: 0.000119399
	LOSS [training: 0.06487810150729874 | validation: 0.060124086004371496]
	TIME [epoch: 8.44 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05664172491926804		[learning rate: 0.00011897]
	Learning Rate: 0.000118966
	LOSS [training: 0.05664172491926804 | validation: 0.05031518711027326]
	TIME [epoch: 8.42 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05471391125415063		[learning rate: 0.00011853]
	Learning Rate: 0.000118534
	LOSS [training: 0.05471391125415063 | validation: 0.06967745167234196]
	TIME [epoch: 8.44 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05927948281783522		[learning rate: 0.0001181]
	Learning Rate: 0.000118104
	LOSS [training: 0.05927948281783522 | validation: 0.06547569929470819]
	TIME [epoch: 8.43 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0632892329974234		[learning rate: 0.00011767]
	Learning Rate: 0.000117675
	LOSS [training: 0.0632892329974234 | validation: 0.06989070880877758]
	TIME [epoch: 8.43 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058616673612726336		[learning rate: 0.00011725]
	Learning Rate: 0.000117248
	LOSS [training: 0.058616673612726336 | validation: 0.05496962917888746]
	TIME [epoch: 8.42 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062159948616912784		[learning rate: 0.00011682]
	Learning Rate: 0.000116822
	LOSS [training: 0.062159948616912784 | validation: 0.06359329168355445]
	TIME [epoch: 8.42 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654183242178711		[learning rate: 0.0001164]
	Learning Rate: 0.000116398
	LOSS [training: 0.0654183242178711 | validation: 0.07489676055337945]
	TIME [epoch: 8.45 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05652556945103339		[learning rate: 0.00011598]
	Learning Rate: 0.000115976
	LOSS [training: 0.05652556945103339 | validation: 0.06746703310045551]
	TIME [epoch: 8.43 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06752557332009892		[learning rate: 0.00011556]
	Learning Rate: 0.000115555
	LOSS [training: 0.06752557332009892 | validation: 0.06852140325897296]
	TIME [epoch: 8.42 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062092266502966585		[learning rate: 0.00011514]
	Learning Rate: 0.000115136
	LOSS [training: 0.062092266502966585 | validation: 0.0562375566273169]
	TIME [epoch: 8.43 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05065666033092053		[learning rate: 0.00011472]
	Learning Rate: 0.000114718
	LOSS [training: 0.05065666033092053 | validation: 0.06145405452701858]
	TIME [epoch: 8.43 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06693763218967545		[learning rate: 0.0001143]
	Learning Rate: 0.000114302
	LOSS [training: 0.06693763218967545 | validation: 0.06415735973922816]
	TIME [epoch: 8.42 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05751594900843463		[learning rate: 0.00011389]
	Learning Rate: 0.000113887
	LOSS [training: 0.05751594900843463 | validation: 0.05914704968800849]
	TIME [epoch: 8.42 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05796130881533196		[learning rate: 0.00011347]
	Learning Rate: 0.000113474
	LOSS [training: 0.05796130881533196 | validation: 0.07230916462486876]
	TIME [epoch: 8.44 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058191947442372216		[learning rate: 0.00011306]
	Learning Rate: 0.000113062
	LOSS [training: 0.058191947442372216 | validation: 0.06304199024461082]
	TIME [epoch: 8.42 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05524650036245904		[learning rate: 0.00011265]
	Learning Rate: 0.000112651
	LOSS [training: 0.05524650036245904 | validation: 0.06867216268537318]
	TIME [epoch: 8.43 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05572350140957203		[learning rate: 0.00011224]
	Learning Rate: 0.000112243
	LOSS [training: 0.05572350140957203 | validation: 0.06160849809721515]
	TIME [epoch: 8.43 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05661152918105172		[learning rate: 0.00011184]
	Learning Rate: 0.000111835
	LOSS [training: 0.05661152918105172 | validation: 0.061105618862]
	TIME [epoch: 8.44 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052843983815675954		[learning rate: 0.00011143]
	Learning Rate: 0.000111429
	LOSS [training: 0.052843983815675954 | validation: 0.06780089991121695]
	TIME [epoch: 8.43 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06005903751943331		[learning rate: 0.00011103]
	Learning Rate: 0.000111025
	LOSS [training: 0.06005903751943331 | validation: 0.06129267883444323]
	TIME [epoch: 8.43 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06269370117470506		[learning rate: 0.00011062]
	Learning Rate: 0.000110622
	LOSS [training: 0.06269370117470506 | validation: 0.05873410404336931]
	TIME [epoch: 8.44 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0582855668054021		[learning rate: 0.00011022]
	Learning Rate: 0.000110221
	LOSS [training: 0.0582855668054021 | validation: 0.059451732666059784]
	TIME [epoch: 8.43 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06144626098202448		[learning rate: 0.00010982]
	Learning Rate: 0.000109821
	LOSS [training: 0.06144626098202448 | validation: 0.06330317367692953]
	TIME [epoch: 8.43 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06857694373553205		[learning rate: 0.00010942]
	Learning Rate: 0.000109422
	LOSS [training: 0.06857694373553205 | validation: 0.07891289963669204]
	TIME [epoch: 8.43 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.07350928104425719		[learning rate: 0.00010903]
	Learning Rate: 0.000109025
	LOSS [training: 0.07350928104425719 | validation: 0.061016464644540344]
	TIME [epoch: 8.44 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06507458646340002		[learning rate: 0.00010863]
	Learning Rate: 0.000108629
	LOSS [training: 0.06507458646340002 | validation: 0.07059885169802567]
	TIME [epoch: 8.43 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549798516944416		[learning rate: 0.00010824]
	Learning Rate: 0.000108235
	LOSS [training: 0.0549798516944416 | validation: 0.06307986495038057]
	TIME [epoch: 8.43 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06145829767639273		[learning rate: 0.00010784]
	Learning Rate: 0.000107842
	LOSS [training: 0.06145829767639273 | validation: 0.08247215842156132]
	TIME [epoch: 8.45 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06529821698880697		[learning rate: 0.00010745]
	Learning Rate: 0.000107451
	LOSS [training: 0.06529821698880697 | validation: 0.0524070442217153]
	TIME [epoch: 8.43 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0625036532947133		[learning rate: 0.00010706]
	Learning Rate: 0.000107061
	LOSS [training: 0.0625036532947133 | validation: 0.05703111722572319]
	TIME [epoch: 8.42 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06430579086992397		[learning rate: 0.00010667]
	Learning Rate: 0.000106673
	LOSS [training: 0.06430579086992397 | validation: 0.061602900054961315]
	TIME [epoch: 8.42 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05752241782056833		[learning rate: 0.00010629]
	Learning Rate: 0.000106285
	LOSS [training: 0.05752241782056833 | validation: 0.06543061201228506]
	TIME [epoch: 8.45 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06137471245663154		[learning rate: 0.0001059]
	Learning Rate: 0.0001059
	LOSS [training: 0.06137471245663154 | validation: 0.04978680442720941]
	TIME [epoch: 8.43 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06452993426549854		[learning rate: 0.00010552]
	Learning Rate: 0.000105515
	LOSS [training: 0.06452993426549854 | validation: 0.059334485161730094]
	TIME [epoch: 8.43 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056519150344118994		[learning rate: 0.00010513]
	Learning Rate: 0.000105132
	LOSS [training: 0.056519150344118994 | validation: 0.05896133376281919]
	TIME [epoch: 8.44 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06325916844521737		[learning rate: 0.00010475]
	Learning Rate: 0.000104751
	LOSS [training: 0.06325916844521737 | validation: 0.06241338380242334]
	TIME [epoch: 8.44 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06033856027563037		[learning rate: 0.00010437]
	Learning Rate: 0.000104371
	LOSS [training: 0.06033856027563037 | validation: 0.05572404282320353]
	TIME [epoch: 8.42 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05680456392951977		[learning rate: 0.00010399]
	Learning Rate: 0.000103992
	LOSS [training: 0.05680456392951977 | validation: 0.06661515936108502]
	TIME [epoch: 8.42 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05917887941039707		[learning rate: 0.00010361]
	Learning Rate: 0.000103615
	LOSS [training: 0.05917887941039707 | validation: 0.05365350082870413]
	TIME [epoch: 8.44 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05787926791529478		[learning rate: 0.00010324]
	Learning Rate: 0.000103239
	LOSS [training: 0.05787926791529478 | validation: 0.05546561869332418]
	TIME [epoch: 8.43 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648287586201105		[learning rate: 0.00010286]
	Learning Rate: 0.000102864
	LOSS [training: 0.0648287586201105 | validation: 0.06042006019446319]
	TIME [epoch: 8.42 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062160174726327636		[learning rate: 0.00010249]
	Learning Rate: 0.000102491
	LOSS [training: 0.062160174726327636 | validation: 0.06504977805224083]
	TIME [epoch: 8.44 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06395586175697457		[learning rate: 0.00010212]
	Learning Rate: 0.000102119
	LOSS [training: 0.06395586175697457 | validation: 0.05614438028073949]
	TIME [epoch: 8.44 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06152039693199242		[learning rate: 0.00010175]
	Learning Rate: 0.000101748
	LOSS [training: 0.06152039693199242 | validation: 0.04817601287662185]
	TIME [epoch: 8.42 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0555905082928555		[learning rate: 0.00010138]
	Learning Rate: 0.000101379
	LOSS [training: 0.0555905082928555 | validation: 0.05936365414859032]
	TIME [epoch: 8.42 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05405947298200884		[learning rate: 0.00010101]
	Learning Rate: 0.000101011
	LOSS [training: 0.05405947298200884 | validation: 0.05862445499242199]
	TIME [epoch: 8.45 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05772994671319133		[learning rate: 0.00010064]
	Learning Rate: 0.000100644
	LOSS [training: 0.05772994671319133 | validation: 0.06007787360789176]
	TIME [epoch: 8.43 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0594260966137974		[learning rate: 0.00010028]
	Learning Rate: 0.000100279
	LOSS [training: 0.0594260966137974 | validation: 0.05363351830507315]
	TIME [epoch: 8.42 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060024182639961086		[learning rate: 9.9915e-05]
	Learning Rate: 9.99152e-05
	LOSS [training: 0.060024182639961086 | validation: 0.06307743316036737]
	TIME [epoch: 8.43 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05381410309265509		[learning rate: 9.9553e-05]
	Learning Rate: 9.95526e-05
	LOSS [training: 0.05381410309265509 | validation: 0.062192775100194955]
	TIME [epoch: 8.44 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06102891858171278		[learning rate: 9.9191e-05]
	Learning Rate: 9.91913e-05
	LOSS [training: 0.06102891858171278 | validation: 0.06779139937600967]
	TIME [epoch: 8.42 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629255054358959		[learning rate: 9.8831e-05]
	Learning Rate: 9.88314e-05
	LOSS [training: 0.0629255054358959 | validation: 0.057572911873567334]
	TIME [epoch: 8.43 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060972969525668205		[learning rate: 9.8473e-05]
	Learning Rate: 9.84727e-05
	LOSS [training: 0.060972969525668205 | validation: 0.05575433672933404]
	TIME [epoch: 8.44 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056927939388472425		[learning rate: 9.8115e-05]
	Learning Rate: 9.81153e-05
	LOSS [training: 0.056927939388472425 | validation: 0.06319605959220694]
	TIME [epoch: 8.43 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05754093453039055		[learning rate: 9.7759e-05]
	Learning Rate: 9.77592e-05
	LOSS [training: 0.05754093453039055 | validation: 0.05344467593019007]
	TIME [epoch: 8.42 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054522837142688865		[learning rate: 9.7404e-05]
	Learning Rate: 9.74045e-05
	LOSS [training: 0.054522837142688865 | validation: 0.06609698981198983]
	TIME [epoch: 8.43 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.070681113907088		[learning rate: 9.7051e-05]
	Learning Rate: 9.7051e-05
	LOSS [training: 0.070681113907088 | validation: 0.06294156156097332]
	TIME [epoch: 8.45 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05940644585569497		[learning rate: 9.6699e-05]
	Learning Rate: 9.66988e-05
	LOSS [training: 0.05940644585569497 | validation: 0.056065201489589586]
	TIME [epoch: 8.43 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06217439549415717		[learning rate: 9.6348e-05]
	Learning Rate: 9.63479e-05
	LOSS [training: 0.06217439549415717 | validation: 0.06310706317013465]
	TIME [epoch: 8.42 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056619901883008875		[learning rate: 9.5998e-05]
	Learning Rate: 9.59982e-05
	LOSS [training: 0.056619901883008875 | validation: 0.05547797071686063]
	TIME [epoch: 8.43 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061009412143076994		[learning rate: 9.565e-05]
	Learning Rate: 9.56499e-05
	LOSS [training: 0.061009412143076994 | validation: 0.07158220277254071]
	TIME [epoch: 8.43 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057509656393980965		[learning rate: 9.5303e-05]
	Learning Rate: 9.53027e-05
	LOSS [training: 0.057509656393980965 | validation: 0.049091140886225286]
	TIME [epoch: 8.43 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05925570236760931		[learning rate: 9.4957e-05]
	Learning Rate: 9.49569e-05
	LOSS [training: 0.05925570236760931 | validation: 0.062485070855989096]
	TIME [epoch: 8.42 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06047097271428664		[learning rate: 9.4612e-05]
	Learning Rate: 9.46122e-05
	LOSS [training: 0.06047097271428664 | validation: 0.05600382811452226]
	TIME [epoch: 8.44 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0645094436946275		[learning rate: 9.4269e-05]
	Learning Rate: 9.42689e-05
	LOSS [training: 0.0645094436946275 | validation: 0.0636513787081713]
	TIME [epoch: 8.43 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06772563640365686		[learning rate: 9.3927e-05]
	Learning Rate: 9.39268e-05
	LOSS [training: 0.06772563640365686 | validation: 0.05986865666025282]
	TIME [epoch: 8.43 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05419174474058279		[learning rate: 9.3586e-05]
	Learning Rate: 9.35859e-05
	LOSS [training: 0.05419174474058279 | validation: 0.05508893120491282]
	TIME [epoch: 8.43 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05788874090466256		[learning rate: 9.3246e-05]
	Learning Rate: 9.32463e-05
	LOSS [training: 0.05788874090466256 | validation: 0.05606316334193252]
	TIME [epoch: 8.44 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05711313145356395		[learning rate: 9.2908e-05]
	Learning Rate: 9.29079e-05
	LOSS [training: 0.05711313145356395 | validation: 0.056354946712499764]
	TIME [epoch: 8.43 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05651315686386812		[learning rate: 9.2571e-05]
	Learning Rate: 9.25707e-05
	LOSS [training: 0.05651315686386812 | validation: 0.061708148670506426]
	TIME [epoch: 8.43 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06534772060008134		[learning rate: 9.2235e-05]
	Learning Rate: 9.22348e-05
	LOSS [training: 0.06534772060008134 | validation: 0.05222670381592173]
	TIME [epoch: 8.44 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0629102288451114		[learning rate: 9.19e-05]
	Learning Rate: 9.19001e-05
	LOSS [training: 0.0629102288451114 | validation: 0.06594177074303617]
	TIME [epoch: 8.42 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0662798617421851		[learning rate: 9.1567e-05]
	Learning Rate: 9.15665e-05
	LOSS [training: 0.0662798617421851 | validation: 0.053798625779294944]
	TIME [epoch: 8.42 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062421323306049034		[learning rate: 9.1234e-05]
	Learning Rate: 9.12343e-05
	LOSS [training: 0.062421323306049034 | validation: 0.056312803401626726]
	TIME [epoch: 8.42 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05714177832220778		[learning rate: 9.0903e-05]
	Learning Rate: 9.09031e-05
	LOSS [training: 0.05714177832220778 | validation: 0.05918803648502095]
	TIME [epoch: 8.45 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0582000178804402		[learning rate: 9.0573e-05]
	Learning Rate: 9.05733e-05
	LOSS [training: 0.0582000178804402 | validation: 0.06641178132800007]
	TIME [epoch: 8.43 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105220430385785		[learning rate: 9.0245e-05]
	Learning Rate: 9.02446e-05
	LOSS [training: 0.06105220430385785 | validation: 0.06473252099605362]
	TIME [epoch: 8.43 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06050176252829385		[learning rate: 8.9917e-05]
	Learning Rate: 8.99171e-05
	LOSS [training: 0.06050176252829385 | validation: 0.060294205953995185]
	TIME [epoch: 8.43 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06330869776013384		[learning rate: 8.9591e-05]
	Learning Rate: 8.95908e-05
	LOSS [training: 0.06330869776013384 | validation: 0.06362619394028354]
	TIME [epoch: 8.42 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05862084601065365		[learning rate: 8.9266e-05]
	Learning Rate: 8.92656e-05
	LOSS [training: 0.05862084601065365 | validation: 0.05962096403708575]
	TIME [epoch: 8.42 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06458562142134577		[learning rate: 8.8942e-05]
	Learning Rate: 8.89417e-05
	LOSS [training: 0.06458562142134577 | validation: 0.05970536751192812]
	TIME [epoch: 8.42 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06223712229188143		[learning rate: 8.8619e-05]
	Learning Rate: 8.86189e-05
	LOSS [training: 0.06223712229188143 | validation: 0.0717789811508206]
	TIME [epoch: 8.44 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06312357392302591		[learning rate: 8.8297e-05]
	Learning Rate: 8.82973e-05
	LOSS [training: 0.06312357392302591 | validation: 0.06007840202244386]
	TIME [epoch: 8.41 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055832350323368266		[learning rate: 8.7977e-05]
	Learning Rate: 8.79769e-05
	LOSS [training: 0.055832350323368266 | validation: 0.056557054687713854]
	TIME [epoch: 8.42 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06102454040988388		[learning rate: 8.7658e-05]
	Learning Rate: 8.76576e-05
	LOSS [training: 0.06102454040988388 | validation: 0.057689910340174885]
	TIME [epoch: 8.43 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05602242628400781		[learning rate: 8.7339e-05]
	Learning Rate: 8.73395e-05
	LOSS [training: 0.05602242628400781 | validation: 0.05695671573612421]
	TIME [epoch: 8.44 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0643063803848847		[learning rate: 8.7023e-05]
	Learning Rate: 8.70225e-05
	LOSS [training: 0.0643063803848847 | validation: 0.04080925606471993]
	TIME [epoch: 8.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1405.pth
	Model improved!!!
EPOCH 1406/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06020382902689821		[learning rate: 8.6707e-05]
	Learning Rate: 8.67067e-05
	LOSS [training: 0.06020382902689821 | validation: 0.05600461822516178]
	TIME [epoch: 8.42 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056620159690121255		[learning rate: 8.6392e-05]
	Learning Rate: 8.63921e-05
	LOSS [training: 0.056620159690121255 | validation: 0.04929212033225487]
	TIME [epoch: 8.45 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06163413425515224		[learning rate: 8.6079e-05]
	Learning Rate: 8.60785e-05
	LOSS [training: 0.06163413425515224 | validation: 0.06269725926393357]
	TIME [epoch: 8.42 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05752000303489633		[learning rate: 8.5766e-05]
	Learning Rate: 8.57661e-05
	LOSS [training: 0.05752000303489633 | validation: 0.059163740562402374]
	TIME [epoch: 8.42 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05095279112026646		[learning rate: 8.5455e-05]
	Learning Rate: 8.54549e-05
	LOSS [training: 0.05095279112026646 | validation: 0.0566237744554252]
	TIME [epoch: 8.43 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0631005743118499		[learning rate: 8.5145e-05]
	Learning Rate: 8.51448e-05
	LOSS [training: 0.0631005743118499 | validation: 0.07129053240126398]
	TIME [epoch: 8.44 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06385981567625167		[learning rate: 8.4836e-05]
	Learning Rate: 8.48358e-05
	LOSS [training: 0.06385981567625167 | validation: 0.05823494240432911]
	TIME [epoch: 8.42 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408005224042752		[learning rate: 8.4528e-05]
	Learning Rate: 8.45279e-05
	LOSS [training: 0.06408005224042752 | validation: 0.07194353196929233]
	TIME [epoch: 8.42 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060804901825439225		[learning rate: 8.4221e-05]
	Learning Rate: 8.42211e-05
	LOSS [training: 0.060804901825439225 | validation: 0.06420507095859042]
	TIME [epoch: 8.43 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05976941765707815		[learning rate: 8.3916e-05]
	Learning Rate: 8.39155e-05
	LOSS [training: 0.05976941765707815 | validation: 0.0578796732155096]
	TIME [epoch: 8.42 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05637576574796703		[learning rate: 8.3611e-05]
	Learning Rate: 8.3611e-05
	LOSS [training: 0.05637576574796703 | validation: 0.0609511567565148]
	TIME [epoch: 8.42 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06459111574813842		[learning rate: 8.3308e-05]
	Learning Rate: 8.33075e-05
	LOSS [training: 0.06459111574813842 | validation: 0.06242876904377438]
	TIME [epoch: 8.41 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0663844820557213		[learning rate: 8.3005e-05]
	Learning Rate: 8.30052e-05
	LOSS [training: 0.0663844820557213 | validation: 0.07708137445112398]
	TIME [epoch: 8.44 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06134207439558816		[learning rate: 8.2704e-05]
	Learning Rate: 8.2704e-05
	LOSS [training: 0.06134207439558816 | validation: 0.0708897112569934]
	TIME [epoch: 8.41 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054016121341160586		[learning rate: 8.2404e-05]
	Learning Rate: 8.24038e-05
	LOSS [training: 0.054016121341160586 | validation: 0.0629627832532853]
	TIME [epoch: 8.42 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054711015362149985		[learning rate: 8.2105e-05]
	Learning Rate: 8.21048e-05
	LOSS [training: 0.054711015362149985 | validation: 0.0626002433549885]
	TIME [epoch: 8.44 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06627017949646027		[learning rate: 8.1807e-05]
	Learning Rate: 8.18068e-05
	LOSS [training: 0.06627017949646027 | validation: 0.05891410692942811]
	TIME [epoch: 8.42 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06886961441034842		[learning rate: 8.151e-05]
	Learning Rate: 8.15099e-05
	LOSS [training: 0.06886961441034842 | validation: 0.0635383362065855]
	TIME [epoch: 8.42 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06264830975078459		[learning rate: 8.1214e-05]
	Learning Rate: 8.12142e-05
	LOSS [training: 0.06264830975078459 | validation: 0.06500255478429393]
	TIME [epoch: 8.41 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060664173816946235		[learning rate: 8.0919e-05]
	Learning Rate: 8.09194e-05
	LOSS [training: 0.060664173816946235 | validation: 0.05365797642977914]
	TIME [epoch: 8.45 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059798426403174045		[learning rate: 8.0626e-05]
	Learning Rate: 8.06257e-05
	LOSS [training: 0.059798426403174045 | validation: 0.0590495608158727]
	TIME [epoch: 8.41 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06758740609493655		[learning rate: 8.0333e-05]
	Learning Rate: 8.03331e-05
	LOSS [training: 0.06758740609493655 | validation: 0.06894855575102658]
	TIME [epoch: 8.43 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06441932893419934		[learning rate: 8.0042e-05]
	Learning Rate: 8.00416e-05
	LOSS [training: 0.06441932893419934 | validation: 0.06633235249108725]
	TIME [epoch: 8.43 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051946103719251555		[learning rate: 7.9751e-05]
	Learning Rate: 7.97511e-05
	LOSS [training: 0.051946103719251555 | validation: 0.06188664071751696]
	TIME [epoch: 8.43 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06392933486162024		[learning rate: 7.9462e-05]
	Learning Rate: 7.94617e-05
	LOSS [training: 0.06392933486162024 | validation: 0.06887966817113783]
	TIME [epoch: 8.42 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05707585659316028		[learning rate: 7.9173e-05]
	Learning Rate: 7.91733e-05
	LOSS [training: 0.05707585659316028 | validation: 0.05547623864794084]
	TIME [epoch: 8.41 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05678652023744415		[learning rate: 7.8886e-05]
	Learning Rate: 7.8886e-05
	LOSS [training: 0.05678652023744415 | validation: 0.060950315083226916]
	TIME [epoch: 8.44 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05506247424497666		[learning rate: 7.86e-05]
	Learning Rate: 7.85997e-05
	LOSS [training: 0.05506247424497666 | validation: 0.06292346905837684]
	TIME [epoch: 8.42 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0637153496318992		[learning rate: 7.8315e-05]
	Learning Rate: 7.83145e-05
	LOSS [training: 0.0637153496318992 | validation: 0.06207289766620472]
	TIME [epoch: 8.43 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062484316871156756		[learning rate: 7.803e-05]
	Learning Rate: 7.80303e-05
	LOSS [training: 0.062484316871156756 | validation: 0.058479100681822285]
	TIME [epoch: 8.44 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06009119672657069		[learning rate: 7.7747e-05]
	Learning Rate: 7.77471e-05
	LOSS [training: 0.06009119672657069 | validation: 0.07305034834366814]
	TIME [epoch: 8.43 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06574629300660753		[learning rate: 7.7465e-05]
	Learning Rate: 7.7465e-05
	LOSS [training: 0.06574629300660753 | validation: 0.07248447512093166]
	TIME [epoch: 8.43 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0654202725297959		[learning rate: 7.7184e-05]
	Learning Rate: 7.71838e-05
	LOSS [training: 0.0654202725297959 | validation: 0.06497286388688793]
	TIME [epoch: 8.41 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060114461503143035		[learning rate: 7.6904e-05]
	Learning Rate: 7.69037e-05
	LOSS [training: 0.060114461503143035 | validation: 0.0611628417086214]
	TIME [epoch: 8.44 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056723394629609715		[learning rate: 7.6625e-05]
	Learning Rate: 7.66246e-05
	LOSS [training: 0.056723394629609715 | validation: 0.07168967272446015]
	TIME [epoch: 8.42 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0648340261437946		[learning rate: 7.6347e-05]
	Learning Rate: 7.63466e-05
	LOSS [training: 0.0648340261437946 | validation: 0.07353842360529479]
	TIME [epoch: 8.43 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06060009269415939		[learning rate: 7.607e-05]
	Learning Rate: 7.60695e-05
	LOSS [training: 0.06060009269415939 | validation: 0.05312233438006708]
	TIME [epoch: 8.42 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060671456893404044		[learning rate: 7.5793e-05]
	Learning Rate: 7.57935e-05
	LOSS [training: 0.060671456893404044 | validation: 0.05708780068137956]
	TIME [epoch: 8.45 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061241720223746056		[learning rate: 7.5518e-05]
	Learning Rate: 7.55184e-05
	LOSS [training: 0.061241720223746056 | validation: 0.06274475865896742]
	TIME [epoch: 8.43 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06216686792847177		[learning rate: 7.5244e-05]
	Learning Rate: 7.52443e-05
	LOSS [training: 0.06216686792847177 | validation: 0.050297744006900305]
	TIME [epoch: 8.42 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060529695804046144		[learning rate: 7.4971e-05]
	Learning Rate: 7.49712e-05
	LOSS [training: 0.060529695804046144 | validation: 0.05778550562063601]
	TIME [epoch: 8.44 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05717026106182319		[learning rate: 7.4699e-05]
	Learning Rate: 7.46992e-05
	LOSS [training: 0.05717026106182319 | validation: 0.049206229740375626]
	TIME [epoch: 8.42 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060463033137337904		[learning rate: 7.4428e-05]
	Learning Rate: 7.44281e-05
	LOSS [training: 0.060463033137337904 | validation: 0.06817640914388394]
	TIME [epoch: 8.43 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06087680877955888		[learning rate: 7.4158e-05]
	Learning Rate: 7.4158e-05
	LOSS [training: 0.06087680877955888 | validation: 0.05525521339512808]
	TIME [epoch: 8.41 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05962333708589139		[learning rate: 7.3889e-05]
	Learning Rate: 7.38889e-05
	LOSS [training: 0.05962333708589139 | validation: 0.050505905045102134]
	TIME [epoch: 8.45 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06606852423411176		[learning rate: 7.3621e-05]
	Learning Rate: 7.36207e-05
	LOSS [training: 0.06606852423411176 | validation: 0.06235716666912769]
	TIME [epoch: 8.42 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057616461892186735		[learning rate: 7.3354e-05]
	Learning Rate: 7.33536e-05
	LOSS [training: 0.057616461892186735 | validation: 0.06434573583500802]
	TIME [epoch: 8.43 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588297249288985		[learning rate: 7.3087e-05]
	Learning Rate: 7.30873e-05
	LOSS [training: 0.05588297249288985 | validation: 0.057689945191045394]
	TIME [epoch: 8.45 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055937356349487134		[learning rate: 7.2822e-05]
	Learning Rate: 7.28221e-05
	LOSS [training: 0.055937356349487134 | validation: 0.0644957507777264]
	TIME [epoch: 8.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056319657158331614		[learning rate: 7.2558e-05]
	Learning Rate: 7.25578e-05
	LOSS [training: 0.056319657158331614 | validation: 0.05687775754134163]
	TIME [epoch: 8.42 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06206647966790511		[learning rate: 7.2295e-05]
	Learning Rate: 7.22945e-05
	LOSS [training: 0.06206647966790511 | validation: 0.07233660481714765]
	TIME [epoch: 8.41 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05321532485724516		[learning rate: 7.2032e-05]
	Learning Rate: 7.20321e-05
	LOSS [training: 0.05321532485724516 | validation: 0.060842521058985605]
	TIME [epoch: 8.45 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054056964745012925		[learning rate: 7.1771e-05]
	Learning Rate: 7.17707e-05
	LOSS [training: 0.054056964745012925 | validation: 0.05588212569940661]
	TIME [epoch: 8.42 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06392825267559801		[learning rate: 7.151e-05]
	Learning Rate: 7.15103e-05
	LOSS [training: 0.06392825267559801 | validation: 0.05987689260202445]
	TIME [epoch: 8.42 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05955814789189697		[learning rate: 7.1251e-05]
	Learning Rate: 7.12508e-05
	LOSS [training: 0.05955814789189697 | validation: 0.04954447215431561]
	TIME [epoch: 8.43 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05383471830182719		[learning rate: 7.0992e-05]
	Learning Rate: 7.09922e-05
	LOSS [training: 0.05383471830182719 | validation: 0.06807792657682676]
	TIME [epoch: 8.44 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061951463359037916		[learning rate: 7.0735e-05]
	Learning Rate: 7.07345e-05
	LOSS [training: 0.061951463359037916 | validation: 0.057008198344548976]
	TIME [epoch: 8.42 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06655724995315244		[learning rate: 7.0478e-05]
	Learning Rate: 7.04778e-05
	LOSS [training: 0.06655724995315244 | validation: 0.05494434247327838]
	TIME [epoch: 8.43 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05004709734981887		[learning rate: 7.0222e-05]
	Learning Rate: 7.02221e-05
	LOSS [training: 0.05004709734981887 | validation: 0.050090556562051886]
	TIME [epoch: 8.44 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0562153683136262		[learning rate: 6.9967e-05]
	Learning Rate: 6.99672e-05
	LOSS [training: 0.0562153683136262 | validation: 0.055136115626854026]
	TIME [epoch: 8.43 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06273007965034176		[learning rate: 6.9713e-05]
	Learning Rate: 6.97133e-05
	LOSS [training: 0.06273007965034176 | validation: 0.05605581688887814]
	TIME [epoch: 8.42 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04995955089410795		[learning rate: 6.946e-05]
	Learning Rate: 6.94603e-05
	LOSS [training: 0.04995955089410795 | validation: 0.05084734806196729]
	TIME [epoch: 8.42 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058977254835696435		[learning rate: 6.9208e-05]
	Learning Rate: 6.92083e-05
	LOSS [training: 0.058977254835696435 | validation: 0.04877358304510861]
	TIME [epoch: 8.45 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05008699098527604		[learning rate: 6.8957e-05]
	Learning Rate: 6.89571e-05
	LOSS [training: 0.05008699098527604 | validation: 0.05874112965563815]
	TIME [epoch: 8.42 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061031843309715526		[learning rate: 6.8707e-05]
	Learning Rate: 6.87068e-05
	LOSS [training: 0.061031843309715526 | validation: 0.05154588906588716]
	TIME [epoch: 8.43 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062436440661128065		[learning rate: 6.8457e-05]
	Learning Rate: 6.84575e-05
	LOSS [training: 0.062436440661128065 | validation: 0.065177785111929]
	TIME [epoch: 8.44 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059420427347357044		[learning rate: 6.8209e-05]
	Learning Rate: 6.82091e-05
	LOSS [training: 0.059420427347357044 | validation: 0.05975109963409892]
	TIME [epoch: 8.43 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06115183519938041		[learning rate: 6.7962e-05]
	Learning Rate: 6.79615e-05
	LOSS [training: 0.06115183519938041 | validation: 0.05133970420462302]
	TIME [epoch: 8.42 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059775883503558405		[learning rate: 6.7715e-05]
	Learning Rate: 6.77149e-05
	LOSS [training: 0.059775883503558405 | validation: 0.05886241025261573]
	TIME [epoch: 8.43 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05693662693151112		[learning rate: 6.7469e-05]
	Learning Rate: 6.74692e-05
	LOSS [training: 0.05693662693151112 | validation: 0.05601933137831577]
	TIME [epoch: 8.44 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289019043222838		[learning rate: 6.7224e-05]
	Learning Rate: 6.72243e-05
	LOSS [training: 0.06289019043222838 | validation: 0.05121401005758712]
	TIME [epoch: 8.43 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059903484234352544		[learning rate: 6.698e-05]
	Learning Rate: 6.69804e-05
	LOSS [training: 0.059903484234352544 | validation: 0.061882339728182]
	TIME [epoch: 8.43 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055432533790296834		[learning rate: 6.6737e-05]
	Learning Rate: 6.67373e-05
	LOSS [training: 0.055432533790296834 | validation: 0.05924876858652848]
	TIME [epoch: 8.44 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060045477444670634		[learning rate: 6.6495e-05]
	Learning Rate: 6.64951e-05
	LOSS [training: 0.060045477444670634 | validation: 0.05840663063861093]
	TIME [epoch: 8.43 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06023915757489863		[learning rate: 6.6254e-05]
	Learning Rate: 6.62538e-05
	LOSS [training: 0.06023915757489863 | validation: 0.060842921274117674]
	TIME [epoch: 8.43 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050955302926751565		[learning rate: 6.6013e-05]
	Learning Rate: 6.60133e-05
	LOSS [training: 0.050955302926751565 | validation: 0.07011492200821107]
	TIME [epoch: 8.42 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059272160513140326		[learning rate: 6.5774e-05]
	Learning Rate: 6.57738e-05
	LOSS [training: 0.059272160513140326 | validation: 0.061755789233814085]
	TIME [epoch: 8.45 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05422716949831646		[learning rate: 6.5535e-05]
	Learning Rate: 6.55351e-05
	LOSS [training: 0.05422716949831646 | validation: 0.048779018201077565]
	TIME [epoch: 8.42 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058371812915155044		[learning rate: 6.5297e-05]
	Learning Rate: 6.52972e-05
	LOSS [training: 0.058371812915155044 | validation: 0.057962272471620196]
	TIME [epoch: 8.43 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0614613484749784		[learning rate: 6.506e-05]
	Learning Rate: 6.50603e-05
	LOSS [training: 0.0614613484749784 | validation: 0.05979403833633942]
	TIME [epoch: 8.44 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06127529470283257		[learning rate: 6.4824e-05]
	Learning Rate: 6.48242e-05
	LOSS [training: 0.06127529470283257 | validation: 0.0669542941304279]
	TIME [epoch: 8.44 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06831583311520234		[learning rate: 6.4589e-05]
	Learning Rate: 6.45889e-05
	LOSS [training: 0.06831583311520234 | validation: 0.07194188973706361]
	TIME [epoch: 8.42 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057282866410684787		[learning rate: 6.4354e-05]
	Learning Rate: 6.43545e-05
	LOSS [training: 0.057282866410684787 | validation: 0.05437510939527947]
	TIME [epoch: 8.42 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058710931152251414		[learning rate: 6.4121e-05]
	Learning Rate: 6.4121e-05
	LOSS [training: 0.058710931152251414 | validation: 0.056743577033969886]
	TIME [epoch: 8.44 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057603646387197616		[learning rate: 6.3888e-05]
	Learning Rate: 6.38883e-05
	LOSS [training: 0.057603646387197616 | validation: 0.050803125848737356]
	TIME [epoch: 8.42 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06179266644249607		[learning rate: 6.3656e-05]
	Learning Rate: 6.36564e-05
	LOSS [training: 0.06179266644249607 | validation: 0.0621335933614807]
	TIME [epoch: 8.42 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061904888231158806		[learning rate: 6.3425e-05]
	Learning Rate: 6.34254e-05
	LOSS [training: 0.061904888231158806 | validation: 0.05749488762857392]
	TIME [epoch: 8.43 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06076536726534308		[learning rate: 6.3195e-05]
	Learning Rate: 6.31952e-05
	LOSS [training: 0.06076536726534308 | validation: 0.05509995131751648]
	TIME [epoch: 8.44 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057057565605653025		[learning rate: 6.2966e-05]
	Learning Rate: 6.29659e-05
	LOSS [training: 0.057057565605653025 | validation: 0.05437924205299939]
	TIME [epoch: 8.42 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0544705819104004		[learning rate: 6.2737e-05]
	Learning Rate: 6.27374e-05
	LOSS [training: 0.0544705819104004 | validation: 0.04975574371172429]
	TIME [epoch: 8.42 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06440938472332916		[learning rate: 6.251e-05]
	Learning Rate: 6.25097e-05
	LOSS [training: 0.06440938472332916 | validation: 0.05595511996551983]
	TIME [epoch: 8.45 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05669219302950314		[learning rate: 6.2283e-05]
	Learning Rate: 6.22828e-05
	LOSS [training: 0.05669219302950314 | validation: 0.05514244260542724]
	TIME [epoch: 8.42 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05792603233174476		[learning rate: 6.2057e-05]
	Learning Rate: 6.20568e-05
	LOSS [training: 0.05792603233174476 | validation: 0.058564823785827155]
	TIME [epoch: 8.43 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05280044440239632		[learning rate: 6.1832e-05]
	Learning Rate: 6.18316e-05
	LOSS [training: 0.05280044440239632 | validation: 0.0580781505773267]
	TIME [epoch: 8.42 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0640084189969101		[learning rate: 6.1607e-05]
	Learning Rate: 6.16072e-05
	LOSS [training: 0.0640084189969101 | validation: 0.06962069534572231]
	TIME [epoch: 8.45 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061689931626168995		[learning rate: 6.1384e-05]
	Learning Rate: 6.13836e-05
	LOSS [training: 0.061689931626168995 | validation: 0.058080121599400056]
	TIME [epoch: 8.43 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06055836312691615		[learning rate: 6.1161e-05]
	Learning Rate: 6.11609e-05
	LOSS [training: 0.06055836312691615 | validation: 0.04903866087125479]
	TIME [epoch: 8.43 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06294743206338897		[learning rate: 6.0939e-05]
	Learning Rate: 6.09389e-05
	LOSS [training: 0.06294743206338897 | validation: 0.057701717982571364]
	TIME [epoch: 8.44 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06085287648405564		[learning rate: 6.0718e-05]
	Learning Rate: 6.07178e-05
	LOSS [training: 0.06085287648405564 | validation: 0.06650446517220135]
	TIME [epoch: 8.42 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05506347412055146		[learning rate: 6.0497e-05]
	Learning Rate: 6.04974e-05
	LOSS [training: 0.05506347412055146 | validation: 0.0595836422586139]
	TIME [epoch: 8.42 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058930701318471335		[learning rate: 6.0278e-05]
	Learning Rate: 6.02779e-05
	LOSS [training: 0.058930701318471335 | validation: 0.05530603941364047]
	TIME [epoch: 8.43 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05291486124457691		[learning rate: 6.0059e-05]
	Learning Rate: 6.00591e-05
	LOSS [training: 0.05291486124457691 | validation: 0.06272637772977711]
	TIME [epoch: 8.44 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06415326412489814		[learning rate: 5.9841e-05]
	Learning Rate: 5.98412e-05
	LOSS [training: 0.06415326412489814 | validation: 0.06579327754746894]
	TIME [epoch: 8.43 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059583592423179364		[learning rate: 5.9624e-05]
	Learning Rate: 5.9624e-05
	LOSS [training: 0.059583592423179364 | validation: 0.05800535030383421]
	TIME [epoch: 8.42 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05720568874767198		[learning rate: 5.9408e-05]
	Learning Rate: 5.94076e-05
	LOSS [training: 0.05720568874767198 | validation: 0.057269116658183246]
	TIME [epoch: 8.43 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06428489802963624		[learning rate: 5.9192e-05]
	Learning Rate: 5.9192e-05
	LOSS [training: 0.06428489802963624 | validation: 0.06487295572035587]
	TIME [epoch: 8.44 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05406553467440215		[learning rate: 5.8977e-05]
	Learning Rate: 5.89772e-05
	LOSS [training: 0.05406553467440215 | validation: 0.06852561413564096]
	TIME [epoch: 8.42 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05599225716649518		[learning rate: 5.8763e-05]
	Learning Rate: 5.87632e-05
	LOSS [training: 0.05599225716649518 | validation: 0.060516108099670146]
	TIME [epoch: 8.42 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06005288254391326		[learning rate: 5.855e-05]
	Learning Rate: 5.85499e-05
	LOSS [training: 0.06005288254391326 | validation: 0.06232151152321258]
	TIME [epoch: 8.44 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06523124787738518		[learning rate: 5.8337e-05]
	Learning Rate: 5.83374e-05
	LOSS [training: 0.06523124787738518 | validation: 0.0599215078468489]
	TIME [epoch: 8.43 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060726626280342574		[learning rate: 5.8126e-05]
	Learning Rate: 5.81257e-05
	LOSS [training: 0.060726626280342574 | validation: 0.060191504566637764]
	TIME [epoch: 8.42 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058660073651878794		[learning rate: 5.7915e-05]
	Learning Rate: 5.79148e-05
	LOSS [training: 0.058660073651878794 | validation: 0.050934722924474256]
	TIME [epoch: 8.43 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0598338704743399		[learning rate: 5.7705e-05]
	Learning Rate: 5.77046e-05
	LOSS [training: 0.0598338704743399 | validation: 0.07270352060692833]
	TIME [epoch: 8.44 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05340177809493647		[learning rate: 5.7495e-05]
	Learning Rate: 5.74952e-05
	LOSS [training: 0.05340177809493647 | validation: 0.06778693846068196]
	TIME [epoch: 8.42 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05132003174820658		[learning rate: 5.7287e-05]
	Learning Rate: 5.72866e-05
	LOSS [training: 0.05132003174820658 | validation: 0.06726298899685941]
	TIME [epoch: 8.43 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06167894606696911		[learning rate: 5.7079e-05]
	Learning Rate: 5.70787e-05
	LOSS [training: 0.06167894606696911 | validation: 0.058381143969760796]
	TIME [epoch: 8.44 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06325103739247388		[learning rate: 5.6872e-05]
	Learning Rate: 5.68715e-05
	LOSS [training: 0.06325103739247388 | validation: 0.0623617105522622]
	TIME [epoch: 8.43 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06181402411872903		[learning rate: 5.6665e-05]
	Learning Rate: 5.66651e-05
	LOSS [training: 0.06181402411872903 | validation: 0.061394402491441]
	TIME [epoch: 8.42 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05212507026761577		[learning rate: 5.6459e-05]
	Learning Rate: 5.64595e-05
	LOSS [training: 0.05212507026761577 | validation: 0.05870484827655381]
	TIME [epoch: 8.42 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05540909339205126		[learning rate: 5.6255e-05]
	Learning Rate: 5.62546e-05
	LOSS [training: 0.05540909339205126 | validation: 0.0659407216661073]
	TIME [epoch: 8.44 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061525172770175704		[learning rate: 5.605e-05]
	Learning Rate: 5.60504e-05
	LOSS [training: 0.061525172770175704 | validation: 0.06229668470136903]
	TIME [epoch: 8.43 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06235832580085573		[learning rate: 5.5847e-05]
	Learning Rate: 5.5847e-05
	LOSS [training: 0.06235832580085573 | validation: 0.060099583890033725]
	TIME [epoch: 8.42 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05967269316876289		[learning rate: 5.5644e-05]
	Learning Rate: 5.56444e-05
	LOSS [training: 0.05967269316876289 | validation: 0.06532435166597438]
	TIME [epoch: 8.44 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06125808610468295		[learning rate: 5.5442e-05]
	Learning Rate: 5.54424e-05
	LOSS [training: 0.06125808610468295 | validation: 0.06717892063537287]
	TIME [epoch: 8.42 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05497762210251683		[learning rate: 5.5241e-05]
	Learning Rate: 5.52412e-05
	LOSS [training: 0.05497762210251683 | validation: 0.07333685214075814]
	TIME [epoch: 8.42 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06108032993131742		[learning rate: 5.5041e-05]
	Learning Rate: 5.50407e-05
	LOSS [training: 0.06108032993131742 | validation: 0.05343239375345249]
	TIME [epoch: 8.42 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05332002650812184		[learning rate: 5.4841e-05]
	Learning Rate: 5.4841e-05
	LOSS [training: 0.05332002650812184 | validation: 0.053765670386755844]
	TIME [epoch: 8.44 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058786712262758535		[learning rate: 5.4642e-05]
	Learning Rate: 5.4642e-05
	LOSS [training: 0.058786712262758535 | validation: 0.05854043372219967]
	TIME [epoch: 8.42 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06130356039293152		[learning rate: 5.4444e-05]
	Learning Rate: 5.44437e-05
	LOSS [training: 0.06130356039293152 | validation: 0.06550595656875036]
	TIME [epoch: 8.42 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054078724072807616		[learning rate: 5.4246e-05]
	Learning Rate: 5.42461e-05
	LOSS [training: 0.054078724072807616 | validation: 0.06238909377313392]
	TIME [epoch: 8.43 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056801758112989834		[learning rate: 5.4049e-05]
	Learning Rate: 5.40492e-05
	LOSS [training: 0.056801758112989834 | validation: 0.07259586475419724]
	TIME [epoch: 8.43 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06313933948394479		[learning rate: 5.3853e-05]
	Learning Rate: 5.38531e-05
	LOSS [training: 0.06313933948394479 | validation: 0.06754135452037718]
	TIME [epoch: 8.42 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0684756643998296		[learning rate: 5.3658e-05]
	Learning Rate: 5.36577e-05
	LOSS [training: 0.0684756643998296 | validation: 0.07748780998303471]
	TIME [epoch: 8.42 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0614967692952092		[learning rate: 5.3463e-05]
	Learning Rate: 5.34629e-05
	LOSS [training: 0.0614967692952092 | validation: 0.06865774946982522]
	TIME [epoch: 8.44 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06876692224402227		[learning rate: 5.3269e-05]
	Learning Rate: 5.32689e-05
	LOSS [training: 0.06876692224402227 | validation: 0.06405747471778428]
	TIME [epoch: 8.43 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06291284751546364		[learning rate: 5.3076e-05]
	Learning Rate: 5.30756e-05
	LOSS [training: 0.06291284751546364 | validation: 0.060185519639724086]
	TIME [epoch: 8.42 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903947964447853		[learning rate: 5.2883e-05]
	Learning Rate: 5.2883e-05
	LOSS [training: 0.05903947964447853 | validation: 0.07217197055232093]
	TIME [epoch: 8.43 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05978031028668428		[learning rate: 5.2691e-05]
	Learning Rate: 5.26911e-05
	LOSS [training: 0.05978031028668428 | validation: 0.06259794034248611]
	TIME [epoch: 8.43 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061049320346793376		[learning rate: 5.25e-05]
	Learning Rate: 5.24998e-05
	LOSS [training: 0.061049320346793376 | validation: 0.06746367053258223]
	TIME [epoch: 8.43 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06093408574775894		[learning rate: 5.2309e-05]
	Learning Rate: 5.23093e-05
	LOSS [training: 0.06093408574775894 | validation: 0.05544364991379844]
	TIME [epoch: 8.42 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06890072896493206		[learning rate: 5.2119e-05]
	Learning Rate: 5.21195e-05
	LOSS [training: 0.06890072896493206 | validation: 0.07604747714142684]
	TIME [epoch: 8.43 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06826934500821542		[learning rate: 5.193e-05]
	Learning Rate: 5.19303e-05
	LOSS [training: 0.06826934500821542 | validation: 0.07107953563363312]
	TIME [epoch: 8.42 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06026591838000104		[learning rate: 5.1742e-05]
	Learning Rate: 5.17419e-05
	LOSS [training: 0.06026591838000104 | validation: 0.06449645579457397]
	TIME [epoch: 8.42 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05546269560544657		[learning rate: 5.1554e-05]
	Learning Rate: 5.15541e-05
	LOSS [training: 0.05546269560544657 | validation: 0.06161343005677652]
	TIME [epoch: 8.42 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05655252984524717		[learning rate: 5.1367e-05]
	Learning Rate: 5.1367e-05
	LOSS [training: 0.05655252984524717 | validation: 0.06385318599602904]
	TIME [epoch: 8.44 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06330009307516471		[learning rate: 5.1181e-05]
	Learning Rate: 5.11806e-05
	LOSS [training: 0.06330009307516471 | validation: 0.05964131544222012]
	TIME [epoch: 8.42 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060737766067661146		[learning rate: 5.0995e-05]
	Learning Rate: 5.09949e-05
	LOSS [training: 0.060737766067661146 | validation: 0.061293089123973486]
	TIME [epoch: 8.42 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0606535877120014		[learning rate: 5.081e-05]
	Learning Rate: 5.08098e-05
	LOSS [training: 0.0606535877120014 | validation: 0.05579499138102582]
	TIME [epoch: 8.43 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061610224221828616		[learning rate: 5.0625e-05]
	Learning Rate: 5.06254e-05
	LOSS [training: 0.061610224221828616 | validation: 0.06071937842076706]
	TIME [epoch: 8.43 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05194336770675704		[learning rate: 5.0442e-05]
	Learning Rate: 5.04417e-05
	LOSS [training: 0.05194336770675704 | validation: 0.06270272048881248]
	TIME [epoch: 8.42 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06046267608992943		[learning rate: 5.0259e-05]
	Learning Rate: 5.02586e-05
	LOSS [training: 0.06046267608992943 | validation: 0.057551106302296616]
	TIME [epoch: 8.42 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0573617389067115		[learning rate: 5.0076e-05]
	Learning Rate: 5.00762e-05
	LOSS [training: 0.0573617389067115 | validation: 0.06408989996206384]
	TIME [epoch: 8.44 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05153231167150687		[learning rate: 4.9894e-05]
	Learning Rate: 4.98945e-05
	LOSS [training: 0.05153231167150687 | validation: 0.058558320066061265]
	TIME [epoch: 8.42 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061460019562396384		[learning rate: 4.9713e-05]
	Learning Rate: 4.97134e-05
	LOSS [training: 0.061460019562396384 | validation: 0.055268784083860344]
	TIME [epoch: 8.42 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056708430249001074		[learning rate: 4.9533e-05]
	Learning Rate: 4.9533e-05
	LOSS [training: 0.056708430249001074 | validation: 0.04641726940569184]
	TIME [epoch: 8.43 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061356906714577816		[learning rate: 4.9353e-05]
	Learning Rate: 4.93533e-05
	LOSS [training: 0.061356906714577816 | validation: 0.06491865675894279]
	TIME [epoch: 8.43 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05767368333889611		[learning rate: 4.9174e-05]
	Learning Rate: 4.91742e-05
	LOSS [training: 0.05767368333889611 | validation: 0.058399563020892435]
	TIME [epoch: 8.42 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05872614495739424		[learning rate: 4.8996e-05]
	Learning Rate: 4.89957e-05
	LOSS [training: 0.05872614495739424 | validation: 0.06307645346466817]
	TIME [epoch: 8.43 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06289625207871652		[learning rate: 4.8818e-05]
	Learning Rate: 4.88179e-05
	LOSS [training: 0.06289625207871652 | validation: 0.06064193474919597]
	TIME [epoch: 8.44 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05853793050255126		[learning rate: 4.8641e-05]
	Learning Rate: 4.86407e-05
	LOSS [training: 0.05853793050255126 | validation: 0.06193231818301716]
	TIME [epoch: 8.43 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05723897630960639		[learning rate: 4.8464e-05]
	Learning Rate: 4.84642e-05
	LOSS [training: 0.05723897630960639 | validation: 0.058176641305994516]
	TIME [epoch: 8.43 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0556771288493228		[learning rate: 4.8288e-05]
	Learning Rate: 4.82883e-05
	LOSS [training: 0.0556771288493228 | validation: 0.05245208545525028]
	TIME [epoch: 8.43 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06545848200534973		[learning rate: 4.8113e-05]
	Learning Rate: 4.81131e-05
	LOSS [training: 0.06545848200534973 | validation: 0.05719295531279468]
	TIME [epoch: 8.43 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05743025494340981		[learning rate: 4.7938e-05]
	Learning Rate: 4.79385e-05
	LOSS [training: 0.05743025494340981 | validation: 0.06007838053364052]
	TIME [epoch: 8.42 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05715122157309925		[learning rate: 4.7765e-05]
	Learning Rate: 4.77645e-05
	LOSS [training: 0.05715122157309925 | validation: 0.05570563603013428]
	TIME [epoch: 8.42 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06268332817419056		[learning rate: 4.7591e-05]
	Learning Rate: 4.75912e-05
	LOSS [training: 0.06268332817419056 | validation: 0.05813959462307653]
	TIME [epoch: 8.43 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059402048592649206		[learning rate: 4.7418e-05]
	Learning Rate: 4.74185e-05
	LOSS [training: 0.059402048592649206 | validation: 0.06553837451315755]
	TIME [epoch: 8.43 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053794682946493255		[learning rate: 4.7246e-05]
	Learning Rate: 4.72464e-05
	LOSS [training: 0.053794682946493255 | validation: 0.06378111926631702]
	TIME [epoch: 8.42 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055946023373582676		[learning rate: 4.7075e-05]
	Learning Rate: 4.70749e-05
	LOSS [training: 0.055946023373582676 | validation: 0.06318452236745817]
	TIME [epoch: 8.43 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054302824998449836		[learning rate: 4.6904e-05]
	Learning Rate: 4.69041e-05
	LOSS [training: 0.054302824998449836 | validation: 0.058520446214135005]
	TIME [epoch: 8.44 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06198463814841302		[learning rate: 4.6734e-05]
	Learning Rate: 4.67339e-05
	LOSS [training: 0.06198463814841302 | validation: 0.051414771155605145]
	TIME [epoch: 8.42 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05666446694072199		[learning rate: 4.6564e-05]
	Learning Rate: 4.65643e-05
	LOSS [training: 0.05666446694072199 | validation: 0.06323956915273256]
	TIME [epoch: 8.43 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05833206752307193		[learning rate: 4.6395e-05]
	Learning Rate: 4.63953e-05
	LOSS [training: 0.05833206752307193 | validation: 0.06819446269278974]
	TIME [epoch: 8.44 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06492833727501313		[learning rate: 4.6227e-05]
	Learning Rate: 4.62269e-05
	LOSS [training: 0.06492833727501313 | validation: 0.05960116917716732]
	TIME [epoch: 8.43 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06196597217099868		[learning rate: 4.6059e-05]
	Learning Rate: 4.60591e-05
	LOSS [training: 0.06196597217099868 | validation: 0.060181082624362454]
	TIME [epoch: 8.43 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05413479947084674		[learning rate: 4.5892e-05]
	Learning Rate: 4.5892e-05
	LOSS [training: 0.05413479947084674 | validation: 0.05779070561941174]
	TIME [epoch: 8.43 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05387793733775984		[learning rate: 4.5725e-05]
	Learning Rate: 4.57254e-05
	LOSS [training: 0.05387793733775984 | validation: 0.05542901497233775]
	TIME [epoch: 8.45 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05784992479695913		[learning rate: 4.556e-05]
	Learning Rate: 4.55595e-05
	LOSS [training: 0.05784992479695913 | validation: 0.05383877923618496]
	TIME [epoch: 8.43 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06181692985438516		[learning rate: 4.5394e-05]
	Learning Rate: 4.53942e-05
	LOSS [training: 0.06181692985438516 | validation: 0.04988628303062494]
	TIME [epoch: 8.43 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06144605321431146		[learning rate: 4.5229e-05]
	Learning Rate: 4.52294e-05
	LOSS [training: 0.06144605321431146 | validation: 0.05448742865845941]
	TIME [epoch: 8.44 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316476574292547		[learning rate: 4.5065e-05]
	Learning Rate: 4.50653e-05
	LOSS [training: 0.05316476574292547 | validation: 0.05838316612205784]
	TIME [epoch: 8.44 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05296969481394407		[learning rate: 4.4902e-05]
	Learning Rate: 4.49017e-05
	LOSS [training: 0.05296969481394407 | validation: 0.053499339171486894]
	TIME [epoch: 8.43 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05583337631515493		[learning rate: 4.4739e-05]
	Learning Rate: 4.47388e-05
	LOSS [training: 0.05583337631515493 | validation: 0.05929193228687468]
	TIME [epoch: 8.42 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053453405850271696		[learning rate: 4.4576e-05]
	Learning Rate: 4.45764e-05
	LOSS [training: 0.053453405850271696 | validation: 0.06160267205208783]
	TIME [epoch: 8.45 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053773675749793935		[learning rate: 4.4415e-05]
	Learning Rate: 4.44147e-05
	LOSS [training: 0.053773675749793935 | validation: 0.05576907295850629]
	TIME [epoch: 8.42 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05178681602193165		[learning rate: 4.4253e-05]
	Learning Rate: 4.42535e-05
	LOSS [training: 0.05178681602193165 | validation: 0.06017980409634685]
	TIME [epoch: 8.43 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059499228475545084		[learning rate: 4.4093e-05]
	Learning Rate: 4.40929e-05
	LOSS [training: 0.059499228475545084 | validation: 0.056591157252178115]
	TIME [epoch: 8.43 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05290502733684258		[learning rate: 4.3933e-05]
	Learning Rate: 4.39329e-05
	LOSS [training: 0.05290502733684258 | validation: 0.05667460817486727]
	TIME [epoch: 8.44 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05959547990865534		[learning rate: 4.3773e-05]
	Learning Rate: 4.37734e-05
	LOSS [training: 0.05959547990865534 | validation: 0.06295871798052971]
	TIME [epoch: 8.42 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05284916534243478		[learning rate: 4.3615e-05]
	Learning Rate: 4.36146e-05
	LOSS [training: 0.05284916534243478 | validation: 0.061674382502177556]
	TIME [epoch: 8.43 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06069957077617823		[learning rate: 4.3456e-05]
	Learning Rate: 4.34563e-05
	LOSS [training: 0.06069957077617823 | validation: 0.06220119918467627]
	TIME [epoch: 8.44 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057122070675331905		[learning rate: 4.3299e-05]
	Learning Rate: 4.32986e-05
	LOSS [training: 0.057122070675331905 | validation: 0.053733572608847216]
	TIME [epoch: 8.43 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050941669615751715		[learning rate: 4.3141e-05]
	Learning Rate: 4.31415e-05
	LOSS [training: 0.050941669615751715 | validation: 0.0520067666689008]
	TIME [epoch: 8.42 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05976143367721899		[learning rate: 4.2985e-05]
	Learning Rate: 4.29849e-05
	LOSS [training: 0.05976143367721899 | validation: 0.05430038420918447]
	TIME [epoch: 8.42 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05837086532318549		[learning rate: 4.2829e-05]
	Learning Rate: 4.28289e-05
	LOSS [training: 0.05837086532318549 | validation: 0.056360556153723304]
	TIME [epoch: 8.44 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05927856346511924		[learning rate: 4.2673e-05]
	Learning Rate: 4.26735e-05
	LOSS [training: 0.05927856346511924 | validation: 0.06718281492052017]
	TIME [epoch: 8.42 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05414079491479436		[learning rate: 4.2519e-05]
	Learning Rate: 4.25186e-05
	LOSS [training: 0.05414079491479436 | validation: 0.06743254241035206]
	TIME [epoch: 8.42 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061347564640772		[learning rate: 4.2364e-05]
	Learning Rate: 4.23643e-05
	LOSS [training: 0.061347564640772 | validation: 0.054747295014780685]
	TIME [epoch: 8.43 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06560056718394984		[learning rate: 4.2211e-05]
	Learning Rate: 4.22106e-05
	LOSS [training: 0.06560056718394984 | validation: 0.05700110676676317]
	TIME [epoch: 8.43 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05569872841437382		[learning rate: 4.2057e-05]
	Learning Rate: 4.20574e-05
	LOSS [training: 0.05569872841437382 | validation: 0.054990205534463585]
	TIME [epoch: 8.42 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06192130105024494		[learning rate: 4.1905e-05]
	Learning Rate: 4.19047e-05
	LOSS [training: 0.06192130105024494 | validation: 0.04917427406860847]
	TIME [epoch: 8.42 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05030367412401136		[learning rate: 4.1753e-05]
	Learning Rate: 4.17527e-05
	LOSS [training: 0.05030367412401136 | validation: 0.05558509013854582]
	TIME [epoch: 8.44 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05783800814586919		[learning rate: 4.1601e-05]
	Learning Rate: 4.16012e-05
	LOSS [training: 0.05783800814586919 | validation: 0.050240364584525944]
	TIME [epoch: 8.42 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06266141424164348		[learning rate: 4.145e-05]
	Learning Rate: 4.14502e-05
	LOSS [training: 0.06266141424164348 | validation: 0.061757528553694305]
	TIME [epoch: 8.43 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061720240863757936		[learning rate: 4.13e-05]
	Learning Rate: 4.12998e-05
	LOSS [training: 0.061720240863757936 | validation: 0.056236521636486236]
	TIME [epoch: 8.43 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06509227346345156		[learning rate: 4.115e-05]
	Learning Rate: 4.11499e-05
	LOSS [training: 0.06509227346345156 | validation: 0.05123010946526816]
	TIME [epoch: 8.43 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05098697276603446		[learning rate: 4.1001e-05]
	Learning Rate: 4.10005e-05
	LOSS [training: 0.05098697276603446 | validation: 0.06735690084238577]
	TIME [epoch: 8.42 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053055909382776066		[learning rate: 4.0852e-05]
	Learning Rate: 4.08517e-05
	LOSS [training: 0.053055909382776066 | validation: 0.04680819403964062]
	TIME [epoch: 8.42 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05937189623367097		[learning rate: 4.0703e-05]
	Learning Rate: 4.07035e-05
	LOSS [training: 0.05937189623367097 | validation: 0.05651150436604374]
	TIME [epoch: 8.44 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05161221895462599		[learning rate: 4.0556e-05]
	Learning Rate: 4.05558e-05
	LOSS [training: 0.05161221895462599 | validation: 0.05556719937116411]
	TIME [epoch: 8.42 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05606736966445709		[learning rate: 4.0409e-05]
	Learning Rate: 4.04086e-05
	LOSS [training: 0.05606736966445709 | validation: 0.05529273033052086]
	TIME [epoch: 8.42 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.047034089230621315		[learning rate: 4.0262e-05]
	Learning Rate: 4.0262e-05
	LOSS [training: 0.047034089230621315 | validation: 0.05484723096849867]
	TIME [epoch: 8.42 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051045283586402944		[learning rate: 4.0116e-05]
	Learning Rate: 4.01158e-05
	LOSS [training: 0.051045283586402944 | validation: 0.04726078669029521]
	TIME [epoch: 8.43 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0544965737206405		[learning rate: 3.997e-05]
	Learning Rate: 3.99703e-05
	LOSS [training: 0.0544965737206405 | validation: 0.05887333366735846]
	TIME [epoch: 8.42 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05938158346849427		[learning rate: 3.9825e-05]
	Learning Rate: 3.98252e-05
	LOSS [training: 0.05938158346849427 | validation: 0.05925115917755809]
	TIME [epoch: 8.42 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05343542127863345		[learning rate: 3.9681e-05]
	Learning Rate: 3.96807e-05
	LOSS [training: 0.05343542127863345 | validation: 0.05919417704571569]
	TIME [epoch: 8.44 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05956767615235524		[learning rate: 3.9537e-05]
	Learning Rate: 3.95367e-05
	LOSS [training: 0.05956767615235524 | validation: 0.04915115910496685]
	TIME [epoch: 8.42 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05437363215486264		[learning rate: 3.9393e-05]
	Learning Rate: 3.93932e-05
	LOSS [training: 0.05437363215486264 | validation: 0.05284389252568565]
	TIME [epoch: 8.42 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057108212678870215		[learning rate: 3.925e-05]
	Learning Rate: 3.92502e-05
	LOSS [training: 0.057108212678870215 | validation: 0.057351386791291425]
	TIME [epoch: 8.42 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05502733660605873		[learning rate: 3.9108e-05]
	Learning Rate: 3.91078e-05
	LOSS [training: 0.05502733660605873 | validation: 0.04879121099174665]
	TIME [epoch: 8.44 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05164934917998798		[learning rate: 3.8966e-05]
	Learning Rate: 3.89659e-05
	LOSS [training: 0.05164934917998798 | validation: 0.05762545819637834]
	TIME [epoch: 8.41 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05787198612495916		[learning rate: 3.8824e-05]
	Learning Rate: 3.88245e-05
	LOSS [training: 0.05787198612495916 | validation: 0.056360487183907675]
	TIME [epoch: 8.42 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06149785658330505		[learning rate: 3.8684e-05]
	Learning Rate: 3.86836e-05
	LOSS [training: 0.06149785658330505 | validation: 0.04778257693428996]
	TIME [epoch: 8.44 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05831474645154089		[learning rate: 3.8543e-05]
	Learning Rate: 3.85432e-05
	LOSS [training: 0.05831474645154089 | validation: 0.05255559824964606]
	TIME [epoch: 8.42 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05251409811065209		[learning rate: 3.8403e-05]
	Learning Rate: 3.84033e-05
	LOSS [training: 0.05251409811065209 | validation: 0.05704284270715642]
	TIME [epoch: 8.42 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05456699806258858		[learning rate: 3.8264e-05]
	Learning Rate: 3.82639e-05
	LOSS [training: 0.05456699806258858 | validation: 0.057067696358641236]
	TIME [epoch: 8.42 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06229891614937516		[learning rate: 3.8125e-05]
	Learning Rate: 3.81251e-05
	LOSS [training: 0.06229891614937516 | validation: 0.05306393207206034]
	TIME [epoch: 8.44 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053062103633241285		[learning rate: 3.7987e-05]
	Learning Rate: 3.79867e-05
	LOSS [training: 0.053062103633241285 | validation: 0.06884478123159025]
	TIME [epoch: 8.42 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05974380397734689		[learning rate: 3.7849e-05]
	Learning Rate: 3.78489e-05
	LOSS [training: 0.05974380397734689 | validation: 0.054068804127282884]
	TIME [epoch: 8.42 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05964992712656255		[learning rate: 3.7711e-05]
	Learning Rate: 3.77115e-05
	LOSS [training: 0.05964992712656255 | validation: 0.05668431281849665]
	TIME [epoch: 8.43 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05977791602757896		[learning rate: 3.7575e-05]
	Learning Rate: 3.75746e-05
	LOSS [training: 0.05977791602757896 | validation: 0.06250324150395112]
	TIME [epoch: 8.43 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054962055055170336		[learning rate: 3.7438e-05]
	Learning Rate: 3.74383e-05
	LOSS [training: 0.054962055055170336 | validation: 0.05361386756857974]
	TIME [epoch: 8.42 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05358287967818377		[learning rate: 3.7302e-05]
	Learning Rate: 3.73024e-05
	LOSS [training: 0.05358287967818377 | validation: 0.06217807486897352]
	TIME [epoch: 8.42 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05989860954020787		[learning rate: 3.7167e-05]
	Learning Rate: 3.7167e-05
	LOSS [training: 0.05989860954020787 | validation: 0.06208090646394984]
	TIME [epoch: 8.45 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05840634593785252		[learning rate: 3.7032e-05]
	Learning Rate: 3.70322e-05
	LOSS [training: 0.05840634593785252 | validation: 0.057702420535061645]
	TIME [epoch: 8.42 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05941488260299479		[learning rate: 3.6898e-05]
	Learning Rate: 3.68978e-05
	LOSS [training: 0.05941488260299479 | validation: 0.060967470870808976]
	TIME [epoch: 8.42 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054588688840444564		[learning rate: 3.6764e-05]
	Learning Rate: 3.67639e-05
	LOSS [training: 0.054588688840444564 | validation: 0.04585562570917587]
	TIME [epoch: 8.43 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0657384752972611		[learning rate: 3.663e-05]
	Learning Rate: 3.66304e-05
	LOSS [training: 0.0657384752972611 | validation: 0.051301336865996486]
	TIME [epoch: 8.43 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05702856530600945		[learning rate: 3.6498e-05]
	Learning Rate: 3.64975e-05
	LOSS [training: 0.05702856530600945 | validation: 0.06132797143569296]
	TIME [epoch: 8.42 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05990862159474196		[learning rate: 3.6365e-05]
	Learning Rate: 3.63651e-05
	LOSS [training: 0.05990862159474196 | validation: 0.060242740828141884]
	TIME [epoch: 8.42 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054202360975781		[learning rate: 3.6233e-05]
	Learning Rate: 3.62331e-05
	LOSS [training: 0.054202360975781 | validation: 0.05759432197404811]
	TIME [epoch: 8.44 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050220290185078585		[learning rate: 3.6102e-05]
	Learning Rate: 3.61016e-05
	LOSS [training: 0.050220290185078585 | validation: 0.05954213159440364]
	TIME [epoch: 8.43 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05176748336792828		[learning rate: 3.5971e-05]
	Learning Rate: 3.59706e-05
	LOSS [training: 0.05176748336792828 | validation: 0.05565233361653514]
	TIME [epoch: 8.43 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059952513033724605		[learning rate: 3.584e-05]
	Learning Rate: 3.584e-05
	LOSS [training: 0.059952513033724605 | validation: 0.05861023410132063]
	TIME [epoch: 8.42 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05776993249468605		[learning rate: 3.571e-05]
	Learning Rate: 3.571e-05
	LOSS [training: 0.05776993249468605 | validation: 0.06268513380338436]
	TIME [epoch: 8.44 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06251558829182885		[learning rate: 3.558e-05]
	Learning Rate: 3.55804e-05
	LOSS [training: 0.06251558829182885 | validation: 0.047045658197373864]
	TIME [epoch: 8.43 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06000006781919418		[learning rate: 3.5451e-05]
	Learning Rate: 3.54513e-05
	LOSS [training: 0.06000006781919418 | validation: 0.06139593514036003]
	TIME [epoch: 8.43 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05267795158167621		[learning rate: 3.5323e-05]
	Learning Rate: 3.53226e-05
	LOSS [training: 0.05267795158167621 | validation: 0.05252680881207544]
	TIME [epoch: 8.44 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05338292202409782		[learning rate: 3.5194e-05]
	Learning Rate: 3.51944e-05
	LOSS [training: 0.05338292202409782 | validation: 0.06234875862786502]
	TIME [epoch: 8.42 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053203544447103714		[learning rate: 3.5067e-05]
	Learning Rate: 3.50667e-05
	LOSS [training: 0.053203544447103714 | validation: 0.052938363286760465]
	TIME [epoch: 8.43 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054871996355445485		[learning rate: 3.4939e-05]
	Learning Rate: 3.49394e-05
	LOSS [training: 0.054871996355445485 | validation: 0.05983103352161184]
	TIME [epoch: 8.42 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05430554483654544		[learning rate: 3.4813e-05]
	Learning Rate: 3.48126e-05
	LOSS [training: 0.05430554483654544 | validation: 0.05677842886206442]
	TIME [epoch: 8.45 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056880259774763894		[learning rate: 3.4686e-05]
	Learning Rate: 3.46863e-05
	LOSS [training: 0.056880259774763894 | validation: 0.05375453025935353]
	TIME [epoch: 8.43 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052629348004626465		[learning rate: 3.456e-05]
	Learning Rate: 3.45604e-05
	LOSS [training: 0.052629348004626465 | validation: 0.05882091009807009]
	TIME [epoch: 8.43 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06027608123746131		[learning rate: 3.4435e-05]
	Learning Rate: 3.4435e-05
	LOSS [training: 0.06027608123746131 | validation: 0.06227710136348474]
	TIME [epoch: 8.43 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06105283376228238		[learning rate: 3.431e-05]
	Learning Rate: 3.431e-05
	LOSS [training: 0.06105283376228238 | validation: 0.051511102957538336]
	TIME [epoch: 8.44 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05748593811007872		[learning rate: 3.4186e-05]
	Learning Rate: 3.41855e-05
	LOSS [training: 0.05748593811007872 | validation: 0.06175455055192399]
	TIME [epoch: 8.42 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059546972736846046		[learning rate: 3.4061e-05]
	Learning Rate: 3.40615e-05
	LOSS [training: 0.059546972736846046 | validation: 0.05654550863383675]
	TIME [epoch: 8.43 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05867542354842407		[learning rate: 3.3938e-05]
	Learning Rate: 3.39378e-05
	LOSS [training: 0.05867542354842407 | validation: 0.06214483712809302]
	TIME [epoch: 8.45 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05335158900148677		[learning rate: 3.3815e-05]
	Learning Rate: 3.38147e-05
	LOSS [training: 0.05335158900148677 | validation: 0.05643409069694785]
	TIME [epoch: 8.42 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053036438938858975		[learning rate: 3.3692e-05]
	Learning Rate: 3.3692e-05
	LOSS [training: 0.053036438938858975 | validation: 0.05360948748514448]
	TIME [epoch: 8.43 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05991073609609656		[learning rate: 3.357e-05]
	Learning Rate: 3.35697e-05
	LOSS [training: 0.05991073609609656 | validation: 0.05597148391878404]
	TIME [epoch: 8.44 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05974648782258459		[learning rate: 3.3448e-05]
	Learning Rate: 3.34479e-05
	LOSS [training: 0.05974648782258459 | validation: 0.0550848943514395]
	TIME [epoch: 8.44 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05495428205490632		[learning rate: 3.3326e-05]
	Learning Rate: 3.33265e-05
	LOSS [training: 0.05495428205490632 | validation: 0.051288771173773916]
	TIME [epoch: 8.43 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05213571130938875		[learning rate: 3.3206e-05]
	Learning Rate: 3.32055e-05
	LOSS [training: 0.05213571130938875 | validation: 0.059679494811369665]
	TIME [epoch: 8.43 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05901804422712535		[learning rate: 3.3085e-05]
	Learning Rate: 3.3085e-05
	LOSS [training: 0.05901804422712535 | validation: 0.05276656747810918]
	TIME [epoch: 8.45 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0580259270210857		[learning rate: 3.2965e-05]
	Learning Rate: 3.2965e-05
	LOSS [training: 0.0580259270210857 | validation: 0.06855762399326698]
	TIME [epoch: 8.42 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053909808029996495		[learning rate: 3.2845e-05]
	Learning Rate: 3.28453e-05
	LOSS [training: 0.053909808029996495 | validation: 0.057651800975113306]
	TIME [epoch: 8.42 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055230680995129046		[learning rate: 3.2726e-05]
	Learning Rate: 3.27261e-05
	LOSS [training: 0.055230680995129046 | validation: 0.054288707655188465]
	TIME [epoch: 8.43 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05922808894008138		[learning rate: 3.2607e-05]
	Learning Rate: 3.26074e-05
	LOSS [training: 0.05922808894008138 | validation: 0.059442355035127306]
	TIME [epoch: 8.45 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06164109170648139		[learning rate: 3.2489e-05]
	Learning Rate: 3.2489e-05
	LOSS [training: 0.06164109170648139 | validation: 0.05592634727793176]
	TIME [epoch: 8.43 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06081576931056202		[learning rate: 3.2371e-05]
	Learning Rate: 3.23711e-05
	LOSS [training: 0.06081576931056202 | validation: 0.05465020950355591]
	TIME [epoch: 8.42 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05100338121455389		[learning rate: 3.2254e-05]
	Learning Rate: 3.22537e-05
	LOSS [training: 0.05100338121455389 | validation: 0.05871106983330679]
	TIME [epoch: 8.45 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06408624915916002		[learning rate: 3.2137e-05]
	Learning Rate: 3.21366e-05
	LOSS [training: 0.06408624915916002 | validation: 0.05406466226632647]
	TIME [epoch: 8.43 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058152751934652566		[learning rate: 3.202e-05]
	Learning Rate: 3.202e-05
	LOSS [training: 0.058152751934652566 | validation: 0.0573197821958394]
	TIME [epoch: 8.43 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05541631810630382		[learning rate: 3.1904e-05]
	Learning Rate: 3.19038e-05
	LOSS [training: 0.05541631810630382 | validation: 0.05662415507033133]
	TIME [epoch: 8.43 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05525706135190228		[learning rate: 3.1788e-05]
	Learning Rate: 3.1788e-05
	LOSS [training: 0.05525706135190228 | validation: 0.057905380430375575]
	TIME [epoch: 8.45 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06063363263876801		[learning rate: 3.1673e-05]
	Learning Rate: 3.16726e-05
	LOSS [training: 0.06063363263876801 | validation: 0.04562187684512847]
	TIME [epoch: 8.43 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06101889006398651		[learning rate: 3.1558e-05]
	Learning Rate: 3.15577e-05
	LOSS [training: 0.06101889006398651 | validation: 0.05872531748876308]
	TIME [epoch: 8.43 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059621675538102534		[learning rate: 3.1443e-05]
	Learning Rate: 3.14432e-05
	LOSS [training: 0.059621675538102534 | validation: 0.06501191562918919]
	TIME [epoch: 8.44 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05692233391214137		[learning rate: 3.1329e-05]
	Learning Rate: 3.13291e-05
	LOSS [training: 0.05692233391214137 | validation: 0.059716804394350044]
	TIME [epoch: 8.44 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06263010654841869		[learning rate: 3.1215e-05]
	Learning Rate: 3.12154e-05
	LOSS [training: 0.06263010654841869 | validation: 0.05720364458396928]
	TIME [epoch: 8.43 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05226684723333391		[learning rate: 3.1102e-05]
	Learning Rate: 3.11021e-05
	LOSS [training: 0.05226684723333391 | validation: 0.05522764164769534]
	TIME [epoch: 8.42 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06062528652418277		[learning rate: 3.0989e-05]
	Learning Rate: 3.09892e-05
	LOSS [training: 0.06062528652418277 | validation: 0.056620790592634085]
	TIME [epoch: 8.45 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0646575100857252		[learning rate: 3.0877e-05]
	Learning Rate: 3.08768e-05
	LOSS [training: 0.0646575100857252 | validation: 0.04748008358947175]
	TIME [epoch: 8.43 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06042509134812955		[learning rate: 3.0765e-05]
	Learning Rate: 3.07647e-05
	LOSS [training: 0.06042509134812955 | validation: 0.06451769773295146]
	TIME [epoch: 8.43 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05020512050474764		[learning rate: 3.0653e-05]
	Learning Rate: 3.0653e-05
	LOSS [training: 0.05020512050474764 | validation: 0.05357150324998717]
	TIME [epoch: 8.44 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055749610795296965		[learning rate: 3.0542e-05]
	Learning Rate: 3.05418e-05
	LOSS [training: 0.055749610795296965 | validation: 0.05663786002283452]
	TIME [epoch: 8.44 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04768315989346704		[learning rate: 3.0431e-05]
	Learning Rate: 3.0431e-05
	LOSS [training: 0.04768315989346704 | validation: 0.05175809579783508]
	TIME [epoch: 8.43 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05822691747674129		[learning rate: 3.0321e-05]
	Learning Rate: 3.03205e-05
	LOSS [training: 0.05822691747674129 | validation: 0.04580254288168593]
	TIME [epoch: 8.42 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05901683992939995		[learning rate: 3.0211e-05]
	Learning Rate: 3.02105e-05
	LOSS [training: 0.05901683992939995 | validation: 0.055272922558157606]
	TIME [epoch: 8.45 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0614303435536301		[learning rate: 3.0101e-05]
	Learning Rate: 3.01009e-05
	LOSS [training: 0.0614303435536301 | validation: 0.06659778312158007]
	TIME [epoch: 8.43 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05522104999744444		[learning rate: 2.9992e-05]
	Learning Rate: 2.99916e-05
	LOSS [training: 0.05522104999744444 | validation: 0.056546704436589115]
	TIME [epoch: 8.43 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060174610007341714		[learning rate: 2.9883e-05]
	Learning Rate: 2.98828e-05
	LOSS [training: 0.060174610007341714 | validation: 0.059632654242667144]
	TIME [epoch: 8.43 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06198620520333198		[learning rate: 2.9774e-05]
	Learning Rate: 2.97743e-05
	LOSS [training: 0.06198620520333198 | validation: 0.055913259188979755]
	TIME [epoch: 8.44 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0573097491617946		[learning rate: 2.9666e-05]
	Learning Rate: 2.96663e-05
	LOSS [training: 0.0573097491617946 | validation: 0.05660894083025015]
	TIME [epoch: 8.43 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0571592082186221		[learning rate: 2.9559e-05]
	Learning Rate: 2.95586e-05
	LOSS [training: 0.0571592082186221 | validation: 0.06099082657988203]
	TIME [epoch: 8.42 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05874420129735408		[learning rate: 2.9451e-05]
	Learning Rate: 2.94514e-05
	LOSS [training: 0.05874420129735408 | validation: 0.0426914704124977]
	TIME [epoch: 8.45 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05559986901532774		[learning rate: 2.9344e-05]
	Learning Rate: 2.93445e-05
	LOSS [training: 0.05559986901532774 | validation: 0.06314004765872819]
	TIME [epoch: 8.43 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05692983606573756		[learning rate: 2.9238e-05]
	Learning Rate: 2.9238e-05
	LOSS [training: 0.05692983606573756 | validation: 0.06227858679262961]
	TIME [epoch: 8.43 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0571561418334454		[learning rate: 2.9132e-05]
	Learning Rate: 2.91319e-05
	LOSS [training: 0.0571561418334454 | validation: 0.06437065715673362]
	TIME [epoch: 8.43 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05708713630574064		[learning rate: 2.9026e-05]
	Learning Rate: 2.90262e-05
	LOSS [training: 0.05708713630574064 | validation: 0.062349210609005744]
	TIME [epoch: 8.45 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06110636508021583		[learning rate: 2.8921e-05]
	Learning Rate: 2.89208e-05
	LOSS [training: 0.06110636508021583 | validation: 0.05828545754343065]
	TIME [epoch: 8.44 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06039684634168966		[learning rate: 2.8816e-05]
	Learning Rate: 2.88159e-05
	LOSS [training: 0.06039684634168966 | validation: 0.049741352803519046]
	TIME [epoch: 8.43 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674924706549259		[learning rate: 2.8711e-05]
	Learning Rate: 2.87113e-05
	LOSS [training: 0.05674924706549259 | validation: 0.049794900714179115]
	TIME [epoch: 8.45 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05615073637172795		[learning rate: 2.8607e-05]
	Learning Rate: 2.86071e-05
	LOSS [training: 0.05615073637172795 | validation: 0.060493101095471305]
	TIME [epoch: 8.43 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0575046285687167		[learning rate: 2.8503e-05]
	Learning Rate: 2.85033e-05
	LOSS [training: 0.0575046285687167 | validation: 0.05003099310827658]
	TIME [epoch: 8.43 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060418464857178666		[learning rate: 2.84e-05]
	Learning Rate: 2.83998e-05
	LOSS [training: 0.060418464857178666 | validation: 0.05677169346934083]
	TIME [epoch: 8.43 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05755564913165008		[learning rate: 2.8297e-05]
	Learning Rate: 2.82968e-05
	LOSS [training: 0.05755564913165008 | validation: 0.053724592135687144]
	TIME [epoch: 8.45 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04976566094384493		[learning rate: 2.8194e-05]
	Learning Rate: 2.81941e-05
	LOSS [training: 0.04976566094384493 | validation: 0.06048531425707876]
	TIME [epoch: 8.43 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05986372794851439		[learning rate: 2.8092e-05]
	Learning Rate: 2.80918e-05
	LOSS [training: 0.05986372794851439 | validation: 0.06506074850327959]
	TIME [epoch: 8.42 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05922694594631413		[learning rate: 2.799e-05]
	Learning Rate: 2.79898e-05
	LOSS [training: 0.05922694594631413 | validation: 0.055457589662058854]
	TIME [epoch: 8.43 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05774678969279555		[learning rate: 2.7888e-05]
	Learning Rate: 2.78882e-05
	LOSS [training: 0.05774678969279555 | validation: 0.05527783928886866]
	TIME [epoch: 8.44 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05149798621371361		[learning rate: 2.7787e-05]
	Learning Rate: 2.7787e-05
	LOSS [training: 0.05149798621371361 | validation: 0.058960591814851485]
	TIME [epoch: 8.43 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05137144674562705		[learning rate: 2.7686e-05]
	Learning Rate: 2.76862e-05
	LOSS [training: 0.05137144674562705 | validation: 0.05515903726614202]
	TIME [epoch: 8.43 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052832677178027275		[learning rate: 2.7586e-05]
	Learning Rate: 2.75857e-05
	LOSS [training: 0.052832677178027275 | validation: 0.0470675823923958]
	TIME [epoch: 8.45 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061350349262524174		[learning rate: 2.7486e-05]
	Learning Rate: 2.74856e-05
	LOSS [training: 0.061350349262524174 | validation: 0.06269030469984191]
	TIME [epoch: 8.43 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049589513026878064		[learning rate: 2.7386e-05]
	Learning Rate: 2.73859e-05
	LOSS [training: 0.049589513026878064 | validation: 0.05407307112622366]
	TIME [epoch: 8.42 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05821661361346131		[learning rate: 2.7286e-05]
	Learning Rate: 2.72865e-05
	LOSS [training: 0.05821661361346131 | validation: 0.05196259715496094]
	TIME [epoch: 8.43 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058686910102646685		[learning rate: 2.7187e-05]
	Learning Rate: 2.71875e-05
	LOSS [training: 0.058686910102646685 | validation: 0.06615810496308669]
	TIME [epoch: 8.44 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058270818450301486		[learning rate: 2.7089e-05]
	Learning Rate: 2.70888e-05
	LOSS [training: 0.058270818450301486 | validation: 0.058081398814332566]
	TIME [epoch: 8.43 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05708905940193908		[learning rate: 2.699e-05]
	Learning Rate: 2.69905e-05
	LOSS [training: 0.05708905940193908 | validation: 0.04739680722583929]
	TIME [epoch: 8.43 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05357674131655386		[learning rate: 2.6893e-05]
	Learning Rate: 2.68925e-05
	LOSS [training: 0.05357674131655386 | validation: 0.05390624506226055]
	TIME [epoch: 8.45 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124105299786411		[learning rate: 2.6795e-05]
	Learning Rate: 2.67949e-05
	LOSS [training: 0.06124105299786411 | validation: 0.05543032923222026]
	TIME [epoch: 8.43 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0505299809724709		[learning rate: 2.6698e-05]
	Learning Rate: 2.66977e-05
	LOSS [training: 0.0505299809724709 | validation: 0.05591257605831007]
	TIME [epoch: 8.43 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061737251162048576		[learning rate: 2.6601e-05]
	Learning Rate: 2.66008e-05
	LOSS [training: 0.061737251162048576 | validation: 0.05383504692678577]
	TIME [epoch: 8.43 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059890434701017015		[learning rate: 2.6504e-05]
	Learning Rate: 2.65043e-05
	LOSS [training: 0.059890434701017015 | validation: 0.05231050780731334]
	TIME [epoch: 8.45 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058729715661497796		[learning rate: 2.6408e-05]
	Learning Rate: 2.64081e-05
	LOSS [training: 0.058729715661497796 | validation: 0.06303774767230236]
	TIME [epoch: 8.43 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05223585251113716		[learning rate: 2.6312e-05]
	Learning Rate: 2.63123e-05
	LOSS [training: 0.05223585251113716 | validation: 0.06317400015471164]
	TIME [epoch: 8.42 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06371774239972201		[learning rate: 2.6217e-05]
	Learning Rate: 2.62168e-05
	LOSS [training: 0.06371774239972201 | validation: 0.05222414328521889]
	TIME [epoch: 8.44 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270573995651251		[learning rate: 2.6122e-05]
	Learning Rate: 2.61216e-05
	LOSS [training: 0.05270573995651251 | validation: 0.06715978251469884]
	TIME [epoch: 8.43 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06434948683389641		[learning rate: 2.6027e-05]
	Learning Rate: 2.60268e-05
	LOSS [training: 0.06434948683389641 | validation: 0.0516503306437913]
	TIME [epoch: 8.43 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05469863999410475		[learning rate: 2.5932e-05]
	Learning Rate: 2.59324e-05
	LOSS [training: 0.05469863999410475 | validation: 0.059435345625302616]
	TIME [epoch: 8.43 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05250764297579615		[learning rate: 2.5838e-05]
	Learning Rate: 2.58383e-05
	LOSS [training: 0.05250764297579615 | validation: 0.0474155989861548]
	TIME [epoch: 8.45 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052103919517254085		[learning rate: 2.5744e-05]
	Learning Rate: 2.57445e-05
	LOSS [training: 0.052103919517254085 | validation: 0.043677115757854205]
	TIME [epoch: 8.43 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0609721211689626		[learning rate: 2.5651e-05]
	Learning Rate: 2.56511e-05
	LOSS [training: 0.0609721211689626 | validation: 0.051409735818903936]
	TIME [epoch: 8.42 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05953499917718104		[learning rate: 2.5558e-05]
	Learning Rate: 2.5558e-05
	LOSS [training: 0.05953499917718104 | validation: 0.04625349082640276]
	TIME [epoch: 8.44 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05182817564295715		[learning rate: 2.5465e-05]
	Learning Rate: 2.54652e-05
	LOSS [training: 0.05182817564295715 | validation: 0.054188255193838714]
	TIME [epoch: 8.45 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05155914727223716		[learning rate: 2.5373e-05]
	Learning Rate: 2.53728e-05
	LOSS [training: 0.05155914727223716 | validation: 0.05794919750842764]
	TIME [epoch: 8.43 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054241882986423004		[learning rate: 2.5281e-05]
	Learning Rate: 2.52807e-05
	LOSS [training: 0.054241882986423004 | validation: 0.05485820667047127]
	TIME [epoch: 8.43 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054567547209718		[learning rate: 2.5189e-05]
	Learning Rate: 2.5189e-05
	LOSS [training: 0.054567547209718 | validation: 0.05131405277729775]
	TIME [epoch: 8.45 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056383504634477125		[learning rate: 2.5098e-05]
	Learning Rate: 2.50976e-05
	LOSS [training: 0.056383504634477125 | validation: 0.06267180343785862]
	TIME [epoch: 8.42 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986688281364425		[learning rate: 2.5006e-05]
	Learning Rate: 2.50065e-05
	LOSS [training: 0.04986688281364425 | validation: 0.052882936475299104]
	TIME [epoch: 8.42 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05631013698089445		[learning rate: 2.4916e-05]
	Learning Rate: 2.49157e-05
	LOSS [training: 0.05631013698089445 | validation: 0.054265893806206035]
	TIME [epoch: 8.44 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05989057316049871		[learning rate: 2.4825e-05]
	Learning Rate: 2.48253e-05
	LOSS [training: 0.05989057316049871 | validation: 0.056939249839194475]
	TIME [epoch: 8.44 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05679305755682664		[learning rate: 2.4735e-05]
	Learning Rate: 2.47352e-05
	LOSS [training: 0.05679305755682664 | validation: 0.058949970196402184]
	TIME [epoch: 8.43 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0578322031923149		[learning rate: 2.4645e-05]
	Learning Rate: 2.46455e-05
	LOSS [training: 0.0578322031923149 | validation: 0.054475344149597364]
	TIME [epoch: 8.43 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062370635803370246		[learning rate: 2.4556e-05]
	Learning Rate: 2.4556e-05
	LOSS [training: 0.062370635803370246 | validation: 0.045858642013826924]
	TIME [epoch: 8.44 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058156476456586746		[learning rate: 2.4467e-05]
	Learning Rate: 2.44669e-05
	LOSS [training: 0.058156476456586746 | validation: 0.06113134195062265]
	TIME [epoch: 8.43 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05158610416553834		[learning rate: 2.4378e-05]
	Learning Rate: 2.43781e-05
	LOSS [training: 0.05158610416553834 | validation: 0.05550274236673508]
	TIME [epoch: 8.43 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05283803114805924		[learning rate: 2.429e-05]
	Learning Rate: 2.42896e-05
	LOSS [training: 0.05283803114805924 | validation: 0.05495403119490373]
	TIME [epoch: 8.43 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061034552581927005		[learning rate: 2.4201e-05]
	Learning Rate: 2.42015e-05
	LOSS [training: 0.061034552581927005 | validation: 0.06132116286087126]
	TIME [epoch: 8.45 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051953951818900654		[learning rate: 2.4114e-05]
	Learning Rate: 2.41137e-05
	LOSS [training: 0.051953951818900654 | validation: 0.05747020438106225]
	TIME [epoch: 8.43 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0604664032850028		[learning rate: 2.4026e-05]
	Learning Rate: 2.40262e-05
	LOSS [training: 0.0604664032850028 | validation: 0.05712245160833389]
	TIME [epoch: 8.43 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05416718071624924		[learning rate: 2.3939e-05]
	Learning Rate: 2.3939e-05
	LOSS [training: 0.05416718071624924 | validation: 0.04887205519877246]
	TIME [epoch: 8.45 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05272001529886476		[learning rate: 2.3852e-05]
	Learning Rate: 2.38521e-05
	LOSS [training: 0.05272001529886476 | validation: 0.06639953326900795]
	TIME [epoch: 8.43 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05819772428284823		[learning rate: 2.3766e-05]
	Learning Rate: 2.37655e-05
	LOSS [training: 0.05819772428284823 | validation: 0.05486065951758609]
	TIME [epoch: 8.43 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06039969340380108		[learning rate: 2.3679e-05]
	Learning Rate: 2.36793e-05
	LOSS [training: 0.06039969340380108 | validation: 0.05880569142131265]
	TIME [epoch: 8.43 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05526739658869182		[learning rate: 2.3593e-05]
	Learning Rate: 2.35933e-05
	LOSS [training: 0.05526739658869182 | validation: 0.05592888861082223]
	TIME [epoch: 8.44 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05899441964157839		[learning rate: 2.3508e-05]
	Learning Rate: 2.35077e-05
	LOSS [training: 0.05899441964157839 | validation: 0.0487508180657262]
	TIME [epoch: 8.43 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05510482640923777		[learning rate: 2.3422e-05]
	Learning Rate: 2.34224e-05
	LOSS [training: 0.05510482640923777 | validation: 0.05000961380407649]
	TIME [epoch: 8.43 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05588900689573791		[learning rate: 2.3337e-05]
	Learning Rate: 2.33374e-05
	LOSS [training: 0.05588900689573791 | validation: 0.055297808445479255]
	TIME [epoch: 8.45 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05710838844896804		[learning rate: 2.3253e-05]
	Learning Rate: 2.32527e-05
	LOSS [training: 0.05710838844896804 | validation: 0.054615542992226235]
	TIME [epoch: 8.43 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056823664845019065		[learning rate: 2.3168e-05]
	Learning Rate: 2.31683e-05
	LOSS [training: 0.056823664845019065 | validation: 0.0526957032198075]
	TIME [epoch: 8.43 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06021600871705		[learning rate: 2.3084e-05]
	Learning Rate: 2.30843e-05
	LOSS [training: 0.06021600871705 | validation: 0.050863503282780144]
	TIME [epoch: 8.43 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05731284723422779		[learning rate: 2.3e-05]
	Learning Rate: 2.30005e-05
	LOSS [training: 0.05731284723422779 | validation: 0.04881397198273286]
	TIME [epoch: 8.45 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05849298842901275		[learning rate: 2.2917e-05]
	Learning Rate: 2.2917e-05
	LOSS [training: 0.05849298842901275 | validation: 0.05063440183214843]
	TIME [epoch: 8.43 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05733876809858783		[learning rate: 2.2834e-05]
	Learning Rate: 2.28338e-05
	LOSS [training: 0.05733876809858783 | validation: 0.05598247471673908]
	TIME [epoch: 8.43 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057812834718606695		[learning rate: 2.2751e-05]
	Learning Rate: 2.2751e-05
	LOSS [training: 0.057812834718606695 | validation: 0.05001709313210714]
	TIME [epoch: 8.44 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0557194727233172		[learning rate: 2.2668e-05]
	Learning Rate: 2.26684e-05
	LOSS [training: 0.0557194727233172 | validation: 0.062292114781883394]
	TIME [epoch: 8.44 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049801431480318695		[learning rate: 2.2586e-05]
	Learning Rate: 2.25862e-05
	LOSS [training: 0.049801431480318695 | validation: 0.05172396797231586]
	TIME [epoch: 8.43 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05677473180632203		[learning rate: 2.2504e-05]
	Learning Rate: 2.25042e-05
	LOSS [training: 0.05677473180632203 | validation: 0.062405879777440616]
	TIME [epoch: 8.43 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059944160005713364		[learning rate: 2.2423e-05]
	Learning Rate: 2.24225e-05
	LOSS [training: 0.059944160005713364 | validation: 0.048943192496412484]
	TIME [epoch: 8.45 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06015747982486129		[learning rate: 2.2341e-05]
	Learning Rate: 2.23411e-05
	LOSS [training: 0.06015747982486129 | validation: 0.05150330039288499]
	TIME [epoch: 8.43 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05894567958235978		[learning rate: 2.226e-05]
	Learning Rate: 2.22601e-05
	LOSS [training: 0.05894567958235978 | validation: 0.05349003865073146]
	TIME [epoch: 8.42 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05823270993108033		[learning rate: 2.2179e-05]
	Learning Rate: 2.21793e-05
	LOSS [training: 0.05823270993108033 | validation: 0.05575996564715853]
	TIME [epoch: 8.43 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05053402577284918		[learning rate: 2.2099e-05]
	Learning Rate: 2.20988e-05
	LOSS [training: 0.05053402577284918 | validation: 0.04843981491320538]
	TIME [epoch: 8.44 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053703020451926965		[learning rate: 2.2019e-05]
	Learning Rate: 2.20186e-05
	LOSS [training: 0.053703020451926965 | validation: 0.055875515484993254]
	TIME [epoch: 8.43 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05059773632933282		[learning rate: 2.1939e-05]
	Learning Rate: 2.19387e-05
	LOSS [training: 0.05059773632933282 | validation: 0.06285012020037674]
	TIME [epoch: 8.43 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05809952819896802		[learning rate: 2.1859e-05]
	Learning Rate: 2.18591e-05
	LOSS [training: 0.05809952819896802 | validation: 0.05242197084501875]
	TIME [epoch: 8.44 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05881679124157324		[learning rate: 2.178e-05]
	Learning Rate: 2.17797e-05
	LOSS [training: 0.05881679124157324 | validation: 0.0530779905353649]
	TIME [epoch: 8.44 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05012843747748928		[learning rate: 2.1701e-05]
	Learning Rate: 2.17007e-05
	LOSS [training: 0.05012843747748928 | validation: 0.05523389927339424]
	TIME [epoch: 8.43 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051012037371846786		[learning rate: 2.1622e-05]
	Learning Rate: 2.16219e-05
	LOSS [training: 0.051012037371846786 | validation: 0.05075833936491807]
	TIME [epoch: 8.43 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056828858982936235		[learning rate: 2.1543e-05]
	Learning Rate: 2.15435e-05
	LOSS [training: 0.056828858982936235 | validation: 0.06307335891190434]
	TIME [epoch: 8.45 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05686829364934017		[learning rate: 2.1465e-05]
	Learning Rate: 2.14653e-05
	LOSS [training: 0.05686829364934017 | validation: 0.056311624724054314]
	TIME [epoch: 8.43 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052844839955466405		[learning rate: 2.1387e-05]
	Learning Rate: 2.13874e-05
	LOSS [training: 0.052844839955466405 | validation: 0.058045897073399355]
	TIME [epoch: 8.43 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052897707732903164		[learning rate: 2.131e-05]
	Learning Rate: 2.13098e-05
	LOSS [training: 0.052897707732903164 | validation: 0.046757062327098156]
	TIME [epoch: 8.45 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05689327907191882		[learning rate: 2.1232e-05]
	Learning Rate: 2.12325e-05
	LOSS [training: 0.05689327907191882 | validation: 0.05829700203289147]
	TIME [epoch: 8.44 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05520706332125609		[learning rate: 2.1155e-05]
	Learning Rate: 2.11554e-05
	LOSS [training: 0.05520706332125609 | validation: 0.049229511834168606]
	TIME [epoch: 8.42 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05260750913177198		[learning rate: 2.1079e-05]
	Learning Rate: 2.10786e-05
	LOSS [training: 0.05260750913177198 | validation: 0.053156515094212445]
	TIME [epoch: 8.43 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06014840659861694		[learning rate: 2.1002e-05]
	Learning Rate: 2.10021e-05
	LOSS [training: 0.06014840659861694 | validation: 0.050510265184077724]
	TIME [epoch: 8.45 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05681179659302772		[learning rate: 2.0926e-05]
	Learning Rate: 2.09259e-05
	LOSS [training: 0.05681179659302772 | validation: 0.052956163933887655]
	TIME [epoch: 8.43 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04927248173319444		[learning rate: 2.085e-05]
	Learning Rate: 2.085e-05
	LOSS [training: 0.04927248173319444 | validation: 0.06332132618189809]
	TIME [epoch: 8.43 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05007365240991228		[learning rate: 2.0774e-05]
	Learning Rate: 2.07743e-05
	LOSS [training: 0.05007365240991228 | validation: 0.04660313494885915]
	TIME [epoch: 8.44 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05583026179375496		[learning rate: 2.0699e-05]
	Learning Rate: 2.06989e-05
	LOSS [training: 0.05583026179375496 | validation: 0.061626382095253285]
	TIME [epoch: 8.44 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054670838429431545		[learning rate: 2.0624e-05]
	Learning Rate: 2.06238e-05
	LOSS [training: 0.054670838429431545 | validation: 0.05293653686954973]
	TIME [epoch: 8.43 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06118023514077484		[learning rate: 2.0549e-05]
	Learning Rate: 2.05489e-05
	LOSS [training: 0.06118023514077484 | validation: 0.05504751246011292]
	TIME [epoch: 8.43 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05947426601191943		[learning rate: 2.0474e-05]
	Learning Rate: 2.04744e-05
	LOSS [training: 0.05947426601191943 | validation: 0.04751124546046348]
	TIME [epoch: 8.45 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05558060831385292		[learning rate: 2.04e-05]
	Learning Rate: 2.04001e-05
	LOSS [training: 0.05558060831385292 | validation: 0.06149101745135342]
	TIME [epoch: 8.43 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054837090488622654		[learning rate: 2.0326e-05]
	Learning Rate: 2.0326e-05
	LOSS [training: 0.054837090488622654 | validation: 0.05080079258662962]
	TIME [epoch: 8.43 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058843941478516196		[learning rate: 2.0252e-05]
	Learning Rate: 2.02523e-05
	LOSS [training: 0.058843941478516196 | validation: 0.05839974518097504]
	TIME [epoch: 8.44 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05903551538255934		[learning rate: 2.0179e-05]
	Learning Rate: 2.01788e-05
	LOSS [training: 0.05903551538255934 | validation: 0.05903934415018862]
	TIME [epoch: 8.44 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05674975217530822		[learning rate: 2.0106e-05]
	Learning Rate: 2.01055e-05
	LOSS [training: 0.05674975217530822 | validation: 0.06600968342440876]
	TIME [epoch: 8.43 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05763282777782082		[learning rate: 2.0033e-05]
	Learning Rate: 2.00326e-05
	LOSS [training: 0.05763282777782082 | validation: 0.06549141514184673]
	TIME [epoch: 8.43 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04955676209604436		[learning rate: 1.996e-05]
	Learning Rate: 1.99599e-05
	LOSS [training: 0.04955676209604436 | validation: 0.06224790210625604]
	TIME [epoch: 8.45 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05597214256422104		[learning rate: 1.9887e-05]
	Learning Rate: 1.98874e-05
	LOSS [training: 0.05597214256422104 | validation: 0.0564361374864191]
	TIME [epoch: 8.44 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0538928332196245		[learning rate: 1.9815e-05]
	Learning Rate: 1.98153e-05
	LOSS [training: 0.0538928332196245 | validation: 0.05968879796914192]
	TIME [epoch: 8.42 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05916701083599331		[learning rate: 1.9743e-05]
	Learning Rate: 1.97434e-05
	LOSS [training: 0.05916701083599331 | validation: 0.05274609887017981]
	TIME [epoch: 8.43 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05542111212066975		[learning rate: 1.9672e-05]
	Learning Rate: 1.96717e-05
	LOSS [training: 0.05542111212066975 | validation: 0.060548287042785934]
	TIME [epoch: 8.45 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05955727848184585		[learning rate: 1.96e-05]
	Learning Rate: 1.96003e-05
	LOSS [training: 0.05955727848184585 | validation: 0.0590127019208781]
	TIME [epoch: 8.43 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05641636803297132		[learning rate: 1.9529e-05]
	Learning Rate: 1.95292e-05
	LOSS [training: 0.05641636803297132 | validation: 0.05737667022713907]
	TIME [epoch: 8.43 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050892747935029035		[learning rate: 1.9458e-05]
	Learning Rate: 1.94583e-05
	LOSS [training: 0.050892747935029035 | validation: 0.049040567608855244]
	TIME [epoch: 8.45 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05744632051906466		[learning rate: 1.9388e-05]
	Learning Rate: 1.93877e-05
	LOSS [training: 0.05744632051906466 | validation: 0.054321396989079715]
	TIME [epoch: 8.43 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04979135546598299		[learning rate: 1.9317e-05]
	Learning Rate: 1.93173e-05
	LOSS [training: 0.04979135546598299 | validation: 0.054371096121336386]
	TIME [epoch: 8.43 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0536331594927084		[learning rate: 1.9247e-05]
	Learning Rate: 1.92472e-05
	LOSS [training: 0.0536331594927084 | validation: 0.04947748464060289]
	TIME [epoch: 8.43 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054911291449155554		[learning rate: 1.9177e-05]
	Learning Rate: 1.91774e-05
	LOSS [training: 0.054911291449155554 | validation: 0.05357276572089864]
	TIME [epoch: 8.45 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058432238880456996		[learning rate: 1.9108e-05]
	Learning Rate: 1.91078e-05
	LOSS [training: 0.058432238880456996 | validation: 0.05506773287678804]
	TIME [epoch: 8.43 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05152177585241664		[learning rate: 1.9038e-05]
	Learning Rate: 1.90384e-05
	LOSS [training: 0.05152177585241664 | validation: 0.06011895946035958]
	TIME [epoch: 8.43 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05788738337804687		[learning rate: 1.8969e-05]
	Learning Rate: 1.89694e-05
	LOSS [training: 0.05788738337804687 | validation: 0.0543995194837857]
	TIME [epoch: 8.45 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05197799731259708		[learning rate: 1.8901e-05]
	Learning Rate: 1.89005e-05
	LOSS [training: 0.05197799731259708 | validation: 0.047036603393180804]
	TIME [epoch: 8.44 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05124645687919773		[learning rate: 1.8832e-05]
	Learning Rate: 1.88319e-05
	LOSS [training: 0.05124645687919773 | validation: 0.056740866608903824]
	TIME [epoch: 8.43 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05226186049599607		[learning rate: 1.8764e-05]
	Learning Rate: 1.87636e-05
	LOSS [training: 0.05226186049599607 | validation: 0.0635329906393343]
	TIME [epoch: 8.43 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05270882542275368		[learning rate: 1.8695e-05]
	Learning Rate: 1.86955e-05
	LOSS [training: 0.05270882542275368 | validation: 0.052508132566516603]
	TIME [epoch: 8.45 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06175194485442439		[learning rate: 1.8628e-05]
	Learning Rate: 1.86276e-05
	LOSS [training: 0.06175194485442439 | validation: 0.05036992799301709]
	TIME [epoch: 8.43 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059540956590322824		[learning rate: 1.856e-05]
	Learning Rate: 1.856e-05
	LOSS [training: 0.059540956590322824 | validation: 0.05178060303046204]
	TIME [epoch: 8.43 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0514958175593062		[learning rate: 1.8493e-05]
	Learning Rate: 1.84927e-05
	LOSS [training: 0.0514958175593062 | validation: 0.052021987894851386]
	TIME [epoch: 8.43 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058882183996696744		[learning rate: 1.8426e-05]
	Learning Rate: 1.84256e-05
	LOSS [training: 0.058882183996696744 | validation: 0.052356113865269296]
	TIME [epoch: 8.45 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05650237906464432		[learning rate: 1.8359e-05]
	Learning Rate: 1.83587e-05
	LOSS [training: 0.05650237906464432 | validation: 0.05034707585801265]
	TIME [epoch: 8.43 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055278661791073505		[learning rate: 1.8292e-05]
	Learning Rate: 1.82921e-05
	LOSS [training: 0.055278661791073505 | validation: 0.06579590539186246]
	TIME [epoch: 8.44 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06191061858049385		[learning rate: 1.8226e-05]
	Learning Rate: 1.82257e-05
	LOSS [training: 0.06191061858049385 | validation: 0.06287999251671926]
	TIME [epoch: 8.45 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0473955973090438		[learning rate: 1.816e-05]
	Learning Rate: 1.81596e-05
	LOSS [training: 0.0473955973090438 | validation: 0.05363710855830091]
	TIME [epoch: 8.44 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052987992172733554		[learning rate: 1.8094e-05]
	Learning Rate: 1.80937e-05
	LOSS [training: 0.052987992172733554 | validation: 0.060028455645581]
	TIME [epoch: 8.43 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0587653193174393		[learning rate: 1.8028e-05]
	Learning Rate: 1.8028e-05
	LOSS [training: 0.0587653193174393 | validation: 0.050984325756118366]
	TIME [epoch: 8.44 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04837221528758899		[learning rate: 1.7963e-05]
	Learning Rate: 1.79626e-05
	LOSS [training: 0.04837221528758899 | validation: 0.059639069551412155]
	TIME [epoch: 8.45 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054152834482260735		[learning rate: 1.7897e-05]
	Learning Rate: 1.78974e-05
	LOSS [training: 0.054152834482260735 | validation: 0.06536297010907771]
	TIME [epoch: 8.43 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05759420514173611		[learning rate: 1.7832e-05]
	Learning Rate: 1.78324e-05
	LOSS [training: 0.05759420514173611 | validation: 0.06260709741365444]
	TIME [epoch: 8.43 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054140036510789434		[learning rate: 1.7768e-05]
	Learning Rate: 1.77677e-05
	LOSS [training: 0.054140036510789434 | validation: 0.053055317941349794]
	TIME [epoch: 8.45 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05952401860698101		[learning rate: 1.7703e-05]
	Learning Rate: 1.77032e-05
	LOSS [training: 0.05952401860698101 | validation: 0.05952260641046336]
	TIME [epoch: 8.43 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06025997594710484		[learning rate: 1.7639e-05]
	Learning Rate: 1.7639e-05
	LOSS [training: 0.06025997594710484 | validation: 0.04079388184572736]
	TIME [epoch: 8.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1844.pth
	Model improved!!!
EPOCH 1845/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04587850434706102		[learning rate: 1.7575e-05]
	Learning Rate: 1.7575e-05
	LOSS [training: 0.04587850434706102 | validation: 0.054528891679932995]
	TIME [epoch: 8.43 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05379705024610223		[learning rate: 1.7511e-05]
	Learning Rate: 1.75112e-05
	LOSS [training: 0.05379705024610223 | validation: 0.05189953779141164]
	TIME [epoch: 8.46 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05107120222415392		[learning rate: 1.7448e-05]
	Learning Rate: 1.74476e-05
	LOSS [training: 0.05107120222415392 | validation: 0.04276710740799906]
	TIME [epoch: 8.43 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05089028360783941		[learning rate: 1.7384e-05]
	Learning Rate: 1.73843e-05
	LOSS [training: 0.05089028360783941 | validation: 0.05894833434038568]
	TIME [epoch: 8.43 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05368137678539786		[learning rate: 1.7321e-05]
	Learning Rate: 1.73212e-05
	LOSS [training: 0.05368137678539786 | validation: 0.061440278507809455]
	TIME [epoch: 8.44 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0497535340981759		[learning rate: 1.7258e-05]
	Learning Rate: 1.72584e-05
	LOSS [training: 0.0497535340981759 | validation: 0.05973643874420054]
	TIME [epoch: 8.43 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05618769394380676		[learning rate: 1.7196e-05]
	Learning Rate: 1.71957e-05
	LOSS [training: 0.05618769394380676 | validation: 0.051188580961758434]
	TIME [epoch: 8.43 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056598742360569984		[learning rate: 1.7133e-05]
	Learning Rate: 1.71333e-05
	LOSS [training: 0.056598742360569984 | validation: 0.046628222551743065]
	TIME [epoch: 8.43 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055116585914295115		[learning rate: 1.7071e-05]
	Learning Rate: 1.70712e-05
	LOSS [training: 0.055116585914295115 | validation: 0.0652685082605992]
	TIME [epoch: 8.46 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05140261200114042		[learning rate: 1.7009e-05]
	Learning Rate: 1.70092e-05
	LOSS [training: 0.05140261200114042 | validation: 0.056298980724480585]
	TIME [epoch: 8.43 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05642422274340904		[learning rate: 1.6947e-05]
	Learning Rate: 1.69475e-05
	LOSS [training: 0.05642422274340904 | validation: 0.058616766851231975]
	TIME [epoch: 8.43 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05859827266798971		[learning rate: 1.6886e-05]
	Learning Rate: 1.6886e-05
	LOSS [training: 0.05859827266798971 | validation: 0.06518398025094727]
	TIME [epoch: 8.44 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050821178230391915		[learning rate: 1.6825e-05]
	Learning Rate: 1.68247e-05
	LOSS [training: 0.050821178230391915 | validation: 0.04522602276156505]
	TIME [epoch: 8.44 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04645648211761535		[learning rate: 1.6764e-05]
	Learning Rate: 1.67636e-05
	LOSS [training: 0.04645648211761535 | validation: 0.05599614037824857]
	TIME [epoch: 8.43 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0536528101973278		[learning rate: 1.6703e-05]
	Learning Rate: 1.67028e-05
	LOSS [training: 0.0536528101973278 | validation: 0.056218441241776926]
	TIME [epoch: 8.43 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0569179074077924		[learning rate: 1.6642e-05]
	Learning Rate: 1.66422e-05
	LOSS [training: 0.0569179074077924 | validation: 0.053561894463712824]
	TIME [epoch: 8.45 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05803276762128371		[learning rate: 1.6582e-05]
	Learning Rate: 1.65818e-05
	LOSS [training: 0.05803276762128371 | validation: 0.05448409546370057]
	TIME [epoch: 8.43 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05601628103556379		[learning rate: 1.6522e-05]
	Learning Rate: 1.65216e-05
	LOSS [training: 0.05601628103556379 | validation: 0.05172834854062584]
	TIME [epoch: 8.43 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05676293608606027		[learning rate: 1.6462e-05]
	Learning Rate: 1.64617e-05
	LOSS [training: 0.05676293608606027 | validation: 0.05914884464773235]
	TIME [epoch: 8.44 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05658033424491758		[learning rate: 1.6402e-05]
	Learning Rate: 1.64019e-05
	LOSS [training: 0.05658033424491758 | validation: 0.05995014201576819]
	TIME [epoch: 8.44 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05820051073393827		[learning rate: 1.6342e-05]
	Learning Rate: 1.63424e-05
	LOSS [training: 0.05820051073393827 | validation: 0.05565849239606639]
	TIME [epoch: 8.43 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0585880766163428		[learning rate: 1.6283e-05]
	Learning Rate: 1.62831e-05
	LOSS [training: 0.0585880766163428 | validation: 0.055515793595176645]
	TIME [epoch: 8.42 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0578299597622103		[learning rate: 1.6224e-05]
	Learning Rate: 1.6224e-05
	LOSS [training: 0.0578299597622103 | validation: 0.05578759369469325]
	TIME [epoch: 8.44 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04986671938245847		[learning rate: 1.6165e-05]
	Learning Rate: 1.61651e-05
	LOSS [training: 0.04986671938245847 | validation: 0.07003209406221822]
	TIME [epoch: 8.43 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05693135461574296		[learning rate: 1.6106e-05]
	Learning Rate: 1.61065e-05
	LOSS [training: 0.05693135461574296 | validation: 0.05060520134440051]
	TIME [epoch: 8.43 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05081882836947964		[learning rate: 1.6048e-05]
	Learning Rate: 1.6048e-05
	LOSS [training: 0.05081882836947964 | validation: 0.04871648638417496]
	TIME [epoch: 8.43 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05119191574108384		[learning rate: 1.599e-05]
	Learning Rate: 1.59898e-05
	LOSS [training: 0.05119191574108384 | validation: 0.05100180508167199]
	TIME [epoch: 8.45 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06066758906008326		[learning rate: 1.5932e-05]
	Learning Rate: 1.59317e-05
	LOSS [training: 0.06066758906008326 | validation: 0.04656163439357706]
	TIME [epoch: 8.42 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057131766870768506		[learning rate: 1.5874e-05]
	Learning Rate: 1.58739e-05
	LOSS [training: 0.057131766870768506 | validation: 0.05822750190366602]
	TIME [epoch: 8.43 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055443459450933395		[learning rate: 1.5816e-05]
	Learning Rate: 1.58163e-05
	LOSS [training: 0.055443459450933395 | validation: 0.044681712774497236]
	TIME [epoch: 8.44 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058135972725633		[learning rate: 1.5759e-05]
	Learning Rate: 1.57589e-05
	LOSS [training: 0.058135972725633 | validation: 0.05602076023251921]
	TIME [epoch: 8.43 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05239326025402966		[learning rate: 1.5702e-05]
	Learning Rate: 1.57017e-05
	LOSS [training: 0.05239326025402966 | validation: 0.06214190515121739]
	TIME [epoch: 8.42 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056334783064261026		[learning rate: 1.5645e-05]
	Learning Rate: 1.56447e-05
	LOSS [training: 0.056334783064261026 | validation: 0.0482024941460226]
	TIME [epoch: 8.42 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057497783994353235		[learning rate: 1.5588e-05]
	Learning Rate: 1.5588e-05
	LOSS [training: 0.057497783994353235 | validation: 0.057646624289056564]
	TIME [epoch: 8.45 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058687140625517206		[learning rate: 1.5531e-05]
	Learning Rate: 1.55314e-05
	LOSS [training: 0.058687140625517206 | validation: 0.05980831859210779]
	TIME [epoch: 8.43 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0568872483502723		[learning rate: 1.5475e-05]
	Learning Rate: 1.5475e-05
	LOSS [training: 0.0568872483502723 | validation: 0.05829665482599429]
	TIME [epoch: 8.43 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05772007610674242		[learning rate: 1.5419e-05]
	Learning Rate: 1.54189e-05
	LOSS [training: 0.05772007610674242 | validation: 0.056122659977509766]
	TIME [epoch: 8.44 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05517600589356279		[learning rate: 1.5363e-05]
	Learning Rate: 1.53629e-05
	LOSS [training: 0.05517600589356279 | validation: 0.05403785826112069]
	TIME [epoch: 8.44 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057614793227756325		[learning rate: 1.5307e-05]
	Learning Rate: 1.53072e-05
	LOSS [training: 0.057614793227756325 | validation: 0.05525936696570503]
	TIME [epoch: 8.43 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05884045115797476		[learning rate: 1.5252e-05]
	Learning Rate: 1.52516e-05
	LOSS [training: 0.05884045115797476 | validation: 0.05757633756736585]
	TIME [epoch: 8.43 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05762290796730505		[learning rate: 1.5196e-05]
	Learning Rate: 1.51963e-05
	LOSS [training: 0.05762290796730505 | validation: 0.05741684415601467]
	TIME [epoch: 8.44 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05316826715753714		[learning rate: 1.5141e-05]
	Learning Rate: 1.51411e-05
	LOSS [training: 0.05316826715753714 | validation: 0.05276857859654321]
	TIME [epoch: 8.42 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060491986150364566		[learning rate: 1.5086e-05]
	Learning Rate: 1.50862e-05
	LOSS [training: 0.060491986150364566 | validation: 0.04315359522642011]
	TIME [epoch: 8.43 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06145137687237623		[learning rate: 1.5031e-05]
	Learning Rate: 1.50314e-05
	LOSS [training: 0.06145137687237623 | validation: 0.05467364232147113]
	TIME [epoch: 8.44 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05317202151584878		[learning rate: 1.4977e-05]
	Learning Rate: 1.49769e-05
	LOSS [training: 0.05317202151584878 | validation: 0.06250762218373702]
	TIME [epoch: 8.44 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05886739002486707		[learning rate: 1.4923e-05]
	Learning Rate: 1.49225e-05
	LOSS [training: 0.05886739002486707 | validation: 0.04775498086007299]
	TIME [epoch: 8.43 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06124121141897189		[learning rate: 1.4868e-05]
	Learning Rate: 1.48684e-05
	LOSS [training: 0.06124121141897189 | validation: 0.06188119389986164]
	TIME [epoch: 8.43 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05503912315583411		[learning rate: 1.4814e-05]
	Learning Rate: 1.48144e-05
	LOSS [training: 0.05503912315583411 | validation: 0.06549347149656123]
	TIME [epoch: 8.45 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055650530782981725		[learning rate: 1.4761e-05]
	Learning Rate: 1.47606e-05
	LOSS [training: 0.055650530782981725 | validation: 0.056751167770381465]
	TIME [epoch: 8.42 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051327594928699684		[learning rate: 1.4707e-05]
	Learning Rate: 1.47071e-05
	LOSS [training: 0.051327594928699684 | validation: 0.055416292740988256]
	TIME [epoch: 8.42 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054793566284756026		[learning rate: 1.4654e-05]
	Learning Rate: 1.46537e-05
	LOSS [training: 0.054793566284756026 | validation: 0.05934584140687957]
	TIME [epoch: 8.43 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049887830128837005		[learning rate: 1.4601e-05]
	Learning Rate: 1.46005e-05
	LOSS [training: 0.049887830128837005 | validation: 0.05719416700131055]
	TIME [epoch: 8.44 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05689498294808132		[learning rate: 1.4548e-05]
	Learning Rate: 1.45475e-05
	LOSS [training: 0.05689498294808132 | validation: 0.05109200979430149]
	TIME [epoch: 8.42 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06151900548893866		[learning rate: 1.4495e-05]
	Learning Rate: 1.44947e-05
	LOSS [training: 0.06151900548893866 | validation: 0.05632849806668612]
	TIME [epoch: 8.43 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.059014994234053805		[learning rate: 1.4442e-05]
	Learning Rate: 1.44421e-05
	LOSS [training: 0.059014994234053805 | validation: 0.05301639225773349]
	TIME [epoch: 8.45 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05060146459278627		[learning rate: 1.439e-05]
	Learning Rate: 1.43897e-05
	LOSS [training: 0.05060146459278627 | validation: 0.05778771108405796]
	TIME [epoch: 8.43 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05080437349196478		[learning rate: 1.4338e-05]
	Learning Rate: 1.43375e-05
	LOSS [training: 0.05080437349196478 | validation: 0.05259249536533735]
	TIME [epoch: 8.43 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05029596230873272		[learning rate: 1.4285e-05]
	Learning Rate: 1.42855e-05
	LOSS [training: 0.05029596230873272 | validation: 0.047449810317682556]
	TIME [epoch: 8.42 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054310656663888034		[learning rate: 1.4234e-05]
	Learning Rate: 1.42336e-05
	LOSS [training: 0.054310656663888034 | validation: 0.054450079336503907]
	TIME [epoch: 8.45 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05548107163393445		[learning rate: 1.4182e-05]
	Learning Rate: 1.4182e-05
	LOSS [training: 0.05548107163393445 | validation: 0.057553331284559056]
	TIME [epoch: 8.43 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0576897767092297		[learning rate: 1.4131e-05]
	Learning Rate: 1.41305e-05
	LOSS [training: 0.0576897767092297 | validation: 0.056492016080614854]
	TIME [epoch: 8.42 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05957857660899139		[learning rate: 1.4079e-05]
	Learning Rate: 1.40792e-05
	LOSS [training: 0.05957857660899139 | validation: 0.04357672083994553]
	TIME [epoch: 8.44 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061409896497843494		[learning rate: 1.4028e-05]
	Learning Rate: 1.40281e-05
	LOSS [training: 0.061409896497843494 | validation: 0.05187506822695946]
	TIME [epoch: 8.44 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06177826841165869		[learning rate: 1.3977e-05]
	Learning Rate: 1.39772e-05
	LOSS [training: 0.06177826841165869 | validation: 0.056726304274865136]
	TIME [epoch: 8.42 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05612085608145716		[learning rate: 1.3927e-05]
	Learning Rate: 1.39265e-05
	LOSS [training: 0.05612085608145716 | validation: 0.0505018320890054]
	TIME [epoch: 8.42 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06155614760951694		[learning rate: 1.3876e-05]
	Learning Rate: 1.3876e-05
	LOSS [training: 0.06155614760951694 | validation: 0.05112996037454091]
	TIME [epoch: 8.45 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05862989517126016		[learning rate: 1.3826e-05]
	Learning Rate: 1.38256e-05
	LOSS [training: 0.05862989517126016 | validation: 0.05695532956280855]
	TIME [epoch: 8.42 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0520086136974696		[learning rate: 1.3775e-05]
	Learning Rate: 1.37754e-05
	LOSS [training: 0.0520086136974696 | validation: 0.05365077587470737]
	TIME [epoch: 8.43 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053772642901456		[learning rate: 1.3725e-05]
	Learning Rate: 1.37254e-05
	LOSS [training: 0.053772642901456 | validation: 0.05090772287634062]
	TIME [epoch: 8.44 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05476620866592678		[learning rate: 1.3676e-05]
	Learning Rate: 1.36756e-05
	LOSS [training: 0.05476620866592678 | validation: 0.05191988970486511]
	TIME [epoch: 8.44 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04855745368131391		[learning rate: 1.3626e-05]
	Learning Rate: 1.3626e-05
	LOSS [training: 0.04855745368131391 | validation: 0.05493072269946634]
	TIME [epoch: 8.43 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05101654826937947		[learning rate: 1.3577e-05]
	Learning Rate: 1.35766e-05
	LOSS [training: 0.05101654826937947 | validation: 0.052065566220253684]
	TIME [epoch: 8.43 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057773071344864826		[learning rate: 1.3527e-05]
	Learning Rate: 1.35273e-05
	LOSS [training: 0.057773071344864826 | validation: 0.039285363677631066]
	TIME [epoch: 8.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl2/tr_study204/model_tr_study204_r3_20240219_205156/states/model_tr_study204_1917.pth
	Model improved!!!
EPOCH 1918/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057873018008164044		[learning rate: 1.3478e-05]
	Learning Rate: 1.34782e-05
	LOSS [training: 0.057873018008164044 | validation: 0.04893429659386065]
	TIME [epoch: 8.43 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06078844414346768		[learning rate: 1.3429e-05]
	Learning Rate: 1.34293e-05
	LOSS [training: 0.06078844414346768 | validation: 0.05142673881875976]
	TIME [epoch: 8.43 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054927602086770645		[learning rate: 1.3381e-05]
	Learning Rate: 1.33805e-05
	LOSS [training: 0.054927602086770645 | validation: 0.05493385627966062]
	TIME [epoch: 8.44 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056097101976025264		[learning rate: 1.3332e-05]
	Learning Rate: 1.3332e-05
	LOSS [training: 0.056097101976025264 | validation: 0.053440003841391755]
	TIME [epoch: 8.44 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05351961378305568		[learning rate: 1.3284e-05]
	Learning Rate: 1.32836e-05
	LOSS [training: 0.05351961378305568 | validation: 0.05453327319230679]
	TIME [epoch: 8.43 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060811856940565144		[learning rate: 1.3235e-05]
	Learning Rate: 1.32354e-05
	LOSS [training: 0.060811856940565144 | validation: 0.05939182186222722]
	TIME [epoch: 8.43 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05414280582530047		[learning rate: 1.3187e-05]
	Learning Rate: 1.31874e-05
	LOSS [training: 0.05414280582530047 | validation: 0.06139893266134601]
	TIME [epoch: 8.45 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049463973299949254		[learning rate: 1.314e-05]
	Learning Rate: 1.31395e-05
	LOSS [training: 0.049463973299949254 | validation: 0.049501808145886034]
	TIME [epoch: 8.43 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05352565939373296		[learning rate: 1.3092e-05]
	Learning Rate: 1.30918e-05
	LOSS [training: 0.05352565939373296 | validation: 0.05199229764552762]
	TIME [epoch: 8.42 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06060171469830712		[learning rate: 1.3044e-05]
	Learning Rate: 1.30443e-05
	LOSS [training: 0.06060171469830712 | validation: 0.05588055549926798]
	TIME [epoch: 8.44 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05375236211312519		[learning rate: 1.2997e-05]
	Learning Rate: 1.2997e-05
	LOSS [training: 0.05375236211312519 | validation: 0.05566588594715874]
	TIME [epoch: 8.44 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0538546381491999		[learning rate: 1.295e-05]
	Learning Rate: 1.29498e-05
	LOSS [training: 0.0538546381491999 | validation: 0.0488029503236163]
	TIME [epoch: 8.43 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06176470978651836		[learning rate: 1.2903e-05]
	Learning Rate: 1.29028e-05
	LOSS [training: 0.06176470978651836 | validation: 0.06083143050395936]
	TIME [epoch: 8.42 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06033732577185944		[learning rate: 1.2856e-05]
	Learning Rate: 1.2856e-05
	LOSS [training: 0.06033732577185944 | validation: 0.05006337718715941]
	TIME [epoch: 8.44 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04841298030698649		[learning rate: 1.2809e-05]
	Learning Rate: 1.28093e-05
	LOSS [training: 0.04841298030698649 | validation: 0.060976533154058696]
	TIME [epoch: 8.42 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05777485602645184		[learning rate: 1.2763e-05]
	Learning Rate: 1.27628e-05
	LOSS [training: 0.05777485602645184 | validation: 0.060685327519844984]
	TIME [epoch: 8.43 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549567723682861		[learning rate: 1.2717e-05]
	Learning Rate: 1.27165e-05
	LOSS [training: 0.0549567723682861 | validation: 0.056102720157247585]
	TIME [epoch: 8.43 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052164537136992685		[learning rate: 1.267e-05]
	Learning Rate: 1.26704e-05
	LOSS [training: 0.052164537136992685 | validation: 0.05580376801170802]
	TIME [epoch: 8.45 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06281110152540616		[learning rate: 1.2624e-05]
	Learning Rate: 1.26244e-05
	LOSS [training: 0.06281110152540616 | validation: 0.0515273121516095]
	TIME [epoch: 8.43 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053027294061002914		[learning rate: 1.2579e-05]
	Learning Rate: 1.25786e-05
	LOSS [training: 0.053027294061002914 | validation: 0.05355184835914478]
	TIME [epoch: 8.43 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06177517606460472		[learning rate: 1.2533e-05]
	Learning Rate: 1.25329e-05
	LOSS [training: 0.06177517606460472 | validation: 0.050780140314789786]
	TIME [epoch: 8.45 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05959534034076234		[learning rate: 1.2487e-05]
	Learning Rate: 1.24874e-05
	LOSS [training: 0.05959534034076234 | validation: 0.054352730910699934]
	TIME [epoch: 8.43 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0561858193386335		[learning rate: 1.2442e-05]
	Learning Rate: 1.24421e-05
	LOSS [training: 0.0561858193386335 | validation: 0.054988724413218545]
	TIME [epoch: 8.43 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056354243836644266		[learning rate: 1.2397e-05]
	Learning Rate: 1.2397e-05
	LOSS [training: 0.056354243836644266 | validation: 0.05497945106629253]
	TIME [epoch: 8.43 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.061113181700782504		[learning rate: 1.2352e-05]
	Learning Rate: 1.2352e-05
	LOSS [training: 0.061113181700782504 | validation: 0.059496577644028784]
	TIME [epoch: 8.45 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056517933979579625		[learning rate: 1.2307e-05]
	Learning Rate: 1.23072e-05
	LOSS [training: 0.056517933979579625 | validation: 0.06706266748397927]
	TIME [epoch: 8.42 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.054065893639636355		[learning rate: 1.2263e-05]
	Learning Rate: 1.22625e-05
	LOSS [training: 0.054065893639636355 | validation: 0.04958917619024372]
	TIME [epoch: 8.42 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052666517854638405		[learning rate: 1.2218e-05]
	Learning Rate: 1.2218e-05
	LOSS [training: 0.052666517854638405 | validation: 0.04936561366870178]
	TIME [epoch: 8.43 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05669618286196125		[learning rate: 1.2174e-05]
	Learning Rate: 1.21737e-05
	LOSS [training: 0.05669618286196125 | validation: 0.0499281276758577]
	TIME [epoch: 8.44 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056921404518130624		[learning rate: 1.2129e-05]
	Learning Rate: 1.21295e-05
	LOSS [training: 0.056921404518130624 | validation: 0.048249506936927755]
	TIME [epoch: 8.42 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05653271192786141		[learning rate: 1.2085e-05]
	Learning Rate: 1.20855e-05
	LOSS [training: 0.05653271192786141 | validation: 0.06258824123184151]
	TIME [epoch: 8.43 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05593291475064164		[learning rate: 1.2042e-05]
	Learning Rate: 1.20416e-05
	LOSS [training: 0.05593291475064164 | validation: 0.05547812505297299]
	TIME [epoch: 8.46 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049504044535346174		[learning rate: 1.1998e-05]
	Learning Rate: 1.19979e-05
	LOSS [training: 0.049504044535346174 | validation: 0.057958613459364275]
	TIME [epoch: 8.43 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05679718470347933		[learning rate: 1.1954e-05]
	Learning Rate: 1.19544e-05
	LOSS [training: 0.05679718470347933 | validation: 0.05901077635868113]
	TIME [epoch: 8.43 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05914870760646981		[learning rate: 1.1911e-05]
	Learning Rate: 1.1911e-05
	LOSS [training: 0.05914870760646981 | validation: 0.047618458675880104]
	TIME [epoch: 8.43 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0565197702074413		[learning rate: 1.1868e-05]
	Learning Rate: 1.18678e-05
	LOSS [training: 0.0565197702074413 | validation: 0.05224845020574813]
	TIME [epoch: 8.45 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05848959272262018		[learning rate: 1.1825e-05]
	Learning Rate: 1.18247e-05
	LOSS [training: 0.05848959272262018 | validation: 0.05436702619539634]
	TIME [epoch: 8.43 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.051047628588916746		[learning rate: 1.1782e-05]
	Learning Rate: 1.17818e-05
	LOSS [training: 0.051047628588916746 | validation: 0.05859553016145311]
	TIME [epoch: 8.43 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05133670580703002		[learning rate: 1.1739e-05]
	Learning Rate: 1.1739e-05
	LOSS [training: 0.05133670580703002 | validation: 0.058295673515264476]
	TIME [epoch: 8.45 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0549029528908203		[learning rate: 1.1696e-05]
	Learning Rate: 1.16964e-05
	LOSS [training: 0.0549029528908203 | validation: 0.051953019176274234]
	TIME [epoch: 8.43 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05573874010491955		[learning rate: 1.1654e-05]
	Learning Rate: 1.1654e-05
	LOSS [training: 0.05573874010491955 | validation: 0.056677209675174256]
	TIME [epoch: 8.43 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05136345730930546		[learning rate: 1.1612e-05]
	Learning Rate: 1.16117e-05
	LOSS [training: 0.05136345730930546 | validation: 0.047973267563213115]
	TIME [epoch: 8.43 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.058997804153313106		[learning rate: 1.157e-05]
	Learning Rate: 1.15695e-05
	LOSS [training: 0.058997804153313106 | validation: 0.05627284431608056]
	TIME [epoch: 8.45 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.050829972910740484		[learning rate: 1.1528e-05]
	Learning Rate: 1.15275e-05
	LOSS [training: 0.050829972910740484 | validation: 0.06168414678442238]
	TIME [epoch: 8.43 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05247966157236021		[learning rate: 1.1486e-05]
	Learning Rate: 1.14857e-05
	LOSS [training: 0.05247966157236021 | validation: 0.045960743852658366]
	TIME [epoch: 8.43 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.052575662775097155		[learning rate: 1.1444e-05]
	Learning Rate: 1.1444e-05
	LOSS [training: 0.052575662775097155 | validation: 0.057180886345459696]
	TIME [epoch: 8.45 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05672458530600266		[learning rate: 1.1402e-05]
	Learning Rate: 1.14025e-05
	LOSS [training: 0.05672458530600266 | validation: 0.05777306290410812]
	TIME [epoch: 8.43 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06009155305410326		[learning rate: 1.1361e-05]
	Learning Rate: 1.13611e-05
	LOSS [training: 0.06009155305410326 | validation: 0.05511262870203411]
	TIME [epoch: 8.43 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.049228224215985175		[learning rate: 1.132e-05]
	Learning Rate: 1.13199e-05
	LOSS [training: 0.049228224215985175 | validation: 0.05054746777051788]
	TIME [epoch: 8.43 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05182339918801178		[learning rate: 1.1279e-05]
	Learning Rate: 1.12788e-05
	LOSS [training: 0.05182339918801178 | validation: 0.06630062795666662]
	TIME [epoch: 8.46 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05871859691772392		[learning rate: 1.1238e-05]
	Learning Rate: 1.12379e-05
	LOSS [training: 0.05871859691772392 | validation: 0.055571884476656154]
	TIME [epoch: 8.43 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06444816499394498		[learning rate: 1.1197e-05]
	Learning Rate: 1.11971e-05
	LOSS [training: 0.06444816499394498 | validation: 0.06081781238102198]
	TIME [epoch: 8.43 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05059110778833498		[learning rate: 1.1156e-05]
	Learning Rate: 1.11565e-05
	LOSS [training: 0.05059110778833498 | validation: 0.05689997004789844]
	TIME [epoch: 8.45 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05739427146176427		[learning rate: 1.1116e-05]
	Learning Rate: 1.1116e-05
	LOSS [training: 0.05739427146176427 | validation: 0.0536964302732969]
	TIME [epoch: 8.43 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05390990265896296		[learning rate: 1.1076e-05]
	Learning Rate: 1.10756e-05
	LOSS [training: 0.05390990265896296 | validation: 0.05874906550000062]
	TIME [epoch: 8.43 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05746834935886484		[learning rate: 1.1035e-05]
	Learning Rate: 1.10354e-05
	LOSS [training: 0.05746834935886484 | validation: 0.061915575897160735]
	TIME [epoch: 8.43 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05784836071071668		[learning rate: 1.0995e-05]
	Learning Rate: 1.09954e-05
	LOSS [training: 0.05784836071071668 | validation: 0.06966076818145935]
	TIME [epoch: 8.45 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056454799927503616		[learning rate: 1.0955e-05]
	Learning Rate: 1.09555e-05
	LOSS [training: 0.056454799927503616 | validation: 0.0509874329873799]
	TIME [epoch: 8.43 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.046796202873601186		[learning rate: 1.0916e-05]
	Learning Rate: 1.09157e-05
	LOSS [training: 0.046796202873601186 | validation: 0.05230053434788171]
	TIME [epoch: 8.43 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05646785264624856		[learning rate: 1.0876e-05]
	Learning Rate: 1.08761e-05
	LOSS [training: 0.05646785264624856 | validation: 0.06192860730740178]
	TIME [epoch: 8.44 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0569734776767301		[learning rate: 1.0837e-05]
	Learning Rate: 1.08366e-05
	LOSS [training: 0.0569734776767301 | validation: 0.059185020708848096]
	TIME [epoch: 8.44 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053161792066805505		[learning rate: 1.0797e-05]
	Learning Rate: 1.07973e-05
	LOSS [training: 0.053161792066805505 | validation: 0.05933444748122997]
	TIME [epoch: 8.43 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.062157775094927		[learning rate: 1.0758e-05]
	Learning Rate: 1.07581e-05
	LOSS [training: 0.062157775094927 | validation: 0.058494337376578644]
	TIME [epoch: 8.43 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04840466633327235		[learning rate: 1.0719e-05]
	Learning Rate: 1.07191e-05
	LOSS [training: 0.04840466633327235 | validation: 0.0539351603769645]
	TIME [epoch: 8.45 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06194647228154546		[learning rate: 1.068e-05]
	Learning Rate: 1.06802e-05
	LOSS [training: 0.06194647228154546 | validation: 0.06007493428071099]
	TIME [epoch: 8.43 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.060136253039767065		[learning rate: 1.0641e-05]
	Learning Rate: 1.06414e-05
	LOSS [training: 0.060136253039767065 | validation: 0.054602397441116265]
	TIME [epoch: 8.43 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05431188228984687		[learning rate: 1.0603e-05]
	Learning Rate: 1.06028e-05
	LOSS [training: 0.05431188228984687 | validation: 0.06160986829648263]
	TIME [epoch: 8.43 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05035720487696691		[learning rate: 1.0564e-05]
	Learning Rate: 1.05643e-05
	LOSS [training: 0.05035720487696691 | validation: 0.06270238308321241]
	TIME [epoch: 8.45 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.057355909758217125		[learning rate: 1.0526e-05]
	Learning Rate: 1.0526e-05
	LOSS [training: 0.057355909758217125 | validation: 0.05675748295288582]
	TIME [epoch: 8.43 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04771595459089545		[learning rate: 1.0488e-05]
	Learning Rate: 1.04878e-05
	LOSS [training: 0.04771595459089545 | validation: 0.0643165683629432]
	TIME [epoch: 8.42 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.053276929985844344		[learning rate: 1.045e-05]
	Learning Rate: 1.04497e-05
	LOSS [training: 0.053276929985844344 | validation: 0.06054763201340917]
	TIME [epoch: 8.45 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05632660595606835		[learning rate: 1.0412e-05]
	Learning Rate: 1.04118e-05
	LOSS [training: 0.05632660595606835 | validation: 0.047458768058419185]
	TIME [epoch: 8.43 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.06123038389954234		[learning rate: 1.0374e-05]
	Learning Rate: 1.0374e-05
	LOSS [training: 0.06123038389954234 | validation: 0.06333015526579162]
	TIME [epoch: 8.43 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04808906851172075		[learning rate: 1.0336e-05]
	Learning Rate: 1.03364e-05
	LOSS [training: 0.04808906851172075 | validation: 0.054500002592730835]
	TIME [epoch: 8.43 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0587919751498112		[learning rate: 1.0299e-05]
	Learning Rate: 1.02989e-05
	LOSS [training: 0.0587919751498112 | validation: 0.05424279307839156]
	TIME [epoch: 8.45 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.056662015597544545		[learning rate: 1.0261e-05]
	Learning Rate: 1.02615e-05
	LOSS [training: 0.056662015597544545 | validation: 0.048855862528430445]
	TIME [epoch: 8.42 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05392452143660339		[learning rate: 1.0224e-05]
	Learning Rate: 1.02243e-05
	LOSS [training: 0.05392452143660339 | validation: 0.05913755602507703]
	TIME [epoch: 8.42 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.0495968148415458		[learning rate: 1.0187e-05]
	Learning Rate: 1.01872e-05
	LOSS [training: 0.0495968148415458 | validation: 0.05753041334195209]
	TIME [epoch: 8.45 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04755680004645475		[learning rate: 1.015e-05]
	Learning Rate: 1.01502e-05
	LOSS [training: 0.04755680004645475 | validation: 0.0478920579343128]
	TIME [epoch: 8.43 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05872423486250189		[learning rate: 1.0113e-05]
	Learning Rate: 1.01133e-05
	LOSS [training: 0.05872423486250189 | validation: 0.05438688248577569]
	TIME [epoch: 8.43 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.05759663642847278		[learning rate: 1.0077e-05]
	Learning Rate: 1.00766e-05
	LOSS [training: 0.05759663642847278 | validation: 0.05223672084542066]
	TIME [epoch: 8.43 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.055819699707436644		[learning rate: 1.004e-05]
	Learning Rate: 1.00401e-05
	LOSS [training: 0.055819699707436644 | validation: 0.04715323274148573]
	TIME [epoch: 8.45 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 10/10] avg loss: 0.04971712107075128		[learning rate: 1.0004e-05]
	Learning Rate: 1.00036e-05
	LOSS [training: 0.04971712107075128 | validation: 0.06000397051198225]
	TIME [epoch: 8.43 sec]
Finished training in 17011.250 seconds.
