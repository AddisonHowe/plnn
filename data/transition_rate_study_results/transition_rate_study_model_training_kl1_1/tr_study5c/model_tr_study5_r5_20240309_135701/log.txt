Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2678705983

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.45534101613248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.45534101613248 | validation: 9.762175254174728]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.535598734431355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.535598734431355 | validation: 8.187165603870156]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6935922150186276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6935922150186276 | validation: 7.431391636763473]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.231233340525701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.231233340525701 | validation: 7.901874278894427]
	TIME [epoch: 24.8 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.129328987096052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.129328987096052 | validation: 6.848308746956718]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.899186419889148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.899186419889148 | validation: 8.004080498849884]
	TIME [epoch: 24.7 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7548980095876585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7548980095876585 | validation: 6.2463819562640035]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.008249532192675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.008249532192675 | validation: 5.688646763486986]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.241198316623747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.241198316623747 | validation: 6.92779507276804]
	TIME [epoch: 24.7 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.046855376612543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.046855376612543 | validation: 5.5735344629621295]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.399080156596989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.399080156596989 | validation: 5.0676052050052185]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.216590871020333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.216590871020333 | validation: 7.019425017313027]
	TIME [epoch: 24.7 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.713427962790053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.713427962790053 | validation: 5.770198362293252]
	TIME [epoch: 24.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.386952179920993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.386952179920993 | validation: 5.097353869585096]
	TIME [epoch: 24.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.206621146932026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.206621146932026 | validation: 5.063537627262273]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.051328294017339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.051328294017339 | validation: 5.0686211463331]
	TIME [epoch: 24.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.99565233473224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.99565233473224 | validation: 7.680568701251176]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.349430505553283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.349430505553283 | validation: 5.469812356574014]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2884083662819465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2884083662819465 | validation: 4.943748535541525]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.637544494773799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.637544494773799 | validation: 6.515677987025485]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.626594907725139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.626594907725139 | validation: 5.556901281406588]
	TIME [epoch: 24.8 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.47855271211888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.47855271211888 | validation: 5.1131752829465835]
	TIME [epoch: 24.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.404910842090601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.404910842090601 | validation: 5.133785146321127]
	TIME [epoch: 24.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.094954549131778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.094954549131778 | validation: 5.79429995163693]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732395409683592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.732395409683592 | validation: 5.331351240792781]
	TIME [epoch: 24.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.224541316789075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.224541316789075 | validation: 5.106861788786297]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.994582301160889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.994582301160889 | validation: 5.590350343798016]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.328574122371793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.328574122371793 | validation: 5.364161366847359]
	TIME [epoch: 24.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.234547545545126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.234547545545126 | validation: 5.1667517666073275]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9526685910155415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9526685910155415 | validation: 10.910128435011138]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.782513908661192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.782513908661192 | validation: 5.628558605861206]
	TIME [epoch: 24.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.317940651825692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.317940651825692 | validation: 5.158884005267432]
	TIME [epoch: 24.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.134370386548623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.134370386548623 | validation: 5.010062433046141]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.046745924053188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.046745924053188 | validation: 5.99511239783973]
	TIME [epoch: 24.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.655554526518015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.655554526518015 | validation: 5.196258983622214]
	TIME [epoch: 24.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.090810531567195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.090810531567195 | validation: 4.794919781120957]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.100407999815804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.100407999815804 | validation: 6.474682078359322]
	TIME [epoch: 24.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.354487743059523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.354487743059523 | validation: 4.904306423056627]
	TIME [epoch: 24.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.858551754454372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.858551754454372 | validation: 4.820762272935542]
	TIME [epoch: 24.7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.838069455328867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.838069455328867 | validation: 4.527008888900013]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.50810076536542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.50810076536542 | validation: 5.342904276897265]
	TIME [epoch: 24.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.865851165029333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.865851165029333 | validation: 9.419451218770348]
	TIME [epoch: 24.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7776768191178824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7776768191178824 | validation: 5.5732113869386835]
	TIME [epoch: 24.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.236427068014587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.236427068014587 | validation: 5.109345669748867]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.092434596440251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.092434596440251 | validation: 5.285610442448078]
	TIME [epoch: 24.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.158084072513443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.158084072513443 | validation: 5.110938714215443]
	TIME [epoch: 24.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.108805877731635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.108805877731635 | validation: 5.34033418690218]
	TIME [epoch: 24.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.017591286058106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.017591286058106 | validation: 4.657938105600219]
	TIME [epoch: 24.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.024431017277641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.024431017277641 | validation: 4.688490884516798]
	TIME [epoch: 24.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.76361761532431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.76361761532431 | validation: 4.43043372441315]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.406385254408038		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.406385254408038 | validation: 4.711187608786202]
	TIME [epoch: 24.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.184581717241084		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 6.184581717241084 | validation: 5.024976296730389]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.91941867323107		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.91941867323107 | validation: 4.917644909078612]
	TIME [epoch: 24.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771912154686346		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.771912154686346 | validation: 4.348212554198822]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.569747294283937		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.569747294283937 | validation: 5.078875712585864]
	TIME [epoch: 24.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.459488782623643		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.459488782623643 | validation: 4.732346259856386]
	TIME [epoch: 24.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473968663192963		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.473968663192963 | validation: 4.194145060304774]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915316679290775		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.915316679290775 | validation: 6.538557977869906]
	TIME [epoch: 24.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.399935753587662		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.399935753587662 | validation: 4.4928677265674]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.432432093605488		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.432432093605488 | validation: 4.760916613471588]
	TIME [epoch: 24.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.805627712376593		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.805627712376593 | validation: 5.079294847920335]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.832362943057918		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.832362943057918 | validation: 4.053936687932009]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1913869793352445		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.1913869793352445 | validation: 4.289200664158383]
	TIME [epoch: 24.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.525961557149968		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.525961557149968 | validation: 4.646434765029423]
	TIME [epoch: 24.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559250932560578		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.559250932560578 | validation: 5.094582450468253]
	TIME [epoch: 24.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.625215464411044		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.625215464411044 | validation: 5.013331492538743]
	TIME [epoch: 24.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.343351755656256		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.343351755656256 | validation: 4.496686440435944]
	TIME [epoch: 24.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452907731759788		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.452907731759788 | validation: 4.53112958234958]
	TIME [epoch: 24.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.552662022982982		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 5.552662022982982 | validation: 6.004585090957863]
	TIME [epoch: 24.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.101704778117637		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.101704778117637 | validation: 4.664773277404577]
	TIME [epoch: 24.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736425557700768		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.736425557700768 | validation: 5.780148297383449]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.981284408308982		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.981284408308982 | validation: 4.980180426800296]
	TIME [epoch: 24.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.943363523676363		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.943363523676363 | validation: 4.638233365324539]
	TIME [epoch: 24.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621900788549649		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.621900788549649 | validation: 5.201706537533806]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.722511358945339		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.722511358945339 | validation: 9.064595218373046]
	TIME [epoch: 24.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.758587123653238		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 7.758587123653238 | validation: 4.141634616754439]
	TIME [epoch: 24.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365749462827798		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.365749462827798 | validation: 5.281940268605552]
	TIME [epoch: 24.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.660328094344615		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 6.660328094344615 | validation: 7.346288829465256]
	TIME [epoch: 24.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.365920480720791		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 6.365920480720791 | validation: 5.627715836128098]
	TIME [epoch: 24.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.159355586862099		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.159355586862099 | validation: 4.582670706358063]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.386321527593754		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.386321527593754 | validation: 4.521645271824611]
	TIME [epoch: 24.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.461364295203904		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.461364295203904 | validation: 5.144220522753981]
	TIME [epoch: 24.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.746448500042018		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.746448500042018 | validation: 4.69470310521531]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463574718953481		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.463574718953481 | validation: 4.078081533392092]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.17101055719117		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.17101055719117 | validation: 3.9725175412881812]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0448017414153785		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.0448017414153785 | validation: 4.565906957606464]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.310143369524045		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 4.310143369524045 | validation: 4.143149880135872]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2534307294221225		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.2534307294221225 | validation: 4.961723267338331]
	TIME [epoch: 24.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483194425463509		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.483194425463509 | validation: 4.192491017480993]
	TIME [epoch: 24.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.39580637797738		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.39580637797738 | validation: 4.92036879450644]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7262548391718		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.7262548391718 | validation: 4.1460897513939825]
	TIME [epoch: 24.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.245382657045156		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.245382657045156 | validation: 4.511659231835884]
	TIME [epoch: 24.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.388033133314312		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.388033133314312 | validation: 4.863282948583824]
	TIME [epoch: 24.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.136727954866718		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 5.136727954866718 | validation: 4.423789091008999]
	TIME [epoch: 24.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.582290363065217		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.582290363065217 | validation: 4.3174583509575415]
	TIME [epoch: 24.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.517004714572608		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.517004714572608 | validation: 4.094792677785405]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.397512252861322		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.397512252861322 | validation: 4.278655863965162]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.518272519526332		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 7.518272519526332 | validation: 9.075891492016613]
	TIME [epoch: 24.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.549180757120952		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 7.549180757120952 | validation: 4.92897689156]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8162088207238165		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 5.8162088207238165 | validation: 6.104870088277903]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.191535788367054		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 6.191535788367054 | validation: 6.648935198189833]
	TIME [epoch: 24.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.710899971672106		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 6.710899971672106 | validation: 6.597352889898196]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5041799070019914		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 6.5041799070019914 | validation: 7.505004350779715]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.082534164933648		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 8.082534164933648 | validation: 9.021076989653313]
	TIME [epoch: 24.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.387395991274442		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 8.387395991274442 | validation: 8.570024848180324]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.495242845260913		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 7.495242845260913 | validation: 6.594815508832396]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.368120509102798		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 6.368120509102798 | validation: 7.582107477219584]
	TIME [epoch: 24.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.580266952183607		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 8.580266952183607 | validation: 8.600826933664257]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.280234371497762		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 7.280234371497762 | validation: 6.830541284208107]
	TIME [epoch: 24.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.340181810560785		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 6.340181810560785 | validation: 6.111182432375281]
	TIME [epoch: 24.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.716933018069979		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 5.716933018069979 | validation: 5.757689725125971]
	TIME [epoch: 24.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.520895481111012		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 5.520895481111012 | validation: 5.580153425495212]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.277691191859459		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 5.277691191859459 | validation: 5.44204931656664]
	TIME [epoch: 24.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.965990944938462		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.965990944938462 | validation: 5.0184183197672]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.544334635414888		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.544334635414888 | validation: 4.249121330697785]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.161246006244846		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.161246006244846 | validation: 4.0551178260872245]
	TIME [epoch: 24.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.199734304132592		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.199734304132592 | validation: 4.591966351738038]
	TIME [epoch: 24.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.635870995571575		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 6.635870995571575 | validation: 9.518746849291947]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.022249609328162		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 9.022249609328162 | validation: 8.56659364943765]
	TIME [epoch: 24.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.363226634684322		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 6.363226634684322 | validation: 6.7825302987613325]
	TIME [epoch: 24.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.82569611176044		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 7.82569611176044 | validation: 6.226899376131148]
	TIME [epoch: 24.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.658428027318436		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 7.658428027318436 | validation: 8.078438221040148]
	TIME [epoch: 24.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.366723289313086		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 10.366723289313086 | validation: 8.963780191460023]
	TIME [epoch: 24.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.600730041017815		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 9.600730041017815 | validation: 11.216272439383534]
	TIME [epoch: 24.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.794255296823861		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 9.794255296823861 | validation: 7.034927140248885]
	TIME [epoch: 24.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.6970917062876785		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 7.6970917062876785 | validation: 7.3491330547577505]
	TIME [epoch: 24.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.725280738152156		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 11.725280738152156 | validation: 10.614178479484263]
	TIME [epoch: 24.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.721846052333891		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 9.721846052333891 | validation: 7.968341690387194]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.36125990523185		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 9.36125990523185 | validation: 14.243720122099683]
	TIME [epoch: 24.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 14.295868660927207		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 14.295868660927207 | validation: 13.962964942674123]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.766267183594149		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 11.766267183594149 | validation: 9.90744315388194]
	TIME [epoch: 24.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.59100547664726		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 9.59100547664726 | validation: 9.63625721562802]
	TIME [epoch: 24.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.879621720986075		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 9.879621720986075 | validation: 9.664901114871197]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.700490041302704		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 9.700490041302704 | validation: 9.270229453016553]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.74059549107366		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 9.74059549107366 | validation: 9.65158436668129]
	TIME [epoch: 24.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.795896696708944		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 9.795896696708944 | validation: 9.514522835112588]
	TIME [epoch: 24.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.613533325927838		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 9.613533325927838 | validation: 9.134739113188571]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.127361136645453		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 9.127361136645453 | validation: 8.503330129879483]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.852004622579024		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 8.852004622579024 | validation: 8.637297340776131]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.081581701356361		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 9.081581701356361 | validation: 8.501668990794158]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.132038633020555		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 9.132038633020555 | validation: 9.833867249155869]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.780342437323192		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 10.780342437323192 | validation: 12.006803790670078]
	TIME [epoch: 24.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.684331301704184		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 13.684331301704184 | validation: 10.809914219160355]
	TIME [epoch: 24.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.847801796504015		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 10.847801796504015 | validation: 13.059667321312316]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.910885808940893		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 13.910885808940893 | validation: 14.025135931632951]
	TIME [epoch: 24.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.24353898254222		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 12.24353898254222 | validation: 10.316744552358474]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.958135060524198		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 11.958135060524198 | validation: 14.453380511179198]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 14.14378671088038		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 14.14378671088038 | validation: 13.841607402286304]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 14.445052675147029		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 14.445052675147029 | validation: 13.807762218483546]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.596450314567422		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 13.596450314567422 | validation: 9.915856251493365]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.601048819141532		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 9.601048819141532 | validation: 8.591538043837254]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.30387707902226		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 8.30387707902226 | validation: 8.707648947779346]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.404229118898733		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 8.404229118898733 | validation: 8.303560263907137]
	TIME [epoch: 24.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.301019685578012		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 8.301019685578012 | validation: 8.624427268205046]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.561291622096004		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 8.561291622096004 | validation: 9.308916119553249]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.86559332842527		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 8.86559332842527 | validation: 9.299027767193264]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.416763934704214		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 8.416763934704214 | validation: 8.353408214443142]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.31016616601529		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 8.31016616601529 | validation: 9.996781670425001]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.53755881669997		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 11.53755881669997 | validation: 12.469811918329079]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.340627230717539		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 11.340627230717539 | validation: 9.4600304698937]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.876118949314442		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 8.876118949314442 | validation: 8.912680864589639]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.758031522102325		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 8.758031522102325 | validation: 10.236813269919034]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.822029704775481		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 10.822029704775481 | validation: 11.470561772641123]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.193168885133066		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 11.193168885133066 | validation: 11.497829136948628]
	TIME [epoch: 24.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 13.192950999134485		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 13.192950999134485 | validation: 13.893860840125404]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.426739831025046		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 12.426739831025046 | validation: 12.3243145604827]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.15183715934745		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 11.15183715934745 | validation: 7.767984230173539]
	TIME [epoch: 24.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.159437959790345		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 9.159437959790345 | validation: 9.585943695995903]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.946497743816034		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 9.946497743816034 | validation: 9.227829713056234]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.589874848358901		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 10.589874848358901 | validation: 10.719102889427013]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.01059411663707		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 11.01059411663707 | validation: 11.11317423186842]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.62312156031205		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 10.62312156031205 | validation: 8.069300508492192]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.766165064102278		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 9.766165064102278 | validation: 12.220009136269244]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.01018744050135		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 9.01018744050135 | validation: 5.939692115862642]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.961872457906235		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 8.961872457906235 | validation: 6.346297236409114]
	TIME [epoch: 24.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.417149274250333		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 7.417149274250333 | validation: 8.21442637449792]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.613008633581396		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 9.613008633581396 | validation: 6.385172644191019]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.921397590061153		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 6.921397590061153 | validation: 7.125806870371133]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.754901585498242		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 9.754901585498242 | validation: 9.94117108336449]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.198495347867684		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 10.198495347867684 | validation: 9.927783657432824]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.35107033754526		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 10.35107033754526 | validation: 10.32227945945201]
	TIME [epoch: 24.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.579287990821813		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 10.579287990821813 | validation: 9.661075259630278]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.38712467984975		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 10.38712467984975 | validation: 10.666148955066774]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.960918212615713		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 10.960918212615713 | validation: 10.310749455533479]
	TIME [epoch: 24.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.591105765306905		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 9.591105765306905 | validation: 8.501624321830302]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.547760970058793		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 8.547760970058793 | validation: 7.900909337921744]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.380202339527507		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 8.380202339527507 | validation: 7.763587147878516]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.294958252294443		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 8.294958252294443 | validation: 7.819657110295021]
	TIME [epoch: 24.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.745655423792496		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 7.745655423792496 | validation: 5.775098992337371]
	TIME [epoch: 24.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7178084984997		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 5.7178084984997 | validation: 4.797319741119947]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.079356633085434		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 5.079356633085434 | validation: 4.640200346460629]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.811898646907728		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 4.811898646907728 | validation: 4.645289224718681]
	TIME [epoch: 24.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.593584287386979		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.593584287386979 | validation: 4.67083099203081]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.688046731318289		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 4.688046731318289 | validation: 4.354555130093794]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.378848045855782		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 4.378848045855782 | validation: 4.543258467033535]
	TIME [epoch: 24.8 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.462542893828786		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.462542893828786 | validation: 4.577208469827033]
	TIME [epoch: 24.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.476328837824027		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 4.476328837824027 | validation: 4.358612362406063]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.818842577581771		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 4.818842577581771 | validation: 4.712516360289168]
	TIME [epoch: 24.8 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8865951805891354		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.8865951805891354 | validation: 4.434614734555724]
	TIME [epoch: 24.8 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.398329983096728		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.398329983096728 | validation: 4.17370337056186]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.074990424410906		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.074990424410906 | validation: 4.274660470567385]
	TIME [epoch: 24.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.548629206230999		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 5.548629206230999 | validation: 6.4857821438896535]
	TIME [epoch: 24.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.944190064471776		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.944190064471776 | validation: 3.9047249370562374]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.271665560973521		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.271665560973521 | validation: 4.21531979491665]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.182167220701523		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.182167220701523 | validation: 4.6753603012605325]
	TIME [epoch: 24.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.465675289411632		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.465675289411632 | validation: 3.9409299258905106]
	TIME [epoch: 24.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.215789100944336		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.215789100944336 | validation: 4.489445333598794]
	TIME [epoch: 24.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.336827337104648		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.336827337104648 | validation: 3.9785580298461753]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.083560629845792		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.083560629845792 | validation: 3.997179634589688]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.919441667709032		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.919441667709032 | validation: 3.8845939253968864]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.307412647195731		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 4.307412647195731 | validation: 4.510435083178144]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9549154503351116		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.9549154503351116 | validation: 3.8505151169833494]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.960861357429459		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.960861357429459 | validation: 4.825473815255799]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2184790567707555		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 6.2184790567707555 | validation: 5.706892217534682]
	TIME [epoch: 24.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4170309386764215		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.4170309386764215 | validation: 3.723302478664044]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.772094375396228		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.772094375396228 | validation: 3.7034070564193122]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.877952635000681		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.877952635000681 | validation: 4.006331918943531]
	TIME [epoch: 24.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035306027031901		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 4.035306027031901 | validation: 4.537790286522834]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.985543948813148		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.985543948813148 | validation: 3.5407242148402935]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7025067266005065		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.7025067266005065 | validation: 3.5273287073259234]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7359160084475986		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.7359160084475986 | validation: 3.4845511824120536]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8146016064687513		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.8146016064687513 | validation: 3.84006312851246]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.205502153039744		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 4.205502153039744 | validation: 4.461782961135859]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.237819176661161		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 4.237819176661161 | validation: 3.6244201214887686]
	TIME [epoch: 24.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.721200716865172		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.721200716865172 | validation: 3.6980732352313215]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.736270304961109		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.736270304961109 | validation: 3.9444594624556135]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7108038946554305		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.7108038946554305 | validation: 3.550270474661548]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.832349400176066		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.832349400176066 | validation: 4.123949185464327]
	TIME [epoch: 24.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7529447936260913		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.7529447936260913 | validation: 3.6456882268960804]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.608499647806339		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 3.608499647806339 | validation: 3.6697815619882306]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5157007765598767		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.5157007765598767 | validation: 3.6780210788146874]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.711881848252797		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.711881848252797 | validation: 3.594830862758729]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.620062165402953		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.620062165402953 | validation: 4.133345837516192]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.510603513586144		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 6.510603513586144 | validation: 10.828980934740187]
	TIME [epoch: 24.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.290689196365793		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 9.290689196365793 | validation: 7.734681705851196]
	TIME [epoch: 24.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.66157015512106		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 8.66157015512106 | validation: 11.179175346809084]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.64764173135863		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 10.64764173135863 | validation: 9.692219393042695]
	TIME [epoch: 24.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.198946770331396		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 7.198946770331396 | validation: 6.227595145315802]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.283271490880518		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 5.283271490880518 | validation: 4.608017586905196]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.901527739368928		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.901527739368928 | validation: 4.979493508935449]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.483206086264672		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 6.483206086264672 | validation: 8.243330958458126]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.676623639118306		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 7.676623639118306 | validation: 8.255946411283917]
	TIME [epoch: 24.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.940821486781866		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 8.940821486781866 | validation: 10.609425144336601]
	TIME [epoch: 24.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.991664925382928		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 9.991664925382928 | validation: 9.23115520463909]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.718763741628177		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 8.718763741628177 | validation: 9.317047065502395]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.752835824876534		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 8.752835824876534 | validation: 8.921184730766676]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.115290092051415		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 8.115290092051415 | validation: 7.748761286141643]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.601122891364412		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 7.601122891364412 | validation: 7.679424634423526]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3053222371704205		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 7.3053222371704205 | validation: 9.035173197243337]
	TIME [epoch: 24.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.336770666107219		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 8.336770666107219 | validation: 8.04996633452058]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.402594919750996		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 8.402594919750996 | validation: 8.773332350665852]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.731475192840785		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 6.731475192840785 | validation: 5.585040892760819]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558924045567088		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 5.558924045567088 | validation: 7.553427704085439]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.0236352435836		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 9.0236352435836 | validation: 11.585924619111761]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.789682927157518		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 10.789682927157518 | validation: 9.877666647428507]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.984641742474336		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 8.984641742474336 | validation: 8.371487208124885]
	TIME [epoch: 24.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.938818012473858		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 7.938818012473858 | validation: 8.591314220983696]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.780445652674148		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 8.780445652674148 | validation: 9.369146037842397]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.39787459058187		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 9.39787459058187 | validation: 9.92805951983]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.8937413467658		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 9.8937413467658 | validation: 9.762691084953515]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.55895479547151		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 9.55895479547151 | validation: 9.349990224789188]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.06882149964292		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 9.06882149964292 | validation: 8.890342356190036]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.407738633698298		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 8.407738633698298 | validation: 8.667254248640063]
	TIME [epoch: 24.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.16981637353256		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 8.16981637353256 | validation: 8.962503693275414]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.384727109307223		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 8.384727109307223 | validation: 8.967544272949967]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.005515060653837		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 9.005515060653837 | validation: 10.448586630455102]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.286496166944723		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 9.286496166944723 | validation: 9.189329729787437]
	TIME [epoch: 24.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.479684407269403		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 8.479684407269403 | validation: 9.117075145838777]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.812628185009613		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 8.812628185009613 | validation: 8.987409632546774]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.23757061108715		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 8.23757061108715 | validation: 7.381582062480609]
	TIME [epoch: 24.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.731842754963922		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 5.731842754963922 | validation: 5.775594417114194]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.91067061735893		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 4.91067061735893 | validation: 4.43497280766515]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.189605955832107		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 4.189605955832107 | validation: 4.619909644842637]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.160911177359246		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 4.160911177359246 | validation: 4.294397401745072]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9242108106248		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.9242108106248 | validation: 3.7307546404384153]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.736696508017264		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.736696508017264 | validation: 3.9474623392308503]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.875501405571649		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.875501405571649 | validation: 3.9790107751190056]
	TIME [epoch: 24.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6841135399692204		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.6841135399692204 | validation: 3.684067335088209]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7335473510293182		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.7335473510293182 | validation: 3.951750240084964]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9473613264085747		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.9473613264085747 | validation: 4.1850166184903195]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.954614244500717		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.954614244500717 | validation: 3.612595393993829]
	TIME [epoch: 24.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.713861979477967		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.713861979477967 | validation: 3.7869831889337107]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8699638974734984		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.8699638974734984 | validation: 3.6456833305896397]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5476322520326926		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.5476322520326926 | validation: 3.735182996608545]
	TIME [epoch: 24.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457212844171842		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.457212844171842 | validation: 3.3248005513190244]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3201988531439364		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.3201988531439364 | validation: 5.042000525035024]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.918659298224987		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 4.918659298224987 | validation: 3.9881953898043547]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4851313617080364		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.4851313617080364 | validation: 4.524022011471415]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7188136475044398		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.7188136475044398 | validation: 3.3000342861655105]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.569284518359069		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.569284518359069 | validation: 3.321796927012756]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207120148737762		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.207120148737762 | validation: 3.442830870973145]
	TIME [epoch: 24.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4216202326085003		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.4216202326085003 | validation: 3.9546549240703213]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.518041556682208		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.518041556682208 | validation: 3.17674393058974]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.165406546157009		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 3.165406546157009 | validation: 3.0887641509772146]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0729029590827643		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 3.0729029590827643 | validation: 3.5470836391114493]
	TIME [epoch: 24.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1763755445847583		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 3.1763755445847583 | validation: 3.019809033287369]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.031127980620293		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 3.031127980620293 | validation: 3.6162996958135953]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.47803583357949		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 4.47803583357949 | validation: 3.921731809822288]
	TIME [epoch: 24.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28447548295983		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.28447548295983 | validation: 3.3423154370268024]
	TIME [epoch: 24.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.134419988824105		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.134419988824105 | validation: 2.877691472233546]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0195793513662226		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.0195793513662226 | validation: 3.046385238372665]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.910816726251829		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.910816726251829 | validation: 2.716741660793736]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9146057110287193		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.9146057110287193 | validation: 3.0051687063919754]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8553595271015304		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.8553595271015304 | validation: 3.0586746093484476]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8079906183246974		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 2.8079906183246974 | validation: 2.763285737194753]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6534585176607437		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.6534585176607437 | validation: 2.7584864010097827]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8214593026418804		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.8214593026418804 | validation: 3.052610560568609]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8708615707727034		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.8708615707727034 | validation: 2.9251331033442707]
	TIME [epoch: 24.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5937472644791013		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.5937472644791013 | validation: 2.7943750412123474]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8237347888199498		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.8237347888199498 | validation: 2.6027135509755475]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5413332108414295		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.5413332108414295 | validation: 2.4873881331167347]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449425017886071		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 2.449425017886071 | validation: 2.6592699813526015]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.494616819048482		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.494616819048482 | validation: 4.5061577625114]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6745569988383515		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.6745569988383515 | validation: 2.587136146649964]
	TIME [epoch: 24.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.86396872304353		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.86396872304353 | validation: 2.973707300555597]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.644191997090949		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.644191997090949 | validation: 2.3637867601688796]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2681893412996965		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.2681893412996965 | validation: 2.628771457603856]
	TIME [epoch: 24.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3618179089324256		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.3618179089324256 | validation: 2.330104859710674]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4480555598417957		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 2.4480555598417957 | validation: 2.3454545354010983]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4762911709641315		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.4762911709641315 | validation: 2.8211036207200904]
	TIME [epoch: 24.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.802313657491845		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.802313657491845 | validation: 2.461860767126039]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3527842654502136		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.3527842654502136 | validation: 2.351686879044379]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452999611410478		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 2.452999611410478 | validation: 2.7131887413299216]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9489501604899813		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.9489501604899813 | validation: 2.8758807154254793]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.600638587188948		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 2.600638587188948 | validation: 2.469240416606525]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3746188464307236		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.3746188464307236 | validation: 2.2248033219491963]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.268200288049142		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.268200288049142 | validation: 2.1064197022968]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3999241653653236		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.3999241653653236 | validation: 2.3271667344285105]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.217567994502284		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.217567994502284 | validation: 2.2633450621043374]
	TIME [epoch: 24.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.510893881958938		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 2.510893881958938 | validation: 2.237952204064747]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234077162094164		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.234077162094164 | validation: 2.1720012194083056]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1502460502670537		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 2.1502460502670537 | validation: 2.3270222523475796]
	TIME [epoch: 24.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0891326075236853		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.0891326075236853 | validation: 2.4861201076325883]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1550287835410122		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 2.1550287835410122 | validation: 2.317629891459997]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1111058746760643		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.1111058746760643 | validation: 2.2571132827164635]
	TIME [epoch: 24.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2764464064663246		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.2764464064663246 | validation: 2.2651337293317564]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8321429060749104		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 2.8321429060749104 | validation: 2.1397273725348382]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9565898387099323		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.9565898387099323 | validation: 2.3254970452730883]
	TIME [epoch: 24.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.535297253316796		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 2.535297253316796 | validation: 2.2978110354030883]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1194062348731544		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.1194062348731544 | validation: 2.566324074424458]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1124048759956873		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 2.1124048759956873 | validation: 2.0494639001205006]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_341.pth
	Model improved!!!
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9493464185270115		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.9493464185270115 | validation: 2.4191286713918356]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1356344451806657		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 2.1356344451806657 | validation: 2.6001705112124696]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.248291329202754		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 2.248291329202754 | validation: 2.6058738166087414]
	TIME [epoch: 24.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3765138004263506		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.3765138004263506 | validation: 2.004064672875365]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.08816876982944		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 2.08816876982944 | validation: 2.083625121145935]
	TIME [epoch: 24.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.155513842927597		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.155513842927597 | validation: 2.225756956070527]
	TIME [epoch: 24.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9103413225322403		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.9103413225322403 | validation: 1.944375201154087]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9338266949258804		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.9338266949258804 | validation: 2.014784649890111]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.027939194617381		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.027939194617381 | validation: 2.5394295969806087]
	TIME [epoch: 24.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9469935887470726		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.9469935887470726 | validation: 2.0112318342609794]
	TIME [epoch: 24.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8823994110786986		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.8823994110786986 | validation: 1.9789620675296582]
	TIME [epoch: 24.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7605710734225775		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.7605710734225775 | validation: 2.3832352738808855]
	TIME [epoch: 24.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.16521581018824		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.16521581018824 | validation: 2.1670315894156396]
	TIME [epoch: 24.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9344155627709165		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.9344155627709165 | validation: 2.455261810730338]
	TIME [epoch: 24.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0445181376081454		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 2.0445181376081454 | validation: 2.513373824056449]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.890184556599485		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.890184556599485 | validation: 1.8145676978852265]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8417309420292698		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.8417309420292698 | validation: 2.4081440074605673]
	TIME [epoch: 24.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.480527926581857		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.480527926581857 | validation: 3.0602864283712177]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39040423561615		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 2.39040423561615 | validation: 2.618854579111197]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1671213337599613		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 2.1671213337599613 | validation: 2.3109994617778007]
	TIME [epoch: 24.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8310942518165472		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.8310942518165472 | validation: 2.378207573686559]
	TIME [epoch: 24.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.079159045302836		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.079159045302836 | validation: 2.281619805931795]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.094341775516081		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.094341775516081 | validation: 2.5223293542400107]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8459517165400463		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.8459517165400463 | validation: 1.8304328915069994]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7170322688429123		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.7170322688429123 | validation: 3.3564072382988175]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5308610054317153		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 2.5308610054317153 | validation: 2.0438714242004976]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9719764356008502		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.9719764356008502 | validation: 1.6939859580743137]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7034256218119133		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.7034256218119133 | validation: 2.296323494463272]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8150337223103972		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.8150337223103972 | validation: 1.6451097070815366]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.481501082071163		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.481501082071163 | validation: 1.7569163713509717]
	TIME [epoch: 24.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8068825552357		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.8068825552357 | validation: 1.8193209602892537]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6209660115002609		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.6209660115002609 | validation: 2.0802813438564867]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7003002595269678		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.7003002595269678 | validation: 2.4140403160039]
	TIME [epoch: 24.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9177738922485137		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.9177738922485137 | validation: 1.8854390891354962]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.621528395333834		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.621528395333834 | validation: 2.377673693481339]
	TIME [epoch: 24.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7717814864992423		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.7717814864992423 | validation: 1.9977819602040279]
	TIME [epoch: 24.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5667858250461455		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.5667858250461455 | validation: 1.6340377176832335]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7460918612243836		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.7460918612243836 | validation: 1.7255998674098942]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6337258778937167		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.6337258778937167 | validation: 1.6092739009633141]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5313209018397096		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.5313209018397096 | validation: 1.6601845991895616]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4562232812353755		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.4562232812353755 | validation: 1.9391165521813198]
	TIME [epoch: 24.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6763581283967723		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.6763581283967723 | validation: 1.965657516225156]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6819486992843633		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.6819486992843633 | validation: 1.7554441455140517]
	TIME [epoch: 24.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.539004404025585		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.539004404025585 | validation: 1.6960895530106779]
	TIME [epoch: 24.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5731365301296694		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.5731365301296694 | validation: 2.2146278095981042]
	TIME [epoch: 24.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9621006627917774		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.9621006627917774 | validation: 1.756752280094206]
	TIME [epoch: 24.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4992963280962095		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.4992963280962095 | validation: 1.7832070545635694]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.603702692983708		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.603702692983708 | validation: 2.061698094102308]
	TIME [epoch: 24.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5917624051811134		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.5917624051811134 | validation: 2.1953038231780004]
	TIME [epoch: 24.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8169467468966025		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.8169467468966025 | validation: 1.7570517257203415]
	TIME [epoch: 24.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6522044506778322		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.6522044506778322 | validation: 1.6507597946685446]
	TIME [epoch: 24.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.688305323091729		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.688305323091729 | validation: 1.584110851364785]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4223413125079072		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.4223413125079072 | validation: 1.9037597592814002]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.720290808087507		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.720290808087507 | validation: 1.8400371496940173]
	TIME [epoch: 24.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5154791099518614		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.5154791099518614 | validation: 1.487876411997008]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4007049804660368		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.4007049804660368 | validation: 1.7073619226896426]
	TIME [epoch: 24.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3460997979260418		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.3460997979260418 | validation: 1.7176484748795702]
	TIME [epoch: 24.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6131863545866914		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.6131863545866914 | validation: 1.9792485606182806]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7778888339465047		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.7778888339465047 | validation: 2.876260421544913]
	TIME [epoch: 24.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9219208358622297		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.9219208358622297 | validation: 1.9317421989956252]
	TIME [epoch: 24.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4637370135315084		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.4637370135315084 | validation: 1.6115694644787875]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4840370202037048		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.4840370202037048 | validation: 1.5798978038862117]
	TIME [epoch: 24.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.330161288176746		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.330161288176746 | validation: 1.4747261130369538]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_404.pth
	Model improved!!!
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3414355155718103		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.3414355155718103 | validation: 1.6220746757605036]
	TIME [epoch: 24.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5791039395526951		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.5791039395526951 | validation: 1.7873475396637981]
	TIME [epoch: 24.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6186893083944909		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.6186893083944909 | validation: 1.8709358777541867]
	TIME [epoch: 24.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436974002410875		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.436974002410875 | validation: 1.5453027956162408]
	TIME [epoch: 24.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3411464319186897		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3411464319186897 | validation: 1.5366341883074404]
	TIME [epoch: 24.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5235785546583989		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.5235785546583989 | validation: 1.7640204316796693]
	TIME [epoch: 24.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6046913107777003		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.6046913107777003 | validation: 1.4752154674058604]
	TIME [epoch: 24.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6671786195389453		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.6671786195389453 | validation: 2.360976418785757]
	TIME [epoch: 24.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.949902591657905		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.949902591657905 | validation: 1.9160996839395084]
	TIME [epoch: 24.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6770420654461862		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.6770420654461862 | validation: 1.9212712751803165]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6743289568214554		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.6743289568214554 | validation: 1.9839603687209135]
	TIME [epoch: 24.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6607404665700916		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.6607404665700916 | validation: 2.2365904014391957]
	TIME [epoch: 24.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6245343781598924		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.6245343781598924 | validation: 1.7876974174955935]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463904967727595		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.463904967727595 | validation: 1.6886167075394398]
	TIME [epoch: 24.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.598648250985371		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.598648250985371 | validation: 1.5512158528981876]
	TIME [epoch: 24.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4318973918341462		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.4318973918341462 | validation: 1.996689648510974]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8087689394177677		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.8087689394177677 | validation: 2.3074714395544]
	TIME [epoch: 24.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6318718230351352		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.6318718230351352 | validation: 1.832491782914217]
	TIME [epoch: 24.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4343917539914617		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.4343917539914617 | validation: 1.5889497336709826]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436440152728395		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.436440152728395 | validation: 1.6935428145448093]
	TIME [epoch: 24.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3627686953280258		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.3627686953280258 | validation: 1.6506558430661389]
	TIME [epoch: 24.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7308339822114087		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.7308339822114087 | validation: 1.4947480324006819]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7815002025111766		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.7815002025111766 | validation: 1.5754461715922048]
	TIME [epoch: 24.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4749440058324437		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.4749440058324437 | validation: 1.410613751348805]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5296909355963728		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.5296909355963728 | validation: 1.5937526035897158]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5767996098330166		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.5767996098330166 | validation: 1.7111601344898606]
	TIME [epoch: 24.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.38724642271545		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.38724642271545 | validation: 1.6006944497985125]
	TIME [epoch: 24.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3098262466095965		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.3098262466095965 | validation: 2.1670666429251573]
	TIME [epoch: 24.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.87735242970022		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.87735242970022 | validation: 2.177210693718714]
	TIME [epoch: 24.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.793830796547042		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.793830796547042 | validation: 1.6953787374736289]
	TIME [epoch: 24.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.358369955933167		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.358369955933167 | validation: 1.3998684140026216]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3440238139622016		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.3440238139622016 | validation: 1.7167621696803474]
	TIME [epoch: 24.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3205598992078749		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.3205598992078749 | validation: 1.6594022093214558]
	TIME [epoch: 24.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4066015156568614		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.4066015156568614 | validation: 2.042456870002304]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4795714976400662		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.4795714976400662 | validation: 1.5325779536440205]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2034431403759767		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.2034431403759767 | validation: 1.4613279349823904]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.204130026108237		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.204130026108237 | validation: 2.1931170836983553]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.674665055760668		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.674665055760668 | validation: 1.3303137807049228]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2729905321337192		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.2729905321337192 | validation: 1.354711466623117]
	TIME [epoch: 24.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1968382873484975		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.1968382873484975 | validation: 1.4729989789773965]
	TIME [epoch: 24.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4474428210028965		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.4474428210028965 | validation: 1.7117130614617855]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5835343826051511		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.5835343826051511 | validation: 1.6329898802903764]
	TIME [epoch: 24.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.547647109348873		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.547647109348873 | validation: 1.700733654743063]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.437512798373351		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.437512798373351 | validation: 1.4004779363213171]
	TIME [epoch: 24.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3427179530673434		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.3427179530673434 | validation: 1.8493324300675524]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.501811522100434		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.501811522100434 | validation: 1.5429324808366063]
	TIME [epoch: 24.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364099132129176		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.364099132129176 | validation: 1.3604142215152786]
	TIME [epoch: 24.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2395014183576962		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.2395014183576962 | validation: 1.480385588358189]
	TIME [epoch: 24.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2106985497823848		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.2106985497823848 | validation: 1.4972504669465578]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.322877026283848		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.322877026283848 | validation: 2.1028067324291717]
	TIME [epoch: 24.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5925471880777693		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.5925471880777693 | validation: 1.273513566590798]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1528894190362193		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.1528894190362193 | validation: 1.449496990746411]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1850162791975882		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.1850162791975882 | validation: 1.3279891736467846]
	TIME [epoch: 24.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1064296708069232		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.1064296708069232 | validation: 1.4638424078625962]
	TIME [epoch: 24.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160750930062839		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.160750930062839 | validation: 1.2896080816158366]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1750687978283407		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.1750687978283407 | validation: 1.2079030416732988]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1388648559424286		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.1388648559424286 | validation: 1.2854911237646314]
	TIME [epoch: 24.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1215437204992138		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.1215437204992138 | validation: 1.4804034705532088]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.224263086110957		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.224263086110957 | validation: 1.2318421770983856]
	TIME [epoch: 24.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.138718911675213		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.138718911675213 | validation: 1.306555979683379]
	TIME [epoch: 24.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542611364347681		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.1542611364347681 | validation: 1.712275162659251]
	TIME [epoch: 24.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4986070676000027		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.4986070676000027 | validation: 1.3528329442519367]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.337105856173216		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.337105856173216 | validation: 1.5416203186924928]
	TIME [epoch: 24.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2679542814063745		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.2679542814063745 | validation: 1.4370709358953293]
	TIME [epoch: 24.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232860012050304		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.232860012050304 | validation: 2.0472925621444973]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0549928886239215		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 2.0549928886239215 | validation: 5.165612001048727]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.56846330004384		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 3.56846330004384 | validation: 2.332842224433001]
	TIME [epoch: 24.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8598080137135178		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.8598080137135178 | validation: 1.6972303252163297]
	TIME [epoch: 24.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4562236798691852		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.4562236798691852 | validation: 1.499441848823841]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4054441107343962		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.4054441107343962 | validation: 1.6914827647304294]
	TIME [epoch: 24.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3757880756328358		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.3757880756328358 | validation: 1.657891531029269]
	TIME [epoch: 24.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2230938126311353		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.2230938126311353 | validation: 1.453020740613352]
	TIME [epoch: 24.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2430915248497056		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.2430915248497056 | validation: 1.3168543086658273]
	TIME [epoch: 24.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3401912769939968		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.3401912769939968 | validation: 1.3591313139550598]
	TIME [epoch: 24.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3589849660513371		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.3589849660513371 | validation: 2.0725386068487643]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6137652574905215		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.6137652574905215 | validation: 2.4794489257734362]
	TIME [epoch: 24.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7222783147176677		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.7222783147176677 | validation: 1.774928609730697]
	TIME [epoch: 24.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3617907913789953		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.3617907913789953 | validation: 1.421328754685919]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.416302735762212		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.416302735762212 | validation: 1.7115216941100084]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4406950483821106		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.4406950483821106 | validation: 1.4572328568398087]
	TIME [epoch: 24.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.316022786199671		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.316022786199671 | validation: 1.9188485695517796]
	TIME [epoch: 24.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3787688049872784		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.3787688049872784 | validation: 1.3298684843269508]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1209914638832768		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.1209914638832768 | validation: 1.394741231889439]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2058610482773764		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.2058610482773764 | validation: 1.4680238582262066]
	TIME [epoch: 24.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1781303771508331		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.1781303771508331 | validation: 1.840806587709231]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3947046398254561		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.3947046398254561 | validation: 1.8085328157575327]
	TIME [epoch: 24.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4090627250035133		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.4090627250035133 | validation: 1.8730776588855764]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.642612242285545		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.642612242285545 | validation: 1.5508016061896235]
	TIME [epoch: 24.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2866148109932896		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.2866148109932896 | validation: 1.477996298368625]
	TIME [epoch: 24.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.357041415758188		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.357041415758188 | validation: 1.3910462031856186]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3441639658012958		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.3441639658012958 | validation: 1.3707947104819602]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1575823288793963		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.1575823288793963 | validation: 1.3338521666671646]
	TIME [epoch: 24.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1769674752302997		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.1769674752302997 | validation: 1.2686775679714084]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0694691485876777		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.0694691485876777 | validation: 1.334043419674777]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806020060050742		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.2806020060050742 | validation: 1.5224736475364193]
	TIME [epoch: 24.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.544032323205931		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 2.544032323205931 | validation: 2.4576053903739274]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7888663265191036		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.7888663265191036 | validation: 2.0081606937437413]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5539967339988883		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.5539967339988883 | validation: 1.5248192465093655]
	TIME [epoch: 24.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3485666318568765		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.3485666318568765 | validation: 1.2906723890284753]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2214858909769317		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.2214858909769317 | validation: 1.2366418945911644]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703144033523762		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.1703144033523762 | validation: 1.324240554689511]
	TIME [epoch: 24.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2267563469853564		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.2267563469853564 | validation: 1.2308938077114495]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1735919508781918		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.1735919508781918 | validation: 1.12108117505233]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_507.pth
	Model improved!!!
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0906773344554397		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.0906773344554397 | validation: 1.119986144625855]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.120898781905484		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.120898781905484 | validation: 1.4510513335750153]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2248168740421717		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.2248168740421717 | validation: 1.2674420406791875]
	TIME [epoch: 24.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2139435094170503		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.2139435094170503 | validation: 1.3982854006808925]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1312987702096706		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.1312987702096706 | validation: 1.157240705945563]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0898669014448754		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.0898669014448754 | validation: 1.9384180198702587]
	TIME [epoch: 24.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5530441145898168		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.5530441145898168 | validation: 1.435979668335803]
	TIME [epoch: 24.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2818845911784829		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.2818845911784829 | validation: 1.2982733015895414]
	TIME [epoch: 24.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1782966002810225		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.1782966002810225 | validation: 1.4618629942167027]
	TIME [epoch: 24.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.482572932505125		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.482572932505125 | validation: 1.5096257761968945]
	TIME [epoch: 24.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1072272771466998		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.1072272771466998 | validation: 1.401105773081606]
	TIME [epoch: 24.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2232745781179177		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.2232745781179177 | validation: 1.5214919454923381]
	TIME [epoch: 24.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3704083060459609		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.3704083060459609 | validation: 1.3103519262653038]
	TIME [epoch: 24.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1597728052052598		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.1597728052052598 | validation: 1.0979701606353793]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0750571724863367		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.0750571724863367 | validation: 1.182356038364133]
	TIME [epoch: 24.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2301989859884088		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.2301989859884088 | validation: 1.2919852640240606]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.192519178443621		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.192519178443621 | validation: 1.4482182361773437]
	TIME [epoch: 24.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3780730228823455		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 1.3780730228823455 | validation: 1.4440679781398564]
	TIME [epoch: 24.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1762096173591874		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.1762096173591874 | validation: 1.1576856706034229]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621191675837165		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.0621191675837165 | validation: 1.1353650653961942]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.204318253808451		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.204318253808451 | validation: 1.2369678476075632]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3540174252557475		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.3540174252557475 | validation: 1.616664231067999]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2683216911991249		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.2683216911991249 | validation: 1.2869930321294578]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2367828777150702		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.2367828777150702 | validation: 1.3589829850118162]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0944527736474468		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.0944527736474468 | validation: 1.1748179798441774]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0685614226555464		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.0685614226555464 | validation: 1.7957453525614673]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4754752804551963		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.4754752804551963 | validation: 1.2943759129584895]
	TIME [epoch: 24.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9902615712044691		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.9902615712044691 | validation: 1.1678243703952556]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9705854165549337		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.9705854165549337 | validation: 1.173487862235299]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9544248494211802		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.9544248494211802 | validation: 1.1553658784321506]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146348408349924		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 1.146348408349924 | validation: 1.261932998793459]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0655368708135748		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.0655368708135748 | validation: 1.0849576616378946]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_539.pth
	Model improved!!!
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0060153281434157		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.0060153281434157 | validation: 1.0365600599237734]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9289440780425701		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.9289440780425701 | validation: 1.068392264637078]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9087179050717109		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.9087179050717109 | validation: 1.081857022449075]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9770642019994391		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.9770642019994391 | validation: 1.001612855649617]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_543.pth
	Model improved!!!
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9182928678202484		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.9182928678202484 | validation: 1.3818252379721536]
	TIME [epoch: 24.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.114193844026506		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.114193844026506 | validation: 1.2788997868816756]
	TIME [epoch: 24.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0151618388490529		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.0151618388490529 | validation: 1.1596066400795844]
	TIME [epoch: 24.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034035875122789		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.0034035875122789 | validation: 1.1123604458498502]
	TIME [epoch: 24.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0229906091241427		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.0229906091241427 | validation: 1.0041017768907812]
	TIME [epoch: 24.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.891483083357648		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.891483083357648 | validation: 1.073125843920872]
	TIME [epoch: 24.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9632073131505661		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.9632073131505661 | validation: 1.1221555268449106]
	TIME [epoch: 24.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371656851362447		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.0371656851362447 | validation: 1.195658583567355]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9105188955091316		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.9105188955091316 | validation: 1.3272067866408974]
	TIME [epoch: 24.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1944220670217505		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.1944220670217505 | validation: 1.374925697314838]
	TIME [epoch: 24.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067361817272808		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.067361817272808 | validation: 1.0870036053303886]
	TIME [epoch: 24.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0422457657982476		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.0422457657982476 | validation: 1.200073483957101]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0612470041601203		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.0612470041601203 | validation: 1.0288735801921676]
	TIME [epoch: 24.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0097677017622817		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 1.0097677017622817 | validation: 1.227357875864474]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764233181641436		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.0764233181641436 | validation: 1.1732926461217137]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054787261198187		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.054787261198187 | validation: 1.155290091336712]
	TIME [epoch: 24.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1875466763057085		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.1875466763057085 | validation: 1.3242713740530394]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2255938370501318		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.2255938370501318 | validation: 1.397886044147294]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2110684870020125		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.2110684870020125 | validation: 1.139669272830995]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9858178172139385		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.9858178172139385 | validation: 1.2216125140024046]
	TIME [epoch: 24.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9922185701224298		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.9922185701224298 | validation: 1.140260781194853]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.122426490162612		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.122426490162612 | validation: 1.9190832308162054]
	TIME [epoch: 24.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480853877809836		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.480853877809836 | validation: 1.1885004027526054]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052172269229948		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.052172269229948 | validation: 1.1344109106825107]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0483038262673576		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.0483038262673576 | validation: 1.2029063397593909]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3240938363823158		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.3240938363823158 | validation: 1.9337118885140985]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.299279813458539		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.299279813458539 | validation: 1.2077156226505372]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008783067123432		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.008783067123432 | validation: 1.0114188174745744]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9824593058244687		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.9824593058244687 | validation: 1.0230777630720276]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.072264051712067		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.072264051712067 | validation: 1.4697000855255247]
	TIME [epoch: 24.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3011279977121726		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.3011279977121726 | validation: 1.2104628990112618]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1360716035853793		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.1360716035853793 | validation: 1.1112115375325844]
	TIME [epoch: 24.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.965466230090833		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.965466230090833 | validation: 1.0153121766235493]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9380311213242551		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.9380311213242551 | validation: 0.920390562384996]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8629062488462389		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.8629062488462389 | validation: 1.0048572197968029]
	TIME [epoch: 24.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9616310675067861		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.9616310675067861 | validation: 1.0845232918970464]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234205885841905		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.0234205885841905 | validation: 1.1698018788154705]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9732899269172637		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.9732899269172637 | validation: 0.9741331023626841]
	TIME [epoch: 24.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374008841924949		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.9374008841924949 | validation: 0.9427815831730197]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0592213499685608		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.0592213499685608 | validation: 1.0876283907560345]
	TIME [epoch: 24.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2214268221645628		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.2214268221645628 | validation: 1.1461024404150053]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0119144090628756		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.0119144090628756 | validation: 1.062309205198005]
	TIME [epoch: 24.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9361370934681682		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.9361370934681682 | validation: 1.3570421704881221]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041291529324151		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.041291529324151 | validation: 1.1110858069353478]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9831587245878632		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.9831587245878632 | validation: 1.0882527364447865]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0160394966497468		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.0160394966497468 | validation: 0.8856810868044641]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035738297006364		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.9035738297006364 | validation: 1.0681723418382807]
	TIME [epoch: 24.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9944430640166992		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.9944430640166992 | validation: 1.006725833611452]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9204421148399596		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.9204421148399596 | validation: 1.1764666733474027]
	TIME [epoch: 24.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022027240130174		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.022027240130174 | validation: 1.1834858969765913]
	TIME [epoch: 24.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566198305675321		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.1566198305675321 | validation: 0.9398617635549285]
	TIME [epoch: 24.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9783026406454709		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.9783026406454709 | validation: 1.2207376690950327]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0159926785364466		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.0159926785364466 | validation: 0.9230978869284963]
	TIME [epoch: 24.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8801628139341374		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.8801628139341374 | validation: 0.9620196208803597]
	TIME [epoch: 24.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938037962402785		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.8938037962402785 | validation: 0.8245425324023282]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0413752341704594		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.0413752341704594 | validation: 1.1447200772203332]
	TIME [epoch: 24.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0065550670938248		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 1.0065550670938248 | validation: 1.2314941786798042]
	TIME [epoch: 24.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.018180072891221		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.018180072891221 | validation: 0.88429054825299]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.82388678955882		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.82388678955882 | validation: 1.2033489917865836]
	TIME [epoch: 24.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032143133756057		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.032143133756057 | validation: 1.133115456650818]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8895272935634138		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.8895272935634138 | validation: 1.5790919062130753]
	TIME [epoch: 24.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2047703588125247		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 1.2047703588125247 | validation: 1.1480071225089776]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0067982857703268		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.0067982857703268 | validation: 1.1652824249363456]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292978073853315		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.9292978073853315 | validation: 1.0764203435624766]
	TIME [epoch: 24.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0396228928735805		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.0396228928735805 | validation: 1.113855822662909]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.911601747330426		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.911601747330426 | validation: 1.040745624972554]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0345170091824696		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.0345170091824696 | validation: 0.9088278281793168]
	TIME [epoch: 24.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8425052113174119		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.8425052113174119 | validation: 0.8643129527344721]
	TIME [epoch: 24.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8746288886923403		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.8746288886923403 | validation: 1.1501366154443293]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0344754143690582		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.0344754143690582 | validation: 0.8896755124764993]
	TIME [epoch: 24.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977638036751905		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7977638036751905 | validation: 0.9484395304119804]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8327454362273914		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.8327454362273914 | validation: 0.8247024357282183]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305600083837052		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.7305600083837052 | validation: 0.9807221140738202]
	TIME [epoch: 24.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.774622584492153		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.774622584492153 | validation: 1.0205612837750613]
	TIME [epoch: 24.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840324761420474		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.9840324761420474 | validation: 1.6309793068573433]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557609386459274		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 1.2557609386459274 | validation: 0.9641601765122474]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8824499760296551		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.8824499760296551 | validation: 0.8673263147457568]
	TIME [epoch: 24.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9316734339268155		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.9316734339268155 | validation: 0.8820126082239245]
	TIME [epoch: 24.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9355494837747528		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.9355494837747528 | validation: 0.9003523668030701]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337901115254983		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.9337901115254983 | validation: 1.1086944269339667]
	TIME [epoch: 24.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9086787541891275		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.9086787541891275 | validation: 1.5267189905652503]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1398111327817217		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.1398111327817217 | validation: 0.8742724307988508]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846846820074354		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.7846846820074354 | validation: 0.9617654121220619]
	TIME [epoch: 24.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.931779793589551		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.931779793589551 | validation: 1.0897815112557703]
	TIME [epoch: 24.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9562657180249561		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.9562657180249561 | validation: 0.8022373492392921]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.748737251999906		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.748737251999906 | validation: 0.7773425275155337]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_629.pth
	Model improved!!!
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.819361221015442		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.819361221015442 | validation: 0.8381465791617057]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500365144269767		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.7500365144269767 | validation: 0.7630801551618818]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.761331703716614		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.761331703716614 | validation: 0.7517559743688605]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592705231841345		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.7592705231841345 | validation: 0.7443920444957189]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_633.pth
	Model improved!!!
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7921251036783139		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.7921251036783139 | validation: 0.7592723009155943]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640354496866683		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.7640354496866683 | validation: 0.8094219232771755]
	TIME [epoch: 24.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842228757043898		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.7842228757043898 | validation: 1.0449324134890454]
	TIME [epoch: 24.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0631419345846373		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.0631419345846373 | validation: 0.9373982389942171]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555847597777986		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.8555847597777986 | validation: 0.9969738916027528]
	TIME [epoch: 24.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157604470706226		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.157604470706226 | validation: 1.5868771132285582]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9716358377722825		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.9716358377722825 | validation: 1.2764278935435212]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1185752396333042		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.1185752396333042 | validation: 1.0703658460682168]
	TIME [epoch: 24.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8772386092411543		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.8772386092411543 | validation: 1.0915365212798473]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9126804740277907		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.9126804740277907 | validation: 1.0345862601085245]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8796649934820229		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.8796649934820229 | validation: 0.9215356771026086]
	TIME [epoch: 24.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8354739106165943		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.8354739106165943 | validation: 0.8791183670840045]
	TIME [epoch: 24.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9782949522582869		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.9782949522582869 | validation: 1.0737072605467903]
	TIME [epoch: 24.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240380030772043		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.0240380030772043 | validation: 1.1276709808324286]
	TIME [epoch: 24.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0549013180038436		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.0549013180038436 | validation: 0.989713658448302]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8921318416973676		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.8921318416973676 | validation: 0.8335056900113418]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7706979470557219		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.7706979470557219 | validation: 0.8390399172523235]
	TIME [epoch: 24.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9090423244441536		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.9090423244441536 | validation: 0.9796601907913237]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7951896070082297		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.7951896070082297 | validation: 0.7197938803786235]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575508560192905		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.7575508560192905 | validation: 0.8852028542178517]
	TIME [epoch: 24.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791453116106094		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.791453116106094 | validation: 0.7951342739651144]
	TIME [epoch: 24.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8504712602891549		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.8504712602891549 | validation: 1.0936859641308379]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8825156080522246		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.8825156080522246 | validation: 0.8180347363072277]
	TIME [epoch: 24.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689120834626254		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.7689120834626254 | validation: 0.8789946738086725]
	TIME [epoch: 24.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876557331880634		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.7876557331880634 | validation: 0.9492009227934344]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7423048178525777		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.7423048178525777 | validation: 0.8152344803514935]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722750631395174		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.722750631395174 | validation: 0.7848787217916406]
	TIME [epoch: 24.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7140243300966683		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7140243300966683 | validation: 0.736382152967965]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999217552618795		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.6999217552618795 | validation: 0.761339531656888]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7421485203088906		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.7421485203088906 | validation: 0.8762520131856701]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7254470959359656		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.7254470959359656 | validation: 0.8250100793492137]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8570061455502938		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.8570061455502938 | validation: 1.008003488758934]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9585138292077457		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.9585138292077457 | validation: 0.9480038379989404]
	TIME [epoch: 24.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8140195614487645		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.8140195614487645 | validation: 0.7561649958880784]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7970936215682682		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.7970936215682682 | validation: 1.0397734916674104]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7869835919031827		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.7869835919031827 | validation: 0.7897743609387309]
	TIME [epoch: 24.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852300395010036		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.6852300395010036 | validation: 1.122956721192762]
	TIME [epoch: 24.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962868280204265		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.7962868280204265 | validation: 1.666000948678967]
	TIME [epoch: 24.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4757656076823544		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 1.4757656076823544 | validation: 1.101237567170374]
	TIME [epoch: 24.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7810304156289649		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.7810304156289649 | validation: 0.7282610405947569]
	TIME [epoch: 24.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993603448269309		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.6993603448269309 | validation: 0.6969081735693792]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_674.pth
	Model improved!!!
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220368295170352		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.7220368295170352 | validation: 0.7162388495045943]
	TIME [epoch: 24.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676572193330887		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.6676572193330887 | validation: 1.1762355790847188]
	TIME [epoch: 24.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7993790216275771		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.7993790216275771 | validation: 0.6746054565545376]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310114695001048		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6310114695001048 | validation: 0.7846410797333215]
	TIME [epoch: 24.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505721048375815		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.6505721048375815 | validation: 0.668383190123366]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6607073452912147		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6607073452912147 | validation: 0.8979862896289893]
	TIME [epoch: 24.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694206340162341		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.694206340162341 | validation: 0.908436943639643]
	TIME [epoch: 24.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996478183903548		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6996478183903548 | validation: 0.8580157175778894]
	TIME [epoch: 24.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426938165103885		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.7426938165103885 | validation: 0.8705798253126577]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399152841399653		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.7399152841399653 | validation: 0.7752505640076757]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6362458534205064		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.6362458534205064 | validation: 0.7993761530888821]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505337052810196		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.6505337052810196 | validation: 0.7915083430643316]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6862875516029272		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.6862875516029272 | validation: 1.361953029978909]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.932435853776222		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.932435853776222 | validation: 0.9266067910606218]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486051017053923		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.7486051017053923 | validation: 0.7624796052583611]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6969937035401053		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.6969937035401053 | validation: 0.8172295525083331]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262733593455909		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.7262733593455909 | validation: 0.9017661564719321]
	TIME [epoch: 24.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057736424799791		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.8057736424799791 | validation: 0.8194766434747809]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517260630644474		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6517260630644474 | validation: 0.7238288914827533]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344403397226309		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6344403397226309 | validation: 0.7464001771968438]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326145425114753		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6326145425114753 | validation: 0.6976826769475747]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7172136419110682		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.7172136419110682 | validation: 0.8928449637978709]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8614703009867742		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.8614703009867742 | validation: 0.7858632979377573]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7092003858151908		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.7092003858151908 | validation: 0.6366514449567952]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894800373853132		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6894800373853132 | validation: 0.7596637458838751]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031295452415598		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.7031295452415598 | validation: 0.7216141491252647]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505740846196579		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.6505740846196579 | validation: 0.7491817781284843]
	TIME [epoch: 24.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6489219299813624		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6489219299813624 | validation: 0.8002569780808559]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157565538605389		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.7157565538605389 | validation: 0.6704621125783115]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252526078734951		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.6252526078734951 | validation: 0.714915129089143]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989089740095068		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6989089740095068 | validation: 0.6910230582641848]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7343453517732029		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.7343453517732029 | validation: 0.8497374951229251]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791186905199249		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.6791186905199249 | validation: 0.7952840975603571]
	TIME [epoch: 24.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370775405714144		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.6370775405714144 | validation: 0.9542007229865352]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7072875320743288		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.7072875320743288 | validation: 0.6076683397430547]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540817097315796		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5540817097315796 | validation: 0.6476931597602087]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217133914227224		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6217133914227224 | validation: 0.7014212829196985]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865507015453395		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5865507015453395 | validation: 0.7399299450871348]
	TIME [epoch: 24.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6098620436667829		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.6098620436667829 | validation: 0.7819052085175561]
	TIME [epoch: 24.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713441203168754		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.713441203168754 | validation: 0.902021935864124]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8456681525157962		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.8456681525157962 | validation: 0.9728987585989717]
	TIME [epoch: 24.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8053969339136421		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.8053969339136421 | validation: 0.6527928454639712]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5984886387596008		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5984886387596008 | validation: 0.8573535204656642]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980797732715147		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6980797732715147 | validation: 0.7689228410689841]
	TIME [epoch: 24.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948634387878019		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.5948634387878019 | validation: 0.6487007368707529]
	TIME [epoch: 24.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544822228790076		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5544822228790076 | validation: 0.744794676595088]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913034976635314		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.5913034976635314 | validation: 0.7482940152032066]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6164330836554908		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.6164330836554908 | validation: 0.9329852850128856]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488995506969235		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.8488995506969235 | validation: 1.0904804335856395]
	TIME [epoch: 24.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8512997678619276		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.8512997678619276 | validation: 1.28082757677094]
	TIME [epoch: 24.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9589624011153951		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.9589624011153951 | validation: 0.8429133966717473]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7051887839296244		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.7051887839296244 | validation: 0.7103507827194901]
	TIME [epoch: 24.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742856765733252		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.6742856765733252 | validation: 0.7242386925893466]
	TIME [epoch: 24.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119880796970695		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.7119880796970695 | validation: 0.7895963569462869]
	TIME [epoch: 24.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745685388697122		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6745685388697122 | validation: 0.7814905643694275]
	TIME [epoch: 24.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708402364167894		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.7708402364167894 | validation: 0.9861641442492135]
	TIME [epoch: 24.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129233024461856		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.7129233024461856 | validation: 0.6917683420114656]
	TIME [epoch: 24.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938474049416608		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.6938474049416608 | validation: 0.9094957532746495]
	TIME [epoch: 24.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285200147479904		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.7285200147479904 | validation: 0.6753944440571773]
	TIME [epoch: 24.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917155549730437		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5917155549730437 | validation: 0.8165953354912365]
	TIME [epoch: 24.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6398844586883436		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.6398844586883436 | validation: 0.6789104712735283]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905723869801349		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5905723869801349 | validation: 0.7081031308468476]
	TIME [epoch: 24.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.634251370058823		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.634251370058823 | validation: 0.7333683572417417]
	TIME [epoch: 24.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341313859665171		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.6341313859665171 | validation: 0.5831032733695123]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5858378004588223		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5858378004588223 | validation: 0.5597141870745829]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992627953513536		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.5992627953513536 | validation: 0.6795784945001582]
	TIME [epoch: 24.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5707345502026611		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5707345502026611 | validation: 0.6350410305872811]
	TIME [epoch: 24.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680544254136221		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.680544254136221 | validation: 0.8098154882989321]
	TIME [epoch: 24.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568370631510734		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.7568370631510734 | validation: 0.8132700977920316]
	TIME [epoch: 24.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529982762397161		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.6529982762397161 | validation: 0.7595751629537395]
	TIME [epoch: 24.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998989122795405		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.6998989122795405 | validation: 0.6168102837123518]
	TIME [epoch: 24.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346670973539791		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.6346670973539791 | validation: 0.8073886301404133]
	TIME [epoch: 24.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634000316267557		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.7634000316267557 | validation: 0.7566041462574026]
	TIME [epoch: 24.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459690405172449		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.6459690405172449 | validation: 0.7103155834269274]
	TIME [epoch: 24.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322811399230583		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.6322811399230583 | validation: 0.7101815106491466]
	TIME [epoch: 24.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917270327276815		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5917270327276815 | validation: 0.8360123929197814]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8828153551652591		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.8828153551652591 | validation: 0.8492809876917932]
	TIME [epoch: 24.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930596420783255		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.6930596420783255 | validation: 0.6270072366874442]
	TIME [epoch: 24.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773242966894184		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.6773242966894184 | validation: 0.754385581092219]
	TIME [epoch: 24.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220471619212805		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.7220471619212805 | validation: 0.7454899929210571]
	TIME [epoch: 24.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7047188127856125		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.7047188127856125 | validation: 0.7823947577686723]
	TIME [epoch: 24.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662271278861403		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.662271278861403 | validation: 0.7706307549478101]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881495352308656		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6881495352308656 | validation: 0.9769576035801173]
	TIME [epoch: 24.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7398127190548328		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.7398127190548328 | validation: 0.9023041349103247]
	TIME [epoch: 24.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7123709939981537		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.7123709939981537 | validation: 0.7574365228793286]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669742182027889		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.6669742182027889 | validation: 0.6480015782114305]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617329291918765		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5617329291918765 | validation: 0.5879871936294163]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173329370555266		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5173329370555266 | validation: 0.6829568506322494]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915620060037878		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5915620060037878 | validation: 0.6592225433360912]
	TIME [epoch: 24.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525390537366448		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5525390537366448 | validation: 0.6378755364207699]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235412605759133		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5235412605759133 | validation: 0.6142863748901827]
	TIME [epoch: 24.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208716510047275		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5208716510047275 | validation: 0.5700725135908609]
	TIME [epoch: 24.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151375131465079		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.5151375131465079 | validation: 0.7288267214718134]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931473196800812		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5931473196800812 | validation: 0.6546573330381571]
	TIME [epoch: 24.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6549780492853261		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.6549780492853261 | validation: 0.66956404471921]
	TIME [epoch: 24.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5922057217111917		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.5922057217111917 | validation: 0.7222899853094434]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155494000274506		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.6155494000274506 | validation: 0.8882054434219679]
	TIME [epoch: 24.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256816529106015		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.7256816529106015 | validation: 0.8869010731927532]
	TIME [epoch: 24.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672620039214929		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.672620039214929 | validation: 0.7554796925341485]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096846735110675		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.6096846735110675 | validation: 0.8167294482462149]
	TIME [epoch: 24.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6246987292443196		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.6246987292443196 | validation: 0.6760513082120587]
	TIME [epoch: 24.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282334502136886		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.6282334502136886 | validation: 0.6057396439750835]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277888772848892		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.5277888772848892 | validation: 0.6209496402251697]
	TIME [epoch: 24.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626398077947852		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5626398077947852 | validation: 0.5900812775720511]
	TIME [epoch: 24.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5494647754375679		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.5494647754375679 | validation: 0.5673369169624828]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.513564431090747		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.513564431090747 | validation: 0.5481882144905493]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_780.pth
	Model improved!!!
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582172314105745		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.582172314105745 | validation: 0.6136016731070123]
	TIME [epoch: 24.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914769257709773		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5914769257709773 | validation: 0.7598056991579785]
	TIME [epoch: 24.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6376127864649136		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.6376127864649136 | validation: 0.7923267084189708]
	TIME [epoch: 24.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8023746247699042		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.8023746247699042 | validation: 0.8813611037259412]
	TIME [epoch: 24.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589289170937564		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.6589289170937564 | validation: 0.5727636030871492]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426040148446087		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.5426040148446087 | validation: 0.5564354205317642]
	TIME [epoch: 24.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518722733708017		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.518722733708017 | validation: 0.5746163374879879]
	TIME [epoch: 24.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849201741100601		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.4849201741100601 | validation: 0.5348443053680948]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346852757892878		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5346852757892878 | validation: 0.621842672833293]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154762458275968		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.5154762458275968 | validation: 0.5376395056823582]
	TIME [epoch: 24.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469647026125927		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.5469647026125927 | validation: 1.006434898063349]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8292327453483902		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.8292327453483902 | validation: 0.6986805898697257]
	TIME [epoch: 24.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788215232177812		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.5788215232177812 | validation: 0.7131330922320693]
	TIME [epoch: 24.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138363032919313		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.6138363032919313 | validation: 0.5663129770203028]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5537852133784001		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.5537852133784001 | validation: 0.6768007342284442]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606252829272117		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.606252829272117 | validation: 0.6842515237906739]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6266186851712012		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.6266186851712012 | validation: 0.7471458697221439]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5608726783432848		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.5608726783432848 | validation: 0.6481550260188886]
	TIME [epoch: 24.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399623741422926		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.5399623741422926 | validation: 0.621730999212553]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333965222993178		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.5333965222993178 | validation: 0.6290820117170809]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382448854283628		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.5382448854283628 | validation: 0.6252139026671779]
	TIME [epoch: 24.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587797030120889		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5587797030120889 | validation: 0.6254807882522643]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744073267726563		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.7744073267726563 | validation: 0.8343835660750882]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7416574138524336		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.7416574138524336 | validation: 0.9044358557614798]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8674809445298808		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.8674809445298808 | validation: 0.7536431694617859]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.851371602846263		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.851371602846263 | validation: 0.9019501077242884]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722891525783954		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.722891525783954 | validation: 0.7710451478154043]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299280104517946		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.6299280104517946 | validation: 0.6141795468185939]
	TIME [epoch: 24.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5956738145420082		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5956738145420082 | validation: 0.6432086054992455]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5836438945694431		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.5836438945694431 | validation: 0.6199597347847574]
	TIME [epoch: 24.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341116480702207		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.6341116480702207 | validation: 0.6346855137258954]
	TIME [epoch: 24.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473048401947976		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6473048401947976 | validation: 0.8078441880027427]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177134748061881		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.8177134748061881 | validation: 0.8406163885930937]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202012248493186		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.7202012248493186 | validation: 0.7914177811325759]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030761703690723		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.7030761703690723 | validation: 0.9193881575254612]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304241697828682		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.7304241697828682 | validation: 0.721703058238106]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907637139678963		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5907637139678963 | validation: 0.6710961264747204]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6654135611643722		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.6654135611643722 | validation: 0.6779334646371666]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608380619916552		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.608380619916552 | validation: 0.6397614972418191]
	TIME [epoch: 24.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613504474387299		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.613504474387299 | validation: 0.6591384280615796]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620300641709064		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5620300641709064 | validation: 0.6053796056339933]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261618167862832		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.6261618167862832 | validation: 0.7241669589326739]
	TIME [epoch: 24.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404325430417277		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.6404325430417277 | validation: 0.6541036845352585]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987134419882798		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.5987134419882798 | validation: 0.7095687115797003]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525365011175633		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.5525365011175633 | validation: 0.5863814737478285]
	TIME [epoch: 24.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255394602024441		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.5255394602024441 | validation: 0.7836376510231042]
	TIME [epoch: 24.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638644504595602		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.638644504595602 | validation: 0.5425255706222716]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4884177400740775		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.4884177400740775 | validation: 0.5859351601595617]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149915089063117		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.5149915089063117 | validation: 0.5246593294228774]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_829.pth
	Model improved!!!
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093517934140934		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.5093517934140934 | validation: 0.6113626689839881]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196039028237129		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.5196039028237129 | validation: 0.5097782899379445]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643414205362961		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.4643414205362961 | validation: 0.5608748541045928]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5546502834415455		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5546502834415455 | validation: 0.5192090664202544]
	TIME [epoch: 24.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465309730677356		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.5465309730677356 | validation: 0.7688512251115374]
	TIME [epoch: 24.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289994544791122		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.6289994544791122 | validation: 0.7046768747964142]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501097344686356		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.5501097344686356 | validation: 0.6286814665518407]
	TIME [epoch: 24.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5397672375961072		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.5397672375961072 | validation: 0.5148116982532757]
	TIME [epoch: 24.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4794486280627925		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4794486280627925 | validation: 0.563189106980193]
	TIME [epoch: 24.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841175912271545		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.4841175912271545 | validation: 0.558280616873007]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5560819126303773		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.5560819126303773 | validation: 0.5966098724759519]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4797659350910798		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4797659350910798 | validation: 0.5364484219451225]
	TIME [epoch: 24.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5259346049913303		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.5259346049913303 | validation: 0.5904146145461922]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106349441776293		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.5106349441776293 | validation: 0.6614589848408978]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969721446870819		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4969721446870819 | validation: 0.6562488684782054]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454610356772866		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.6454610356772866 | validation: 0.632841063838923]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197802787765124		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.5197802787765124 | validation: 0.563852652361083]
	TIME [epoch: 24.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138740129011946		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.5138740129011946 | validation: 0.6617789036252749]
	TIME [epoch: 24.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382481149260602		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.5382481149260602 | validation: 0.626586281153533]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6022389380402164		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.6022389380402164 | validation: 0.635778045253212]
	TIME [epoch: 24.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5360118171299842		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.5360118171299842 | validation: 0.5875744493338141]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5719778473135053		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.5719778473135053 | validation: 0.7720099158313639]
	TIME [epoch: 24.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5910352226811104		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.5910352226811104 | validation: 0.8220600929686397]
	TIME [epoch: 24.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115033189534283		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.7115033189534283 | validation: 0.7502578138968046]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565777518772488		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.565777518772488 | validation: 0.5978847368339685]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235446641311585		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.5235446641311585 | validation: 0.5591140392992279]
	TIME [epoch: 24.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681551629435269		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.4681551629435269 | validation: 0.533680130766649]
	TIME [epoch: 24.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47230312568863453		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.47230312568863453 | validation: 0.5161741062238152]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516083173814599		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.516083173814599 | validation: 0.621617303024114]
	TIME [epoch: 24.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5901051251964644		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5901051251964644 | validation: 0.5930577659083933]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4949180434042397		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.4949180434042397 | validation: 0.5156866140845106]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446991480124038		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4446991480124038 | validation: 0.5163767090475931]
	TIME [epoch: 24.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597948125180386		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.4597948125180386 | validation: 0.5269793232200076]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49673948187521444		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.49673948187521444 | validation: 0.7130535305354568]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976975295002935		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.4976975295002935 | validation: 0.5022976098424727]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_864.pth
	Model improved!!!
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464646093092246		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.464646093092246 | validation: 0.4882482633600492]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240309_135701/states/model_tr_study5_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506805131450405		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4506805131450405 | validation: 0.4980898524639642]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45854856296055657		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.45854856296055657 | validation: 0.5201718345807399]
	TIME [epoch: 24.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.450489770544886		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.450489770544886 | validation: 0.5590839790892249]
	TIME [epoch: 24.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5550011233794436		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.5550011233794436 | validation: 0.7955786075061849]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6446384721053149		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.6446384721053149 | validation: 0.6966848395656571]
	TIME [epoch: 24.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4956259574949221		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4956259574949221 | validation: 0.5222272553754301]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123805873485369		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5123805873485369 | validation: 0.5347149063632413]
	TIME [epoch: 24.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4286162905106993		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4286162905106993 | validation: 0.5069313285376731]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44057023000240847		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.44057023000240847 | validation: 0.5504085217283615]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773974854896413		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4773974854896413 | validation: 0.5556800593310206]
	TIME [epoch: 24.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052825423055446		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.6052825423055446 | validation: 0.9401717548620974]
	TIME [epoch: 24.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594185724263437		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.6594185724263437 | validation: 0.6967418983133213]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
