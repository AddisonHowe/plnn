Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r5', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2075243201

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.831760739805585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.831760739805585 | validation: 6.126783845804466]
	TIME [epoch: 94.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.791000102826535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.791000102826535 | validation: 5.842513993227884]
	TIME [epoch: 5.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.855666479328992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.855666479328992 | validation: 5.007403035079224]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.835835966704468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.835835966704468 | validation: 3.9222500462690806]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7915632200047176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7915632200047176 | validation: 5.253406901477799]
	TIME [epoch: 5.75 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9756181162775324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9756181162775324 | validation: 2.889761458964998]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7730189263301104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7730189263301104 | validation: 2.8219726009476775]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9539527559777468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9539527559777468 | validation: 2.4121492920086838]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7040161918089383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7040161918089383 | validation: 2.1280877615959257]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.500842191411488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.500842191411488 | validation: 2.0867513229699814]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5812726336406158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5812726336406158 | validation: 2.8356105753595306]
	TIME [epoch: 5.76 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558341770617595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.558341770617595 | validation: 1.8594704814682523]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294526410699535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.294526410699535 | validation: 1.741704739214514]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.086782839627598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.086782839627598 | validation: 1.5199270119634654]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9216605242345894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9216605242345894 | validation: 1.6393120661947467]
	TIME [epoch: 5.77 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0963775067248824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0963775067248824 | validation: 1.4886176497255317]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8739787156403551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8739787156403551 | validation: 1.5408330651571385]
	TIME [epoch: 5.76 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9326011460818775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9326011460818775 | validation: 1.3309679121087568]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7428140139790742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7428140139790742 | validation: 1.2562985464127316]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6016513541794395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6016513541794395 | validation: 1.0852607442555706]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.55674923008789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.55674923008789 | validation: 1.623163177986895]
	TIME [epoch: 5.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7609074314332411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7609074314332411 | validation: 1.1291947962515387]
	TIME [epoch: 5.74 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5135946025717288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5135946025717288 | validation: 1.4056212849705185]
	TIME [epoch: 5.74 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4521535441888256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4521535441888256 | validation: 1.105985210271866]
	TIME [epoch: 5.75 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4256945580770126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4256945580770126 | validation: 1.4109111797903007]
	TIME [epoch: 5.75 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5472655330700662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5472655330700662 | validation: 1.2046321542274936]
	TIME [epoch: 5.79 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.315316776143229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.315316776143229 | validation: 0.9121333083018217]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1983147363728304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1983147363728304 | validation: 0.96515053313192]
	TIME [epoch: 5.75 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.684039133214061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.684039133214061 | validation: 1.7199657440535825]
	TIME [epoch: 5.74 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2852799773058132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2852799773058132 | validation: 0.831189947629218]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9700453804795266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9700453804795266 | validation: 0.7019895127122012]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4587590531879442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4587590531879442 | validation: 0.9087172925200687]
	TIME [epoch: 5.78 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3586354039453064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3586354039453064 | validation: 1.5166708472907078]
	TIME [epoch: 5.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0901802746706153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0901802746706153 | validation: 0.7910636890174931]
	TIME [epoch: 5.74 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7961795888758159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7961795888758159 | validation: 1.0295250810107215]
	TIME [epoch: 5.74 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4395473689131284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4395473689131284 | validation: 0.9289071547695028]
	TIME [epoch: 5.76 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26794700051903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.26794700051903 | validation: 0.7446633122122925]
	TIME [epoch: 5.76 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713245796063942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9713245796063942 | validation: 0.6777167571368966]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.248767757326477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.248767757326477 | validation: 0.9327507472234643]
	TIME [epoch: 5.79 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0089974457853563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0089974457853563 | validation: 1.5802563264222549]
	TIME [epoch: 5.77 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.023800257094259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.023800257094259 | validation: 0.9168133110795946]
	TIME [epoch: 5.76 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8746951637386352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8746951637386352 | validation: 1.6684972763854609]
	TIME [epoch: 5.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1150370013458895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1150370013458895 | validation: 0.9155946657621522]
	TIME [epoch: 5.76 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9467871845186193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9467871845186193 | validation: 0.9860601835939897]
	TIME [epoch: 5.76 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1542323777066377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1542323777066377 | validation: 0.7806616965481071]
	TIME [epoch: 5.76 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744223488196557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7744223488196557 | validation: 0.6290360565887722]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849208459829105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6849208459829105 | validation: 0.46335205205718466]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681179070930331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6681179070930331 | validation: 0.9968892927485642]
	TIME [epoch: 5.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8403780179467577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8403780179467577 | validation: 0.5573384748804799]
	TIME [epoch: 5.75 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8644752784238976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8644752784238976 | validation: 0.8344126527385681]
	TIME [epoch: 5.76 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6960664118380626		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.6960664118380626 | validation: 0.9082074032362845]
	TIME [epoch: 5.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8188336395886917		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.8188336395886917 | validation: 0.5608936233445927]
	TIME [epoch: 5.83 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7751581824584115		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.7751581824584115 | validation: 1.032833366322948]
	TIME [epoch: 5.76 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8641538440669825		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.8641538440669825 | validation: 0.82606704372308]
	TIME [epoch: 5.76 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0756591195521037		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.0756591195521037 | validation: 0.719884960705664]
	TIME [epoch: 5.76 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6725897967465053		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6725897967465053 | validation: 0.7088513229804377]
	TIME [epoch: 5.76 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851318984055283		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5851318984055283 | validation: 0.4386074187454085]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542091176682039		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.6542091176682039 | validation: 0.522377342144951]
	TIME [epoch: 5.78 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188017956468209		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.6188017956468209 | validation: 0.6672994788681119]
	TIME [epoch: 5.77 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009454003145745		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.7009454003145745 | validation: 0.5373079488485466]
	TIME [epoch: 5.74 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.669707933150343		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.669707933150343 | validation: 0.4885238063482951]
	TIME [epoch: 5.76 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699364571076842		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.6699364571076842 | validation: 0.8641194310348225]
	TIME [epoch: 5.74 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.719880622241361		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.719880622241361 | validation: 1.1951473002839632]
	TIME [epoch: 5.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993471579327698		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.6993471579327698 | validation: 0.5702716111322591]
	TIME [epoch: 5.75 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481150907677868		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5481150907677868 | validation: 0.42765600737474996]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078661366336803		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5078661366336803 | validation: 0.38698077917499873]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48419185401198045		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.48419185401198045 | validation: 0.7516224612498796]
	TIME [epoch: 5.74 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390204219117738		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5390204219117738 | validation: 0.3729721801436383]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5481037739074611		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.5481037739074611 | validation: 0.9717743378099308]
	TIME [epoch: 5.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9134448579931416		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.9134448579931416 | validation: 0.5744129193422949]
	TIME [epoch: 5.74 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7606961174173821		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7606961174173821 | validation: 0.4376419025135244]
	TIME [epoch: 5.78 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5426850122304477		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5426850122304477 | validation: 0.5020022946072799]
	TIME [epoch: 5.75 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504621706790026		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6504621706790026 | validation: 0.4456553979928765]
	TIME [epoch: 5.73 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889673531415198		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5889673531415198 | validation: 0.48506895452442894]
	TIME [epoch: 5.74 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612675401819267		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.4612675401819267 | validation: 0.5507785605236]
	TIME [epoch: 5.74 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5286997601661243		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5286997601661243 | validation: 0.7046939374491297]
	TIME [epoch: 5.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589294951794472		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.5589294951794472 | validation: 0.4800343952110588]
	TIME [epoch: 5.75 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49515676266036424		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.49515676266036424 | validation: 0.48073562598616454]
	TIME [epoch: 5.77 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346856366193296		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.5346856366193296 | validation: 0.6550084108761308]
	TIME [epoch: 5.75 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730352811055684		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6730352811055684 | validation: 0.743874109136682]
	TIME [epoch: 5.75 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999373584042735		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5999373584042735 | validation: 0.5849586621373738]
	TIME [epoch: 5.74 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5654739490431676		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5654739490431676 | validation: 0.4413640584949306]
	TIME [epoch: 5.76 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47534634598047626		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.47534634598047626 | validation: 0.455208764757883]
	TIME [epoch: 5.75 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997623977365554		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6997623977365554 | validation: 1.2741148812684027]
	TIME [epoch: 5.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635831673390504		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.7635831673390504 | validation: 0.7398051637205343]
	TIME [epoch: 5.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.613927881805844		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.613927881805844 | validation: 0.5061253782178875]
	TIME [epoch: 5.74 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977271778863623		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4977271778863623 | validation: 0.4578491906008474]
	TIME [epoch: 5.74 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094315334664941		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5094315334664941 | validation: 0.7126359378683341]
	TIME [epoch: 5.74 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138155937718665		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6138155937718665 | validation: 0.44674844520463836]
	TIME [epoch: 5.74 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687525545749299		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4687525545749299 | validation: 0.594849220783333]
	TIME [epoch: 5.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449139150632227		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6449139150632227 | validation: 0.7522484141004425]
	TIME [epoch: 5.78 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818978246543769		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5818978246543769 | validation: 0.636679089788426]
	TIME [epoch: 5.76 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5154452535252168		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5154452535252168 | validation: 0.5025373891979349]
	TIME [epoch: 5.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879009484915876		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4879009484915876 | validation: 0.5922032279001758]
	TIME [epoch: 5.74 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744861165165766		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5744861165165766 | validation: 0.5493589200205254]
	TIME [epoch: 5.74 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416050762709133		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.5416050762709133 | validation: 0.5584182734114554]
	TIME [epoch: 5.74 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052230892107666		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.5052230892107666 | validation: 0.4106843998247649]
	TIME [epoch: 5.79 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44761765509099183		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.44761765509099183 | validation: 0.47209722071000215]
	TIME [epoch: 5.75 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6521803408017453		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.6521803408017453 | validation: 0.6953163399417234]
	TIME [epoch: 5.74 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.670478605902763		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.670478605902763 | validation: 0.5246948580230213]
	TIME [epoch: 5.74 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57456246175748		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.57456246175748 | validation: 0.5308063778521498]
	TIME [epoch: 5.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48170919583524135		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.48170919583524135 | validation: 0.49562949319066735]
	TIME [epoch: 5.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5530328847901631		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5530328847901631 | validation: 0.598113754361369]
	TIME [epoch: 5.76 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46577902457161946		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.46577902457161946 | validation: 0.6621366580297633]
	TIME [epoch: 5.78 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4950977670595841		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4950977670595841 | validation: 0.36978439318787165]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642997463100957		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4642997463100957 | validation: 0.7196841168429324]
	TIME [epoch: 5.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567397000260385		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.567397000260385 | validation: 0.5521888741359068]
	TIME [epoch: 5.74 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251515691533842		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.5251515691533842 | validation: 0.48019640641225814]
	TIME [epoch: 5.74 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45076337021049956		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.45076337021049956 | validation: 0.4593218812324976]
	TIME [epoch: 5.75 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47668329960980493		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.47668329960980493 | validation: 0.4240993842332915]
	TIME [epoch: 5.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8404862567772746		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.8404862567772746 | validation: 3.453899657251536]
	TIME [epoch: 5.75 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668787295468756		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.0668787295468756 | validation: 0.4187483412404269]
	TIME [epoch: 5.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40515533861719216		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.40515533861719216 | validation: 0.40737173917228914]
	TIME [epoch: 5.75 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42342674966040095		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.42342674966040095 | validation: 0.4531070017154525]
	TIME [epoch: 5.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246383101887702		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5246383101887702 | validation: 0.39365894654851685]
	TIME [epoch: 5.76 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867153442896738		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3867153442896738 | validation: 0.36571243077905297]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571055272648857		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.4571055272648857 | validation: 0.5151370753291858]
	TIME [epoch: 5.77 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684750988940135		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.6684750988940135 | validation: 0.5731712976436962]
	TIME [epoch: 5.74 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44291407139808897		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.44291407139808897 | validation: 0.6091173380801012]
	TIME [epoch: 5.75 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794160418124588		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5794160418124588 | validation: 0.482631187386857]
	TIME [epoch: 5.73 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4911608938759557		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4911608938759557 | validation: 0.5043577896778563]
	TIME [epoch: 5.75 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452397187258037		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.4452397187258037 | validation: 0.4229183753070867]
	TIME [epoch: 5.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692618209187508		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3692618209187508 | validation: 0.32879165806191935]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4144417916767269		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4144417916767269 | validation: 0.37367039958496767]
	TIME [epoch: 5.75 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4322177435219917		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4322177435219917 | validation: 0.40220577491356024]
	TIME [epoch: 5.76 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920297953216469		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.3920297953216469 | validation: 0.47147257390672975]
	TIME [epoch: 5.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42289752219230614		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.42289752219230614 | validation: 0.333583186348117]
	TIME [epoch: 5.76 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3953791616363961		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3953791616363961 | validation: 0.36614628835341606]
	TIME [epoch: 5.76 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271282044336035		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4271282044336035 | validation: 0.5740249129449603]
	TIME [epoch: 5.79 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422526554448188		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.7422526554448188 | validation: 0.47157636239668577]
	TIME [epoch: 5.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35571720665004686		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.35571720665004686 | validation: 0.39032903032799626]
	TIME [epoch: 5.76 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723635849544687		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3723635849544687 | validation: 0.3683267557132416]
	TIME [epoch: 5.76 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36830465963544123		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.36830465963544123 | validation: 0.2992536654007508]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35258936841760263		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.35258936841760263 | validation: 0.5262110372029472]
	TIME [epoch: 5.76 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.446742985834496		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.446742985834496 | validation: 0.3370706355544136]
	TIME [epoch: 5.76 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007901946212911		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3007901946212911 | validation: 0.2957214291068295]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28415763071780065		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.28415763071780065 | validation: 0.34338318482326313]
	TIME [epoch: 5.76 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.639979621779931		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.639979621779931 | validation: 0.30653703430030277]
	TIME [epoch: 5.76 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687602078217117		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3687602078217117 | validation: 0.39465612129469735]
	TIME [epoch: 5.76 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35399754806439865		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.35399754806439865 | validation: 0.3580481548160422]
	TIME [epoch: 5.76 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40870544262127584		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.40870544262127584 | validation: 0.5949295464840074]
	TIME [epoch: 5.76 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753007928121794		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3753007928121794 | validation: 0.3805054221686692]
	TIME [epoch: 5.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893750993510836		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.5893750993510836 | validation: 0.4001595905167362]
	TIME [epoch: 5.77 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35996903836279287		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.35996903836279287 | validation: 0.36905358646322883]
	TIME [epoch: 5.76 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37333539130489507		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.37333539130489507 | validation: 0.2431978739734218]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3567322026852841		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3567322026852841 | validation: 0.5349996754687948]
	TIME [epoch: 5.75 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622022511128457		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3622022511128457 | validation: 0.34321734107370433]
	TIME [epoch: 5.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36125128113140986		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.36125128113140986 | validation: 0.6539516642327652]
	TIME [epoch: 5.78 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343091317431556		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3343091317431556 | validation: 0.2528083266631393]
	TIME [epoch: 5.77 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33493555751007464		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.33493555751007464 | validation: 0.5623960074242494]
	TIME [epoch: 5.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098399893076283		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.3098399893076283 | validation: 0.19082170606808282]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706696913727734		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3706696913727734 | validation: 0.42790007498913624]
	TIME [epoch: 5.74 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37678564074439647		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.37678564074439647 | validation: 0.24689189671431094]
	TIME [epoch: 5.75 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3048358642054119		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3048358642054119 | validation: 0.20038793044587166]
	TIME [epoch: 5.76 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669097876358817		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.2669097876358817 | validation: 0.8414841560256865]
	TIME [epoch: 5.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44781773686870013		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.44781773686870013 | validation: 0.4061207903628617]
	TIME [epoch: 5.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32621176138630437		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.32621176138630437 | validation: 0.5498950207444898]
	TIME [epoch: 5.76 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518756601181636		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6518756601181636 | validation: 0.3482422594406897]
	TIME [epoch: 5.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028139393519509		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3028139393519509 | validation: 0.43560627146527064]
	TIME [epoch: 5.74 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26137476326886044		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.26137476326886044 | validation: 0.26235439082201717]
	TIME [epoch: 5.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196659821369419		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2196659821369419 | validation: 0.190327150241964]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29639661452795285		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.29639661452795285 | validation: 0.18832835372502735]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207274598785619		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.207274598785619 | validation: 0.19580257616493713]
	TIME [epoch: 5.76 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29106522853882244		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.29106522853882244 | validation: 0.6002581260245781]
	TIME [epoch: 5.75 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687841303076153		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2687841303076153 | validation: 0.2901032721399104]
	TIME [epoch: 5.76 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25159981935190584		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.25159981935190584 | validation: 0.16480934284506124]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23004747505111586		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.23004747505111586 | validation: 0.14825496384701448]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23275400311009423		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.23275400311009423 | validation: 0.12479019092850947]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706075317324046		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.2706075317324046 | validation: 0.10797783878409059]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28854294594182234		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.28854294594182234 | validation: 0.5539311595941578]
	TIME [epoch: 5.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39505803306187576		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.39505803306187576 | validation: 0.3958027084014053]
	TIME [epoch: 5.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2997670217723272		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2997670217723272 | validation: 0.12605695160937924]
	TIME [epoch: 5.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204173333280364		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.4204173333280364 | validation: 0.5254817061611726]
	TIME [epoch: 6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319460088155524		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.3319460088155524 | validation: 0.34189791055089536]
	TIME [epoch: 5.79 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4392744820400708		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.4392744820400708 | validation: 0.21566461903734088]
	TIME [epoch: 5.76 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29194564361624314		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.29194564361624314 | validation: 0.2939805844557234]
	TIME [epoch: 5.76 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060108532130353		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3060108532130353 | validation: 0.22777167897776296]
	TIME [epoch: 5.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764556415479547		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.2764556415479547 | validation: 0.3403888063121644]
	TIME [epoch: 5.76 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733176257908558		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3733176257908558 | validation: 0.1993821605173874]
	TIME [epoch: 5.76 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24749438179622796		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.24749438179622796 | validation: 0.7160620128241684]
	TIME [epoch: 5.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598281787950059		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.4598281787950059 | validation: 0.3069095208543043]
	TIME [epoch: 5.77 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22084040438271818		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.22084040438271818 | validation: 0.21532898699336805]
	TIME [epoch: 5.76 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19867875514111244		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.19867875514111244 | validation: 0.30877011514022157]
	TIME [epoch: 5.76 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.286392451382931		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.286392451382931 | validation: 0.3096434950098828]
	TIME [epoch: 5.76 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659198793647315		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.2659198793647315 | validation: 0.2721126504025753]
	TIME [epoch: 5.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34330200305441455		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.34330200305441455 | validation: 0.19468848343249667]
	TIME [epoch: 5.78 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36079138362864627		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.36079138362864627 | validation: 0.2107576893747195]
	TIME [epoch: 5.79 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120836815568483		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2120836815568483 | validation: 0.26683152842750557]
	TIME [epoch: 5.76 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25225131327346695		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.25225131327346695 | validation: 0.3073543428756384]
	TIME [epoch: 5.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18459895388648825		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.18459895388648825 | validation: 0.3381862617572708]
	TIME [epoch: 5.76 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923082431612885		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2923082431612885 | validation: 0.37972610977838744]
	TIME [epoch: 5.78 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046728432521616		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.3046728432521616 | validation: 0.15689034291048512]
	TIME [epoch: 5.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18797193395709633		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.18797193395709633 | validation: 0.2682852320133417]
	TIME [epoch: 5.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33597810812378603		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.33597810812378603 | validation: 0.15826893002753273]
	TIME [epoch: 5.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32622258648621505		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.32622258648621505 | validation: 0.17456948839002961]
	TIME [epoch: 5.76 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18405112082953626		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.18405112082953626 | validation: 0.15357282042706805]
	TIME [epoch: 5.76 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24246422591422376		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24246422591422376 | validation: 0.21905071370334964]
	TIME [epoch: 5.76 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24353169651913376		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.24353169651913376 | validation: 0.3074365672917793]
	TIME [epoch: 5.76 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20832012047370807		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.20832012047370807 | validation: 0.27082489127580084]
	TIME [epoch: 5.77 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23062242410385375		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.23062242410385375 | validation: 0.4522358539629036]
	TIME [epoch: 5.79 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48451475579827474		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.48451475579827474 | validation: 0.2234816354234875]
	TIME [epoch: 5.76 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24511492566356713		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.24511492566356713 | validation: 0.1601247524333558]
	TIME [epoch: 5.76 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22689904543377928		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.22689904543377928 | validation: 0.17316335713991982]
	TIME [epoch: 5.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40154549236110715		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.40154549236110715 | validation: 0.3879872954275742]
	TIME [epoch: 5.76 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44555601644951387		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.44555601644951387 | validation: 0.3702353209491234]
	TIME [epoch: 5.76 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33986474719205406		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.33986474719205406 | validation: 0.2440840072525517]
	TIME [epoch: 5.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371898792789998		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.4371898792789998 | validation: 0.9677558486533482]
	TIME [epoch: 5.76 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3789864826000247		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.3789864826000247 | validation: 0.18201110109555393]
	TIME [epoch: 5.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876254533936174		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2876254533936174 | validation: 0.2514632488974743]
	TIME [epoch: 5.76 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37018634330066724		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.37018634330066724 | validation: 0.6083760925708925]
	TIME [epoch: 5.76 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28597601289191454		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.28597601289191454 | validation: 0.21409515996439282]
	TIME [epoch: 5.76 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118877851839418		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.3118877851839418 | validation: 0.25143245887600274]
	TIME [epoch: 5.78 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750442254126711		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2750442254126711 | validation: 0.5257649460865343]
	TIME [epoch: 5.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35785441029801934		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.35785441029801934 | validation: 0.2873816983285672]
	TIME [epoch: 5.76 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27586361903618806		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.27586361903618806 | validation: 0.1984164070810759]
	TIME [epoch: 5.76 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26864275728814313		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.26864275728814313 | validation: 0.2840767391598335]
	TIME [epoch: 5.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33879889872524416		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.33879889872524416 | validation: 0.3725818894906153]
	TIME [epoch: 5.76 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27676436368499546		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.27676436368499546 | validation: 0.18904688273945638]
	TIME [epoch: 5.76 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19899163808543954		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.19899163808543954 | validation: 0.24134535636797683]
	TIME [epoch: 5.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285177586066569		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.285177586066569 | validation: 0.19729677994796227]
	TIME [epoch: 5.76 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010466236799414		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.2010466236799414 | validation: 0.21002907247206015]
	TIME [epoch: 5.76 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21835411503575775		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.21835411503575775 | validation: 0.25396063408558034]
	TIME [epoch: 5.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23845078018912233		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.23845078018912233 | validation: 0.315665099563888]
	TIME [epoch: 5.76 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24918364688270453		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.24918364688270453 | validation: 0.20416965473281193]
	TIME [epoch: 5.76 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21269218747894578		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.21269218747894578 | validation: 0.43148152191468264]
	TIME [epoch: 5.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925089449988106		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2925089449988106 | validation: 0.21199869705634442]
	TIME [epoch: 5.79 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33560108463367305		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.33560108463367305 | validation: 0.5959014141783986]
	TIME [epoch: 5.76 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3319316563597926		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.3319316563597926 | validation: 0.28832557444930085]
	TIME [epoch: 5.76 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402920648696112		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.22402920648696112 | validation: 0.13382274415125245]
	TIME [epoch: 5.76 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.208628578525405		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.208628578525405 | validation: 0.1525773666312787]
	TIME [epoch: 5.76 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16245865780475427		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.16245865780475427 | validation: 0.5621641167353549]
	TIME [epoch: 5.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22090097699062616		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.22090097699062616 | validation: 0.1356467846303956]
	TIME [epoch: 5.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153331889702972		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.14153331889702972 | validation: 0.3321186392224469]
	TIME [epoch: 5.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28316393658315875		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.28316393658315875 | validation: 0.7280755165393614]
	TIME [epoch: 5.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3023844280457875		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.3023844280457875 | validation: 0.22370978115811396]
	TIME [epoch: 5.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988094754645294		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.19988094754645294 | validation: 0.21395735248544867]
	TIME [epoch: 5.76 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536897059661993		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.1536897059661993 | validation: 0.15660468790499196]
	TIME [epoch: 5.76 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18433968020406594		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.18433968020406594 | validation: 0.13366746523358664]
	TIME [epoch: 5.77 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18422784808432058		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.18422784808432058 | validation: 0.21932590950356137]
	TIME [epoch: 5.79 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555161615134143		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1555161615134143 | validation: 0.19098845353094374]
	TIME [epoch: 5.76 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22516373585560173		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.22516373585560173 | validation: 0.17662909725280954]
	TIME [epoch: 5.76 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30818073578212946		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.30818073578212946 | validation: 0.2622755146359328]
	TIME [epoch: 5.76 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17510974388558553		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.17510974388558553 | validation: 0.18883468311925997]
	TIME [epoch: 5.76 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14377277166070493		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.14377277166070493 | validation: 0.1701173339008395]
	TIME [epoch: 5.76 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12199154231014653		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.12199154231014653 | validation: 0.08255576335348336]
	TIME [epoch: 5.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17497928064870752		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.17497928064870752 | validation: 0.10368653804819257]
	TIME [epoch: 5.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20468803236267977		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.20468803236267977 | validation: 0.28174775228297755]
	TIME [epoch: 5.76 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373405433840337		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.373405433840337 | validation: 0.16475682531080832]
	TIME [epoch: 5.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1703476687518975		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.1703476687518975 | validation: 0.2099155640729596]
	TIME [epoch: 5.75 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2514961946969945		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2514961946969945 | validation: 0.15356611367449285]
	TIME [epoch: 5.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22516587558342627		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.22516587558342627 | validation: 0.19225309106911512]
	TIME [epoch: 5.79 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044349299812725		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.2044349299812725 | validation: 0.19916910564548565]
	TIME [epoch: 5.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848963045137891		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.2848963045137891 | validation: 0.15933883958489403]
	TIME [epoch: 5.75 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2034642144965172		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2034642144965172 | validation: 0.22836852313905417]
	TIME [epoch: 5.75 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19220401928699732		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.19220401928699732 | validation: 0.15396197606796327]
	TIME [epoch: 5.76 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17702561829920208		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.17702561829920208 | validation: 0.16986146809571742]
	TIME [epoch: 5.75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20970597840882824		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.20970597840882824 | validation: 0.21544838160242216]
	TIME [epoch: 5.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17311267811359932		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.17311267811359932 | validation: 0.1428974379889597]
	TIME [epoch: 5.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16005761696870144		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.16005761696870144 | validation: 0.32950636061231564]
	TIME [epoch: 5.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670224440971444		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2670224440971444 | validation: 0.16110501291315718]
	TIME [epoch: 5.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18178892078146908		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.18178892078146908 | validation: 0.1446816319746627]
	TIME [epoch: 5.76 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18105840217282565		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.18105840217282565 | validation: 0.08114552079917335]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18444449259477502		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.18444449259477502 | validation: 0.14767634027571108]
	TIME [epoch: 5.75 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14171455484928636		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.14171455484928636 | validation: 0.21858734856100875]
	TIME [epoch: 5.78 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18154245758130094		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.18154245758130094 | validation: 0.1540072756809721]
	TIME [epoch: 5.77 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14837793249745732		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.14837793249745732 | validation: 0.2482334605343919]
	TIME [epoch: 5.74 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15236847015648367		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.15236847015648367 | validation: 0.2009908141889508]
	TIME [epoch: 5.74 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12946628614664712		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.12946628614664712 | validation: 0.3771223323115948]
	TIME [epoch: 5.74 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20998305561697972		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.20998305561697972 | validation: 0.18282534645884607]
	TIME [epoch: 5.74 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17348425227847988		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17348425227847988 | validation: 0.13233918260067434]
	TIME [epoch: 5.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786176186261012		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.13786176186261012 | validation: 0.17837747118652295]
	TIME [epoch: 5.79 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19527635570565954		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.19527635570565954 | validation: 0.22564055566932267]
	TIME [epoch: 5.74 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2190080379468625		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2190080379468625 | validation: 0.1489779849578608]
	TIME [epoch: 5.74 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23050528414817983		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.23050528414817983 | validation: 0.09197669146846181]
	TIME [epoch: 5.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16714686357610792		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.16714686357610792 | validation: 0.13969242826413233]
	TIME [epoch: 5.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25675319676551567		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.25675319676551567 | validation: 0.2565145524214176]
	TIME [epoch: 5.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820902363572065		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.3820902363572065 | validation: 0.4547315218713572]
	TIME [epoch: 5.78 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32106332060137865		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.32106332060137865 | validation: 0.13657461452784259]
	TIME [epoch: 5.76 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899195704786497		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.1899195704786497 | validation: 0.14499557759507353]
	TIME [epoch: 5.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19228656534870456		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.19228656534870456 | validation: 0.250898006931523]
	TIME [epoch: 5.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26183097766112745		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.26183097766112745 | validation: 0.1061579695253069]
	TIME [epoch: 5.73 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18716586869962282		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.18716586869962282 | validation: 0.21445375423750943]
	TIME [epoch: 5.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21428047870066483		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.21428047870066483 | validation: 0.38414387259204064]
	TIME [epoch: 5.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37638666369602714		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.37638666369602714 | validation: 0.4819639474634109]
	TIME [epoch: 5.79 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46768227670671547		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.46768227670671547 | validation: 0.30597476583336763]
	TIME [epoch: 5.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21234678084287809		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.21234678084287809 | validation: 0.1145429791078177]
	TIME [epoch: 5.74 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965855332325019		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.15965855332325019 | validation: 0.133507879537128]
	TIME [epoch: 5.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451251025638989		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.1451251025638989 | validation: 0.24136957512172508]
	TIME [epoch: 5.75 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728763410243243		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.1728763410243243 | validation: 0.14247049286943234]
	TIME [epoch: 5.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521082312730017		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.11521082312730017 | validation: 0.21259395540196827]
	TIME [epoch: 5.78 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20548749320432336		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.20548749320432336 | validation: 0.1460557805652522]
	TIME [epoch: 5.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16074496223964962		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.16074496223964962 | validation: 0.07353016513665578]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464685137320486		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.1464685137320486 | validation: 0.08914414583208183]
	TIME [epoch: 5.76 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292545376392642		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.1292545376392642 | validation: 0.11684007837133788]
	TIME [epoch: 5.75 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16884228637653523		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16884228637653523 | validation: 0.1562511756468886]
	TIME [epoch: 5.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12144269409498674		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.12144269409498674 | validation: 0.10240330436785378]
	TIME [epoch: 5.77 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042195679797821		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.12042195679797821 | validation: 0.11024780957030661]
	TIME [epoch: 5.77 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17084439791227687		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.17084439791227687 | validation: 0.10853676152553578]
	TIME [epoch: 5.74 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367198702294992		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.11367198702294992 | validation: 0.11828182880363361]
	TIME [epoch: 5.75 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389861016734813		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1389861016734813 | validation: 0.23128320763448276]
	TIME [epoch: 5.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287760853473217		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.1287760853473217 | validation: 0.09088656874188429]
	TIME [epoch: 5.74 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361854666580933		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.1361854666580933 | validation: 0.22024513871151763]
	TIME [epoch: 5.76 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24668444068203155		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.24668444068203155 | validation: 0.11996791554658462]
	TIME [epoch: 5.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084986793703592		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.15084986793703592 | validation: 0.1809451457575487]
	TIME [epoch: 5.76 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939065335016547		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.11939065335016547 | validation: 0.057698089624117446]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15177792979529886		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.15177792979529886 | validation: 0.1496100485031322]
	TIME [epoch: 5.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15394094642883271		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.15394094642883271 | validation: 0.1628168318710626]
	TIME [epoch: 5.74 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874921343568854		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1874921343568854 | validation: 0.1893654209549583]
	TIME [epoch: 5.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27074958862646387		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.27074958862646387 | validation: 0.18009582575127256]
	TIME [epoch: 5.76 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20140053937129695		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.20140053937129695 | validation: 0.14370566514215413]
	TIME [epoch: 5.77 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253687174411531		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.253687174411531 | validation: 0.2653564929699662]
	TIME [epoch: 5.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18505091659030928		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.18505091659030928 | validation: 0.10763292672098895]
	TIME [epoch: 5.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14142274725845896		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.14142274725845896 | validation: 0.087001157760265]
	TIME [epoch: 5.74 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14810745688346585		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.14810745688346585 | validation: 0.09928900797720479]
	TIME [epoch: 5.74 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12909503162965094		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.12909503162965094 | validation: 0.14399983793086144]
	TIME [epoch: 5.74 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13525392205838255		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.13525392205838255 | validation: 0.17846663936510884]
	TIME [epoch: 5.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161478798126103		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.161478798126103 | validation: 0.18430628105036787]
	TIME [epoch: 5.76 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20687389905765255		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.20687389905765255 | validation: 0.16781961478513147]
	TIME [epoch: 5.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14009983694821526		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.14009983694821526 | validation: 0.06638108522760898]
	TIME [epoch: 5.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510718123707416		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.10510718123707416 | validation: 0.17662227506932301]
	TIME [epoch: 5.76 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15868253449437283		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.15868253449437283 | validation: 0.16183357890871106]
	TIME [epoch: 5.74 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18185213832805938		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.18185213832805938 | validation: 0.21833923493510451]
	TIME [epoch: 5.78 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19642648787005493		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.19642648787005493 | validation: 0.15795264318135252]
	TIME [epoch: 5.79 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885041495905417		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.1885041495905417 | validation: 0.17329174397334796]
	TIME [epoch: 5.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354687583881461		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1354687583881461 | validation: 0.13254502396552295]
	TIME [epoch: 5.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032972198194783		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.15032972198194783 | validation: 0.129314276747513]
	TIME [epoch: 5.76 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14932531028671076		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.14932531028671076 | validation: 0.1618603028521908]
	TIME [epoch: 5.75 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090736767094393		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.2090736767094393 | validation: 0.25622764052989966]
	TIME [epoch: 5.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19500106640852594		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.19500106640852594 | validation: 0.20146743184050828]
	TIME [epoch: 5.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20756717758043716		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.20756717758043716 | validation: 0.19307520228075803]
	TIME [epoch: 5.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566561493029855		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.13566561493029855 | validation: 0.0901188562285743]
	TIME [epoch: 5.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298773407577738		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.11298773407577738 | validation: 0.07473317707363666]
	TIME [epoch: 5.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10193687467028562		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.10193687467028562 | validation: 0.09339769439918559]
	TIME [epoch: 5.74 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415336871792032		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.12415336871792032 | validation: 0.09906840013879509]
	TIME [epoch: 5.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194298203360663		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1194298203360663 | validation: 0.12757199739399802]
	TIME [epoch: 5.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477000322451176		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.10477000322451176 | validation: 0.1446097413784389]
	TIME [epoch: 5.77 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13397925702032037		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.13397925702032037 | validation: 0.19019648140167347]
	TIME [epoch: 5.75 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22710532730793603		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.22710532730793603 | validation: 0.36952261072532844]
	TIME [epoch: 5.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1917952482967174		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.1917952482967174 | validation: 0.2005207604019705]
	TIME [epoch: 5.74 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644700765950358		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1644700765950358 | validation: 0.1656108439204264]
	TIME [epoch: 5.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655127715315122		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1655127715315122 | validation: 0.1514619454181205]
	TIME [epoch: 5.74 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393811353745048		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.1393811353745048 | validation: 0.09900854464491782]
	TIME [epoch: 5.79 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12059109683038056		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.12059109683038056 | validation: 0.06709410845972082]
	TIME [epoch: 5.74 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26136963087445075		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.26136963087445075 | validation: 0.14512106100903802]
	TIME [epoch: 5.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18703807800310668		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.18703807800310668 | validation: 0.1893075820792769]
	TIME [epoch: 5.74 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821538146757196		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.14821538146757196 | validation: 0.0979744238435787]
	TIME [epoch: 5.75 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14802065846319282		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.14802065846319282 | validation: 0.12812015988958936]
	TIME [epoch: 5.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14170544932433254		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.14170544932433254 | validation: 0.07741677987233281]
	TIME [epoch: 5.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248361316503117		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.12248361316503117 | validation: 0.07456389335718665]
	TIME [epoch: 5.77 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15733671607306862		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.15733671607306862 | validation: 0.1412479415459278]
	TIME [epoch: 5.76 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13985447952985453		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.13985447952985453 | validation: 0.08394888733432537]
	TIME [epoch: 5.74 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16780914425934104		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.16780914425934104 | validation: 0.16037105035114732]
	TIME [epoch: 5.75 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15581389559563075		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.15581389559563075 | validation: 0.058283931373540786]
	TIME [epoch: 5.74 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18499502119649192		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.18499502119649192 | validation: 0.1164556548058409]
	TIME [epoch: 5.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365849055477164		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.13365849055477164 | validation: 0.27931660586981055]
	TIME [epoch: 5.78 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653298262246529		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.1653298262246529 | validation: 0.046457159531431015]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_356.pth
	Model improved!!!
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10113743971580222		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.10113743971580222 | validation: 0.1393913855672785]
	TIME [epoch: 5.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152899101240566		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.10152899101240566 | validation: 0.07141451078110223]
	TIME [epoch: 5.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124638421536105		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.09124638421536105 | validation: 0.0726738963604405]
	TIME [epoch: 5.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11557523010876333		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.11557523010876333 | validation: 0.08037178593287912]
	TIME [epoch: 5.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756407195495449		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.10756407195495449 | validation: 0.11116651381354928]
	TIME [epoch: 5.78 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10797394492470168		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.10797394492470168 | validation: 0.11410659465784029]
	TIME [epoch: 5.76 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870659171626394		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.14870659171626394 | validation: 0.17500619778096393]
	TIME [epoch: 5.76 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11019352155029433		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.11019352155029433 | validation: 0.06509858583264003]
	TIME [epoch: 5.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104036669197675		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.07104036669197675 | validation: 0.04437203896646468]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_365.pth
	Model improved!!!
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11651257919125466		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.11651257919125466 | validation: 0.1505874021684406]
	TIME [epoch: 5.75 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19497631217987688		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.19497631217987688 | validation: 0.11344147350515708]
	TIME [epoch: 5.74 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176591707507848		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.10176591707507848 | validation: 0.0853306051900579]
	TIME [epoch: 5.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11591776915350696		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.11591776915350696 | validation: 0.1476347150106781]
	TIME [epoch: 5.75 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19857944065134892		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.19857944065134892 | validation: 0.10891170642736904]
	TIME [epoch: 5.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15949616137234515		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.15949616137234515 | validation: 0.14353743911926728]
	TIME [epoch: 5.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240874602463903		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.09240874602463903 | validation: 0.19852571545446795]
	TIME [epoch: 5.75 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18335892847811242		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.18335892847811242 | validation: 0.13323931065607994]
	TIME [epoch: 5.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460587638037538		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.10460587638037538 | validation: 0.10186637197893861]
	TIME [epoch: 5.79 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634989624182469		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1634989624182469 | validation: 0.2160813495375056]
	TIME [epoch: 5.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270782817450922		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.1270782817450922 | validation: 0.1367689518774788]
	TIME [epoch: 5.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454185755656085		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.10454185755656085 | validation: 0.09727090002589024]
	TIME [epoch: 5.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12984032756770567		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.12984032756770567 | validation: 0.07563603171705349]
	TIME [epoch: 5.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08631678420576072		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.08631678420576072 | validation: 0.08345981888093429]
	TIME [epoch: 5.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12212522271151116		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.12212522271151116 | validation: 0.19094792830714025]
	TIME [epoch: 5.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12052321452342732		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.12052321452342732 | validation: 0.15264332691877713]
	TIME [epoch: 5.78 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928941184088532		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.18928941184088532 | validation: 0.26308542501310817]
	TIME [epoch: 5.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16176184430435284		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.16176184430435284 | validation: 0.1875074286345641]
	TIME [epoch: 5.76 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10954186409846045		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.10954186409846045 | validation: 0.10878088035963585]
	TIME [epoch: 5.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159513374721835		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.159513374721835 | validation: 0.08546509507802666]
	TIME [epoch: 5.75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12304338819108554		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.12304338819108554 | validation: 0.10317914697135674]
	TIME [epoch: 5.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0950906842654779		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.0950906842654779 | validation: 0.18299680875248697]
	TIME [epoch: 5.78 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11972001361898905		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.11972001361898905 | validation: 0.12378220794283365]
	TIME [epoch: 5.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11996616874958428		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.11996616874958428 | validation: 0.1343084009279486]
	TIME [epoch: 5.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125849327163716		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.125849327163716 | validation: 0.17673356719615374]
	TIME [epoch: 5.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17250538584031444		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.17250538584031444 | validation: 0.12805382099195392]
	TIME [epoch: 5.75 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213956232048457		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.13213956232048457 | validation: 0.1117211618341489]
	TIME [epoch: 5.76 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15442362990864186		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.15442362990864186 | validation: 0.14965346919257405]
	TIME [epoch: 5.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365928439865593		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.1365928439865593 | validation: 0.10483469502022728]
	TIME [epoch: 5.79 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326710735530929		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1326710735530929 | validation: 0.10311716186107639]
	TIME [epoch: 5.76 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11631583031695396		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.11631583031695396 | validation: 0.1509215282950297]
	TIME [epoch: 5.74 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385893688246406		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.10385893688246406 | validation: 0.09292235563727413]
	TIME [epoch: 5.76 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1046539284160922		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.1046539284160922 | validation: 0.09122520600559214]
	TIME [epoch: 5.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813511181507028		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.14813511181507028 | validation: 0.11186195200260088]
	TIME [epoch: 5.75 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10512332272478551		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.10512332272478551 | validation: 0.25312468538957894]
	TIME [epoch: 5.77 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12359295590014192		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.12359295590014192 | validation: 0.07378832296293751]
	TIME [epoch: 5.77 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577494655338043		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.08577494655338043 | validation: 0.042607454951779165]
	TIME [epoch: 5.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872930554202246		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.08872930554202246 | validation: 0.06610316489224395]
	TIME [epoch: 5.75 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09350193153289718		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.09350193153289718 | validation: 0.05898280155543839]
	TIME [epoch: 5.74 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903933498115228		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.11903933498115228 | validation: 0.05288202572644942]
	TIME [epoch: 5.74 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06594576008396932		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.06594576008396932 | validation: 0.11962892013293736]
	TIME [epoch: 5.76 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09592742196282791		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.09592742196282791 | validation: 0.07487362357050327]
	TIME [epoch: 5.77 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09600614711799321		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.09600614711799321 | validation: 0.1671987333979404]
	TIME [epoch: 5.76 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551054559628477		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.12551054559628477 | validation: 0.061105663221009035]
	TIME [epoch: 5.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727592842329683		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.0727592842329683 | validation: 0.06458054077800136]
	TIME [epoch: 5.74 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07547289279830097		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.07547289279830097 | validation: 0.08697270459779198]
	TIME [epoch: 5.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07982908951582998		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.07982908951582998 | validation: 0.10630851518087767]
	TIME [epoch: 5.73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14546316051991728		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.14546316051991728 | validation: 0.046566479017800144]
	TIME [epoch: 5.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800700565025557		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.0800700565025557 | validation: 0.09729557490540486]
	TIME [epoch: 5.76 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09912636655074833		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.09912636655074833 | validation: 0.04712880394492148]
	TIME [epoch: 5.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08027530970053522		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.08027530970053522 | validation: 0.06279939151028885]
	TIME [epoch: 5.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07916696410217813		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.07916696410217813 | validation: 0.04679960900432775]
	TIME [epoch: 5.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446000803336366		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.11446000803336366 | validation: 0.06979567058131515]
	TIME [epoch: 5.75 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11036508616296727		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.11036508616296727 | validation: 0.08366085119387005]
	TIME [epoch: 5.77 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22402782802049617		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.22402782802049617 | validation: 0.23815359733395014]
	TIME [epoch: 5.78 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13499988099365348		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.13499988099365348 | validation: 0.10666829576885442]
	TIME [epoch: 5.74 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480047849254458		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.12480047849254458 | validation: 0.08216168608139383]
	TIME [epoch: 5.75 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497881058356865		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.11497881058356865 | validation: 0.13083984181147817]
	TIME [epoch: 5.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08473348608215182		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.08473348608215182 | validation: 0.14203478020967686]
	TIME [epoch: 5.75 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09568365868589515		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09568365868589515 | validation: 0.04894115035287703]
	TIME [epoch: 5.74 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784357385709577		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.0784357385709577 | validation: 0.07645443456818828]
	TIME [epoch: 5.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762287248844431		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.09762287248844431 | validation: 0.09400834613788277]
	TIME [epoch: 5.76 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15082616642280677		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.15082616642280677 | validation: 0.14575895891049193]
	TIME [epoch: 5.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969193084014756		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.14969193084014756 | validation: 0.21788983825840216]
	TIME [epoch: 5.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10693084538749889		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.10693084538749889 | validation: 0.08566884967461119]
	TIME [epoch: 5.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06786419501652562		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.06786419501652562 | validation: 0.06352731312404811]
	TIME [epoch: 5.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06692851446385803		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.06692851446385803 | validation: 0.05987106954832045]
	TIME [epoch: 5.77 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08985963079291215		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.08985963079291215 | validation: 0.16188655432296653]
	TIME [epoch: 5.79 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440221981207565		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.1440221981207565 | validation: 0.1862706044046598]
	TIME [epoch: 5.76 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19196876224394616		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.19196876224394616 | validation: 0.13697551212969306]
	TIME [epoch: 5.76 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149043078996259		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.149043078996259 | validation: 0.11692574836649698]
	TIME [epoch: 5.74 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385545357891003		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.11385545357891003 | validation: 0.1075886684896814]
	TIME [epoch: 5.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12976943095830296		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.12976943095830296 | validation: 0.10345354842508514]
	TIME [epoch: 5.74 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139115689460723		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1139115689460723 | validation: 0.07733747059731778]
	TIME [epoch: 5.79 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695430161629976		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.10695430161629976 | validation: 0.03968221578667553]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07899408336127761		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.07899408336127761 | validation: 0.06819497895140182]
	TIME [epoch: 5.75 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06928001245725471		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.06928001245725471 | validation: 0.04989350850705911]
	TIME [epoch: 5.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674141447218156		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.08674141447218156 | validation: 0.07162690567299565]
	TIME [epoch: 5.75 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20717485357267196		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.20717485357267196 | validation: 0.1676906231639814]
	TIME [epoch: 5.75 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327823989448398		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.13327823989448398 | validation: 0.07092653564972087]
	TIME [epoch: 5.77 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10404076986384764		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.10404076986384764 | validation: 0.03465407359355102]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05689457994852299		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.05689457994852299 | validation: 0.08370115257185312]
	TIME [epoch: 5.74 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570841580688745		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.07570841580688745 | validation: 0.042560305914612497]
	TIME [epoch: 5.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553447170832358		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.09553447170832358 | validation: 0.06039589984183616]
	TIME [epoch: 5.75 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09968717175727651		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.09968717175727651 | validation: 0.07626901428850616]
	TIME [epoch: 5.75 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326602143462436		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.1326602143462436 | validation: 0.07008240964332259]
	TIME [epoch: 5.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984268040015897		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.08984268040015897 | validation: 0.11999897939324682]
	TIME [epoch: 5.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08213011933956238		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.08213011933956238 | validation: 0.04063284763207095]
	TIME [epoch: 5.75 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06587445942987513		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.06587445942987513 | validation: 0.08004755506218336]
	TIME [epoch: 5.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08380266439182878		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08380266439182878 | validation: 0.04530768080722293]
	TIME [epoch: 5.75 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633519994965947		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.07633519994965947 | validation: 0.049005928881146604]
	TIME [epoch: 5.73 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291454198493954		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.11291454198493954 | validation: 0.09663791884386377]
	TIME [epoch: 5.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07388243413026085		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.07388243413026085 | validation: 0.07987875397724865]
	TIME [epoch: 5.78 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07289816969582938		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.07289816969582938 | validation: 0.06695057639045789]
	TIME [epoch: 5.77 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09003535217406292		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09003535217406292 | validation: 0.1742560246462524]
	TIME [epoch: 5.75 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18793343327020837		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.18793343327020837 | validation: 0.2047747544082035]
	TIME [epoch: 5.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702384315808408		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.10702384315808408 | validation: 0.1365966345629172]
	TIME [epoch: 5.75 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07544238800342434		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.07544238800342434 | validation: 0.06751193193506737]
	TIME [epoch: 5.75 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593711035154832		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.07593711035154832 | validation: 0.13586651935936314]
	TIME [epoch: 5.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18793430377676895		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.18793430377676895 | validation: 0.13169599614097263]
	TIME [epoch: 5.79 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09042189336008928		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.09042189336008928 | validation: 0.09039031078224216]
	TIME [epoch: 5.76 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331392970705429		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.08331392970705429 | validation: 0.10144375120599029]
	TIME [epoch: 5.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10758172877126052		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.10758172877126052 | validation: 0.10743629580217574]
	TIME [epoch: 5.75 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331952959695913		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1331952959695913 | validation: 0.12785471423678016]
	TIME [epoch: 5.75 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11811794387540198		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.11811794387540198 | validation: 0.1400829233938605]
	TIME [epoch: 5.75 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10632094608395437		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.10632094608395437 | validation: 0.07765020784042241]
	TIME [epoch: 5.77 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11910901407637348		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.11910901407637348 | validation: 0.15630018805965504]
	TIME [epoch: 5.77 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241418279391968		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.11241418279391968 | validation: 0.10193243490128918]
	TIME [epoch: 5.76 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11498660911847608		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.11498660911847608 | validation: 0.10295752984395443]
	TIME [epoch: 5.75 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11506683699039606		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.11506683699039606 | validation: 0.10653716352154176]
	TIME [epoch: 5.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041178106869229		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.11041178106869229 | validation: 0.08201662044248105]
	TIME [epoch: 5.75 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011560793500766		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.10011560793500766 | validation: 0.11399509733684003]
	TIME [epoch: 5.76 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625537646547209		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.10625537646547209 | validation: 0.06588990118578679]
	TIME [epoch: 5.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09245416965196265		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.09245416965196265 | validation: 0.1045310937984788]
	TIME [epoch: 5.75 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09548301797970961		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.09548301797970961 | validation: 0.088126463322333]
	TIME [epoch: 5.75 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924879355898991		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.09924879355898991 | validation: 0.10646456810521684]
	TIME [epoch: 5.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08146720744078406		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.08146720744078406 | validation: 0.06261412616608741]
	TIME [epoch: 5.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253907669319831		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.07253907669319831 | validation: 0.08888817480842899]
	TIME [epoch: 5.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11318117022691312		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.11318117022691312 | validation: 0.08215283666988625]
	TIME [epoch: 5.79 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453805853527436		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.09453805853527436 | validation: 0.0814185505402073]
	TIME [epoch: 5.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07844655444403476		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.07844655444403476 | validation: 0.08527503814813761]
	TIME [epoch: 5.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08129221779754503		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.08129221779754503 | validation: 0.053369516912603346]
	TIME [epoch: 5.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06823294225908758		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.06823294225908758 | validation: 0.047949697884845176]
	TIME [epoch: 5.73 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543943948415927		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.07543943948415927 | validation: 0.05629633622135941]
	TIME [epoch: 5.73 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08410378751219472		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08410378751219472 | validation: 0.12021697501030583]
	TIME [epoch: 5.73 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09820488747518148		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.09820488747518148 | validation: 0.17788056079101247]
	TIME [epoch: 5.78 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778360707615158		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.12778360707615158 | validation: 0.10085950431288933]
	TIME [epoch: 5.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07301786349297222		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.07301786349297222 | validation: 0.05411833688207262]
	TIME [epoch: 5.73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966638589720808		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.09966638589720808 | validation: 0.14437985463990546]
	TIME [epoch: 5.73 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10479277342498029		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.10479277342498029 | validation: 0.0750572003477483]
	TIME [epoch: 5.75 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798431593608837		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.08798431593608837 | validation: 0.05340733816342777]
	TIME [epoch: 5.75 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07599609639775522		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.07599609639775522 | validation: 0.08842096580307426]
	TIME [epoch: 5.78 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07926371766679616		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.07926371766679616 | validation: 0.07184685526112632]
	TIME [epoch: 5.77 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07633472659383972		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.07633472659383972 | validation: 0.06338505643688604]
	TIME [epoch: 5.75 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860677100194453		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.05860677100194453 | validation: 0.06379730203393277]
	TIME [epoch: 5.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06545573015180833		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.06545573015180833 | validation: 0.0484218914394045]
	TIME [epoch: 5.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06058411213273596		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.06058411213273596 | validation: 0.11091964901215008]
	TIME [epoch: 5.75 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08807735851201728		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.08807735851201728 | validation: 0.037145597939110306]
	TIME [epoch: 5.75 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045341172162701865		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.045341172162701865 | validation: 0.12928858972139476]
	TIME [epoch: 5.78 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06029601587225239		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.06029601587225239 | validation: 0.030029788488716316]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05714630541296217		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.05714630541296217 | validation: 0.037421471860759115]
	TIME [epoch: 5.76 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472917159530804		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.07472917159530804 | validation: 0.05527182550875647]
	TIME [epoch: 5.74 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612142978388774		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.0612142978388774 | validation: 0.15019946613775256]
	TIME [epoch: 5.74 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348977211741204		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.1348977211741204 | validation: 0.14222355751811322]
	TIME [epoch: 5.74 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640186797507744		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09640186797507744 | validation: 0.04762798307469872]
	TIME [epoch: 5.78 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05072267803213676		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.05072267803213676 | validation: 0.07871419564231269]
	TIME [epoch: 5.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.072013485019761		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.072013485019761 | validation: 0.0404583996469076]
	TIME [epoch: 5.74 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047891661132778506		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.047891661132778506 | validation: 0.09568240787399117]
	TIME [epoch: 5.74 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841839664526604		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.1841839664526604 | validation: 0.30878708353479495]
	TIME [epoch: 5.74 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14350439312311358		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.14350439312311358 | validation: 0.1481588988332159]
	TIME [epoch: 5.74 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13628682862828706		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.13628682862828706 | validation: 0.08433885132490908]
	TIME [epoch: 5.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11332008178065893		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.11332008178065893 | validation: 0.10326521792193524]
	TIME [epoch: 5.77 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13419699513213293		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.13419699513213293 | validation: 0.18069908450841873]
	TIME [epoch: 5.74 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1227371937515453		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.1227371937515453 | validation: 0.09258644672448212]
	TIME [epoch: 5.74 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223449786699365		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.10223449786699365 | validation: 0.09664514458974846]
	TIME [epoch: 5.74 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12203821546785842		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.12203821546785842 | validation: 0.15679816287847845]
	TIME [epoch: 5.73 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11411233190588972		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.11411233190588972 | validation: 0.12206542309260485]
	TIME [epoch: 5.74 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13312462762801208		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.13312462762801208 | validation: 0.09194438853440656]
	TIME [epoch: 5.78 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977833300144918		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.0977833300144918 | validation: 0.13610242319323776]
	TIME [epoch: 5.74 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189912957557878		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.11189912957557878 | validation: 0.09604589235373542]
	TIME [epoch: 5.74 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230002873351747		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.08230002873351747 | validation: 0.11964978192088829]
	TIME [epoch: 5.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12317819680936089		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.12317819680936089 | validation: 0.0868986504146424]
	TIME [epoch: 5.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11857838375856206		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11857838375856206 | validation: 0.1038714103107058]
	TIME [epoch: 5.74 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10637966151086137		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.10637966151086137 | validation: 0.04521232436036275]
	TIME [epoch: 5.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049959286028308805		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.049959286028308805 | validation: 0.05921942451611813]
	TIME [epoch: 5.77 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365282249903492		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.06365282249903492 | validation: 0.1089207716603435]
	TIME [epoch: 5.74 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08861714751622835		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.08861714751622835 | validation: 0.055382730934095604]
	TIME [epoch: 5.74 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06437541784795672		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.06437541784795672 | validation: 0.06998135542101266]
	TIME [epoch: 5.74 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807902942326449		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.07807902942326449 | validation: 0.08601664957867293]
	TIME [epoch: 5.74 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1166077541875985		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1166077541875985 | validation: 0.10846036084356048]
	TIME [epoch: 5.74 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953199833292672		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.08953199833292672 | validation: 0.06084872416890276]
	TIME [epoch: 5.78 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043697267909674875		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.043697267909674875 | validation: 0.04877099159004605]
	TIME [epoch: 5.74 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086938958580757		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.07086938958580757 | validation: 0.07261829124466118]
	TIME [epoch: 5.74 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05982468033239109		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.05982468033239109 | validation: 0.1354934198895017]
	TIME [epoch: 5.74 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043416680362132		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.12043416680362132 | validation: 0.12070068677488471]
	TIME [epoch: 5.74 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06765948863966616		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.06765948863966616 | validation: 0.05722039852115596]
	TIME [epoch: 5.74 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09242007655302183		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.09242007655302183 | validation: 0.05654386332225841]
	TIME [epoch: 5.75 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03668259527867842		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.03668259527867842 | validation: 0.04287266969981701]
	TIME [epoch: 5.76 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446855667657627		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.0446855667657627 | validation: 0.05905648969172368]
	TIME [epoch: 5.74 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052828755024666246		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.052828755024666246 | validation: 0.12050766431323527]
	TIME [epoch: 5.74 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0735970570062296		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.0735970570062296 | validation: 0.09195400191352228]
	TIME [epoch: 5.74 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821944937446338		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06821944937446338 | validation: 0.0717482032747225]
	TIME [epoch: 5.74 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05793136123735676		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.05793136123735676 | validation: 0.10109246642517623]
	TIME [epoch: 5.74 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753288589516619		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.09753288589516619 | validation: 0.08643111526103513]
	TIME [epoch: 5.78 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07554126899173597		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.07554126899173597 | validation: 0.0697657752699135]
	TIME [epoch: 5.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06109129274999898		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.06109129274999898 | validation: 0.06531159168626031]
	TIME [epoch: 5.74 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06118953710795113		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.06118953710795113 | validation: 0.052768063597639206]
	TIME [epoch: 5.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061610483983403325		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.061610483983403325 | validation: 0.08168091882253758]
	TIME [epoch: 5.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06988311599141832		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.06988311599141832 | validation: 0.0697520797700951]
	TIME [epoch: 5.74 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05282778884873861		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.05282778884873861 | validation: 0.03592299882457466]
	TIME [epoch: 5.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768254426804936		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.05768254426804936 | validation: 0.027981328740021696]
	TIME [epoch: 5.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05236619716269772		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.05236619716269772 | validation: 0.07260283657333029]
	TIME [epoch: 5.74 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583304556175808		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.06583304556175808 | validation: 0.03784354225864296]
	TIME [epoch: 5.73 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051147019955200684		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.051147019955200684 | validation: 0.06551600836030236]
	TIME [epoch: 5.73 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07525456445507886		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.07525456445507886 | validation: 0.054726843416340216]
	TIME [epoch: 5.74 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054874481282204214		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.054874481282204214 | validation: 0.06025561176917619]
	TIME [epoch: 5.74 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283885775892956		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.05283885775892956 | validation: 0.05395640388443969]
	TIME [epoch: 5.78 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05966834539133477		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.05966834539133477 | validation: 0.055631614564657456]
	TIME [epoch: 5.75 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1144842960864446		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.1144842960864446 | validation: 0.09527396189736605]
	TIME [epoch: 5.73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09550888056474258		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09550888056474258 | validation: 0.06703381968178779]
	TIME [epoch: 5.74 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646320850353013		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.0646320850353013 | validation: 0.06646096921471735]
	TIME [epoch: 5.74 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05686302322407281		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.05686302322407281 | validation: 0.07558612478754054]
	TIME [epoch: 5.74 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05266360583416219		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.05266360583416219 | validation: 0.04489398611181063]
	TIME [epoch: 5.75 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07151292760286627		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.07151292760286627 | validation: 0.06054384856137011]
	TIME [epoch: 5.76 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06726991901730697		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.06726991901730697 | validation: 0.09039895544312579]
	TIME [epoch: 5.74 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07162684836304327		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.07162684836304327 | validation: 0.062097901000017226]
	TIME [epoch: 5.74 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047413801538972705		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.047413801538972705 | validation: 0.0417796201152855]
	TIME [epoch: 5.73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07275371678511725		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.07275371678511725 | validation: 0.047750922832525376]
	TIME [epoch: 5.73 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920362433185377		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.06920362433185377 | validation: 0.06363259837810491]
	TIME [epoch: 5.73 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318305706196786		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.06318305706196786 | validation: 0.0393513701027048]
	TIME [epoch: 5.79 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453255722655135		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.06453255722655135 | validation: 0.08976862516814083]
	TIME [epoch: 5.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154913708772323		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.08154913708772323 | validation: 0.06467073229625994]
	TIME [epoch: 5.73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521516576483384		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.08521516576483384 | validation: 0.06741674413505466]
	TIME [epoch: 5.73 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243755777960873		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.06243755777960873 | validation: 0.04846288347378525]
	TIME [epoch: 5.73 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535646779343914		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.04535646779343914 | validation: 0.03544392003281272]
	TIME [epoch: 5.73 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04888482483435797		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.04888482483435797 | validation: 0.02838279553782746]
	TIME [epoch: 5.75 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05798742892968304		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.05798742892968304 | validation: 0.04092801399988043]
	TIME [epoch: 5.75 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743015794705903		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.06743015794705903 | validation: 0.04124014778094525]
	TIME [epoch: 5.73 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059256783097580534		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.059256783097580534 | validation: 0.04407647977349775]
	TIME [epoch: 5.73 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961568287044256		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.05961568287044256 | validation: 0.041162873989392244]
	TIME [epoch: 5.73 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044312164833844134		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.044312164833844134 | validation: 0.03983371098488554]
	TIME [epoch: 5.73 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07263058483681942		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.07263058483681942 | validation: 0.03601957878313932]
	TIME [epoch: 5.73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138162507140973		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.05138162507140973 | validation: 0.04782320458129843]
	TIME [epoch: 5.77 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07842079950391381		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.07842079950391381 | validation: 0.0700710124066095]
	TIME [epoch: 5.74 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487972288195888		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.0487972288195888 | validation: 0.04331985172845007]
	TIME [epoch: 5.73 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659074422136217		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.04659074422136217 | validation: 0.023692966562768064]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04195967614695007		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.04195967614695007 | validation: 0.054140519659506836]
	TIME [epoch: 5.75 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053455311192478275		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.053455311192478275 | validation: 0.084516616053991]
	TIME [epoch: 5.74 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05979051054682325		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.05979051054682325 | validation: 0.03906292058386561]
	TIME [epoch: 5.77 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049646261982981686		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.049646261982981686 | validation: 0.05171992306090496]
	TIME [epoch: 5.77 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04627293888333148		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.04627293888333148 | validation: 0.04155755449839627]
	TIME [epoch: 5.74 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04831101771477376		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.04831101771477376 | validation: 0.042376031472302574]
	TIME [epoch: 5.74 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05404756407156553		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.05404756407156553 | validation: 0.05580923423742007]
	TIME [epoch: 5.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376445258174905		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.04376445258174905 | validation: 0.04103613694741897]
	TIME [epoch: 5.75 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997842582334553		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.04997842582334553 | validation: 0.03387232592929578]
	TIME [epoch: 5.74 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04984122855707668		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.04984122855707668 | validation: 0.032729885948667034]
	TIME [epoch: 5.79 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557008464669893		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.05557008464669893 | validation: 0.09862526053719287]
	TIME [epoch: 5.75 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014093871286255		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.1014093871286255 | validation: 0.03933065924833021]
	TIME [epoch: 5.74 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588642175907104		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.04588642175907104 | validation: 0.06052605876557264]
	TIME [epoch: 5.75 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043861528445978154		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.043861528445978154 | validation: 0.02486600324894597]
	TIME [epoch: 5.74 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05114502397352874		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.05114502397352874 | validation: 0.030114277695198765]
	TIME [epoch: 5.76 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05234756222569735		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.05234756222569735 | validation: 0.057416918754292334]
	TIME [epoch: 5.79 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045920589526141295		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.045920589526141295 | validation: 0.055722420212529704]
	TIME [epoch: 5.77 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06530190469789326		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.06530190469789326 | validation: 0.05584211270368215]
	TIME [epoch: 5.75 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06131970386602438		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.06131970386602438 | validation: 0.03980282863633372]
	TIME [epoch: 5.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05779548642881964		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.05779548642881964 | validation: 0.0670432841589355]
	TIME [epoch: 5.74 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07294044274418886		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.07294044274418886 | validation: 0.04965605638616854]
	TIME [epoch: 5.74 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06800154417258931		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.06800154417258931 | validation: 0.0497315726380525]
	TIME [epoch: 5.75 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06923501783442283		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.06923501783442283 | validation: 0.08609872763262773]
	TIME [epoch: 5.79 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06135751586636938		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.06135751586636938 | validation: 0.05536595029317044]
	TIME [epoch: 5.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644638648632598		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.06644638648632598 | validation: 0.05175307121852375]
	TIME [epoch: 5.75 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811582767207871		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.0811582767207871 | validation: 0.07507402528471385]
	TIME [epoch: 5.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789463332428097		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.09789463332428097 | validation: 0.09118882729751433]
	TIME [epoch: 5.75 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09698126045521582		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.09698126045521582 | validation: 0.04870655983752426]
	TIME [epoch: 5.75 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789183684312341		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.0789183684312341 | validation: 0.045774204030240045]
	TIME [epoch: 5.78 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588081797672466		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.08588081797672466 | validation: 0.1415378165580504]
	TIME [epoch: 5.76 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362533874720586		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.09362533874720586 | validation: 0.058832290736547284]
	TIME [epoch: 5.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831292713558324		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.07831292713558324 | validation: 0.07792917649478846]
	TIME [epoch: 5.75 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443564989971784		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.06443564989971784 | validation: 0.06135626439942009]
	TIME [epoch: 5.75 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07847784946560385		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.07847784946560385 | validation: 0.035991939216724965]
	TIME [epoch: 5.75 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054825313899739984		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.054825313899739984 | validation: 0.06409639802673335]
	TIME [epoch: 5.75 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122303406863013		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.05122303406863013 | validation: 0.03564304725230051]
	TIME [epoch: 5.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04779106616569672		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.04779106616569672 | validation: 0.04878346902788277]
	TIME [epoch: 5.75 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05830058814346522		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.05830058814346522 | validation: 0.0644706015669512]
	TIME [epoch: 5.75 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10184978766794167		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.10184978766794167 | validation: 0.09730680296745053]
	TIME [epoch: 5.75 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10932095499745417		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.10932095499745417 | validation: 0.08290151242772252]
	TIME [epoch: 5.75 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06515736181942106		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.06515736181942106 | validation: 0.03886886295690286]
	TIME [epoch: 5.75 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717485649502191		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.0717485649502191 | validation: 0.09312244821073012]
	TIME [epoch: 5.78 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711149212553334		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07711149212553334 | validation: 0.12381697527863601]
	TIME [epoch: 5.76 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08275425894847258		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.08275425894847258 | validation: 0.058836819009031344]
	TIME [epoch: 5.75 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060966856584961676		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.060966856584961676 | validation: 0.05217256863875188]
	TIME [epoch: 5.75 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04963980610795727		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.04963980610795727 | validation: 0.05400775470284384]
	TIME [epoch: 5.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789430196373472		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.05789430196373472 | validation: 0.04743790939030518]
	TIME [epoch: 5.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538541728716299		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0538541728716299 | validation: 0.03886976697809101]
	TIME [epoch: 5.75 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034092337314728216		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.034092337314728216 | validation: 0.031001435933703504]
	TIME [epoch: 5.79 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408248327893989		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0408248327893989 | validation: 0.03938085584625657]
	TIME [epoch: 5.74 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048647170156180156		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.048647170156180156 | validation: 0.07104384235751335]
	TIME [epoch: 5.74 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673322204767015		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.0673322204767015 | validation: 0.09655538590559093]
	TIME [epoch: 5.75 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816754038452883		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.05816754038452883 | validation: 0.028984282805465302]
	TIME [epoch: 5.75 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04128187653025049		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.04128187653025049 | validation: 0.035739896805947594]
	TIME [epoch: 5.75 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05132716111065498		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.05132716111065498 | validation: 0.06629017672225283]
	TIME [epoch: 5.79 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045359742257459354		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.045359742257459354 | validation: 0.04675014121923996]
	TIME [epoch: 5.76 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039360571700440466		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.039360571700440466 | validation: 0.02882751123011039]
	TIME [epoch: 5.75 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044591914831142734		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.044591914831142734 | validation: 0.02792578865907821]
	TIME [epoch: 5.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044071093847267664		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.044071093847267664 | validation: 0.03068127801156588]
	TIME [epoch: 5.74 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04280932020623922		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.04280932020623922 | validation: 0.1066630890566864]
	TIME [epoch: 5.76 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06085987026879007		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.06085987026879007 | validation: 0.04948495156194649]
	TIME [epoch: 5.76 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522680038169521		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1522680038169521 | validation: 0.0831385052226809]
	TIME [epoch: 5.79 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776365631705871		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0776365631705871 | validation: 0.03711287999326189]
	TIME [epoch: 5.75 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062075915545462		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.05062075915545462 | validation: 0.08860850007213535]
	TIME [epoch: 5.74 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046961818266194444		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.046961818266194444 | validation: 0.023649497962795172]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04358510540873848		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.04358510540873848 | validation: 0.028729066312868264]
	TIME [epoch: 5.74 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03317685369915985		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.03317685369915985 | validation: 0.02959306378581073]
	TIME [epoch: 5.74 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138507702586298		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.04138507702586298 | validation: 0.032839258459934614]
	TIME [epoch: 5.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042394518088701726		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.042394518088701726 | validation: 0.07448623121023923]
	TIME [epoch: 5.76 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061090817399245066		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.061090817399245066 | validation: 0.0403551320662825]
	TIME [epoch: 5.75 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08976243824879404		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.08976243824879404 | validation: 0.05254872066385431]
	TIME [epoch: 5.74 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633272201543637		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.0633272201543637 | validation: 0.035360014542254674]
	TIME [epoch: 5.74 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381389534743644		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.04381389534743644 | validation: 0.044633562980748935]
	TIME [epoch: 5.74 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988464955475377		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07988464955475377 | validation: 0.06042682953954895]
	TIME [epoch: 5.76 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06524743494318863		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.06524743494318863 | validation: 0.06647495494055945]
	TIME [epoch: 5.77 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315599921801358		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.04315599921801358 | validation: 0.025954316876044773]
	TIME [epoch: 5.75 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455223299319761		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.03455223299319761 | validation: 0.07319255943860874]
	TIME [epoch: 5.75 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058274252801864775		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.058274252801864775 | validation: 0.12737966990854668]
	TIME [epoch: 5.74 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991301691450432		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08991301691450432 | validation: 0.046291623072442736]
	TIME [epoch: 5.74 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05657862826249124		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.05657862826249124 | validation: 0.059531936378226916]
	TIME [epoch: 5.74 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05247615152049922		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.05247615152049922 | validation: 0.04125843615975664]
	TIME [epoch: 5.78 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05611346368963426		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.05611346368963426 | validation: 0.053511152008119414]
	TIME [epoch: 5.75 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058356591164761336		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.058356591164761336 | validation: 0.05363461503127526]
	TIME [epoch: 5.74 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307710958638511		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.05307710958638511 | validation: 0.04840073856163212]
	TIME [epoch: 5.74 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05455634533640269		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.05455634533640269 | validation: 0.05663609514255452]
	TIME [epoch: 5.74 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056858848430468796		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.056858848430468796 | validation: 0.04148780608026437]
	TIME [epoch: 5.74 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060430621451974385		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.060430621451974385 | validation: 0.04816623827073652]
	TIME [epoch: 5.76 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240148893016668		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.07240148893016668 | validation: 0.07687810403882392]
	TIME [epoch: 5.77 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110719957433328		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.05110719957433328 | validation: 0.04477428949426702]
	TIME [epoch: 5.75 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586244002089933		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.04586244002089933 | validation: 0.03822472430604035]
	TIME [epoch: 5.74 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04292448874021002		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.04292448874021002 | validation: 0.0398343881937682]
	TIME [epoch: 5.74 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039997547890032875		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.039997547890032875 | validation: 0.03894839378473918]
	TIME [epoch: 5.74 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002882078471881		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.04002882078471881 | validation: 0.03817107783788616]
	TIME [epoch: 5.73 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05660476899170842		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.05660476899170842 | validation: 0.05372706803921853]
	TIME [epoch: 5.79 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056495929130849026		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.056495929130849026 | validation: 0.07359683893849837]
	TIME [epoch: 5.75 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475111445208118		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.06475111445208118 | validation: 0.07801247614360884]
	TIME [epoch: 5.75 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050731803704851516		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.050731803704851516 | validation: 0.03930957574039063]
	TIME [epoch: 5.75 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756053566543275		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.05756053566543275 | validation: 0.05209123855632863]
	TIME [epoch: 5.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061469923966969583		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.061469923966969583 | validation: 0.06381431684741803]
	TIME [epoch: 5.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045019297087793		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.045019297087793 | validation: 0.0632488848369494]
	TIME [epoch: 5.76 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058010073638620055		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.058010073638620055 | validation: 0.052885555272471726]
	TIME [epoch: 5.77 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042631448788465184		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.042631448788465184 | validation: 0.05419530379630712]
	TIME [epoch: 5.74 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04144826341293217		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.04144826341293217 | validation: 0.06256559943106794]
	TIME [epoch: 5.74 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05523115630688573		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.05523115630688573 | validation: 0.0518551494014701]
	TIME [epoch: 5.74 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065083581265265		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.065083581265265 | validation: 0.11358259715055172]
	TIME [epoch: 5.74 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417260096717889		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.08417260096717889 | validation: 0.036364187761345]
	TIME [epoch: 5.74 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04392161876976222		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.04392161876976222 | validation: 0.04312882976433368]
	TIME [epoch: 5.79 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840637033491164		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.03840637033491164 | validation: 0.03820439942573827]
	TIME [epoch: 5.74 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508748593055282		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.03508748593055282 | validation: 0.06416401082336108]
	TIME [epoch: 5.74 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038857706942591295		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.038857706942591295 | validation: 0.04589455731653002]
	TIME [epoch: 5.74 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04006163925306623		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.04006163925306623 | validation: 0.01961276156495464]
	TIME [epoch: 5.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550858029436571		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.03550858029436571 | validation: 0.022586531709332607]
	TIME [epoch: 5.75 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029216610641896238		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.029216610641896238 | validation: 0.030759284601527194]
	TIME [epoch: 5.77 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863684356418821		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.04863684356418821 | validation: 0.06007322068186996]
	TIME [epoch: 5.78 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04823560447409784		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.04823560447409784 | validation: 0.09466500385504062]
	TIME [epoch: 5.75 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06669657473940868		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.06669657473940868 | validation: 0.06784671775167164]
	TIME [epoch: 5.75 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051359661386874325		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.051359661386874325 | validation: 0.06367254997132872]
	TIME [epoch: 5.75 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704590601930566		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.06704590601930566 | validation: 0.04289457274965313]
	TIME [epoch: 5.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728675456168373		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.04728675456168373 | validation: 0.04765519006624235]
	TIME [epoch: 5.75 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598389096684761		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.0598389096684761 | validation: 0.033896782777778]
	TIME [epoch: 5.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046034373215772556		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.046034373215772556 | validation: 0.027759898919234024]
	TIME [epoch: 5.76 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04227655447835312		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.04227655447835312 | validation: 0.03520483573312328]
	TIME [epoch: 5.75 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505952826481968		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.03505952826481968 | validation: 0.0547564231828693]
	TIME [epoch: 5.75 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003833751753757		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.04003833751753757 | validation: 0.02750221527402579]
	TIME [epoch: 5.75 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034983171526847406		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.034983171526847406 | validation: 0.031527457409521356]
	TIME [epoch: 5.75 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029723078905024125		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.029723078905024125 | validation: 0.01877269904291949]
	TIME [epoch: 5.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034327182756844876		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.034327182756844876 | validation: 0.0964285883430118]
	TIME [epoch: 5.77 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06077031834564535		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.06077031834564535 | validation: 0.05232590078644022]
	TIME [epoch: 5.76 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04450196387877732		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.04450196387877732 | validation: 0.03557005698879775]
	TIME [epoch: 5.75 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550001503725998		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.03550001503725998 | validation: 0.05002148417373847]
	TIME [epoch: 5.75 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053208710266683855		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.053208710266683855 | validation: 0.05161893506535495]
	TIME [epoch: 5.75 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05287101899743806		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.05287101899743806 | validation: 0.02607560783027432]
	TIME [epoch: 5.76 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802259350819549		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.03802259350819549 | validation: 0.03261989830618285]
	TIME [epoch: 5.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033755435390655425		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.033755435390655425 | validation: 0.03021734864209813]
	TIME [epoch: 5.75 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728784039730648		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.04728784039730648 | validation: 0.057855957346002955]
	TIME [epoch: 5.75 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003298201873591		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.04003298201873591 | validation: 0.03308712058908313]
	TIME [epoch: 5.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947239110552744		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.03947239110552744 | validation: 0.031011462523857638]
	TIME [epoch: 5.75 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03652209169586065		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.03652209169586065 | validation: 0.03129114170422939]
	TIME [epoch: 5.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797800124655284		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.03797800124655284 | validation: 0.035418792396883156]
	TIME [epoch: 5.78 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035405153096944704		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.035405153096944704 | validation: 0.026453289069457035]
	TIME [epoch: 5.76 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242246064184406		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.04242246064184406 | validation: 0.060262755025762366]
	TIME [epoch: 5.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344667821547085		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.05344667821547085 | validation: 0.05852943410802396]
	TIME [epoch: 5.75 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05163937937592244		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.05163937937592244 | validation: 0.0199808406012398]
	TIME [epoch: 5.75 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035462298905461445		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.035462298905461445 | validation: 0.025737118796235026]
	TIME [epoch: 5.75 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0351614335042653		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.0351614335042653 | validation: 0.030119133404065804]
	TIME [epoch: 5.75 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341322911038878		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.03341322911038878 | validation: 0.007218552801219072]
	TIME [epoch: 5.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028725932286543618		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.028725932286543618 | validation: 0.01851617429972123]
	TIME [epoch: 5.76 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032144766009875474		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.032144766009875474 | validation: 0.037325356583156694]
	TIME [epoch: 5.75 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04152978272144918		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.04152978272144918 | validation: 0.028204942695107482]
	TIME [epoch: 5.75 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03061647146707326		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.03061647146707326 | validation: 0.02638031654331484]
	TIME [epoch: 5.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03393419050543632		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.03393419050543632 | validation: 0.023893254274153515]
	TIME [epoch: 5.75 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033149142315054544		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.033149142315054544 | validation: 0.027135682255878927]
	TIME [epoch: 5.79 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03617955175578564		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.03617955175578564 | validation: 0.02629310909115701]
	TIME [epoch: 5.76 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04658134981971223		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.04658134981971223 | validation: 0.02781112291568863]
	TIME [epoch: 5.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03283194533138733		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.03283194533138733 | validation: 0.022456239565447195]
	TIME [epoch: 5.75 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03089122302340563		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.03089122302340563 | validation: 0.038083264097330684]
	TIME [epoch: 5.75 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04797053625722948		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.04797053625722948 | validation: 0.04333963959800656]
	TIME [epoch: 5.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859842088104314		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.04859842088104314 | validation: 0.05701346219911138]
	TIME [epoch: 5.77 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262763305875891		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.04262763305875891 | validation: 0.027864788225452963]
	TIME [epoch: 5.78 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04094157327544005		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.04094157327544005 | validation: 0.0644509783824228]
	TIME [epoch: 5.76 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738624492193276		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.04738624492193276 | validation: 0.05095812785932496]
	TIME [epoch: 5.75 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05103489847753093		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.05103489847753093 | validation: 0.0300975308573796]
	TIME [epoch: 5.75 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03294601911271423		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.03294601911271423 | validation: 0.017902163808462226]
	TIME [epoch: 5.75 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04238489218266621		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.04238489218266621 | validation: 0.09367373439181595]
	TIME [epoch: 5.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05572850095986882		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.05572850095986882 | validation: 0.035175087579147134]
	TIME [epoch: 5.79 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043660597357621844		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.043660597357621844 | validation: 0.04886687652062007]
	TIME [epoch: 5.76 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03901183185167813		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.03901183185167813 | validation: 0.020880999645738103]
	TIME [epoch: 5.75 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03237814194041211		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.03237814194041211 | validation: 0.01829934323572662]
	TIME [epoch: 5.75 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025290788606490314		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.025290788606490314 | validation: 0.023488260528193916]
	TIME [epoch: 5.75 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919725485889264		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.02919725485889264 | validation: 0.03068805590183778]
	TIME [epoch: 5.75 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939492122402602		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.03939492122402602 | validation: 0.12234352576737945]
	TIME [epoch: 5.77 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460333949991607		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.07460333949991607 | validation: 0.043466257512008194]
	TIME [epoch: 5.78 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844273054120829		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.03844273054120829 | validation: 0.037412190460347994]
	TIME [epoch: 5.75 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03896541610421248		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.03896541610421248 | validation: 0.01732688430735321]
	TIME [epoch: 5.75 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039101237021921226		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.039101237021921226 | validation: 0.05908978344577773]
	TIME [epoch: 5.75 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05086623480269214		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.05086623480269214 | validation: 0.06513866053578576]
	TIME [epoch: 5.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472579156190399		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.03472579156190399 | validation: 0.04987843494306283]
	TIME [epoch: 5.75 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04491255261458384		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.04491255261458384 | validation: 0.05964133168977956]
	TIME [epoch: 5.79 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040711387949255176		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.040711387949255176 | validation: 0.03974635090531252]
	TIME [epoch: 5.75 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037626035173747255		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.037626035173747255 | validation: 0.036657169093486444]
	TIME [epoch: 5.75 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909881074127706		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.03909881074127706 | validation: 0.024007135352228065]
	TIME [epoch: 5.75 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03022829573293884		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.03022829573293884 | validation: 0.01996599240342307]
	TIME [epoch: 5.75 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030706461523436566		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.030706461523436566 | validation: 0.022819551125868056]
	TIME [epoch: 5.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026622359923087247		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.026622359923087247 | validation: 0.024951838956478074]
	TIME [epoch: 5.76 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171830404216759		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.03171830404216759 | validation: 0.04406579467102244]
	TIME [epoch: 5.78 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034553608542044506		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.034553608542044506 | validation: 0.030120451552039695]
	TIME [epoch: 5.75 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661499714900919		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.03661499714900919 | validation: 0.07156197865304952]
	TIME [epoch: 5.75 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06673272995409535		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06673272995409535 | validation: 0.04615921152017293]
	TIME [epoch: 5.75 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038778520968973086		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.038778520968973086 | validation: 0.042078159423855344]
	TIME [epoch: 5.75 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04793455526081333		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.04793455526081333 | validation: 0.038518291440096546]
	TIME [epoch: 5.75 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029376165431978657		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.029376165431978657 | validation: 0.050380937812945725]
	TIME [epoch: 5.79 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040201697313532445		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.040201697313532445 | validation: 0.020209484909263678]
	TIME [epoch: 5.76 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03205575635318318		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.03205575635318318 | validation: 0.02379243784551216]
	TIME [epoch: 5.75 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834315443180959		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.03834315443180959 | validation: 0.052324090210838906]
	TIME [epoch: 5.75 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04928855591145647		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.04928855591145647 | validation: 0.052947259907360406]
	TIME [epoch: 5.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750409311702383		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.04750409311702383 | validation: 0.04130202349286269]
	TIME [epoch: 5.75 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034741906156973715		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.034741906156973715 | validation: 0.03292723878226852]
	TIME [epoch: 5.77 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040016941919292115		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.040016941919292115 | validation: 0.057769171478112454]
	TIME [epoch: 5.78 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656139404825324		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.04656139404825324 | validation: 0.02435007813734691]
	TIME [epoch: 5.75 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813817352221163		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.03813817352221163 | validation: 0.04363677818110892]
	TIME [epoch: 5.75 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040027964853598184		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.040027964853598184 | validation: 0.034885044873690256]
	TIME [epoch: 5.75 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038551905726447		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.04038551905726447 | validation: 0.03181075038300987]
	TIME [epoch: 5.75 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038716924408762676		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.038716924408762676 | validation: 0.04221344528622335]
	TIME [epoch: 5.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033034754599252446		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.033034754599252446 | validation: 0.021981056675551496]
	TIME [epoch: 5.79 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03205598571481572		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.03205598571481572 | validation: 0.02963002957202071]
	TIME [epoch: 5.75 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227763779218067		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.03227763779218067 | validation: 0.03355803891502109]
	TIME [epoch: 5.75 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04009900610358126		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.04009900610358126 | validation: 0.030033787185031167]
	TIME [epoch: 5.75 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03653347001289881		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.03653347001289881 | validation: 0.03594216542186945]
	TIME [epoch: 5.75 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885292675677946		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.03885292675677946 | validation: 0.04142264862954731]
	TIME [epoch: 5.75 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04247124867716436		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.04247124867716436 | validation: 0.022728567465303984]
	TIME [epoch: 5.78 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04253113597812333		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.04253113597812333 | validation: 0.05631984122808376]
	TIME [epoch: 5.76 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06423498393120955		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06423498393120955 | validation: 0.0462195672141639]
	TIME [epoch: 5.75 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325446682246881		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.03325446682246881 | validation: 0.050142393374383865]
	TIME [epoch: 5.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270891263878877		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.03270891263878877 | validation: 0.028886622209890817]
	TIME [epoch: 5.75 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037050438070941785		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.037050438070941785 | validation: 0.03217298616981946]
	TIME [epoch: 5.75 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03520338482399532		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.03520338482399532 | validation: 0.03304297371334907]
	TIME [epoch: 5.75 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035397530467760834		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.035397530467760834 | validation: 0.03955358225944133]
	TIME [epoch: 5.79 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451559336658338		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.03451559336658338 | validation: 0.019634773637117103]
	TIME [epoch: 5.75 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232172538414553		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.03232172538414553 | validation: 0.02778901451222128]
	TIME [epoch: 5.75 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035530446733757076		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.035530446733757076 | validation: 0.04885821168160189]
	TIME [epoch: 5.75 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04547183813079071		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.04547183813079071 | validation: 0.061735919499691205]
	TIME [epoch: 5.75 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731698218750869		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04731698218750869 | validation: 0.034758374809512584]
	TIME [epoch: 5.75 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739468489650528		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.04739468489650528 | validation: 0.04082358430268978]
	TIME [epoch: 5.78 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04378920813789784		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.04378920813789784 | validation: 0.03785980336468672]
	TIME [epoch: 5.76 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05269315107908343		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.05269315107908343 | validation: 0.04054278153863862]
	TIME [epoch: 5.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056282933871771426		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.056282933871771426 | validation: 0.0377062128485665]
	TIME [epoch: 5.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694835293893808		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.04694835293893808 | validation: 0.029009629845072313]
	TIME [epoch: 5.75 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703810816765991		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.03703810816765991 | validation: 0.04274444087295149]
	TIME [epoch: 5.75 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057811198911608484		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.057811198911608484 | validation: 0.028005079020017077]
	TIME [epoch: 5.75 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944638217917505		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.03944638217917505 | validation: 0.013932977975467189]
	TIME [epoch: 5.79 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496506255538653		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.03496506255538653 | validation: 0.0208159668517894]
	TIME [epoch: 5.75 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038845370733818836		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.038845370733818836 | validation: 0.04227987731728638]
	TIME [epoch: 5.75 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03696325781628933		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03696325781628933 | validation: 0.031862851700045026]
	TIME [epoch: 5.75 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041939919193353596		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.041939919193353596 | validation: 0.027280732737302815]
	TIME [epoch: 5.75 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040932760409063074		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.040932760409063074 | validation: 0.025527112558271097]
	TIME [epoch: 5.75 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038725128480820215		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.038725128480820215 | validation: 0.024497506127431096]
	TIME [epoch: 5.78 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03351100789221487		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.03351100789221487 | validation: 0.027064312716130842]
	TIME [epoch: 5.76 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03094544368217298		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.03094544368217298 | validation: 0.028074466817302423]
	TIME [epoch: 5.75 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031510804657458175		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.031510804657458175 | validation: 0.0214439612452135]
	TIME [epoch: 5.75 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040355337911237396		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.040355337911237396 | validation: 0.022475465122004188]
	TIME [epoch: 5.75 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03723158292946106		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.03723158292946106 | validation: 0.052186152104523556]
	TIME [epoch: 5.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048594239239745145		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.048594239239745145 | validation: 0.03930115523480993]
	TIME [epoch: 5.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038082977121835275		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.038082977121835275 | validation: 0.033058843732362994]
	TIME [epoch: 5.79 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0410887958109413		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0410887958109413 | validation: 0.030529599548517958]
	TIME [epoch: 5.75 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03950102946741947		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.03950102946741947 | validation: 0.039694875468926874]
	TIME [epoch: 5.75 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569396138395641		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.03569396138395641 | validation: 0.02531317541516204]
	TIME [epoch: 5.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391779445885863		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0391779445885863 | validation: 0.030879956476420153]
	TIME [epoch: 5.75 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03334857702427531		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.03334857702427531 | validation: 0.026071579219774686]
	TIME [epoch: 5.75 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03439146607970109		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03439146607970109 | validation: 0.026433676637335077]
	TIME [epoch: 5.78 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0453609135005079		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0453609135005079 | validation: 0.03309240664288923]
	TIME [epoch: 5.76 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043552875499336036		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.043552875499336036 | validation: 0.02695304707921941]
	TIME [epoch: 5.75 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525459754158441		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.03525459754158441 | validation: 0.04932622774726987]
	TIME [epoch: 5.75 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05024277517904249		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.05024277517904249 | validation: 0.035914189881987524]
	TIME [epoch: 5.75 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039168346379143223		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.039168346379143223 | validation: 0.022587228286962295]
	TIME [epoch: 5.75 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352939380285728		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.04352939380285728 | validation: 0.04375660868477938]
	TIME [epoch: 5.75 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041594952892332386		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.041594952892332386 | validation: 0.0268777955590548]
	TIME [epoch: 5.79 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035392367316855716		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.035392367316855716 | validation: 0.018284307355905017]
	TIME [epoch: 5.75 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03836604507121172		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.03836604507121172 | validation: 0.03429114746779912]
	TIME [epoch: 5.75 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331668978561018		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0331668978561018 | validation: 0.02597483673917661]
	TIME [epoch: 5.75 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030747202240463022		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.030747202240463022 | validation: 0.024262052668681575]
	TIME [epoch: 5.75 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03999316727117598		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.03999316727117598 | validation: 0.022623303270522165]
	TIME [epoch: 5.75 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220390229222357		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03220390229222357 | validation: 0.033013039940711184]
	TIME [epoch: 5.78 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195151572180509		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03195151572180509 | validation: 0.029630978884628796]
	TIME [epoch: 5.76 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042479100813618484		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.042479100813618484 | validation: 0.043827629904858834]
	TIME [epoch: 5.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04463515215263465		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.04463515215263465 | validation: 0.052770603297865995]
	TIME [epoch: 5.75 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052505564909394245		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.052505564909394245 | validation: 0.03210441232303134]
	TIME [epoch: 5.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04334956449547814		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.04334956449547814 | validation: 0.024937884070697313]
	TIME [epoch: 5.75 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040783732128199274		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.040783732128199274 | validation: 0.030768901233444397]
	TIME [epoch: 5.76 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04351699946084553		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.04351699946084553 | validation: 0.03561680103592917]
	TIME [epoch: 5.79 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022440831149018		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.04022440831149018 | validation: 0.03311540131248246]
	TIME [epoch: 5.75 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04160844928254659		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.04160844928254659 | validation: 0.031653081712842444]
	TIME [epoch: 5.75 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750937881482966		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.03750937881482966 | validation: 0.019993083718515534]
	TIME [epoch: 5.75 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03591055487667364		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03591055487667364 | validation: 0.026455035421391253]
	TIME [epoch: 5.75 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286703268409359		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.03286703268409359 | validation: 0.026399642502243675]
	TIME [epoch: 5.75 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031947653141370824		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.031947653141370824 | validation: 0.027054634183951987]
	TIME [epoch: 5.79 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171379869805537		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.03171379869805537 | validation: 0.029535386782116608]
	TIME [epoch: 5.75 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278568213799628		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0278568213799628 | validation: 0.02845377434368796]
	TIME [epoch: 5.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330729082158971		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.03330729082158971 | validation: 0.031659147644182546]
	TIME [epoch: 5.75 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027512328712575102		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.027512328712575102 | validation: 0.01914084392451035]
	TIME [epoch: 5.75 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0314338118807725		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0314338118807725 | validation: 0.03042663603321683]
	TIME [epoch: 5.75 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03568989754911708		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.03568989754911708 | validation: 0.043265352570638654]
	TIME [epoch: 5.76 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287496986432419		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.03287496986432419 | validation: 0.022459719012440003]
	TIME [epoch: 5.78 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169525144611509		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.03169525144611509 | validation: 0.03279034056707026]
	TIME [epoch: 5.75 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682082369608104		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.03682082369608104 | validation: 0.028039025188183356]
	TIME [epoch: 5.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036779881232543325		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.036779881232543325 | validation: 0.039435715502024474]
	TIME [epoch: 5.75 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030857890101898804		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.030857890101898804 | validation: 0.017952862467441003]
	TIME [epoch: 5.75 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038651293471088616		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.038651293471088616 | validation: 0.02780122947561786]
	TIME [epoch: 5.75 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03579873976861364		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.03579873976861364 | validation: 0.04247406628543188]
	TIME [epoch: 5.79 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597524409443306		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.03597524409443306 | validation: 0.021734331405069723]
	TIME [epoch: 5.76 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337069568401383		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.0337069568401383 | validation: 0.020438626593158954]
	TIME [epoch: 5.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02493558165002048		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.02493558165002048 | validation: 0.015889731233145223]
	TIME [epoch: 5.75 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02762197708251983		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.02762197708251983 | validation: 0.026090120824155336]
	TIME [epoch: 5.75 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029472505884789536		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.029472505884789536 | validation: 0.02228233640482686]
	TIME [epoch: 5.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025191658577633468		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.025191658577633468 | validation: 0.021265938544892952]
	TIME [epoch: 5.77 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02817788987945652		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.02817788987945652 | validation: 0.018487756217674685]
	TIME [epoch: 5.78 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02746953283628039		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.02746953283628039 | validation: 0.014359904950588046]
	TIME [epoch: 5.75 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028762262697939765		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.028762262697939765 | validation: 0.04144672905629065]
	TIME [epoch: 5.75 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838121204151984		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.03838121204151984 | validation: 0.0319850190808197]
	TIME [epoch: 5.75 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555351802872196		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.04555351802872196 | validation: 0.0363596672583126]
	TIME [epoch: 5.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030578078420788017		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.030578078420788017 | validation: 0.021131738246431168]
	TIME [epoch: 5.75 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025657552671838335		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.025657552671838335 | validation: 0.026251636530648312]
	TIME [epoch: 5.79 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03363615012747266		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.03363615012747266 | validation: 0.03276585850111401]
	TIME [epoch: 5.76 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028425224452769834		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.028425224452769834 | validation: 0.03353221905068432]
	TIME [epoch: 5.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027426007446029164		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.027426007446029164 | validation: 0.037121273914149135]
	TIME [epoch: 5.75 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037058778212570184		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.037058778212570184 | validation: 0.029871821536107925]
	TIME [epoch: 5.75 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026216618042351054		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.026216618042351054 | validation: 0.016281003283171443]
	TIME [epoch: 5.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026245944102180695		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.026245944102180695 | validation: 0.022014254797097194]
	TIME [epoch: 5.77 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029517060841940813		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.029517060841940813 | validation: 0.021631992295419726]
	TIME [epoch: 5.78 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026675701527671826		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.026675701527671826 | validation: 0.019617773083010534]
	TIME [epoch: 5.75 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026737027213978498		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.026737027213978498 | validation: 0.021882036173971768]
	TIME [epoch: 5.75 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028222290880268126		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.028222290880268126 | validation: 0.031206667484973565]
	TIME [epoch: 5.75 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029189115430051336		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.029189115430051336 | validation: 0.021237087659444907]
	TIME [epoch: 5.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023087146137094637		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.023087146137094637 | validation: 0.022549167254131478]
	TIME [epoch: 5.75 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031932056687898384		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.031932056687898384 | validation: 0.0534020582204297]
	TIME [epoch: 5.79 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0441237068810655		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.0441237068810655 | validation: 0.019958305554156768]
	TIME [epoch: 5.76 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027354359199891584		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.027354359199891584 | validation: 0.018067317519335994]
	TIME [epoch: 5.75 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320968422777667		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.026320968422777667 | validation: 0.02586415055741285]
	TIME [epoch: 5.75 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028629019362332992		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.028629019362332992 | validation: 0.03247060427796022]
	TIME [epoch: 5.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032352275667089966		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.032352275667089966 | validation: 0.035519594146615215]
	TIME [epoch: 5.75 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03455150862126044		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.03455150862126044 | validation: 0.04333288590758398]
	TIME [epoch: 5.76 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543899722676486		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.03543899722676486 | validation: 0.023748502330117528]
	TIME [epoch: 5.78 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023232459157526506		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.023232459157526506 | validation: 0.009024817955914652]
	TIME [epoch: 5.75 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023301858880929976		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.023301858880929976 | validation: 0.03228046998477668]
	TIME [epoch: 5.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03537184283128833		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.03537184283128833 | validation: 0.021979277628875717]
	TIME [epoch: 5.75 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022991681166421907		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.022991681166421907 | validation: 0.025256558255776385]
	TIME [epoch: 5.75 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026178354968564164		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.026178354968564164 | validation: 0.022460731895680174]
	TIME [epoch: 5.75 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024433137676247038		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.024433137676247038 | validation: 0.024403039211506657]
	TIME [epoch: 5.79 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02574156577587797		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.02574156577587797 | validation: 0.02665293592191501]
	TIME [epoch: 5.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033046894098804264		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.033046894098804264 | validation: 0.01991850243912882]
	TIME [epoch: 5.75 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02626422588047321		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.02626422588047321 | validation: 0.023570434887733933]
	TIME [epoch: 5.75 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027738958883643538		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.027738958883643538 | validation: 0.01410189108554865]
	TIME [epoch: 5.75 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028946977260197893		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.028946977260197893 | validation: 0.028845383486809376]
	TIME [epoch: 5.75 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02553323678778005		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.02553323678778005 | validation: 0.032232301511242484]
	TIME [epoch: 5.78 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022507060503211385		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.022507060503211385 | validation: 0.030282655253782265]
	TIME [epoch: 5.76 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034061570347617094		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.034061570347617094 | validation: 0.032203605452899034]
	TIME [epoch: 5.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03324849635143722		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.03324849635143722 | validation: 0.0352066546939638]
	TIME [epoch: 5.75 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030706390086127806		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.030706390086127806 | validation: 0.023769538325388223]
	TIME [epoch: 5.75 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02688295938404456		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.02688295938404456 | validation: 0.029725019264866526]
	TIME [epoch: 5.75 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030766697869598323		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.030766697869598323 | validation: 0.019238295769908376]
	TIME [epoch: 5.75 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02566565577542728		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.02566565577542728 | validation: 0.02978693646807551]
	TIME [epoch: 5.79 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033164668641640485		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.033164668641640485 | validation: 0.025783416019225226]
	TIME [epoch: 5.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036744221596408305		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.036744221596408305 | validation: 0.034803913616678374]
	TIME [epoch: 5.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025655228023779564		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.025655228023779564 | validation: 0.015187797902730314]
	TIME [epoch: 5.75 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024058496186809646		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.024058496186809646 | validation: 0.022247122104325005]
	TIME [epoch: 5.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711586572580621		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.02711586572580621 | validation: 0.031818530412579274]
	TIME [epoch: 5.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034640729238341536		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.034640729238341536 | validation: 0.026896768764154064]
	TIME [epoch: 5.78 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046348625215374		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.03046348625215374 | validation: 0.04527731931848464]
	TIME [epoch: 5.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04102853470011708		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.04102853470011708 | validation: 0.02525210923929308]
	TIME [epoch: 5.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029997955496244358		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.029997955496244358 | validation: 0.022463532492331774]
	TIME [epoch: 5.75 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026780071778246976		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.026780071778246976 | validation: 0.021018042950000346]
	TIME [epoch: 5.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022054994471213316		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.022054994471213316 | validation: 0.028296301165326474]
	TIME [epoch: 5.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636664750423603		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.02636664750423603 | validation: 0.020251421725042282]
	TIME [epoch: 5.75 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02880727500159601		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.02880727500159601 | validation: 0.03657926358559191]
	TIME [epoch: 5.79 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267290540170213		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.03267290540170213 | validation: 0.02308796082321799]
	TIME [epoch: 5.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030761365035050642		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.030761365035050642 | validation: 0.028829145609996897]
	TIME [epoch: 5.75 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03423161701530654		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.03423161701530654 | validation: 0.03459475870015]
	TIME [epoch: 5.75 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032528920600620195		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.032528920600620195 | validation: 0.026494032284447633]
	TIME [epoch: 5.75 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330475555482016		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.0330475555482016 | validation: 0.04511241724121012]
	TIME [epoch: 5.75 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029805780844918504		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.029805780844918504 | validation: 0.020510697701498236]
	TIME [epoch: 5.78 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02611784604549412		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.02611784604549412 | validation: 0.020244013829402326]
	TIME [epoch: 5.76 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027569387921564388		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.027569387921564388 | validation: 0.02558637832157964]
	TIME [epoch: 5.75 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024424081589282002		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.024424081589282002 | validation: 0.013685209674161232]
	TIME [epoch: 5.75 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0246602144761605		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.0246602144761605 | validation: 0.03176340491602678]
	TIME [epoch: 5.75 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026515487118868104		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.026515487118868104 | validation: 0.022921298270578944]
	TIME [epoch: 5.75 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031158770932944998		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.031158770932944998 | validation: 0.02495340445578754]
	TIME [epoch: 5.75 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027633393579139742		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.027633393579139742 | validation: 0.02363242601403716]
	TIME [epoch: 5.79 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02103405260559626		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.02103405260559626 | validation: 0.04162597711316326]
	TIME [epoch: 5.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03069123029048361		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.03069123029048361 | validation: 0.016643149039314523]
	TIME [epoch: 5.75 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02248468388193491		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.02248468388193491 | validation: 0.018070714383518365]
	TIME [epoch: 5.75 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035660587815669005		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.035660587815669005 | validation: 0.0395999318950958]
	TIME [epoch: 5.75 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03683830614088171		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03683830614088171 | validation: 0.04773161276645123]
	TIME [epoch: 5.75 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02319376815496812		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.02319376815496812 | validation: 0.03281654606198206]
	TIME [epoch: 5.78 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041038079354977997		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.041038079354977997 | validation: 0.02251649301350898]
	TIME [epoch: 5.76 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028395970896550098		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.028395970896550098 | validation: 0.016554098792739076]
	TIME [epoch: 5.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712348934474871		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.02712348934474871 | validation: 0.022174659529502767]
	TIME [epoch: 5.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025728295365477338		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.025728295365477338 | validation: 0.017700036888489864]
	TIME [epoch: 5.75 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022710820515069542		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.022710820515069542 | validation: 0.016738261441336028]
	TIME [epoch: 5.75 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02915419989176117		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.02915419989176117 | validation: 0.02775391942110028]
	TIME [epoch: 5.75 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03398867490271076		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.03398867490271076 | validation: 0.022850983419637438]
	TIME [epoch: 5.79 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024958480453439732		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.024958480453439732 | validation: 0.026130537230214853]
	TIME [epoch: 5.75 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266262906289842		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0266262906289842 | validation: 0.02571427062841991]
	TIME [epoch: 5.75 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02259704718118143		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.02259704718118143 | validation: 0.02613448639588749]
	TIME [epoch: 5.75 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636003326798225		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.02636003326798225 | validation: 0.026346240143577858]
	TIME [epoch: 5.75 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022414752969199654		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.022414752969199654 | validation: 0.023621615979369476]
	TIME [epoch: 5.75 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022134142717988206		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.022134142717988206 | validation: 0.022799171444535943]
	TIME [epoch: 5.78 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232654483357589		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.02232654483357589 | validation: 0.030722810784333764]
	TIME [epoch: 5.76 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03085317035631646		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.03085317035631646 | validation: 0.025048704523565953]
	TIME [epoch: 5.75 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03138006136469444		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.03138006136469444 | validation: 0.015399902255340457]
	TIME [epoch: 5.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029503078579234843		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.029503078579234843 | validation: 0.02316858243763301]
	TIME [epoch: 5.75 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02282492516989471		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.02282492516989471 | validation: 0.02506736273276669]
	TIME [epoch: 5.75 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026852107276879394		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.026852107276879394 | validation: 0.025482695982529897]
	TIME [epoch: 5.76 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023095533529185586		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.023095533529185586 | validation: 0.03194215272507234]
	TIME [epoch: 5.79 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359024270001145		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.02359024270001145 | validation: 0.021795374443568296]
	TIME [epoch: 5.75 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471826188377306		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03471826188377306 | validation: 0.054505536275899547]
	TIME [epoch: 5.75 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038816015318882464		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.038816015318882464 | validation: 0.03996110436667283]
	TIME [epoch: 5.75 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024582951375899116		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.024582951375899116 | validation: 0.01671499689887989]
	TIME [epoch: 5.75 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024939355722636593		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.024939355722636593 | validation: 0.025153773262480333]
	TIME [epoch: 5.75 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027363111327271625		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.027363111327271625 | validation: 0.026684675287297236]
	TIME [epoch: 5.79 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029456253328383544		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.029456253328383544 | validation: 0.03623871059196057]
	TIME [epoch: 5.76 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02529292396195129		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.02529292396195129 | validation: 0.021268627350430783]
	TIME [epoch: 5.75 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025521128578472642		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.025521128578472642 | validation: 0.02279895907432967]
	TIME [epoch: 5.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025760064156714516		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.025760064156714516 | validation: 0.024392391462487523]
	TIME [epoch: 5.75 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025187730459068344		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.025187730459068344 | validation: 0.019373102655726164]
	TIME [epoch: 5.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02416198688703744		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.02416198688703744 | validation: 0.022499247727850124]
	TIME [epoch: 5.77 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021207166570491785		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.021207166570491785 | validation: 0.01861790634377955]
	TIME [epoch: 5.78 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025850288793100834		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.025850288793100834 | validation: 0.022542754460553923]
	TIME [epoch: 5.75 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030402604133272317		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.030402604133272317 | validation: 0.031045535207800238]
	TIME [epoch: 5.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02301806781583549		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.02301806781583549 | validation: 0.02375322855303224]
	TIME [epoch: 5.75 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022744798734975435		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.022744798734975435 | validation: 0.017385046757485246]
	TIME [epoch: 5.75 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02702646771498997		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.02702646771498997 | validation: 0.02746529292339532]
	TIME [epoch: 5.75 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027509553192309764		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.027509553192309764 | validation: 0.018658320909833225]
	TIME [epoch: 5.79 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026762610960552415		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.026762610960552415 | validation: 0.035348282813812436]
	TIME [epoch: 5.76 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026574737894927904		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.026574737894927904 | validation: 0.016920246736917985]
	TIME [epoch: 5.75 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024798075954647746		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.024798075954647746 | validation: 0.035423918776767024]
	TIME [epoch: 5.75 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030606775323443774		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.030606775323443774 | validation: 0.03683418074531847]
	TIME [epoch: 5.75 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03312367959106034		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03312367959106034 | validation: 0.02458729930813887]
	TIME [epoch: 5.75 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026337650553260962		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.026337650553260962 | validation: 0.015573746507176037]
	TIME [epoch: 5.77 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023120731707627847		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.023120731707627847 | validation: 0.028103432663706896]
	TIME [epoch: 5.78 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026667200850866768		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.026667200850866768 | validation: 0.031813247928733]
	TIME [epoch: 5.75 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575976169777697		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.02575976169777697 | validation: 0.024041223994298654]
	TIME [epoch: 5.75 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023986001305495948		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.023986001305495948 | validation: 0.01900159711504409]
	TIME [epoch: 5.75 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02220712135696378		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.02220712135696378 | validation: 0.02175923509354235]
	TIME [epoch: 5.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02640254520352385		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.02640254520352385 | validation: 0.034873949681563224]
	TIME [epoch: 5.75 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0242283093342713		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0242283093342713 | validation: 0.03355458977875278]
	TIME [epoch: 5.79 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418942010303265		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.03418942010303265 | validation: 0.01969882716380268]
	TIME [epoch: 5.76 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02766034627616831		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.02766034627616831 | validation: 0.030582872004903165]
	TIME [epoch: 5.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024039111716492933		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.024039111716492933 | validation: 0.02458842460339044]
	TIME [epoch: 5.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0257955298760788		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0257955298760788 | validation: 0.016530937823084204]
	TIME [epoch: 5.75 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023615494871326553		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.023615494871326553 | validation: 0.01650878823494443]
	TIME [epoch: 5.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0220537002523216		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0220537002523216 | validation: 0.023418084093475115]
	TIME [epoch: 5.76 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022034987787446208		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.022034987787446208 | validation: 0.01745135932100049]
	TIME [epoch: 5.78 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022784088278699405		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.022784088278699405 | validation: 0.019393597600376355]
	TIME [epoch: 5.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02104886094500447		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.02104886094500447 | validation: 0.022174162841665224]
	TIME [epoch: 5.75 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02342382973481388		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.02342382973481388 | validation: 0.03125195074072057]
	TIME [epoch: 5.75 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03271154727333846		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.03271154727333846 | validation: 0.031132642660956295]
	TIME [epoch: 5.75 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034398545293227355		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.034398545293227355 | validation: 0.03079258684084919]
	TIME [epoch: 5.75 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028777530453334157		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.028777530453334157 | validation: 0.018810649599853443]
	TIME [epoch: 5.79 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023877599236459428		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.023877599236459428 | validation: 0.024340051952370982]
	TIME [epoch: 5.76 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02497537585124656		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.02497537585124656 | validation: 0.008513353014392475]
	TIME [epoch: 5.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290192399977269		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.02290192399977269 | validation: 0.02670923112137638]
	TIME [epoch: 5.75 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02327547504181139		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.02327547504181139 | validation: 0.01674958586420512]
	TIME [epoch: 5.75 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020340596408756628		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.020340596408756628 | validation: 0.020234712931669455]
	TIME [epoch: 5.75 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022030389579832416		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.022030389579832416 | validation: 0.011592665037682255]
	TIME [epoch: 5.77 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021380832106933517		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.021380832106933517 | validation: 0.03307305327266174]
	TIME [epoch: 5.78 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01896861068553013		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.01896861068553013 | validation: 0.0194316605528017]
	TIME [epoch: 5.75 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834854552163533		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.02834854552163533 | validation: 0.0308933412610604]
	TIME [epoch: 5.75 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023890950638465937		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.023890950638465937 | validation: 0.03271227628313837]
	TIME [epoch: 5.75 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02573003159441819		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.02573003159441819 | validation: 0.021159119787863254]
	TIME [epoch: 5.75 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017496628311346886		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.017496628311346886 | validation: 0.02480690431218866]
	TIME [epoch: 5.75 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022555389704264246		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.022555389704264246 | validation: 0.02240241352319538]
	TIME [epoch: 5.79 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028071457280241935		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.028071457280241935 | validation: 0.03290937522906618]
	TIME [epoch: 5.75 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02869453599117647		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.02869453599117647 | validation: 0.014512933905537474]
	TIME [epoch: 5.75 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768458494363155		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.01768458494363155 | validation: 0.009277483071408792]
	TIME [epoch: 5.75 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019431108921341107		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.019431108921341107 | validation: 0.030380187913318694]
	TIME [epoch: 5.75 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02936217989000872		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.02936217989000872 | validation: 0.02591012160476753]
	TIME [epoch: 5.75 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017956067662270085		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.017956067662270085 | validation: 0.01570889017577863]
	TIME [epoch: 5.78 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020084015991766093		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.020084015991766093 | validation: 0.020579241123738178]
	TIME [epoch: 5.76 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018253761903780762		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.018253761903780762 | validation: 0.013541794953364921]
	TIME [epoch: 5.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020967203892771027		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.020967203892771027 | validation: 0.01708297392722215]
	TIME [epoch: 5.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022176888439139824		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.022176888439139824 | validation: 0.01060911347390654]
	TIME [epoch: 5.75 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02617116642565425		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.02617116642565425 | validation: 0.021673555683536565]
	TIME [epoch: 5.75 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022361397143804345		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.022361397143804345 | validation: 0.017769583839545224]
	TIME [epoch: 5.75 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023450549825849258		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.023450549825849258 | validation: 0.020303452125046736]
	TIME [epoch: 5.79 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311140443355029		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.02311140443355029 | validation: 0.01821126672343392]
	TIME [epoch: 5.75 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02026296490269983		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.02026296490269983 | validation: 0.017346276276283705]
	TIME [epoch: 5.75 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021420915667527414		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.021420915667527414 | validation: 0.023895948219344786]
	TIME [epoch: 5.75 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0255582792177185		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0255582792177185 | validation: 0.023041916321829083]
	TIME [epoch: 5.75 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026592474119499346		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.026592474119499346 | validation: 0.017280302052436393]
	TIME [epoch: 5.75 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359216169184874		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.02359216169184874 | validation: 0.025128287072737454]
	TIME [epoch: 5.78 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028182895072775768		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.028182895072775768 | validation: 0.03479773922793953]
	TIME [epoch: 5.76 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187603257278599		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.03187603257278599 | validation: 0.032299623363578535]
	TIME [epoch: 5.75 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026798419483406246		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.026798419483406246 | validation: 0.02295182865139859]
	TIME [epoch: 5.75 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024862833080537168		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.024862833080537168 | validation: 0.025379067169115234]
	TIME [epoch: 5.75 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025222186623640917		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.025222186623640917 | validation: 0.025828507568113578]
	TIME [epoch: 5.75 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01958198771837598		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.01958198771837598 | validation: 0.02084273059161797]
	TIME [epoch: 5.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027454143895758693		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.027454143895758693 | validation: 0.018940548610250487]
	TIME [epoch: 5.79 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018969086821451906		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.018969086821451906 | validation: 0.01611520006902917]
	TIME [epoch: 5.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025003056719319627		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.025003056719319627 | validation: 0.018017773265522154]
	TIME [epoch: 5.75 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02726580281649497		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.02726580281649497 | validation: 0.026782414893286612]
	TIME [epoch: 5.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025084023118458927		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.025084023118458927 | validation: 0.013304430906181768]
	TIME [epoch: 5.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026613407300831764		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.026613407300831764 | validation: 0.025505070203051976]
	TIME [epoch: 5.75 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467381450423781		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.03467381450423781 | validation: 0.028265224262373767]
	TIME [epoch: 5.78 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02667891522217713		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.02667891522217713 | validation: 0.022307928994095127]
	TIME [epoch: 5.76 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02740576008926337		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.02740576008926337 | validation: 0.02690431804017738]
	TIME [epoch: 5.75 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025985886915515663		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.025985886915515663 | validation: 0.01978998674150199]
	TIME [epoch: 5.75 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030836721941647216		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.030836721941647216 | validation: 0.04000611553449868]
	TIME [epoch: 5.75 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428803404467323		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.03428803404467323 | validation: 0.02274962645752972]
	TIME [epoch: 5.75 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037262180764923866		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.037262180764923866 | validation: 0.03056188140048123]
	TIME [epoch: 5.75 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029908010454255306		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.029908010454255306 | validation: 0.018031841258986905]
	TIME [epoch: 5.79 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02694224811086559		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.02694224811086559 | validation: 0.026361141769158873]
	TIME [epoch: 5.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02342034089126292		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.02342034089126292 | validation: 0.006461885197148665]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_1082.pth
	Model improved!!!
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027766097487641864		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.027766097487641864 | validation: 0.02536892534178647]
	TIME [epoch: 5.75 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023880123617290326		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.023880123617290326 | validation: 0.01930602909710313]
	TIME [epoch: 5.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022097081373513305		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.022097081373513305 | validation: 0.027168086834282304]
	TIME [epoch: 5.75 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023849545631837166		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.023849545631837166 | validation: 0.01931553342307926]
	TIME [epoch: 5.79 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018084745831157184		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.018084745831157184 | validation: 0.017176701532847134]
	TIME [epoch: 5.76 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027922977536372847		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.027922977536372847 | validation: 0.0192753163701107]
	TIME [epoch: 5.75 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02687364673035303		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.02687364673035303 | validation: 0.02242957175087041]
	TIME [epoch: 5.75 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02230431941299385		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.02230431941299385 | validation: 0.019083536356642984]
	TIME [epoch: 5.75 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02624525777358457		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.02624525777358457 | validation: 0.019553489301674748]
	TIME [epoch: 5.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02301422224082912		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.02301422224082912 | validation: 0.02103277807587535]
	TIME [epoch: 5.76 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021679899638785135		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.021679899638785135 | validation: 0.034621468950843844]
	TIME [epoch: 5.78 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044728434239981955		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.044728434239981955 | validation: 0.019036679366805132]
	TIME [epoch: 5.75 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02814850643078909		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.02814850643078909 | validation: 0.020487488590529707]
	TIME [epoch: 5.75 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028288394316623444		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.028288394316623444 | validation: 0.01617739065302492]
	TIME [epoch: 5.75 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02513654702317017		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.02513654702317017 | validation: 0.022657944917846704]
	TIME [epoch: 5.75 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028288748913363138		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.028288748913363138 | validation: 0.019984651698161895]
	TIME [epoch: 5.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031713185357576404		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.031713185357576404 | validation: 0.03611530938312187]
	TIME [epoch: 5.79 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03808694344399214		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.03808694344399214 | validation: 0.019894242842255497]
	TIME [epoch: 5.75 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0263503844411217		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.0263503844411217 | validation: 0.01549432506528504]
	TIME [epoch: 5.75 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02467409287145268		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.02467409287145268 | validation: 0.025038855226084632]
	TIME [epoch: 5.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025895391309125864		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.025895391309125864 | validation: 0.01892993020909648]
	TIME [epoch: 5.75 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930573288843885		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.025930573288843885 | validation: 0.020412433965691392]
	TIME [epoch: 5.75 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036209229163816886		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.036209229163816886 | validation: 0.025954269827840947]
	TIME [epoch: 5.76 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03831585759502275		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.03831585759502275 | validation: 0.03477942301794827]
	TIME [epoch: 5.78 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03096243353133805		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.03096243353133805 | validation: 0.01914071251197518]
	TIME [epoch: 5.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220636555623243		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.03220636555623243 | validation: 0.03542747332269998]
	TIME [epoch: 5.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317638171682116		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.0317638171682116 | validation: 0.03352620754705082]
	TIME [epoch: 5.75 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027342021462366112		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.027342021462366112 | validation: 0.017520762323744294]
	TIME [epoch: 5.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025954728657943207		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.025954728657943207 | validation: 0.01756173125131422]
	TIME [epoch: 5.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026058814115492664		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.026058814115492664 | validation: 0.017241392375049326]
	TIME [epoch: 5.79 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742472485827808		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.02742472485827808 | validation: 0.019166677199895305]
	TIME [epoch: 5.75 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025885659121946156		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.025885659121946156 | validation: 0.020220439611132082]
	TIME [epoch: 5.75 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026296711771732647		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.026296711771732647 | validation: 0.022277668894239887]
	TIME [epoch: 5.75 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027500146884332766		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.027500146884332766 | validation: 0.01968383708816215]
	TIME [epoch: 5.75 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023215316890998577		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.023215316890998577 | validation: 0.023136167681823548]
	TIME [epoch: 5.75 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024933329900034447		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.024933329900034447 | validation: 0.00964478477621885]
	TIME [epoch: 5.76 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022699707404282937		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.022699707404282937 | validation: 0.025636279411923164]
	TIME [epoch: 5.77 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030754694286056664		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.030754694286056664 | validation: 0.019728530961811326]
	TIME [epoch: 5.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232636480285293		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.02232636480285293 | validation: 0.016942112454065496]
	TIME [epoch: 5.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02492423838589081		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.02492423838589081 | validation: 0.0058686437426609915]
	TIME [epoch: 5.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_1122.pth
	Model improved!!!
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022396830800101804		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.022396830800101804 | validation: 0.010473915622844956]
	TIME [epoch: 5.75 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02493564658397769		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.02493564658397769 | validation: 0.02314867323549618]
	TIME [epoch: 5.75 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02331112986525969		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.02331112986525969 | validation: 0.01768463048828922]
	TIME [epoch: 5.79 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027302738112422804		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.027302738112422804 | validation: 0.01902171524750073]
	TIME [epoch: 5.75 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244061095226414		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.02244061095226414 | validation: 0.009075679865699396]
	TIME [epoch: 5.75 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024289341927366093		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.024289341927366093 | validation: 0.027289262397459275]
	TIME [epoch: 5.75 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02759535705270095		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.02759535705270095 | validation: 0.013356098920837422]
	TIME [epoch: 5.75 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020138742353864127		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.020138742353864127 | validation: 0.021927302760513835]
	TIME [epoch: 5.75 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01988319814806482		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.01988319814806482 | validation: 0.01937914017891664]
	TIME [epoch: 5.78 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021335035330115614		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.021335035330115614 | validation: 0.02679533677675423]
	TIME [epoch: 5.76 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026877998429482998		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.026877998429482998 | validation: 0.02672062485708612]
	TIME [epoch: 5.75 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025401549759590872		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.025401549759590872 | validation: 0.025495017670820488]
	TIME [epoch: 5.75 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018861110916916408		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.018861110916916408 | validation: 0.014744737408046391]
	TIME [epoch: 5.75 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025202547320120536		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.025202547320120536 | validation: 0.018563183864734767]
	TIME [epoch: 5.75 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024393056577211355		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.024393056577211355 | validation: 0.032517249767164025]
	TIME [epoch: 5.75 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02684208770992245		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.02684208770992245 | validation: 0.020761581301518586]
	TIME [epoch: 5.79 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022884820517666545		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.022884820517666545 | validation: 0.015279515584977367]
	TIME [epoch: 5.75 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022528964577917268		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.022528964577917268 | validation: 0.01670554023566865]
	TIME [epoch: 5.75 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019971976982604837		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.019971976982604837 | validation: 0.025004333494208743]
	TIME [epoch: 5.75 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019977041452675683		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.019977041452675683 | validation: 0.0281356192785088]
	TIME [epoch: 5.75 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02176574761928501		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.02176574761928501 | validation: 0.015917340418851032]
	TIME [epoch: 5.75 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021058740917001884		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.021058740917001884 | validation: 0.025508624350200654]
	TIME [epoch: 5.78 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021459569508796416		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.021459569508796416 | validation: 0.017112605544768074]
	TIME [epoch: 5.76 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020012015415742074		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.020012015415742074 | validation: 0.022444987065456504]
	TIME [epoch: 5.75 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02029223969098699		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.02029223969098699 | validation: 0.030673837064265106]
	TIME [epoch: 5.75 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016065396855505135		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.016065396855505135 | validation: 0.017670496898991913]
	TIME [epoch: 5.75 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019615402863610427		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.019615402863610427 | validation: 0.012373942573914967]
	TIME [epoch: 5.75 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021355344118551372		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.021355344118551372 | validation: 0.015873565348256888]
	TIME [epoch: 5.75 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02048937188416198		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.02048937188416198 | validation: 0.015340932057825973]
	TIME [epoch: 5.78 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023311783849799168		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.023311783849799168 | validation: 0.015487128136549452]
	TIME [epoch: 5.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020014914662711623		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.020014914662711623 | validation: 0.01773391596755629]
	TIME [epoch: 5.75 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018699747725887967		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.018699747725887967 | validation: 0.014764900915598771]
	TIME [epoch: 5.75 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022125473401184273		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.022125473401184273 | validation: 0.01969975541461128]
	TIME [epoch: 5.75 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024105921895610748		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.024105921895610748 | validation: 0.0266835707596508]
	TIME [epoch: 5.75 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022749725549478166		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.022749725549478166 | validation: 0.016859676106551404]
	TIME [epoch: 5.79 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0214097921224181		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0214097921224181 | validation: 0.02365190313428134]
	TIME [epoch: 5.75 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026570488701799316		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.026570488701799316 | validation: 0.02902141873454544]
	TIME [epoch: 5.75 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027608871760974187		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.027608871760974187 | validation: 0.023969934085511287]
	TIME [epoch: 5.75 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02346127300899721		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.02346127300899721 | validation: 0.02250673718476654]
	TIME [epoch: 5.75 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02251019034765597		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.02251019034765597 | validation: 0.017901042265425948]
	TIME [epoch: 5.75 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02297503528425017		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.02297503528425017 | validation: 0.015195209744450771]
	TIME [epoch: 5.76 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02069783567812917		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.02069783567812917 | validation: 0.009676276101193785]
	TIME [epoch: 5.78 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02027926938937575		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.02027926938937575 | validation: 0.012169436347581187]
	TIME [epoch: 5.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019904204920681633		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.019904204920681633 | validation: 0.023524006076325862]
	TIME [epoch: 5.75 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019023818339175394		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.019023818339175394 | validation: 0.014181736058853379]
	TIME [epoch: 5.75 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023097277117430707		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.023097277117430707 | validation: 0.008645572287095308]
	TIME [epoch: 5.75 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025481253642784835		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.025481253642784835 | validation: 0.013112701741398848]
	TIME [epoch: 5.75 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03128793141800593		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.03128793141800593 | validation: 0.02450638773353137]
	TIME [epoch: 5.79 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02339641954268569		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.02339641954268569 | validation: 0.01845960680675245]
	TIME [epoch: 5.75 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02060210339516214		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.02060210339516214 | validation: 0.011531731119960024]
	TIME [epoch: 5.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02415730747003336		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.02415730747003336 | validation: 0.022596657418601056]
	TIME [epoch: 5.75 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026496309536369243		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.026496309536369243 | validation: 0.012169979573157526]
	TIME [epoch: 5.75 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02731199364616318		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.02731199364616318 | validation: 0.025920903730156396]
	TIME [epoch: 5.75 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028911915042122597		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.028911915042122597 | validation: 0.023693853371556124]
	TIME [epoch: 5.76 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031389498067114587		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.031389498067114587 | validation: 0.016345875618700295]
	TIME [epoch: 5.78 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02302404178744043		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.02302404178744043 | validation: 0.016541765316698324]
	TIME [epoch: 5.75 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465869505917343		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.02465869505917343 | validation: 0.014645398318670035]
	TIME [epoch: 5.75 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021746517607066595		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.021746517607066595 | validation: 0.031660987345479015]
	TIME [epoch: 5.75 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023396246890703798		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.023396246890703798 | validation: 0.024767269456154907]
	TIME [epoch: 5.75 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026719821320840116		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.026719821320840116 | validation: 0.02474212887847666]
	TIME [epoch: 5.75 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02651405136447469		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.02651405136447469 | validation: 0.0183488028837076]
	TIME [epoch: 5.79 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024182057973881954		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.024182057973881954 | validation: 0.021437936819549693]
	TIME [epoch: 5.75 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02389318593666672		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.02389318593666672 | validation: 0.01059694110096211]
	TIME [epoch: 5.75 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020517622083817997		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.020517622083817997 | validation: 0.022173973184516204]
	TIME [epoch: 5.75 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0183021423831325		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.0183021423831325 | validation: 0.016236220325331167]
	TIME [epoch: 5.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020352821536093746		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.020352821536093746 | validation: 0.02030737701802906]
	TIME [epoch: 5.75 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024904210382359113		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.024904210382359113 | validation: 0.009219541478029445]
	TIME [epoch: 5.76 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02152997123057291		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.02152997123057291 | validation: 0.02891083088750987]
	TIME [epoch: 5.78 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022369467599197706		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.022369467599197706 | validation: 0.024983128183530542]
	TIME [epoch: 5.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021890156848042342		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.021890156848042342 | validation: 0.01715498218509921]
	TIME [epoch: 5.75 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019786148314605317		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.019786148314605317 | validation: 0.026973236470422633]
	TIME [epoch: 5.75 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020093509542485587		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.020093509542485587 | validation: 0.012625159631381675]
	TIME [epoch: 5.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021353168397923672		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.021353168397923672 | validation: 0.026014893645435872]
	TIME [epoch: 5.75 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021291926795481787		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.021291926795481787 | validation: 0.017550698794130768]
	TIME [epoch: 5.79 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02129809396743285		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.02129809396743285 | validation: 0.017010568006825152]
	TIME [epoch: 5.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02158929384164942		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.02158929384164942 | validation: 0.02218447922949234]
	TIME [epoch: 5.75 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02275057816279452		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.02275057816279452 | validation: 0.024124759910996843]
	TIME [epoch: 5.75 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02496499740100031		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.02496499740100031 | validation: 0.019712603115020672]
	TIME [epoch: 5.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02810533142222621		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.02810533142222621 | validation: 0.023672994354385746]
	TIME [epoch: 5.75 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02643962471917367		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.02643962471917367 | validation: 0.027875375968956773]
	TIME [epoch: 5.76 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022212418422797593		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.022212418422797593 | validation: 0.02033204081054249]
	TIME [epoch: 5.78 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015755001052359132		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.015755001052359132 | validation: 0.016925855331346426]
	TIME [epoch: 5.75 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018803943394574717		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.018803943394574717 | validation: 0.017912724881024453]
	TIME [epoch: 5.75 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016501605817573633		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.016501605817573633 | validation: 0.014506045698818245]
	TIME [epoch: 5.75 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017653103248057862		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.017653103248057862 | validation: 0.019935965953341052]
	TIME [epoch: 5.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019231078177035427		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.019231078177035427 | validation: 0.030752025880301445]
	TIME [epoch: 6.03 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018124051616085508		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.018124051616085508 | validation: 0.022102817588686614]
	TIME [epoch: 5.78 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022137179497742354		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.022137179497742354 | validation: 0.025110442893166784]
	TIME [epoch: 5.74 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02238119506665969		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.02238119506665969 | validation: 0.017304734565455452]
	TIME [epoch: 5.73 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024167561461061006		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.024167561461061006 | validation: 0.020259985227453203]
	TIME [epoch: 5.73 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019862211413489955		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.019862211413489955 | validation: 0.02198899295018313]
	TIME [epoch: 5.73 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02367031699799739		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.02367031699799739 | validation: 0.016599465148009335]
	TIME [epoch: 5.73 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02063723731628498		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.02063723731628498 | validation: 0.016284980424158473]
	TIME [epoch: 5.76 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018918185386890156		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.018918185386890156 | validation: 0.017046342032136893]
	TIME [epoch: 5.75 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018679557337075287		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.018679557337075287 | validation: 0.01173458708808171]
	TIME [epoch: 5.73 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022123657820364555		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.022123657820364555 | validation: 0.016953486551687342]
	TIME [epoch: 5.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01955513837049104		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.01955513837049104 | validation: 0.025534146357931914]
	TIME [epoch: 5.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018957416842899453		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.018957416842899453 | validation: 0.019593373364871755]
	TIME [epoch: 5.73 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02125258482868441		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.02125258482868441 | validation: 0.019259669846831213]
	TIME [epoch: 5.73 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021140328599104915		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.021140328599104915 | validation: 0.01643430510573866]
	TIME [epoch: 5.78 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021758863774178443		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.021758863774178443 | validation: 0.02400279803396043]
	TIME [epoch: 5.73 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018688078944473052		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.018688078944473052 | validation: 0.022868103808486476]
	TIME [epoch: 5.73 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017137188620120477		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.017137188620120477 | validation: 0.022288783182214146]
	TIME [epoch: 5.73 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014852523077071914		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.014852523077071914 | validation: 0.017268701043149905]
	TIME [epoch: 5.73 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022107056814462008		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.022107056814462008 | validation: 0.01790959221952865]
	TIME [epoch: 5.73 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017781263962489982		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.017781263962489982 | validation: 0.01507055707661204]
	TIME [epoch: 5.76 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01933122952333071		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.01933122952333071 | validation: 0.025422253344503414]
	TIME [epoch: 5.75 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021863074522129083		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.021863074522129083 | validation: 0.015630610806974015]
	TIME [epoch: 5.73 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02462687755190286		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.02462687755190286 | validation: 0.011593946047553167]
	TIME [epoch: 5.73 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017563323274002562		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.017563323274002562 | validation: 0.02867384969787591]
	TIME [epoch: 5.73 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020823594713703236		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.020823594713703236 | validation: 0.010598554435398786]
	TIME [epoch: 5.73 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01783537766853825		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.01783537766853825 | validation: 0.013647575695172293]
	TIME [epoch: 5.73 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023785280540803345		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.023785280540803345 | validation: 0.01727651732565438]
	TIME [epoch: 5.78 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022124319059610736		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.022124319059610736 | validation: 0.023788436835562372]
	TIME [epoch: 5.74 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021754163900491834		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.021754163900491834 | validation: 0.015864977442602714]
	TIME [epoch: 5.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023092707691404316		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.023092707691404316 | validation: 0.0217384016248102]
	TIME [epoch: 5.73 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023504238209168516		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.023504238209168516 | validation: 0.014358680767023511]
	TIME [epoch: 5.74 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019929373972779323		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.019929373972779323 | validation: 0.01874903668269117]
	TIME [epoch: 5.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018197610817817237		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.018197610817817237 | validation: 0.011810016519048947]
	TIME [epoch: 5.77 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016555636115155245		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.016555636115155245 | validation: 0.021031159782369677]
	TIME [epoch: 5.75 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01949412410755644		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.01949412410755644 | validation: 0.0182471273196324]
	TIME [epoch: 5.74 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733270747125007		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.01733270747125007 | validation: 0.007177375452213701]
	TIME [epoch: 5.74 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015902834197582844		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.015902834197582844 | validation: 0.015819645682040934]
	TIME [epoch: 5.74 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017446250864627512		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.017446250864627512 | validation: 0.01657290590979093]
	TIME [epoch: 5.74 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020875523310509868		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.020875523310509868 | validation: 0.01990890004451694]
	TIME [epoch: 5.74 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01902709200929064		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.01902709200929064 | validation: 0.018156544389555457]
	TIME [epoch: 5.78 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022927006484487956		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.022927006484487956 | validation: 0.01032398920048638]
	TIME [epoch: 5.74 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019372997007772345		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.019372997007772345 | validation: 0.020938715446114024]
	TIME [epoch: 5.74 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01880699927533584		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.01880699927533584 | validation: 0.015032173036492043]
	TIME [epoch: 5.74 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02300265045675167		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.02300265045675167 | validation: 0.023808985184015086]
	TIME [epoch: 5.74 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016499231577955187		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.016499231577955187 | validation: 0.01506802178952107]
	TIME [epoch: 5.74 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01725306737135946		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.01725306737135946 | validation: 0.0186800631561765]
	TIME [epoch: 5.77 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019116212775572735		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.019116212775572735 | validation: 0.021044520839386537]
	TIME [epoch: 5.75 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021499247475527797		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.021499247475527797 | validation: 0.021777663974116547]
	TIME [epoch: 5.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019087191269809803		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.019087191269809803 | validation: 0.014382535060550317]
	TIME [epoch: 5.74 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01898795113357259		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.01898795113357259 | validation: 0.023842528733933287]
	TIME [epoch: 5.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024244606783259723		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.024244606783259723 | validation: 0.02972893071837438]
	TIME [epoch: 5.74 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01938048729934956		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.01938048729934956 | validation: 0.01184497196961633]
	TIME [epoch: 5.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01864319848744825		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.01864319848744825 | validation: 0.017172049974631332]
	TIME [epoch: 5.78 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233049875351971		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.02233049875351971 | validation: 0.016566624555567476]
	TIME [epoch: 5.74 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02389857782574871		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.02389857782574871 | validation: 0.02193860230644223]
	TIME [epoch: 5.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023447963543609188		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.023447963543609188 | validation: 0.03074658770776737]
	TIME [epoch: 5.74 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026177648860042566		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.026177648860042566 | validation: 0.028250648603798237]
	TIME [epoch: 5.74 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022306401968177455		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.022306401968177455 | validation: 0.02534144026084571]
	TIME [epoch: 5.74 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024965709512563224		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.024965709512563224 | validation: 0.024507204845982872]
	TIME [epoch: 5.77 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02631074138088648		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.02631074138088648 | validation: 0.021171926263950785]
	TIME [epoch: 5.75 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023232921905936735		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.023232921905936735 | validation: 0.02204072663358169]
	TIME [epoch: 5.74 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026368558177084417		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.026368558177084417 | validation: 0.01970067262264615]
	TIME [epoch: 5.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021878331190608908		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.021878331190608908 | validation: 0.01683320537467664]
	TIME [epoch: 5.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219974912945333		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.02219974912945333 | validation: 0.012436296159272888]
	TIME [epoch: 5.74 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02062544497691314		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.02062544497691314 | validation: 0.009058797666876011]
	TIME [epoch: 5.75 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024725389456815072		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.024725389456815072 | validation: 0.023247481442358726]
	TIME [epoch: 5.77 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021957229966737393		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.021957229966737393 | validation: 0.023477305568292854]
	TIME [epoch: 5.74 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02169372323953652		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.02169372323953652 | validation: 0.020325622322311533]
	TIME [epoch: 5.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019230675237707946		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.019230675237707946 | validation: 0.026842638676482473]
	TIME [epoch: 5.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019446592449424385		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.019446592449424385 | validation: 0.01604969375676554]
	TIME [epoch: 5.74 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0246864724719824		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0246864724719824 | validation: 0.025549462489733825]
	TIME [epoch: 5.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023271633638952315		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.023271633638952315 | validation: 0.029040163297722625]
	TIME [epoch: 5.78 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020677945259428253		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.020677945259428253 | validation: 0.02676085663367114]
	TIME [epoch: 5.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212092501883299		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.02212092501883299 | validation: 0.024768573644680717]
	TIME [epoch: 5.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027902589995074417		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.027902589995074417 | validation: 0.014648284182619454]
	TIME [epoch: 5.74 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026813644075195264		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.026813644075195264 | validation: 0.028956937918536593]
	TIME [epoch: 5.74 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026556704627586664		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.026556704627586664 | validation: 0.02475101084937644]
	TIME [epoch: 5.74 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024590431902771135		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.024590431902771135 | validation: 0.0262779890833695]
	TIME [epoch: 5.75 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656194238936542		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.02656194238936542 | validation: 0.017076299523176366]
	TIME [epoch: 5.77 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023074143634199594		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.023074143634199594 | validation: 0.02549448574739949]
	TIME [epoch: 5.74 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718250365565619		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.01718250365565619 | validation: 0.014150110277237764]
	TIME [epoch: 5.74 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021152362653405598		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.021152362653405598 | validation: 0.011237410083101845]
	TIME [epoch: 5.73 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021409102359277482		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.021409102359277482 | validation: 0.008588096890005923]
	TIME [epoch: 5.74 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022532811714034554		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.022532811714034554 | validation: 0.014902667112013324]
	TIME [epoch: 5.74 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01998098163344962		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.01998098163344962 | validation: 0.014592492000154127]
	TIME [epoch: 5.78 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022130638280175526		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.022130638280175526 | validation: 0.023615326248195824]
	TIME [epoch: 5.74 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02144675009396317		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.02144675009396317 | validation: 0.020802760292649304]
	TIME [epoch: 5.74 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248780177228538		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.0248780177228538 | validation: 0.015650645466554338]
	TIME [epoch: 5.74 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021005276581898512		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.021005276581898512 | validation: 0.02124646995733597]
	TIME [epoch: 5.74 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371237007984791		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.02371237007984791 | validation: 0.020823022766985253]
	TIME [epoch: 5.73 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02336936561413436		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.02336936561413436 | validation: 0.01457570478524973]
	TIME [epoch: 5.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020523943153781893		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.020523943153781893 | validation: 0.020822778300304486]
	TIME [epoch: 5.76 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021411098900101223		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.021411098900101223 | validation: 0.017528820164868748]
	TIME [epoch: 5.74 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019674476131395127		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.019674476131395127 | validation: 0.023704543051781]
	TIME [epoch: 5.73 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02065296362148667		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.02065296362148667 | validation: 0.016067648316213455]
	TIME [epoch: 5.73 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019074979539156073		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.019074979539156073 | validation: 0.02205806464681397]
	TIME [epoch: 5.73 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02361455342087039		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.02361455342087039 | validation: 0.02487124635341756]
	TIME [epoch: 5.73 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022949749263839712		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.022949749263839712 | validation: 0.023359685056567377]
	TIME [epoch: 5.78 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020010727997520295		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.020010727997520295 | validation: 0.01701656785009376]
	TIME [epoch: 5.74 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022146854300721275		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.022146854300721275 | validation: 0.021931540671692878]
	TIME [epoch: 5.73 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02260116782657372		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.02260116782657372 | validation: 0.016721841188580052]
	TIME [epoch: 5.73 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020478904487046347		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.020478904487046347 | validation: 0.03487657047208237]
	TIME [epoch: 5.73 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851167012351751		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.02851167012351751 | validation: 0.03215985455691855]
	TIME [epoch: 5.73 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027448829781941467		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.027448829781941467 | validation: 0.02396839276732407]
	TIME [epoch: 5.75 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02594037020643949		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.02594037020643949 | validation: 0.024622537703572926]
	TIME [epoch: 5.76 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02588314926556271		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.02588314926556271 | validation: 0.018482304938567125]
	TIME [epoch: 5.74 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930038770341217		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.025930038770341217 | validation: 0.0262085426146471]
	TIME [epoch: 5.74 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02518476919686405		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.02518476919686405 | validation: 0.02748683368702864]
	TIME [epoch: 5.73 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02593969991072677		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.02593969991072677 | validation: 0.027851473033808267]
	TIME [epoch: 5.74 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021715860867353737		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.021715860867353737 | validation: 0.029246910799888993]
	TIME [epoch: 5.74 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019756889957916097		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.019756889957916097 | validation: 0.025313698147830143]
	TIME [epoch: 5.78 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018196139174378064		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.018196139174378064 | validation: 0.020614216861831142]
	TIME [epoch: 5.74 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021395173362662494		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.021395173362662494 | validation: 0.015275499215444003]
	TIME [epoch: 5.73 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02301810336650214		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.02301810336650214 | validation: 0.029797159664284426]
	TIME [epoch: 5.73 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017520256416583998		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.017520256416583998 | validation: 0.0161602028531491]
	TIME [epoch: 5.73 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022399016683364765		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.022399016683364765 | validation: 0.019325910167714906]
	TIME [epoch: 5.73 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023733655996490903		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.023733655996490903 | validation: 0.011665034575019337]
	TIME [epoch: 5.75 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022406193106237215		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.022406193106237215 | validation: 0.022012307214259806]
	TIME [epoch: 5.76 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02127689093469519		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.02127689093469519 | validation: 0.018143237356829666]
	TIME [epoch: 5.74 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517995803469458		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.02517995803469458 | validation: 0.016696423120171527]
	TIME [epoch: 5.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020458210619661212		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.020458210619661212 | validation: 0.021845120081617066]
	TIME [epoch: 5.74 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02181681384920778		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.02181681384920778 | validation: 0.012396627774826384]
	TIME [epoch: 5.73 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019350745871632775		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.019350745871632775 | validation: 0.02406665894814537]
	TIME [epoch: 5.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02071443298703706		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.02071443298703706 | validation: 0.016561376039007272]
	TIME [epoch: 5.78 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024703725023977618		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.024703725023977618 | validation: 0.018645634835447053]
	TIME [epoch: 5.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02400619912208412		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.02400619912208412 | validation: 0.0197964231872371]
	TIME [epoch: 5.73 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040201251701324		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.02040201251701324 | validation: 0.016890779934571342]
	TIME [epoch: 5.73 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023805937752099316		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.023805937752099316 | validation: 0.020797087021483193]
	TIME [epoch: 5.74 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018155558269815044		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.018155558269815044 | validation: 0.014083884445860027]
	TIME [epoch: 5.73 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01758800361766315		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.01758800361766315 | validation: 0.013977518438055761]
	TIME [epoch: 5.75 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02303755089766785		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.02303755089766785 | validation: 0.015512935851656438]
	TIME [epoch: 5.76 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018738428131276862		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.018738428131276862 | validation: 0.007739817242600664]
	TIME [epoch: 5.74 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01906177586812729		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.01906177586812729 | validation: 0.02394130065462382]
	TIME [epoch: 5.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581897583790505		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.01581897583790505 | validation: 0.021400846994330824]
	TIME [epoch: 5.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02138837717359335		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.02138837717359335 | validation: 0.015585697346019205]
	TIME [epoch: 5.73 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01849221192955635		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.01849221192955635 | validation: 0.017950460805509973]
	TIME [epoch: 5.74 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018716557825552392		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.018716557825552392 | validation: 0.029729929327897146]
	TIME [epoch: 5.78 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019834384830372493		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.019834384830372493 | validation: 0.01916435517704143]
	TIME [epoch: 5.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857128458112994		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.01857128458112994 | validation: 0.02324823414041575]
	TIME [epoch: 5.73 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01958745987752886		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.01958745987752886 | validation: 0.01683803901913659]
	TIME [epoch: 5.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021720352725815188		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.021720352725815188 | validation: 0.011817684512373715]
	TIME [epoch: 5.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019117022449024502		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.019117022449024502 | validation: 0.0286576509625909]
	TIME [epoch: 5.73 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018070126013611763		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.018070126013611763 | validation: 0.010526385693916604]
	TIME [epoch: 5.76 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021062882153129445		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.021062882153129445 | validation: 0.012223695130983267]
	TIME [epoch: 5.75 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01947749939847066		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.01947749939847066 | validation: 0.016410986443200007]
	TIME [epoch: 5.73 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020422454096703447		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.020422454096703447 | validation: 0.012508247990992472]
	TIME [epoch: 5.74 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018697714013105004		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.018697714013105004 | validation: 0.013468686969295157]
	TIME [epoch: 5.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01921504375820689		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.01921504375820689 | validation: 0.019845099444310267]
	TIME [epoch: 5.73 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01703870995033307		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.01703870995033307 | validation: 0.01487060381665784]
	TIME [epoch: 5.74 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022450165638834403		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.022450165638834403 | validation: 0.014094541325880705]
	TIME [epoch: 5.78 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019718062940083606		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.019718062940083606 | validation: 0.012771634926249149]
	TIME [epoch: 5.74 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019503196241929133		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.019503196241929133 | validation: 0.017952201130525897]
	TIME [epoch: 5.74 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02847502327996702		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.02847502327996702 | validation: 0.026969599317530922]
	TIME [epoch: 5.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02538878411363939		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.02538878411363939 | validation: 0.024621303022025923]
	TIME [epoch: 5.73 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001985133906832		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02001985133906832 | validation: 0.02377348721624669]
	TIME [epoch: 5.73 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263754026764178		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.02263754026764178 | validation: 0.01675896162282536]
	TIME [epoch: 5.77 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022517143656518836		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.022517143656518836 | validation: 0.02196676064063546]
	TIME [epoch: 5.75 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022213317291182703		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.022213317291182703 | validation: 0.017106745372712236]
	TIME [epoch: 5.74 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018238564150159384		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.018238564150159384 | validation: 0.013524050523693168]
	TIME [epoch: 5.74 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020563461217452454		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.020563461217452454 | validation: 0.021670930219082035]
	TIME [epoch: 5.73 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986704148154027		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.01986704148154027 | validation: 0.021002727198316865]
	TIME [epoch: 5.73 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01875995902658481		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.01875995902658481 | validation: 0.023508517427188496]
	TIME [epoch: 5.74 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02103617696684556		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.02103617696684556 | validation: 0.009066108110340164]
	TIME [epoch: 5.78 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02104867066466312		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.02104867066466312 | validation: 0.020767784901927103]
	TIME [epoch: 5.74 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017048665531548237		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.017048665531548237 | validation: 0.0192862654414572]
	TIME [epoch: 5.73 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019973226547850435		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.019973226547850435 | validation: 0.013924504172916694]
	TIME [epoch: 5.73 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023766701765740497		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.023766701765740497 | validation: 0.021217965733536768]
	TIME [epoch: 5.73 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022792018280208094		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.022792018280208094 | validation: 0.01805453685188491]
	TIME [epoch: 5.73 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018941249378314283		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.018941249378314283 | validation: 0.017799552185740128]
	TIME [epoch: 5.77 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023374342064953466		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.023374342064953466 | validation: 0.018380033350119382]
	TIME [epoch: 5.75 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018979404376477795		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.018979404376477795 | validation: 0.016013896437892992]
	TIME [epoch: 5.74 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021135006225840004		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.021135006225840004 | validation: 0.017174789577226016]
	TIME [epoch: 5.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022585759110402844		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.022585759110402844 | validation: 0.02539381903264128]
	TIME [epoch: 5.73 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02211038548548774		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.02211038548548774 | validation: 0.01986730793238998]
	TIME [epoch: 5.73 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023177351230397117		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.023177351230397117 | validation: 0.016619252017754015]
	TIME [epoch: 5.74 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236226070748479		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.02236226070748479 | validation: 0.020983108725651116]
	TIME [epoch: 5.78 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927912127719466		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.01927912127719466 | validation: 0.014855342642406542]
	TIME [epoch: 5.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017909561020911048		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.017909561020911048 | validation: 0.018078469931420676]
	TIME [epoch: 5.73 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02124473657997702		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.02124473657997702 | validation: 0.012826299055045159]
	TIME [epoch: 5.73 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023225335978922713		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.023225335978922713 | validation: 0.016698679055613345]
	TIME [epoch: 5.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017597267297854213		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.017597267297854213 | validation: 0.0074195087502148364]
	TIME [epoch: 5.73 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752579757942932		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.01752579757942932 | validation: 0.015990127754633137]
	TIME [epoch: 5.77 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019165902397044795		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.019165902397044795 | validation: 0.016913913991234052]
	TIME [epoch: 5.75 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023304369426640822		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.023304369426640822 | validation: 0.014462461743292578]
	TIME [epoch: 5.74 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01899673893324		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.01899673893324 | validation: 0.013168151290442926]
	TIME [epoch: 5.73 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018695112817960553		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.018695112817960553 | validation: 0.015689271098374473]
	TIME [epoch: 5.73 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02241813574655017		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02241813574655017 | validation: 0.020203396115411453]
	TIME [epoch: 5.73 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019226400924480677		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.019226400924480677 | validation: 0.012507301217932722]
	TIME [epoch: 5.74 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018133387034760015		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.018133387034760015 | validation: 0.02067744966671766]
	TIME [epoch: 5.78 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021100066064740797		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.021100066064740797 | validation: 0.0156479700109421]
	TIME [epoch: 5.74 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021350547148910628		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.021350547148910628 | validation: 0.015750358530581456]
	TIME [epoch: 5.73 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017365287155904435		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.017365287155904435 | validation: 0.016365552149438786]
	TIME [epoch: 5.73 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016882659698977995		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.016882659698977995 | validation: 0.012096192975511654]
	TIME [epoch: 5.74 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020045365527823808		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.020045365527823808 | validation: 0.015822724899994797]
	TIME [epoch: 5.73 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018893245207482944		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.018893245207482944 | validation: 0.016711531164440113]
	TIME [epoch: 5.77 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01764528974537942		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.01764528974537942 | validation: 0.023151517487339762]
	TIME [epoch: 5.75 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020171818936749034		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.020171818936749034 | validation: 0.01568402375998753]
	TIME [epoch: 5.74 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01980323238182918		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.01980323238182918 | validation: 0.016772583521368234]
	TIME [epoch: 5.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018263931192696974		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.018263931192696974 | validation: 0.020432196141892584]
	TIME [epoch: 5.73 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016982602510855413		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.016982602510855413 | validation: 0.010588472353007805]
	TIME [epoch: 5.73 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017828749545127174		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.017828749545127174 | validation: 0.016377030635981688]
	TIME [epoch: 5.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016319913218158587		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.016319913218158587 | validation: 0.014265056620789168]
	TIME [epoch: 5.78 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02030750326497002		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.02030750326497002 | validation: 0.010180664572719359]
	TIME [epoch: 5.74 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020881037134743985		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.020881037134743985 | validation: 0.015149580421215792]
	TIME [epoch: 5.74 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017753319094517186		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.017753319094517186 | validation: 0.02303162973713004]
	TIME [epoch: 5.73 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01514780583664948		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.01514780583664948 | validation: 0.025203739354079522]
	TIME [epoch: 5.74 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02009378574242715		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.02009378574242715 | validation: 0.018406222732646603]
	TIME [epoch: 5.73 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020081047957879145		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.020081047957879145 | validation: 0.015680225372706334]
	TIME [epoch: 5.77 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013626630291269		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.02013626630291269 | validation: 0.025744996879377525]
	TIME [epoch: 5.74 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0203137946912984		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0203137946912984 | validation: 0.017810145425032002]
	TIME [epoch: 5.74 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01963751823576508		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.01963751823576508 | validation: 0.013246026130838282]
	TIME [epoch: 5.74 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020339901442517953		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.020339901442517953 | validation: 0.018758756041921416]
	TIME [epoch: 5.74 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020809709577206518		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.020809709577206518 | validation: 0.011840170172100609]
	TIME [epoch: 5.73 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021306900577480237		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.021306900577480237 | validation: 0.01574827249430895]
	TIME [epoch: 5.75 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015197056041419361		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.015197056041419361 | validation: 0.016133351905277843]
	TIME [epoch: 5.76 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021153368012075475		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.021153368012075475 | validation: 0.02298470207296639]
	TIME [epoch: 5.74 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01965908009737949		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.01965908009737949 | validation: 0.015091572916988585]
	TIME [epoch: 5.73 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020180504801589727		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.020180504801589727 | validation: 0.012934357662637636]
	TIME [epoch: 5.73 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021092056605800165		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.021092056605800165 | validation: 0.020263839412017086]
	TIME [epoch: 5.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0233483313953619		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.0233483313953619 | validation: 0.022688386732234868]
	TIME [epoch: 5.74 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01830178472666529		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.01830178472666529 | validation: 0.015479286101235168]
	TIME [epoch: 5.78 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022710413010262814		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.022710413010262814 | validation: 0.018182010360334563]
	TIME [epoch: 5.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022865655447791906		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.022865655447791906 | validation: 0.018140290016181657]
	TIME [epoch: 5.73 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020866976909208676		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.020866976909208676 | validation: 0.022137041336934535]
	TIME [epoch: 5.73 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021220299197170667		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.021220299197170667 | validation: 0.018582245054598014]
	TIME [epoch: 5.73 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222822510767857		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.02222822510767857 | validation: 0.01059512904707356]
	TIME [epoch: 5.74 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020602294091904453		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.020602294091904453 | validation: 0.012802849672471323]
	TIME [epoch: 5.75 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0176755952467669		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0176755952467669 | validation: 0.014763258076970884]
	TIME [epoch: 5.76 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822068388009984		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.01822068388009984 | validation: 0.028243742932418048]
	TIME [epoch: 5.74 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019898823502643298		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.019898823502643298 | validation: 0.02139701274686326]
	TIME [epoch: 5.73 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020620684740365346		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.020620684740365346 | validation: 0.015397651391174046]
	TIME [epoch: 5.73 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018825833792508177		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.018825833792508177 | validation: 0.021483853749005785]
	TIME [epoch: 5.73 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017939552340276634		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.017939552340276634 | validation: 0.013043160774708752]
	TIME [epoch: 5.73 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020261335005966403		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.020261335005966403 | validation: 0.02244502214007212]
	TIME [epoch: 5.8 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019767811492540012		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.019767811492540012 | validation: 0.022262012406097233]
	TIME [epoch: 5.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017371660840749453		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.017371660840749453 | validation: 0.015291907525999777]
	TIME [epoch: 5.73 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0194320326468836		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.0194320326468836 | validation: 0.017650535911667296]
	TIME [epoch: 5.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018531278289802874		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.018531278289802874 | validation: 0.018100224226262344]
	TIME [epoch: 5.73 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018013789145642597		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.018013789145642597 | validation: 0.01342641213879127]
	TIME [epoch: 5.73 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01623072657945286		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.01623072657945286 | validation: 0.011705137772691226]
	TIME [epoch: 5.75 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019321959556094795		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.019321959556094795 | validation: 0.017340767150128007]
	TIME [epoch: 5.76 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760789830782302		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.01760789830782302 | validation: 0.02092644216381065]
	TIME [epoch: 5.74 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016726550685304		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.016726550685304 | validation: 0.025220839076864385]
	TIME [epoch: 5.73 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016850894345503468		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.016850894345503468 | validation: 0.008981478376024945]
	TIME [epoch: 5.73 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019953812621911086		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.019953812621911086 | validation: 0.014882965987395018]
	TIME [epoch: 5.73 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01865131943641518		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.01865131943641518 | validation: 0.013890054934519475]
	TIME [epoch: 5.74 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756573750817622		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.01756573750817622 | validation: 0.012587579081335969]
	TIME [epoch: 5.78 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014552821176009858		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.014552821176009858 | validation: 0.014953387127698142]
	TIME [epoch: 5.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019635049676137446		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.019635049676137446 | validation: 0.01836577169808872]
	TIME [epoch: 5.73 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02140139515516547		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02140139515516547 | validation: 0.018660319152473126]
	TIME [epoch: 5.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018665469103669365		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.018665469103669365 | validation: 0.024296111086500104]
	TIME [epoch: 5.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01893971882167367		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.01893971882167367 | validation: 0.019302140631867273]
	TIME [epoch: 5.73 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014860507454284392		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.014860507454284392 | validation: 0.019433156225424603]
	TIME [epoch: 5.75 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0179823852598073		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.0179823852598073 | validation: 0.015426538470862177]
	TIME [epoch: 5.77 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019230202580686796		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.019230202580686796 | validation: 0.01430744485887318]
	TIME [epoch: 5.74 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222340592160845		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.02222340592160845 | validation: 0.015692747525786848]
	TIME [epoch: 5.73 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023269388456728643		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.023269388456728643 | validation: 0.013353972235005958]
	TIME [epoch: 5.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020583616326108372		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.020583616326108372 | validation: 0.02049113229154358]
	TIME [epoch: 5.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024187008410593104		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.024187008410593104 | validation: 0.0308705996951143]
	TIME [epoch: 5.73 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0236647890707923		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.0236647890707923 | validation: 0.021642953806214213]
	TIME [epoch: 5.78 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025024314739599075		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.025024314739599075 | validation: 0.018499511207981736]
	TIME [epoch: 5.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0226039742948884		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0226039742948884 | validation: 0.021847692275081935]
	TIME [epoch: 5.73 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020797197062877845		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.020797197062877845 | validation: 0.02368040467897416]
	TIME [epoch: 5.74 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017812495064955365		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.017812495064955365 | validation: 0.027064467556856906]
	TIME [epoch: 5.73 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02063317889163839		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.02063317889163839 | validation: 0.025886854551476643]
	TIME [epoch: 5.73 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017766118112041		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.017766118112041 | validation: 0.017704644550660925]
	TIME [epoch: 5.75 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02085419231283022		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.02085419231283022 | validation: 0.01867514921615346]
	TIME [epoch: 5.76 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016100736211303986		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.016100736211303986 | validation: 0.010439850198803986]
	TIME [epoch: 5.74 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017670014669699526		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.017670014669699526 | validation: 0.01430544244114687]
	TIME [epoch: 5.73 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017985890237003303		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.017985890237003303 | validation: 0.01904601156612099]
	TIME [epoch: 5.73 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845432129281272		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.01845432129281272 | validation: 0.01797651749370543]
	TIME [epoch: 5.73 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211251238621094		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.0211251238621094 | validation: 0.01872872167567338]
	TIME [epoch: 5.74 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01714312758286677		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.01714312758286677 | validation: 0.01705194080657153]
	TIME [epoch: 5.78 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021264006661542115		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.021264006661542115 | validation: 0.01444160924531233]
	TIME [epoch: 5.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02103945477255282		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.02103945477255282 | validation: 0.02231676554226734]
	TIME [epoch: 5.73 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020297369305699635		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.020297369305699635 | validation: 0.018072629245558778]
	TIME [epoch: 5.73 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020757641215455785		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.020757641215455785 | validation: 0.013063764532921534]
	TIME [epoch: 5.73 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02101765507425197		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.02101765507425197 | validation: 0.019298017780966483]
	TIME [epoch: 5.73 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021846818590110825		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.021846818590110825 | validation: 0.02587756122270152]
	TIME [epoch: 5.77 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019506690966449563		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.019506690966449563 | validation: 0.011279553909754768]
	TIME [epoch: 5.75 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018533521740129996		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.018533521740129996 | validation: 0.018903658351840092]
	TIME [epoch: 5.74 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018303192373551973		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.018303192373551973 | validation: 0.012611051087244704]
	TIME [epoch: 5.73 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859467876375988		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.01859467876375988 | validation: 0.01827844444677995]
	TIME [epoch: 5.73 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017428685344482588		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.017428685344482588 | validation: 0.01584075412989741]
	TIME [epoch: 5.73 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018379076658282693		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.018379076658282693 | validation: 0.01739207512002888]
	TIME [epoch: 5.74 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019753070764607687		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.019753070764607687 | validation: 0.013292374864100112]
	TIME [epoch: 5.78 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019587625067835755		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.019587625067835755 | validation: 0.02245259611481644]
	TIME [epoch: 5.73 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017550359646365865		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.017550359646365865 | validation: 0.01659402070003897]
	TIME [epoch: 5.73 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019493493289509355		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.019493493289509355 | validation: 0.014612556706457771]
	TIME [epoch: 5.73 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01970199542831565		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.01970199542831565 | validation: 0.015710311945856235]
	TIME [epoch: 5.73 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019594156102687353		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.019594156102687353 | validation: 0.02044085083987186]
	TIME [epoch: 5.73 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01849676337368464		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.01849676337368464 | validation: 0.02130382281231624]
	TIME [epoch: 5.77 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019738794167625712		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.019738794167625712 | validation: 0.01276797042985995]
	TIME [epoch: 5.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015784316630100728		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.015784316630100728 | validation: 0.02317902404564731]
	TIME [epoch: 5.73 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019861371182256733		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.019861371182256733 | validation: 0.016182151527635715]
	TIME [epoch: 5.73 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02098387797598817		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.02098387797598817 | validation: 0.016647222525738522]
	TIME [epoch: 5.73 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015808905810270318		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.015808905810270318 | validation: 0.013902249580531118]
	TIME [epoch: 5.73 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015971381028902304		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.015971381028902304 | validation: 0.01247221641516152]
	TIME [epoch: 5.74 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021631277455986513		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.021631277455986513 | validation: 0.019195588337879443]
	TIME [epoch: 5.77 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01971519667411609		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.01971519667411609 | validation: 0.015666460265241013]
	TIME [epoch: 5.73 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019803619226496524		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.019803619226496524 | validation: 0.02228241137735281]
	TIME [epoch: 5.73 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018268885809191764		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.018268885809191764 | validation: 0.02057745499314429]
	TIME [epoch: 5.73 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02052651596072933		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.02052651596072933 | validation: 0.018800349845033572]
	TIME [epoch: 5.73 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017543672635839853		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.017543672635839853 | validation: 0.01925642683159343]
	TIME [epoch: 5.73 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018356477850898438		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.018356477850898438 | validation: 0.010238130117442606]
	TIME [epoch: 5.76 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018169626247914426		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.018169626247914426 | validation: 0.011711845850341782]
	TIME [epoch: 5.75 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018863384278805746		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.018863384278805746 | validation: 0.017711010595171505]
	TIME [epoch: 5.74 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02231846164559511		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.02231846164559511 | validation: 0.024581858740211713]
	TIME [epoch: 5.73 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022989928185467863		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.022989928185467863 | validation: 0.015329178620200752]
	TIME [epoch: 5.73 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02279643973537025		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.02279643973537025 | validation: 0.011231510195044616]
	TIME [epoch: 5.73 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020664337548718686		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.020664337548718686 | validation: 0.01565361657682812]
	TIME [epoch: 5.74 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021834227070833594		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.021834227070833594 | validation: 0.015585606606698131]
	TIME [epoch: 5.78 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018564659444313604		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.018564659444313604 | validation: 0.026219193919745438]
	TIME [epoch: 5.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020459769075896892		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.020459769075896892 | validation: 0.017294413162070376]
	TIME [epoch: 5.73 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019963025253152498		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.019963025253152498 | validation: 0.01328763147034193]
	TIME [epoch: 5.73 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0192869650142173		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0192869650142173 | validation: 0.024751888275756296]
	TIME [epoch: 5.73 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02150239739327852		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02150239739327852 | validation: 0.013259611276307703]
	TIME [epoch: 5.73 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01862811097948735		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.01862811097948735 | validation: 0.021071170737002886]
	TIME [epoch: 5.76 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013708315907137732		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.013708315907137732 | validation: 0.015887740094948345]
	TIME [epoch: 5.75 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018275182773533277		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.018275182773533277 | validation: 0.019573823666536986]
	TIME [epoch: 5.74 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017362010613175754		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.017362010613175754 | validation: 0.014426368208689802]
	TIME [epoch: 5.73 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850553232228775		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.01850553232228775 | validation: 0.018877159328099354]
	TIME [epoch: 5.73 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017333309691897527		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.017333309691897527 | validation: 0.011085392375965255]
	TIME [epoch: 5.73 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021869866051718416		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.021869866051718416 | validation: 0.017448899452859306]
	TIME [epoch: 5.73 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020199117700558523		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.020199117700558523 | validation: 0.009218778203420073]
	TIME [epoch: 5.78 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01807367347781601		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.01807367347781601 | validation: 0.01739895517567558]
	TIME [epoch: 5.74 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019531615649500168		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.019531615649500168 | validation: 0.012649316971619565]
	TIME [epoch: 5.73 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019925873232208166		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.019925873232208166 | validation: 0.018168831531799216]
	TIME [epoch: 5.73 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019834676997761532		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.019834676997761532 | validation: 0.019219376515585612]
	TIME [epoch: 5.73 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020614977268030747		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.020614977268030747 | validation: 0.02132696602750845]
	TIME [epoch: 5.73 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01806921289547691		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.01806921289547691 | validation: 0.015617596804210388]
	TIME [epoch: 5.77 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015566990313426409		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.015566990313426409 | validation: 0.014717280874058792]
	TIME [epoch: 5.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021600011406679057		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.021600011406679057 | validation: 0.02071611934449031]
	TIME [epoch: 5.74 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01725753269324684		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.01725753269324684 | validation: 0.021276458881745848]
	TIME [epoch: 5.73 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020670787096344415		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.020670787096344415 | validation: 0.01573522839905535]
	TIME [epoch: 5.73 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945550947030065		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.01945550947030065 | validation: 0.021072488209295238]
	TIME [epoch: 5.73 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01889217567054152		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.01889217567054152 | validation: 0.01572669305463288]
	TIME [epoch: 5.74 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017404726993155015		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.017404726993155015 | validation: 0.011239917294328303]
	TIME [epoch: 5.77 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02099668261844074		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.02099668261844074 | validation: 0.01329367591327133]
	TIME [epoch: 5.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013011419033986		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.02013011419033986 | validation: 0.023897042692837607]
	TIME [epoch: 5.74 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017811066719482266		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.017811066719482266 | validation: 0.014998786450917215]
	TIME [epoch: 5.73 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876477939719287		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.01876477939719287 | validation: 0.015898291644159346]
	TIME [epoch: 5.73 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01938144722636313		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.01938144722636313 | validation: 0.022062992451719547]
	TIME [epoch: 5.73 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017254740093582223		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.017254740093582223 | validation: 0.018158536093069663]
	TIME [epoch: 5.77 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016177205427535493		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.016177205427535493 | validation: 0.015960205026803394]
	TIME [epoch: 5.74 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02201414603212963		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.02201414603212963 | validation: 0.02142216250703446]
	TIME [epoch: 5.73 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018104980295625003		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.018104980295625003 | validation: 0.01836431689722816]
	TIME [epoch: 5.73 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019087063965917746		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.019087063965917746 | validation: 0.014478104612701824]
	TIME [epoch: 5.73 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017938139632580855		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.017938139632580855 | validation: 0.018672903669370286]
	TIME [epoch: 5.73 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718157207346639		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.01718157207346639 | validation: 0.016583177775108374]
	TIME [epoch: 5.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020099763682028083		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.020099763682028083 | validation: 0.01992396572225817]
	TIME [epoch: 5.76 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017499932218516426		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.017499932218516426 | validation: 0.01798787816934467]
	TIME [epoch: 5.73 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017234307931030854		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.017234307931030854 | validation: 0.023918594733066838]
	TIME [epoch: 5.73 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012397253537059703		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.012397253537059703 | validation: 0.01785493629256904]
	TIME [epoch: 5.73 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022708638624795302		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.022708638624795302 | validation: 0.01633065356812169]
	TIME [epoch: 5.73 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01915996928718656		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.01915996928718656 | validation: 0.011646018976348902]
	TIME [epoch: 5.73 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01814830069755593		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.01814830069755593 | validation: 0.014275273896500879]
	TIME [epoch: 5.77 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014822648015480899		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.014822648015480899 | validation: 0.011825774219046908]
	TIME [epoch: 5.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017236345158910232		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.017236345158910232 | validation: 0.013468685480853722]
	TIME [epoch: 5.73 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021164031426200006		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.021164031426200006 | validation: 0.014990523849220158]
	TIME [epoch: 5.73 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020134603572354002		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.020134603572354002 | validation: 0.010463603921512892]
	TIME [epoch: 5.73 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02270316851341573		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.02270316851341573 | validation: 0.020448363595952188]
	TIME [epoch: 5.73 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018705526421535213		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.018705526421535213 | validation: 0.019296597331970207]
	TIME [epoch: 5.75 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021139334890091874		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.021139334890091874 | validation: 0.016326977082317517]
	TIME [epoch: 5.76 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021584837467091986		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.021584837467091986 | validation: 0.008826852948436886]
	TIME [epoch: 5.74 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021469934931155583		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.021469934931155583 | validation: 0.023737251882251655]
	TIME [epoch: 5.73 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020510911703511485		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.020510911703511485 | validation: 0.012478361875975433]
	TIME [epoch: 5.73 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020035127413841836		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.020035127413841836 | validation: 0.018943481442598255]
	TIME [epoch: 5.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01901971674065515		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.01901971674065515 | validation: 0.02171217524147717]
	TIME [epoch: 5.73 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017336591830638143		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.017336591830638143 | validation: 0.012070065375563543]
	TIME [epoch: 5.77 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019910718941245763		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.019910718941245763 | validation: 0.022815491024644318]
	TIME [epoch: 5.74 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018971865979699486		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.018971865979699486 | validation: 0.021683201756134106]
	TIME [epoch: 5.73 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021212124164241845		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.021212124164241845 | validation: 0.010634826469698681]
	TIME [epoch: 5.73 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02008809284918038		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.02008809284918038 | validation: 0.017172903578653972]
	TIME [epoch: 5.73 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020696404308445573		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.020696404308445573 | validation: 0.0127071343699798]
	TIME [epoch: 5.73 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017480918633504268		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.017480918633504268 | validation: 0.016481693525406273]
	TIME [epoch: 5.75 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017555829121182302		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.017555829121182302 | validation: 0.014428054399358205]
	TIME [epoch: 5.76 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019482759176168818		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.019482759176168818 | validation: 0.016510435412020984]
	TIME [epoch: 5.73 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01923851007763644		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.01923851007763644 | validation: 0.018340080240412414]
	TIME [epoch: 5.73 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016859958602905067		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.016859958602905067 | validation: 0.015450103508271114]
	TIME [epoch: 5.73 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015755951717246048		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.015755951717246048 | validation: 0.016121008967272057]
	TIME [epoch: 5.73 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019481914536298595		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.019481914536298595 | validation: 0.01279501578736471]
	TIME [epoch: 5.73 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021930306424894106		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.021930306424894106 | validation: 0.009238240826151482]
	TIME [epoch: 5.77 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020570133215463686		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.020570133215463686 | validation: 0.017181759849639]
	TIME [epoch: 5.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019151322592684556		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.019151322592684556 | validation: 0.02221745841206413]
	TIME [epoch: 5.73 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01886120117151861		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.01886120117151861 | validation: 0.013038226658532473]
	TIME [epoch: 5.73 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018849745036154178		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.018849745036154178 | validation: 0.01508768243600838]
	TIME [epoch: 5.73 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01731540604137593		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.01731540604137593 | validation: 0.010305825349290898]
	TIME [epoch: 5.73 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023584803261845807		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.023584803261845807 | validation: 0.01833828214258448]
	TIME [epoch: 5.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017388694366909683		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.017388694366909683 | validation: 0.01484650974480596]
	TIME [epoch: 5.76 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020392339004631683		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.020392339004631683 | validation: 0.018241180002278857]
	TIME [epoch: 5.73 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019885626341928704		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.019885626341928704 | validation: 0.02373975235062968]
	TIME [epoch: 5.73 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01852543331043729		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.01852543331043729 | validation: 0.012229269192535783]
	TIME [epoch: 5.73 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02033307053772341		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.02033307053772341 | validation: 0.020124796347444414]
	TIME [epoch: 5.73 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02033716135882801		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.02033716135882801 | validation: 0.010588716585395227]
	TIME [epoch: 5.73 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01880481164491542		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.01880481164491542 | validation: 0.015354884900909287]
	TIME [epoch: 5.77 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016880976724348427		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.016880976724348427 | validation: 0.0177380111709786]
	TIME [epoch: 5.74 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01762491406757638		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.01762491406757638 | validation: 0.023807418974326967]
	TIME [epoch: 5.73 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01856549475175425		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.01856549475175425 | validation: 0.012001352268655783]
	TIME [epoch: 5.73 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017158116067275967		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.017158116067275967 | validation: 0.021004433751899542]
	TIME [epoch: 5.73 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02215858555711592		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.02215858555711592 | validation: 0.022866365989230412]
	TIME [epoch: 5.73 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01715998182092457		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01715998182092457 | validation: 0.010491801976141878]
	TIME [epoch: 5.75 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019905217871478705		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.019905217871478705 | validation: 0.02582157893778442]
	TIME [epoch: 5.76 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01901750350733315		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.01901750350733315 | validation: 0.014626406699375054]
	TIME [epoch: 5.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020218075817089107		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.020218075817089107 | validation: 0.01519514042312089]
	TIME [epoch: 5.73 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018963907207639963		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.018963907207639963 | validation: 0.01958749169480855]
	TIME [epoch: 5.73 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016488505019895572		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.016488505019895572 | validation: 0.010920375631135912]
	TIME [epoch: 5.73 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018118979931031513		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.018118979931031513 | validation: 0.014272160156345278]
	TIME [epoch: 5.73 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022368231441936354		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.022368231441936354 | validation: 0.022318644291253673]
	TIME [epoch: 5.77 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01433947449668466		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.01433947449668466 | validation: 0.012892526098153124]
	TIME [epoch: 5.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015619763696092264		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.015619763696092264 | validation: 0.018425674236287368]
	TIME [epoch: 5.73 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020606401349968214		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.020606401349968214 | validation: 0.016231474616683287]
	TIME [epoch: 5.73 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802118758161041		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.01802118758161041 | validation: 0.01074584706054609]
	TIME [epoch: 5.73 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01902127796386255		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.01902127796386255 | validation: 0.014197543761724916]
	TIME [epoch: 5.73 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015732816699667168		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.015732816699667168 | validation: 0.020534564833204]
	TIME [epoch: 5.76 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018914093691108334		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.018914093691108334 | validation: 0.019014859697563846]
	TIME [epoch: 5.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018476256194994635		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.018476256194994635 | validation: 0.02298636364970864]
	TIME [epoch: 5.74 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020228625771012282		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.020228625771012282 | validation: 0.024892778633030837]
	TIME [epoch: 5.73 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018030803262122565		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.018030803262122565 | validation: 0.016711371678737964]
	TIME [epoch: 5.73 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0208888582370177		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.0208888582370177 | validation: 0.019719708187407536]
	TIME [epoch: 5.73 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015642482750124146		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.015642482750124146 | validation: 0.009015489855016835]
	TIME [epoch: 5.73 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019569748483425145		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.019569748483425145 | validation: 0.02268313277662942]
	TIME [epoch: 5.77 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01586953868978653		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.01586953868978653 | validation: 0.022264094472005783]
	TIME [epoch: 5.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022654071352967566		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.022654071352967566 | validation: 0.004502851119612704]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_1632.pth
	Model improved!!!
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01685893364316796		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.01685893364316796 | validation: 0.010887802008601852]
	TIME [epoch: 5.73 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016193133313822095		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.016193133313822095 | validation: 0.030060472004747762]
	TIME [epoch: 5.73 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018529048102183143		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.018529048102183143 | validation: 0.015946415883062965]
	TIME [epoch: 5.73 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016426024623415192		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.016426024623415192 | validation: 0.015265739312532469]
	TIME [epoch: 5.76 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019686737086818132		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.019686737086818132 | validation: 0.019017228158105887]
	TIME [epoch: 5.74 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017561367637826415		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.017561367637826415 | validation: 0.01755203440952991]
	TIME [epoch: 5.73 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018451024575732434		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.018451024575732434 | validation: 0.022284630160466824]
	TIME [epoch: 5.73 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016583031034787952		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.016583031034787952 | validation: 0.019470209272947018]
	TIME [epoch: 5.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021207371400759612		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.021207371400759612 | validation: 0.0171709989373176]
	TIME [epoch: 5.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02003714890708435		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.02003714890708435 | validation: 0.024944482959245066]
	TIME [epoch: 5.73 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016754990598218097		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.016754990598218097 | validation: 0.018461784406179644]
	TIME [epoch: 5.77 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01654645841109048		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.01654645841109048 | validation: 0.019917294231764013]
	TIME [epoch: 5.73 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017683829475862112		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.017683829475862112 | validation: 0.01384157053899676]
	TIME [epoch: 5.73 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01714797771972689		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.01714797771972689 | validation: 0.009772645665688508]
	TIME [epoch: 5.73 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951696359726449		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.01951696359726449 | validation: 0.017878249027746252]
	TIME [epoch: 5.73 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01637768872839017		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.01637768872839017 | validation: 0.025722334820503085]
	TIME [epoch: 5.73 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019268090150707642		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.019268090150707642 | validation: 0.013664517849880107]
	TIME [epoch: 5.77 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019046951971944948		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.019046951971944948 | validation: 0.01894636709047656]
	TIME [epoch: 5.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017268247273412494		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.017268247273412494 | validation: 0.013571047285530493]
	TIME [epoch: 5.73 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016171884013934656		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.016171884013934656 | validation: 0.02019248977897887]
	TIME [epoch: 5.73 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01589621486623006		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.01589621486623006 | validation: 0.004427529019086308]
	TIME [epoch: 5.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r5_20240309_135637/states/model_tr_study2_1653.pth
	Model improved!!!
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01792835858803714		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.01792835858803714 | validation: 0.007204798603704486]
	TIME [epoch: 5.73 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01590940698333186		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.01590940698333186 | validation: 0.01718096145838312]
	TIME [epoch: 5.74 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013910869667260267		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.013910869667260267 | validation: 0.009724232972235633]
	TIME [epoch: 5.76 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018728660705066784		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.018728660705066784 | validation: 0.013039963117600377]
	TIME [epoch: 5.73 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017253655363900625		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.017253655363900625 | validation: 0.021622854427866364]
	TIME [epoch: 5.73 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01843741526852679		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.01843741526852679 | validation: 0.02320878124121786]
	TIME [epoch: 5.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017478786724749205		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.017478786724749205 | validation: 0.020012127628194418]
	TIME [epoch: 5.73 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01836108096523223		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.01836108096523223 | validation: 0.008943685965120483]
	TIME [epoch: 5.73 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01810989814779437		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.01810989814779437 | validation: 0.022077481508912932]
	TIME [epoch: 5.77 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016281128658463498		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.016281128658463498 | validation: 0.009242345348263287]
	TIME [epoch: 5.73 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019217956132964967		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.019217956132964967 | validation: 0.01933064805037168]
	TIME [epoch: 5.73 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020037507362707863		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.020037507362707863 | validation: 0.012697633042086405]
	TIME [epoch: 5.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811231765045784		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.01811231765045784 | validation: 0.016622536296342735]
	TIME [epoch: 5.73 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018019172691833802		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.018019172691833802 | validation: 0.0158515356955991]
	TIME [epoch: 5.73 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019437826337347416		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.019437826337347416 | validation: 0.01653901329718204]
	TIME [epoch: 5.75 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014212411232590712		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.014212411232590712 | validation: 0.01387073100806321]
	TIME [epoch: 5.76 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021256180116279565		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.021256180116279565 | validation: 0.010794351600297633]
	TIME [epoch: 5.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855993879992899		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.01855993879992899 | validation: 0.01945981396628061]
	TIME [epoch: 5.73 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018446771934705977		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.018446771934705977 | validation: 0.01392685207848428]
	TIME [epoch: 5.73 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016411132550610105		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.016411132550610105 | validation: 0.011495309081279699]
	TIME [epoch: 5.73 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017605868269038167		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.017605868269038167 | validation: 0.018654328895551072]
	TIME [epoch: 5.73 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016781608283403204		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.016781608283403204 | validation: 0.018030852071166788]
	TIME [epoch: 5.77 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018332724297006456		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.018332724297006456 | validation: 0.022702566648934778]
	TIME [epoch: 5.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018396135057534225		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.018396135057534225 | validation: 0.016516732894789936]
	TIME [epoch: 5.73 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019757254589594042		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.019757254589594042 | validation: 0.01684495622738962]
	TIME [epoch: 5.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015607710162564323		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.015607710162564323 | validation: 0.013006456446821621]
	TIME [epoch: 5.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01714980448888757		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.01714980448888757 | validation: 0.022341093372067165]
	TIME [epoch: 5.73 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0207423654550362		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.0207423654550362 | validation: 0.017552653726601468]
	TIME [epoch: 5.76 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01996029744941834		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.01996029744941834 | validation: 0.0157504207901869]
	TIME [epoch: 5.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015851502161225557		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.015851502161225557 | validation: 0.014768236499558695]
	TIME [epoch: 5.73 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021844657865185774		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.021844657865185774 | validation: 0.01718660792632897]
	TIME [epoch: 5.73 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016395992979308854		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.016395992979308854 | validation: 0.014486861443336916]
	TIME [epoch: 5.73 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02100882759747787		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.02100882759747787 | validation: 0.012563286448598757]
	TIME [epoch: 5.73 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01869775421122975		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.01869775421122975 | validation: 0.013986154399717305]
	TIME [epoch: 5.73 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015474670529658795		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.015474670529658795 | validation: 0.013628228882166558]
	TIME [epoch: 5.77 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018323763536730497		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.018323763536730497 | validation: 0.013790272176837114]
	TIME [epoch: 5.74 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014517621789212308		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.014517621789212308 | validation: 0.022352693774711864]
	TIME [epoch: 5.73 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021440043297530575		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.021440043297530575 | validation: 0.009741471880976755]
	TIME [epoch: 5.73 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016991363949746343		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.016991363949746343 | validation: 0.021070543999472568]
	TIME [epoch: 5.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018533667834933123		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.018533667834933123 | validation: 0.018709863744586594]
	TIME [epoch: 5.73 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020405859527378042		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.020405859527378042 | validation: 0.013882916021232858]
	TIME [epoch: 5.76 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018654062997944757		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.018654062997944757 | validation: 0.018749068119244313]
	TIME [epoch: 5.74 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01781985411400435		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.01781985411400435 | validation: 0.020750996416740088]
	TIME [epoch: 5.73 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01555495959130756		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.01555495959130756 | validation: 0.021201694905656022]
	TIME [epoch: 5.73 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022046335922637713		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.022046335922637713 | validation: 0.024209754832675394]
	TIME [epoch: 5.73 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021145017221260713		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.021145017221260713 | validation: 0.016106730594487535]
	TIME [epoch: 5.73 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015942388106626494		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.015942388106626494 | validation: 0.018732525579382483]
	TIME [epoch: 5.73 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01630873370776087		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.01630873370776087 | validation: 0.017144265286562824]
	TIME [epoch: 5.77 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019079504460480977		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.019079504460480977 | validation: 0.012315117774321005]
	TIME [epoch: 5.73 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01674238749179274		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.01674238749179274 | validation: 0.02388901445615264]
	TIME [epoch: 5.73 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021540491485650178		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.021540491485650178 | validation: 0.021903869714190977]
	TIME [epoch: 5.73 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860690378011365		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.01860690378011365 | validation: 0.019600731815407595]
	TIME [epoch: 5.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018846635143717316		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.018846635143717316 | validation: 0.021588444885245]
	TIME [epoch: 5.73 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017086439987176114		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.017086439987176114 | validation: 0.02047002444382926]
	TIME [epoch: 5.76 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712717412033066		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.01712717412033066 | validation: 0.021828028223675983]
	TIME [epoch: 5.74 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018841858724513133		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.018841858724513133 | validation: 0.013476784630933892]
	TIME [epoch: 5.73 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01471192237542086		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.01471192237542086 | validation: 0.012182669402264985]
	TIME [epoch: 5.73 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016999869545801755		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.016999869545801755 | validation: 0.017192014638640903]
	TIME [epoch: 5.73 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016737383023856994		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.016737383023856994 | validation: 0.016127753471467502]
	TIME [epoch: 5.73 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016078861957148714		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.016078861957148714 | validation: 0.019732402307995944]
	TIME [epoch: 5.73 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019419161272424292		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.019419161272424292 | validation: 0.01326318633892522]
	TIME [epoch: 5.77 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879611801332302		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.01879611801332302 | validation: 0.01088423029396921]
	TIME [epoch: 5.73 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018106294374378117		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.018106294374378117 | validation: 0.013694294387101336]
	TIME [epoch: 5.73 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013314032706067		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.02013314032706067 | validation: 0.01482494747413114]
	TIME [epoch: 5.73 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019247178291187463		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.019247178291187463 | validation: 0.012520655195781829]
	TIME [epoch: 5.73 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01881132874356968		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.01881132874356968 | validation: 0.020295660982017433]
	TIME [epoch: 5.73 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01788497070783934		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.01788497070783934 | validation: 0.021310312634676212]
	TIME [epoch: 5.76 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016981317418299034		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.016981317418299034 | validation: 0.012628636447572119]
	TIME [epoch: 5.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018778099232846075		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.018778099232846075 | validation: 0.01847909098835422]
	TIME [epoch: 5.73 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0190286022783131		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.0190286022783131 | validation: 0.014129576682256157]
	TIME [epoch: 5.73 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01715905708768762		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.01715905708768762 | validation: 0.021961903438096748]
	TIME [epoch: 5.73 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019575308591297788		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.019575308591297788 | validation: 0.011099690171434654]
	TIME [epoch: 5.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01999925591272151		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.01999925591272151 | validation: 0.008454726481331]
	TIME [epoch: 5.73 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021327735391729365		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.021327735391729365 | validation: 0.020124617287950352]
	TIME [epoch: 5.77 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023654632048991396		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.023654632048991396 | validation: 0.018045418891316303]
	TIME [epoch: 5.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745278240898522		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.01745278240898522 | validation: 0.013598622778390313]
	TIME [epoch: 5.73 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020549520701313457		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.020549520701313457 | validation: 0.01758929331719384]
	TIME [epoch: 5.73 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017408824483506932		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.017408824483506932 | validation: 0.013568332209017438]
	TIME [epoch: 5.73 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015925507371596308		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.015925507371596308 | validation: 0.014520750451549776]
	TIME [epoch: 5.73 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019841073312735248		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.019841073312735248 | validation: 0.010970212546871187]
	TIME [epoch: 5.76 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01784672960218323		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.01784672960218323 | validation: 0.015858618504163653]
	TIME [epoch: 5.74 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016861718375672605		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.016861718375672605 | validation: 0.01868230219240184]
	TIME [epoch: 5.73 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017650292067401478		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.017650292067401478 | validation: 0.009662095823789603]
	TIME [epoch: 5.73 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015159242943067714		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.015159242943067714 | validation: 0.0184802164637481]
	TIME [epoch: 5.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019799203648564093		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.019799203648564093 | validation: 0.01684927012573723]
	TIME [epoch: 5.73 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0197289482600729		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.0197289482600729 | validation: 0.01912768549613883]
	TIME [epoch: 5.74 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020353236028302246		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.020353236028302246 | validation: 0.011031289667906641]
	TIME [epoch: 5.77 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019411325768710415		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.019411325768710415 | validation: 0.017087858662858297]
	TIME [epoch: 5.73 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019433020961738347		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.019433020961738347 | validation: 0.013334129410089289]
	TIME [epoch: 5.73 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01307491923904724		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.01307491923904724 | validation: 0.01798917044458586]
	TIME [epoch: 5.73 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017166713502253905		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.017166713502253905 | validation: 0.016289608755350394]
	TIME [epoch: 5.73 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018967368231707388		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.018967368231707388 | validation: 0.021185469523205953]
	TIME [epoch: 5.73 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021153789553267865		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.021153789553267865 | validation: 0.016035169675313838]
	TIME [epoch: 5.77 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015621210248409664		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.015621210248409664 | validation: 0.018936449261238483]
	TIME [epoch: 5.73 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01592200342863187		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.01592200342863187 | validation: 0.015190689121428812]
	TIME [epoch: 5.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019247949920796894		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.019247949920796894 | validation: 0.017813285160088847]
	TIME [epoch: 5.73 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021222187285258494		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.021222187285258494 | validation: 0.015560018532760447]
	TIME [epoch: 5.73 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015263271039657685		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.015263271039657685 | validation: 0.022138035045848214]
	TIME [epoch: 5.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016449669224228546		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.016449669224228546 | validation: 0.015558658777254302]
	TIME [epoch: 5.74 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018448055625474778		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.018448055625474778 | validation: 0.017084133080565892]
	TIME [epoch: 5.76 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019627240557928482		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.019627240557928482 | validation: 0.023133852802505732]
	TIME [epoch: 5.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018286984165364624		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.018286984165364624 | validation: 0.012973950442059668]
	TIME [epoch: 5.73 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01961497264649286		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.01961497264649286 | validation: 0.0159250510336701]
	TIME [epoch: 5.73 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015107433622614842		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.015107433622614842 | validation: 0.01007132464934261]
	TIME [epoch: 5.73 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018369829295609978		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.018369829295609978 | validation: 0.011686900875631233]
	TIME [epoch: 5.73 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01676320900403519		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.01676320900403519 | validation: 0.024348538294475246]
	TIME [epoch: 5.77 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01680430082511845		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.01680430082511845 | validation: 0.02032857862857866]
	TIME [epoch: 5.73 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017193949260102512		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.017193949260102512 | validation: 0.01325595737043258]
	TIME [epoch: 5.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01561247403741747		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.01561247403741747 | validation: 0.015596136567033077]
	TIME [epoch: 5.73 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752007089974623		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.01752007089974623 | validation: 0.013378320668800427]
	TIME [epoch: 5.73 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018810490051644792		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.018810490051644792 | validation: 0.021127586757570104]
	TIME [epoch: 5.73 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01474228424070208		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.01474228424070208 | validation: 0.013349708473885327]
	TIME [epoch: 5.74 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200804857771244		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.0200804857771244 | validation: 0.021221794349282664]
	TIME [epoch: 5.76 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015398153106047502		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.015398153106047502 | validation: 0.011972900334661994]
	TIME [epoch: 5.73 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017752761323391417		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.017752761323391417 | validation: 0.019971756251325915]
	TIME [epoch: 5.73 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019292493184552548		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.019292493184552548 | validation: 0.02645445854932346]
	TIME [epoch: 5.73 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017802442620385488		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.017802442620385488 | validation: 0.02132235029242732]
	TIME [epoch: 5.73 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018700117584177205		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.018700117584177205 | validation: 0.016916948031028323]
	TIME [epoch: 5.73 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017265263765063325		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.017265263765063325 | validation: 0.01619782342688721]
	TIME [epoch: 5.77 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019116023849544972		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.019116023849544972 | validation: 0.01849664058818449]
	TIME [epoch: 5.73 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019453291290268612		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.019453291290268612 | validation: 0.01621342253293656]
	TIME [epoch: 5.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018496735137331903		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.018496735137331903 | validation: 0.01281999545747153]
	TIME [epoch: 5.73 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019181261952359516		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.019181261952359516 | validation: 0.009367337816984112]
	TIME [epoch: 5.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02064730941246901		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.02064730941246901 | validation: 0.01231646462922321]
	TIME [epoch: 5.73 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017170432908644243		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.017170432908644243 | validation: 0.012571246984864053]
	TIME [epoch: 5.74 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01736962543958713		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.01736962543958713 | validation: 0.018117111423411582]
	TIME [epoch: 5.76 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01792915033094587		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.01792915033094587 | validation: 0.019403763568644542]
	TIME [epoch: 5.73 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020036210093602368		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.020036210093602368 | validation: 0.01296099812836938]
	TIME [epoch: 5.73 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01719003278724953		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.01719003278724953 | validation: 0.017154590079988805]
	TIME [epoch: 5.73 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01969727235293721		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.01969727235293721 | validation: 0.014988273956537715]
	TIME [epoch: 5.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020235116625076415		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.020235116625076415 | validation: 0.013667642488742375]
	TIME [epoch: 5.73 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464707093310292		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.01464707093310292 | validation: 0.01987583694387361]
	TIME [epoch: 5.77 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019172686414414816		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.019172686414414816 | validation: 0.018905481853963884]
	TIME [epoch: 5.74 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01593702706288462		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.01593702706288462 | validation: 0.023833687980756874]
	TIME [epoch: 5.73 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014452656753401804		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.014452656753401804 | validation: 0.017545105394266174]
	TIME [epoch: 5.73 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01731167253137874		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.01731167253137874 | validation: 0.026701779090193247]
	TIME [epoch: 5.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018957422723216683		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.018957422723216683 | validation: 0.015947430083320408]
	TIME [epoch: 5.73 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018680857940568344		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.018680857940568344 | validation: 0.01735328601791472]
	TIME [epoch: 5.75 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017796106278412993		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.017796106278412993 | validation: 0.005524197738124451]
	TIME [epoch: 5.76 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021635250053692063		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.021635250053692063 | validation: 0.024199475800364648]
	TIME [epoch: 5.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019393814028384363		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.019393814028384363 | validation: 0.008766860293511454]
	TIME [epoch: 5.73 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017111045674481906		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.017111045674481906 | validation: 0.024935542250124766]
	TIME [epoch: 5.73 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017935080063684782		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.017935080063684782 | validation: 0.02002654028747743]
	TIME [epoch: 5.73 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019360126110923796		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.019360126110923796 | validation: 0.016488516517776084]
	TIME [epoch: 5.73 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02155575671269057		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.02155575671269057 | validation: 0.016476386260341785]
	TIME [epoch: 5.77 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018049083689557044		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.018049083689557044 | validation: 0.024101810121607566]
	TIME [epoch: 5.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02098803955334258		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.02098803955334258 | validation: 0.021646828636055365]
	TIME [epoch: 5.73 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01732173006597549		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.01732173006597549 | validation: 0.012229227516201716]
	TIME [epoch: 5.73 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0183222154198951		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.0183222154198951 | validation: 0.018998847202315355]
	TIME [epoch: 5.73 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017787579894537997		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.017787579894537997 | validation: 0.021966722856637456]
	TIME [epoch: 5.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01596889731389279		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.01596889731389279 | validation: 0.01680060370224294]
	TIME [epoch: 5.76 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020574897454859194		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.020574897454859194 | validation: 0.011871825749035945]
	TIME [epoch: 5.74 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014392836999947365		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.014392836999947365 | validation: 0.009973600560518799]
	TIME [epoch: 5.73 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017430493987937595		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.017430493987937595 | validation: 0.01674209925582957]
	TIME [epoch: 5.73 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017762134249885094		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.017762134249885094 | validation: 0.014984649400705055]
	TIME [epoch: 5.73 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015603677595619016		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.015603677595619016 | validation: 0.0173709612838196]
	TIME [epoch: 5.73 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01994715688544031		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.01994715688544031 | validation: 0.02125899093023409]
	TIME [epoch: 5.73 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409931943581949		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.01409931943581949 | validation: 0.019269306580779473]
	TIME [epoch: 5.8 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015631921053366825		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.015631921053366825 | validation: 0.009062800583359803]
	TIME [epoch: 5.73 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688937075737137		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.01688937075737137 | validation: 0.023843906646004047]
	TIME [epoch: 5.73 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018507558755886458		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.018507558755886458 | validation: 0.020901398592230926]
	TIME [epoch: 5.73 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01919953566381191		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.01919953566381191 | validation: 0.014580062246876095]
	TIME [epoch: 5.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017019067918643174		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.017019067918643174 | validation: 0.0236052565537265]
	TIME [epoch: 5.73 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018331479985543866		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.018331479985543866 | validation: 0.017788173205300566]
	TIME [epoch: 5.76 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019290142053753963		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.019290142053753963 | validation: 0.025372712132873634]
	TIME [epoch: 5.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01814201552963877		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.01814201552963877 | validation: 0.010810689834769521]
	TIME [epoch: 5.73 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019687930666796593		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.019687930666796593 | validation: 0.021371720150934307]
	TIME [epoch: 5.73 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01642303883447098		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.01642303883447098 | validation: 0.01601739457069932]
	TIME [epoch: 5.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01883701726522086		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.01883701726522086 | validation: 0.01103368904004003]
	TIME [epoch: 5.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018932824467514316		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.018932824467514316 | validation: 0.020556402103988198]
	TIME [epoch: 5.73 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018616521189827165		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.018616521189827165 | validation: 0.01976416639288166]
	TIME [epoch: 5.77 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021017259129304203		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.021017259129304203 | validation: 0.019410619882848805]
	TIME [epoch: 5.73 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020645788124575633		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.020645788124575633 | validation: 0.014819720151563649]
	TIME [epoch: 5.73 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014970132570010824		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.014970132570010824 | validation: 0.01291289384862707]
	TIME [epoch: 5.73 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02092959453589471		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.02092959453589471 | validation: 0.01795952775942234]
	TIME [epoch: 5.73 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01578776933598839		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.01578776933598839 | validation: 0.01085490747286915]
	TIME [epoch: 5.73 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013073762760546816		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.013073762760546816 | validation: 0.0167414263879303]
	TIME [epoch: 5.76 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020226398874180675		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.020226398874180675 | validation: 0.011936346734351325]
	TIME [epoch: 5.74 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01819540866861364		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.01819540866861364 | validation: 0.022323360987468694]
	TIME [epoch: 5.73 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018504341073722952		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.018504341073722952 | validation: 0.021934089302123122]
	TIME [epoch: 5.73 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019140555497901522		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.019140555497901522 | validation: 0.012955868865351557]
	TIME [epoch: 5.73 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018440979313450876		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.018440979313450876 | validation: 0.019203674421874675]
	TIME [epoch: 5.73 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01686356725700683		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.01686356725700683 | validation: 0.012222836453686008]
	TIME [epoch: 5.73 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021431214371962087		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.021431214371962087 | validation: 0.02101919503317168]
	TIME [epoch: 5.77 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017214996080460336		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.017214996080460336 | validation: 0.019236543319611644]
	TIME [epoch: 5.73 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018145402849484158		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.018145402849484158 | validation: 0.015519459508569753]
	TIME [epoch: 5.73 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017964957225423402		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.017964957225423402 | validation: 0.010288889181194968]
	TIME [epoch: 5.73 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01826921993445908		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.01826921993445908 | validation: 0.015058924051812164]
	TIME [epoch: 5.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016244484044986282		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.016244484044986282 | validation: 0.01435371924955468]
	TIME [epoch: 5.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02074363660221574		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.02074363660221574 | validation: 0.016652155145667695]
	TIME [epoch: 5.76 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01543470972193562		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.01543470972193562 | validation: 0.020746289343688593]
	TIME [epoch: 5.74 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01701708876271099		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.01701708876271099 | validation: 0.016139922077824772]
	TIME [epoch: 5.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019021747929283513		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.019021747929283513 | validation: 0.0123362427220286]
	TIME [epoch: 5.73 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016569521592181367		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.016569521592181367 | validation: 0.01357429955969128]
	TIME [epoch: 5.73 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020717090646832012		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.020717090646832012 | validation: 0.014395958246159505]
	TIME [epoch: 5.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01958727883640623		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.01958727883640623 | validation: 0.025922706044843462]
	TIME [epoch: 5.73 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017888162659157103		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.017888162659157103 | validation: 0.013583069260363881]
	TIME [epoch: 5.77 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014251109050873866		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.014251109050873866 | validation: 0.01889085454982828]
	TIME [epoch: 5.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02116828187187072		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.02116828187187072 | validation: 0.013677368498326068]
	TIME [epoch: 5.73 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021115144352710787		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.021115144352710787 | validation: 0.011952104185652805]
	TIME [epoch: 5.73 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017952254440458892		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.017952254440458892 | validation: 0.01889127803005855]
	TIME [epoch: 5.73 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01708923468361906		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.01708923468361906 | validation: 0.019628662231971558]
	TIME [epoch: 5.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021183320688123695		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.021183320688123695 | validation: 0.011044538470011855]
	TIME [epoch: 5.76 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017695136615460655		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.017695136615460655 | validation: 0.011355116201440998]
	TIME [epoch: 5.74 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825197272096697		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.01825197272096697 | validation: 0.021692882101173375]
	TIME [epoch: 5.73 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021077698783726805		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.021077698783726805 | validation: 0.015972312325431205]
	TIME [epoch: 5.73 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017635324074613205		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.017635324074613205 | validation: 0.010674264468897432]
	TIME [epoch: 5.73 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01949315718073654		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.01949315718073654 | validation: 0.018010225435332285]
	TIME [epoch: 5.73 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01700637604314774		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.01700637604314774 | validation: 0.01634237153480367]
	TIME [epoch: 5.74 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020433266470627817		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.020433266470627817 | validation: 0.01798307426292122]
	TIME [epoch: 5.75 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760223645893187		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.01760223645893187 | validation: 0.01326392506510719]
	TIME [epoch: 5.73 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181890560068456		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0181890560068456 | validation: 0.015506559849822252]
	TIME [epoch: 5.73 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018423967540475768		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.018423967540475768 | validation: 0.020865090243774257]
	TIME [epoch: 5.73 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017359179880744875		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.017359179880744875 | validation: 0.01374364341036343]
	TIME [epoch: 5.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811835298284198		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.01811835298284198 | validation: 0.014237787751145899]
	TIME [epoch: 5.73 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019752228604751912		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.019752228604751912 | validation: 0.013026840380132522]
	TIME [epoch: 5.77 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019046816623493293		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.019046816623493293 | validation: 0.020488280293777698]
	TIME [epoch: 5.73 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01684557175187915		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.01684557175187915 | validation: 0.021088049452079885]
	TIME [epoch: 5.73 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016787932514504826		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.016787932514504826 | validation: 0.010415662057407713]
	TIME [epoch: 5.73 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016825363202922085		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.016825363202922085 | validation: 0.017043176248354257]
	TIME [epoch: 5.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018949786719538418		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.018949786719538418 | validation: 0.015645377870328905]
	TIME [epoch: 5.73 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019513588612936318		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.019513588612936318 | validation: 0.01609308361258272]
	TIME [epoch: 5.74 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017114940477570634		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.017114940477570634 | validation: 0.015583753970789994]
	TIME [epoch: 5.76 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01628093985826615		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.01628093985826615 | validation: 0.018267784250254358]
	TIME [epoch: 5.73 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01787093508394301		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.01787093508394301 | validation: 0.019815774442586732]
	TIME [epoch: 5.73 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015562299074133278		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.015562299074133278 | validation: 0.020482090985761224]
	TIME [epoch: 5.73 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020416260245900708		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.020416260245900708 | validation: 0.008281225824766227]
	TIME [epoch: 5.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014273541060744152		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.014273541060744152 | validation: 0.011313241755854749]
	TIME [epoch: 5.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683322113224286		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.01683322113224286 | validation: 0.016610915698369283]
	TIME [epoch: 5.77 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017255930749699284		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.017255930749699284 | validation: 0.020789013677316507]
	TIME [epoch: 5.73 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02078771114504946		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.02078771114504946 | validation: 0.014388591800183606]
	TIME [epoch: 5.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017747817348494066		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.017747817348494066 | validation: 0.020086583390034465]
	TIME [epoch: 5.73 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017342400631178447		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.017342400631178447 | validation: 0.015024928982244248]
	TIME [epoch: 5.73 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847701489766122		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.01847701489766122 | validation: 0.022806160213608945]
	TIME [epoch: 5.73 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017417542206780712		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.017417542206780712 | validation: 0.010907823254289111]
	TIME [epoch: 5.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017272477879596338		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.017272477879596338 | validation: 0.016742568043178526]
	TIME [epoch: 5.76 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017221168695450564		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.017221168695450564 | validation: 0.0196374489184433]
	TIME [epoch: 5.73 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016838344548528034		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.016838344548528034 | validation: 0.016643853182610455]
	TIME [epoch: 5.73 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019883868020526926		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.019883868020526926 | validation: 0.01744898083313275]
	TIME [epoch: 5.73 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02120690308613333		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.02120690308613333 | validation: 0.012288081656568379]
	TIME [epoch: 5.73 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018722115638150905		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.018722115638150905 | validation: 0.012961166254649738]
	TIME [epoch: 5.73 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0194466019635839		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.0194466019635839 | validation: 0.020368014533191998]
	TIME [epoch: 5.77 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017476920819794517		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.017476920819794517 | validation: 0.021518852458894552]
	TIME [epoch: 5.73 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017916063920688653		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.017916063920688653 | validation: 0.022769006867666856]
	TIME [epoch: 5.73 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01704264415830882		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.01704264415830882 | validation: 0.014523969530734178]
	TIME [epoch: 5.73 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019976657756283562		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.019976657756283562 | validation: 0.02446032983258571]
	TIME [epoch: 5.73 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614639464858298		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.01614639464858298 | validation: 0.020156858509353014]
	TIME [epoch: 5.73 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017622444192475977		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.017622444192475977 | validation: 0.02123587706948726]
	TIME [epoch: 5.74 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020298925412877908		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.020298925412877908 | validation: 0.014403814544891144]
	TIME [epoch: 5.76 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0185321278963574		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.0185321278963574 | validation: 0.021232010866708166]
	TIME [epoch: 5.73 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017211128454070676		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.017211128454070676 | validation: 0.024226841981608977]
	TIME [epoch: 5.73 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021282682273797766		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.021282682273797766 | validation: 0.02183511101060962]
	TIME [epoch: 5.73 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022952472512216795		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.022952472512216795 | validation: 0.01997088337955413]
	TIME [epoch: 5.73 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017745230831910274		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.017745230831910274 | validation: 0.021585323264574293]
	TIME [epoch: 5.73 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017746923372111728		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.017746923372111728 | validation: 0.021607459205396785]
	TIME [epoch: 5.77 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02028268236470757		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.02028268236470757 | validation: 0.018803842419201213]
	TIME [epoch: 5.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018376681241749408		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.018376681241749408 | validation: 0.01000377127415498]
	TIME [epoch: 5.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01728267434627648		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.01728267434627648 | validation: 0.016147709006673873]
	TIME [epoch: 5.73 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568292090629075		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.01568292090629075 | validation: 0.012824821840104767]
	TIME [epoch: 5.73 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0182234077766146		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.0182234077766146 | validation: 0.015285258118139416]
	TIME [epoch: 5.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01891832478923574		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.01891832478923574 | validation: 0.015261145429166243]
	TIME [epoch: 5.76 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022197593907270725		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.022197593907270725 | validation: 0.013299654301724743]
	TIME [epoch: 5.74 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018976959359230376		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.018976959359230376 | validation: 0.010674672438732902]
	TIME [epoch: 5.73 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199985179049892		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.02199985179049892 | validation: 0.015700480657866663]
	TIME [epoch: 5.73 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021914924797022835		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.021914924797022835 | validation: 0.013986495445014182]
	TIME [epoch: 5.73 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01692484992329365		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.01692484992329365 | validation: 0.015118537180499771]
	TIME [epoch: 5.73 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016147964278595058		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.016147964278595058 | validation: 0.011951679889904287]
	TIME [epoch: 5.73 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02397011801315911		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.02397011801315911 | validation: 0.020043692548743528]
	TIME [epoch: 5.77 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01662079776527205		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.01662079776527205 | validation: 0.014298699091556127]
	TIME [epoch: 5.73 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01910351569689295		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.01910351569689295 | validation: 0.017675277417760177]
	TIME [epoch: 5.73 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013650614398392		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.02013650614398392 | validation: 0.019186514108427505]
	TIME [epoch: 5.73 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019947677862825763		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.019947677862825763 | validation: 0.014346737701191208]
	TIME [epoch: 5.73 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610192934194658		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.01610192934194658 | validation: 0.017669837809659743]
	TIME [epoch: 5.73 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021946845197024015		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.021946845197024015 | validation: 0.014684341807424452]
	TIME [epoch: 5.76 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017771469068171713		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.017771469068171713 | validation: 0.0136131755175124]
	TIME [epoch: 5.74 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02110001168044338		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.02110001168044338 | validation: 0.016855624698637026]
	TIME [epoch: 5.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768293235217928		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.01768293235217928 | validation: 0.012507451602957258]
	TIME [epoch: 5.73 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017950311494144035		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.017950311494144035 | validation: 0.017199258324640133]
	TIME [epoch: 5.73 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016025955511005427		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.016025955511005427 | validation: 0.017758005877141828]
	TIME [epoch: 5.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018190877190230336		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.018190877190230336 | validation: 0.01352577061154317]
	TIME [epoch: 5.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014653104490661883		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.014653104490661883 | validation: 0.01394006074882497]
	TIME [epoch: 5.77 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016515511373158275		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.016515511373158275 | validation: 0.01810813131526145]
	TIME [epoch: 5.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017047479043228876		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.017047479043228876 | validation: 0.009542338407162601]
	TIME [epoch: 5.73 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017422077981246953		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.017422077981246953 | validation: 0.019633582280100495]
	TIME [epoch: 5.73 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812599747573317		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.01812599747573317 | validation: 0.01402760780637537]
	TIME [epoch: 5.73 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018568240671881283		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.018568240671881283 | validation: 0.014977486662610909]
	TIME [epoch: 5.72 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014923574186757639		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.014923574186757639 | validation: 0.01770178185202226]
	TIME [epoch: 5.76 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016705796158715584		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.016705796158715584 | validation: 0.019285840060640262]
	TIME [epoch: 5.74 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017242572206777364		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.017242572206777364 | validation: 0.015323473787398486]
	TIME [epoch: 5.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01997518566317676		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.01997518566317676 | validation: 0.016330146674958763]
	TIME [epoch: 5.73 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018207190190842597		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.018207190190842597 | validation: 0.01884893303274068]
	TIME [epoch: 5.73 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019856014959267917		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.019856014959267917 | validation: 0.015348066951693516]
	TIME [epoch: 5.73 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016606279263712588		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.016606279263712588 | validation: 0.01829715405460657]
	TIME [epoch: 5.73 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016735480735928523		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.016735480735928523 | validation: 0.021135212620731342]
	TIME [epoch: 5.77 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01814049347704274		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.01814049347704274 | validation: 0.017956365729325945]
	TIME [epoch: 5.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021135771724399916		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.021135771724399916 | validation: 0.012512767368789559]
	TIME [epoch: 5.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0233417905869154		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.0233417905869154 | validation: 0.013839586940672492]
	TIME [epoch: 5.73 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202577312683856		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.02202577312683856 | validation: 0.016994075641998223]
	TIME [epoch: 5.73 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017332642706395097		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.017332642706395097 | validation: 0.009801373529462198]
	TIME [epoch: 5.73 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021152075884689325		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.021152075884689325 | validation: 0.019063060755752904]
	TIME [epoch: 5.76 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019337111234328012		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.019337111234328012 | validation: 0.012748005489726537]
	TIME [epoch: 5.74 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016087842087105106		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.016087842087105106 | validation: 0.016373970761501596]
	TIME [epoch: 5.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0167486742656263		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.0167486742656263 | validation: 0.01603024703287984]
	TIME [epoch: 5.73 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0168342904607027		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.0168342904607027 | validation: 0.016295507133511904]
	TIME [epoch: 5.73 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016719685499998645		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.016719685499998645 | validation: 0.019476537159065964]
	TIME [epoch: 5.73 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023023082830172216		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.023023082830172216 | validation: 0.01856482261752017]
	TIME [epoch: 5.73 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015331958802825174		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.015331958802825174 | validation: 0.015047193333769153]
	TIME [epoch: 5.76 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0168485484604609		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.0168485484604609 | validation: 0.017063586022274774]
	TIME [epoch: 5.73 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698013645572616		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.01698013645572616 | validation: 0.007566281112717989]
	TIME [epoch: 5.73 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017771722223321046		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.017771722223321046 | validation: 0.008604694910877805]
	TIME [epoch: 5.73 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017981654154792474		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.017981654154792474 | validation: 0.023268416860072617]
	TIME [epoch: 5.73 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015500732867967408		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.015500732867967408 | validation: 0.015907003545855246]
	TIME [epoch: 5.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02009382031741305		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.02009382031741305 | validation: 0.019006351724185515]
	TIME [epoch: 5.77 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018048504849565647		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.018048504849565647 | validation: 0.015185531952301925]
	TIME [epoch: 5.73 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017224530769284777		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.017224530769284777 | validation: 0.02127588079780261]
	TIME [epoch: 5.73 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01870745964460807		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.01870745964460807 | validation: 0.013245060451393334]
	TIME [epoch: 5.73 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013979894099082098		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.013979894099082098 | validation: 0.018470347071786342]
	TIME [epoch: 5.73 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014885561781121506		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.014885561781121506 | validation: 0.01629265197417885]
	TIME [epoch: 5.73 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594246975123972		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.015594246975123972 | validation: 0.011683846271818048]
	TIME [epoch: 5.74 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01628140198073924		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.01628140198073924 | validation: 0.016200697277695915]
	TIME [epoch: 5.75 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016523873785853797		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.016523873785853797 | validation: 0.01602293629618088]
	TIME [epoch: 5.73 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0182866998313536		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.0182866998313536 | validation: 0.010375100465290108]
	TIME [epoch: 5.73 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017927973170125604		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.017927973170125604 | validation: 0.010514324509932593]
	TIME [epoch: 5.73 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017767945182837707		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.017767945182837707 | validation: 0.019794858352335635]
	TIME [epoch: 5.73 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016365833987965858		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.016365833987965858 | validation: 0.015261589411879087]
	TIME [epoch: 5.73 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017108888301269966		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.017108888301269966 | validation: 0.01437815391207252]
	TIME [epoch: 5.76 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017028638003270376		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.017028638003270376 | validation: 0.01482708611425724]
	TIME [epoch: 5.73 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018514778258306577		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.018514778258306577 | validation: 0.019601875757941027]
	TIME [epoch: 5.73 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01672681551790153		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.01672681551790153 | validation: 0.02027335865449038]
	TIME [epoch: 5.73 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01890515944546291		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.01890515944546291 | validation: 0.018997105087249503]
	TIME [epoch: 5.73 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016862754288574887		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.016862754288574887 | validation: 0.020117196995836584]
	TIME [epoch: 5.73 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016103741573345643		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.016103741573345643 | validation: 0.020893844303473283]
	TIME [epoch: 5.74 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01632760384091505		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.01632760384091505 | validation: 0.015967000461711706]
	TIME [epoch: 5.75 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019666856705552422		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.019666856705552422 | validation: 0.02202235438835366]
	TIME [epoch: 5.74 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017987796472466448		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.017987796472466448 | validation: 0.011909393666808144]
	TIME [epoch: 5.72 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019693492864131773		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.019693492864131773 | validation: 0.018837255379571365]
	TIME [epoch: 5.72 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016034919310248388		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.016034919310248388 | validation: 0.023842093389657943]
	TIME [epoch: 5.72 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017012736904071967		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.017012736904071967 | validation: 0.019799549208070304]
	TIME [epoch: 5.72 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021197528501074116		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.021197528501074116 | validation: 0.018261195446703828]
	TIME [epoch: 5.76 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017257417015774087		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.017257417015774087 | validation: 0.016258029391874988]
	TIME [epoch: 5.73 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019386089829867656		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.019386089829867656 | validation: 0.021349316956642276]
	TIME [epoch: 5.72 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016579836724956915		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.016579836724956915 | validation: 0.013876815213037208]
	TIME [epoch: 5.72 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015162962618540533		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.015162962618540533 | validation: 0.0153815541416984]
	TIME [epoch: 5.72 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016079994463863705		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.016079994463863705 | validation: 0.0220885672082151]
	TIME [epoch: 5.73 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017772366921692147		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.017772366921692147 | validation: 0.02046216831585533]
	TIME [epoch: 5.73 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018326677067564783		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.018326677067564783 | validation: 0.007194214599218689]
	TIME [epoch: 5.74 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01614212645930362		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.01614212645930362 | validation: 0.012206097392767906]
	TIME [epoch: 5.72 sec]
Finished training in 11689.585 seconds.
