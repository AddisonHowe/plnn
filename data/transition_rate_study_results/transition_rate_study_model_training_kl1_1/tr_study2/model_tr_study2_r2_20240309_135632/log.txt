Args:
Namespace(name='model_tr_study2', outdir='out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2', training_data='data/transition_rate_studies/tr_study2/tr_study2_training/r2', validation_data='data/transition_rate_studies/tr_study2/tr_study2_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 851672036

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.346274969870276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.346274969870276 | validation: 7.70218912533108]
	TIME [epoch: 84.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.630831380614767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.630831380614767 | validation: 5.2644851612450445]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.403012223414705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.403012223414705 | validation: 4.979676140998736]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8836655503072794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8836655503072794 | validation: 4.558290047237054]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.375077096507882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.375077096507882 | validation: 3.5951577255706444]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.089380694610364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.089380694610364 | validation: 3.4569088394252048]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.89009302523739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.89009302523739 | validation: 3.420079561603765]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.166038302056138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.166038302056138 | validation: 3.1364770582775385]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.550617684410487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.550617684410487 | validation: 3.034558436587561]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.848569567149173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.848569567149173 | validation: 2.9276273583848393]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677060768345484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6677060768345484 | validation: 2.4376266044643904]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5041200141234614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5041200141234614 | validation: 2.7588006754252627]
	TIME [epoch: 6.43 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.569313991043537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.569313991043537 | validation: 2.1822539124336964]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4470840351588103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4470840351588103 | validation: 2.3695597753886792]
	TIME [epoch: 6.42 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4799911975325704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4799911975325704 | validation: 1.9490669089824133]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9021041895670165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9021041895670165 | validation: 1.7981373448091313]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.817396410316511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.817396410316511 | validation: 1.7883042218164114]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7965368228233443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7965368228233443 | validation: 1.5418169604213563]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9493355201276166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9493355201276166 | validation: 2.577825224035755]
	TIME [epoch: 6.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8742573669643083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8742573669643083 | validation: 1.36090096328247]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.888523591813503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.888523591813503 | validation: 2.182518855456646]
	TIME [epoch: 6.45 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6564973758239836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6564973758239836 | validation: 1.7206692610662198]
	TIME [epoch: 6.47 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6374883850687953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6374883850687953 | validation: 1.1647413826106705]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.678915298636673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.678915298636673 | validation: 1.3521748178111639]
	TIME [epoch: 6.48 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5311066889257336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5311066889257336 | validation: 1.3640610540906222]
	TIME [epoch: 6.48 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2215442365587155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2215442365587155 | validation: 1.0379795793371718]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1455767068789795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1455767068789795 | validation: 1.1332015403251]
	TIME [epoch: 6.47 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166877347948196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.166877347948196 | validation: 0.9849799372558451]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9229792673481609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9229792673481609 | validation: 1.8967521892959878]
	TIME [epoch: 6.45 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823256854944724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1823256854944724 | validation: 1.0206978152210124]
	TIME [epoch: 6.47 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9384205398508513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9384205398508513 | validation: 1.0193365662656815]
	TIME [epoch: 6.48 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9543752997566022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9543752997566022 | validation: 1.1250181464782918]
	TIME [epoch: 6.45 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0487363305129187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0487363305129187 | validation: 0.8885184420047217]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466565393051122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1466565393051122 | validation: 0.8957963687887813]
	TIME [epoch: 6.44 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9110700880375835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9110700880375835 | validation: 0.9304526599931401]
	TIME [epoch: 6.44 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270461374923774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8270461374923774 | validation: 1.0182915055985928]
	TIME [epoch: 6.45 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0378993464048634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0378993464048634 | validation: 0.7071751808459075]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1329822126628328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1329822126628328 | validation: 0.9224964480813529]
	TIME [epoch: 6.45 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4249586199706596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4249586199706596 | validation: 1.2743691735173999]
	TIME [epoch: 6.45 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437643850096952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8437643850096952 | validation: 0.773438809648309]
	TIME [epoch: 6.45 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8401695193277994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8401695193277994 | validation: 0.7293630600017041]
	TIME [epoch: 6.45 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271948096708194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7271948096708194 | validation: 0.9329807883330006]
	TIME [epoch: 6.45 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555682227158159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8555682227158159 | validation: 0.7493978909525173]
	TIME [epoch: 6.47 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7954318541790796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7954318541790796 | validation: 1.057279320780099]
	TIME [epoch: 6.47 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8495158316346091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8495158316346091 | validation: 0.7514135865565574]
	TIME [epoch: 6.45 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857286139705907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6857286139705907 | validation: 1.1812302617095842]
	TIME [epoch: 6.45 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346632379008162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8346632379008162 | validation: 0.8309410463839172]
	TIME [epoch: 6.45 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707493673888587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7707493673888587 | validation: 0.8463630564643149]
	TIME [epoch: 6.45 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90941567078004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.90941567078004 | validation: 0.866383917245311]
	TIME [epoch: 6.45 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0974767523412834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0974767523412834 | validation: 0.8740340744229752]
	TIME [epoch: 6.47 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592238248429568		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.7592238248429568 | validation: 0.7740053943455019]
	TIME [epoch: 6.46 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6903849505597064		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.6903849505597064 | validation: 0.6638092605085695]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904916910701132		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.6904916910701132 | validation: 1.0437143985489408]
	TIME [epoch: 6.45 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8323086511507192		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.8323086511507192 | validation: 0.624095025362643]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044598156159824		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.6044598156159824 | validation: 0.6262807953057689]
	TIME [epoch: 6.45 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646282996664281		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.6646282996664281 | validation: 0.8067560791024474]
	TIME [epoch: 6.45 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6612348736513952		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.6612348736513952 | validation: 0.586010269935077]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030442154637126		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.6030442154637126 | validation: 0.795166812626847]
	TIME [epoch: 6.45 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8853589389630793		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.8853589389630793 | validation: 2.9869331525907183]
	TIME [epoch: 6.44 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.803273567051746		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.803273567051746 | validation: 0.7722546567978004]
	TIME [epoch: 6.44 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276934129198652		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.7276934129198652 | validation: 1.0857745074362815]
	TIME [epoch: 6.45 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849540777456743		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.6849540777456743 | validation: 0.5669593444205845]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684999969527112		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.684999969527112 | validation: 0.6367726595919593]
	TIME [epoch: 6.47 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937041616022094		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5937041616022094 | validation: 0.7105496177236256]
	TIME [epoch: 6.46 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8395017230236723		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.8395017230236723 | validation: 0.6328127694077935]
	TIME [epoch: 6.45 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396735671638597		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5396735671638597 | validation: 0.6617757973978187]
	TIME [epoch: 6.46 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113003876099461		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5113003876099461 | validation: 0.7493517669955869]
	TIME [epoch: 6.47 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205707518924939		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.7205707518924939 | validation: 0.737820519866849]
	TIME [epoch: 6.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720009741442858		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.720009741442858 | validation: 0.6688622208460016]
	TIME [epoch: 6.46 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239426350545979		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7239426350545979 | validation: 0.6880022402667781]
	TIME [epoch: 6.48 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344724875820053		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6344724875820053 | validation: 1.1545502678352981]
	TIME [epoch: 6.47 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198361487249029		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7198361487249029 | validation: 0.5127299199261997]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458103125274951		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5458103125274951 | validation: 0.5837143784995185]
	TIME [epoch: 6.47 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529426217347224		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.529426217347224 | validation: 0.545797358240228]
	TIME [epoch: 6.46 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165369361068416		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5165369361068416 | validation: 0.6794080970958506]
	TIME [epoch: 6.47 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927129097236544		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.6927129097236544 | validation: 0.7480629358291256]
	TIME [epoch: 6.47 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919065755786169		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6919065755786169 | validation: 0.9402869331421068]
	TIME [epoch: 6.48 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7533072341382228		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.7533072341382228 | validation: 0.8212368060349363]
	TIME [epoch: 6.46 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858449108725908		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.6858449108725908 | validation: 0.5461972210270173]
	TIME [epoch: 6.47 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6489224267296935		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6489224267296935 | validation: 0.572798958427006]
	TIME [epoch: 6.47 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431524255372898		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5431524255372898 | validation: 0.582475834387035]
	TIME [epoch: 6.46 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46661262470937837		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.46661262470937837 | validation: 0.6227830948671521]
	TIME [epoch: 6.46 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5969265206174975		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5969265206174975 | validation: 0.7008877430149961]
	TIME [epoch: 6.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048922364731838		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5048922364731838 | validation: 0.604064699527151]
	TIME [epoch: 6.47 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5898744726225911		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5898744726225911 | validation: 0.5534487652299224]
	TIME [epoch: 6.46 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586337282951356		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.586337282951356 | validation: 0.4841824426192629]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4622632559582912		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4622632559582912 | validation: 0.42820947701562156]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6402103737531807		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.6402103737531807 | validation: 0.6713173587535454]
	TIME [epoch: 6.45 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6003550306365776		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6003550306365776 | validation: 0.6314187426196305]
	TIME [epoch: 6.48 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815626362321968		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5815626362321968 | validation: 0.6017569393440779]
	TIME [epoch: 6.48 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207676740903263		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.5207676740903263 | validation: 0.4313236713640957]
	TIME [epoch: 6.46 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4691365600728848		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.4691365600728848 | validation: 1.8090703054270636]
	TIME [epoch: 6.47 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9164650023971357		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.9164650023971357 | validation: 0.6540462133874304]
	TIME [epoch: 6.45 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516580765875711		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.516580765875711 | validation: 0.6741646033967064]
	TIME [epoch: 6.46 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6444289690889159		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6444289690889159 | validation: 0.5370846283876588]
	TIME [epoch: 6.46 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031321559993998		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.6031321559993998 | validation: 0.6779722870946092]
	TIME [epoch: 6.49 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307922840204647		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6307922840204647 | validation: 0.4951166094439121]
	TIME [epoch: 6.46 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4283851142744435		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4283851142744435 | validation: 0.5911415839037861]
	TIME [epoch: 6.46 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42130723939845705		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.42130723939845705 | validation: 0.37168494608028796]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3730231214140771		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.3730231214140771 | validation: 0.3357731017862453]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34707082278657697		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.34707082278657697 | validation: 0.6028213066041956]
	TIME [epoch: 6.47 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122484269007949		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5122484269007949 | validation: 0.4792434509037561]
	TIME [epoch: 6.46 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010684136584125		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.4010684136584125 | validation: 0.5556247026299814]
	TIME [epoch: 6.47 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336268123280084		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.4336268123280084 | validation: 0.500430564690796]
	TIME [epoch: 6.45 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46245264247132856		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.46245264247132856 | validation: 0.49305819087775965]
	TIME [epoch: 6.45 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42710968821702044		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.42710968821702044 | validation: 0.7977040638947211]
	TIME [epoch: 6.45 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663412030165851		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.4663412030165851 | validation: 0.5327998494896824]
	TIME [epoch: 6.45 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136748942506567		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.5136748942506567 | validation: 0.3154410728670413]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021139555116484		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5021139555116484 | validation: 0.4255070875638481]
	TIME [epoch: 6.48 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40088838129102755		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.40088838129102755 | validation: 0.4725144533934723]
	TIME [epoch: 6.46 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36830558851239564		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.36830558851239564 | validation: 0.34239120328394607]
	TIME [epoch: 6.45 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36366419412977924		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.36366419412977924 | validation: 0.4117640898236564]
	TIME [epoch: 6.45 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329253810251215		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.5329253810251215 | validation: 0.49921454371046514]
	TIME [epoch: 6.45 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45530377240104175		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.45530377240104175 | validation: 0.8446169039298718]
	TIME [epoch: 6.45 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939360742489334		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.4939360742489334 | validation: 0.9946958575293866]
	TIME [epoch: 6.45 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140441447963875		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.6140441447963875 | validation: 0.51303832388403]
	TIME [epoch: 6.47 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3634755182629205		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.3634755182629205 | validation: 0.3785154037742284]
	TIME [epoch: 6.45 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28829624975822904		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.28829624975822904 | validation: 0.3851886924964393]
	TIME [epoch: 6.45 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3728844592912913		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.3728844592912913 | validation: 0.2916901745391825]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3570083230081956		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.3570083230081956 | validation: 0.3075278115826906]
	TIME [epoch: 6.44 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3074834125771556		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3074834125771556 | validation: 0.30899235962326543]
	TIME [epoch: 6.44 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910548515859324		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.2910548515859324 | validation: 0.3072740976155564]
	TIME [epoch: 6.47 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4203667928608572		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.4203667928608572 | validation: 0.47486510358650663]
	TIME [epoch: 6.45 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103689055076291		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.5103689055076291 | validation: 0.3098460023469901]
	TIME [epoch: 6.44 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3216596865896214		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3216596865896214 | validation: 0.3871074485353195]
	TIME [epoch: 6.44 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38358372272474717		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.38358372272474717 | validation: 0.36215614734996693]
	TIME [epoch: 6.44 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30826776960940644		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.30826776960940644 | validation: 0.44440222983394023]
	TIME [epoch: 6.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735556070980147		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3735556070980147 | validation: 0.33425648466912594]
	TIME [epoch: 6.45 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4231104379542266		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4231104379542266 | validation: 0.5094011959733008]
	TIME [epoch: 6.46 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4158059098987461		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.4158059098987461 | validation: 0.3307499987732733]
	TIME [epoch: 6.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4410795312763819		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.4410795312763819 | validation: 0.3569056819451241]
	TIME [epoch: 6.44 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23620574756232843		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.23620574756232843 | validation: 0.27688744821067013]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39017361024166775		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.39017361024166775 | validation: 0.3318347814606228]
	TIME [epoch: 6.43 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2705936142711586		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2705936142711586 | validation: 0.2915120774599091]
	TIME [epoch: 6.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47932068781153675		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.47932068781153675 | validation: 0.6493102155949879]
	TIME [epoch: 6.45 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44312247344051775		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.44312247344051775 | validation: 0.22742143999894357]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28221397479854093		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.28221397479854093 | validation: 0.33819060858577016]
	TIME [epoch: 6.44 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34849915816805477		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.34849915816805477 | validation: 0.27607178277878924]
	TIME [epoch: 6.44 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32105545418161385		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.32105545418161385 | validation: 0.2335727993261174]
	TIME [epoch: 6.44 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20815570428611463		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.20815570428611463 | validation: 0.2976053050636554]
	TIME [epoch: 6.44 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488163072847412		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3488163072847412 | validation: 0.2926306528714593]
	TIME [epoch: 6.44 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31068275736938455		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.31068275736938455 | validation: 0.21775125706169257]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18798922286728095		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.18798922286728095 | validation: 0.4041390775233353]
	TIME [epoch: 6.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028130067108439		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3028130067108439 | validation: 0.1814085280908872]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29816463442980895		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.29816463442980895 | validation: 0.5450318411736965]
	TIME [epoch: 6.44 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3842013544512743		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3842013544512743 | validation: 0.3566834120400759]
	TIME [epoch: 6.44 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140589243352688		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3140589243352688 | validation: 0.3744644578180152]
	TIME [epoch: 6.44 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758243998150558		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.2758243998150558 | validation: 0.40578988023531076]
	TIME [epoch: 6.46 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.322754410453806		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.322754410453806 | validation: 0.21729491395610545]
	TIME [epoch: 6.46 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573477692689868		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2573477692689868 | validation: 0.29782384480910756]
	TIME [epoch: 6.45 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771529349652044		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.2771529349652044 | validation: 0.21797385533525857]
	TIME [epoch: 6.45 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21734256037875094		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.21734256037875094 | validation: 0.16811524089784208]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25741688232197407		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.25741688232197407 | validation: 0.3387469716489339]
	TIME [epoch: 6.44 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946400768853768		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.2946400768853768 | validation: 0.20192413090277825]
	TIME [epoch: 6.44 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33312923687558993		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.33312923687558993 | validation: 0.31779251446984236]
	TIME [epoch: 6.47 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660704902782288		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.2660704902782288 | validation: 0.24460308700773287]
	TIME [epoch: 6.45 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25247393245740274		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.25247393245740274 | validation: 1.3675976033257453]
	TIME [epoch: 6.44 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6592977701753306		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6592977701753306 | validation: 0.3913355860342692]
	TIME [epoch: 6.44 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103609827651985		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3103609827651985 | validation: 0.21244505173577788]
	TIME [epoch: 6.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19605925860385082		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.19605925860385082 | validation: 0.3779531849947344]
	TIME [epoch: 6.45 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756651924969902		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2756651924969902 | validation: 0.22012700532560112]
	TIME [epoch: 6.45 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532856722787212		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.2532856722787212 | validation: 0.2998489141298641]
	TIME [epoch: 6.48 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244873380046424		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.244873380046424 | validation: 0.2846248795452337]
	TIME [epoch: 6.46 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35466077521934547		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.35466077521934547 | validation: 0.7606930979189375]
	TIME [epoch: 6.45 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4519750321020317		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.4519750321020317 | validation: 0.35846308302756924]
	TIME [epoch: 6.45 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669416134722514		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.2669416134722514 | validation: 0.21048481554192322]
	TIME [epoch: 6.45 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31606892143542453		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.31606892143542453 | validation: 0.3228233723272794]
	TIME [epoch: 6.45 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25600489316743036		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.25600489316743036 | validation: 0.2009167567909068]
	TIME [epoch: 6.47 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22907147754882018		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.22907147754882018 | validation: 0.36193585165962544]
	TIME [epoch: 6.48 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24315945996032923		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.24315945996032923 | validation: 0.277420279439132]
	TIME [epoch: 6.46 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25625869503698423		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.25625869503698423 | validation: 0.1622304350334972]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858168130107853		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2858168130107853 | validation: 0.19520505039595212]
	TIME [epoch: 6.45 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637639780006288		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.2637639780006288 | validation: 0.3279096053735836]
	TIME [epoch: 6.45 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851063282940933		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2851063282940933 | validation: 0.4489200199260225]
	TIME [epoch: 6.45 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35093117927828965		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.35093117927828965 | validation: 0.22088903975844582]
	TIME [epoch: 6.48 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.311295941299942		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.311295941299942 | validation: 0.1779186596675401]
	TIME [epoch: 6.46 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21622328383062522		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.21622328383062522 | validation: 0.41884729224932715]
	TIME [epoch: 6.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29786138007867863		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.29786138007867863 | validation: 0.21608770574799976]
	TIME [epoch: 6.45 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2969705059010929		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2969705059010929 | validation: 0.34008618660342554]
	TIME [epoch: 6.45 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28418805634364297		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.28418805634364297 | validation: 0.27349272991481915]
	TIME [epoch: 6.45 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24230308880357326		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.24230308880357326 | validation: 0.2384191819350653]
	TIME [epoch: 6.47 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29650841182443893		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.29650841182443893 | validation: 0.49427947983841175]
	TIME [epoch: 6.47 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22953654868118076		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.22953654868118076 | validation: 0.28384823623802435]
	TIME [epoch: 6.46 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38512440444775725		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.38512440444775725 | validation: 0.25194058009984277]
	TIME [epoch: 6.45 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18376492765392424		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.18376492765392424 | validation: 0.729944423092891]
	TIME [epoch: 6.45 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891805895718565		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2891805895718565 | validation: 0.27365516159662323]
	TIME [epoch: 6.45 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19580110646461135		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.19580110646461135 | validation: 0.4684300381595613]
	TIME [epoch: 6.45 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898600545810891		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2898600545810891 | validation: 0.16527496272744913]
	TIME [epoch: 6.48 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16300064476002885		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.16300064476002885 | validation: 0.2108749845339056]
	TIME [epoch: 6.47 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193325081883292		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.193325081883292 | validation: 0.15807344826909517]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922857155260537		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2922857155260537 | validation: 0.3890570297597424]
	TIME [epoch: 6.45 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2700953944896177		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.2700953944896177 | validation: 0.41352762528249076]
	TIME [epoch: 6.45 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33406827398612315		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.33406827398612315 | validation: 0.24293541154297452]
	TIME [epoch: 6.45 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24639343219584897		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.24639343219584897 | validation: 0.1727041120020343]
	TIME [epoch: 6.45 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693003637014415		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.3693003637014415 | validation: 0.5718215521038922]
	TIME [epoch: 6.49 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698447087146589		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.3698447087146589 | validation: 0.3386504633883726]
	TIME [epoch: 6.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22984202388965252		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.22984202388965252 | validation: 0.18135285971355777]
	TIME [epoch: 6.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22685930637754642		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.22685930637754642 | validation: 0.1514269846877438]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19812846336295248		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.19812846336295248 | validation: 0.1491495967234622]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15120581629307364		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.15120581629307364 | validation: 0.13117181014643756]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13487497863614928		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.13487497863614928 | validation: 0.17890805734788345]
	TIME [epoch: 6.48 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756548193941448		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.1756548193941448 | validation: 0.17310627154030309]
	TIME [epoch: 6.46 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15945909106442635		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.15945909106442635 | validation: 0.24318770607200826]
	TIME [epoch: 6.45 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193496185389281		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.193496185389281 | validation: 0.21844059973438107]
	TIME [epoch: 6.45 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064406004731045		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.20064406004731045 | validation: 0.2709995410486184]
	TIME [epoch: 6.45 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3199277218703844		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3199277218703844 | validation: 0.1282961294229214]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13530534905751815		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.13530534905751815 | validation: 0.11418111875950226]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23551543362168734		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.23551543362168734 | validation: 0.22343346888638527]
	TIME [epoch: 6.48 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2481991619463378		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2481991619463378 | validation: 0.2394670385491175]
	TIME [epoch: 6.45 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272797439307535		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.2272797439307535 | validation: 0.22233209160817713]
	TIME [epoch: 6.45 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840943209421273		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.840943209421273 | validation: 0.3009511519753417]
	TIME [epoch: 6.45 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21728625601740387		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.21728625601740387 | validation: 0.4116358468544335]
	TIME [epoch: 6.45 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25551853193209495		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.25551853193209495 | validation: 0.29146498545329835]
	TIME [epoch: 6.45 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23032016778592812		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.23032016778592812 | validation: 0.24793197374019205]
	TIME [epoch: 6.48 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1840435534463016		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1840435534463016 | validation: 0.25063789450433005]
	TIME [epoch: 6.46 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20572924586074454		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.20572924586074454 | validation: 0.1569435076701434]
	TIME [epoch: 6.45 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20822224682243606		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.20822224682243606 | validation: 0.2626584435648264]
	TIME [epoch: 6.45 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2690121719685911		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.2690121719685911 | validation: 0.23660625354458972]
	TIME [epoch: 6.45 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20230201922489074		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.20230201922489074 | validation: 0.22823533129166707]
	TIME [epoch: 6.45 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20652718603237036		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.20652718603237036 | validation: 0.169537299917816]
	TIME [epoch: 6.46 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939447254639306		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.1939447254639306 | validation: 0.20202523919945775]
	TIME [epoch: 6.48 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22868436969571615		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.22868436969571615 | validation: 0.2741426529491243]
	TIME [epoch: 6.46 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142752725712412		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.2142752725712412 | validation: 0.16113756027232604]
	TIME [epoch: 6.45 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2184348266029401		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2184348266029401 | validation: 0.13329866677536806]
	TIME [epoch: 6.45 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21997860032946268		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.21997860032946268 | validation: 0.1988052804198216]
	TIME [epoch: 6.45 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13429291446464986		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.13429291446464986 | validation: 0.10329840504873508]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17952103444572193		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.17952103444572193 | validation: 0.2898704954822434]
	TIME [epoch: 6.46 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20546722273066848		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.20546722273066848 | validation: 0.23376434204966579]
	TIME [epoch: 6.48 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19811367622214351		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.19811367622214351 | validation: 0.26807068965586434]
	TIME [epoch: 6.47 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17079849559611154		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17079849559611154 | validation: 0.2043775351966749]
	TIME [epoch: 6.46 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23601781520684867		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.23601781520684867 | validation: 0.1715885456604591]
	TIME [epoch: 6.47 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22564998667746		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.22564998667746 | validation: 0.24129298525218454]
	TIME [epoch: 6.47 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24269482475295714		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24269482475295714 | validation: 0.1589810312040593]
	TIME [epoch: 6.47 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729927821275001		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.2729927821275001 | validation: 0.22406791256169065]
	TIME [epoch: 6.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20937884268868984		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.20937884268868984 | validation: 0.239398029531419]
	TIME [epoch: 6.48 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15913755811694244		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.15913755811694244 | validation: 0.16138813765644763]
	TIME [epoch: 6.48 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13557873308761542		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.13557873308761542 | validation: 0.13069431866752848]
	TIME [epoch: 6.46 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13528914059334307		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.13528914059334307 | validation: 0.14104591208335598]
	TIME [epoch: 6.47 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22526868752184567		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.22526868752184567 | validation: 0.2296619354040867]
	TIME [epoch: 6.47 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14936451232837242		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.14936451232837242 | validation: 0.166695330972118]
	TIME [epoch: 6.49 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17854317242255652		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.17854317242255652 | validation: 0.3402786293650265]
	TIME [epoch: 6.49 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18347860852180842		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.18347860852180842 | validation: 0.07998336507975705]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26063096968635124		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.26063096968635124 | validation: 0.36168243554398544]
	TIME [epoch: 6.46 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22944931476768493		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.22944931476768493 | validation: 0.14688576160844335]
	TIME [epoch: 6.47 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18530956909986057		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.18530956909986057 | validation: 0.2849376671096413]
	TIME [epoch: 6.46 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191898274097649		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.2191898274097649 | validation: 0.12477021485428211]
	TIME [epoch: 6.46 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13223728573646354		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.13223728573646354 | validation: 0.10057695644957365]
	TIME [epoch: 6.49 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395480426791598		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.1395480426791598 | validation: 0.3196284837356863]
	TIME [epoch: 6.48 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033465956276535		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.2033465956276535 | validation: 0.16217056031822105]
	TIME [epoch: 6.46 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726893186634944		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.12726893186634944 | validation: 0.13443579188661625]
	TIME [epoch: 6.47 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17040406927786317		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.17040406927786317 | validation: 0.13802914062385693]
	TIME [epoch: 6.46 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17565626291970055		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.17565626291970055 | validation: 0.12298709128698238]
	TIME [epoch: 6.47 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22458030123292788		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.22458030123292788 | validation: 0.2535212206828406]
	TIME [epoch: 6.46 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663795154800036		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.1663795154800036 | validation: 0.10459242146826504]
	TIME [epoch: 6.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819288599698473		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.10819288599698473 | validation: 0.1319974346928645]
	TIME [epoch: 6.47 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473167642230593		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.1473167642230593 | validation: 0.14118271913660443]
	TIME [epoch: 6.47 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16429390996670837		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.16429390996670837 | validation: 0.15605833747346484]
	TIME [epoch: 6.48 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728168247340535		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.1728168247340535 | validation: 0.17125608070212728]
	TIME [epoch: 6.48 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558300907846223		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.12558300907846223 | validation: 0.22574759178005127]
	TIME [epoch: 6.47 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923259130636637		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.14923259130636637 | validation: 0.21269380391568352]
	TIME [epoch: 6.49 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24213667542878892		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.24213667542878892 | validation: 0.4468444148091383]
	TIME [epoch: 6.48 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211287760538657		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.3211287760538657 | validation: 0.10618188043989442]
	TIME [epoch: 6.47 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021923131902684		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.1021923131902684 | validation: 0.2221843882955087]
	TIME [epoch: 6.47 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951790174399735		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.11951790174399735 | validation: 0.09330199178569634]
	TIME [epoch: 6.48 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548497651123636		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1548497651123636 | validation: 0.11163650367523094]
	TIME [epoch: 6.46 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14979677703484337		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.14979677703484337 | validation: 0.0844730102397922]
	TIME [epoch: 6.47 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13307303741555965		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.13307303741555965 | validation: 0.2830095699548988]
	TIME [epoch: 6.51 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433030897367348		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.1433030897367348 | validation: 0.2332673613922163]
	TIME [epoch: 6.48 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13501629957581926		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.13501629957581926 | validation: 0.18129689318104714]
	TIME [epoch: 6.48 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239056885204404		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.14239056885204404 | validation: 0.14024573573538449]
	TIME [epoch: 6.48 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332799558501129		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.1332799558501129 | validation: 0.16904747404876083]
	TIME [epoch: 6.47 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17850466246885727		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.17850466246885727 | validation: 0.33646326319108416]
	TIME [epoch: 6.48 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3191344447737292		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.3191344447737292 | validation: 0.2535268247262322]
	TIME [epoch: 6.48 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15665223656978644		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.15665223656978644 | validation: 0.18273318976629885]
	TIME [epoch: 6.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21462723943712697		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.21462723943712697 | validation: 0.10635518752676636]
	TIME [epoch: 6.47 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16481910596009042		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.16481910596009042 | validation: 0.1019114974242325]
	TIME [epoch: 6.47 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09781033254026432		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.09781033254026432 | validation: 0.18123157423934522]
	TIME [epoch: 6.47 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107182765284628		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.1107182765284628 | validation: 0.10425619026021529]
	TIME [epoch: 6.48 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09858494565672203		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.09858494565672203 | validation: 0.2766079233764814]
	TIME [epoch: 6.47 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21248508508585306		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.21248508508585306 | validation: 0.4972646102003551]
	TIME [epoch: 6.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4443960960584882		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.4443960960584882 | validation: 0.4062600124707488]
	TIME [epoch: 6.48 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483576598555488		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.3483576598555488 | validation: 0.5545501185697126]
	TIME [epoch: 6.47 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3399800620021031		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.3399800620021031 | validation: 0.10194408466030808]
	TIME [epoch: 6.47 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12149676211539925		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.12149676211539925 | validation: 0.17769491932658263]
	TIME [epoch: 6.48 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380719747945721		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1380719747945721 | validation: 0.11905063476805326]
	TIME [epoch: 6.47 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15125560111874964		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.15125560111874964 | validation: 0.13056764172544083]
	TIME [epoch: 6.47 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080073929666608		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.12080073929666608 | validation: 0.14249514155535745]
	TIME [epoch: 6.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855804475020772		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.10855804475020772 | validation: 0.13244631456422906]
	TIME [epoch: 6.48 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391771989940974		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.11391771989940974 | validation: 0.13029722497081686]
	TIME [epoch: 6.47 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879160671835106		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.13879160671835106 | validation: 0.14754290171984807]
	TIME [epoch: 6.47 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17991075426883668		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.17991075426883668 | validation: 0.23375140257289118]
	TIME [epoch: 6.47 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13493414232677375		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.13493414232677375 | validation: 0.19280983886098157]
	TIME [epoch: 6.47 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15048900582402064		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.15048900582402064 | validation: 0.10578952899375396]
	TIME [epoch: 6.48 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12560048063887286		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.12560048063887286 | validation: 0.10885773929435823]
	TIME [epoch: 6.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004458197870478		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.13004458197870478 | validation: 0.09590718117240588]
	TIME [epoch: 6.47 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12682439444357024		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.12682439444357024 | validation: 0.29804134443306063]
	TIME [epoch: 6.48 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903823739126043		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.1903823739126043 | validation: 0.12383139258307527]
	TIME [epoch: 6.47 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11139447558617495		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.11139447558617495 | validation: 0.08483077182624105]
	TIME [epoch: 6.47 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190856954391495		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.12190856954391495 | validation: 0.23136640812690634]
	TIME [epoch: 6.48 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15189132075739714		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.15189132075739714 | validation: 0.11502633088858892]
	TIME [epoch: 6.51 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360242167192561		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.1360242167192561 | validation: 0.1297022167542337]
	TIME [epoch: 6.48 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16227083904237669		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.16227083904237669 | validation: 0.09686520457798992]
	TIME [epoch: 6.47 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15318547666374893		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.15318547666374893 | validation: 0.0971892884955411]
	TIME [epoch: 6.48 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202249232770787		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.09202249232770787 | validation: 0.10151122578943092]
	TIME [epoch: 6.46 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471718686141478		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1471718686141478 | validation: 0.21660626230797647]
	TIME [epoch: 6.48 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17597481976474436		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.17597481976474436 | validation: 0.16755948190776881]
	TIME [epoch: 6.47 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1167879502718283		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.1167879502718283 | validation: 0.07608602709662637]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15883957874287688		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.15883957874287688 | validation: 0.18017474448726842]
	TIME [epoch: 6.47 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17032745652171735		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.17032745652171735 | validation: 0.12017036428621125]
	TIME [epoch: 6.46 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14977211944778684		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.14977211944778684 | validation: 0.28095613993278035]
	TIME [epoch: 6.47 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15268077452369347		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.15268077452369347 | validation: 0.1185721423432085]
	TIME [epoch: 6.46 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12497689142159268		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.12497689142159268 | validation: 0.09867666801137653]
	TIME [epoch: 6.47 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470185116192584		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.1470185116192584 | validation: 0.07938942591097471]
	TIME [epoch: 6.48 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266720565372418		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.1266720565372418 | validation: 0.13897677058942345]
	TIME [epoch: 6.47 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10830985824867136		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.10830985824867136 | validation: 0.13625753208827462]
	TIME [epoch: 6.46 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14988822329040524		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.14988822329040524 | validation: 0.19584968276760328]
	TIME [epoch: 6.47 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13887940493046086		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.13887940493046086 | validation: 0.1014676924496596]
	TIME [epoch: 6.47 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13428475604284099		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.13428475604284099 | validation: 0.17973812821587778]
	TIME [epoch: 6.47 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272556948267171		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.1272556948267171 | validation: 0.14269099230961016]
	TIME [epoch: 6.47 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921045938961281		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.10921045938961281 | validation: 0.12786077026872256]
	TIME [epoch: 6.51 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15772671672920788		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.15772671672920788 | validation: 0.13736194863642415]
	TIME [epoch: 6.46 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08759120831375261		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.08759120831375261 | validation: 0.10279532585199079]
	TIME [epoch: 6.47 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341889994318663		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.11341889994318663 | validation: 0.10401077914512787]
	TIME [epoch: 6.46 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586267807081162		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.1586267807081162 | validation: 0.18392160941036195]
	TIME [epoch: 6.47 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037786329442517		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.14037786329442517 | validation: 0.08774818107117845]
	TIME [epoch: 6.46 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093262182488571		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.1093262182488571 | validation: 0.28124217057130035]
	TIME [epoch: 6.48 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14255751664601776		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.14255751664601776 | validation: 0.10682957381503372]
	TIME [epoch: 6.49 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09275401856495287		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.09275401856495287 | validation: 0.08052783646800694]
	TIME [epoch: 6.48 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09628616776628206		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.09628616776628206 | validation: 0.10690383441380323]
	TIME [epoch: 6.46 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427611398138677		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.12427611398138677 | validation: 0.0970268396912584]
	TIME [epoch: 6.46 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17580804478662865		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.17580804478662865 | validation: 0.21740879204051983]
	TIME [epoch: 6.47 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539832916480151		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.1539832916480151 | validation: 0.14717974232216643]
	TIME [epoch: 6.46 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715031886232252		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.11715031886232252 | validation: 0.18359529736418545]
	TIME [epoch: 6.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15986567544360897		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.15986567544360897 | validation: 0.11955049512197466]
	TIME [epoch: 6.48 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14227204921672337		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.14227204921672337 | validation: 0.09885263683524699]
	TIME [epoch: 6.47 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246185558598966		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.11246185558598966 | validation: 0.16848344136897817]
	TIME [epoch: 6.47 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1232102996339108		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.1232102996339108 | validation: 0.13177703398335436]
	TIME [epoch: 6.47 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674432452564225		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.10674432452564225 | validation: 0.14413828677313645]
	TIME [epoch: 6.47 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543562976302783		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.12543562976302783 | validation: 0.17379774350615843]
	TIME [epoch: 6.48 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411053272314728		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1411053272314728 | validation: 0.07588898742744418]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252614267822099		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1252614267822099 | validation: 0.2296596275373124]
	TIME [epoch: 6.47 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17357238114672136		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.17357238114672136 | validation: 0.20747933141777178]
	TIME [epoch: 6.45 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12357206290581826		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.12357206290581826 | validation: 0.17733088447520076]
	TIME [epoch: 6.47 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1222217089724236		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.1222217089724236 | validation: 0.10955384604044519]
	TIME [epoch: 6.46 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015888770169113		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.17015888770169113 | validation: 0.17528992410965338]
	TIME [epoch: 6.46 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269502383044184		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.1269502383044184 | validation: 0.11930722593798553]
	TIME [epoch: 6.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11543550577557422		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.11543550577557422 | validation: 0.13547994376782452]
	TIME [epoch: 6.48 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507263345508563		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.10507263345508563 | validation: 0.10456850312772664]
	TIME [epoch: 6.46 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617541233909942		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.08617541233909942 | validation: 0.17848287878411503]
	TIME [epoch: 6.46 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478444865284235		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.10478444865284235 | validation: 0.09003428656438364]
	TIME [epoch: 6.46 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212196226502463		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.11212196226502463 | validation: 0.0872891815061456]
	TIME [epoch: 6.46 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975120262096631		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.0975120262096631 | validation: 0.18955468276704002]
	TIME [epoch: 6.46 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12519315141132184		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.12519315141132184 | validation: 0.1506804355268925]
	TIME [epoch: 6.49 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252858595972364		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.09252858595972364 | validation: 0.08822606952178436]
	TIME [epoch: 6.46 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08958665065708453		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.08958665065708453 | validation: 0.10750873626257419]
	TIME [epoch: 6.47 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881103887219654		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.10881103887219654 | validation: 0.12555072198645795]
	TIME [epoch: 6.45 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252811407670179		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.1252811407670179 | validation: 0.09697898848054265]
	TIME [epoch: 6.46 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1082469268681094		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.1082469268681094 | validation: 0.1258932258494175]
	TIME [epoch: 6.46 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1185848897633132		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.1185848897633132 | validation: 0.10520899272490451]
	TIME [epoch: 6.47 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128564393127645		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1128564393127645 | validation: 0.0817223988549831]
	TIME [epoch: 6.49 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08686336040352073		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.08686336040352073 | validation: 0.1537543976232217]
	TIME [epoch: 6.47 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870209281682045		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.14870209281682045 | validation: 0.12682567368461936]
	TIME [epoch: 6.45 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384350127613		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.07384350127613 | validation: 0.09096732603029159]
	TIME [epoch: 6.46 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087330764785316		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.087330764785316 | validation: 0.12647143783202178]
	TIME [epoch: 6.46 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09315024956215436		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.09315024956215436 | validation: 0.10572653971283583]
	TIME [epoch: 6.48 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850049319716945		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.07850049319716945 | validation: 0.18441943948042266]
	TIME [epoch: 6.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854507854945179		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.10854507854945179 | validation: 0.11586201095584617]
	TIME [epoch: 6.47 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09404776746520796		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.09404776746520796 | validation: 0.23842436477415463]
	TIME [epoch: 6.46 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15613416118275875		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.15613416118275875 | validation: 0.1847658602367797]
	TIME [epoch: 6.46 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428632026209547		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1428632026209547 | validation: 0.14867257847087464]
	TIME [epoch: 6.46 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441181665216602		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.1441181665216602 | validation: 0.14083843600237128]
	TIME [epoch: 6.46 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1120557042622175		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.1120557042622175 | validation: 0.08930352939191137]
	TIME [epoch: 6.48 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08688958925614622		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.08688958925614622 | validation: 0.0902240165867343]
	TIME [epoch: 6.49 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07969755858007087		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.07969755858007087 | validation: 0.09431653855740191]
	TIME [epoch: 6.46 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13427080108182068		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.13427080108182068 | validation: 0.14167463515261594]
	TIME [epoch: 6.46 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629022640154142		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.09629022640154142 | validation: 0.08288472724158893]
	TIME [epoch: 6.47 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510301655611292		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.06510301655611292 | validation: 0.07761643712000217]
	TIME [epoch: 6.46 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383614824316055		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1383614824316055 | validation: 0.17808326388888482]
	TIME [epoch: 6.46 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005660515986723		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.14005660515986723 | validation: 0.127043720648986]
	TIME [epoch: 6.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09873806703027367		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.09873806703027367 | validation: 0.19629687944900553]
	TIME [epoch: 6.47 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186617448435217		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.13186617448435217 | validation: 0.08855274265961771]
	TIME [epoch: 6.46 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131961334258627		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.09131961334258627 | validation: 0.10557158953073761]
	TIME [epoch: 6.46 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11742330697186507		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.11742330697186507 | validation: 0.2006001778513342]
	TIME [epoch: 6.46 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14387667570286133		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.14387667570286133 | validation: 0.05539539820291564]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2254420764776902		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2254420764776902 | validation: 0.3161413505340006]
	TIME [epoch: 6.46 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20013538118103946		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.20013538118103946 | validation: 0.08793755318720167]
	TIME [epoch: 6.49 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08457945919272791		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.08457945919272791 | validation: 0.06080180239299377]
	TIME [epoch: 6.46 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07733192095635498		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.07733192095635498 | validation: 0.07919873585601928]
	TIME [epoch: 6.46 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09132246661298374		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.09132246661298374 | validation: 0.07586155310809191]
	TIME [epoch: 6.47 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634479918336044		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08634479918336044 | validation: 0.0710292530413119]
	TIME [epoch: 6.45 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09001970204369068		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.09001970204369068 | validation: 0.1613892810933127]
	TIME [epoch: 6.45 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07435966971428513		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.07435966971428513 | validation: 0.06439333380954025]
	TIME [epoch: 6.47 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018212543961652		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.1018212543961652 | validation: 0.18580337519946025]
	TIME [epoch: 6.49 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14652150328156197		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.14652150328156197 | validation: 0.08962020796329632]
	TIME [epoch: 6.46 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08129041957586385		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.08129041957586385 | validation: 0.08955737464614004]
	TIME [epoch: 6.45 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331668488290301		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.12331668488290301 | validation: 0.07944364163280558]
	TIME [epoch: 6.46 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0616192239857497		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.0616192239857497 | validation: 0.13178215034030608]
	TIME [epoch: 6.46 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15684445758295823		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.15684445758295823 | validation: 0.1349623605193021]
	TIME [epoch: 6.46 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369778163414953		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.1369778163414953 | validation: 0.13009653145195618]
	TIME [epoch: 6.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10929613208720407		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.10929613208720407 | validation: 0.13481305708152128]
	TIME [epoch: 6.48 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738838208366151		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.0738838208366151 | validation: 0.1334258504879503]
	TIME [epoch: 6.46 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265458037255916		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.1265458037255916 | validation: 0.11929986282278389]
	TIME [epoch: 6.46 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10297598118780175		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.10297598118780175 | validation: 0.09676552725766804]
	TIME [epoch: 6.46 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08016781900181852		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.08016781900181852 | validation: 0.09192918481946573]
	TIME [epoch: 6.46 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09456124638194058		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.09456124638194058 | validation: 0.110736678652145]
	TIME [epoch: 6.46 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281488101344853		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.08281488101344853 | validation: 0.08526130466404443]
	TIME [epoch: 6.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17808858930354404		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.17808858930354404 | validation: 0.25464948595835185]
	TIME [epoch: 6.46 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14779502214579765		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.14779502214579765 | validation: 0.0975931887965113]
	TIME [epoch: 6.46 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093341947720751		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.1093341947720751 | validation: 0.08218087901195993]
	TIME [epoch: 6.46 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11176005153523794		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.11176005153523794 | validation: 0.12912600281613507]
	TIME [epoch: 6.46 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478214390805094		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.09478214390805094 | validation: 0.13170865408600077]
	TIME [epoch: 6.46 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10208884208538273		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.10208884208538273 | validation: 0.06019263988643228]
	TIME [epoch: 6.49 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07804843719631147		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.07804843719631147 | validation: 0.1627986401193801]
	TIME [epoch: 6.47 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512398880600969		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.1512398880600969 | validation: 0.1076549662478536]
	TIME [epoch: 6.47 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189866235433348		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.11189866235433348 | validation: 0.1051975956673944]
	TIME [epoch: 6.46 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340534292365157		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.09340534292365157 | validation: 0.11651792242230462]
	TIME [epoch: 6.46 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731964360884688		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.0731964360884688 | validation: 0.1099905815412627]
	TIME [epoch: 6.46 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11587650028103136		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.11587650028103136 | validation: 0.054024891462239426]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742524154330218		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.04742524154330218 | validation: 0.08072195824126137]
	TIME [epoch: 6.51 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943229826311702		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.06943229826311702 | validation: 0.06623809820140499]
	TIME [epoch: 6.48 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832943078605497		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.08832943078605497 | validation: 0.046699750669522214]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05552465590218131		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.05552465590218131 | validation: 0.05670805865532633]
	TIME [epoch: 6.46 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06327119751317117		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.06327119751317117 | validation: 0.07455288582953476]
	TIME [epoch: 6.46 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18723335342121955		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.18723335342121955 | validation: 0.19976577998183687]
	TIME [epoch: 6.46 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506694242725667		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1506694242725667 | validation: 0.14814881821202522]
	TIME [epoch: 6.49 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09533147120300663		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.09533147120300663 | validation: 0.07478536066622744]
	TIME [epoch: 6.48 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253799088770696		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.07253799088770696 | validation: 0.08735708581517092]
	TIME [epoch: 6.47 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814153009552403		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.0814153009552403 | validation: 0.07495069603255772]
	TIME [epoch: 6.47 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502939729571976		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.09502939729571976 | validation: 0.08257464833890608]
	TIME [epoch: 6.47 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655086679418427		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.10655086679418427 | validation: 0.16967225112367387]
	TIME [epoch: 6.46 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15241275042209582		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.15241275042209582 | validation: 0.08427957507528439]
	TIME [epoch: 6.46 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05560485302645043		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.05560485302645043 | validation: 0.09190515762119741]
	TIME [epoch: 6.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09335546885269966		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.09335546885269966 | validation: 0.1006213399029917]
	TIME [epoch: 6.47 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09692739955926556		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.09692739955926556 | validation: 0.13677866968057675]
	TIME [epoch: 6.47 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010368653037249		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1010368653037249 | validation: 0.056368257591512795]
	TIME [epoch: 6.47 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056345908144732684		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.056345908144732684 | validation: 0.0482104317280006]
	TIME [epoch: 6.47 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062018060702561745		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.062018060702561745 | validation: 0.09421908040119263]
	TIME [epoch: 6.47 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619744584541933		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.07619744584541933 | validation: 0.08386891529126274]
	TIME [epoch: 6.48 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05504500034762507		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.05504500034762507 | validation: 0.11591762885654625]
	TIME [epoch: 6.49 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921603244451969		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.07921603244451969 | validation: 0.07486179223777552]
	TIME [epoch: 6.47 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11318813077643762		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.11318813077643762 | validation: 0.23686654543366323]
	TIME [epoch: 6.47 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13261630033713123		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.13261630033713123 | validation: 0.06577654801204114]
	TIME [epoch: 6.46 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719764685281811		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.0719764685281811 | validation: 0.07513353517986017]
	TIME [epoch: 6.47 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508712276187211		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.05508712276187211 | validation: 0.08429049402877402]
	TIME [epoch: 6.47 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05257288635455705		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.05257288635455705 | validation: 0.09618902392207115]
	TIME [epoch: 6.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022840805975122		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.07022840805975122 | validation: 0.08338580316578906]
	TIME [epoch: 6.48 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06631555949941735		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.06631555949941735 | validation: 0.0831420558537204]
	TIME [epoch: 6.47 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09572953674282605		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.09572953674282605 | validation: 0.08689937967463744]
	TIME [epoch: 6.47 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06939029020012431		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.06939029020012431 | validation: 0.10548006353918413]
	TIME [epoch: 6.47 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12648602852922147		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.12648602852922147 | validation: 0.17616604404501934]
	TIME [epoch: 6.47 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09279880477842689		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.09279880477842689 | validation: 0.0802800078901984]
	TIME [epoch: 6.47 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06622972553201661		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.06622972553201661 | validation: 0.14299525680711608]
	TIME [epoch: 6.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12067544171806616		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.12067544171806616 | validation: 0.1345691771680393]
	TIME [epoch: 6.47 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08294366982674856		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.08294366982674856 | validation: 0.09991808882798407]
	TIME [epoch: 6.47 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197179156079847		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08197179156079847 | validation: 0.1639713292576586]
	TIME [epoch: 6.47 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08398783276716532		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.08398783276716532 | validation: 0.07264638472940921]
	TIME [epoch: 6.47 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08794804287323635		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.08794804287323635 | validation: 0.11044437680304675]
	TIME [epoch: 6.46 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09209514347199024		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.09209514347199024 | validation: 0.07028623796632294]
	TIME [epoch: 6.47 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370750306513698		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.04370750306513698 | validation: 0.04620716479612611]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05806055270667827		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.05806055270667827 | validation: 0.07779670593373006]
	TIME [epoch: 6.45 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051154225517491846		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.051154225517491846 | validation: 0.09176292394203299]
	TIME [epoch: 6.45 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16179528718695166		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.16179528718695166 | validation: 0.186628314986978]
	TIME [epoch: 6.45 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046264939914632		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.08046264939914632 | validation: 0.09926929957040372]
	TIME [epoch: 6.45 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06782245254638404		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.06782245254638404 | validation: 0.04763649361843679]
	TIME [epoch: 6.45 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08172615317579655		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08172615317579655 | validation: 0.07391275267828283]
	TIME [epoch: 6.48 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05704503617775272		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.05704503617775272 | validation: 0.09432638965976288]
	TIME [epoch: 6.45 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04894992000373276		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.04894992000373276 | validation: 0.07163124454317124]
	TIME [epoch: 6.45 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06997781957368535		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.06997781957368535 | validation: 0.04570947733663445]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06081400887942008		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.06081400887942008 | validation: 0.12228694863945026]
	TIME [epoch: 6.45 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955996188851117		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08955996188851117 | validation: 0.060221669966491]
	TIME [epoch: 6.45 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869976492414327		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.0869976492414327 | validation: 0.1002754130206365]
	TIME [epoch: 6.47 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09054089423873668		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.09054089423873668 | validation: 0.13416706957211977]
	TIME [epoch: 6.48 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309070875695645		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.1309070875695645 | validation: 0.064066463567918]
	TIME [epoch: 6.45 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527467721768916		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.07527467721768916 | validation: 0.12468089744989005]
	TIME [epoch: 6.46 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0938774448300848		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.0938774448300848 | validation: 0.14269597862090785]
	TIME [epoch: 6.46 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10359657238070791		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.10359657238070791 | validation: 0.05005538654234869]
	TIME [epoch: 6.46 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832550270270055		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.05832550270270055 | validation: 0.10086519716485198]
	TIME [epoch: 6.46 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06835517565448353		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.06835517565448353 | validation: 0.05382867131397397]
	TIME [epoch: 6.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060271452498695484		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.060271452498695484 | validation: 0.05661162682774338]
	TIME [epoch: 6.47 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044856217395941145		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.044856217395941145 | validation: 0.06600949913005161]
	TIME [epoch: 6.47 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07179569934215119		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.07179569934215119 | validation: 0.0816911855496846]
	TIME [epoch: 6.47 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06454942914724099		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.06454942914724099 | validation: 0.0671634553055306]
	TIME [epoch: 6.48 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913686216974196		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.06913686216974196 | validation: 0.09864293887632906]
	TIME [epoch: 6.48 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06256334484589633		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.06256334484589633 | validation: 0.09015670471071886]
	TIME [epoch: 6.49 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08139621237783037		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08139621237783037 | validation: 0.16508233987074575]
	TIME [epoch: 6.52 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162498851256335		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.162498851256335 | validation: 0.1141517615828299]
	TIME [epoch: 6.49 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659663596237154		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.09659663596237154 | validation: 0.07847511164069097]
	TIME [epoch: 6.49 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07009257277332762		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.07009257277332762 | validation: 0.0660752706996443]
	TIME [epoch: 6.48 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06713191405509644		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.06713191405509644 | validation: 0.05907697128977692]
	TIME [epoch: 6.48 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05674519646293294		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.05674519646293294 | validation: 0.0596091965850651]
	TIME [epoch: 6.48 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038415130892541546		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.038415130892541546 | validation: 0.0627604696500203]
	TIME [epoch: 6.51 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0460306910639904		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.0460306910639904 | validation: 0.035586203840353055]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055755903730783235		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.055755903730783235 | validation: 0.08314748981389654]
	TIME [epoch: 6.48 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11735786675709683		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.11735786675709683 | validation: 0.17938588655866552]
	TIME [epoch: 6.47 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09520874345561757		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09520874345561757 | validation: 0.06863028499208298]
	TIME [epoch: 6.48 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042764739641139		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.07042764739641139 | validation: 0.08380671558134087]
	TIME [epoch: 6.47 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736018305043458		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.0736018305043458 | validation: 0.23441335962822696]
	TIME [epoch: 6.47 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15254864780085958		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.15254864780085958 | validation: 0.05253807143561897]
	TIME [epoch: 6.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02662820213913895		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.02662820213913895 | validation: 0.07681311627850694]
	TIME [epoch: 6.49 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05690832604426629		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.05690832604426629 | validation: 0.05955035307250761]
	TIME [epoch: 6.48 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04792688882797752		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.04792688882797752 | validation: 0.0770030620035363]
	TIME [epoch: 6.48 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06667475867081031		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.06667475867081031 | validation: 0.09101565600904801]
	TIME [epoch: 6.47 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318443815472243		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.08318443815472243 | validation: 0.1132208222668496]
	TIME [epoch: 6.47 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05118620921885075		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.05118620921885075 | validation: 0.048728161540939036]
	TIME [epoch: 6.49 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04261498369267143		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.04261498369267143 | validation: 0.0423442429222912]
	TIME [epoch: 6.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038799087133289716		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.038799087133289716 | validation: 0.0674621400191836]
	TIME [epoch: 6.48 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07412145282693021		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.07412145282693021 | validation: 0.11266412291499915]
	TIME [epoch: 6.48 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013499730101151		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.07013499730101151 | validation: 0.07590637105902268]
	TIME [epoch: 6.47 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05837074810417013		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.05837074810417013 | validation: 0.07015194200359894]
	TIME [epoch: 6.48 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739205881294742		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09739205881294742 | validation: 0.08920085149347047]
	TIME [epoch: 6.48 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644720493834208		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.0644720493834208 | validation: 0.09996786179163644]
	TIME [epoch: 6.51 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920083631634608		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.06920083631634608 | validation: 0.043061159854520775]
	TIME [epoch: 6.49 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04942810152867639		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.04942810152867639 | validation: 0.06572040053892955]
	TIME [epoch: 6.48 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476169285838956		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.06476169285838956 | validation: 0.07259172060992805]
	TIME [epoch: 6.47 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03761965076816798		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.03761965076816798 | validation: 0.0386873222197471]
	TIME [epoch: 6.48 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034398838197859244		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.034398838197859244 | validation: 0.06270399652384816]
	TIME [epoch: 6.48 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054100534377760606		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.054100534377760606 | validation: 0.055036936789096345]
	TIME [epoch: 6.48 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058603827024523276		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.058603827024523276 | validation: 0.05272680460357888]
	TIME [epoch: 6.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05604590648061647		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.05604590648061647 | validation: 0.03758039520204046]
	TIME [epoch: 6.48 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05439813658216628		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.05439813658216628 | validation: 0.05884107020968415]
	TIME [epoch: 6.48 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06399700032370947		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.06399700032370947 | validation: 0.05103000584339923]
	TIME [epoch: 6.48 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058130768487712176		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.058130768487712176 | validation: 0.08592962496901362]
	TIME [epoch: 6.48 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440413066503218		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.13440413066503218 | validation: 0.10575797317939163]
	TIME [epoch: 6.47 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07903891425514883		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.07903891425514883 | validation: 0.04821476431074801]
	TIME [epoch: 6.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06229557129395412		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.06229557129395412 | validation: 0.08190933641573139]
	TIME [epoch: 6.48 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755022335474495		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.13755022335474495 | validation: 0.06895177584647164]
	TIME [epoch: 6.46 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0573167545594839		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.0573167545594839 | validation: 0.04898254135662939]
	TIME [epoch: 6.47 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214791326473094		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.04214791326473094 | validation: 0.0865880986560325]
	TIME [epoch: 6.47 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056515341684085264		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.056515341684085264 | validation: 0.07386305969899765]
	TIME [epoch: 6.47 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0436339004575609		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.0436339004575609 | validation: 0.043648541106501786]
	TIME [epoch: 6.48 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834592080534763		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.03834592080534763 | validation: 0.0578028296723419]
	TIME [epoch: 6.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050946914497437205		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.050946914497437205 | validation: 0.04260226395995777]
	TIME [epoch: 6.47 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034995562551837334		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.034995562551837334 | validation: 0.0817176645726365]
	TIME [epoch: 6.47 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.071979203422071		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.071979203422071 | validation: 0.1151506427949882]
	TIME [epoch: 6.47 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06464260652501688		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.06464260652501688 | validation: 0.050545193864944694]
	TIME [epoch: 6.47 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033611175227361414		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.033611175227361414 | validation: 0.04441721648578751]
	TIME [epoch: 6.47 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034175546394034535		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.034175546394034535 | validation: 0.07426323048000087]
	TIME [epoch: 6.49 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530234044173707		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.04530234044173707 | validation: 0.03532001071700172]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05418774432892016		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.05418774432892016 | validation: 0.05803113373441469]
	TIME [epoch: 6.46 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777169228146133		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.0777169228146133 | validation: 0.09359718977782625]
	TIME [epoch: 6.46 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054283174971255434		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.054283174971255434 | validation: 0.06460171244344663]
	TIME [epoch: 6.46 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05163563157804095		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.05163563157804095 | validation: 0.04533095189162865]
	TIME [epoch: 6.46 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04491599307983167		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.04491599307983167 | validation: 0.07936949028978146]
	TIME [epoch: 6.47 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143039289761711		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.08143039289761711 | validation: 0.04592291902826783]
	TIME [epoch: 6.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044584135474977964		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.044584135474977964 | validation: 0.05918124074022453]
	TIME [epoch: 6.48 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864971519288803		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.08864971519288803 | validation: 0.11473446928480537]
	TIME [epoch: 6.46 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06723941548819148		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06723941548819148 | validation: 0.06315794375250394]
	TIME [epoch: 6.47 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054853080740607914		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.054853080740607914 | validation: 0.06183510344884683]
	TIME [epoch: 6.47 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06875111128916253		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.06875111128916253 | validation: 0.08418699278490889]
	TIME [epoch: 6.46 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06308042564592103		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.06308042564592103 | validation: 0.05354096910405277]
	TIME [epoch: 6.47 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578466274463093		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.05578466274463093 | validation: 0.05226654083555871]
	TIME [epoch: 6.49 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051420992574984815		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.051420992574984815 | validation: 0.04982792609987424]
	TIME [epoch: 6.47 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05757661587967107		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.05757661587967107 | validation: 0.07097232616653729]
	TIME [epoch: 6.46 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561632144193501		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.0561632144193501 | validation: 0.08136752219623246]
	TIME [epoch: 6.46 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718484245144388		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.05718484245144388 | validation: 0.044062739979273104]
	TIME [epoch: 6.46 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261341907044051		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1261341907044051 | validation: 0.07946772633152882]
	TIME [epoch: 6.47 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254986478108857		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.05254986478108857 | validation: 0.07035697467264045]
	TIME [epoch: 6.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05789117223442426		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.05789117223442426 | validation: 0.08194973937138034]
	TIME [epoch: 6.49 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725887696019046		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.0725887696019046 | validation: 0.07750711844332867]
	TIME [epoch: 6.46 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318429657892839		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.04318429657892839 | validation: 0.061974824048821056]
	TIME [epoch: 6.46 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051446681442578704		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.051446681442578704 | validation: 0.05233481783636932]
	TIME [epoch: 6.46 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04365290331337136		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.04365290331337136 | validation: 0.06700443029764878]
	TIME [epoch: 6.47 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042997084253968046		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.042997084253968046 | validation: 0.056351599717388234]
	TIME [epoch: 6.47 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839362068486322		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.04839362068486322 | validation: 0.08963126855826463]
	TIME [epoch: 6.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05694147178497831		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.05694147178497831 | validation: 0.038898917905967584]
	TIME [epoch: 6.47 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04558740891463354		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.04558740891463354 | validation: 0.10966923497996547]
	TIME [epoch: 6.47 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07331638481346509		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.07331638481346509 | validation: 0.06912401069680173]
	TIME [epoch: 6.46 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538360050823208		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.0538360050823208 | validation: 0.05251662620414761]
	TIME [epoch: 6.46 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06360105575854416		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.06360105575854416 | validation: 0.05983488750319665]
	TIME [epoch: 6.47 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425476488769991		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.07425476488769991 | validation: 0.09923851516874287]
	TIME [epoch: 6.47 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05582335745364614		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.05582335745364614 | validation: 0.04510341634691189]
	TIME [epoch: 6.49 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03206528468028913		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.03206528468028913 | validation: 0.04488099579082706]
	TIME [epoch: 6.47 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056493405296996965		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.056493405296996965 | validation: 0.0457426071995609]
	TIME [epoch: 6.46 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03432558056875444		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.03432558056875444 | validation: 0.06456910881516026]
	TIME [epoch: 6.47 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05234699811745177		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.05234699811745177 | validation: 0.06058361644307093]
	TIME [epoch: 6.46 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04556760424987385		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.04556760424987385 | validation: 0.07623732216496536]
	TIME [epoch: 6.46 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236107321915861		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.09236107321915861 | validation: 0.0842312628494014]
	TIME [epoch: 6.51 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059613654271042774		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.059613654271042774 | validation: 0.04010060784502493]
	TIME [epoch: 6.47 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030311725773855158		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.030311725773855158 | validation: 0.049931518040207304]
	TIME [epoch: 6.47 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473737439320541		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.03473737439320541 | validation: 0.052918284229890436]
	TIME [epoch: 6.46 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922183606092499		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.04922183606092499 | validation: 0.05112629413708218]
	TIME [epoch: 6.47 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057515672825651114		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.057515672825651114 | validation: 0.07543692899290132]
	TIME [epoch: 6.47 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051315282869021046		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.051315282869021046 | validation: 0.08439844148284928]
	TIME [epoch: 6.47 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05563339525999636		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.05563339525999636 | validation: 0.05048511209607492]
	TIME [epoch: 6.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661812414420885		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.03661812414420885 | validation: 0.05671413248415298]
	TIME [epoch: 6.47 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062235684272591546		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.062235684272591546 | validation: 0.0759394637131221]
	TIME [epoch: 6.47 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038372608433838364		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.038372608433838364 | validation: 0.04786451537343377]
	TIME [epoch: 6.46 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03518955768730229		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.03518955768730229 | validation: 0.041037541486096646]
	TIME [epoch: 6.46 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795022797436101		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.03795022797436101 | validation: 0.03808333903301886]
	TIME [epoch: 6.46 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039775409834170425		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.039775409834170425 | validation: 0.043437951811434276]
	TIME [epoch: 6.49 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672030467882148		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.04672030467882148 | validation: 0.05758109645823402]
	TIME [epoch: 6.48 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032115091085153036		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.032115091085153036 | validation: 0.04386351168530423]
	TIME [epoch: 6.47 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03285680257064802		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.03285680257064802 | validation: 0.0595170864095121]
	TIME [epoch: 6.47 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0366238030130069		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.0366238030130069 | validation: 0.05337608132850867]
	TIME [epoch: 6.47 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041251192339668924		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.041251192339668924 | validation: 0.04180134161492353]
	TIME [epoch: 6.47 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02801327363387209		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.02801327363387209 | validation: 0.037899774296637274]
	TIME [epoch: 6.47 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923989396940192		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.03923989396940192 | validation: 0.03986923311988993]
	TIME [epoch: 6.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047752349355965645		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.047752349355965645 | validation: 0.1082553305625295]
	TIME [epoch: 6.48 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791964704466788		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.08791964704466788 | validation: 0.0684337662495747]
	TIME [epoch: 6.47 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06269536278463739		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.06269536278463739 | validation: 0.09721287739897255]
	TIME [epoch: 6.47 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512695623464123		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.05512695623464123 | validation: 0.04012262618260505]
	TIME [epoch: 6.46 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827607965131174		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.04827607965131174 | validation: 0.04643982748720582]
	TIME [epoch: 6.47 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05003346203564652		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.05003346203564652 | validation: 0.04321775113574129]
	TIME [epoch: 6.47 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036959562377516714		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.036959562377516714 | validation: 0.043283632267116436]
	TIME [epoch: 6.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030897280201409555		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.030897280201409555 | validation: 0.04614058527170755]
	TIME [epoch: 6.46 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05128922913532263		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.05128922913532263 | validation: 0.06370658956936984]
	TIME [epoch: 6.49 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941593274817744		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.06941593274817744 | validation: 0.05311169296926838]
	TIME [epoch: 6.46 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997907866721935		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.04997907866721935 | validation: 0.047156580068407575]
	TIME [epoch: 6.46 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04904818506957266		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.04904818506957266 | validation: 0.058158676618266326]
	TIME [epoch: 6.46 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637703033935253		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0637703033935253 | validation: 0.051420424105619596]
	TIME [epoch: 6.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06509839475235571		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.06509839475235571 | validation: 0.06027980169245895]
	TIME [epoch: 6.47 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035725241503724435		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.035725241503724435 | validation: 0.0407630259747207]
	TIME [epoch: 6.47 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031240259984314907		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.031240259984314907 | validation: 0.06457629685310995]
	TIME [epoch: 6.46 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04097175922845436		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.04097175922845436 | validation: 0.04045453560693664]
	TIME [epoch: 6.47 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525568254636151		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.03525568254636151 | validation: 0.07264617911385125]
	TIME [epoch: 6.46 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05354362956099023		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.05354362956099023 | validation: 0.05940255719170409]
	TIME [epoch: 6.48 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05606443164244751		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.05606443164244751 | validation: 0.05120643641044547]
	TIME [epoch: 6.49 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394519345682573		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.04394519345682573 | validation: 0.060445469854894435]
	TIME [epoch: 6.46 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612128579538355		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.06612128579538355 | validation: 0.06015757080441755]
	TIME [epoch: 6.47 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045752808147857565		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.045752808147857565 | validation: 0.05345183106399344]
	TIME [epoch: 6.47 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0491762594686256		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.0491762594686256 | validation: 0.05374893637094923]
	TIME [epoch: 6.46 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040052458811959804		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.040052458811959804 | validation: 0.05298523132148281]
	TIME [epoch: 6.47 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041259123858987515		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.041259123858987515 | validation: 0.09346547119517312]
	TIME [epoch: 6.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918657368919027		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.07918657368919027 | validation: 0.062469240650449044]
	TIME [epoch: 6.48 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756086508542976		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.04756086508542976 | validation: 0.05597660657301631]
	TIME [epoch: 6.47 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869383120224938		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.04869383120224938 | validation: 0.040486701494778565]
	TIME [epoch: 6.46 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034342919897806724		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.034342919897806724 | validation: 0.0345494227265925]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03941143362177305		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.03941143362177305 | validation: 0.06314039112905576]
	TIME [epoch: 6.46 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06243097025357304		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.06243097025357304 | validation: 0.045272998939409115]
	TIME [epoch: 6.46 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055264936710779755		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.055264936710779755 | validation: 0.055893554011612584]
	TIME [epoch: 6.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330527491320395		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.06330527491320395 | validation: 0.07479369598559663]
	TIME [epoch: 6.47 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06779340585071002		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.06779340585071002 | validation: 0.055088445115176174]
	TIME [epoch: 6.46 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05393174043253459		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.05393174043253459 | validation: 0.07012034236309467]
	TIME [epoch: 6.46 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06364540866189831		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.06364540866189831 | validation: 0.05051914873832544]
	TIME [epoch: 6.46 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030201521855215643		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.030201521855215643 | validation: 0.05777856650798672]
	TIME [epoch: 6.46 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056551609235697325		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.056551609235697325 | validation: 0.05702202603629686]
	TIME [epoch: 6.48 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07170069160128195		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.07170069160128195 | validation: 0.12059089463876785]
	TIME [epoch: 6.49 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943107112165218		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08943107112165218 | validation: 0.05206736510578065]
	TIME [epoch: 6.47 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090565287346028		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.03090565287346028 | validation: 0.03309441213305992]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257769415436714		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.03257769415436714 | validation: 0.04913517315016593]
	TIME [epoch: 6.46 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531252459086153		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.03531252459086153 | validation: 0.05208193170560682]
	TIME [epoch: 6.46 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045131977523622455		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.045131977523622455 | validation: 0.052109028009891326]
	TIME [epoch: 6.46 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445798301563431		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.0445798301563431 | validation: 0.0390207015330348]
	TIME [epoch: 6.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03708920342762658		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.03708920342762658 | validation: 0.05989804520089814]
	TIME [epoch: 6.47 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05641305047831614		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.05641305047831614 | validation: 0.06583478812883646]
	TIME [epoch: 6.47 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06526418783804537		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.06526418783804537 | validation: 0.06722552454068292]
	TIME [epoch: 6.47 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05914330381645359		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.05914330381645359 | validation: 0.05251623471207234]
	TIME [epoch: 6.47 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042448955493264294		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.042448955493264294 | validation: 0.049417136017282905]
	TIME [epoch: 6.47 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642307459130928		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.03642307459130928 | validation: 0.03425647551252096]
	TIME [epoch: 6.48 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039068739949353115		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.039068739949353115 | validation: 0.03683642951227253]
	TIME [epoch: 6.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025348996008726143		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.025348996008726143 | validation: 0.0362621799035986]
	TIME [epoch: 6.48 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042830398498471214		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.042830398498471214 | validation: 0.048970738987422574]
	TIME [epoch: 6.47 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344663348597168		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.05344663348597168 | validation: 0.07375319680629215]
	TIME [epoch: 6.47 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667097493591566		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0667097493591566 | validation: 0.07537066746322342]
	TIME [epoch: 6.47 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05809560874672827		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.05809560874672827 | validation: 0.046750126135775]
	TIME [epoch: 6.47 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038688423215863375		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.038688423215863375 | validation: 0.0734540617997022]
	TIME [epoch: 6.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058956710334886614		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.058956710334886614 | validation: 0.09345825290050887]
	TIME [epoch: 6.48 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148929832122123		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.08148929832122123 | validation: 0.07588612330938091]
	TIME [epoch: 6.47 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054429252429129577		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.054429252429129577 | validation: 0.0401469173651255]
	TIME [epoch: 6.47 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033905985550471064		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.033905985550471064 | validation: 0.04220629482042382]
	TIME [epoch: 6.46 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028350791620119147		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.028350791620119147 | validation: 0.03760570599873548]
	TIME [epoch: 6.47 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030217092452571606		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.030217092452571606 | validation: 0.05779499545544176]
	TIME [epoch: 6.46 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04037511255313092		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.04037511255313092 | validation: 0.034403398525329795]
	TIME [epoch: 6.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052198446177845		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.03052198446177845 | validation: 0.04751165787808416]
	TIME [epoch: 6.46 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779588047435336		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.03779588047435336 | validation: 0.06227765593082671]
	TIME [epoch: 6.48 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382056703682182		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.06382056703682182 | validation: 0.08773828279095447]
	TIME [epoch: 6.47 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058122078684913		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.07058122078684913 | validation: 0.06346054898531056]
	TIME [epoch: 6.48 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046660066108850144		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.046660066108850144 | validation: 0.048464057788712565]
	TIME [epoch: 6.47 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587135310166862		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.03587135310166862 | validation: 0.04420984069950574]
	TIME [epoch: 6.49 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034790297797721956		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.034790297797721956 | validation: 0.04573678341180303]
	TIME [epoch: 6.49 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583847833539834		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.03583847833539834 | validation: 0.05044309725588912]
	TIME [epoch: 6.47 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06524831653443067		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.06524831653443067 | validation: 0.0976223659604705]
	TIME [epoch: 6.48 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09253276609099383		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.09253276609099383 | validation: 0.12449918856405688]
	TIME [epoch: 6.47 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204968869206629		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.10204968869206629 | validation: 0.10342119591855888]
	TIME [epoch: 6.48 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08717960986055355		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.08717960986055355 | validation: 0.0851674245794353]
	TIME [epoch: 6.47 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07451026833642714		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07451026833642714 | validation: 0.08786016127758516]
	TIME [epoch: 6.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06157100816739403		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.06157100816739403 | validation: 0.05124421090746912]
	TIME [epoch: 6.47 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06393616870635141		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.06393616870635141 | validation: 0.0707145319468534]
	TIME [epoch: 6.47 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04971562380493448		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.04971562380493448 | validation: 0.0912295365183376]
	TIME [epoch: 6.47 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06591879353202656		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06591879353202656 | validation: 0.07418534047077394]
	TIME [epoch: 6.46 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540160700932886		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.0540160700932886 | validation: 0.04977930481976697]
	TIME [epoch: 6.47 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034248284461345306		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.034248284461345306 | validation: 0.04917584560531862]
	TIME [epoch: 6.49 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420846021802693		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0420846021802693 | validation: 0.051759962730052476]
	TIME [epoch: 6.49 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04036536604163418		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.04036536604163418 | validation: 0.03543338220608459]
	TIME [epoch: 6.47 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142964581250401		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.03142964581250401 | validation: 0.07351675190234783]
	TIME [epoch: 6.47 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0548745725841758		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0548745725841758 | validation: 0.06107450905669508]
	TIME [epoch: 6.47 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03893935168291795		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.03893935168291795 | validation: 0.03260251423553627]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05325355712990163		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.05325355712990163 | validation: 0.09679849222164125]
	TIME [epoch: 6.47 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959019418867804		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.06959019418867804 | validation: 0.06146161697606978]
	TIME [epoch: 6.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06775766044866112		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.06775766044866112 | validation: 0.063413088169522]
	TIME [epoch: 6.48 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049389626467816916		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.049389626467816916 | validation: 0.07512410603619361]
	TIME [epoch: 6.47 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04054536450320864		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.04054536450320864 | validation: 0.04119316323404238]
	TIME [epoch: 6.46 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036572688108755656		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.036572688108755656 | validation: 0.04766973467711841]
	TIME [epoch: 6.46 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03522699937826664		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.03522699937826664 | validation: 0.05378791121781992]
	TIME [epoch: 6.46 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044832157988754055		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.044832157988754055 | validation: 0.06872572394572567]
	TIME [epoch: 6.48 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051326008496010524		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.051326008496010524 | validation: 0.07974666067568353]
	TIME [epoch: 6.49 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05202244777342304		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.05202244777342304 | validation: 0.046523814106928366]
	TIME [epoch: 6.47 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04020706701918712		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.04020706701918712 | validation: 0.04734401391701628]
	TIME [epoch: 6.49 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257188490624798		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.03257188490624798 | validation: 0.03524084722775607]
	TIME [epoch: 6.48 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023379554300032992		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.023379554300032992 | validation: 0.04385903688956191]
	TIME [epoch: 6.46 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05315170619799946		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.05315170619799946 | validation: 0.07971311843507234]
	TIME [epoch: 6.48 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05237082805895646		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.05237082805895646 | validation: 0.035265448565520975]
	TIME [epoch: 6.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029634472252895762		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.029634472252895762 | validation: 0.04210736352186424]
	TIME [epoch: 6.48 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767250629668564		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.04767250629668564 | validation: 0.04746503575130376]
	TIME [epoch: 6.47 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03651327794501881		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.03651327794501881 | validation: 0.0562908545302771]
	TIME [epoch: 6.47 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430115107366385		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06430115107366385 | validation: 0.054694035926132686]
	TIME [epoch: 6.46 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485203713113004		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.03485203713113004 | validation: 0.03981125168782274]
	TIME [epoch: 6.47 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028367347951239432		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.028367347951239432 | validation: 0.03980325421709662]
	TIME [epoch: 6.47 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02944782497234958		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.02944782497234958 | validation: 0.045965105023235746]
	TIME [epoch: 6.51 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142689225524543		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.03142689225524543 | validation: 0.05897610703684965]
	TIME [epoch: 6.47 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05389383080900031		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.05389383080900031 | validation: 0.049668469399690385]
	TIME [epoch: 6.47 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04199580660167046		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.04199580660167046 | validation: 0.06801914109247915]
	TIME [epoch: 6.48 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0474437340660093		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0474437340660093 | validation: 0.0459923755841679]
	TIME [epoch: 6.47 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026588822596263748		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.026588822596263748 | validation: 0.043323321171370666]
	TIME [epoch: 6.47 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531187945764336		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.03531187945764336 | validation: 0.044244704884851986]
	TIME [epoch: 6.48 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032794457384777306		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.032794457384777306 | validation: 0.042448918632915084]
	TIME [epoch: 6.49 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042853588770223404		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.042853588770223404 | validation: 0.04066640189578306]
	TIME [epoch: 6.47 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029932454424098653		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.029932454424098653 | validation: 0.030237995025924305]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023690219059805173		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.023690219059805173 | validation: 0.032049289899267475]
	TIME [epoch: 6.47 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02987471180395541		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.02987471180395541 | validation: 0.06873448536663093]
	TIME [epoch: 6.49 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0629623236025289		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.0629623236025289 | validation: 0.074673133797089]
	TIME [epoch: 6.48 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0374277871741098		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0374277871741098 | validation: 0.025415615340287436]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_722.pth
	Model improved!!!
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026744794552067		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.026744794552067 | validation: 0.04546227693673714]
	TIME [epoch: 6.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0349858017714736		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.0349858017714736 | validation: 0.052535874916877015]
	TIME [epoch: 6.49 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033510061983414566		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.033510061983414566 | validation: 0.04089713394319791]
	TIME [epoch: 6.48 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543490053323517		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.03543490053323517 | validation: 0.03568034375791054]
	TIME [epoch: 6.48 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028982377917718967		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.028982377917718967 | validation: 0.04479248161119026]
	TIME [epoch: 6.48 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293316495609766		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.03293316495609766 | validation: 0.04818780898612679]
	TIME [epoch: 6.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112956908374085		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.04112956908374085 | validation: 0.04797820912059363]
	TIME [epoch: 6.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044374118882693755		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.044374118882693755 | validation: 0.06533043159520995]
	TIME [epoch: 6.48 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06702667817102323		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.06702667817102323 | validation: 0.06347089413973313]
	TIME [epoch: 6.48 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04965817094822112		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.04965817094822112 | validation: 0.04952675337706284]
	TIME [epoch: 6.48 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035872054437985135		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.035872054437985135 | validation: 0.06396798890575928]
	TIME [epoch: 6.49 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03872074297944296		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.03872074297944296 | validation: 0.049382438233744275]
	TIME [epoch: 6.48 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029240000170495304		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.029240000170495304 | validation: 0.04708117187807979]
	TIME [epoch: 6.52 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027196996863331054		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.027196996863331054 | validation: 0.03951834580797715]
	TIME [epoch: 6.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391387124254112		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.03391387124254112 | validation: 0.04743059144357867]
	TIME [epoch: 6.48 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03688556587416576		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.03688556587416576 | validation: 0.045649526299769365]
	TIME [epoch: 6.48 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029788659912354493		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.029788659912354493 | validation: 0.05254207254032173]
	TIME [epoch: 6.48 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03446734983539455		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.03446734983539455 | validation: 0.06767379843683907]
	TIME [epoch: 6.48 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032088637809299256		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.032088637809299256 | validation: 0.046677512404450616]
	TIME [epoch: 6.49 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041274890933940246		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.041274890933940246 | validation: 0.0608528297820161]
	TIME [epoch: 6.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042368008857412834		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.042368008857412834 | validation: 0.05195875115118405]
	TIME [epoch: 6.49 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032268162649371844		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.032268162649371844 | validation: 0.043411522443929054]
	TIME [epoch: 6.49 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104624757572029		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.04104624757572029 | validation: 0.0483857409629559]
	TIME [epoch: 6.48 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048818491448460656		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.048818491448460656 | validation: 0.060766532017923966]
	TIME [epoch: 6.48 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045049031804683795		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.045049031804683795 | validation: 0.04286125360631978]
	TIME [epoch: 6.48 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0299220261775714		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0299220261775714 | validation: 0.037887199678001915]
	TIME [epoch: 6.51 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253857724207859		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.03253857724207859 | validation: 0.040704931772297136]
	TIME [epoch: 6.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027129289424615993		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.027129289424615993 | validation: 0.07652359338791825]
	TIME [epoch: 6.49 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04199113023574155		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.04199113023574155 | validation: 0.07068166535371082]
	TIME [epoch: 6.48 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03498122355274353		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.03498122355274353 | validation: 0.035191359560118866]
	TIME [epoch: 6.49 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038151085576027345		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.038151085576027345 | validation: 0.04645570547362666]
	TIME [epoch: 6.48 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04475283912566466		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.04475283912566466 | validation: 0.04393711929357856]
	TIME [epoch: 6.48 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041924743981747004		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.041924743981747004 | validation: 0.0708782350925895]
	TIME [epoch: 6.51 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037587311538899		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.037587311538899 | validation: 0.046550058078731284]
	TIME [epoch: 6.47 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025821628558533642		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.025821628558533642 | validation: 0.03251663825292175]
	TIME [epoch: 6.46 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409229333355828		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.02409229333355828 | validation: 0.053498467451616384]
	TIME [epoch: 6.46 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576449010420439		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.04576449010420439 | validation: 0.047171431454599906]
	TIME [epoch: 6.46 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03944735776693248		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.03944735776693248 | validation: 0.05408650145478447]
	TIME [epoch: 6.47 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036923457910088914		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.036923457910088914 | validation: 0.04922420404176428]
	TIME [epoch: 6.48 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041693223985685854		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.041693223985685854 | validation: 0.038526185491123494]
	TIME [epoch: 6.49 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326314745767994		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0326314745767994 | validation: 0.047204240049673184]
	TIME [epoch: 6.47 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483416568443773		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.03483416568443773 | validation: 0.04273440891718837]
	TIME [epoch: 6.47 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037918123473073745		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.037918123473073745 | validation: 0.04312096178386641]
	TIME [epoch: 6.46 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531915376498697		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.03531915376498697 | validation: 0.04290086227602687]
	TIME [epoch: 6.47 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378528806473302		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0378528806473302 | validation: 0.05596722051850185]
	TIME [epoch: 6.46 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058679293695857795		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.058679293695857795 | validation: 0.06642853559275883]
	TIME [epoch: 6.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058132184794479555		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.058132184794479555 | validation: 0.04972480494848225]
	TIME [epoch: 6.47 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412019994682438		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.03412019994682438 | validation: 0.044534758549456085]
	TIME [epoch: 6.47 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03320607581396865		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.03320607581396865 | validation: 0.03389156687322366]
	TIME [epoch: 6.47 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041651685021770024		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.041651685021770024 | validation: 0.0577118304969132]
	TIME [epoch: 6.47 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034012710658565544		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.034012710658565544 | validation: 0.04371849824462652]
	TIME [epoch: 6.47 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03418305804099016		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.03418305804099016 | validation: 0.05070036142340646]
	TIME [epoch: 6.49 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04702112135899229		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.04702112135899229 | validation: 0.0581248660155106]
	TIME [epoch: 6.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038290789809785813		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.038290789809785813 | validation: 0.0512789713373568]
	TIME [epoch: 6.48 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385682712384034		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.04385682712384034 | validation: 0.07660763002120169]
	TIME [epoch: 6.47 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816974758277405		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.04816974758277405 | validation: 0.06305159661620409]
	TIME [epoch: 6.47 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06392274739855533		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.06392274739855533 | validation: 0.036458104465520766]
	TIME [epoch: 6.48 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542141179729879		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.02542141179729879 | validation: 0.034849044442244]
	TIME [epoch: 6.48 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02835336392479458		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.02835336392479458 | validation: 0.05784753993584072]
	TIME [epoch: 6.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05421730109903707		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.05421730109903707 | validation: 0.048098916936883444]
	TIME [epoch: 6.49 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05386599654225256		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.05386599654225256 | validation: 0.05520181252636542]
	TIME [epoch: 6.48 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03866408627530633		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.03866408627530633 | validation: 0.03539468009943817]
	TIME [epoch: 6.48 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023672424741777123		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.023672424741777123 | validation: 0.024348452037402407]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023718905185914962		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.023718905185914962 | validation: 0.03030481274990454]
	TIME [epoch: 6.47 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018116557451992633		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.018116557451992633 | validation: 0.026122010553725178]
	TIME [epoch: 6.47 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026470136540235948		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.026470136540235948 | validation: 0.028857854138363188]
	TIME [epoch: 6.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028238305418064977		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.028238305418064977 | validation: 0.0423911084028238]
	TIME [epoch: 6.47 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036069156893798894		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.036069156893798894 | validation: 0.05804467898766124]
	TIME [epoch: 6.47 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04957744277501495		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04957744277501495 | validation: 0.04535944430192044]
	TIME [epoch: 6.47 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036666162282711405		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.036666162282711405 | validation: 0.03531141904033895]
	TIME [epoch: 6.48 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01940363315546815		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.01940363315546815 | validation: 0.0346638951259338]
	TIME [epoch: 6.47 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02469852802844061		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.02469852802844061 | validation: 0.03810665005867753]
	TIME [epoch: 6.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031320970962774065		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.031320970962774065 | validation: 0.04286313368196357]
	TIME [epoch: 6.47 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02673113301658908		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.02673113301658908 | validation: 0.03422355122479062]
	TIME [epoch: 6.47 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031965078337123434		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.031965078337123434 | validation: 0.03519190720275794]
	TIME [epoch: 6.47 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030723520605769536		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.030723520605769536 | validation: 0.03713526904598256]
	TIME [epoch: 6.48 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02627024332981631		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.02627024332981631 | validation: 0.03241062088215738]
	TIME [epoch: 6.47 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02270417460736987		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.02270417460736987 | validation: 0.029231630765395568]
	TIME [epoch: 6.46 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02519412509085392		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.02519412509085392 | validation: 0.042079494137030105]
	TIME [epoch: 6.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03590981196953823		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.03590981196953823 | validation: 0.037139686091969895]
	TIME [epoch: 6.48 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04428173104698489		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.04428173104698489 | validation: 0.04746977996971815]
	TIME [epoch: 6.48 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04825381152613717		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.04825381152613717 | validation: 0.07413337138726526]
	TIME [epoch: 6.47 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164811587229977		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.04164811587229977 | validation: 0.02700927341354482]
	TIME [epoch: 6.47 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02594110860822251		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.02594110860822251 | validation: 0.035723898561225174]
	TIME [epoch: 6.47 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03195526224621986		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.03195526224621986 | validation: 0.041778785558189195]
	TIME [epoch: 6.48 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035578172815511046		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.035578172815511046 | validation: 0.05970760122737111]
	TIME [epoch: 6.49 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835272275391896		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.04835272275391896 | validation: 0.051344971223653606]
	TIME [epoch: 6.48 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035330945131499245		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.035330945131499245 | validation: 0.06603751011729102]
	TIME [epoch: 6.48 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039745810316731356		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.039745810316731356 | validation: 0.0582760423302447]
	TIME [epoch: 6.47 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726180865382299		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.03726180865382299 | validation: 0.048205819510985855]
	TIME [epoch: 6.47 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04338215582168932		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04338215582168932 | validation: 0.04207826735498706]
	TIME [epoch: 6.47 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02972963277581904		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.02972963277581904 | validation: 0.05049203336493807]
	TIME [epoch: 6.51 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028652015275071056		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.028652015275071056 | validation: 0.03492050814522067]
	TIME [epoch: 6.47 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024057080456066117		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.024057080456066117 | validation: 0.034200305269222034]
	TIME [epoch: 6.46 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025978093247071565		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.025978093247071565 | validation: 0.029033856490927455]
	TIME [epoch: 6.45 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023902621935212767		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.023902621935212767 | validation: 0.03104534130020066]
	TIME [epoch: 6.46 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018883113395009164		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.018883113395009164 | validation: 0.026353135627066357]
	TIME [epoch: 6.45 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023277291511593405		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.023277291511593405 | validation: 0.057357754534568546]
	TIME [epoch: 6.47 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046876189293364144		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.046876189293364144 | validation: 0.04899512899290102]
	TIME [epoch: 6.49 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035906643696318324		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.035906643696318324 | validation: 0.041347394102256525]
	TIME [epoch: 6.46 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02564091727189098		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.02564091727189098 | validation: 0.02638708903364754]
	TIME [epoch: 6.46 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018914086760194557		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.018914086760194557 | validation: 0.038054149961979894]
	TIME [epoch: 6.46 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025709509670707616		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.025709509670707616 | validation: 0.03224110763989789]
	TIME [epoch: 6.46 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02192903410710985		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.02192903410710985 | validation: 0.04100044783779261]
	TIME [epoch: 6.47 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025973117640747546		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.025973117640747546 | validation: 0.037147229679925516]
	TIME [epoch: 6.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021071023346260105		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.021071023346260105 | validation: 0.028448058210237354]
	TIME [epoch: 6.48 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021043780357902508		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.021043780357902508 | validation: 0.0326409961888974]
	TIME [epoch: 6.46 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024065017808509247		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.024065017808509247 | validation: 0.023479302417529033]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_830.pth
	Model improved!!!
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017643701422020153		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.017643701422020153 | validation: 0.0269098278992412]
	TIME [epoch: 6.46 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02659391465207575		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.02659391465207575 | validation: 0.03432903012574321]
	TIME [epoch: 6.46 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029841128478390842		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.029841128478390842 | validation: 0.03913825630885575]
	TIME [epoch: 6.46 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03131974320381447		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.03131974320381447 | validation: 0.049509996543222703]
	TIME [epoch: 6.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03778347547446219		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.03778347547446219 | validation: 0.03759451582305503]
	TIME [epoch: 6.47 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241670313866596		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.03241670313866596 | validation: 0.03984458721707745]
	TIME [epoch: 6.47 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025862978528849022		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.025862978528849022 | validation: 0.03260157518630336]
	TIME [epoch: 6.46 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020266387175406117		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.020266387175406117 | validation: 0.03641315740679557]
	TIME [epoch: 6.47 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025128155271626054		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.025128155271626054 | validation: 0.0365001740294894]
	TIME [epoch: 6.46 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05119025935506241		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.05119025935506241 | validation: 0.07265894612930435]
	TIME [epoch: 6.48 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587922148921658		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.04587922148921658 | validation: 0.05640333692902953]
	TIME [epoch: 6.48 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530985508171762		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.04530985508171762 | validation: 0.04138079392499584]
	TIME [epoch: 6.47 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04174401625385325		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.04174401625385325 | validation: 0.0492934464117968]
	TIME [epoch: 6.46 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03819800877083958		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.03819800877083958 | validation: 0.05895669659168665]
	TIME [epoch: 6.47 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04430298768558752		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.04430298768558752 | validation: 0.05844877977554608]
	TIME [epoch: 6.46 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040551679862925585		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.040551679862925585 | validation: 0.04911095723812713]
	TIME [epoch: 6.48 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026388680117572467		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.026388680117572467 | validation: 0.04193623292695138]
	TIME [epoch: 6.51 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029737869839769768		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.029737869839769768 | validation: 0.036181762587355226]
	TIME [epoch: 6.48 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04073938559591524		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.04073938559591524 | validation: 0.03623300459053629]
	TIME [epoch: 6.47 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296654903610692		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.03296654903610692 | validation: 0.040442326762967495]
	TIME [epoch: 6.48 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033452494954018794		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.033452494954018794 | validation: 0.032583379276607455]
	TIME [epoch: 6.47 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036806059284261235		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.036806059284261235 | validation: 0.04720433583286629]
	TIME [epoch: 6.47 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03831330535094385		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03831330535094385 | validation: 0.04371196086652784]
	TIME [epoch: 6.49 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045978821035209866		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.045978821035209866 | validation: 0.04572603594286745]
	TIME [epoch: 6.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04086857978464587		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.04086857978464587 | validation: 0.0461839929417045]
	TIME [epoch: 6.48 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029683646801640186		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.029683646801640186 | validation: 0.0325936902668334]
	TIME [epoch: 6.47 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024761566664775844		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.024761566664775844 | validation: 0.033903944106875764]
	TIME [epoch: 6.47 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781408440090037		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.02781408440090037 | validation: 0.03419562351351763]
	TIME [epoch: 6.47 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030108296255679373		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.030108296255679373 | validation: 0.042428079469807665]
	TIME [epoch: 6.47 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03189134109873636		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.03189134109873636 | validation: 0.036580572718589034]
	TIME [epoch: 6.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029196661201886805		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.029196661201886805 | validation: 0.0370747621071136]
	TIME [epoch: 6.48 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03500353741805205		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03500353741805205 | validation: 0.04634877663023973]
	TIME [epoch: 6.47 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039005328800923625		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.039005328800923625 | validation: 0.051881544868573014]
	TIME [epoch: 6.47 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028310144606810334		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.028310144606810334 | validation: 0.035334704944868]
	TIME [epoch: 6.47 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029352325558401907		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.029352325558401907 | validation: 0.034188578932582585]
	TIME [epoch: 6.47 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995244914586513		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.02995244914586513 | validation: 0.04864322348319492]
	TIME [epoch: 6.47 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03935297477394571		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.03935297477394571 | validation: 0.04648206899016967]
	TIME [epoch: 6.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022326269940365635		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.022326269940365635 | validation: 0.03279865836206469]
	TIME [epoch: 6.48 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020309841051020034		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.020309841051020034 | validation: 0.03303236054680896]
	TIME [epoch: 6.48 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017731663656937527		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.017731663656937527 | validation: 0.04763542944314685]
	TIME [epoch: 6.48 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027081695204135364		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.027081695204135364 | validation: 0.04344851458319747]
	TIME [epoch: 6.46 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021445322765986805		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.021445322765986805 | validation: 0.025079484675680958]
	TIME [epoch: 6.48 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018685481578495124		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.018685481578495124 | validation: 0.0388657341243744]
	TIME [epoch: 6.48 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493660913735012		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.03493660913735012 | validation: 0.037669252465215804]
	TIME [epoch: 6.51 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034635427268272324		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.034635427268272324 | validation: 0.04738181500385896]
	TIME [epoch: 6.46 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227911522026125		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.03227911522026125 | validation: 0.03049782625882545]
	TIME [epoch: 6.47 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029548348974072915		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.029548348974072915 | validation: 0.029883042558436337]
	TIME [epoch: 6.46 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02755231193214261		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.02755231193214261 | validation: 0.026246191065512212]
	TIME [epoch: 6.48 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01983241366034882		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.01983241366034882 | validation: 0.03071975499176035]
	TIME [epoch: 6.47 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022895692332874817		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.022895692332874817 | validation: 0.03852665768761853]
	TIME [epoch: 6.51 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02435281304283133		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.02435281304283133 | validation: 0.04222882165472388]
	TIME [epoch: 6.47 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02209272151866791		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.02209272151866791 | validation: 0.023201295363347422]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018072503630440773		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.018072503630440773 | validation: 0.02662879851795304]
	TIME [epoch: 6.48 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021610604265747103		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.021610604265747103 | validation: 0.04773737236934343]
	TIME [epoch: 6.46 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025532627587658906		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.025532627587658906 | validation: 0.02543182568377624]
	TIME [epoch: 6.47 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018983631129978324		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.018983631129978324 | validation: 0.02564605934470094]
	TIME [epoch: 6.49 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022288112383962		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.022288112383962 | validation: 0.031170882573556716]
	TIME [epoch: 6.51 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02018317541455323		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.02018317541455323 | validation: 0.02794682102665546]
	TIME [epoch: 6.48 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020363688367755862		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.020363688367755862 | validation: 0.024382995601571537]
	TIME [epoch: 6.48 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01448128345645774		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.01448128345645774 | validation: 0.021107558030412806]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_890.pth
	Model improved!!!
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014942304695618086		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.014942304695618086 | validation: 0.030499940266723993]
	TIME [epoch: 6.48 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02132305412062134		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.02132305412062134 | validation: 0.03127867167101183]
	TIME [epoch: 6.48 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018501500096005496		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.018501500096005496 | validation: 0.039193869763386985]
	TIME [epoch: 6.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021315697336213094		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.021315697336213094 | validation: 0.03503945637565254]
	TIME [epoch: 6.48 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025698680750747854		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.025698680750747854 | validation: 0.03308896082562777]
	TIME [epoch: 6.48 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028044157878520957		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.028044157878520957 | validation: 0.03040857533342259]
	TIME [epoch: 6.47 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428927328585408		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.03428927328585408 | validation: 0.043882119434902896]
	TIME [epoch: 6.48 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043388287578497844		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.043388287578497844 | validation: 0.03881958045176797]
	TIME [epoch: 6.48 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140122210598317		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03140122210598317 | validation: 0.024381005803298415]
	TIME [epoch: 6.49 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022944112396616808		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.022944112396616808 | validation: 0.03046723773727355]
	TIME [epoch: 6.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026283476726915778		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.026283476726915778 | validation: 0.04083831297877025]
	TIME [epoch: 6.48 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250101753593699		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.02250101753593699 | validation: 0.04222184845145392]
	TIME [epoch: 6.47 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025942846317838324		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.025942846317838324 | validation: 0.04292507329305755]
	TIME [epoch: 6.47 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905721409157624		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.02905721409157624 | validation: 0.059999225363868196]
	TIME [epoch: 6.47 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032654468014562815		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.032654468014562815 | validation: 0.030789516139535938]
	TIME [epoch: 6.47 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023193891519691073		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.023193891519691073 | validation: 0.031634795412151584]
	TIME [epoch: 6.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023782659524788554		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.023782659524788554 | validation: 0.03111805982669795]
	TIME [epoch: 6.48 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024344619792280864		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.024344619792280864 | validation: 0.03382567720656695]
	TIME [epoch: 6.47 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024397612691060146		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.024397612691060146 | validation: 0.04754524273570173]
	TIME [epoch: 6.47 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03322484771898446		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.03322484771898446 | validation: 0.03123678500911669]
	TIME [epoch: 6.48 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014128053954210722		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.014128053954210722 | validation: 0.02432139496445994]
	TIME [epoch: 6.48 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022849444384876155		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.022849444384876155 | validation: 0.03946749726908558]
	TIME [epoch: 6.46 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046203752862834		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.03046203752862834 | validation: 0.030228080316800656]
	TIME [epoch: 6.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0173945758777438		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.0173945758777438 | validation: 0.03246219524689164]
	TIME [epoch: 6.47 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045486476321885		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.02045486476321885 | validation: 0.04145400211441039]
	TIME [epoch: 6.46 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019422337191266025		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.019422337191266025 | validation: 0.028723354120306237]
	TIME [epoch: 6.46 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024099115095186637		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.024099115095186637 | validation: 0.020674027696672193]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_917.pth
	Model improved!!!
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021396920414524		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.021396920414524 | validation: 0.028450274965859883]
	TIME [epoch: 6.46 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018801962597643294		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.018801962597643294 | validation: 0.03593604659205282]
	TIME [epoch: 6.49 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01694213431644543		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.01694213431644543 | validation: 0.029561599168381966]
	TIME [epoch: 6.49 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02410510821687961		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.02410510821687961 | validation: 0.03290387858313576]
	TIME [epoch: 6.46 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030749504468510623		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.030749504468510623 | validation: 0.030993133523038764]
	TIME [epoch: 6.47 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031017258222832696		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.031017258222832696 | validation: 0.0323728585269658]
	TIME [epoch: 6.47 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023214255381566552		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.023214255381566552 | validation: 0.031967377818002816]
	TIME [epoch: 6.46 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02636087920077374		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.02636087920077374 | validation: 0.03517685014513567]
	TIME [epoch: 6.46 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023213013192649193		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.023213013192649193 | validation: 0.0342260844929342]
	TIME [epoch: 6.49 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024269240389244953		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.024269240389244953 | validation: 0.028738557400190025]
	TIME [epoch: 6.49 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02193150105505981		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.02193150105505981 | validation: 0.028901571500507622]
	TIME [epoch: 6.46 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025804610003899813		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.025804610003899813 | validation: 0.04525010936754354]
	TIME [epoch: 6.46 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032626975376281765		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.032626975376281765 | validation: 0.03875563172864751]
	TIME [epoch: 6.46 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029511747932876205		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.029511747932876205 | validation: 0.0426393491664283]
	TIME [epoch: 6.47 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03343791712825388		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.03343791712825388 | validation: 0.03857623192423436]
	TIME [epoch: 6.49 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029747664239871806		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.029747664239871806 | validation: 0.03803244055753734]
	TIME [epoch: 6.49 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388610243430336		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.03388610243430336 | validation: 0.045518580095946844]
	TIME [epoch: 6.47 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038811152439773636		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.038811152439773636 | validation: 0.047362439661839846]
	TIME [epoch: 6.46 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03080180263085036		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.03080180263085036 | validation: 0.03671943076803871]
	TIME [epoch: 6.46 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029526154226197126		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.029526154226197126 | validation: 0.037838562608934964]
	TIME [epoch: 6.47 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325055008887255		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0325055008887255 | validation: 0.05421665281365156]
	TIME [epoch: 6.46 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037620947083630195		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.037620947083630195 | validation: 0.04366944034820418]
	TIME [epoch: 6.51 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031071983302200804		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.031071983302200804 | validation: 0.03016781781517965]
	TIME [epoch: 6.48 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0232197980843748		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.0232197980843748 | validation: 0.03712392225958006]
	TIME [epoch: 6.46 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03146489833624867		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.03146489833624867 | validation: 0.0323011667664651]
	TIME [epoch: 6.48 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022900946125080784		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.022900946125080784 | validation: 0.025931724959469157]
	TIME [epoch: 6.47 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022445336563224724		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.022445336563224724 | validation: 0.03459302125493698]
	TIME [epoch: 6.46 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020052162466001982		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.020052162466001982 | validation: 0.031138554946525846]
	TIME [epoch: 6.46 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951366982617543		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.01951366982617543 | validation: 0.03924409869550117]
	TIME [epoch: 6.51 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02187953526477932		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.02187953526477932 | validation: 0.04457779956101785]
	TIME [epoch: 6.46 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025420919855552643		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.025420919855552643 | validation: 0.04288274788929403]
	TIME [epoch: 6.48 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024990297742496163		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.024990297742496163 | validation: 0.02735399668122243]
	TIME [epoch: 6.46 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022466586466474838		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.022466586466474838 | validation: 0.02960735845975074]
	TIME [epoch: 6.47 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02111845061336688		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.02111845061336688 | validation: 0.03338764917748664]
	TIME [epoch: 6.48 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02377867199123647		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.02377867199123647 | validation: 0.033730586211455006]
	TIME [epoch: 6.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023497460334841198		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.023497460334841198 | validation: 0.029726453971858163]
	TIME [epoch: 6.47 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017359710979999565		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.017359710979999565 | validation: 0.028784314466786406]
	TIME [epoch: 6.47 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021277098915937046		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.021277098915937046 | validation: 0.03802991850808823]
	TIME [epoch: 6.47 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02741244115722251		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.02741244115722251 | validation: 0.030112553393745193]
	TIME [epoch: 6.46 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025340495774326306		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.025340495774326306 | validation: 0.023011593355716235]
	TIME [epoch: 6.46 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02048708549563079		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.02048708549563079 | validation: 0.034849967249601]
	TIME [epoch: 6.46 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01944924289038251		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.01944924289038251 | validation: 0.039874609993305166]
	TIME [epoch: 6.49 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0359594314850668		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0359594314850668 | validation: 0.05135032474546508]
	TIME [epoch: 6.47 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030658988393872866		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.030658988393872866 | validation: 0.03686835288137619]
	TIME [epoch: 6.46 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025995206662808242		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.025995206662808242 | validation: 0.038522780677355234]
	TIME [epoch: 6.46 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026738348879450095		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.026738348879450095 | validation: 0.03188480628134519]
	TIME [epoch: 6.46 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764508822884647		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.02764508822884647 | validation: 0.0327659127534538]
	TIME [epoch: 6.46 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024513355588795582		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.024513355588795582 | validation: 0.03691500623393203]
	TIME [epoch: 6.47 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027193683881567288		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.027193683881567288 | validation: 0.030173646055714067]
	TIME [epoch: 6.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0262624563716579		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0262624563716579 | validation: 0.02686237443323042]
	TIME [epoch: 6.47 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022974341368726777		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.022974341368726777 | validation: 0.030364702701055696]
	TIME [epoch: 6.46 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01935330963107253		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.01935330963107253 | validation: 0.02790577540337827]
	TIME [epoch: 6.47 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021907158166125526		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.021907158166125526 | validation: 0.02874898380263218]
	TIME [epoch: 6.48 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0209252290476201		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0209252290476201 | validation: 0.0241528387712623]
	TIME [epoch: 6.47 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02442640183712448		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.02442640183712448 | validation: 0.0388248214936647]
	TIME [epoch: 6.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244741375037039		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.03244741375037039 | validation: 0.0314755943073463]
	TIME [epoch: 6.49 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023290511784124224		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.023290511784124224 | validation: 0.033312572122030225]
	TIME [epoch: 6.47 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021200292255236862		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.021200292255236862 | validation: 0.03310964974857249]
	TIME [epoch: 6.47 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02626865273889074		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.02626865273889074 | validation: 0.023874607027080323]
	TIME [epoch: 6.47 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015666532037392805		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.015666532037392805 | validation: 0.03471345057765449]
	TIME [epoch: 6.47 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024651701132691703		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.024651701132691703 | validation: 0.02994992610494396]
	TIME [epoch: 6.46 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029160017206668026		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.029160017206668026 | validation: 0.03698598249699955]
	TIME [epoch: 6.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020050527666451285		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.020050527666451285 | validation: 0.032311278470264826]
	TIME [epoch: 6.47 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020041661893817245		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.020041661893817245 | validation: 0.028761097962639967]
	TIME [epoch: 6.46 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01404615624030984		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.01404615624030984 | validation: 0.028734507689157595]
	TIME [epoch: 6.46 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02380462179474127		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.02380462179474127 | validation: 0.023484273534467737]
	TIME [epoch: 6.46 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015036692022194383		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.015036692022194383 | validation: 0.03355097137799261]
	TIME [epoch: 6.47 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024154729880540543		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.024154729880540543 | validation: 0.03308373131807173]
	TIME [epoch: 6.49 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016086195050222397		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.016086195050222397 | validation: 0.023736619967227632]
	TIME [epoch: 6.48 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01874119950756389		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.01874119950756389 | validation: 0.027415325437640838]
	TIME [epoch: 6.47 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017747743420098726		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.017747743420098726 | validation: 0.03266337511459242]
	TIME [epoch: 6.47 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017801514300064068		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.017801514300064068 | validation: 0.026874558069513315]
	TIME [epoch: 6.46 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0152180443811833		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.0152180443811833 | validation: 0.022570170498922487]
	TIME [epoch: 6.47 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019162057238108918		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.019162057238108918 | validation: 0.03544744009759426]
	TIME [epoch: 6.47 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016659447019478777		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.016659447019478777 | validation: 0.03346810642511427]
	TIME [epoch: 6.51 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019468019388336373		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.019468019388336373 | validation: 0.02669310924791608]
	TIME [epoch: 6.47 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02364292172386806		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.02364292172386806 | validation: 0.035120048908279]
	TIME [epoch: 6.47 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022943154998514		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.022943154998514 | validation: 0.031635732475535416]
	TIME [epoch: 6.46 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02035634119432877		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.02035634119432877 | validation: 0.029425389297793564]
	TIME [epoch: 6.47 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172767067663377		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0172767067663377 | validation: 0.026999714993620316]
	TIME [epoch: 6.46 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0184636512707189		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0184636512707189 | validation: 0.028250844034978472]
	TIME [epoch: 6.47 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01832585306999148		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.01832585306999148 | validation: 0.03101873756550099]
	TIME [epoch: 6.49 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01828733254551761		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.01828733254551761 | validation: 0.023569426576091134]
	TIME [epoch: 6.46 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165763806624227		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.0165763806624227 | validation: 0.023540631068046318]
	TIME [epoch: 6.46 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212815872473386		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.02212815872473386 | validation: 0.038894780187650864]
	TIME [epoch: 6.46 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026233144791694037		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.026233144791694037 | validation: 0.033260838276994636]
	TIME [epoch: 6.47 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021968562068348855		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.021968562068348855 | validation: 0.036696691212914294]
	TIME [epoch: 6.46 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024132753657504682		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.024132753657504682 | validation: 0.04503989593179071]
	TIME [epoch: 6.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03088041839653303		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.03088041839653303 | validation: 0.045924088716881285]
	TIME [epoch: 6.47 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02123942884283129		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.02123942884283129 | validation: 0.034653812852104164]
	TIME [epoch: 6.46 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016225580475733734		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.016225580475733734 | validation: 0.029580004635407945]
	TIME [epoch: 6.46 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019910932981278842		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.019910932981278842 | validation: 0.03239881847107072]
	TIME [epoch: 6.47 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021542000459384782		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.021542000459384782 | validation: 0.022652309881204695]
	TIME [epoch: 6.46 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01651611195507929		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.01651611195507929 | validation: 0.02252543014805471]
	TIME [epoch: 6.47 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016813503028069124		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.016813503028069124 | validation: 0.03575713243734977]
	TIME [epoch: 6.49 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01972209552382649		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.01972209552382649 | validation: 0.03086213736443046]
	TIME [epoch: 6.47 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02216196114876461		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.02216196114876461 | validation: 0.028462925882723367]
	TIME [epoch: 6.46 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022724490049751127		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.022724490049751127 | validation: 0.028155905510635498]
	TIME [epoch: 6.45 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023642584416925884		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.023642584416925884 | validation: 0.029764555339044946]
	TIME [epoch: 6.46 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020857377761695568		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.020857377761695568 | validation: 0.02219974141825747]
	TIME [epoch: 6.47 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015853630734183406		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.015853630734183406 | validation: 0.024071416392720577]
	TIME [epoch: 6.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019289164100796667		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.019289164100796667 | validation: 0.028607035808259098]
	TIME [epoch: 6.47 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01691817988320363		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.01691817988320363 | validation: 0.02945413336216243]
	TIME [epoch: 6.47 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023492684749337543		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.023492684749337543 | validation: 0.021559843361788563]
	TIME [epoch: 6.47 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015871005009490843		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.015871005009490843 | validation: 0.02627402624570319]
	TIME [epoch: 6.47 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020351503953477002		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.020351503953477002 | validation: 0.019896378765644995]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_1023.pth
	Model improved!!!
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017851527190466863		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.017851527190466863 | validation: 0.038370673311800906]
	TIME [epoch: 6.47 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019708584111819336		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.019708584111819336 | validation: 0.03694574491041113]
	TIME [epoch: 6.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023043582224933794		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.023043582224933794 | validation: 0.03184898730901387]
	TIME [epoch: 6.47 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021848273326940733		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.021848273326940733 | validation: 0.03335201523560657]
	TIME [epoch: 6.46 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020446549059639406		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.020446549059639406 | validation: 0.033921560864400624]
	TIME [epoch: 6.47 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0230047231215482		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.0230047231215482 | validation: 0.03790044046870042]
	TIME [epoch: 6.46 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020596845114499728		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.020596845114499728 | validation: 0.021799435287595658]
	TIME [epoch: 6.47 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014700180110287848		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.014700180110287848 | validation: 0.028576367473879198]
	TIME [epoch: 6.49 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018196612039181048		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.018196612039181048 | validation: 0.030964391815865976]
	TIME [epoch: 6.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027543839756087516		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.027543839756087516 | validation: 0.03245378629058149]
	TIME [epoch: 6.46 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02121857919766647		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.02121857919766647 | validation: 0.032781787428000475]
	TIME [epoch: 6.48 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022806409628027317		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.022806409628027317 | validation: 0.0350080750593892]
	TIME [epoch: 6.47 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01774604447722658		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.01774604447722658 | validation: 0.03338047177174072]
	TIME [epoch: 6.48 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02072554830353574		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.02072554830353574 | validation: 0.028558551660609294]
	TIME [epoch: 6.47 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023831796556728388		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.023831796556728388 | validation: 0.03276256663993542]
	TIME [epoch: 6.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013296985415856532		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.013296985415856532 | validation: 0.02907693044812163]
	TIME [epoch: 6.49 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02485927036156381		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.02485927036156381 | validation: 0.035948856523322886]
	TIME [epoch: 6.48 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022524481119635814		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.022524481119635814 | validation: 0.023809802947074608]
	TIME [epoch: 6.46 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015614841998973386		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.015614841998973386 | validation: 0.033785977564750914]
	TIME [epoch: 6.47 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045659488709481		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.02045659488709481 | validation: 0.03132485510063389]
	TIME [epoch: 6.48 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015003647454645112		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.015003647454645112 | validation: 0.02066318419759226]
	TIME [epoch: 6.47 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015846510327394956		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.015846510327394956 | validation: 0.02203158622051003]
	TIME [epoch: 6.49 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017944056861353586		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.017944056861353586 | validation: 0.029553710262099644]
	TIME [epoch: 6.47 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02024650052861658		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.02024650052861658 | validation: 0.035936373757643206]
	TIME [epoch: 6.47 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812779478276106		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.01812779478276106 | validation: 0.02483501700042659]
	TIME [epoch: 6.48 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01620488140448518		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.01620488140448518 | validation: 0.02591926923194963]
	TIME [epoch: 6.46 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018367091131275957		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.018367091131275957 | validation: 0.026930880935208235]
	TIME [epoch: 6.46 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01667822585405223		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.01667822585405223 | validation: 0.02876419582727737]
	TIME [epoch: 6.49 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020923013594058393		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.020923013594058393 | validation: 0.0187928751233033]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01692575195792435		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.01692575195792435 | validation: 0.021412196787950852]
	TIME [epoch: 6.47 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014898296492347415		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.014898296492347415 | validation: 0.03258235055630398]
	TIME [epoch: 6.46 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648283466361992		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.01648283466361992 | validation: 0.025087088958188536]
	TIME [epoch: 6.46 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312935163268265		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.02312935163268265 | validation: 0.026542451801799753]
	TIME [epoch: 6.46 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017910087735811528		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.017910087735811528 | validation: 0.02914033800200709]
	TIME [epoch: 6.46 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020016221943851976		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.020016221943851976 | validation: 0.024074936741055]
	TIME [epoch: 6.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017966510702671166		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.017966510702671166 | validation: 0.028191031911701036]
	TIME [epoch: 6.46 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014273028167618999		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.014273028167618999 | validation: 0.02098930120349014]
	TIME [epoch: 6.46 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01668526678021723		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.01668526678021723 | validation: 0.02169186254579071]
	TIME [epoch: 6.47 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019822291001793862		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.019822291001793862 | validation: 0.022343754555835565]
	TIME [epoch: 6.47 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014373332086623015		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.014373332086623015 | validation: 0.029408401365983352]
	TIME [epoch: 6.46 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016383563760724598		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.016383563760724598 | validation: 0.020595633608061322]
	TIME [epoch: 6.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014681319154729477		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.014681319154729477 | validation: 0.03029505821814418]
	TIME [epoch: 6.48 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016342911346537085		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.016342911346537085 | validation: 0.030365858777723187]
	TIME [epoch: 6.48 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02054768620984163		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.02054768620984163 | validation: 0.03537771447096912]
	TIME [epoch: 6.48 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01731641174884708		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.01731641174884708 | validation: 0.008742297906384911]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study2/model_tr_study2_r2_20240309_135632/states/model_tr_study2_1068.pth
	Model improved!!!
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012776196981401205		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.012776196981401205 | validation: 0.01829272334385755]
	TIME [epoch: 6.47 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013181826252470797		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.013181826252470797 | validation: 0.02039768390706081]
	TIME [epoch: 6.47 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017523106234501824		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.017523106234501824 | validation: 0.029269220768736563]
	TIME [epoch: 6.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016418039161768795		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.016418039161768795 | validation: 0.03043415277175333]
	TIME [epoch: 6.48 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017043832115238352		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.017043832115238352 | validation: 0.0380571240959672]
	TIME [epoch: 6.47 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02535279637006639		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.02535279637006639 | validation: 0.033235031402065844]
	TIME [epoch: 6.47 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311882660605386		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.02311882660605386 | validation: 0.033797229603644084]
	TIME [epoch: 6.47 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020116308117279852		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.020116308117279852 | validation: 0.024892644237070393]
	TIME [epoch: 6.47 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015193032832542638		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.015193032832542638 | validation: 0.021979977206777468]
	TIME [epoch: 6.49 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020867072525617775		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.020867072525617775 | validation: 0.02622365906289806]
	TIME [epoch: 6.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018300372895502754		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.018300372895502754 | validation: 0.01694136042250724]
	TIME [epoch: 6.48 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01834034024378968		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.01834034024378968 | validation: 0.02456868076022459]
	TIME [epoch: 6.48 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02309354561641749		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.02309354561641749 | validation: 0.026104138804663553]
	TIME [epoch: 6.47 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024965783884804006		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.024965783884804006 | validation: 0.03825524157963924]
	TIME [epoch: 6.47 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02255738436130167		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.02255738436130167 | validation: 0.027641812542936052]
	TIME [epoch: 6.47 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02109586496940779		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.02109586496940779 | validation: 0.030028960531681203]
	TIME [epoch: 6.51 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025930225762862052		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.025930225762862052 | validation: 0.028532912297109123]
	TIME [epoch: 6.48 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021771284738588602		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.021771284738588602 | validation: 0.029651788569786106]
	TIME [epoch: 6.48 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023140128392119288		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.023140128392119288 | validation: 0.03720219908556951]
	TIME [epoch: 6.47 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018914866747346278		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.018914866747346278 | validation: 0.02777614940096424]
	TIME [epoch: 6.47 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02000208097433248		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.02000208097433248 | validation: 0.02155480460901588]
	TIME [epoch: 6.47 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015425292413990219		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.015425292413990219 | validation: 0.02200718495829109]
	TIME [epoch: 6.48 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018558692505362247		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.018558692505362247 | validation: 0.01679878724773134]
	TIME [epoch: 6.49 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855068862864478		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.01855068862864478 | validation: 0.031201354255573858]
	TIME [epoch: 6.47 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017722386226342778		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.017722386226342778 | validation: 0.03437094765923471]
	TIME [epoch: 6.47 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01667400761296214		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.01667400761296214 | validation: 0.02187006251112562]
	TIME [epoch: 6.47 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016003536415452886		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.016003536415452886 | validation: 0.0255067989965608]
	TIME [epoch: 6.47 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015444238935625267		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.015444238935625267 | validation: 0.027995054834580962]
	TIME [epoch: 6.47 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012473015805423938		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.012473015805423938 | validation: 0.035981653307010676]
	TIME [epoch: 6.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01611605150262697		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.01611605150262697 | validation: 0.02701143870688152]
	TIME [epoch: 6.49 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010855985258850676		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.010855985258850676 | validation: 0.02595445271810413]
	TIME [epoch: 6.48 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02873651982461355		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.02873651982461355 | validation: 0.023322014803866035]
	TIME [epoch: 6.47 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310698064497424		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.02310698064497424 | validation: 0.03280561016498355]
	TIME [epoch: 6.47 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01602606843685451		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.01602606843685451 | validation: 0.02557801586218049]
	TIME [epoch: 6.47 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634281385493923		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.01634281385493923 | validation: 0.02736592578237522]
	TIME [epoch: 6.48 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02211204497889108		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.02211204497889108 | validation: 0.04046529360092082]
	TIME [epoch: 6.51 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024646168869449703		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.024646168869449703 | validation: 0.024707888697691475]
	TIME [epoch: 6.48 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017861128955284605		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.017861128955284605 | validation: 0.033159373825733834]
	TIME [epoch: 6.47 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019565945373417337		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.019565945373417337 | validation: 0.02614623478693162]
	TIME [epoch: 6.47 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018861317959107338		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.018861317959107338 | validation: 0.029101573149139526]
	TIME [epoch: 6.48 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016288411649255808		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.016288411649255808 | validation: 0.021448569872988793]
	TIME [epoch: 6.47 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015179520856782302		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.015179520856782302 | validation: 0.02955881501321759]
	TIME [epoch: 6.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01433546683823563		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.01433546683823563 | validation: 0.02642065191349612]
	TIME [epoch: 6.48 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015748175016729454		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.015748175016729454 | validation: 0.0235921924876766]
	TIME [epoch: 6.48 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014021979907891467		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.014021979907891467 | validation: 0.02078911310619667]
	TIME [epoch: 6.49 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01699280861875889		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.01699280861875889 | validation: 0.03495842638814087]
	TIME [epoch: 6.48 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018315544126795123		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.018315544126795123 | validation: 0.03383221813699854]
	TIME [epoch: 6.47 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0179866757220827		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0179866757220827 | validation: 0.02862268197890101]
	TIME [epoch: 6.48 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021226178213814662		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.021226178213814662 | validation: 0.0308063836650109]
	TIME [epoch: 6.51 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022858236744426146		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.022858236744426146 | validation: 0.027988595819417556]
	TIME [epoch: 6.48 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02075807779790251		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.02075807779790251 | validation: 0.029352337117214963]
	TIME [epoch: 6.48 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027109936632689742		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.027109936632689742 | validation: 0.038580705613840034]
	TIME [epoch: 6.48 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0298345146166844		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.0298345146166844 | validation: 0.03079870905244613]
	TIME [epoch: 6.47 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023510900366846665		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.023510900366846665 | validation: 0.024433391802151344]
	TIME [epoch: 6.48 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023951264968851166		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.023951264968851166 | validation: 0.033956030523843946]
	TIME [epoch: 6.49 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018980791943702165		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.018980791943702165 | validation: 0.03313458329074803]
	TIME [epoch: 6.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02106214646426194		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.02106214646426194 | validation: 0.02755494263821598]
	TIME [epoch: 6.48 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01473012630144015		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.01473012630144015 | validation: 0.023786281637591156]
	TIME [epoch: 6.48 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310963077893896		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.02310963077893896 | validation: 0.028716042736210944]
	TIME [epoch: 6.48 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02142104694633477		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.02142104694633477 | validation: 0.03446246655948231]
	TIME [epoch: 6.48 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022988110093772975		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.022988110093772975 | validation: 0.02926697955407117]
	TIME [epoch: 6.48 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610959526545997		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.01610959526545997 | validation: 0.018832640379280282]
	TIME [epoch: 6.52 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165862032498029		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.0165862032498029 | validation: 0.029752283389919282]
	TIME [epoch: 6.49 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01559126775475368		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.01559126775475368 | validation: 0.03156222640511058]
	TIME [epoch: 6.48 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01955039889321827		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.01955039889321827 | validation: 0.023510310134430387]
	TIME [epoch: 6.48 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01758281299846357		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.01758281299846357 | validation: 0.032048017991254625]
	TIME [epoch: 6.48 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016604682023556222		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.016604682023556222 | validation: 0.024119880307422778]
	TIME [epoch: 6.48 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01663950298811534		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.01663950298811534 | validation: 0.020199019397183694]
	TIME [epoch: 6.48 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0164728300502442		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.0164728300502442 | validation: 0.02249030276413178]
	TIME [epoch: 6.51 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017405767293156762		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.017405767293156762 | validation: 0.016177433912288403]
	TIME [epoch: 6.48 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013044672461238		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.02013044672461238 | validation: 0.039954803639837035]
	TIME [epoch: 6.48 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0230589780837665		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.0230589780837665 | validation: 0.04013753793003106]
	TIME [epoch: 6.48 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023906292218464516		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.023906292218464516 | validation: 0.03801999360834672]
	TIME [epoch: 6.48 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022432644349752017		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.022432644349752017 | validation: 0.0294581145575218]
	TIME [epoch: 6.48 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013266048149916755		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.013266048149916755 | validation: 0.03592134965599936]
	TIME [epoch: 6.51 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568869238833604		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.01568869238833604 | validation: 0.025524256340313193]
	TIME [epoch: 6.49 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013473955067180602		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.013473955067180602 | validation: 0.03077863785602519]
	TIME [epoch: 6.48 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019478462210109848		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.019478462210109848 | validation: 0.03018077923274536]
	TIME [epoch: 6.48 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017707998836314656		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.017707998836314656 | validation: 0.027021511325248344]
	TIME [epoch: 6.48 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014981017389827569		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.014981017389827569 | validation: 0.027852326189201016]
	TIME [epoch: 6.48 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01618393811778601		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.01618393811778601 | validation: 0.02517847708073611]
	TIME [epoch: 6.48 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01683086101692369		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.01683086101692369 | validation: 0.022421117677593506]
	TIME [epoch: 6.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019656458384937993		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.019656458384937993 | validation: 0.025105264875573314]
	TIME [epoch: 6.48 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017278748296102604		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.017278748296102604 | validation: 0.027375381239008918]
	TIME [epoch: 6.48 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01668390560393217		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.01668390560393217 | validation: 0.021051926379818616]
	TIME [epoch: 6.48 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015731276304401225		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.015731276304401225 | validation: 0.024716004213988778]
	TIME [epoch: 6.48 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012943672208484334		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.012943672208484334 | validation: 0.024069434489684745]
	TIME [epoch: 6.48 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014870187820934857		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.014870187820934857 | validation: 0.021445431350130644]
	TIME [epoch: 6.49 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01386071715710327		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.01386071715710327 | validation: 0.02297254799493084]
	TIME [epoch: 6.51 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01695970174784635		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.01695970174784635 | validation: 0.02345598613222646]
	TIME [epoch: 6.48 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01398326781955929		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.01398326781955929 | validation: 0.036925653464599834]
	TIME [epoch: 6.48 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0177067317036679		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.0177067317036679 | validation: 0.022817413444297618]
	TIME [epoch: 6.48 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015137067903190865		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.015137067903190865 | validation: 0.0230749695029789]
	TIME [epoch: 6.48 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018496535922295842		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.018496535922295842 | validation: 0.022808070070587806]
	TIME [epoch: 6.48 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013094907863184123		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.013094907863184123 | validation: 0.038169355670790946]
	TIME [epoch: 6.51 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01598256902273139		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.01598256902273139 | validation: 0.027217970204760356]
	TIME [epoch: 6.48 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017634217950312052		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.017634217950312052 | validation: 0.016604869301100954]
	TIME [epoch: 6.48 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017936677380972155		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.017936677380972155 | validation: 0.028960834125524047]
	TIME [epoch: 6.48 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01690192561174424		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.01690192561174424 | validation: 0.019730659954312505]
	TIME [epoch: 6.48 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015474310195832603		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.015474310195832603 | validation: 0.01944300753631503]
	TIME [epoch: 6.48 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014748076860810432		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.014748076860810432 | validation: 0.029464074583252592]
	TIME [epoch: 6.49 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0155993439594269		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0155993439594269 | validation: 0.02268286855119306]
	TIME [epoch: 6.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017284610106204207		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.017284610106204207 | validation: 0.021457018431125966]
	TIME [epoch: 6.48 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015062166360767433		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.015062166360767433 | validation: 0.03036401759184462]
	TIME [epoch: 6.48 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666161186307559		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.01666161186307559 | validation: 0.02265561512642303]
	TIME [epoch: 6.48 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010955303825576728		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.010955303825576728 | validation: 0.020247427537058035]
	TIME [epoch: 6.48 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760201227515562		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.01760201227515562 | validation: 0.026473536882245022]
	TIME [epoch: 6.48 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01942789303659856		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.01942789303659856 | validation: 0.020749172478373597]
	TIME [epoch: 6.51 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01675792622642973		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.01675792622642973 | validation: 0.03301324823177515]
	TIME [epoch: 6.49 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017557143768261375		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.017557143768261375 | validation: 0.01896827708132236]
	TIME [epoch: 6.48 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014052887960081199		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.014052887960081199 | validation: 0.02061114112570107]
	TIME [epoch: 6.48 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019026412909352294		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.019026412909352294 | validation: 0.02935522811425501]
	TIME [epoch: 6.48 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02032319302767335		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.02032319302767335 | validation: 0.04026748695629398]
	TIME [epoch: 6.48 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017269313534692684		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.017269313534692684 | validation: 0.022668426141104793]
	TIME [epoch: 6.48 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014660816864055848		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.014660816864055848 | validation: 0.03172408526807336]
	TIME [epoch: 6.51 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01934924660610113		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.01934924660610113 | validation: 0.03978724662016143]
	TIME [epoch: 6.48 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016642673294142003		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.016642673294142003 | validation: 0.029229660632730584]
	TIME [epoch: 6.48 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019195811424966427		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.019195811424966427 | validation: 0.02957451407253025]
	TIME [epoch: 6.48 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015135413216243827		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.015135413216243827 | validation: 0.023078398536884176]
	TIME [epoch: 6.48 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016664290531444814		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.016664290531444814 | validation: 0.02703254247542854]
	TIME [epoch: 6.48 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01566323628495373		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.01566323628495373 | validation: 0.027253167652588513]
	TIME [epoch: 6.49 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014701352595592526		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.014701352595592526 | validation: 0.018650233543106843]
	TIME [epoch: 6.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016166234411680448		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.016166234411680448 | validation: 0.031169245179882666]
	TIME [epoch: 6.48 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014880242727182528		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.014880242727182528 | validation: 0.03095781907437378]
	TIME [epoch: 6.48 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013928442473163416		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.013928442473163416 | validation: 0.023241216784948355]
	TIME [epoch: 6.48 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01589489715333372		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.01589489715333372 | validation: 0.02327214792905097]
	TIME [epoch: 6.48 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015120127033385078		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.015120127033385078 | validation: 0.027625481340017216]
	TIME [epoch: 6.48 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01888619745816519		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.01888619745816519 | validation: 0.02761361985031171]
	TIME [epoch: 6.51 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01890340927796813		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.01890340927796813 | validation: 0.024453138970927525]
	TIME [epoch: 6.48 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016345919079552188		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.016345919079552188 | validation: 0.018719361494909464]
	TIME [epoch: 6.48 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01344632798808234		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.01344632798808234 | validation: 0.024170633821019832]
	TIME [epoch: 6.48 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012838292283767346		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.012838292283767346 | validation: 0.02966136147279363]
	TIME [epoch: 6.48 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01300138064148528		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.01300138064148528 | validation: 0.022386714904389475]
	TIME [epoch: 6.48 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01589505007119		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.01589505007119 | validation: 0.027879410719648695]
	TIME [epoch: 6.49 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015388437401732694		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.015388437401732694 | validation: 0.027476476264509983]
	TIME [epoch: 6.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019410926457953944		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.019410926457953944 | validation: 0.01898951414693348]
	TIME [epoch: 6.48 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0167036551177126		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.0167036551177126 | validation: 0.02145428476002109]
	TIME [epoch: 6.48 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012981847052464333		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.012981847052464333 | validation: 0.024441910812322915]
	TIME [epoch: 6.48 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014827213432695663		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.014827213432695663 | validation: 0.01943327622456625]
	TIME [epoch: 6.48 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013308425337272878		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.013308425337272878 | validation: 0.024786490586009357]
	TIME [epoch: 6.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01347311536306996		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.01347311536306996 | validation: 0.027089657918107912]
	TIME [epoch: 6.51 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015684244419856337		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.015684244419856337 | validation: 0.02668932615034254]
	TIME [epoch: 6.48 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791601762868286		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.01791601762868286 | validation: 0.029427931296608652]
	TIME [epoch: 6.48 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02160133594605729		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.02160133594605729 | validation: 0.03534063887325694]
	TIME [epoch: 6.48 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017495095398595402		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.017495095398595402 | validation: 0.027669879626343652]
	TIME [epoch: 6.48 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01720380475090357		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.01720380475090357 | validation: 0.02984392953115417]
	TIME [epoch: 6.48 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610777220144407		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.01610777220144407 | validation: 0.030392080887120275]
	TIME [epoch: 6.48 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652095631122908		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.01652095631122908 | validation: 0.028259529791606376]
	TIME [epoch: 6.51 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020624294594108698		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.020624294594108698 | validation: 0.03273280214327654]
	TIME [epoch: 6.48 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017532521333834455		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.017532521333834455 | validation: 0.021199269170976427]
	TIME [epoch: 6.48 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020124114055418484		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.020124114055418484 | validation: 0.031935443237041214]
	TIME [epoch: 6.48 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017828687911628387		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.017828687911628387 | validation: 0.029897065278685134]
	TIME [epoch: 6.48 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019906782344979994		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.019906782344979994 | validation: 0.027905078850696013]
	TIME [epoch: 6.48 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014054300138314874		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.014054300138314874 | validation: 0.02764174116798293]
	TIME [epoch: 6.51 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016253550778083197		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.016253550778083197 | validation: 0.028849918605149166]
	TIME [epoch: 6.49 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015666076048840297		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.015666076048840297 | validation: 0.028089914135025224]
	TIME [epoch: 6.48 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020229245482802874		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.020229245482802874 | validation: 0.029575377534726482]
	TIME [epoch: 6.48 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016315379729411276		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.016315379729411276 | validation: 0.014314769774464615]
	TIME [epoch: 6.48 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012519693865887879		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.012519693865887879 | validation: 0.017849921820445015]
	TIME [epoch: 6.48 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011424200957898941		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.011424200957898941 | validation: 0.02177886523115995]
	TIME [epoch: 6.48 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018570694626076856		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.018570694626076856 | validation: 0.025052012012810706]
	TIME [epoch: 6.51 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016776217015560424		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.016776217015560424 | validation: 0.01641563881907385]
	TIME [epoch: 6.48 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019020008721531843		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.019020008721531843 | validation: 0.022659154239924043]
	TIME [epoch: 6.48 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012330204744211192		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.012330204744211192 | validation: 0.02150510292296605]
	TIME [epoch: 6.48 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015099042225104446		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.015099042225104446 | validation: 0.02248800757123538]
	TIME [epoch: 6.48 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012720475262711665		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.012720475262711665 | validation: 0.02635787568633277]
	TIME [epoch: 6.48 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01628439711956591		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.01628439711956591 | validation: 0.025273576460699543]
	TIME [epoch: 6.49 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017638802191194375		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.017638802191194375 | validation: 0.022884939474342274]
	TIME [epoch: 6.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016836055150142276		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.016836055150142276 | validation: 0.014516645431353333]
	TIME [epoch: 6.48 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017086875675799067		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.017086875675799067 | validation: 0.03284587669858615]
	TIME [epoch: 6.48 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018784841454021164		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.018784841454021164 | validation: 0.0233285848315447]
	TIME [epoch: 6.47 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015293634143474708		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.015293634143474708 | validation: 0.027535811165771484]
	TIME [epoch: 6.48 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013229390317474367		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.013229390317474367 | validation: 0.014582818441555883]
	TIME [epoch: 6.48 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013291396641983972		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.013291396641983972 | validation: 0.026554757691928936]
	TIME [epoch: 6.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016428348473945975		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.016428348473945975 | validation: 0.0331119035061696]
	TIME [epoch: 6.48 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801599584813178		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.01801599584813178 | validation: 0.02414065809905668]
	TIME [epoch: 6.48 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01281295409665905		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.01281295409665905 | validation: 0.028599015666755483]
	TIME [epoch: 6.48 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014888868132367967		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.014888868132367967 | validation: 0.027230934666701564]
	TIME [epoch: 6.48 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011916996906227696		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.011916996906227696 | validation: 0.029657655049281736]
	TIME [epoch: 6.48 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014489793278351228		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.014489793278351228 | validation: 0.024095207639541587]
	TIME [epoch: 6.49 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012205558700631372		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.012205558700631372 | validation: 0.03141620695229114]
	TIME [epoch: 6.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010993670424884538		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.010993670424884538 | validation: 0.02631725031204856]
	TIME [epoch: 6.48 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016522593418675888		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.016522593418675888 | validation: 0.025441199737955573]
	TIME [epoch: 6.48 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012628448125183676		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.012628448125183676 | validation: 0.026130000603627176]
	TIME [epoch: 6.48 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014474467746320881		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.014474467746320881 | validation: 0.019643439317291837]
	TIME [epoch: 6.48 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00980611727144034		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.00980611727144034 | validation: 0.029032644813414058]
	TIME [epoch: 6.48 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012685123220031349		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.012685123220031349 | validation: 0.02950274943508727]
	TIME [epoch: 6.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011299396720505558		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.011299396720505558 | validation: 0.028681472742104003]
	TIME [epoch: 6.49 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014888208225419516		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.014888208225419516 | validation: 0.03072989700484192]
	TIME [epoch: 6.48 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014379775345937275		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.014379775345937275 | validation: 0.0363889415501098]
	TIME [epoch: 6.48 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016910902409650392		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.016910902409650392 | validation: 0.021908561797887645]
	TIME [epoch: 6.48 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016080451869487908		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.016080451869487908 | validation: 0.017727543084707528]
	TIME [epoch: 6.48 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016350054371747497		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.016350054371747497 | validation: 0.026239779700254387]
	TIME [epoch: 6.48 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012792985273359947		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.012792985273359947 | validation: 0.02527700434635799]
	TIME [epoch: 6.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011658153371237844		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.011658153371237844 | validation: 0.027217671956341522]
	TIME [epoch: 6.48 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014309889378286169		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.014309889378286169 | validation: 0.02506988253154439]
	TIME [epoch: 6.48 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011970035200415929		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.011970035200415929 | validation: 0.03245900294329552]
	TIME [epoch: 6.48 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015795562723983976		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.015795562723983976 | validation: 0.023370490061064963]
	TIME [epoch: 6.48 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013531866607888564		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.013531866607888564 | validation: 0.027472908251245726]
	TIME [epoch: 6.48 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00868841557756624		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.00868841557756624 | validation: 0.028934726848054423]
	TIME [epoch: 6.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017035610640210672		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.017035610640210672 | validation: 0.025656312620700516]
	TIME [epoch: 6.48 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015759725153928872		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.015759725153928872 | validation: 0.023994757912935295]
	TIME [epoch: 6.48 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011087511828058614		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.011087511828058614 | validation: 0.023138460870115854]
	TIME [epoch: 6.48 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012997713364857827		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.012997713364857827 | validation: 0.017468058042942065]
	TIME [epoch: 6.48 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01700528377698276		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.01700528377698276 | validation: 0.030451819744415146]
	TIME [epoch: 6.47 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0114471004941474		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.0114471004941474 | validation: 0.025803847751079176]
	TIME [epoch: 6.48 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012675772707359105		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.012675772707359105 | validation: 0.02568373995472248]
	TIME [epoch: 6.51 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01704257951284078		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.01704257951284078 | validation: 0.02684372056946967]
	TIME [epoch: 6.48 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01701601777258539		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.01701601777258539 | validation: 0.026166168625343877]
	TIME [epoch: 6.47 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0222594472116987		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.0222594472116987 | validation: 0.029260160469871326]
	TIME [epoch: 6.47 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019311274226199864		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.019311274226199864 | validation: 0.029347545256837027]
	TIME [epoch: 6.47 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01652339229930805		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.01652339229930805 | validation: 0.028493591095589448]
	TIME [epoch: 6.46 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019092918010861253		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.019092918010861253 | validation: 0.025622577298083288]
	TIME [epoch: 6.47 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01996049250806601		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.01996049250806601 | validation: 0.0278818527764102]
	TIME [epoch: 6.48 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02031589059481858		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.02031589059481858 | validation: 0.020994400868729647]
	TIME [epoch: 6.46 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014713771887472804		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.014713771887472804 | validation: 0.025452937136139886]
	TIME [epoch: 6.46 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015369777889024945		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.015369777889024945 | validation: 0.029241211206632933]
	TIME [epoch: 6.46 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018015759688357263		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.018015759688357263 | validation: 0.028312040312313158]
	TIME [epoch: 6.46 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017296622451327147		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.017296622451327147 | validation: 0.022488884780482516]
	TIME [epoch: 6.46 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015552512839390704		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.015552512839390704 | validation: 0.02956580869005209]
	TIME [epoch: 6.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017513849765117565		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.017513849765117565 | validation: 0.02095588697711988]
	TIME [epoch: 6.47 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016010591791424264		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.016010591791424264 | validation: 0.029329481882201955]
	TIME [epoch: 6.46 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014636791394639033		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.014636791394639033 | validation: 0.029134609520826426]
	TIME [epoch: 6.46 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0134445815185192		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0134445815185192 | validation: 0.022233616638123878]
	TIME [epoch: 6.46 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011478664467577093		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.011478664467577093 | validation: 0.03297340111342291]
	TIME [epoch: 6.46 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013293110987363632		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.013293110987363632 | validation: 0.02460972368567388]
	TIME [epoch: 6.46 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01762521425312847		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.01762521425312847 | validation: 0.03381204745922093]
	TIME [epoch: 6.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012081634849072629		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.012081634849072629 | validation: 0.025076972402983577]
	TIME [epoch: 6.47 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017298087748936933		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.017298087748936933 | validation: 0.030180438716973432]
	TIME [epoch: 6.47 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014780690049094799		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.014780690049094799 | validation: 0.023158986516707804]
	TIME [epoch: 6.47 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01598320035892771		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.01598320035892771 | validation: 0.022247433488486967]
	TIME [epoch: 6.47 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014227675087007674		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.014227675087007674 | validation: 0.023883346136756484]
	TIME [epoch: 6.47 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014108793794161124		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.014108793794161124 | validation: 0.014831103440413194]
	TIME [epoch: 6.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01308404008382286		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.01308404008382286 | validation: 0.021864227323442335]
	TIME [epoch: 6.48 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016301255252052775		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.016301255252052775 | validation: 0.02705230949783773]
	TIME [epoch: 6.48 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01473930334885459		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.01473930334885459 | validation: 0.02514960362271656]
	TIME [epoch: 6.47 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011111759102066347		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.011111759102066347 | validation: 0.026659999335613388]
	TIME [epoch: 6.48 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014496819409846956		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.014496819409846956 | validation: 0.03134012657263619]
	TIME [epoch: 6.48 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011914814599182604		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.011914814599182604 | validation: 0.018468580202992024]
	TIME [epoch: 6.48 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015026630480841975		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.015026630480841975 | validation: 0.019386909951010285]
	TIME [epoch: 6.52 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012728631103704207		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.012728631103704207 | validation: 0.020049937631368513]
	TIME [epoch: 6.49 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010108951013928585		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.010108951013928585 | validation: 0.023212084703753688]
	TIME [epoch: 6.49 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017134259314196466		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.017134259314196466 | validation: 0.019833120560885674]
	TIME [epoch: 6.49 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012390876299684031		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.012390876299684031 | validation: 0.026094711710830044]
	TIME [epoch: 6.49 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014134709805756474		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.014134709805756474 | validation: 0.02244428206451161]
	TIME [epoch: 6.49 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015557688667300108		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.015557688667300108 | validation: 0.019490718475280677]
	TIME [epoch: 6.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01611259142360948		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.01611259142360948 | validation: 0.01872550636314462]
	TIME [epoch: 6.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011365083494311902		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.011365083494311902 | validation: 0.03017565030970344]
	TIME [epoch: 6.49 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014534773205433293		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.014534773205433293 | validation: 0.02622079613976662]
	TIME [epoch: 6.49 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014361286135306319		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.014361286135306319 | validation: 0.03222795350922528]
	TIME [epoch: 6.49 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010350311358180589		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.010350311358180589 | validation: 0.02336118032804695]
	TIME [epoch: 6.48 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01725123755949401		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.01725123755949401 | validation: 0.02527916594320913]
	TIME [epoch: 6.48 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012801837641800866		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.012801837641800866 | validation: 0.032491341337425365]
	TIME [epoch: 6.51 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014820435186808305		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.014820435186808305 | validation: 0.030196313694433978]
	TIME [epoch: 6.48 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01777546126197001		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.01777546126197001 | validation: 0.022962324613624272]
	TIME [epoch: 6.48 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009708185922447345		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.009708185922447345 | validation: 0.02191031218383221]
	TIME [epoch: 6.47 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013935382409351247		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.013935382409351247 | validation: 0.024940657089231825]
	TIME [epoch: 6.47 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015478454944285642		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.015478454944285642 | validation: 0.02444113637498154]
	TIME [epoch: 6.48 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01361366400815505		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.01361366400815505 | validation: 0.017084418351224512]
	TIME [epoch: 6.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01350532487462068		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.01350532487462068 | validation: 0.028462455668568656]
	TIME [epoch: 6.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011711924506774208		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.011711924506774208 | validation: 0.03174919934052823]
	TIME [epoch: 6.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696416695891052		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.01696416695891052 | validation: 0.026535032343491045]
	TIME [epoch: 6.48 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0156366549559756		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0156366549559756 | validation: 0.01723768362405986]
	TIME [epoch: 6.49 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014646563702247085		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.014646563702247085 | validation: 0.020210682357246185]
	TIME [epoch: 6.47 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01657645512203309		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.01657645512203309 | validation: 0.035256839902820615]
	TIME [epoch: 6.48 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014493712459157027		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.014493712459157027 | validation: 0.02152495211361076]
	TIME [epoch: 6.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01330543666584897		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.01330543666584897 | validation: 0.023518076970833066]
	TIME [epoch: 6.49 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01790268959597248		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.01790268959597248 | validation: 0.02733949863549302]
	TIME [epoch: 6.47 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014273796665265029		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.014273796665265029 | validation: 0.02302986360553569]
	TIME [epoch: 6.48 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017174194611259196		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.017174194611259196 | validation: 0.024205028145136493]
	TIME [epoch: 6.47 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014212472919450771		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.014212472919450771 | validation: 0.026404263670439385]
	TIME [epoch: 6.48 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014740506202991168		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.014740506202991168 | validation: 0.02651375650409436]
	TIME [epoch: 6.47 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01719593876779369		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.01719593876779369 | validation: 0.024876817507018437]
	TIME [epoch: 6.52 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016728437619912336		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.016728437619912336 | validation: 0.024283887759180972]
	TIME [epoch: 6.47 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014867918048628248		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.014867918048628248 | validation: 0.02343311001231961]
	TIME [epoch: 6.47 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018243951966681972		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.018243951966681972 | validation: 0.028738172728013232]
	TIME [epoch: 6.48 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017542837507725235		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.017542837507725235 | validation: 0.026352833503585558]
	TIME [epoch: 6.49 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013914709939337976		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.013914709939337976 | validation: 0.024040238929550303]
	TIME [epoch: 6.48 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015048155940497795		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.015048155940497795 | validation: 0.019640950225970163]
	TIME [epoch: 6.51 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012337415489178362		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.012337415489178362 | validation: 0.023763627608132668]
	TIME [epoch: 6.49 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017764073704638304		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.017764073704638304 | validation: 0.0253996568715287]
	TIME [epoch: 6.48 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014113932986316718		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.014113932986316718 | validation: 0.02808200256153686]
	TIME [epoch: 6.48 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012463953190451132		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.012463953190451132 | validation: 0.024604753621729227]
	TIME [epoch: 6.48 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014480752417042123		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.014480752417042123 | validation: 0.02030643271647129]
	TIME [epoch: 6.48 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011285684521212376		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.011285684521212376 | validation: 0.015818309452963343]
	TIME [epoch: 6.47 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015252163908829174		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.015252163908829174 | validation: 0.026247375711117096]
	TIME [epoch: 6.51 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01578095987755155		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.01578095987755155 | validation: 0.028491443504931237]
	TIME [epoch: 6.49 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01438261168837355		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.01438261168837355 | validation: 0.020275515914953926]
	TIME [epoch: 6.48 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014115330897605562		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.014115330897605562 | validation: 0.017338876347418854]
	TIME [epoch: 6.47 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014611411770102896		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.014611411770102896 | validation: 0.019176189246297486]
	TIME [epoch: 6.48 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010273989053147203		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.010273989053147203 | validation: 0.025799559838435272]
	TIME [epoch: 6.47 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011700156592067447		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.011700156592067447 | validation: 0.018686629902370064]
	TIME [epoch: 6.49 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01116700444419662		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.01116700444419662 | validation: 0.02852228732605165]
	TIME [epoch: 6.51 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013803022042800522		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.013803022042800522 | validation: 0.022814031865345478]
	TIME [epoch: 6.48 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014737338531189052		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.014737338531189052 | validation: 0.016061492826966495]
	TIME [epoch: 6.48 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009012966974758028		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.009012966974758028 | validation: 0.025217378804325223]
	TIME [epoch: 6.48 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011107187888548076		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.011107187888548076 | validation: 0.021556506472816254]
	TIME [epoch: 6.48 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013196920526307181		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.013196920526307181 | validation: 0.03194556301357203]
	TIME [epoch: 6.47 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013048037132493116		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.013048037132493116 | validation: 0.022769344559640334]
	TIME [epoch: 6.52 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015062607355318561		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.015062607355318561 | validation: 0.02736192636738141]
	TIME [epoch: 6.48 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019042093065764907		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.019042093065764907 | validation: 0.02345066833099505]
	TIME [epoch: 6.48 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017411482389256584		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.017411482389256584 | validation: 0.028718953995388832]
	TIME [epoch: 6.48 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015007564278828659		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.015007564278828659 | validation: 0.032896344883119606]
	TIME [epoch: 6.48 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014096226583533322		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.014096226583533322 | validation: 0.028082807880914055]
	TIME [epoch: 6.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01646689447216613		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.01646689447216613 | validation: 0.02372933790014675]
	TIME [epoch: 6.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012726078125392143		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.012726078125392143 | validation: 0.03755017724049609]
	TIME [epoch: 6.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932535724149993		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.01932535724149993 | validation: 0.022588929711410053]
	TIME [epoch: 6.48 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018780530768799035		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.018780530768799035 | validation: 0.024643200721585296]
	TIME [epoch: 6.47 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01647515655357979		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.01647515655357979 | validation: 0.03226341775457375]
	TIME [epoch: 6.48 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016404727990369572		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.016404727990369572 | validation: 0.03130348427926085]
	TIME [epoch: 6.47 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568025755362253		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.01568025755362253 | validation: 0.01658081072264606]
	TIME [epoch: 6.48 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199518689414713		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0199518689414713 | validation: 0.028561709833563553]
	TIME [epoch: 6.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018028795112493414		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.018028795112493414 | validation: 0.024357811954239555]
	TIME [epoch: 6.49 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01693196659317041		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.01693196659317041 | validation: 0.020487944409153965]
	TIME [epoch: 6.47 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014306417344756938		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.014306417344756938 | validation: 0.025704773660934724]
	TIME [epoch: 6.48 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017658698747689876		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.017658698747689876 | validation: 0.033875893896197724]
	TIME [epoch: 6.48 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013407000218992608		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.013407000218992608 | validation: 0.025108159821978428]
	TIME [epoch: 6.47 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01989458669248095		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.01989458669248095 | validation: 0.028335750505078243]
	TIME [epoch: 6.48 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019190290701433813		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.019190290701433813 | validation: 0.02685666071813976]
	TIME [epoch: 6.51 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01695460410562666		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.01695460410562666 | validation: 0.024801721152046326]
	TIME [epoch: 6.49 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0169090365229475		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.0169090365229475 | validation: 0.020621229594057083]
	TIME [epoch: 6.47 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016712716428919187		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.016712716428919187 | validation: 0.02648999390147515]
	TIME [epoch: 6.48 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018453830698985523		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.018453830698985523 | validation: 0.029433925498473127]
	TIME [epoch: 6.47 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013609000847401062		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.013609000847401062 | validation: 0.03371977653709285]
	TIME [epoch: 6.49 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012395044717629687		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.012395044717629687 | validation: 0.023044865778899845]
	TIME [epoch: 6.48 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016941722727382064		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.016941722727382064 | validation: 0.017809239283965425]
	TIME [epoch: 6.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960577728688654		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.01960577728688654 | validation: 0.029830544844756186]
	TIME [epoch: 6.47 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581999719751311		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.01581999719751311 | validation: 0.028030639431445428]
	TIME [epoch: 6.49 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0158406710500713		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.0158406710500713 | validation: 0.030156314844809896]
	TIME [epoch: 6.47 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01586814721625499		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.01586814721625499 | validation: 0.021783453352449824]
	TIME [epoch: 6.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012449527652666261		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.012449527652666261 | validation: 0.018946269862590355]
	TIME [epoch: 6.47 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018033922084209612		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.018033922084209612 | validation: 0.03575598697047261]
	TIME [epoch: 6.53 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012663073627245619		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.012663073627245619 | validation: 0.024473842023892876]
	TIME [epoch: 6.48 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017380700130459056		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.017380700130459056 | validation: 0.02188909360241978]
	TIME [epoch: 6.48 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015022891001024326		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.015022891001024326 | validation: 0.03049510817349413]
	TIME [epoch: 6.48 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011475846397089106		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.011475846397089106 | validation: 0.023899609853854163]
	TIME [epoch: 6.46 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013404834418593085		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.013404834418593085 | validation: 0.017969304180556384]
	TIME [epoch: 6.48 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01461555475445163		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.01461555475445163 | validation: 0.0309942106359991]
	TIME [epoch: 6.49 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011777772504913357		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.011777772504913357 | validation: 0.030906026170390427]
	TIME [epoch: 6.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011332291584086102		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.011332291584086102 | validation: 0.019336320170688478]
	TIME [epoch: 6.48 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01891469207210931		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.01891469207210931 | validation: 0.013608989875020228]
	TIME [epoch: 6.48 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011447372039520681		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.011447372039520681 | validation: 0.018599602865309917]
	TIME [epoch: 6.48 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013232254656409412		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.013232254656409412 | validation: 0.020663619269063415]
	TIME [epoch: 6.49 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011070869556832365		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.011070869556832365 | validation: 0.023239637119370587]
	TIME [epoch: 6.49 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01289204571257533		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.01289204571257533 | validation: 0.02512160793416637]
	TIME [epoch: 6.52 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013933041008324418		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.013933041008324418 | validation: 0.028367937543189333]
	TIME [epoch: 6.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013012931681557208		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.013012931681557208 | validation: 0.020427252752515175]
	TIME [epoch: 6.49 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0137166342685199		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0137166342685199 | validation: 0.020328322605670107]
	TIME [epoch: 6.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012471545512529941		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.012471545512529941 | validation: 0.02293112228752249]
	TIME [epoch: 6.49 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015291764421232777		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.015291764421232777 | validation: 0.02775159348115092]
	TIME [epoch: 6.49 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008859444475567704		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.008859444475567704 | validation: 0.023800156939963055]
	TIME [epoch: 6.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008199663741390032		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.008199663741390032 | validation: 0.023684767189851474]
	TIME [epoch: 6.51 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011870386595186373		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.011870386595186373 | validation: 0.022798690986499334]
	TIME [epoch: 6.49 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011397013913592402		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.011397013913592402 | validation: 0.023787604320942818]
	TIME [epoch: 6.48 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011643891769713623		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.011643891769713623 | validation: 0.03240696517588168]
	TIME [epoch: 6.47 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009238154597396415		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.009238154597396415 | validation: 0.01990438609144738]
	TIME [epoch: 6.48 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010609738376081368		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.010609738376081368 | validation: 0.02558109291584341]
	TIME [epoch: 6.48 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01647316453931485		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.01647316453931485 | validation: 0.023837469348729514]
	TIME [epoch: 6.51 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015691243056470468		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.015691243056470468 | validation: 0.023861786301956744]
	TIME [epoch: 6.49 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017870384886606916		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.017870384886606916 | validation: 0.018606047200868992]
	TIME [epoch: 6.48 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011212273337625422		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.011212273337625422 | validation: 0.02284585705415159]
	TIME [epoch: 6.48 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013687704147573688		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.013687704147573688 | validation: 0.019878515982332704]
	TIME [epoch: 6.47 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017548643153367245		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.017548643153367245 | validation: 0.023235715158452006]
	TIME [epoch: 6.48 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015452174560388925		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.015452174560388925 | validation: 0.022696353798890012]
	TIME [epoch: 6.47 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015072392314043453		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.015072392314043453 | validation: 0.030364742304960186]
	TIME [epoch: 6.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011570031470815503		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.011570031470815503 | validation: 0.02635486693814313]
	TIME [epoch: 6.47 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01017574612565851		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.01017574612565851 | validation: 0.024473492500884753]
	TIME [epoch: 6.47 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012932803417062828		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.012932803417062828 | validation: 0.024849875415418787]
	TIME [epoch: 6.46 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013246455775842682		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.013246455775842682 | validation: 0.03134326826357399]
	TIME [epoch: 6.47 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014099791578139337		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.014099791578139337 | validation: 0.01270247234424179]
	TIME [epoch: 6.46 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015851753532099565		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.015851753532099565 | validation: 0.020468437298124337]
	TIME [epoch: 6.48 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012248637888691252		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.012248637888691252 | validation: 0.03029953066422806]
	TIME [epoch: 6.48 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013293602231967324		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.013293602231967324 | validation: 0.023567060470414757]
	TIME [epoch: 6.46 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01307815356137835		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.01307815356137835 | validation: 0.022509492585745368]
	TIME [epoch: 6.46 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013203985176910854		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.013203985176910854 | validation: 0.027926180360152996]
	TIME [epoch: 6.46 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012064289030861892		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.012064289030861892 | validation: 0.020512749682795435]
	TIME [epoch: 6.47 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013072262935954936		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.013072262935954936 | validation: 0.023417081784130905]
	TIME [epoch: 6.46 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016547298734656046		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.016547298734656046 | validation: 0.02240157134597994]
	TIME [epoch: 6.52 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012426958165822384		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.012426958165822384 | validation: 0.025300143170261455]
	TIME [epoch: 6.49 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012481481461378284		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.012481481461378284 | validation: 0.028982174828512695]
	TIME [epoch: 6.47 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01042821668097881		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.01042821668097881 | validation: 0.02379812699827653]
	TIME [epoch: 6.48 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012248489947584764		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.012248489947584764 | validation: 0.01477642051735673]
	TIME [epoch: 6.45 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01262432196750769		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.01262432196750769 | validation: 0.018868342932775683]
	TIME [epoch: 6.46 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013974078145544409		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.013974078145544409 | validation: 0.022734263417129225]
	TIME [epoch: 6.47 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010523903311043192		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.010523903311043192 | validation: 0.022040071842525134]
	TIME [epoch: 6.49 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013774097670278729		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.013774097670278729 | validation: 0.020759369319920014]
	TIME [epoch: 6.46 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011048428721495245		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.011048428721495245 | validation: 0.026614122711440796]
	TIME [epoch: 6.46 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015284146585857576		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.015284146585857576 | validation: 0.020232601977973746]
	TIME [epoch: 6.47 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01406873675430483		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.01406873675430483 | validation: 0.02548577124788782]
	TIME [epoch: 6.46 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0125629126972386		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.0125629126972386 | validation: 0.02445302926874729]
	TIME [epoch: 6.46 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011860514946030553		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.011860514946030553 | validation: 0.023995289570245673]
	TIME [epoch: 6.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014922617743509944		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.014922617743509944 | validation: 0.01961389971991834]
	TIME [epoch: 6.49 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013202512185828488		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.013202512185828488 | validation: 0.017274718246149286]
	TIME [epoch: 6.48 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013075679984738083		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.013075679984738083 | validation: 0.02237256318488571]
	TIME [epoch: 6.47 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011448750437411587		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.011448750437411587 | validation: 0.015116475788830935]
	TIME [epoch: 6.46 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735497552343243		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.01735497552343243 | validation: 0.020478602695335368]
	TIME [epoch: 6.47 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010064532838415746		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.010064532838415746 | validation: 0.037186648696441595]
	TIME [epoch: 6.47 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01144692625130899		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.01144692625130899 | validation: 0.019902650614467433]
	TIME [epoch: 6.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011200737548506593		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.011200737548506593 | validation: 0.028644165757948918]
	TIME [epoch: 6.47 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016195894147563124		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.016195894147563124 | validation: 0.02053498896845277]
	TIME [epoch: 6.47 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012207467921082484		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.012207467921082484 | validation: 0.032459202238135816]
	TIME [epoch: 6.47 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016389343463064376		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.016389343463064376 | validation: 0.028163164122431104]
	TIME [epoch: 6.47 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01463079499715629		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.01463079499715629 | validation: 0.02668865368252856]
	TIME [epoch: 6.46 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011747352421660855		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.011747352421660855 | validation: 0.01800789690522038]
	TIME [epoch: 6.49 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017000409384164153		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.017000409384164153 | validation: 0.022176808834405887]
	TIME [epoch: 6.49 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011992947520860452		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.011992947520860452 | validation: 0.023817937672010372]
	TIME [epoch: 6.47 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012660954805322946		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.012660954805322946 | validation: 0.020968027892447755]
	TIME [epoch: 6.48 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015826887588851722		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.015826887588851722 | validation: 0.02856838214545328]
	TIME [epoch: 6.48 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015032660060275553		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.015032660060275553 | validation: 0.02090014305430394]
	TIME [epoch: 6.47 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010998348675646776		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.010998348675646776 | validation: 0.012957452665196736]
	TIME [epoch: 6.48 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018178362393614235		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.018178362393614235 | validation: 0.02290872760708297]
	TIME [epoch: 6.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013792076538765543		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.013792076538765543 | validation: 0.018404694394225225]
	TIME [epoch: 6.48 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016883549126737868		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.016883549126737868 | validation: 0.023581143072084237]
	TIME [epoch: 6.48 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017441846663944528		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.017441846663944528 | validation: 0.023933557519118864]
	TIME [epoch: 6.46 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01379841819776464		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.01379841819776464 | validation: 0.017734048867826972]
	TIME [epoch: 6.46 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010072005459601832		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.010072005459601832 | validation: 0.01913451036481214]
	TIME [epoch: 6.48 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011410012052804142		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.011410012052804142 | validation: 0.021833225814981042]
	TIME [epoch: 6.48 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011286436986462468		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.011286436986462468 | validation: 0.0333215708017081]
	TIME [epoch: 6.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016420968688954634		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.016420968688954634 | validation: 0.02754505118143101]
	TIME [epoch: 6.47 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011897402900619742		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.011897402900619742 | validation: 0.022909120859557996]
	TIME [epoch: 6.47 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011346862486541806		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.011346862486541806 | validation: 0.02165306700791112]
	TIME [epoch: 6.47 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013023557187209277		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.013023557187209277 | validation: 0.024608005442854654]
	TIME [epoch: 6.47 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01505280093845903		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.01505280093845903 | validation: 0.020779781918473732]
	TIME [epoch: 6.46 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013178410417746908		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.013178410417746908 | validation: 0.02465971210158915]
	TIME [epoch: 6.51 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01581250902475064		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.01581250902475064 | validation: 0.021707242261200035]
	TIME [epoch: 6.48 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010816233549612059		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.010816233549612059 | validation: 0.019686036312163823]
	TIME [epoch: 6.47 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015592923290920024		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.015592923290920024 | validation: 0.021786677285854927]
	TIME [epoch: 6.46 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01330112594524445		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.01330112594524445 | validation: 0.02980492458199416]
	TIME [epoch: 6.47 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015230553315107993		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.015230553315107993 | validation: 0.019924714103241533]
	TIME [epoch: 6.48 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01120456634373697		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.01120456634373697 | validation: 0.020957063787017036]
	TIME [epoch: 6.48 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01772674965860317		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.01772674965860317 | validation: 0.01892343711633196]
	TIME [epoch: 6.52 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013630428674583634		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.013630428674583634 | validation: 0.02418909090124163]
	TIME [epoch: 6.48 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014796833688350289		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.014796833688350289 | validation: 0.02192022958918014]
	TIME [epoch: 6.46 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01116249219434308		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.01116249219434308 | validation: 0.01682737737606551]
	TIME [epoch: 6.48 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012671099239154934		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.012671099239154934 | validation: 0.023446494838880252]
	TIME [epoch: 6.46 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01191625702655605		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.01191625702655605 | validation: 0.026640049875708463]
	TIME [epoch: 6.48 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015883875577129867		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.015883875577129867 | validation: 0.025537305826343337]
	TIME [epoch: 6.51 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012169423311026764		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.012169423311026764 | validation: 0.020721133761314965]
	TIME [epoch: 6.49 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014020873446805245		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.014020873446805245 | validation: 0.012278419743965556]
	TIME [epoch: 6.47 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013036381690664466		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.013036381690664466 | validation: 0.02161522075406924]
	TIME [epoch: 6.46 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018103365666302912		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.018103365666302912 | validation: 0.02985271226087103]
	TIME [epoch: 6.47 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013454455754339279		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.013454455754339279 | validation: 0.02944598599008934]
	TIME [epoch: 6.47 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017735759238015222		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.017735759238015222 | validation: 0.024383885286076597]
	TIME [epoch: 6.48 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01475074949501941		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.01475074949501941 | validation: 0.03011886362896835]
	TIME [epoch: 6.51 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014986374766613077		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.014986374766613077 | validation: 0.02485913985745386]
	TIME [epoch: 6.49 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013426307224923873		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.013426307224923873 | validation: 0.03228993893630534]
	TIME [epoch: 6.48 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015380372889154822		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.015380372889154822 | validation: 0.01831312787334061]
	TIME [epoch: 6.46 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015825586088671		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.015825586088671 | validation: 0.022409464399061302]
	TIME [epoch: 6.47 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012319806965101807		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.012319806965101807 | validation: 0.030553981896166874]
	TIME [epoch: 6.46 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012667710361132971		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.012667710361132971 | validation: 0.023393566397365513]
	TIME [epoch: 6.49 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013965451196388558		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.013965451196388558 | validation: 0.022132237384026282]
	TIME [epoch: 6.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015013611073223495		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.015013611073223495 | validation: 0.017858786798593502]
	TIME [epoch: 6.48 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014216655027465924		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.014216655027465924 | validation: 0.027711280651890643]
	TIME [epoch: 6.47 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588181927913227		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.01588181927913227 | validation: 0.031225682522355944]
	TIME [epoch: 6.48 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014376083782011172		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.014376083782011172 | validation: 0.024765887070461904]
	TIME [epoch: 6.47 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012428567555897323		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.012428567555897323 | validation: 0.01876158687750644]
	TIME [epoch: 6.47 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012019028586968548		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.012019028586968548 | validation: 0.018523188995774112]
	TIME [epoch: 6.51 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013904728647263418		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.013904728647263418 | validation: 0.020274348550083712]
	TIME [epoch: 6.48 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011855138458039285		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.011855138458039285 | validation: 0.027463183941536223]
	TIME [epoch: 6.47 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010583440095796214		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.010583440095796214 | validation: 0.027822326855540952]
	TIME [epoch: 6.47 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008659832842329874		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.008659832842329874 | validation: 0.017206924746080553]
	TIME [epoch: 6.47 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011378213074858643		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.011378213074858643 | validation: 0.02303555562495953]
	TIME [epoch: 6.47 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012249558486914867		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.012249558486914867 | validation: 0.01907240086376678]
	TIME [epoch: 6.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010423222842365657		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.010423222842365657 | validation: 0.032511097437728224]
	TIME [epoch: 6.51 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011281858918106073		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.011281858918106073 | validation: 0.015295172696821036]
	TIME [epoch: 6.48 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012271172322357693		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.012271172322357693 | validation: 0.019667727646189005]
	TIME [epoch: 6.47 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013406449417687608		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.013406449417687608 | validation: 0.020911355515421556]
	TIME [epoch: 6.48 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013748447749296495		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.013748447749296495 | validation: 0.022815823626003855]
	TIME [epoch: 6.46 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017119266993070995		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.017119266993070995 | validation: 0.020997365450197182]
	TIME [epoch: 6.46 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014416047189220012		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.014416047189220012 | validation: 0.01838550824809168]
	TIME [epoch: 6.48 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014397242473272207		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.014397242473272207 | validation: 0.024911698427876137]
	TIME [epoch: 6.47 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014250446954074939		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.014250446954074939 | validation: 0.03035086096652016]
	TIME [epoch: 6.47 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009901829761827751		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.009901829761827751 | validation: 0.014247230797177369]
	TIME [epoch: 6.46 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01332105465131206		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.01332105465131206 | validation: 0.01658861607920886]
	TIME [epoch: 6.47 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010726239160680138		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.010726239160680138 | validation: 0.023291906409739473]
	TIME [epoch: 6.47 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011839457255924571		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.011839457255924571 | validation: 0.01728697494858868]
	TIME [epoch: 6.47 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015806677176500056		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.015806677176500056 | validation: 0.021439366630153164]
	TIME [epoch: 6.51 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01376704850973165		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.01376704850973165 | validation: 0.018297627906927058]
	TIME [epoch: 6.46 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015449357561872466		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.015449357561872466 | validation: 0.025575580021360338]
	TIME [epoch: 6.48 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013828363289333546		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.013828363289333546 | validation: 0.0223486595279598]
	TIME [epoch: 6.47 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012783660336827053		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.012783660336827053 | validation: 0.023221398919102902]
	TIME [epoch: 6.47 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012175921120298496		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.012175921120298496 | validation: 0.023799746697455628]
	TIME [epoch: 6.46 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014101671376250888		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.014101671376250888 | validation: 0.02546503426945698]
	TIME [epoch: 6.48 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015639690137443298		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.015639690137443298 | validation: 0.018951879556054957]
	TIME [epoch: 6.48 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014796388095924618		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.014796388095924618 | validation: 0.027870131822295825]
	TIME [epoch: 6.48 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00946313795240406		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.00946313795240406 | validation: 0.01787216557522678]
	TIME [epoch: 6.48 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016838589077633578		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.016838589077633578 | validation: 0.028503310755539482]
	TIME [epoch: 6.46 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759202111954212		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.014759202111954212 | validation: 0.02457173024614293]
	TIME [epoch: 6.47 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015584377973212958		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.015584377973212958 | validation: 0.025410029089072618]
	TIME [epoch: 6.46 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011168740228449416		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.011168740228449416 | validation: 0.02538022558227802]
	TIME [epoch: 6.51 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013641367997634296		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.013641367997634296 | validation: 0.016008076694856998]
	TIME [epoch: 6.47 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015280256466647752		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.015280256466647752 | validation: 0.02293293780316251]
	TIME [epoch: 6.46 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011953263415361152		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.011953263415361152 | validation: 0.026570997533993605]
	TIME [epoch: 6.46 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018441041471303807		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.018441041471303807 | validation: 0.017442198233181726]
	TIME [epoch: 6.47 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015475017520099322		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.015475017520099322 | validation: 0.024645965538128395]
	TIME [epoch: 6.46 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010505675621442084		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.010505675621442084 | validation: 0.008742831459796749]
	TIME [epoch: 6.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016198493024345298		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.016198493024345298 | validation: 0.028174985351820496]
	TIME [epoch: 6.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013618420416314891		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.013618420416314891 | validation: 0.027975442903842265]
	TIME [epoch: 6.48 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013272359836936667		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.013272359836936667 | validation: 0.024667737102291105]
	TIME [epoch: 6.48 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010720817899085485		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.010720817899085485 | validation: 0.030229883795714417]
	TIME [epoch: 6.48 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012640210146066332		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.012640210146066332 | validation: 0.016143131680226616]
	TIME [epoch: 6.47 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01318157911288429		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.01318157911288429 | validation: 0.027117634894119474]
	TIME [epoch: 6.48 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015068152461661528		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.015068152461661528 | validation: 0.026643339339701796]
	TIME [epoch: 6.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010230614731825082		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.010230614731825082 | validation: 0.01862141165993935]
	TIME [epoch: 6.49 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01502549405517671		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.01502549405517671 | validation: 0.024086065631613893]
	TIME [epoch: 6.49 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011611636276612122		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.011611636276612122 | validation: 0.02224425203344138]
	TIME [epoch: 6.49 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014564350253945502		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.014564350253945502 | validation: 0.028248017584249496]
	TIME [epoch: 6.47 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011132315886548486		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.011132315886548486 | validation: 0.02018602660860794]
	TIME [epoch: 6.48 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013355664843247579		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.013355664843247579 | validation: 0.028591240018446495]
	TIME [epoch: 6.49 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013159519751697317		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.013159519751697317 | validation: 0.02706844604190196]
	TIME [epoch: 6.53 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014515704287570305		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.014515704287570305 | validation: 0.026034021391740114]
	TIME [epoch: 6.49 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010679082225938597		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.010679082225938597 | validation: 0.029046483399783662]
	TIME [epoch: 6.49 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011997880116756312		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.011997880116756312 | validation: 0.02174145101442096]
	TIME [epoch: 6.49 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759922051850487		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.014759922051850487 | validation: 0.023796318435996167]
	TIME [epoch: 6.47 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012156986305180703		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.012156986305180703 | validation: 0.019427010758948666]
	TIME [epoch: 6.49 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009054363966121234		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.009054363966121234 | validation: 0.022125976930458396]
	TIME [epoch: 6.51 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01389961629003597		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.01389961629003597 | validation: 0.020237512566486014]
	TIME [epoch: 6.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015774454785934776		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.015774454785934776 | validation: 0.029821136651582595]
	TIME [epoch: 6.48 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014537685812315588		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.014537685812315588 | validation: 0.02890544205558069]
	TIME [epoch: 6.47 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011360073905199193		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.011360073905199193 | validation: 0.02401737998959241]
	TIME [epoch: 6.48 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01246873175102705		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.01246873175102705 | validation: 0.019137562326741065]
	TIME [epoch: 6.47 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015911435001844138		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.015911435001844138 | validation: 0.018504947063279306]
	TIME [epoch: 6.48 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013585279847427148		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.013585279847427148 | validation: 0.024743971184273655]
	TIME [epoch: 6.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012276287535359373		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.012276287535359373 | validation: 0.027396875234668633]
	TIME [epoch: 6.49 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011025919394362128		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.011025919394362128 | validation: 0.01724810214538006]
	TIME [epoch: 6.46 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01388748217218211		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.01388748217218211 | validation: 0.03712384509396282]
	TIME [epoch: 6.48 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01170105863960052		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.01170105863960052 | validation: 0.021083074829024922]
	TIME [epoch: 6.47 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008959618830589036		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.008959618830589036 | validation: 0.01751514540744061]
	TIME [epoch: 6.48 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015547482666467887		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.015547482666467887 | validation: 0.022651722488366246]
	TIME [epoch: 6.49 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009468909160843378		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.009468909160843378 | validation: 0.028034549978737996]
	TIME [epoch: 6.52 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010674321410878016		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.010674321410878016 | validation: 0.01938213508269732]
	TIME [epoch: 6.47 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011922772782808668		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.011922772782808668 | validation: 0.020142791135090606]
	TIME [epoch: 6.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012610282895805257		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.012610282895805257 | validation: 0.019795379631406082]
	TIME [epoch: 6.47 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016150936889781004		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.016150936889781004 | validation: 0.0218605774409862]
	TIME [epoch: 6.48 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013256008089879931		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.013256008089879931 | validation: 0.028640051192760137]
	TIME [epoch: 6.47 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015213029952790684		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.015213029952790684 | validation: 0.019757727276494056]
	TIME [epoch: 6.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014023596127031622		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.014023596127031622 | validation: 0.022289236528744007]
	TIME [epoch: 6.47 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00951539619777272		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.00951539619777272 | validation: 0.030115712401845116]
	TIME [epoch: 6.46 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01255051936819489		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.01255051936819489 | validation: 0.02414172401966287]
	TIME [epoch: 6.47 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013683731183265619		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.013683731183265619 | validation: 0.017002874665460622]
	TIME [epoch: 6.48 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011206003958008295		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.011206003958008295 | validation: 0.011545028514823285]
	TIME [epoch: 6.48 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01156715637136637		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.01156715637136637 | validation: 0.01860793206174071]
	TIME [epoch: 6.49 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01276622908873112		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.01276622908873112 | validation: 0.02201986329618953]
	TIME [epoch: 6.51 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011562437601444472		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.011562437601444472 | validation: 0.018816556914822157]
	TIME [epoch: 6.49 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013566919536195002		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.013566919536195002 | validation: 0.020247860376188292]
	TIME [epoch: 6.49 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01214330542327202		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.01214330542327202 | validation: 0.014748427924845032]
	TIME [epoch: 6.48 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012962529939188751		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.012962529939188751 | validation: 0.017255178722930024]
	TIME [epoch: 6.48 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016407222073508552		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.016407222073508552 | validation: 0.017531334633187273]
	TIME [epoch: 6.48 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010294192115775608		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.010294192115775608 | validation: 0.025061564920085776]
	TIME [epoch: 6.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010426203146403183		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.010426203146403183 | validation: 0.021376850396341917]
	TIME [epoch: 6.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011548062280091248		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.011548062280091248 | validation: 0.024399208753857878]
	TIME [epoch: 6.49 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011870533686862651		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.011870533686862651 | validation: 0.029558943444690563]
	TIME [epoch: 6.49 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01430223624939903		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.01430223624939903 | validation: 0.028964870682971943]
	TIME [epoch: 6.49 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011527669453500606		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.011527669453500606 | validation: 0.019645831270817066]
	TIME [epoch: 6.49 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010221875433330972		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.010221875433330972 | validation: 0.019851129171673098]
	TIME [epoch: 6.49 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011138798081846537		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.011138798081846537 | validation: 0.02195447893673661]
	TIME [epoch: 6.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01341566046848903		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.01341566046848903 | validation: 0.026148634118864377]
	TIME [epoch: 6.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013709812673916504		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.013709812673916504 | validation: 0.014962604788305783]
	TIME [epoch: 6.49 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013578278520596093		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.013578278520596093 | validation: 0.02552642868493314]
	TIME [epoch: 6.48 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015947501099807415		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.015947501099807415 | validation: 0.019083934508290948]
	TIME [epoch: 6.48 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00788451329873946		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.00788451329873946 | validation: 0.017476804492387473]
	TIME [epoch: 6.49 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01732260446075174		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.01732260446075174 | validation: 0.018757186659097317]
	TIME [epoch: 6.51 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016471746325429637		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.016471746325429637 | validation: 0.024043137874487384]
	TIME [epoch: 6.49 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011498410193697592		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.011498410193697592 | validation: 0.017466668307317912]
	TIME [epoch: 6.48 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01600764997055252		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.01600764997055252 | validation: 0.0243759090210132]
	TIME [epoch: 6.49 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016851959098202106		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.016851959098202106 | validation: 0.027673960955142008]
	TIME [epoch: 6.48 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009842053359445877		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.009842053359445877 | validation: 0.023486557654442148]
	TIME [epoch: 6.48 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012844276277275439		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.012844276277275439 | validation: 0.02838443393415089]
	TIME [epoch: 6.48 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01091794940733443		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.01091794940733443 | validation: 0.021378638028982745]
	TIME [epoch: 6.52 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012899933842891002		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.012899933842891002 | validation: 0.021209762978871848]
	TIME [epoch: 6.49 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009878893159252937		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.009878893159252937 | validation: 0.02786259522130511]
	TIME [epoch: 6.49 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008544799273342804		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.008544799273342804 | validation: 0.028841268090415123]
	TIME [epoch: 6.48 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011049009012174055		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.011049009012174055 | validation: 0.020366263043615263]
	TIME [epoch: 6.48 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010599584571706648		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.010599584571706648 | validation: 0.024872616850154718]
	TIME [epoch: 6.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011582862136724902		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.011582862136724902 | validation: 0.02470605773573391]
	TIME [epoch: 6.48 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014827204816127891		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.014827204816127891 | validation: 0.018359171188588007]
	TIME [epoch: 6.51 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015224354226427594		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.015224354226427594 | validation: 0.021408528735358087]
	TIME [epoch: 6.48 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01149472642925779		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.01149472642925779 | validation: 0.02250325128891956]
	TIME [epoch: 6.48 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01475653733948621		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.01475653733948621 | validation: 0.02399825987761957]
	TIME [epoch: 6.48 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012852776115855856		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.012852776115855856 | validation: 0.023732306585344407]
	TIME [epoch: 6.48 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010672936625069476		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.010672936625069476 | validation: 0.02229187958982945]
	TIME [epoch: 6.48 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014172698617473648		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.014172698617473648 | validation: 0.0232605833479418]
	TIME [epoch: 6.52 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010599314193203532		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.010599314193203532 | validation: 0.022537275027712342]
	TIME [epoch: 6.48 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010383388723830244		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.010383388723830244 | validation: 0.023486093332265784]
	TIME [epoch: 6.48 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00849065702487773		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.00849065702487773 | validation: 0.02735617082335244]
	TIME [epoch: 6.47 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013368926258878897		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.013368926258878897 | validation: 0.02433567809802974]
	TIME [epoch: 6.48 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013031770914229789		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.013031770914229789 | validation: 0.0235093340125827]
	TIME [epoch: 6.48 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012801849196852177		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.012801849196852177 | validation: 0.021958782808543163]
	TIME [epoch: 6.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01331440128345274		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.01331440128345274 | validation: 0.023606837465303853]
	TIME [epoch: 6.51 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015476376582497765		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.015476376582497765 | validation: 0.03370332006043302]
	TIME [epoch: 6.47 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013210256323132944		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.013210256323132944 | validation: 0.02862744770450707]
	TIME [epoch: 6.47 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011405748395767759		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.011405748395767759 | validation: 0.025079480009321413]
	TIME [epoch: 6.48 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014885521546945276		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.014885521546945276 | validation: 0.022206941370324834]
	TIME [epoch: 6.48 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008673868741685936		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.008673868741685936 | validation: 0.026675777370491472]
	TIME [epoch: 6.48 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013478941548598036		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.013478941548598036 | validation: 0.02366483763969474]
	TIME [epoch: 6.51 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010813443910280576		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.010813443910280576 | validation: 0.021444859731855805]
	TIME [epoch: 6.49 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01285753139606161		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.01285753139606161 | validation: 0.026306851366571765]
	TIME [epoch: 6.48 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014184695085034275		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.014184695085034275 | validation: 0.028823691104615818]
	TIME [epoch: 6.48 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011020128342394811		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.011020128342394811 | validation: 0.02475425441563033]
	TIME [epoch: 6.47 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015460706136659463		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.015460706136659463 | validation: 0.021331783490954298]
	TIME [epoch: 6.48 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012214088729761732		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.012214088729761732 | validation: 0.01647088352987358]
	TIME [epoch: 6.49 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013735003917266444		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.013735003917266444 | validation: 0.022449901039276736]
	TIME [epoch: 6.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017408379274431895		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.017408379274431895 | validation: 0.015901559791772605]
	TIME [epoch: 6.48 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014763081309080106		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.014763081309080106 | validation: 0.02743854621107999]
	TIME [epoch: 6.48 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014983999614561667		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.014983999614561667 | validation: 0.024688982494745965]
	TIME [epoch: 6.48 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013528213092180802		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.013528213092180802 | validation: 0.027619653889533847]
	TIME [epoch: 6.48 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014990855693032209		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.014990855693032209 | validation: 0.013611346293255]
	TIME [epoch: 6.48 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01074630755775553		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.01074630755775553 | validation: 0.023986573168006623]
	TIME [epoch: 6.51 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00996135988987372		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.00996135988987372 | validation: 0.015176734214570244]
	TIME [epoch: 6.49 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012808845774013103		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.012808845774013103 | validation: 0.02468776508179599]
	TIME [epoch: 6.48 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01351063063441554		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.01351063063441554 | validation: 0.02297020224181214]
	TIME [epoch: 6.47 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011549363342799534		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.011549363342799534 | validation: 0.027567617554311426]
	TIME [epoch: 6.47 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013097412783836825		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.013097412783836825 | validation: 0.031084071474599222]
	TIME [epoch: 6.47 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0122526980437628		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.0122526980437628 | validation: 0.027999338367525894]
	TIME [epoch: 6.47 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010333623866224878		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.010333623866224878 | validation: 0.030840842720548062]
	TIME [epoch: 6.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011893947042557435		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.011893947042557435 | validation: 0.023220819395915374]
	TIME [epoch: 6.47 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01568202559129153		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.01568202559129153 | validation: 0.025659581843485303]
	TIME [epoch: 6.47 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012790200148608094		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.012790200148608094 | validation: 0.02036160385389329]
	TIME [epoch: 6.47 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011602418569096542		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.011602418569096542 | validation: 0.01970325407684803]
	TIME [epoch: 6.47 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015933699431069353		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.015933699431069353 | validation: 0.029569991937375795]
	TIME [epoch: 6.47 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012643367923562306		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.012643367923562306 | validation: 0.019462597543176436]
	TIME [epoch: 6.48 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013199432692676035		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.013199432692676035 | validation: 0.023545218325469568]
	TIME [epoch: 6.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01657593235244346		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.01657593235244346 | validation: 0.02329520114191806]
	TIME [epoch: 6.47 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013275858749987286		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.013275858749987286 | validation: 0.025565584221226772]
	TIME [epoch: 6.47 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011983657506739978		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.011983657506739978 | validation: 0.019728711149339103]
	TIME [epoch: 6.47 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014428656217157429		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.014428656217157429 | validation: 0.021025591729119185]
	TIME [epoch: 6.47 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014267367985832669		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.014267367985832669 | validation: 0.024463571479851433]
	TIME [epoch: 6.47 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015093626488422121		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.015093626488422121 | validation: 0.023821201751605747]
	TIME [epoch: 6.51 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01243902877905656		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.01243902877905656 | validation: 0.022417939666660232]
	TIME [epoch: 6.48 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012284255867300854		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.012284255867300854 | validation: 0.032705897785293106]
	TIME [epoch: 6.47 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01416203182916256		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.01416203182916256 | validation: 0.02459848524484545]
	TIME [epoch: 6.46 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012273841565635046		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.012273841565635046 | validation: 0.029546093675536813]
	TIME [epoch: 6.47 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011115271258343381		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.011115271258343381 | validation: 0.02453757362286421]
	TIME [epoch: 6.46 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014028334637387653		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.014028334637387653 | validation: 0.022091498114635573]
	TIME [epoch: 6.48 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014212100848739632		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.014212100848739632 | validation: 0.022579412594626796]
	TIME [epoch: 6.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015185782228120413		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.015185782228120413 | validation: 0.020829759808127575]
	TIME [epoch: 6.47 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013241667124180553		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.013241667124180553 | validation: 0.022587344991746524]
	TIME [epoch: 6.48 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011307739859587738		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.011307739859587738 | validation: 0.03016727789027297]
	TIME [epoch: 6.46 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014639491526053046		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.014639491526053046 | validation: 0.01921042214884423]
	TIME [epoch: 6.48 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013155921210401354		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.013155921210401354 | validation: 0.023338775648123998]
	TIME [epoch: 6.47 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010869515066558842		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.010869515066558842 | validation: 0.024602863188883894]
	TIME [epoch: 6.51 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012968227840847776		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.012968227840847776 | validation: 0.01949907499746807]
	TIME [epoch: 6.48 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01162492028949153		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.01162492028949153 | validation: 0.031678301154023876]
	TIME [epoch: 6.48 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010549186772155487		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.010549186772155487 | validation: 0.02532295168256457]
	TIME [epoch: 6.46 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012773728120537974		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.012773728120537974 | validation: 0.028440344579323523]
	TIME [epoch: 6.47 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007768779229948193		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.007768779229948193 | validation: 0.02295470250221771]
	TIME [epoch: 6.46 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011750434450279163		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.011750434450279163 | validation: 0.015848741261763215]
	TIME [epoch: 6.48 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013296922709085368		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.013296922709085368 | validation: 0.02377128800916598]
	TIME [epoch: 6.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011158695220643592		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.011158695220643592 | validation: 0.026053677587338456]
	TIME [epoch: 6.48 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014314592940434525		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.014314592940434525 | validation: 0.0259699249188896]
	TIME [epoch: 6.48 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009954689719891075		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.009954689719891075 | validation: 0.024590964138630832]
	TIME [epoch: 6.46 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013177001384032312		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.013177001384032312 | validation: 0.016162420544590515]
	TIME [epoch: 6.47 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015547823547466786		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.015547823547466786 | validation: 0.029145056771187155]
	TIME [epoch: 6.47 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012600217673042289		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.012600217673042289 | validation: 0.023487412314152075]
	TIME [epoch: 6.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013260268482486702		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.013260268482486702 | validation: 0.027671468658414612]
	TIME [epoch: 6.47 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012032826216754583		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.012032826216754583 | validation: 0.02211073728694433]
	TIME [epoch: 6.47 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009806700001648436		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.009806700001648436 | validation: 0.02544025945755615]
	TIME [epoch: 6.47 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855772392323858		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.01855772392323858 | validation: 0.01892452420678488]
	TIME [epoch: 6.47 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011682742551150177		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.011682742551150177 | validation: 0.020916329209374453]
	TIME [epoch: 6.47 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013813671819894884		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.013813671819894884 | validation: 0.028559271195890707]
	TIME [epoch: 6.47 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012359498771392932		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.012359498771392932 | validation: 0.017588340668524025]
	TIME [epoch: 6.52 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012481426600863172		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.012481426600863172 | validation: 0.023369651613274416]
	TIME [epoch: 6.47 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013755174159806916		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.013755174159806916 | validation: 0.020568969581596378]
	TIME [epoch: 6.47 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010742435183956466		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.010742435183956466 | validation: 0.016347857420219394]
	TIME [epoch: 6.49 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012200238715074066		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.012200238715074066 | validation: 0.0157663155284882]
	TIME [epoch: 6.49 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012822681527900226		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.012822681527900226 | validation: 0.01699674125694503]
	TIME [epoch: 6.49 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01002639028963975		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.01002639028963975 | validation: 0.019857496892769767]
	TIME [epoch: 6.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015472390344613198		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.015472390344613198 | validation: 0.023933980247081356]
	TIME [epoch: 6.52 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014092139260233021		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.014092139260233021 | validation: 0.026069980449188828]
	TIME [epoch: 6.49 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012066776538142998		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.012066776538142998 | validation: 0.02218431940125445]
	TIME [epoch: 6.48 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013315272780823324		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.013315272780823324 | validation: 0.02141753104886323]
	TIME [epoch: 6.49 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011720382733123388		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.011720382733123388 | validation: 0.020888406710715013]
	TIME [epoch: 6.49 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015765227200805483		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.015765227200805483 | validation: 0.025561803174569537]
	TIME [epoch: 6.49 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008148980265955463		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.008148980265955463 | validation: 0.027831396719027245]
	TIME [epoch: 6.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016134933043490687		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.016134933043490687 | validation: 0.022157979651777675]
	TIME [epoch: 6.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011542857540703192		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.011542857540703192 | validation: 0.023417378858732227]
	TIME [epoch: 6.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012917356379091388		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.012917356379091388 | validation: 0.021952794616657306]
	TIME [epoch: 6.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01345389796911645		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.01345389796911645 | validation: 0.018850236490570535]
	TIME [epoch: 6.49 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012314244326132703		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.012314244326132703 | validation: 0.02733451058856677]
	TIME [epoch: 6.49 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015188082512987667		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.015188082512987667 | validation: 0.02375218797491926]
	TIME [epoch: 6.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011736588272185627		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.011736588272185627 | validation: 0.030408264982843828]
	TIME [epoch: 6.52 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01102923580312376		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.01102923580312376 | validation: 0.017268841891696855]
	TIME [epoch: 6.49 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015992190840280134		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.015992190840280134 | validation: 0.01672186984000016]
	TIME [epoch: 6.49 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012495727707439508		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.012495727707439508 | validation: 0.020043684962695946]
	TIME [epoch: 6.49 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011546331971110862		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.011546331971110862 | validation: 0.027653581356212174]
	TIME [epoch: 6.49 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01267189860643797		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.01267189860643797 | validation: 0.017803181532693363]
	TIME [epoch: 6.49 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014385791174411189		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.014385791174411189 | validation: 0.021739490614519436]
	TIME [epoch: 6.53 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013165564463691107		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.013165564463691107 | validation: 0.019023255144639237]
	TIME [epoch: 6.49 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01266234257270683		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.01266234257270683 | validation: 0.022842699385602093]
	TIME [epoch: 6.49 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012131652006653705		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.012131652006653705 | validation: 0.021632379117195823]
	TIME [epoch: 6.49 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013527607424762948		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.013527607424762948 | validation: 0.01960647984908663]
	TIME [epoch: 6.49 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012014422075312869		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.012014422075312869 | validation: 0.01975508709614801]
	TIME [epoch: 6.48 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013050466867844933		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.013050466867844933 | validation: 0.024388348956125308]
	TIME [epoch: 6.49 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014050683422942894		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.014050683422942894 | validation: 0.02105199001539885]
	TIME [epoch: 6.52 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01228585247570246		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.01228585247570246 | validation: 0.021228558781128806]
	TIME [epoch: 6.48 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01086330580792174		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.01086330580792174 | validation: 0.022627729357911006]
	TIME [epoch: 6.48 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011002290208410157		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.011002290208410157 | validation: 0.02127653886441927]
	TIME [epoch: 6.49 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013287051960060456		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.013287051960060456 | validation: 0.024607082130767257]
	TIME [epoch: 6.49 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013241171750391462		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.013241171750391462 | validation: 0.02334964550697248]
	TIME [epoch: 6.48 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013102316070295184		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.013102316070295184 | validation: 0.015926108026576406]
	TIME [epoch: 6.52 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011404665374817852		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.011404665374817852 | validation: 0.014904222751240074]
	TIME [epoch: 6.49 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01565529429635852		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.01565529429635852 | validation: 0.022059641827849693]
	TIME [epoch: 6.49 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012994083147892764		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.012994083147892764 | validation: 0.022841529154854504]
	TIME [epoch: 6.49 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01151366531495945		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.01151366531495945 | validation: 0.028534347250221456]
	TIME [epoch: 6.48 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013035862627105831		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.013035862627105831 | validation: 0.019219924278085145]
	TIME [epoch: 6.48 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011767021688131842		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.011767021688131842 | validation: 0.018106818438069078]
	TIME [epoch: 6.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013499279067451193		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.013499279067451193 | validation: 0.02109992537307218]
	TIME [epoch: 6.52 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011919633583831229		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.011919633583831229 | validation: 0.017195260066670433]
	TIME [epoch: 6.49 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015541223417787896		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.015541223417787896 | validation: 0.028085204545558132]
	TIME [epoch: 6.48 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01272087085822543		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.01272087085822543 | validation: 0.023587403431251968]
	TIME [epoch: 6.47 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011565521369858339		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.011565521369858339 | validation: 0.01882382194654697]
	TIME [epoch: 6.49 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013895594292513804		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.013895594292513804 | validation: 0.01941236455599434]
	TIME [epoch: 6.49 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015620785687667877		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.015620785687667877 | validation: 0.01936936595586791]
	TIME [epoch: 6.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011609419326066097		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.011609419326066097 | validation: 0.021772333361376354]
	TIME [epoch: 6.51 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01222467245311506		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.01222467245311506 | validation: 0.020969870766752014]
	TIME [epoch: 6.49 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759395371805496		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.014759395371805496 | validation: 0.022848932807438906]
	TIME [epoch: 6.47 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014879048845906018		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.014879048845906018 | validation: 0.022428691865906247]
	TIME [epoch: 6.47 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014755315677801332		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.014755315677801332 | validation: 0.02831132149403913]
	TIME [epoch: 6.46 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011542180613726815		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.011542180613726815 | validation: 0.02149538610193787]
	TIME [epoch: 6.47 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010032597674776466		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.010032597674776466 | validation: 0.031234687395856053]
	TIME [epoch: 6.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012772562014874714		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.012772562014874714 | validation: 0.02451251638610537]
	TIME [epoch: 6.47 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009341821581125419		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.009341821581125419 | validation: 0.013860374348949598]
	TIME [epoch: 6.48 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013438251685395497		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.013438251685395497 | validation: 0.029018966268832953]
	TIME [epoch: 6.46 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012254501092874785		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.012254501092874785 | validation: 0.02841094348368752]
	TIME [epoch: 6.46 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009749829113915007		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.009749829113915007 | validation: 0.01841536990905749]
	TIME [epoch: 6.46 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011051497043361835		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.011051497043361835 | validation: 0.033002480114459054]
	TIME [epoch: 6.49 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0100937327018976		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.0100937327018976 | validation: 0.02269213963470752]
	TIME [epoch: 6.51 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009015170359055732		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.009015170359055732 | validation: 0.022428630602058294]
	TIME [epoch: 6.48 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014179051993723112		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.014179051993723112 | validation: 0.02756650742241595]
	TIME [epoch: 6.47 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012076227638461027		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.012076227638461027 | validation: 0.02494605803288071]
	TIME [epoch: 6.46 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01197335657582671		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.01197335657582671 | validation: 0.027978167552629777]
	TIME [epoch: 6.47 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01088827788950458		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.01088827788950458 | validation: 0.022435956271793622]
	TIME [epoch: 6.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009627994075821064		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.009627994075821064 | validation: 0.014424809503000359]
	TIME [epoch: 6.51 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012373465086219983		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.012373465086219983 | validation: 0.023465117210425407]
	TIME [epoch: 6.48 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009744694561409003		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.009744694561409003 | validation: 0.018484712434537826]
	TIME [epoch: 6.47 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010867725626679437		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.010867725626679437 | validation: 0.0180990801390246]
	TIME [epoch: 6.47 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01135184466637829		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.01135184466637829 | validation: 0.019119693618454302]
	TIME [epoch: 6.46 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011741135269472996		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.011741135269472996 | validation: 0.023463359384964643]
	TIME [epoch: 6.47 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012411519720256498		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.012411519720256498 | validation: 0.023551453751601104]
	TIME [epoch: 6.47 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011090190216221932		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.011090190216221932 | validation: 0.01725831635364639]
	TIME [epoch: 6.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012620568779465413		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.012620568779465413 | validation: 0.03290754192942338]
	TIME [epoch: 6.47 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011523940825022623		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.011523940825022623 | validation: 0.023172885547629477]
	TIME [epoch: 6.47 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0108082557974428		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.0108082557974428 | validation: 0.03025732525656086]
	TIME [epoch: 6.47 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012160898380445824		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.012160898380445824 | validation: 0.018944923486196866]
	TIME [epoch: 6.48 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013552168016934905		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.013552168016934905 | validation: 0.020538401494581554]
	TIME [epoch: 6.47 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013662698482666265		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.013662698482666265 | validation: 0.020047406941210235]
	TIME [epoch: 6.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01091410953824		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.01091410953824 | validation: 0.021635060156052606]
	TIME [epoch: 6.48 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013095603473786877		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.013095603473786877 | validation: 0.019228424331323518]
	TIME [epoch: 6.48 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0145848179827155		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.0145848179827155 | validation: 0.023358844851380206]
	TIME [epoch: 6.49 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01300139713256859		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.01300139713256859 | validation: 0.021692940557136667]
	TIME [epoch: 6.48 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012120588408911916		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.012120588408911916 | validation: 0.02090073234453508]
	TIME [epoch: 6.47 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009860737325372168		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.009860737325372168 | validation: 0.028214240006241065]
	TIME [epoch: 6.48 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010979246948996017		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.010979246948996017 | validation: 0.02369790496726817]
	TIME [epoch: 6.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012930502705982035		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.012930502705982035 | validation: 0.024781190597232758]
	TIME [epoch: 6.47 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012718443129584618		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.012718443129584618 | validation: 0.024355694081032477]
	TIME [epoch: 6.47 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006785137454504619		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.006785137454504619 | validation: 0.024562035781011626]
	TIME [epoch: 6.47 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009993666231521176		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.009993666231521176 | validation: 0.02136845055299352]
	TIME [epoch: 6.48 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021073683621482802		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.021073683621482802 | validation: 0.02750349082934356]
	TIME [epoch: 6.48 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013286123281362253		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.013286123281362253 | validation: 0.020664287015049198]
	TIME [epoch: 6.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013269294901432133		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.013269294901432133 | validation: 0.01637920707079998]
	TIME [epoch: 6.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012736047779344657		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.012736047779344657 | validation: 0.021308594539279732]
	TIME [epoch: 6.48 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0148477289173997		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0148477289173997 | validation: 0.022106443093597373]
	TIME [epoch: 6.47 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010598451358970095		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.010598451358970095 | validation: 0.01885614488827119]
	TIME [epoch: 6.48 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01399586455693777		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.01399586455693777 | validation: 0.024983857585043262]
	TIME [epoch: 6.47 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013959123965291668		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.013959123965291668 | validation: 0.024181681167701325]
	TIME [epoch: 6.47 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01091624591417062		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.01091624591417062 | validation: 0.027758650199648863]
	TIME [epoch: 6.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01164654162155446		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.01164654162155446 | validation: 0.017905492066640157]
	TIME [epoch: 6.49 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014817137890691256		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.014817137890691256 | validation: 0.022790294666584235]
	TIME [epoch: 6.48 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013268749140416206		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.013268749140416206 | validation: 0.01657487656620174]
	TIME [epoch: 6.48 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014778481628005588		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.014778481628005588 | validation: 0.025694694457310662]
	TIME [epoch: 6.48 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011998200046847797		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.011998200046847797 | validation: 0.015031017164124097]
	TIME [epoch: 6.49 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011395961528458518		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.011395961528458518 | validation: 0.028492619551352766]
	TIME [epoch: 6.48 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014220148841246802		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.014220148841246802 | validation: 0.02275828154197322]
	TIME [epoch: 6.51 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012531761206309677		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.012531761206309677 | validation: 0.02860378491086271]
	TIME [epoch: 6.47 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011435113305781982		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.011435113305781982 | validation: 0.015594847171059158]
	TIME [epoch: 6.48 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014492304886109964		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.014492304886109964 | validation: 0.01092925121315901]
	TIME [epoch: 6.48 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010863149508553233		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.010863149508553233 | validation: 0.021141522577639987]
	TIME [epoch: 6.48 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014925291022217528		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.014925291022217528 | validation: 0.01861118195399174]
	TIME [epoch: 6.48 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014339602660176715		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.014339602660176715 | validation: 0.016236984720955704]
	TIME [epoch: 6.51 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011263298728191946		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.011263298728191946 | validation: 0.013962820975180042]
	TIME [epoch: 6.49 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013249052514785947		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.013249052514785947 | validation: 0.020358024476893916]
	TIME [epoch: 6.49 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008193824036963834		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.008193824036963834 | validation: 0.024892713613075608]
	TIME [epoch: 6.48 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012754298913577787		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.012754298913577787 | validation: 0.017656660132609494]
	TIME [epoch: 6.47 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010817256581253498		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.010817256581253498 | validation: 0.025448011009714926]
	TIME [epoch: 6.48 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012631809748426313		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.012631809748426313 | validation: 0.027747858619650182]
	TIME [epoch: 6.49 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012109124704451274		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.012109124704451274 | validation: 0.01818804071649197]
	TIME [epoch: 6.51 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01464505224964689		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.01464505224964689 | validation: 0.01923376491069559]
	TIME [epoch: 6.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01132762385105179		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.01132762385105179 | validation: 0.02001677424603539]
	TIME [epoch: 6.48 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012668287465084268		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.012668287465084268 | validation: 0.027259285677977436]
	TIME [epoch: 6.47 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013104381521457976		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.013104381521457976 | validation: 0.019922382490449544]
	TIME [epoch: 6.47 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01287901265942719		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.01287901265942719 | validation: 0.021521235380442618]
	TIME [epoch: 6.48 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014867580316372085		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.014867580316372085 | validation: 0.01883105949800539]
	TIME [epoch: 6.51 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011850780120854698		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.011850780120854698 | validation: 0.022758035682280492]
	TIME [epoch: 6.49 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01097065684815052		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.01097065684815052 | validation: 0.022834783623455916]
	TIME [epoch: 6.46 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009719950439703194		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.009719950439703194 | validation: 0.021091657583784996]
	TIME [epoch: 6.47 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012723076963654103		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.012723076963654103 | validation: 0.022207267707029927]
	TIME [epoch: 6.46 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01615413933294811		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.01615413933294811 | validation: 0.018953163328419165]
	TIME [epoch: 6.46 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011072496301980709		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.011072496301980709 | validation: 0.02358989742080744]
	TIME [epoch: 6.46 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011358023576049085		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.011358023576049085 | validation: 0.020047228546247263]
	TIME [epoch: 6.49 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013281335126485688		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.013281335126485688 | validation: 0.022273276018591883]
	TIME [epoch: 6.45 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011946024024402691		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.011946024024402691 | validation: 0.027444965738755416]
	TIME [epoch: 6.46 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013111895467816959		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.013111895467816959 | validation: 0.01952023711802266]
	TIME [epoch: 6.46 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013374761903345326		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.013374761903345326 | validation: 0.03925244388865571]
	TIME [epoch: 6.46 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012164545247281389		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.012164545247281389 | validation: 0.012269223044244089]
	TIME [epoch: 6.46 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009961773187530222		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.009961773187530222 | validation: 0.024424594012115435]
	TIME [epoch: 6.47 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011823358187929824		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.011823358187929824 | validation: 0.025983799440937684]
	TIME [epoch: 6.49 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012189178178851007		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.012189178178851007 | validation: 0.018810187751854925]
	TIME [epoch: 6.46 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01163619505615221		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.01163619505615221 | validation: 0.01755250881433353]
	TIME [epoch: 6.47 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015929612639198204		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.015929612639198204 | validation: 0.016489086395847747]
	TIME [epoch: 6.47 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014994060355193156		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.014994060355193156 | validation: 0.018586299667997793]
	TIME [epoch: 6.47 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010599627791693723		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.010599627791693723 | validation: 0.025762073177576835]
	TIME [epoch: 6.46 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011187483831670085		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.011187483831670085 | validation: 0.021310556015936916]
	TIME [epoch: 6.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010997967850316427		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.010997967850316427 | validation: 0.028029008544913348]
	TIME [epoch: 6.48 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01564756313350493		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.01564756313350493 | validation: 0.02074563303493912]
	TIME [epoch: 6.47 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014619410026336373		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.014619410026336373 | validation: 0.030784886152084058]
	TIME [epoch: 6.47 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010289214971809396		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.010289214971809396 | validation: 0.02262597899701503]
	TIME [epoch: 6.47 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013144386627015055		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.013144386627015055 | validation: 0.020695472181041723]
	TIME [epoch: 6.46 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012300739825577101		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.012300739825577101 | validation: 0.019512842295576555]
	TIME [epoch: 6.49 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01334424308567685		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.01334424308567685 | validation: 0.01308554522403838]
	TIME [epoch: 6.5 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010901700513175312		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.010901700513175312 | validation: 0.020869671164061236]
	TIME [epoch: 6.46 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015725086978042896		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.015725086978042896 | validation: 0.014657719646538739]
	TIME [epoch: 6.46 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012666945182352235		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.012666945182352235 | validation: 0.025552926117969332]
	TIME [epoch: 6.46 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012992359547924038		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.012992359547924038 | validation: 0.02704585640094579]
	TIME [epoch: 6.46 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010499791538670413		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.010499791538670413 | validation: 0.023412411216976698]
	TIME [epoch: 6.46 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010546056499211798		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.010546056499211798 | validation: 0.016640843812467828]
	TIME [epoch: 6.49 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014405612616473789		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.014405612616473789 | validation: 0.02463590896047947]
	TIME [epoch: 6.48 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011244949458651609		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.011244949458651609 | validation: 0.016241259701463857]
	TIME [epoch: 6.46 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0156436596936133		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.0156436596936133 | validation: 0.021249925515946254]
	TIME [epoch: 6.46 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010588106133030357		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.010588106133030357 | validation: 0.019677149800638328]
	TIME [epoch: 6.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011926952470882777		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.011926952470882777 | validation: 0.02037332269509962]
	TIME [epoch: 6.46 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013232990149035211		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.013232990149035211 | validation: 0.022558577074963983]
	TIME [epoch: 6.46 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013240455052910934		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.013240455052910934 | validation: 0.020664776210276053]
	TIME [epoch: 6.5 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015197999283424758		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.015197999283424758 | validation: 0.023117090407011282]
	TIME [epoch: 6.46 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012301445690575771		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.012301445690575771 | validation: 0.024219500585875516]
	TIME [epoch: 6.47 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011633330718035278		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.011633330718035278 | validation: 0.019578866488990064]
	TIME [epoch: 6.46 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011947337768606745		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.011947337768606745 | validation: 0.02620714535777148]
	TIME [epoch: 6.47 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012831647044414425		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.012831647044414425 | validation: 0.021924670219180032]
	TIME [epoch: 6.47 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008608526486086026		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.008608526486086026 | validation: 0.028580269867458312]
	TIME [epoch: 6.51 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012244689849151613		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.012244689849151613 | validation: 0.019622664799656967]
	TIME [epoch: 6.48 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009697788489013839		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.009697788489013839 | validation: 0.027039296027508854]
	TIME [epoch: 6.48 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013414962430745928		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.013414962430745928 | validation: 0.018610448179784175]
	TIME [epoch: 6.48 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010312205916074905		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.010312205916074905 | validation: 0.03242542203941478]
	TIME [epoch: 6.48 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015392521534390554		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.015392521534390554 | validation: 0.01847950777280681]
	TIME [epoch: 6.48 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010510157835781386		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.010510157835781386 | validation: 0.020762544291643873]
	TIME [epoch: 6.48 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012404845396928675		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.012404845396928675 | validation: 0.022091035840631372]
	TIME [epoch: 6.52 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01201372038911521		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.01201372038911521 | validation: 0.03272530360079686]
	TIME [epoch: 6.49 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011413115433216648		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.011413115433216648 | validation: 0.016455218371882102]
	TIME [epoch: 6.49 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013943640341499508		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.013943640341499508 | validation: 0.02271600707122591]
	TIME [epoch: 6.49 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012364487841646878		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.012364487841646878 | validation: 0.021359522896252887]
	TIME [epoch: 6.49 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012418190321081464		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.012418190321081464 | validation: 0.018930050687850357]
	TIME [epoch: 6.49 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012797163919518807		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.012797163919518807 | validation: 0.027664957884328763]
	TIME [epoch: 6.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011074480493012791		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.011074480493012791 | validation: 0.017328099032021132]
	TIME [epoch: 6.52 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00964389202685163		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.00964389202685163 | validation: 0.013931304141539211]
	TIME [epoch: 6.47 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015849540704310324		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.015849540704310324 | validation: 0.027739447775544816]
	TIME [epoch: 6.49 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013351119221202625		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.013351119221202625 | validation: 0.026266756787372225]
	TIME [epoch: 6.48 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01101673595803823		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.01101673595803823 | validation: 0.022641650164669524]
	TIME [epoch: 6.49 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009108039966442976		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.009108039966442976 | validation: 0.018069067867320418]
	TIME [epoch: 6.47 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012923177932540926		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.012923177932540926 | validation: 0.021638952829465947]
	TIME [epoch: 6.52 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012410220620202774		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.012410220620202774 | validation: 0.02037430394871467]
	TIME [epoch: 6.49 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013106856024943955		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.013106856024943955 | validation: 0.0253687943663672]
	TIME [epoch: 6.48 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012831701978118878		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.012831701978118878 | validation: 0.010327884799135432]
	TIME [epoch: 6.48 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013964843482014858		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.013964843482014858 | validation: 0.021584774889834006]
	TIME [epoch: 6.48 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012334192042357684		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.012334192042357684 | validation: 0.02831705234935955]
	TIME [epoch: 6.48 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014176763479634593		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.014176763479634593 | validation: 0.025985522248343194]
	TIME [epoch: 6.49 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01006422111285119		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.01006422111285119 | validation: 0.0233969982182128]
	TIME [epoch: 6.49 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01613752409444353		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.01613752409444353 | validation: 0.020074605676635916]
	TIME [epoch: 6.47 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012074862818431417		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.012074862818431417 | validation: 0.02078729115352378]
	TIME [epoch: 6.47 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01708518681283115		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.01708518681283115 | validation: 0.024724213739578824]
	TIME [epoch: 6.45 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010855882355830841		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.010855882355830841 | validation: 0.018990718258968673]
	TIME [epoch: 6.45 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01126783997738087		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.01126783997738087 | validation: 0.028169940741940694]
	TIME [epoch: 6.44 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013439667419312537		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.013439667419312537 | validation: 0.025705975419725764]
	TIME [epoch: 6.48 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012669559682483955		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.012669559682483955 | validation: 0.022020482089359722]
	TIME [epoch: 6.46 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01329354829537287		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.01329354829537287 | validation: 0.020983451389727587]
	TIME [epoch: 6.46 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011368705476360146		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.011368705476360146 | validation: 0.012207646157224264]
	TIME [epoch: 6.45 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012189243569247766		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.012189243569247766 | validation: 0.020497282294606043]
	TIME [epoch: 6.45 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015214245348886919		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.015214245348886919 | validation: 0.023868862615769936]
	TIME [epoch: 6.45 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014645004424841714		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.014645004424841714 | validation: 0.016885701155847727]
	TIME [epoch: 6.47 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012672781630509227		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.012672781630509227 | validation: 0.022203883685837554]
	TIME [epoch: 6.49 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012513737198971642		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.012513737198971642 | validation: 0.03157427699413522]
	TIME [epoch: 6.45 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013665582697521602		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.013665582697521602 | validation: 0.026913618893577542]
	TIME [epoch: 6.45 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014500803296226243		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.014500803296226243 | validation: 0.01817705293206486]
	TIME [epoch: 6.45 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010870522951797565		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.010870522951797565 | validation: 0.03019620878961324]
	TIME [epoch: 6.46 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012641501816852686		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.012641501816852686 | validation: 0.017447062522497944]
	TIME [epoch: 6.46 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014253237008125967		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.014253237008125967 | validation: 0.018194520834646576]
	TIME [epoch: 6.49 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007455977956965829		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.007455977956965829 | validation: 0.01749532519494035]
	TIME [epoch: 6.47 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010369604036907593		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.010369604036907593 | validation: 0.021432861776877067]
	TIME [epoch: 6.47 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012949597875863464		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.012949597875863464 | validation: 0.02317514962365601]
	TIME [epoch: 6.46 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013555716215144389		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.013555716215144389 | validation: 0.020159154254386573]
	TIME [epoch: 6.46 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012309837637777125		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.012309837637777125 | validation: 0.022266433533743177]
	TIME [epoch: 6.47 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011409246146568873		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.011409246146568873 | validation: 0.023533667671558733]
	TIME [epoch: 6.47 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013011721746749444		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.013011721746749444 | validation: 0.019345778122242998]
	TIME [epoch: 6.49 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011548068383645025		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.011548068383645025 | validation: 0.023920006098316193]
	TIME [epoch: 6.48 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012700782268879557		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.012700782268879557 | validation: 0.017732970503994104]
	TIME [epoch: 6.48 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014352146352813542		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.014352146352813542 | validation: 0.01740046766757844]
	TIME [epoch: 6.48 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012881471966688027		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.012881471966688027 | validation: 0.02062978219870943]
	TIME [epoch: 6.47 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010469760701966882		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.010469760701966882 | validation: 0.020886874418182138]
	TIME [epoch: 6.48 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011091551583276092		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.011091551583276092 | validation: 0.018788063263891083]
	TIME [epoch: 6.49 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013509723403702083		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.013509723403702083 | validation: 0.026420610925427693]
	TIME [epoch: 6.52 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009079216516732089		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.009079216516732089 | validation: 0.027744775245743966]
	TIME [epoch: 6.48 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01041337103627621		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.01041337103627621 | validation: 0.01751157768057831]
	TIME [epoch: 6.49 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014881870891496203		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.014881870891496203 | validation: 0.022122086219031313]
	TIME [epoch: 6.47 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01151662392372885		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.01151662392372885 | validation: 0.024104091370673073]
	TIME [epoch: 6.48 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0121373639817596		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.0121373639817596 | validation: 0.021328891636329176]
	TIME [epoch: 6.48 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013890724467631425		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.013890724467631425 | validation: 0.023141551976149623]
	TIME [epoch: 6.51 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012637748573198743		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.012637748573198743 | validation: 0.03125796946747298]
	TIME [epoch: 6.48 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011865438606124957		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.011865438606124957 | validation: 0.017878631083938664]
	TIME [epoch: 6.48 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009052154691049016		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.009052154691049016 | validation: 0.02279152089922654]
	TIME [epoch: 6.48 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01128852968263298		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.01128852968263298 | validation: 0.020252600363007415]
	TIME [epoch: 6.47 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011317358301254653		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.011317358301254653 | validation: 0.0271319907617206]
	TIME [epoch: 6.49 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016151172168384857		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.016151172168384857 | validation: 0.013920285657700204]
	TIME [epoch: 6.49 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010399353471964894		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.010399353471964894 | validation: 0.02439661542382412]
	TIME [epoch: 6.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009401875026373022		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.009401875026373022 | validation: 0.015307513354591342]
	TIME [epoch: 6.46 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010514936694203822		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.010514936694203822 | validation: 0.021596749573977305]
	TIME [epoch: 6.47 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01271362724280433		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.01271362724280433 | validation: 0.019533202066013226]
	TIME [epoch: 6.48 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01309676693926978		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.01309676693926978 | validation: 0.01836938276072919]
	TIME [epoch: 6.48 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009008781652279434		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.009008781652279434 | validation: 0.027900922398960075]
	TIME [epoch: 6.48 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0139707722412925		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.0139707722412925 | validation: 0.020035447635557903]
	TIME [epoch: 6.5 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013653225593974503		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.013653225593974503 | validation: 0.01781420137575634]
	TIME [epoch: 6.48 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013305699803714599		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.013305699803714599 | validation: 0.026658670671150325]
	TIME [epoch: 6.47 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00953333295549335		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.00953333295549335 | validation: 0.025707580936335017]
	TIME [epoch: 6.47 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013799642320595416		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.013799642320595416 | validation: 0.01930813217327303]
	TIME [epoch: 6.48 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011634234145315068		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.011634234145315068 | validation: 0.020595987817738852]
	TIME [epoch: 6.47 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01243996241177341		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.01243996241177341 | validation: 0.021129154919841433]
	TIME [epoch: 6.48 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012397881454505582		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.012397881454505582 | validation: 0.023765574053832665]
	TIME [epoch: 6.5 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008748149372445804		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.008748149372445804 | validation: 0.009346052756693406]
	TIME [epoch: 6.46 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014613480858324132		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.014613480858324132 | validation: 0.02236256114031625]
	TIME [epoch: 6.48 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009572079647342272		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.009572079647342272 | validation: 0.024331526769626046]
	TIME [epoch: 6.45 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010385018283333287		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.010385018283333287 | validation: 0.018883898569037105]
	TIME [epoch: 6.47 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010220136079491543		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.010220136079491543 | validation: 0.022684730846914657]
	TIME [epoch: 6.47 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0162027992457384		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.0162027992457384 | validation: 0.024421529632912994]
	TIME [epoch: 6.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015694594140422933		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.015694594140422933 | validation: 0.01748705149510668]
	TIME [epoch: 6.48 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00940326739604931		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.00940326739604931 | validation: 0.014850675115829383]
	TIME [epoch: 6.47 sec]
Finished training in 13133.395 seconds.
