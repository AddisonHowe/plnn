Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r5', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4195866099

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.756014428180864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.756014428180864 | validation: 10.306485736328343]
	TIME [epoch: 105 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.858019678762572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.858019678762572 | validation: 9.46589266914817]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.921902581883895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.921902581883895 | validation: 8.417416806709625]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.322755731794079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.322755731794079 | validation: 8.290545492614461]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.300379900075805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.300379900075805 | validation: 10.633886716495292]
	TIME [epoch: 13.1 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.809068249419447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.809068249419447 | validation: 8.213242908942496]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.7587629264504265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7587629264504265 | validation: 7.438895234701899]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3614610549439785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3614610549439785 | validation: 6.802545555307819]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.610377307306134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.610377307306134 | validation: 6.488630757788128]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.520640713937633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.520640713937633 | validation: 7.159587770741216]
	TIME [epoch: 13.2 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.846530128632629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.846530128632629 | validation: 6.568892837421105]
	TIME [epoch: 13.1 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.430085027849909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.430085027849909 | validation: 6.278052921852406]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.176244740967016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.176244740967016 | validation: 6.080732495380872]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.038760795916604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.038760795916604 | validation: 6.103754189788641]
	TIME [epoch: 13.1 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.081114034935834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.081114034935834 | validation: 6.065361744192197]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.118140341998861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.118140341998861 | validation: 6.132468934479037]
	TIME [epoch: 13.1 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9447455774358255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9447455774358255 | validation: 5.931210470002229]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9385227292069995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9385227292069995 | validation: 7.053033936981223]
	TIME [epoch: 13.1 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6039837691836905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6039837691836905 | validation: 8.757864693135566]
	TIME [epoch: 13.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.82796175842838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.82796175842838 | validation: 6.12756051917196]
	TIME [epoch: 13.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.189813436902047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.189813436902047 | validation: 6.062233906031224]
	TIME [epoch: 13.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.042314392197806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.042314392197806 | validation: 5.923945783417378]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.960696366542123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.960696366542123 | validation: 6.038180017525599]
	TIME [epoch: 13.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944059166207154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.944059166207154 | validation: 5.9878261065366]
	TIME [epoch: 13.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859192687124803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.859192687124803 | validation: 6.0294403225977815]
	TIME [epoch: 13.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930305217686637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.930305217686637 | validation: 5.9507986432232745]
	TIME [epoch: 13.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.741532262153669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.741532262153669 | validation: 5.632916270641776]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.863029407311291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.863029407311291 | validation: 5.5425278443734625]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.568483373865673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.568483373865673 | validation: 5.356519460447968]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.697663697465427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.697663697465427 | validation: 5.674430120492107]
	TIME [epoch: 13.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.682986508796402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.682986508796402 | validation: 5.61846684768757]
	TIME [epoch: 13.1 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.790853514981004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.790853514981004 | validation: 5.996079747603998]
	TIME [epoch: 13.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6276831771668325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6276831771668325 | validation: 5.409708299495455]
	TIME [epoch: 13.1 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.407915116476167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.407915116476167 | validation: 5.725499963106083]
	TIME [epoch: 13.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.36016763134574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.36016763134574 | validation: 5.134552311236189]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.999616883175381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.999616883175381 | validation: 11.294751429355538]
	TIME [epoch: 13.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.81232411577913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.81232411577913 | validation: 5.140150803707908]
	TIME [epoch: 13.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1444666155765315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1444666155765315 | validation: 5.083859202719695]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.071133099362674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.071133099362674 | validation: 4.968579297842872]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.108567724399687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.108567724399687 | validation: 5.007173296031619]
	TIME [epoch: 13.1 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.077764589275234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077764589275234 | validation: 5.149921841257861]
	TIME [epoch: 13.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.983484313109154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.983484313109154 | validation: 4.83465680608948]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.970490856590976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.970490856590976 | validation: 4.795557180121945]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.880000049153096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.880000049153096 | validation: 4.587772245417471]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.706569954688051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.706569954688051 | validation: 4.620891740831552]
	TIME [epoch: 13.1 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.684776315211393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.684776315211393 | validation: 4.541953420301134]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560460026991597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.560460026991597 | validation: 4.2652699295774665]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.429937636160601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.429937636160601 | validation: 5.482425238179616]
	TIME [epoch: 13.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.701800324960842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.701800324960842 | validation: 4.179376939532813]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.207266250692712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.207266250692712 | validation: 3.99743700198264]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9800283704308237		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.9800283704308237 | validation: 4.012607369549191]
	TIME [epoch: 13.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.201619371794244		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.201619371794244 | validation: 3.7027646893580557]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.746070838669122		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.746070838669122 | validation: 3.8912358572735277]
	TIME [epoch: 13.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.743018785394608		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.743018785394608 | validation: 3.9108061817444564]
	TIME [epoch: 13.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6086514367876363		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.6086514367876363 | validation: 3.3917182136044866]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5097857313831775		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.5097857313831775 | validation: 3.003429444682893]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0843783317953193		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.0843783317953193 | validation: 3.926996246644613]
	TIME [epoch: 13.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2939705527719796		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.2939705527719796 | validation: 2.849268877108732]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9834013167218543		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.9834013167218543 | validation: 2.7102108531167186]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.192412484857432		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.192412484857432 | validation: 2.741686029685378]
	TIME [epoch: 13.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.847277773948542		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.847277773948542 | validation: 2.7045450955398604]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7963718956497723		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.7963718956497723 | validation: 5.134649156519206]
	TIME [epoch: 13.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.261594351682863		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.261594351682863 | validation: 2.611597354087363]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8701480209104964		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.8701480209104964 | validation: 2.877030848027768]
	TIME [epoch: 13.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8637718758444364		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.8637718758444364 | validation: 3.0389130433656586]
	TIME [epoch: 13.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.717994279791602		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.717994279791602 | validation: 2.863359441813116]
	TIME [epoch: 13.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6691427931693674		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.6691427931693674 | validation: 2.532916353204852]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4860116450844734		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.4860116450844734 | validation: 2.14460241005105]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9840590932566906		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.9840590932566906 | validation: 3.7178799550499293]
	TIME [epoch: 13.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.975778369691811		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.975778369691811 | validation: 2.4745154459293075]
	TIME [epoch: 13.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4531231568154634		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.4531231568154634 | validation: 2.175447245090358]
	TIME [epoch: 13.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.502248241169262		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.502248241169262 | validation: 2.4461179636096184]
	TIME [epoch: 13.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.688619842285337		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.688619842285337 | validation: 2.37968429211062]
	TIME [epoch: 13.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5036568013268994		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.5036568013268994 | validation: 2.332541566752471]
	TIME [epoch: 13.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4659310770944507		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.4659310770944507 | validation: 3.6748691158693827]
	TIME [epoch: 13.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9844447596715398		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.9844447596715398 | validation: 2.2330125928364972]
	TIME [epoch: 13.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3096743181021457		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.3096743181021457 | validation: 1.9727241334886527]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.342977114648529		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.342977114648529 | validation: 2.1057275770783472]
	TIME [epoch: 13.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.113752239181917		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.113752239181917 | validation: 2.696150655475]
	TIME [epoch: 13.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3868577989589337		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.3868577989589337 | validation: 1.9466998600225827]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1115518846305013		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.1115518846305013 | validation: 1.772706640679947]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.229291068113093		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.229291068113093 | validation: 2.319649720856052]
	TIME [epoch: 13.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2396515628155944		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.2396515628155944 | validation: 2.976684885459331]
	TIME [epoch: 13.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6459005514360245		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.6459005514360245 | validation: 1.79467431962707]
	TIME [epoch: 13.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.905789565976496		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.905789565976496 | validation: 2.5016755561581783]
	TIME [epoch: 13.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6767330707660153		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.6767330707660153 | validation: 1.6993314988039834]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0963333489516436		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.0963333489516436 | validation: 1.834583005212027]
	TIME [epoch: 13.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4297346816445726		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.4297346816445726 | validation: 1.9886977641870716]
	TIME [epoch: 13.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1881005667332056		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.1881005667332056 | validation: 2.2544447996758787]
	TIME [epoch: 13.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1630086186640263		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.1630086186640263 | validation: 1.9344256357570435]
	TIME [epoch: 13.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.209451212474408		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.209451212474408 | validation: 1.961995871735506]
	TIME [epoch: 13.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9811243633232214		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.9811243633232214 | validation: 1.8955083814252356]
	TIME [epoch: 13.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2108470049947746		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.2108470049947746 | validation: 1.61815425090153]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3873600603614835		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.3873600603614835 | validation: 2.136677731304689]
	TIME [epoch: 13.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.919825330728509		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.919825330728509 | validation: 1.6022243765428656]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9632185335075625		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.9632185335075625 | validation: 1.9930667290599353]
	TIME [epoch: 13.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8999586696719506		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.8999586696719506 | validation: 1.4429872691929553]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9416021352294344		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9416021352294344 | validation: 2.147509629118712]
	TIME [epoch: 13.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7962022297513391		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.7962022297513391 | validation: 1.4742407239366304]
	TIME [epoch: 13.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6385908224145433		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.6385908224145433 | validation: 3.14679004390999]
	TIME [epoch: 13.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346883607959947		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.346883607959947 | validation: 2.2806398494737925]
	TIME [epoch: 13.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.818471426784762		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.818471426784762 | validation: 1.7423292500310117]
	TIME [epoch: 13.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.675298342421991		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.675298342421991 | validation: 2.9611541349795765]
	TIME [epoch: 13.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8677950756405655		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.8677950756405655 | validation: 3.593014193580933]
	TIME [epoch: 13.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5520884781506843		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.5520884781506843 | validation: 2.023405538856522]
	TIME [epoch: 13.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.812999763321522		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.812999763321522 | validation: 1.4927802475821106]
	TIME [epoch: 13.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.719508834972345		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.719508834972345 | validation: 1.4225741480131109]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8261777084523305		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.8261777084523305 | validation: 1.6125490169967793]
	TIME [epoch: 13.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7596686246901154		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.7596686246901154 | validation: 1.5083158460715123]
	TIME [epoch: 13.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.727648870077105		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.727648870077105 | validation: 1.7416056150751262]
	TIME [epoch: 13.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9064939433926065		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.9064939433926065 | validation: 1.4478474912541672]
	TIME [epoch: 13.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6337909332944587		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6337909332944587 | validation: 1.3969464973503165]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8331936974071086		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.8331936974071086 | validation: 2.191818436030778]
	TIME [epoch: 13.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9617290277968655		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.9617290277968655 | validation: 1.2796279450548635]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.675359163179243		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.675359163179243 | validation: 2.527375543620409]
	TIME [epoch: 13.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.011995695649663		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.011995695649663 | validation: 1.5387660772615317]
	TIME [epoch: 13.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0151421174802815		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.0151421174802815 | validation: 2.940953696117696]
	TIME [epoch: 13.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1921388221446936		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.1921388221446936 | validation: 1.406174769545687]
	TIME [epoch: 13.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7220924168872487		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.7220924168872487 | validation: 1.9952084730382103]
	TIME [epoch: 13.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.833499539919854		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.833499539919854 | validation: 1.2102030307644454]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9943457716870105		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.9943457716870105 | validation: 1.2568559451296566]
	TIME [epoch: 13.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5403263891268792		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.5403263891268792 | validation: 1.9839181921106754]
	TIME [epoch: 13.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8093312639922647		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8093312639922647 | validation: 1.535476477022355]
	TIME [epoch: 13.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5573992289977234		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.5573992289977234 | validation: 1.648693774932322]
	TIME [epoch: 13.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8397966267114947		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.8397966267114947 | validation: 1.9995057391019648]
	TIME [epoch: 13.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0129218480062243		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.0129218480062243 | validation: 1.9826319780246764]
	TIME [epoch: 13.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9673779249011858		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.9673779249011858 | validation: 1.7844860982344437]
	TIME [epoch: 13.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7983352604465843		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.7983352604465843 | validation: 3.9799657016021697]
	TIME [epoch: 13.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.777368720203375		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 2.777368720203375 | validation: 1.3156441821506062]
	TIME [epoch: 13.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6944062320568354		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.6944062320568354 | validation: 1.6631963151924725]
	TIME [epoch: 13.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.573638989854985		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.573638989854985 | validation: 1.6616458311166866]
	TIME [epoch: 13.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6845708353964075		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.6845708353964075 | validation: 1.7529933068764914]
	TIME [epoch: 13.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.606920818410896		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.606920818410896 | validation: 2.0203249046677416]
	TIME [epoch: 13.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7642491944333838		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7642491944333838 | validation: 2.0867452649979983]
	TIME [epoch: 13.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0254228016105755		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.0254228016105755 | validation: 3.0981111001656645]
	TIME [epoch: 13.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.968507227125864		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.968507227125864 | validation: 3.216912883530869]
	TIME [epoch: 13.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1072657663871843		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.1072657663871843 | validation: 1.2131361977777064]
	TIME [epoch: 13.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3376162173991824		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3376162173991824 | validation: 2.6975455486482995]
	TIME [epoch: 13.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9343452450540455		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.9343452450540455 | validation: 1.419658390352749]
	TIME [epoch: 13.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6598039888269736		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.6598039888269736 | validation: 1.739216610722197]
	TIME [epoch: 13.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0105382291322194		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.0105382291322194 | validation: 1.3740789777649622]
	TIME [epoch: 13.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3060035472816813		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.3060035472816813 | validation: 1.5036370505215262]
	TIME [epoch: 13.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5878554165176408		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.5878554165176408 | validation: 1.2699073469298976]
	TIME [epoch: 13.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6256214239565105		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.6256214239565105 | validation: 1.3054305185929247]
	TIME [epoch: 13.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.789598967453958		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.789598967453958 | validation: 1.6055774172492596]
	TIME [epoch: 13.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1190768136844857		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.1190768136844857 | validation: 4.05294461830819]
	TIME [epoch: 13.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7615614299810183		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.7615614299810183 | validation: 1.7162125567575017]
	TIME [epoch: 13.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8176380074046687		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.8176380074046687 | validation: 1.2617326624664786]
	TIME [epoch: 13.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6515174345619792		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6515174345619792 | validation: 1.842481676863188]
	TIME [epoch: 13.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.70737693065177		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.70737693065177 | validation: 1.5352246942733008]
	TIME [epoch: 13.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.039192566251223		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.039192566251223 | validation: 1.8285031812135617]
	TIME [epoch: 13.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752339431913974		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.752339431913974 | validation: 1.8988795288934046]
	TIME [epoch: 13.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8126564751078906		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.8126564751078906 | validation: 2.5592014945853085]
	TIME [epoch: 13.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.932000103595775		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.932000103595775 | validation: 3.120702706006721]
	TIME [epoch: 13.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4526822376683466		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.4526822376683466 | validation: 1.7912605695433745]
	TIME [epoch: 13.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3801078119594323		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.3801078119594323 | validation: 2.178351874489114]
	TIME [epoch: 13.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6234247893600977		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.6234247893600977 | validation: 1.5798320247747095]
	TIME [epoch: 13.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5106676690503824		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.5106676690503824 | validation: 1.4608385189719102]
	TIME [epoch: 13.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7503955860458706		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.7503955860458706 | validation: 1.6602084351031305]
	TIME [epoch: 13.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3876522236537845		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.3876522236537845 | validation: 1.0646820220392164]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8515011970707709		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.8515011970707709 | validation: 1.400129398414528]
	TIME [epoch: 13.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5257101353202465		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.5257101353202465 | validation: 1.2519857939191392]
	TIME [epoch: 13.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.537145412387407		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.537145412387407 | validation: 1.3399299258181092]
	TIME [epoch: 13.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4153020956133175		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.4153020956133175 | validation: 1.3536728061051089]
	TIME [epoch: 13.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.048474933607781		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.048474933607781 | validation: 1.6173686465346315]
	TIME [epoch: 13.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9069709154914363		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.9069709154914363 | validation: 1.7355306444399474]
	TIME [epoch: 13.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4047210505383347		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.4047210505383347 | validation: 1.7321151690159207]
	TIME [epoch: 13.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3312914765840278		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3312914765840278 | validation: 2.0345433018406167]
	TIME [epoch: 13.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7916455286105797		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.7916455286105797 | validation: 2.9631255508283063]
	TIME [epoch: 13.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9266395483321155		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.9266395483321155 | validation: 1.5366055675696848]
	TIME [epoch: 13.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6575070079051086		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.6575070079051086 | validation: 1.5523167257295558]
	TIME [epoch: 13.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3577294689297248		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.3577294689297248 | validation: 1.8184617029077044]
	TIME [epoch: 13.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3091159377466466		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.3091159377466466 | validation: 1.146277022794254]
	TIME [epoch: 13.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3099631784201713		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3099631784201713 | validation: 1.065917092802008]
	TIME [epoch: 13.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1953800138616197		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.1953800138616197 | validation: 1.6442813610703721]
	TIME [epoch: 13.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.405559674801507		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.405559674801507 | validation: 2.429294463869171]
	TIME [epoch: 13.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.803618165083766		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.803618165083766 | validation: 1.7338294243726693]
	TIME [epoch: 13.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4808962389159017		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.4808962389159017 | validation: 1.0164557893676494]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3710933155674427		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.3710933155674427 | validation: 1.0572636988603568]
	TIME [epoch: 13.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7139867345135493		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.7139867345135493 | validation: 1.0940096849497485]
	TIME [epoch: 13.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7208985073568681		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.7208985073568681 | validation: 1.0599498787237247]
	TIME [epoch: 13.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.359554092909463		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.359554092909463 | validation: 1.3037203023786583]
	TIME [epoch: 13.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4521777115270127		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4521777115270127 | validation: 1.452975630154637]
	TIME [epoch: 13.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4242622279228911		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.4242622279228911 | validation: 1.537022238194623]
	TIME [epoch: 13.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.542560360457835		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.542560360457835 | validation: 2.7591444808632577]
	TIME [epoch: 13.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8014757238864203		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.8014757238864203 | validation: 0.9004431807793631]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3536735259360175		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.3536735259360175 | validation: 1.0785919319638817]
	TIME [epoch: 13.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2115871707270096		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2115871707270096 | validation: 1.1182991419467847]
	TIME [epoch: 13.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1971725307430583		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.1971725307430583 | validation: 0.8106038988177982]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175742738204051		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.175742738204051 | validation: 1.2320522713359898]
	TIME [epoch: 13.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1444703353728443		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.1444703353728443 | validation: 2.067538856073948]
	TIME [epoch: 13.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6634763508805797		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.6634763508805797 | validation: 1.8921852210981096]
	TIME [epoch: 13.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8722913530201681		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.8722913530201681 | validation: 0.9075900757409915]
	TIME [epoch: 13.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.483701210327811		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.483701210327811 | validation: 1.3743116554108066]
	TIME [epoch: 13.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.060228079824794		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.060228079824794 | validation: 1.0239164919819355]
	TIME [epoch: 13.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2982894704837085		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.2982894704837085 | validation: 0.9949689631337597]
	TIME [epoch: 13.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2633300542229076		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.2633300542229076 | validation: 1.1161778839926955]
	TIME [epoch: 13.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1475316548663348		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.1475316548663348 | validation: 1.0497776633139941]
	TIME [epoch: 13.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2785177575085949		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.2785177575085949 | validation: 1.804696802449527]
	TIME [epoch: 13.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4002885170399124		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.4002885170399124 | validation: 1.021733078194915]
	TIME [epoch: 13.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2370080874835423		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.2370080874835423 | validation: 0.8546406591872665]
	TIME [epoch: 13.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2266456537468944		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.2266456537468944 | validation: 1.2367126761017235]
	TIME [epoch: 13.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3027111536867115		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.3027111536867115 | validation: 0.8941440341506938]
	TIME [epoch: 13.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5431318925602464		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.5431318925602464 | validation: 1.0877930812227221]
	TIME [epoch: 13.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3812153217965268		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.3812153217965268 | validation: 2.1483960178955157]
	TIME [epoch: 13.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6222346371528364		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.6222346371528364 | validation: 1.4553505344468887]
	TIME [epoch: 13.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4610340328952258		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.4610340328952258 | validation: 0.9417544841284605]
	TIME [epoch: 13.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.260620815934358		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.260620815934358 | validation: 1.6033506869187892]
	TIME [epoch: 13.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4764689370084985		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.4764689370084985 | validation: 1.1567530067155098]
	TIME [epoch: 13.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4612613910987142		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.4612613910987142 | validation: 1.1331215969133965]
	TIME [epoch: 13.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3676433269804487		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.3676433269804487 | validation: 1.063867316081402]
	TIME [epoch: 13.1 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143590372137149		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.143590372137149 | validation: 1.3281495142691973]
	TIME [epoch: 13.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311923132449447		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.311923132449447 | validation: 1.5893449442473746]
	TIME [epoch: 13.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3370675274102726		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.3370675274102726 | validation: 1.1525526646515385]
	TIME [epoch: 13.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1221991011223538		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.1221991011223538 | validation: 0.7963444218087261]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9922278242241367		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9922278242241367 | validation: 1.3811540478101245]
	TIME [epoch: 13.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4757982166215924		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.4757982166215924 | validation: 1.3647866506549071]
	TIME [epoch: 13.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4185577185896672		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4185577185896672 | validation: 1.0341653389156085]
	TIME [epoch: 13.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0337410984403372		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.0337410984403372 | validation: 0.9954979226295266]
	TIME [epoch: 13.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3237919634247923		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.3237919634247923 | validation: 0.9652325744681305]
	TIME [epoch: 13.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.264420849401159		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.264420849401159 | validation: 0.9494949977061997]
	TIME [epoch: 13.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080873895594504		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.2080873895594504 | validation: 0.908668234372486]
	TIME [epoch: 13.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0222990946151034		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.0222990946151034 | validation: 4.665318726036561]
	TIME [epoch: 13.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.713185637682132		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.713185637682132 | validation: 0.96973160508012]
	TIME [epoch: 13.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3343959877876488		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.3343959877876488 | validation: 1.5893960058294112]
	TIME [epoch: 13.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1926856122872103		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.1926856122872103 | validation: 0.8239368974658905]
	TIME [epoch: 13.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04072110468582		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.04072110468582 | validation: 0.988934909878723]
	TIME [epoch: 13.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4113041864186435		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.4113041864186435 | validation: 1.7302005653163712]
	TIME [epoch: 13.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5828647267293248		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.5828647267293248 | validation: 0.9519442797300482]
	TIME [epoch: 13.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3241031145614914		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.3241031145614914 | validation: 1.057980391742655]
	TIME [epoch: 13.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.28761011139517		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.28761011139517 | validation: 1.2294867478267097]
	TIME [epoch: 13.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2440880966102046		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.2440880966102046 | validation: 1.974803730785676]
	TIME [epoch: 13.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5838270960700802		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.5838270960700802 | validation: 1.818440984167422]
	TIME [epoch: 13.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4776243504302928		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.4776243504302928 | validation: 1.3657028923113592]
	TIME [epoch: 13.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3872259935260802		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.3872259935260802 | validation: 0.9640065718666907]
	TIME [epoch: 13.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3579670584844536		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.3579670584844536 | validation: 1.591212157440727]
	TIME [epoch: 13.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3586229154532248		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.3586229154532248 | validation: 1.1493070292921777]
	TIME [epoch: 13.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0868295864215693		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.0868295864215693 | validation: 1.3369279618804932]
	TIME [epoch: 13.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2894149639254955		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2894149639254955 | validation: 1.105669771701761]
	TIME [epoch: 13.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.166662971603351		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.166662971603351 | validation: 2.1230338218308518]
	TIME [epoch: 13.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4286351735686644		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.4286351735686644 | validation: 1.4392712429368157]
	TIME [epoch: 13.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.571674180300338		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.571674180300338 | validation: 2.0154303986174664]
	TIME [epoch: 13.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4984986709179835		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.4984986709179835 | validation: 0.9804163768244633]
	TIME [epoch: 13.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0119296378823548		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.0119296378823548 | validation: 0.8332848637180171]
	TIME [epoch: 13.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399828754133922		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.9399828754133922 | validation: 1.242230920187502]
	TIME [epoch: 13.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1341380995401047		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.1341380995401047 | validation: 1.3142327721191722]
	TIME [epoch: 13.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.361449159092884		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.361449159092884 | validation: 1.379665903151534]
	TIME [epoch: 13.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2587564456339329		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.2587564456339329 | validation: 1.5731315664767491]
	TIME [epoch: 13.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.402379973794992		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.402379973794992 | validation: 1.0020921429514622]
	TIME [epoch: 13.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2080309489526435		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.2080309489526435 | validation: 0.9904512761150867]
	TIME [epoch: 13.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1884758527024646		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.1884758527024646 | validation: 0.9534151854743539]
	TIME [epoch: 13.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0458855500406818		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.0458855500406818 | validation: 0.8841758142398659]
	TIME [epoch: 13.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3291791332473704		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.3291791332473704 | validation: 0.96143634645585]
	TIME [epoch: 13.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5046735441512158		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.5046735441512158 | validation: 1.641768544435486]
	TIME [epoch: 13.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3681241723971278		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.3681241723971278 | validation: 1.0364186802995772]
	TIME [epoch: 13.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.320599965587227		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.320599965587227 | validation: 1.2386995042278752]
	TIME [epoch: 13.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2834941435241638		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.2834941435241638 | validation: 1.161791345042986]
	TIME [epoch: 13.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1432927379446407		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.1432927379446407 | validation: 0.808207568894751]
	TIME [epoch: 13.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.965814734983224		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.965814734983224 | validation: 1.2608689971847764]
	TIME [epoch: 13.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133491607113308		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.1133491607113308 | validation: 1.7307973121550047]
	TIME [epoch: 13.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.61796864256497		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.61796864256497 | validation: 1.4034680849297314]
	TIME [epoch: 13.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1870127867847275		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.1870127867847275 | validation: 1.8308689443461255]
	TIME [epoch: 13.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.408479769250313		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.408479769250313 | validation: 0.9337575991186146]
	TIME [epoch: 13.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1802567873269219		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.1802567873269219 | validation: 0.9980073482107895]
	TIME [epoch: 13.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1622879276002918		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.1622879276002918 | validation: 0.9746629682376456]
	TIME [epoch: 13.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1062594005611857		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.1062594005611857 | validation: 1.2772572002346192]
	TIME [epoch: 13.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2769244773311708		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.2769244773311708 | validation: 0.7853807638223651]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425324185794393		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.2425324185794393 | validation: 0.9858756061568693]
	TIME [epoch: 13.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1600348901327513		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.1600348901327513 | validation: 1.3249109922462083]
	TIME [epoch: 13.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.010838657604054		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.010838657604054 | validation: 0.8685536212260873]
	TIME [epoch: 13.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.038149270314145		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.038149270314145 | validation: 0.9351804216507711]
	TIME [epoch: 13.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.10094523423875		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.10094523423875 | validation: 0.8038795464387362]
	TIME [epoch: 13.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1631524071827166		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1631524071827166 | validation: 1.1743353287472604]
	TIME [epoch: 13.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1107628691278744		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.1107628691278744 | validation: 0.9896661667838359]
	TIME [epoch: 13.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3325393652812199		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.3325393652812199 | validation: 0.7295829895722882]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160118511905309		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.160118511905309 | validation: 1.01380135455328]
	TIME [epoch: 13.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.949943678389148		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.949943678389148 | validation: 0.8008370590137746]
	TIME [epoch: 13.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040837884414572		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.1040837884414572 | validation: 1.432034064044173]
	TIME [epoch: 13.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2591369017485203		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.2591369017485203 | validation: 0.952559145856307]
	TIME [epoch: 13.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.080538555062662		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.080538555062662 | validation: 0.9992930500503249]
	TIME [epoch: 13.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4354355691281917		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.4354355691281917 | validation: 1.607500103252599]
	TIME [epoch: 13.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3862219766258173		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.3862219766258173 | validation: 1.358924075648738]
	TIME [epoch: 13.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274991013583175		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.1274991013583175 | validation: 0.9927289145814779]
	TIME [epoch: 13.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9408924630615434		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9408924630615434 | validation: 1.6921702752924284]
	TIME [epoch: 13.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3297501487142942		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.3297501487142942 | validation: 1.5691061043066246]
	TIME [epoch: 13.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2313178773434044		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.2313178773434044 | validation: 1.3318637182923785]
	TIME [epoch: 13.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2413307791692763		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.2413307791692763 | validation: 1.1128663347371586]
	TIME [epoch: 13.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.095474595827361		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.095474595827361 | validation: 0.929694552367306]
	TIME [epoch: 13.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9961083545068455		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9961083545068455 | validation: 1.192747602969364]
	TIME [epoch: 13.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8695363958387197		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.8695363958387197 | validation: 1.2792276251018913]
	TIME [epoch: 13.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4824521473143801		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.4824521473143801 | validation: 2.3177196151418964]
	TIME [epoch: 13.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4695293145635884		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.4695293145635884 | validation: 1.5895636581856667]
	TIME [epoch: 13.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3868610733726876		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.3868610733726876 | validation: 0.8976407274187918]
	TIME [epoch: 13.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1885523305778471		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.1885523305778471 | validation: 1.680313287326403]
	TIME [epoch: 13.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7569887776198851		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.7569887776198851 | validation: 1.0806202054001424]
	TIME [epoch: 13.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2047878243053471		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.2047878243053471 | validation: 1.6757990792905753]
	TIME [epoch: 13.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3507785261831793		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.3507785261831793 | validation: 1.053969033071216]
	TIME [epoch: 13.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1553316608427608		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.1553316608427608 | validation: 2.3511849582123117]
	TIME [epoch: 13.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8899382995444671		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.8899382995444671 | validation: 2.37476745262456]
	TIME [epoch: 13.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6926892376483882		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.6926892376483882 | validation: 1.1260950550939999]
	TIME [epoch: 13.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4067976626203866		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.4067976626203866 | validation: 1.0967793676972941]
	TIME [epoch: 13.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2942453471344773		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.2942453471344773 | validation: 1.3610605071747546]
	TIME [epoch: 13.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1835058668276086		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.1835058668276086 | validation: 1.4475622578083676]
	TIME [epoch: 13.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.46423430871918		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.46423430871918 | validation: 0.981269632022298]
	TIME [epoch: 13.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0308809406450559		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.0308809406450559 | validation: 1.352418537836377]
	TIME [epoch: 13.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1609416986102246		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.1609416986102246 | validation: 1.5950457394221773]
	TIME [epoch: 13.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1533603237723715		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.1533603237723715 | validation: 1.119527872402243]
	TIME [epoch: 13.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1961705937975995		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.1961705937975995 | validation: 1.30308827922432]
	TIME [epoch: 13.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1888848843356579		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.1888848843356579 | validation: 0.8894757838188508]
	TIME [epoch: 13.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2189879202313758		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.2189879202313758 | validation: 0.8399963714823251]
	TIME [epoch: 13.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355503780922367		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.1355503780922367 | validation: 1.0310929706547125]
	TIME [epoch: 13.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0521537378197452		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.0521537378197452 | validation: 1.007349395945387]
	TIME [epoch: 13.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7165390142080184		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.7165390142080184 | validation: 1.5993671541467354]
	TIME [epoch: 13.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6405149499351968		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.6405149499351968 | validation: 1.0996294118503565]
	TIME [epoch: 13.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.353237124759555		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.353237124759555 | validation: 0.8937991142580325]
	TIME [epoch: 13.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0939750907688883		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.0939750907688883 | validation: 1.0655424239261786]
	TIME [epoch: 13.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9967511908222852		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.9967511908222852 | validation: 0.7917958111675956]
	TIME [epoch: 13.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9159375442121229		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.9159375442121229 | validation: 0.9791469467487716]
	TIME [epoch: 13.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0930176737912864		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.0930176737912864 | validation: 0.9439163889979174]
	TIME [epoch: 13.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0764741941367075		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.0764741941367075 | validation: 1.3563924314816915]
	TIME [epoch: 13.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.139745255746384		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.139745255746384 | validation: 1.434376346969479]
	TIME [epoch: 13.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094632244642172		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.094632244642172 | validation: 0.8491030649406025]
	TIME [epoch: 13.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.884082448809914		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.884082448809914 | validation: 1.2358929424516698]
	TIME [epoch: 13.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2686594655089154		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.2686594655089154 | validation: 0.7240903100332775]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755328147657173		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8755328147657173 | validation: 1.0321717886040775]
	TIME [epoch: 13.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.337493603298385		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.337493603298385 | validation: 1.170301160589303]
	TIME [epoch: 13.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656492124172035		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.0656492124172035 | validation: 0.9578885148290905]
	TIME [epoch: 13.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9183819795429815		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9183819795429815 | validation: 1.1681374028951776]
	TIME [epoch: 13.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1742778874164828		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.1742778874164828 | validation: 0.931708127984229]
	TIME [epoch: 13.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035951793190723		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.9035951793190723 | validation: 0.7220560998057934]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273509357787172		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.0273509357787172 | validation: 1.1048087492366687]
	TIME [epoch: 13.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8924245791665674		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8924245791665674 | validation: 1.7421169738486992]
	TIME [epoch: 13.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2721814851053233		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.2721814851053233 | validation: 1.0536611291719336]
	TIME [epoch: 13.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478995836043584		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.1478995836043584 | validation: 0.9248439203458568]
	TIME [epoch: 13.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9515483019138622		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.9515483019138622 | validation: 1.131025636901548]
	TIME [epoch: 13.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9544730453810224		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.9544730453810224 | validation: 1.2235721308177823]
	TIME [epoch: 13.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4096910928640212		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.4096910928640212 | validation: 1.1935079542491895]
	TIME [epoch: 13.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3324394556897214		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.3324394556897214 | validation: 0.6805365128793537]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9105672179997958		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9105672179997958 | validation: 0.6651768515163768]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1068748447124965		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.1068748447124965 | validation: 0.9669556633406498]
	TIME [epoch: 13.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3053975859774942		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.3053975859774942 | validation: 1.649983895801574]
	TIME [epoch: 13.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.783563780397162		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.783563780397162 | validation: 1.164075752913118]
	TIME [epoch: 13.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0571638888713604		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.0571638888713604 | validation: 1.2473143870596715]
	TIME [epoch: 13.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0329335913646578		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.0329335913646578 | validation: 1.1101675672255775]
	TIME [epoch: 13.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0737881556332054		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.0737881556332054 | validation: 1.7918656819885022]
	TIME [epoch: 13.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6470238303127624		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.6470238303127624 | validation: 1.166376769975099]
	TIME [epoch: 13.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3060541136440769		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.3060541136440769 | validation: 0.9534490474089432]
	TIME [epoch: 13.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833640975450624		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.8833640975450624 | validation: 0.8053789422289314]
	TIME [epoch: 13.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4742800756994443		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.4742800756994443 | validation: 0.8257068746126857]
	TIME [epoch: 13.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9109832841451715		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.9109832841451715 | validation: 0.8689970855837047]
	TIME [epoch: 13.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0332705000235798		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.0332705000235798 | validation: 1.1584949240440983]
	TIME [epoch: 13.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1421815222731566		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.1421815222731566 | validation: 0.8544842970877999]
	TIME [epoch: 13.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9742741834765551		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.9742741834765551 | validation: 0.9307735159197615]
	TIME [epoch: 13.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.374398263147478		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.374398263147478 | validation: 0.7406970618312788]
	TIME [epoch: 13.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.890904847098184		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.890904847098184 | validation: 1.84498775398286]
	TIME [epoch: 13.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.455368427168024		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.455368427168024 | validation: 1.037112545619025]
	TIME [epoch: 13.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1882608263741998		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.1882608263741998 | validation: 0.8084672365732719]
	TIME [epoch: 13.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8480701938015942		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8480701938015942 | validation: 0.9638827057334024]
	TIME [epoch: 13.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056140127708693		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.056140127708693 | validation: 0.9198892183797174]
	TIME [epoch: 13.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0449078419405287		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.0449078419405287 | validation: 0.8997782672569379]
	TIME [epoch: 13.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9608539674407555		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.9608539674407555 | validation: 1.0081066891212402]
	TIME [epoch: 13.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9912193981365318		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.9912193981365318 | validation: 2.213959677380871]
	TIME [epoch: 13.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378414786342581		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.378414786342581 | validation: 1.035441455247921]
	TIME [epoch: 13.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9400501583986189		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.9400501583986189 | validation: 0.6892069394710311]
	TIME [epoch: 13.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8016091023136396		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.8016091023136396 | validation: 0.9661022757185211]
	TIME [epoch: 13.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9037919404574044		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.9037919404574044 | validation: 0.8228673492714075]
	TIME [epoch: 13.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.849020553908912		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.849020553908912 | validation: 0.6945609006899949]
	TIME [epoch: 13.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380649296458793		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.0380649296458793 | validation: 0.8904020013479617]
	TIME [epoch: 13.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146691686043013		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.146691686043013 | validation: 1.7854098962880982]
	TIME [epoch: 13.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.427382441367331		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.427382441367331 | validation: 1.2599744595259716]
	TIME [epoch: 13.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0974353558768988		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.0974353558768988 | validation: 0.7914097572600616]
	TIME [epoch: 13.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150515960704142		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.150515960704142 | validation: 1.4522219348534469]
	TIME [epoch: 13.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2049542262979724		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.2049542262979724 | validation: 0.6741349307896567]
	TIME [epoch: 13.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7734929861720936		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7734929861720936 | validation: 0.6666598507885562]
	TIME [epoch: 13.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1610186586291307		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.1610186586291307 | validation: 1.2256641472191299]
	TIME [epoch: 13.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1588799347265835		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.1588799347265835 | validation: 1.008192816507195]
	TIME [epoch: 13.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.997002907568554		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.997002907568554 | validation: 0.8513487417785246]
	TIME [epoch: 13.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9715362932801344		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.9715362932801344 | validation: 0.8968362651008652]
	TIME [epoch: 13.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9784002116364146		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.9784002116364146 | validation: 1.357572564944672]
	TIME [epoch: 13.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2317574443200932		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.2317574443200932 | validation: 1.2145879902018606]
	TIME [epoch: 13.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2424975813352561		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.2424975813352561 | validation: 1.108628419433847]
	TIME [epoch: 13.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8992144876739399		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.8992144876739399 | validation: 0.868963930887233]
	TIME [epoch: 13.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047189811858322		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.047189811858322 | validation: 1.003822152934337]
	TIME [epoch: 13.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.902112582927638		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.902112582927638 | validation: 0.6869246751298081]
	TIME [epoch: 13.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0130185286523972		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.0130185286523972 | validation: 2.106505337358452]
	TIME [epoch: 13.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2962166818314718		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.2962166818314718 | validation: 0.9232703880526987]
	TIME [epoch: 13.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033295165536309		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.033295165536309 | validation: 1.373590576604665]
	TIME [epoch: 13.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9986392878326518		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.9986392878326518 | validation: 0.7166383104950446]
	TIME [epoch: 13.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9519406900198509		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.9519406900198509 | validation: 1.4491475953974169]
	TIME [epoch: 13.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1343784460658501		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.1343784460658501 | validation: 0.7393036547017202]
	TIME [epoch: 13.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8577682511476534		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8577682511476534 | validation: 0.7891507535664671]
	TIME [epoch: 13.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8577881054375917		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.8577881054375917 | validation: 0.649794671682443]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0846063770607886		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.0846063770607886 | validation: 0.8902968392631914]
	TIME [epoch: 13.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8231688816536741		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.8231688816536741 | validation: 0.7430826342514789]
	TIME [epoch: 13.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8836789402711354		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.8836789402711354 | validation: 0.7573201923608065]
	TIME [epoch: 13.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252331445726521		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.252331445726521 | validation: 1.050438176087716]
	TIME [epoch: 13.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1990925506975645		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.1990925506975645 | validation: 0.8276397808226108]
	TIME [epoch: 13.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9252053902810389		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.9252053902810389 | validation: 0.6952744282579616]
	TIME [epoch: 13.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453181423571595		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7453181423571595 | validation: 0.9248573971957579]
	TIME [epoch: 13.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8146083983823891		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.8146083983823891 | validation: 0.7145817200050836]
	TIME [epoch: 13.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998248880444272		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7998248880444272 | validation: 0.7522308581480124]
	TIME [epoch: 13.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7359476265343903		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.7359476265343903 | validation: 0.48182638806400263]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0894001851538526		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.0894001851538526 | validation: 1.0679001464829747]
	TIME [epoch: 13.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9598212944907316		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.9598212944907316 | validation: 0.7008297182482882]
	TIME [epoch: 13.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6548613037957745		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6548613037957745 | validation: 1.3934849355762986]
	TIME [epoch: 13.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2975415495712892		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.2975415495712892 | validation: 1.0438417878335147]
	TIME [epoch: 13.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7578404101760734		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7578404101760734 | validation: 0.7886292871791714]
	TIME [epoch: 13.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8318673947892692		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.8318673947892692 | validation: 0.6663828906008832]
	TIME [epoch: 13.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.676311481966581		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.676311481966581 | validation: 0.662945461197547]
	TIME [epoch: 13.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1661870464509088		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.1661870464509088 | validation: 1.196803979286897]
	TIME [epoch: 13.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782011985996064		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.8782011985996064 | validation: 1.522098784666053]
	TIME [epoch: 13.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0689430808834748		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.0689430808834748 | validation: 0.5625465596418795]
	TIME [epoch: 13.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1950192059915818		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.1950192059915818 | validation: 0.8678493757394529]
	TIME [epoch: 13.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9779580625445601		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.9779580625445601 | validation: 0.6930848574112468]
	TIME [epoch: 13.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220456925596305		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7220456925596305 | validation: 0.7117846884774403]
	TIME [epoch: 13.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6928569809100512		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6928569809100512 | validation: 0.7634812633580856]
	TIME [epoch: 13.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731361021545535		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7731361021545535 | validation: 0.616109921673245]
	TIME [epoch: 13.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459452777219392		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6459452777219392 | validation: 0.6826155323317449]
	TIME [epoch: 13.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186051827015041		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.8186051827015041 | validation: 0.8107000958217517]
	TIME [epoch: 13.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3675761568275027		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.3675761568275027 | validation: 1.2795518587760843]
	TIME [epoch: 13.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4542059159559702		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.4542059159559702 | validation: 0.7095112293197608]
	TIME [epoch: 13.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1030918465251076		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.1030918465251076 | validation: 0.6281998875409176]
	TIME [epoch: 13.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8283623049118648		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.8283623049118648 | validation: 0.5895544212304956]
	TIME [epoch: 13.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8190416866191486		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.8190416866191486 | validation: 1.0172582566473307]
	TIME [epoch: 13.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088107786048696		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8088107786048696 | validation: 1.6906669204477682]
	TIME [epoch: 13.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3741985946450992		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.3741985946450992 | validation: 0.9341172643228578]
	TIME [epoch: 13.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8648241723599223		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.8648241723599223 | validation: 0.6366721888431276]
	TIME [epoch: 13.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6355958526700409		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.6355958526700409 | validation: 0.6318696886647989]
	TIME [epoch: 13.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687028566409815		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.8687028566409815 | validation: 1.1173353840395006]
	TIME [epoch: 13.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8150008447439809		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.8150008447439809 | validation: 0.876674630601004]
	TIME [epoch: 13.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8784880654139381		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.8784880654139381 | validation: 0.5176319202173183]
	TIME [epoch: 13.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307138533479717		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.8307138533479717 | validation: 0.6413248800625229]
	TIME [epoch: 13.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286681267488994		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6286681267488994 | validation: 0.5499550593376347]
	TIME [epoch: 13.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927337710186859		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.6927337710186859 | validation: 0.6598320523349029]
	TIME [epoch: 13.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604243848440228		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6604243848440228 | validation: 0.6419576922424074]
	TIME [epoch: 13.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4429661115288424		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.4429661115288424 | validation: 2.4207103839750257]
	TIME [epoch: 13.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290848284055907		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.290848284055907 | validation: 0.9087688764232031]
	TIME [epoch: 13.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6670121187511334		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6670121187511334 | validation: 0.6151460416801843]
	TIME [epoch: 13.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336423273252637		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6336423273252637 | validation: 0.8382154846981957]
	TIME [epoch: 13.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692860777934428		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.7692860777934428 | validation: 0.716323270498207]
	TIME [epoch: 13.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310561876965298		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7310561876965298 | validation: 0.45720981923566073]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147122723668756		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7147122723668756 | validation: 0.8641136590115854]
	TIME [epoch: 13.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7732795130038742		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.7732795130038742 | validation: 0.5848186516365723]
	TIME [epoch: 13.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747155932521038		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5747155932521038 | validation: 0.7794617830323057]
	TIME [epoch: 13.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0972662896678578		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.0972662896678578 | validation: 0.7978959146248508]
	TIME [epoch: 13.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964784781778863		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6964784781778863 | validation: 0.6470680264414225]
	TIME [epoch: 13.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120047212670446		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.7120047212670446 | validation: 0.8488238633504024]
	TIME [epoch: 13.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740669736574304		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.8740669736574304 | validation: 0.7325847520137322]
	TIME [epoch: 13.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6456546201243087		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6456546201243087 | validation: 0.5073461517354175]
	TIME [epoch: 13.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.883368296251766		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.883368296251766 | validation: 0.8075925418924464]
	TIME [epoch: 13.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8197304241406068		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8197304241406068 | validation: 0.6305902710675844]
	TIME [epoch: 13.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9110329174311278		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.9110329174311278 | validation: 0.8306426372818047]
	TIME [epoch: 13.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885241712396593		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.7885241712396593 | validation: 1.2035973549026129]
	TIME [epoch: 13.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128800960789313		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.8128800960789313 | validation: 0.6966245713777898]
	TIME [epoch: 13.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0070436871665285		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.0070436871665285 | validation: 1.033110240342344]
	TIME [epoch: 13.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0898217601114466		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.0898217601114466 | validation: 0.5592245080503062]
	TIME [epoch: 13.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7933163431015462		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7933163431015462 | validation: 0.51472984205455]
	TIME [epoch: 13.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5239449285508864		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5239449285508864 | validation: 1.0811085617403178]
	TIME [epoch: 13.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520986765432954		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7520986765432954 | validation: 0.682267441862807]
	TIME [epoch: 13.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782353746304053		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6782353746304053 | validation: 0.5041231159417374]
	TIME [epoch: 13.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998272479587425		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.7998272479587425 | validation: 1.0576339327934843]
	TIME [epoch: 13.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0814084999515432		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.0814084999515432 | validation: 0.6745033849267495]
	TIME [epoch: 13.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683229092023441		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.683229092023441 | validation: 0.5877207330463124]
	TIME [epoch: 13.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8941315236911197		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8941315236911197 | validation: 0.8373933582704873]
	TIME [epoch: 13.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7169195802799478		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7169195802799478 | validation: 0.641264612690691]
	TIME [epoch: 13.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844826405244541		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.6844826405244541 | validation: 0.7570192004107346]
	TIME [epoch: 13.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7583450167076146		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7583450167076146 | validation: 0.5409464510829066]
	TIME [epoch: 13.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5823801428180376		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5823801428180376 | validation: 0.4543190169111731]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411847035844704		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7411847035844704 | validation: 0.8302704025860778]
	TIME [epoch: 13.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100751643270771		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.9100751643270771 | validation: 1.335744040298117]
	TIME [epoch: 13.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9300306563568468		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.9300306563568468 | validation: 0.49834839486530713]
	TIME [epoch: 13.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73668527747459		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.73668527747459 | validation: 0.5722800367311516]
	TIME [epoch: 13.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162939952670865		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.6162939952670865 | validation: 0.49988613332824444]
	TIME [epoch: 13.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3029959713892658		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.3029959713892658 | validation: 0.8273412732510176]
	TIME [epoch: 13.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024461456154598		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7024461456154598 | validation: 0.5643694361508365]
	TIME [epoch: 13.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677328045537082		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5677328045537082 | validation: 0.5824468932106771]
	TIME [epoch: 13.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714717213148489		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5714717213148489 | validation: 1.1739785530549502]
	TIME [epoch: 13.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094115682539176		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.094115682539176 | validation: 0.6723544085582595]
	TIME [epoch: 13.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6611740737334644		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6611740737334644 | validation: 0.5572369737953993]
	TIME [epoch: 13.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6802023717332839		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6802023717332839 | validation: 0.8626304941475548]
	TIME [epoch: 13.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8300756149147127		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.8300756149147127 | validation: 0.5995874326687334]
	TIME [epoch: 13.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6641839486834433		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.6641839486834433 | validation: 0.5422908491016775]
	TIME [epoch: 13.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883077313369134		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5883077313369134 | validation: 1.2970469213945273]
	TIME [epoch: 13.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9156618277386276		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.9156618277386276 | validation: 0.7297918694419537]
	TIME [epoch: 13.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952092206150785		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6952092206150785 | validation: 0.5072208405672078]
	TIME [epoch: 13.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9429937672796223		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.9429937672796223 | validation: 1.1967572067660708]
	TIME [epoch: 13.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.899346387333646		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.899346387333646 | validation: 0.5632909150266213]
	TIME [epoch: 13.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559762859090489		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.559762859090489 | validation: 0.774234166441472]
	TIME [epoch: 13.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6590055035640717		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6590055035640717 | validation: 0.6575900560987913]
	TIME [epoch: 13.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7504408200562717		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.7504408200562717 | validation: 0.5030832374689967]
	TIME [epoch: 13.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708216801123218		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.6708216801123218 | validation: 0.8732809345918691]
	TIME [epoch: 13.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722864502146213		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7722864502146213 | validation: 0.8194681294211378]
	TIME [epoch: 13.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734898760364799		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.734898760364799 | validation: 0.5971133679335782]
	TIME [epoch: 13.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599824181183686		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.6599824181183686 | validation: 0.6755742160130299]
	TIME [epoch: 13.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8305147198276444		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.8305147198276444 | validation: 0.5894869858975663]
	TIME [epoch: 13.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353423557015322		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6353423557015322 | validation: 0.6388507315395678]
	TIME [epoch: 13.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819794381957573		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6819794381957573 | validation: 0.6839272114863799]
	TIME [epoch: 13.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322157381720731		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.6322157381720731 | validation: 0.4774031462654984]
	TIME [epoch: 13.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5895287408077203		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5895287408077203 | validation: 0.6443610933166813]
	TIME [epoch: 13.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878944607587953		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.5878944607587953 | validation: 0.47329580764989077]
	TIME [epoch: 13.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6050921210488781		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6050921210488781 | validation: 0.4222504153212077]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7396499953063496		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7396499953063496 | validation: 0.4255323371878225]
	TIME [epoch: 13.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118924099573635		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7118924099573635 | validation: 0.45185859805288375]
	TIME [epoch: 13.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461248569731147		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5461248569731147 | validation: 0.5415556625987172]
	TIME [epoch: 13.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516718837203995		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5516718837203995 | validation: 0.6300790152127835]
	TIME [epoch: 13.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463116475370863		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.6463116475370863 | validation: 0.5002003228952654]
	TIME [epoch: 13.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5538353663153301		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5538353663153301 | validation: 0.4504081640880686]
	TIME [epoch: 13.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5704584782254829		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.5704584782254829 | validation: 0.5343657598208001]
	TIME [epoch: 13.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018750327785334		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5018750327785334 | validation: 0.5341920561194511]
	TIME [epoch: 13.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782616810682124		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.782616810682124 | validation: 0.6325993404506215]
	TIME [epoch: 13.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410497904628943		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.7410497904628943 | validation: 0.7021560657072482]
	TIME [epoch: 13.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911835234174426		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.6911835234174426 | validation: 0.6076546299742952]
	TIME [epoch: 13.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49824835216217006		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.49824835216217006 | validation: 1.2888123864426002]
	TIME [epoch: 13.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229997032850278		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.8229997032850278 | validation: 0.6675016298883826]
	TIME [epoch: 13.1 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235194183353516		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5235194183353516 | validation: 0.8315420279723341]
	TIME [epoch: 13.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117529152208552		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7117529152208552 | validation: 0.6767333926154936]
	TIME [epoch: 13.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6318404667530985		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6318404667530985 | validation: 0.6566167150931449]
	TIME [epoch: 13.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2331460927614888		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.2331460927614888 | validation: 1.50879064953228]
	TIME [epoch: 13.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0094769051333974		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 1.0094769051333974 | validation: 0.57905410121519]
	TIME [epoch: 13.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962339970844731		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.6962339970844731 | validation: 0.5745951787240291]
	TIME [epoch: 13.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302352820501504		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.7302352820501504 | validation: 0.5043578283279905]
	TIME [epoch: 13.1 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556241280612497		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.5556241280612497 | validation: 0.44954470428269633]
	TIME [epoch: 13.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137270960514091		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.5137270960514091 | validation: 0.7395081610258731]
	TIME [epoch: 13.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58422869768978		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.58422869768978 | validation: 0.7095216488546169]
	TIME [epoch: 13.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7668814491285411		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.7668814491285411 | validation: 1.9940031689580968]
	TIME [epoch: 13.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1339697451902873		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.1339697451902873 | validation: 0.7298587869548723]
	TIME [epoch: 13.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727599475986763		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6727599475986763 | validation: 0.6649422947368556]
	TIME [epoch: 13.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211577325148442		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.211577325148442 | validation: 0.9169422624146119]
	TIME [epoch: 13.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353797655004655		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.7353797655004655 | validation: 0.456398359099179]
	TIME [epoch: 13.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600853609824628		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.4600853609824628 | validation: 0.5237695024377651]
	TIME [epoch: 13.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630116558535819		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.5630116558535819 | validation: 1.2054136209650184]
	TIME [epoch: 13.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381114419686082		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.0381114419686082 | validation: 0.8849088447184049]
	TIME [epoch: 13.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481165715939441		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6481165715939441 | validation: 0.4986943123020187]
	TIME [epoch: 13.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184493379270235		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5184493379270235 | validation: 0.5572705560463728]
	TIME [epoch: 13.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.666855777142193		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.666855777142193 | validation: 0.6897345481437382]
	TIME [epoch: 13.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465753132380059		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5465753132380059 | validation: 0.431596678829266]
	TIME [epoch: 13.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490325313088394		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5490325313088394 | validation: 0.5866528803013599]
	TIME [epoch: 13.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438639825975593		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5438639825975593 | validation: 0.9635510817333878]
	TIME [epoch: 13.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469519299437694		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6469519299437694 | validation: 0.5864133962712035]
	TIME [epoch: 13.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237744883471164		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.5237744883471164 | validation: 0.9042890250579211]
	TIME [epoch: 13.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7550434600224489		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7550434600224489 | validation: 0.4982217530707699]
	TIME [epoch: 13.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548490865543123		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5548490865543123 | validation: 0.6907206834449341]
	TIME [epoch: 13.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073499720981528		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6073499720981528 | validation: 0.7687142130792086]
	TIME [epoch: 13.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687608522182481		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.687608522182481 | validation: 0.5132359519783735]
	TIME [epoch: 13.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236922844586213		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.7236922844586213 | validation: 0.6120344631866103]
	TIME [epoch: 13.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413272707888689		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5413272707888689 | validation: 0.45000727584863165]
	TIME [epoch: 13.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762675704059952		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.5762675704059952 | validation: 0.5746945842949468]
	TIME [epoch: 13.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589849119798286		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6589849119798286 | validation: 0.6284888231445366]
	TIME [epoch: 13.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078771745654883		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5078771745654883 | validation: 0.5490764316771736]
	TIME [epoch: 13.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47776458641417885		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.47776458641417885 | validation: 0.5325511126407858]
	TIME [epoch: 13.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690655811963283		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5690655811963283 | validation: 0.7713673566098221]
	TIME [epoch: 13.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0138540077990665		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.0138540077990665 | validation: 0.5666223131254757]
	TIME [epoch: 13.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237171954236284		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.5237171954236284 | validation: 0.48940307877539824]
	TIME [epoch: 13.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575851246441486		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.575851246441486 | validation: 0.5449075721431234]
	TIME [epoch: 13.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5977935044322141		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5977935044322141 | validation: 0.6181272887915094]
	TIME [epoch: 13.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432428763730883		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6432428763730883 | validation: 0.5523488340042212]
	TIME [epoch: 13.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464660343492596		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5464660343492596 | validation: 0.45611692039526275]
	TIME [epoch: 13.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43193257512847183		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.43193257512847183 | validation: 0.5369160685658025]
	TIME [epoch: 13.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5344520735609748		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.5344520735609748 | validation: 0.7488105798605064]
	TIME [epoch: 13.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6212546179352411		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6212546179352411 | validation: 0.4906740806788541]
	TIME [epoch: 13.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553319784941915		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5553319784941915 | validation: 0.750648199055731]
	TIME [epoch: 13.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519602928818907		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5519602928818907 | validation: 0.5918973963716866]
	TIME [epoch: 13.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4592102821743632		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.4592102821743632 | validation: 0.8984829953302952]
	TIME [epoch: 13.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591792204354002		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.591792204354002 | validation: 0.6821982847742496]
	TIME [epoch: 13.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49349804824300947		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.49349804824300947 | validation: 0.4225831066411603]
	TIME [epoch: 13.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540472069585892		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6540472069585892 | validation: 0.8121821173215606]
	TIME [epoch: 13.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0976892425839853		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.0976892425839853 | validation: 0.6750501720707294]
	TIME [epoch: 13.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956357580835169		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6956357580835169 | validation: 0.6176856787865677]
	TIME [epoch: 13.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.566144242659645		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.566144242659645 | validation: 0.5008293076048804]
	TIME [epoch: 13.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722319562911827		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5722319562911827 | validation: 0.44715049607829954]
	TIME [epoch: 13.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273662241556771		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7273662241556771 | validation: 0.6366438116723813]
	TIME [epoch: 13.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522873436508544		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.522873436508544 | validation: 0.4950059111782816]
	TIME [epoch: 13.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744729243378302		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.4744729243378302 | validation: 0.3901021894164735]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_573.pth
	Model improved!!!
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42671737321456404		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.42671737321456404 | validation: 0.6271510044180874]
	TIME [epoch: 13.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608563206501854		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.6608563206501854 | validation: 0.6705888531510991]
	TIME [epoch: 13.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5570130232676685		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5570130232676685 | validation: 0.4882996630756922]
	TIME [epoch: 13.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49773333749381843		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.49773333749381843 | validation: 1.051177882394732]
	TIME [epoch: 13.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182513387644434		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.8182513387644434 | validation: 0.5763770335889014]
	TIME [epoch: 13.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083186915260353		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6083186915260353 | validation: 0.9769253755041125]
	TIME [epoch: 13.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871440772738215		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6871440772738215 | validation: 0.5430406266706519]
	TIME [epoch: 13.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6072486434537114		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6072486434537114 | validation: 0.7860932682127793]
	TIME [epoch: 13.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391269020520157		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6391269020520157 | validation: 0.6196473486862865]
	TIME [epoch: 13.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088320862741693		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6088320862741693 | validation: 0.6360469039807444]
	TIME [epoch: 13.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9156876585919655		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.9156876585919655 | validation: 0.5727299027493777]
	TIME [epoch: 13.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6161093031435122		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.6161093031435122 | validation: 0.7128338493974374]
	TIME [epoch: 13.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161630389058811		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5161630389058811 | validation: 0.5001849329061442]
	TIME [epoch: 13.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638333349691764		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5638333349691764 | validation: 0.5448290108287931]
	TIME [epoch: 13.1 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805892402243548		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.805892402243548 | validation: 0.7201705889811117]
	TIME [epoch: 13.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603879068664873		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.6603879068664873 | validation: 0.549579475450234]
	TIME [epoch: 13.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571625308323734		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.571625308323734 | validation: 0.46245279798271893]
	TIME [epoch: 13.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4579486682924269		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.4579486682924269 | validation: 0.6052504036851788]
	TIME [epoch: 13.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464778681335554		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5464778681335554 | validation: 0.6336718359268301]
	TIME [epoch: 13.1 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579459847039053		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6579459847039053 | validation: 0.3956487351513646]
	TIME [epoch: 13.1 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641947036595603		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5641947036595603 | validation: 0.4172445551581733]
	TIME [epoch: 13.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833340506973463		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.4833340506973463 | validation: 0.5348709741544206]
	TIME [epoch: 13.1 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794819075326452		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.5794819075326452 | validation: 0.6597987466084289]
	TIME [epoch: 13.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991472394709147		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.6991472394709147 | validation: 0.8183633724451526]
	TIME [epoch: 13.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041948039178807		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6041948039178807 | validation: 0.4211998011968842]
	TIME [epoch: 13.1 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805937059841586		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.4805937059841586 | validation: 0.6265661080343982]
	TIME [epoch: 13.1 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595456945439375		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.595456945439375 | validation: 0.8319300922364816]
	TIME [epoch: 13.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238857139149475		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6238857139149475 | validation: 0.46095553483277996]
	TIME [epoch: 13.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191912894401283		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4191912894401283 | validation: 0.41998390876146047]
	TIME [epoch: 13.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6316340281575794		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6316340281575794 | validation: 0.7119347894732172]
	TIME [epoch: 13.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985428491386849		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6985428491386849 | validation: 0.4528066049484143]
	TIME [epoch: 13.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331211817390751		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5331211817390751 | validation: 0.5586837197730462]
	TIME [epoch: 13.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515768455790008		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.5515768455790008 | validation: 0.39645274400845815]
	TIME [epoch: 13.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39286926182781606		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.39286926182781606 | validation: 0.502317804582935]
	TIME [epoch: 13.1 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43435105492266024		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.43435105492266024 | validation: 0.400560380397785]
	TIME [epoch: 13.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8263014676451919		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.8263014676451919 | validation: 0.492106779670603]
	TIME [epoch: 13.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4902854870068374		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.4902854870068374 | validation: 0.7031173433905831]
	TIME [epoch: 13.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483276096285742		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5483276096285742 | validation: 0.4506859717129571]
	TIME [epoch: 13.1 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.488121944731736		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.488121944731736 | validation: 0.5781379451806656]
	TIME [epoch: 13.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265309146373165		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6265309146373165 | validation: 0.9849881001523173]
	TIME [epoch: 13.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569763260268255		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5569763260268255 | validation: 0.6258665908775892]
	TIME [epoch: 13.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936968455994341		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.5936968455994341 | validation: 0.4139023711849943]
	TIME [epoch: 13.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6568952601686062		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.6568952601686062 | validation: 0.4632655448368655]
	TIME [epoch: 13.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5433301534860051		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5433301534860051 | validation: 0.462635785879427]
	TIME [epoch: 13.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8689722175689296		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.8689722175689296 | validation: 0.7238577616161408]
	TIME [epoch: 13.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.58361088338063		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.58361088338063 | validation: 0.5729730549772177]
	TIME [epoch: 13.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749938441162313		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5749938441162313 | validation: 0.5478338394712888]
	TIME [epoch: 13.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7566026410497031		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.7566026410497031 | validation: 0.4660179470759447]
	TIME [epoch: 13.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561325958918306		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.4561325958918306 | validation: 1.2741667533069714]
	TIME [epoch: 13.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1171028395063083		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.1171028395063083 | validation: 0.4913829878106733]
	TIME [epoch: 13.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155051787961821		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5155051787961821 | validation: 0.4489223398686877]
	TIME [epoch: 13.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016060545640877		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.5016060545640877 | validation: 0.475659182141107]
	TIME [epoch: 13.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3915782269433495		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3915782269433495 | validation: 0.44485922735767836]
	TIME [epoch: 13.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600995481697493		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5600995481697493 | validation: 0.6296712022048346]
	TIME [epoch: 13.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.585574807836891		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.585574807836891 | validation: 0.5388101442642996]
	TIME [epoch: 13.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240621172218278		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5240621172218278 | validation: 0.5511565590418189]
	TIME [epoch: 13.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571883176492629		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.4571883176492629 | validation: 0.4852820239921026]
	TIME [epoch: 13.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881853452145652		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.4881853452145652 | validation: 0.5341435808250816]
	TIME [epoch: 13.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482560571758234		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5482560571758234 | validation: 0.42912293312449673]
	TIME [epoch: 13.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182717243114843		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.4182717243114843 | validation: 0.4765932875425447]
	TIME [epoch: 13.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536046906715072		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6536046906715072 | validation: 0.6571196186841352]
	TIME [epoch: 13.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617234794246787		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5617234794246787 | validation: 0.592364146583718]
	TIME [epoch: 13.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46186253839776503		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.46186253839776503 | validation: 0.6872834512678528]
	TIME [epoch: 13.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5658958859490822		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5658958859490822 | validation: 1.0477669676624928]
	TIME [epoch: 13.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368602666651672		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.0368602666651672 | validation: 0.45668473929434145]
	TIME [epoch: 13.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4724666961757061		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4724666961757061 | validation: 0.39696379269216153]
	TIME [epoch: 13.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238182897426196		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.4238182897426196 | validation: 0.3641885433952018]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_640.pth
	Model improved!!!
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40623280504742104		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.40623280504742104 | validation: 0.7221503218554114]
	TIME [epoch: 13.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049223022844671		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.6049223022844671 | validation: 0.5603320986000959]
	TIME [epoch: 13.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030736928541802		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5030736928541802 | validation: 0.4289790420895568]
	TIME [epoch: 13.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43636201623150944		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.43636201623150944 | validation: 0.6213870369035347]
	TIME [epoch: 13.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703534177995306		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.703534177995306 | validation: 0.45718795396227413]
	TIME [epoch: 13.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47661069728902505		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.47661069728902505 | validation: 0.3793307279683905]
	TIME [epoch: 13.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40699606607108696		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.40699606607108696 | validation: 0.3737524553717779]
	TIME [epoch: 13.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42462204050358693		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.42462204050358693 | validation: 0.7243323130995812]
	TIME [epoch: 13.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7130992626275571		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.7130992626275571 | validation: 0.5481743858200061]
	TIME [epoch: 13.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4313328936232549		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.4313328936232549 | validation: 0.4178410575784852]
	TIME [epoch: 13.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578142220253135		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.578142220253135 | validation: 0.927283705665065]
	TIME [epoch: 13.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083332069625632		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.7083332069625632 | validation: 0.781383181883207]
	TIME [epoch: 13.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6412806943085183		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.6412806943085183 | validation: 0.452771088900699]
	TIME [epoch: 13.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608006336175642		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.4608006336175642 | validation: 0.49080876966537523]
	TIME [epoch: 13.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47235973697834804		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.47235973697834804 | validation: 0.5497244108026319]
	TIME [epoch: 13.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5978457961937228		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5978457961937228 | validation: 0.46545572888211534]
	TIME [epoch: 13.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47090976109814975		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.47090976109814975 | validation: 0.6916749233244162]
	TIME [epoch: 13.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.581132475609581		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.581132475609581 | validation: 0.4547770881184488]
	TIME [epoch: 13.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45346081160200324		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.45346081160200324 | validation: 0.5512096832128608]
	TIME [epoch: 13.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017828134440684		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.6017828134440684 | validation: 0.674431788238653]
	TIME [epoch: 13.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398801351473624		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5398801351473624 | validation: 0.42413038700875916]
	TIME [epoch: 13.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185231523266554		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5185231523266554 | validation: 1.739392066531387]
	TIME [epoch: 13.1 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.175077188725465		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.175077188725465 | validation: 0.4952781625808174]
	TIME [epoch: 13.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454318390407439		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.4454318390407439 | validation: 0.450193560612621]
	TIME [epoch: 13.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3823102468178336		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3823102468178336 | validation: 0.40871813779479704]
	TIME [epoch: 13.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4620901456047627		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.4620901456047627 | validation: 0.5312805277697251]
	TIME [epoch: 13.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4243385703324239		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4243385703324239 | validation: 0.3773833020888263]
	TIME [epoch: 13.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4308517180560341		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.4308517180560341 | validation: 0.5752625016828885]
	TIME [epoch: 13.1 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318167454598433		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5318167454598433 | validation: 0.5825445410750384]
	TIME [epoch: 13.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805345173039173		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.6805345173039173 | validation: 0.8846260647338221]
	TIME [epoch: 13.1 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6087849670835194		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.6087849670835194 | validation: 0.47466056355628006]
	TIME [epoch: 13.1 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002761903319777		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.4002761903319777 | validation: 0.5013659858641338]
	TIME [epoch: 13.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42760114868751664		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.42760114868751664 | validation: 0.34999873755661026]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46327119189901955		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.46327119189901955 | validation: 0.5349667227868957]
	TIME [epoch: 13.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38331486627274225		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.38331486627274225 | validation: 0.4354293962470834]
	TIME [epoch: 13.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34604434937772227		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.34604434937772227 | validation: 0.46656953055408923]
	TIME [epoch: 13.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329888200246986		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.7329888200246986 | validation: 0.6123714601595773]
	TIME [epoch: 13.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6120327342019223		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6120327342019223 | validation: 0.3695996905768604]
	TIME [epoch: 13 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46194039544505583		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.46194039544505583 | validation: 0.567587645782152]
	TIME [epoch: 13.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684529891574921		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.684529891574921 | validation: 0.5143148760685099]
	TIME [epoch: 13.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.445763845321326		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.445763845321326 | validation: 0.7395017623914693]
	TIME [epoch: 13.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696636935024938		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5696636935024938 | validation: 0.6316794774922627]
	TIME [epoch: 13.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497620641551393		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.497620641551393 | validation: 0.39109394050241847]
	TIME [epoch: 13.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255238560432625		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.4255238560432625 | validation: 0.5989891791615924]
	TIME [epoch: 13.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273581857240894		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.4273581857240894 | validation: 0.36550179158949264]
	TIME [epoch: 13.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4270376983055182		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.4270376983055182 | validation: 0.4036469037605588]
	TIME [epoch: 13.1 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231147769854585		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5231147769854585 | validation: 0.8444099482168466]
	TIME [epoch: 13.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5583638140278642		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5583638140278642 | validation: 0.3112203003125814]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452537940564379		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.452537940564379 | validation: 0.443767145953009]
	TIME [epoch: 13.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697577024105989		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.4697577024105989 | validation: 0.3560904065268785]
	TIME [epoch: 13.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196697763939558		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.7196697763939558 | validation: 0.6078372877533446]
	TIME [epoch: 13.1 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688965638257635		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5688965638257635 | validation: 0.4741191398754592]
	TIME [epoch: 13.1 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5798620468868463		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.5798620468868463 | validation: 0.404408097730434]
	TIME [epoch: 13.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38512308405843954		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.38512308405843954 | validation: 0.3446127623560969]
	TIME [epoch: 13.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599529081800558		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3599529081800558 | validation: 0.4944675036491535]
	TIME [epoch: 13.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39443548965063785		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.39443548965063785 | validation: 0.4684408907233391]
	TIME [epoch: 13.1 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3873925110070655		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3873925110070655 | validation: 0.40605320307903453]
	TIME [epoch: 13.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41269786657789054		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.41269786657789054 | validation: 0.5152817160429871]
	TIME [epoch: 13.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42672210116538173		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.42672210116538173 | validation: 0.3905893900657844]
	TIME [epoch: 13.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163385233694002		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5163385233694002 | validation: 0.41759463640519395]
	TIME [epoch: 13.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.398593644770792		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.398593644770792 | validation: 0.4989113929200666]
	TIME [epoch: 13.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5073367679412699		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.5073367679412699 | validation: 0.4212099105735067]
	TIME [epoch: 13.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941602802804644		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3941602802804644 | validation: 0.517787343642489]
	TIME [epoch: 13.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41107401292576107		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.41107401292576107 | validation: 0.44642199144888994]
	TIME [epoch: 13.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48960309669611823		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.48960309669611823 | validation: 0.3815569297743718]
	TIME [epoch: 13.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709592760650285		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3709592760650285 | validation: 0.4807042282455407]
	TIME [epoch: 13.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48495058911077105		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.48495058911077105 | validation: 0.38936707184945]
	TIME [epoch: 13.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452844226034326		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.452844226034326 | validation: 0.3985096256833476]
	TIME [epoch: 13.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6752133456251725		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.6752133456251725 | validation: 0.5416037365796579]
	TIME [epoch: 13.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277013512116184		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.6277013512116184 | validation: 0.5902431807395995]
	TIME [epoch: 13.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549234519423779		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.5549234519423779 | validation: 0.394770145499803]
	TIME [epoch: 13.1 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46690095173882434		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.46690095173882434 | validation: 0.4896884172647195]
	TIME [epoch: 13.1 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930624794931842		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3930624794931842 | validation: 0.38855225029144536]
	TIME [epoch: 13.1 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44815962693169664		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.44815962693169664 | validation: 0.3992842964730599]
	TIME [epoch: 13.1 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4409780717304371		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.4409780717304371 | validation: 0.5201119433321422]
	TIME [epoch: 13.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39223495556790733		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.39223495556790733 | validation: 0.6081960316796416]
	TIME [epoch: 13.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46629542919503486		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.46629542919503486 | validation: 0.7510220999361144]
	TIME [epoch: 13.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4724688342319415		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.4724688342319415 | validation: 0.8649601634330105]
	TIME [epoch: 13.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599828318347936		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.6599828318347936 | validation: 0.30910078382574435]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119382824632658		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3119382824632658 | validation: 0.34312103532005395]
	TIME [epoch: 13.1 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402600301165973		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.3402600301165973 | validation: 0.4441526930839376]
	TIME [epoch: 13.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3874263043915136		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.3874263043915136 | validation: 0.34230077551254084]
	TIME [epoch: 13.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4373688133423083		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.4373688133423083 | validation: 0.4442319968760651]
	TIME [epoch: 13.1 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48906130422892014		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.48906130422892014 | validation: 0.4450381093212613]
	TIME [epoch: 13.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389133666768455		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5389133666768455 | validation: 0.3659602038616559]
	TIME [epoch: 13.1 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230885137578519		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.3230885137578519 | validation: 0.4247963183795555]
	TIME [epoch: 13.1 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585633651637701		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.3585633651637701 | validation: 0.36623158335368106]
	TIME [epoch: 13.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37385246603270716		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.37385246603270716 | validation: 0.38722345555038373]
	TIME [epoch: 13.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3557728807172169		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3557728807172169 | validation: 0.3530496394802449]
	TIME [epoch: 13.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778733709194014		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5778733709194014 | validation: 0.5155447561419807]
	TIME [epoch: 13.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39121273402616197		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.39121273402616197 | validation: 0.2887446088945693]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_731.pth
	Model improved!!!
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35624348116645477		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.35624348116645477 | validation: 0.510265274139215]
	TIME [epoch: 13.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47130263462852623		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.47130263462852623 | validation: 0.44235196582298]
	TIME [epoch: 13.1 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113112720919133		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5113112720919133 | validation: 0.7044402822883649]
	TIME [epoch: 13.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242774104877252		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5242774104877252 | validation: 0.5425757776093706]
	TIME [epoch: 13.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473311636256936		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4473311636256936 | validation: 0.4167070796536384]
	TIME [epoch: 13.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49165078272724		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.49165078272724 | validation: 0.3450481332111751]
	TIME [epoch: 13.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413847139083399		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.3413847139083399 | validation: 0.3936683055388116]
	TIME [epoch: 13.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522881713853805		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.3522881713853805 | validation: 0.33143441199695517]
	TIME [epoch: 13.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48044729390519103		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.48044729390519103 | validation: 0.49709585416487384]
	TIME [epoch: 13.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.335272940054238		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.335272940054238 | validation: 0.3023406458034851]
	TIME [epoch: 13.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35420351290758295		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.35420351290758295 | validation: 0.3740468759370599]
	TIME [epoch: 13.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36392579119104923		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.36392579119104923 | validation: 0.2912525286896594]
	TIME [epoch: 13.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35184541833066363		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.35184541833066363 | validation: 0.5156258610073354]
	TIME [epoch: 13.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40174138631316225		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.40174138631316225 | validation: 0.31869987290778473]
	TIME [epoch: 13.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171839879726592		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3171839879726592 | validation: 0.35218616582389084]
	TIME [epoch: 13.1 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38559939183700187		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.38559939183700187 | validation: 0.438921293207078]
	TIME [epoch: 13.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34637812551480485		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.34637812551480485 | validation: 0.5103869873281736]
	TIME [epoch: 13.1 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37272877766647705		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.37272877766647705 | validation: 0.3215791173544845]
	TIME [epoch: 13.1 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33801158934962616		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.33801158934962616 | validation: 0.5046333389816968]
	TIME [epoch: 13.1 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37615784173521294		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.37615784173521294 | validation: 0.3390223515913872]
	TIME [epoch: 13.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344514475945806		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.344514475945806 | validation: 0.4383062436134387]
	TIME [epoch: 13.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36144452567548413		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.36144452567548413 | validation: 0.49970429160158]
	TIME [epoch: 13.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43871493240846204		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.43871493240846204 | validation: 0.29599832255198516]
	TIME [epoch: 13.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091883530023286		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.3091883530023286 | validation: 0.35140954795893364]
	TIME [epoch: 13.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35257247139157877		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.35257247139157877 | validation: 0.5340971334971875]
	TIME [epoch: 13.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3857877930756968		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.3857877930756968 | validation: 0.3310115248241965]
	TIME [epoch: 13.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609253118345103		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.3609253118345103 | validation: 0.6926759783617066]
	TIME [epoch: 13.1 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517015259940607		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.5517015259940607 | validation: 0.33040688096471016]
	TIME [epoch: 13.1 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37806461936882685		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.37806461936882685 | validation: 0.5568355377949084]
	TIME [epoch: 13.1 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961833787004253		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.6961833787004253 | validation: 0.7284914838540367]
	TIME [epoch: 13.1 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234000923265262		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5234000923265262 | validation: 0.5054411784354051]
	TIME [epoch: 13.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735679262021554		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.3735679262021554 | validation: 0.4163833809929893]
	TIME [epoch: 13.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411426575316675		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.4411426575316675 | validation: 0.337651616039838]
	TIME [epoch: 13.1 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980489209116787		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3980489209116787 | validation: 0.43050782222678186]
	TIME [epoch: 13.1 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48395606374892886		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.48395606374892886 | validation: 0.628166452795438]
	TIME [epoch: 13.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41227086414910646		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.41227086414910646 | validation: 0.3524501283241107]
	TIME [epoch: 13.1 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3736666710522617		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.3736666710522617 | validation: 0.35309462964211813]
	TIME [epoch: 13.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706960619435945		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.3706960619435945 | validation: 0.31014525992116576]
	TIME [epoch: 13.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387024619083998		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.3387024619083998 | validation: 0.37112579524783584]
	TIME [epoch: 13.1 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086827509017602		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.3086827509017602 | validation: 0.45645024106847637]
	TIME [epoch: 13.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706529724709899		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3706529724709899 | validation: 0.37095051019291275]
	TIME [epoch: 13.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3142612227591387		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.3142612227591387 | validation: 0.3212601100440783]
	TIME [epoch: 13.1 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44816010270929996		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.44816010270929996 | validation: 0.6519150807224265]
	TIME [epoch: 13.1 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5344950492166103		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5344950492166103 | validation: 0.6110712778818651]
	TIME [epoch: 13.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865478050133665		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.4865478050133665 | validation: 0.4712381383392]
	TIME [epoch: 13.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828635274665465		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.3828635274665465 | validation: 0.471415887506679]
	TIME [epoch: 13.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852523630200833		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.3852523630200833 | validation: 0.35907969248274113]
	TIME [epoch: 13.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712952554187063		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3712952554187063 | validation: 0.2803820306906031]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3471889588890209		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3471889588890209 | validation: 0.39695785150444046]
	TIME [epoch: 13.1 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131002641337813		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3131002641337813 | validation: 0.3979077904143722]
	TIME [epoch: 13.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510226686976313		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3510226686976313 | validation: 0.3615981865811256]
	TIME [epoch: 13.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3255359157900008		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3255359157900008 | validation: 0.30993577084926066]
	TIME [epoch: 13.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.361247278761506		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.361247278761506 | validation: 0.31815794635503264]
	TIME [epoch: 13.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738452223803267		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2738452223803267 | validation: 0.35806607138375]
	TIME [epoch: 13.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703673736071041		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4703673736071041 | validation: 0.5186143116339799]
	TIME [epoch: 13.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555786342227789		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.555786342227789 | validation: 0.36947984957847885]
	TIME [epoch: 13.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35958857381095655		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.35958857381095655 | validation: 0.3001855802621961]
	TIME [epoch: 13.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3242943389715063		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.3242943389715063 | validation: 0.570411604468503]
	TIME [epoch: 13.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42982279696923165		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.42982279696923165 | validation: 0.5272891800780396]
	TIME [epoch: 13.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362919556732751		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3362919556732751 | validation: 0.4001755840460207]
	TIME [epoch: 13.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42758649057795717		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.42758649057795717 | validation: 0.3574625126162544]
	TIME [epoch: 13.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41015081352633426		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.41015081352633426 | validation: 0.39121843536065626]
	TIME [epoch: 13.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35140850754090636		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.35140850754090636 | validation: 0.28634353058601186]
	TIME [epoch: 13.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016276974668646		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3016276974668646 | validation: 0.34746330496255345]
	TIME [epoch: 13.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36374005036952245		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.36374005036952245 | validation: 0.47269937993933286]
	TIME [epoch: 13.1 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34774790354453977		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.34774790354453977 | validation: 0.37152602490820075]
	TIME [epoch: 13.1 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33728809930269144		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.33728809930269144 | validation: 0.4188995706685512]
	TIME [epoch: 13.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376441342363921		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.4376441342363921 | validation: 0.27369850773338733]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_799.pth
	Model improved!!!
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787403780814453		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4787403780814453 | validation: 0.6307971521514185]
	TIME [epoch: 13.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40108296309953095		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.40108296309953095 | validation: 0.45559851454229344]
	TIME [epoch: 13.1 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7317683213971751		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.7317683213971751 | validation: 0.5414271819587334]
	TIME [epoch: 13.1 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049284098974889		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.5049284098974889 | validation: 0.6219081441971427]
	TIME [epoch: 13.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49470455373899436		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.49470455373899436 | validation: 0.3266253002272946]
	TIME [epoch: 13.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660746140541691		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.4660746140541691 | validation: 0.6615819689845097]
	TIME [epoch: 13.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520382010001837		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.6520382010001837 | validation: 0.3440899086758204]
	TIME [epoch: 13.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727597600940368		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3727597600940368 | validation: 0.5856711172149451]
	TIME [epoch: 13.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43590653898982595		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.43590653898982595 | validation: 0.3897318345400312]
	TIME [epoch: 13.1 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802297870790306		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3802297870790306 | validation: 0.4535589223112368]
	TIME [epoch: 13.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258443582327843		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.4258443582327843 | validation: 0.4125792930256871]
	TIME [epoch: 13.1 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102964666968402		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.6102964666968402 | validation: 0.3967576835398793]
	TIME [epoch: 13.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109329934759579		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.3109329934759579 | validation: 0.2902978599527245]
	TIME [epoch: 13.1 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473656459111416		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3473656459111416 | validation: 0.30350626604927]
	TIME [epoch: 13.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30705159955667727		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.30705159955667727 | validation: 0.4200674709617544]
	TIME [epoch: 13.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3404304979289368		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.3404304979289368 | validation: 0.31368622390762413]
	TIME [epoch: 13.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32339406738811705		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.32339406738811705 | validation: 0.4186871638367783]
	TIME [epoch: 13.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33624903451710286		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.33624903451710286 | validation: 0.4264886204732215]
	TIME [epoch: 13.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353015757918765		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3353015757918765 | validation: 0.2866830502883789]
	TIME [epoch: 13.1 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521971732218037		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3521971732218037 | validation: 0.49420956678589273]
	TIME [epoch: 13.1 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207927504210861		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.5207927504210861 | validation: 0.277831845638272]
	TIME [epoch: 13.1 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522100087403296		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3522100087403296 | validation: 0.41138220341691223]
	TIME [epoch: 13.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386369718812602		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3386369718812602 | validation: 0.34077856864986006]
	TIME [epoch: 13.1 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44081823913728324		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.44081823913728324 | validation: 0.45329033544006414]
	TIME [epoch: 13.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359620117460591		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.359620117460591 | validation: 0.25505692210440956]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34044297356650627		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.34044297356650627 | validation: 0.328794827562769]
	TIME [epoch: 13.1 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37408565228859014		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.37408565228859014 | validation: 0.33402637319232525]
	TIME [epoch: 13.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31868391035912663		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.31868391035912663 | validation: 0.3010815915333583]
	TIME [epoch: 13.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33424766068056694		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.33424766068056694 | validation: 0.41552536734905576]
	TIME [epoch: 13.1 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34035771087357203		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.34035771087357203 | validation: 0.3845829603718265]
	TIME [epoch: 13.1 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30327964177338484		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.30327964177338484 | validation: 0.3703586212567208]
	TIME [epoch: 13.1 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35271806547125534		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.35271806547125534 | validation: 0.3725516034165526]
	TIME [epoch: 13.1 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852212002356153		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.3852212002356153 | validation: 0.4248191604911534]
	TIME [epoch: 13.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878364970200284		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.3878364970200284 | validation: 0.27757201608901755]
	TIME [epoch: 13.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618499965647662		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.2618499965647662 | validation: 0.28711089040627796]
	TIME [epoch: 13.1 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36898289993558053		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.36898289993558053 | validation: 0.4072030962997198]
	TIME [epoch: 13.1 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4029435092796043		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4029435092796043 | validation: 0.303907901159589]
	TIME [epoch: 13.1 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117852198162222		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.3117852198162222 | validation: 0.6568477696503325]
	TIME [epoch: 13.1 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4544292544538071		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4544292544538071 | validation: 0.5809141441978529]
	TIME [epoch: 13.1 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445367240977655		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.5445367240977655 | validation: 0.41919611598027556]
	TIME [epoch: 13.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218529914376116		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3218529914376116 | validation: 0.2875365084353452]
	TIME [epoch: 13.1 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2969642268900853		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2969642268900853 | validation: 0.41907424139271604]
	TIME [epoch: 13.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33265894329330326		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.33265894329330326 | validation: 0.4220287041408284]
	TIME [epoch: 13.1 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36279611419213187		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.36279611419213187 | validation: 0.5805215420191807]
	TIME [epoch: 13.1 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498508516065066		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4498508516065066 | validation: 0.4199367557229769]
	TIME [epoch: 13.1 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3620572959844942		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.3620572959844942 | validation: 0.4238762730426306]
	TIME [epoch: 13.1 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31038962973768597		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.31038962973768597 | validation: 0.2494974338211923]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839213218887848		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2839213218887848 | validation: 0.32539072453329243]
	TIME [epoch: 13.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43335519285353596		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.43335519285353596 | validation: 0.39898994522493975]
	TIME [epoch: 13.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981115764460461		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.2981115764460461 | validation: 0.28309047772940465]
	TIME [epoch: 13.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.465114006868946		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.465114006868946 | validation: 0.5194394433229281]
	TIME [epoch: 13.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42198080376536024		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.42198080376536024 | validation: 0.7170480402075944]
	TIME [epoch: 13.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450748613927278		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.5450748613927278 | validation: 0.5404714176061898]
	TIME [epoch: 13.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44694815868378385		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.44694815868378385 | validation: 0.3899352410927915]
	TIME [epoch: 13.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585525456318942		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.3585525456318942 | validation: 0.3889332811905093]
	TIME [epoch: 13.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926897255862983		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3926897255862983 | validation: 0.4131655588732198]
	TIME [epoch: 13.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38536582461883767		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.38536582461883767 | validation: 0.3121530410733144]
	TIME [epoch: 13.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42612609824745595		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.42612609824745595 | validation: 0.3792681990533827]
	TIME [epoch: 13.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566584349819675		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.3566584349819675 | validation: 0.3185158037714533]
	TIME [epoch: 13.2 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911386681999603		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.2911386681999603 | validation: 0.39083854185117234]
	TIME [epoch: 13.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096513208489264		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.4096513208489264 | validation: 0.2925296431831979]
	TIME [epoch: 13.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431475226785805		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3431475226785805 | validation: 0.2949012610359819]
	TIME [epoch: 13.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29635794255245745		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.29635794255245745 | validation: 0.2748879979294627]
	TIME [epoch: 13.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37746951745168744		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.37746951745168744 | validation: 0.46579157237142915]
	TIME [epoch: 13.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37857163762627766		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.37857163762627766 | validation: 0.26708166133866124]
	TIME [epoch: 13.2 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35799390487654		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.35799390487654 | validation: 0.34045452844350216]
	TIME [epoch: 13.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176866615479312		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.3176866615479312 | validation: 0.3460799601324143]
	TIME [epoch: 13.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169790867526872		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.3169790867526872 | validation: 0.25790205476047845]
	TIME [epoch: 13.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086530256191097		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.3086530256191097 | validation: 0.31389371346016026]
	TIME [epoch: 13.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32875389584978687		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.32875389584978687 | validation: 0.3842182334302596]
	TIME [epoch: 13.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754370258265649		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.3754370258265649 | validation: 0.318366202742389]
	TIME [epoch: 13.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28516366530730775		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.28516366530730775 | validation: 0.2562698242099503]
	TIME [epoch: 13.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24485504296406374		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.24485504296406374 | validation: 0.39772074111348815]
	TIME [epoch: 13.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435401760446468		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.3435401760446468 | validation: 0.2339587788114863]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541991464353427		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2541991464353427 | validation: 0.3517969774323178]
	TIME [epoch: 13.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927881382663418		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.2927881382663418 | validation: 0.5382403842651884]
	TIME [epoch: 13.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4944578427271126		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4944578427271126 | validation: 0.4217743324259999]
	TIME [epoch: 13.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461801632113327		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4461801632113327 | validation: 0.2891505619905118]
	TIME [epoch: 13.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704357853682944		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2704357853682944 | validation: 0.285054408696208]
	TIME [epoch: 13.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2937363645956163		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.2937363645956163 | validation: 0.39505987078132715]
	TIME [epoch: 13.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35477656717593387		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.35477656717593387 | validation: 0.341079071887004]
	TIME [epoch: 13.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27120369894849916		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.27120369894849916 | validation: 0.38122207870659913]
	TIME [epoch: 13.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47150274379040624		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.47150274379040624 | validation: 0.4414749476370959]
	TIME [epoch: 13.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.325025726959255		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.325025726959255 | validation: 0.2825584467067956]
	TIME [epoch: 13.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681296576403001		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.2681296576403001 | validation: 0.30000253754150236]
	TIME [epoch: 13.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26301280948308087		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.26301280948308087 | validation: 0.4378409218297068]
	TIME [epoch: 13.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32733519021299795		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.32733519021299795 | validation: 0.30981703435755825]
	TIME [epoch: 13.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254824938446281		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3254824938446281 | validation: 0.4407587403927204]
	TIME [epoch: 13.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972639401654858		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.3972639401654858 | validation: 0.3195272617911672]
	TIME [epoch: 13.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651011406142439		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.2651011406142439 | validation: 0.26186427612670077]
	TIME [epoch: 13.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613771628202506		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.2613771628202506 | validation: 0.39184767389407416]
	TIME [epoch: 13.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227846538533759		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.4227846538533759 | validation: 0.44791406029888164]
	TIME [epoch: 13.1 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4592153502146896		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.4592153502146896 | validation: 0.38436902668234596]
	TIME [epoch: 13.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49616670532138796		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.49616670532138796 | validation: 0.595741254660464]
	TIME [epoch: 13.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4198979318018438		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.4198979318018438 | validation: 0.27909602893205154]
	TIME [epoch: 13.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32304739542377814		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.32304739542377814 | validation: 0.3487009836322468]
	TIME [epoch: 13.1 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020607539582207		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.3020607539582207 | validation: 0.34922803337782654]
	TIME [epoch: 13.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33013733656953886		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.33013733656953886 | validation: 0.2579613826210186]
	TIME [epoch: 13.1 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4670765049156749		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.4670765049156749 | validation: 0.31868558250892554]
	TIME [epoch: 13.1 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32316128054301013		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.32316128054301013 | validation: 0.2944195637385041]
	TIME [epoch: 13.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28475626422574724		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.28475626422574724 | validation: 0.37191962253307453]
	TIME [epoch: 13.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32759424451077446		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.32759424451077446 | validation: 0.34298066929652116]
	TIME [epoch: 13.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3514248826557333		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3514248826557333 | validation: 0.35528537224977824]
	TIME [epoch: 13.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31052894180637913		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.31052894180637913 | validation: 0.287860197752556]
	TIME [epoch: 13.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25444777975183297		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.25444777975183297 | validation: 0.26730989139540484]
	TIME [epoch: 13.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2700713537455586		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.2700713537455586 | validation: 0.35172817442191034]
	TIME [epoch: 13.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37580286903201643		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.37580286903201643 | validation: 0.43855217011780057]
	TIME [epoch: 13.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43079423559333213		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.43079423559333213 | validation: 0.4223649657893163]
	TIME [epoch: 13.1 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41520598707564077		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.41520598707564077 | validation: 0.5332637696536695]
	TIME [epoch: 13.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48038711494631586		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.48038711494631586 | validation: 0.37391140912436904]
	TIME [epoch: 13.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3036770812202331		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.3036770812202331 | validation: 0.28240849329734563]
	TIME [epoch: 13.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618448556130278		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.4618448556130278 | validation: 0.4292653931061956]
	TIME [epoch: 13.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3650652008016688		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3650652008016688 | validation: 0.41052064710235414]
	TIME [epoch: 13.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44151338421852476		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.44151338421852476 | validation: 0.28910200591069324]
	TIME [epoch: 13.1 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39589854962016235		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.39589854962016235 | validation: 0.2964290919760614]
	TIME [epoch: 13.1 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25482935654493793		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.25482935654493793 | validation: 0.2698008155330271]
	TIME [epoch: 13.1 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34093107302702047		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.34093107302702047 | validation: 0.2799063762637018]
	TIME [epoch: 13.1 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31922575822989957		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.31922575822989957 | validation: 0.29286219242677297]
	TIME [epoch: 13.1 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3693589122868599		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3693589122868599 | validation: 0.4363834508224683]
	TIME [epoch: 13.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44726889704421546		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.44726889704421546 | validation: 0.48726319140133106]
	TIME [epoch: 13.1 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3507617315281358		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.3507617315281358 | validation: 0.36191478251982717]
	TIME [epoch: 13.1 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33651688702993365		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.33651688702993365 | validation: 0.35278966745834195]
	TIME [epoch: 13.1 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27718350967213917		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.27718350967213917 | validation: 0.31238818584012257]
	TIME [epoch: 13.1 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27693251379987815		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.27693251379987815 | validation: 0.27376725028215004]
	TIME [epoch: 13.1 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2767114101985121		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2767114101985121 | validation: 0.39884015076132534]
	TIME [epoch: 13.1 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33295331667509065		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.33295331667509065 | validation: 0.33576260380256934]
	TIME [epoch: 13.1 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25615084067042737		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.25615084067042737 | validation: 0.312193204810365]
	TIME [epoch: 13.1 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332182226500498		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.332182226500498 | validation: 0.333684329636217]
	TIME [epoch: 13.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789653208996015		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.2789653208996015 | validation: 0.28364601622787794]
	TIME [epoch: 13.1 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708594859520187		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2708594859520187 | validation: 0.3966509995803241]
	TIME [epoch: 13.1 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33185695791577496		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.33185695791577496 | validation: 0.3273516866547632]
	TIME [epoch: 13.1 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35170568228574395		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.35170568228574395 | validation: 0.3615142770631438]
	TIME [epoch: 13.1 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2739135608690196		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2739135608690196 | validation: 0.3074200301175041]
	TIME [epoch: 13.1 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27781579960020375		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.27781579960020375 | validation: 0.47032947482093845]
	TIME [epoch: 13.1 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4370083048318781		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.4370083048318781 | validation: 0.30753726796100334]
	TIME [epoch: 13.1 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853306701673418		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.2853306701673418 | validation: 0.4096881344499804]
	TIME [epoch: 13.1 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.309071267459733		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.309071267459733 | validation: 0.28913066512308583]
	TIME [epoch: 13.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29439045618205933		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.29439045618205933 | validation: 0.31837895955655066]
	TIME [epoch: 13.1 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24984437912560087		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.24984437912560087 | validation: 0.2579723369672417]
	TIME [epoch: 13.1 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254361941261225		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.254361941261225 | validation: 0.35012020335341704]
	TIME [epoch: 13.1 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826480289705531		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.2826480289705531 | validation: 0.2764324082889342]
	TIME [epoch: 13.1 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2341677752388767		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.2341677752388767 | validation: 0.2863763462657664]
	TIME [epoch: 13.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622332396737406		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.2622332396737406 | validation: 0.311807972999267]
	TIME [epoch: 13.1 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31082802651064245		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.31082802651064245 | validation: 0.33961655959167575]
	TIME [epoch: 13.1 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866813425630325		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.2866813425630325 | validation: 0.2882185682727513]
	TIME [epoch: 13.1 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23276395618157567		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.23276395618157567 | validation: 0.29010834001600755]
	TIME [epoch: 13.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601989085651931		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.2601989085651931 | validation: 0.3352861698589916]
	TIME [epoch: 13.1 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773136032050873		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.2773136032050873 | validation: 0.31417614222368767]
	TIME [epoch: 13.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672910122137094		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.2672910122137094 | validation: 0.6246851310171797]
	TIME [epoch: 13.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41982396098169295		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.41982396098169295 | validation: 0.32423407279436434]
	TIME [epoch: 13.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868425545868909		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.2868425545868909 | validation: 0.3097286452700713]
	TIME [epoch: 13.1 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32735731657552586		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.32735731657552586 | validation: 0.5095417236052349]
	TIME [epoch: 13.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000014517832252		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.4000014517832252 | validation: 0.4376772441844223]
	TIME [epoch: 13.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462195660966343		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.462195660966343 | validation: 0.5004342805623743]
	TIME [epoch: 13.1 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37838847856776964		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.37838847856776964 | validation: 0.36832739989297947]
	TIME [epoch: 13.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317397469496852		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.3317397469496852 | validation: 0.3319820877076721]
	TIME [epoch: 13.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169215557792278		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.3169215557792278 | validation: 0.32223303519912466]
	TIME [epoch: 13.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29178306856768643		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.29178306856768643 | validation: 0.4206442256456509]
	TIME [epoch: 13.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536684514207095		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.3536684514207095 | validation: 0.31530307539793323]
	TIME [epoch: 13.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030027801701878		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.3030027801701878 | validation: 0.29132936689112704]
	TIME [epoch: 13.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701391898477799		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2701391898477799 | validation: 0.3273411846303405]
	TIME [epoch: 13.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33717865934235713		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.33717865934235713 | validation: 0.46326089284601707]
	TIME [epoch: 13.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556433841379538		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.4556433841379538 | validation: 0.36216977220163143]
	TIME [epoch: 13.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907325653466849		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2907325653466849 | validation: 0.3113974272002084]
	TIME [epoch: 13.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2633974219965513		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.2633974219965513 | validation: 0.2538791940146202]
	TIME [epoch: 13.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254550264261094		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.3254550264261094 | validation: 0.31549158989548176]
	TIME [epoch: 13.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903895837525704		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.2903895837525704 | validation: 0.256508802550141]
	TIME [epoch: 13.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620326735290169		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.2620326735290169 | validation: 0.35053552078808126]
	TIME [epoch: 13.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3674290827175178		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.3674290827175178 | validation: 0.3288873740929351]
	TIME [epoch: 13.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2541808106639029		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.2541808106639029 | validation: 0.2536118082756858]
	TIME [epoch: 13.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23190111078098996		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.23190111078098996 | validation: 0.2561356541643482]
	TIME [epoch: 13.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2486763649845702		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.2486763649845702 | validation: 0.38187341783281775]
	TIME [epoch: 13.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28764980169203547		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.28764980169203547 | validation: 0.3442815979430101]
	TIME [epoch: 13.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29533636774550387		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.29533636774550387 | validation: 0.35444682627299884]
	TIME [epoch: 13.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.281404988777412		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.281404988777412 | validation: 0.28499988250518]
	TIME [epoch: 13.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168326922177208		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.3168326922177208 | validation: 0.4217305341750769]
	TIME [epoch: 13.1 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30574165600828196		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.30574165600828196 | validation: 0.30923731189440257]
	TIME [epoch: 13.1 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29112829287713893		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.29112829287713893 | validation: 0.40445748240521584]
	TIME [epoch: 13.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3178835484914926		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.3178835484914926 | validation: 0.377702123444826]
	TIME [epoch: 13.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40963000740863664		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.40963000740863664 | validation: 0.5983214788467534]
	TIME [epoch: 13.1 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49665209843545266		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.49665209843545266 | validation: 0.429240101561557]
	TIME [epoch: 13.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918530145083383		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.3918530145083383 | validation: 0.31419242076274617]
	TIME [epoch: 13.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31478706671417195		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.31478706671417195 | validation: 0.3872012999357584]
	TIME [epoch: 13.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3572945791905414		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.3572945791905414 | validation: 0.39099995988968916]
	TIME [epoch: 13.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977633749322384		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.2977633749322384 | validation: 0.4042705995255531]
	TIME [epoch: 13.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36343029317431663		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.36343029317431663 | validation: 0.2849003749206635]
	TIME [epoch: 13.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25930874451549146		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.25930874451549146 | validation: 0.36642242313818185]
	TIME [epoch: 13.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305629457946454		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.305629457946454 | validation: 0.2974726655514906]
	TIME [epoch: 13.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26205958625735754		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.26205958625735754 | validation: 0.2707550754323015]
	TIME [epoch: 13.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27097973309886364		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.27097973309886364 | validation: 0.29285638178543716]
	TIME [epoch: 13.1 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30283651537802353		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.30283651537802353 | validation: 0.32093761020440953]
	TIME [epoch: 13.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2562643622051566		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.2562643622051566 | validation: 0.34131767423561826]
	TIME [epoch: 13.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3114477112795896		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.3114477112795896 | validation: 0.34575421923277033]
	TIME [epoch: 13.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2658436246704969		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.2658436246704969 | validation: 0.3916562584001164]
	TIME [epoch: 13.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34826482892763083		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.34826482892763083 | validation: 0.28696873991352234]
	TIME [epoch: 13.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736288860631238		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2736288860631238 | validation: 0.2999410162334499]
	TIME [epoch: 13.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29117652649498094		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.29117652649498094 | validation: 0.28036187569825527]
	TIME [epoch: 13.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295917481184647		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.295917481184647 | validation: 0.3115043117018346]
	TIME [epoch: 13.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623523385944142		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.2623523385944142 | validation: 0.2560688265105051]
	TIME [epoch: 13.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606003775299973		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.2606003775299973 | validation: 0.33115648868215614]
	TIME [epoch: 13.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659330660526543		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.2659330660526543 | validation: 0.2728483437818498]
	TIME [epoch: 13.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23843011275734904		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.23843011275734904 | validation: 0.23476508399637566]
	TIME [epoch: 13.1 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24659890640689708		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.24659890640689708 | validation: 0.2968310356925361]
	TIME [epoch: 13.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599718483052227		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.2599718483052227 | validation: 0.3445642877943467]
	TIME [epoch: 13.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23988857191791813		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.23988857191791813 | validation: 0.22323936270275774]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1004.pth
	Model improved!!!
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272140036570025		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2272140036570025 | validation: 0.23932995795140413]
	TIME [epoch: 13.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21591396888874584		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.21591396888874584 | validation: 0.23890564619658128]
	TIME [epoch: 13.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2374431858729438		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2374431858729438 | validation: 0.268597759711234]
	TIME [epoch: 13.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26875273791175525		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.26875273791175525 | validation: 0.2585554664853033]
	TIME [epoch: 13.1 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.210813851483786		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.210813851483786 | validation: 0.28946584766899763]
	TIME [epoch: 13.1 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27526378457947387		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.27526378457947387 | validation: 0.3136617541469678]
	TIME [epoch: 13.1 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547136763742673		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.3547136763742673 | validation: 0.46712915379307307]
	TIME [epoch: 13.1 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36016383959302817		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.36016383959302817 | validation: 0.31366503154392905]
	TIME [epoch: 13.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627219115957934		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2627219115957934 | validation: 0.36466332576795074]
	TIME [epoch: 13.1 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533509801725307		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.4533509801725307 | validation: 0.2769910097595144]
	TIME [epoch: 13.1 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29399824889657455		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.29399824889657455 | validation: 0.33254225802368986]
	TIME [epoch: 13.2 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030988359452289		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3030988359452289 | validation: 0.29564873996301083]
	TIME [epoch: 13.2 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25518185152718764		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.25518185152718764 | validation: 0.3024543602431762]
	TIME [epoch: 13.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912994662202725		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.2912994662202725 | validation: 0.3057852246597465]
	TIME [epoch: 13.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090009293185512		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3090009293185512 | validation: 0.25672364243895784]
	TIME [epoch: 13.2 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2465983038174326		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.2465983038174326 | validation: 0.33488502128707837]
	TIME [epoch: 13.2 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30448871454911797		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.30448871454911797 | validation: 0.306598831868498]
	TIME [epoch: 13.2 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3611797576271212		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.3611797576271212 | validation: 0.3085080476466763]
	TIME [epoch: 13.2 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876552176822664		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.2876552176822664 | validation: 0.22022947010769287]
	TIME [epoch: 13.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1023.pth
	Model improved!!!
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21191260660364686		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.21191260660364686 | validation: 0.2789214864815924]
	TIME [epoch: 13.1 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738390004222106		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2738390004222106 | validation: 0.298404378818882]
	TIME [epoch: 13.2 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584078296822422		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.2584078296822422 | validation: 0.24672680857507168]
	TIME [epoch: 13.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24179046668968163		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.24179046668968163 | validation: 0.25678436032994145]
	TIME [epoch: 13.1 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25271686284149436		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.25271686284149436 | validation: 0.4817575531489996]
	TIME [epoch: 13.1 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440468296252614		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.4440468296252614 | validation: 0.34617583481083325]
	TIME [epoch: 13.1 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549173419793167		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2549173419793167 | validation: 0.24276848792080535]
	TIME [epoch: 13.2 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459666300489457		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2459666300489457 | validation: 0.2732708611602313]
	TIME [epoch: 13.1 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32005199520290883		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.32005199520290883 | validation: 0.29382007845881397]
	TIME [epoch: 13.1 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858988329283332		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.2858988329283332 | validation: 0.30348513967503765]
	TIME [epoch: 13.2 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670417883781305		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2670417883781305 | validation: 0.23692351253525812]
	TIME [epoch: 13.1 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357742695385082		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.2357742695385082 | validation: 0.2804137061422801]
	TIME [epoch: 13.1 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24692465012516407		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.24692465012516407 | validation: 0.24392046739024634]
	TIME [epoch: 13.1 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211367454533309		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.2211367454533309 | validation: 0.24632532970690915]
	TIME [epoch: 13.1 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441551829780151		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2441551829780151 | validation: 0.22035389635023406]
	TIME [epoch: 13.1 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27226987350766524		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.27226987350766524 | validation: 0.3025988563156305]
	TIME [epoch: 13.1 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24388352521563328		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.24388352521563328 | validation: 0.2432347307918905]
	TIME [epoch: 13.1 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320344525379151		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.2320344525379151 | validation: 0.28512502943168655]
	TIME [epoch: 13.1 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28418536360579316		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.28418536360579316 | validation: 0.32703046169602235]
	TIME [epoch: 13.1 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26974825244536504		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.26974825244536504 | validation: 0.37103353441850784]
	TIME [epoch: 13.2 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34156057568469417		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.34156057568469417 | validation: 0.3892322573224458]
	TIME [epoch: 13.1 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32826153189438295		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.32826153189438295 | validation: 0.2675496052070427]
	TIME [epoch: 13.1 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26073518852816135		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.26073518852816135 | validation: 0.27947493305131005]
	TIME [epoch: 13.1 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28535978437837595		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.28535978437837595 | validation: 0.3800219315193609]
	TIME [epoch: 13.1 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3827567385942395		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.3827567385942395 | validation: 0.4559811923840274]
	TIME [epoch: 13.1 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46034204913801213		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.46034204913801213 | validation: 0.38928053438882537]
	TIME [epoch: 13.1 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3296538154381061		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.3296538154381061 | validation: 0.2749820847595345]
	TIME [epoch: 13.1 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26836275674764404		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.26836275674764404 | validation: 0.336310954496022]
	TIME [epoch: 13.1 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30384373501522804		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.30384373501522804 | validation: 0.33328455683780606]
	TIME [epoch: 13.1 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390360899115507		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.390360899115507 | validation: 0.33457677487376203]
	TIME [epoch: 13.1 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25462548027059917		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.25462548027059917 | validation: 0.2510578809297136]
	TIME [epoch: 13.1 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26027493982682964		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.26027493982682964 | validation: 0.3302502748425245]
	TIME [epoch: 13.1 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624541492518274		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.2624541492518274 | validation: 0.2855913429790956]
	TIME [epoch: 13.1 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24576056876081995		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.24576056876081995 | validation: 0.26428152439814556]
	TIME [epoch: 13.1 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25652656559536535		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.25652656559536535 | validation: 0.33511540794725597]
	TIME [epoch: 13.1 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3374560838381395		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.3374560838381395 | validation: 0.34195331009234664]
	TIME [epoch: 13.1 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29498519635732806		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.29498519635732806 | validation: 0.3073750539399014]
	TIME [epoch: 13.1 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544361932759339		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.2544361932759339 | validation: 0.2820494194334677]
	TIME [epoch: 13.1 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25879480571750124		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.25879480571750124 | validation: 0.3395311409064986]
	TIME [epoch: 13.1 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768882639901404		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.3768882639901404 | validation: 0.3711193988821542]
	TIME [epoch: 13.1 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412119295512386		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3412119295512386 | validation: 0.3735566732960867]
	TIME [epoch: 13.1 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666342177081568		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.2666342177081568 | validation: 0.30435165718967255]
	TIME [epoch: 13.1 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33636224244905766		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.33636224244905766 | validation: 0.3284327616587406]
	TIME [epoch: 13.1 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30246825245386444		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.30246825245386444 | validation: 0.291404343977967]
	TIME [epoch: 13.1 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26882586793258717		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.26882586793258717 | validation: 0.29327620642643104]
	TIME [epoch: 13.1 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30057550056817145		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.30057550056817145 | validation: 0.2956362527902434]
	TIME [epoch: 13.1 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2697210965665591		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.2697210965665591 | validation: 0.2411463462111533]
	TIME [epoch: 13.2 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168356226829674		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2168356226829674 | validation: 0.23529391440837116]
	TIME [epoch: 13.2 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22728110632682075		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.22728110632682075 | validation: 0.28837620447535556]
	TIME [epoch: 13.1 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403515367259715		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.2403515367259715 | validation: 0.2424182159847241]
	TIME [epoch: 13.1 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20750808375510002		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.20750808375510002 | validation: 0.23646200849056015]
	TIME [epoch: 13.1 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23986186767378964		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.23986186767378964 | validation: 0.289362595161182]
	TIME [epoch: 13.1 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26680546245170705		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.26680546245170705 | validation: 0.26230189989779346]
	TIME [epoch: 13.1 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22477600501734957		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.22477600501734957 | validation: 0.24867111789560398]
	TIME [epoch: 13.1 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21453801844901427		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.21453801844901427 | validation: 0.25501491135718934]
	TIME [epoch: 13.1 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25090434825259167		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.25090434825259167 | validation: 0.3068973982273811]
	TIME [epoch: 13.1 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671256977886173		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.2671256977886173 | validation: 0.28068951360770195]
	TIME [epoch: 13.1 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23400882657214517		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.23400882657214517 | validation: 0.24669333637412305]
	TIME [epoch: 13.1 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22591600165844025		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.22591600165844025 | validation: 0.26341954402144546]
	TIME [epoch: 13.1 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24968198040850928		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.24968198040850928 | validation: 0.22553977162427813]
	TIME [epoch: 13.1 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24394159616983374		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.24394159616983374 | validation: 0.23490015330827327]
	TIME [epoch: 13.1 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22489802293517644		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.22489802293517644 | validation: 0.22548461806072476]
	TIME [epoch: 13.1 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21063878380835505		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.21063878380835505 | validation: 0.2339008699405585]
	TIME [epoch: 13.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300763915658274		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.2300763915658274 | validation: 0.22593128971752285]
	TIME [epoch: 13.1 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22151532077353422		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.22151532077353422 | validation: 0.27076845619435885]
	TIME [epoch: 13.1 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23029190407067668		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.23029190407067668 | validation: 0.23775914041550678]
	TIME [epoch: 13.1 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21541153721534267		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.21541153721534267 | validation: 0.27304438486069343]
	TIME [epoch: 13.1 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30240797900596816		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.30240797900596816 | validation: 0.2551174969447377]
	TIME [epoch: 13.1 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420241812791472		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.2420241812791472 | validation: 0.32329455428397474]
	TIME [epoch: 13.1 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524753193383465		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.2524753193383465 | validation: 0.25546683386452496]
	TIME [epoch: 13.1 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2202715310686138		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.2202715310686138 | validation: 0.2623813055525128]
	TIME [epoch: 13.1 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2406376168001211		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2406376168001211 | validation: 0.2522253795823387]
	TIME [epoch: 13.1 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2437932547691975		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2437932547691975 | validation: 0.26743734580011735]
	TIME [epoch: 13.1 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2464798299444019		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.2464798299444019 | validation: 0.23278933518030723]
	TIME [epoch: 13.1 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2207122552122368		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2207122552122368 | validation: 0.2637005542106302]
	TIME [epoch: 13.1 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23548458293959915		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.23548458293959915 | validation: 0.27984035070756186]
	TIME [epoch: 13.1 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26067103758565974		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.26067103758565974 | validation: 0.32406914930934994]
	TIME [epoch: 13.1 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28648890172700797		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.28648890172700797 | validation: 0.28174845545844684]
	TIME [epoch: 13.1 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.245530451436376		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.245530451436376 | validation: 0.35531549716245603]
	TIME [epoch: 13.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30513160174180776		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.30513160174180776 | validation: 0.35038561522186046]
	TIME [epoch: 13.1 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27892858332420334		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.27892858332420334 | validation: 0.22208140413557023]
	TIME [epoch: 13.1 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21499828376435257		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.21499828376435257 | validation: 0.2508387338647298]
	TIME [epoch: 13.1 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24638182261608457		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.24638182261608457 | validation: 0.2145256419110123]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23790108119593995		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.23790108119593995 | validation: 0.2339931084800115]
	TIME [epoch: 13.1 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24966691723547252		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.24966691723547252 | validation: 0.23684753011071266]
	TIME [epoch: 13.1 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28578857501607047		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.28578857501607047 | validation: 0.37382497097030654]
	TIME [epoch: 13.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2982153459126599		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.2982153459126599 | validation: 0.21216139782523344]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1110.pth
	Model improved!!!
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925053070027527		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.20925053070027527 | validation: 0.218605287073216]
	TIME [epoch: 13.1 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25180187318350705		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.25180187318350705 | validation: 0.27201533899313013]
	TIME [epoch: 13.1 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23352708814419518		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.23352708814419518 | validation: 0.2833405820398503]
	TIME [epoch: 13.1 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2731090090903232		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.2731090090903232 | validation: 0.2643011420560841]
	TIME [epoch: 13.1 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569497933618262		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2569497933618262 | validation: 0.25479909263739414]
	TIME [epoch: 13.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22179775060035817		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.22179775060035817 | validation: 0.2548019018292344]
	TIME [epoch: 13.1 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2281207216986439		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2281207216986439 | validation: 0.22710380668079808]
	TIME [epoch: 13.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22787072772206815		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.22787072772206815 | validation: 0.23434989978486256]
	TIME [epoch: 13.1 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22693016319208106		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.22693016319208106 | validation: 0.2327549707026237]
	TIME [epoch: 13.1 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2237600626051368		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2237600626051368 | validation: 0.22330092391699843]
	TIME [epoch: 13.1 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20737490669350483		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.20737490669350483 | validation: 0.29413576722880924]
	TIME [epoch: 13.1 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722589501028766		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.2722589501028766 | validation: 0.2971706225878638]
	TIME [epoch: 13.1 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844337528530458		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2844337528530458 | validation: 0.24538099613997794]
	TIME [epoch: 13.1 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24237327594689978		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.24237327594689978 | validation: 0.2707243695925404]
	TIME [epoch: 13.1 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22264600078682184		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.22264600078682184 | validation: 0.25975838751743197]
	TIME [epoch: 13.1 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24800290498396285		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.24800290498396285 | validation: 0.24404891274281862]
	TIME [epoch: 13.1 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21658079809538455		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.21658079809538455 | validation: 0.21825981528871463]
	TIME [epoch: 13.1 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20167076511634116		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.20167076511634116 | validation: 0.2858911831583027]
	TIME [epoch: 13.1 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2334864423688302		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.2334864423688302 | validation: 0.2807850059741695]
	TIME [epoch: 13.1 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3198345554774108		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.3198345554774108 | validation: 0.2958187543648146]
	TIME [epoch: 13.1 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26464161056833013		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.26464161056833013 | validation: 0.32132374605614766]
	TIME [epoch: 13.1 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39591418609540296		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.39591418609540296 | validation: 0.407173733292357]
	TIME [epoch: 13.1 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321860536341754		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.3321860536341754 | validation: 0.23808662759961724]
	TIME [epoch: 13.1 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21739043412023465		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.21739043412023465 | validation: 0.21279200599935982]
	TIME [epoch: 13.1 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21746449600808895		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.21746449600808895 | validation: 0.2203556913015866]
	TIME [epoch: 13.1 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21866055997772502		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.21866055997772502 | validation: 0.2418365451579385]
	TIME [epoch: 13.1 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102622603351788		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.2102622603351788 | validation: 0.22402866981991076]
	TIME [epoch: 13.1 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20314393030078895		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.20314393030078895 | validation: 0.22528801804346343]
	TIME [epoch: 13.1 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072288160988906		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.2072288160988906 | validation: 0.26803066039731255]
	TIME [epoch: 13.1 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618106815218717		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2618106815218717 | validation: 0.2072321374909469]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21460314121986185		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.21460314121986185 | validation: 0.2553256835195908]
	TIME [epoch: 13.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22415716572209232		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.22415716572209232 | validation: 0.2309715690681096]
	TIME [epoch: 13.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20833264210482183		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.20833264210482183 | validation: 0.20892261151728353]
	TIME [epoch: 13.1 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19468746895017433		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.19468746895017433 | validation: 0.21686312406331942]
	TIME [epoch: 13.1 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20195898367643483		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.20195898367643483 | validation: 0.21907904220647603]
	TIME [epoch: 13.1 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21421943229149415		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.21421943229149415 | validation: 0.24286807118035064]
	TIME [epoch: 13.1 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2429512165130293		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.2429512165130293 | validation: 0.26747199477659667]
	TIME [epoch: 13.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26689280382323166		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.26689280382323166 | validation: 0.3694791091412921]
	TIME [epoch: 13.1 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.326837384806346		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.326837384806346 | validation: 0.32461740865926203]
	TIME [epoch: 13.1 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31092721549435803		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.31092721549435803 | validation: 0.2448735391889694]
	TIME [epoch: 13.1 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23514424204565912		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.23514424204565912 | validation: 0.25986500028722165]
	TIME [epoch: 13.1 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2836096795066161		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2836096795066161 | validation: 0.40804205861461657]
	TIME [epoch: 13.1 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290260493392973		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.4290260493392973 | validation: 0.3605768211581389]
	TIME [epoch: 13.1 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33087186932922685		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.33087186932922685 | validation: 0.2579441012485967]
	TIME [epoch: 13.1 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24606801869142197		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.24606801869142197 | validation: 0.22354990872625563]
	TIME [epoch: 13.1 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24631044777277195		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.24631044777277195 | validation: 0.30654047227034154]
	TIME [epoch: 13.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047749741759124		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.3047749741759124 | validation: 0.2619746044084085]
	TIME [epoch: 13.1 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27248260235956784		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.27248260235956784 | validation: 0.29406001477132476]
	TIME [epoch: 13.1 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26408741058367247		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.26408741058367247 | validation: 0.27715237546716376]
	TIME [epoch: 13.1 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2609305953364109		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.2609305953364109 | validation: 0.24132245578720135]
	TIME [epoch: 13.1 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652581813765508		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.2652581813765508 | validation: 0.2249956326600118]
	TIME [epoch: 13.1 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21381681963011473		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.21381681963011473 | validation: 0.2183723992328655]
	TIME [epoch: 13.1 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22500279582304905		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.22500279582304905 | validation: 0.2561601571722932]
	TIME [epoch: 13.1 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328047284515139		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.2328047284515139 | validation: 0.29218481816355035]
	TIME [epoch: 13.1 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26454369897561214		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.26454369897561214 | validation: 0.26169786305303766]
	TIME [epoch: 13.1 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674780648428436		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.2674780648428436 | validation: 0.23807207923988874]
	TIME [epoch: 13.1 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24108438082083683		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.24108438082083683 | validation: 0.2348565338015699]
	TIME [epoch: 13.1 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2385297808766686		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.2385297808766686 | validation: 0.3221753491790743]
	TIME [epoch: 13.1 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064469303847338		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3064469303847338 | validation: 0.2863273806024866]
	TIME [epoch: 13.1 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730177961100366		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.2730177961100366 | validation: 0.23400588673693995]
	TIME [epoch: 13.1 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332668456607505		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.2332668456607505 | validation: 0.24562833262725284]
	TIME [epoch: 13.1 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24078986386310347		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.24078986386310347 | validation: 0.2504555015292719]
	TIME [epoch: 13.1 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23289902214971647		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.23289902214971647 | validation: 0.2759331680114447]
	TIME [epoch: 13.1 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549354196221886		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.2549354196221886 | validation: 0.283738296160591]
	TIME [epoch: 13.1 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24529342861931402		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.24529342861931402 | validation: 0.273296307403658]
	TIME [epoch: 13.1 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24820215971460258		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.24820215971460258 | validation: 0.2577901815701787]
	TIME [epoch: 13.1 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22223530644383216		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.22223530644383216 | validation: 0.2819858289947254]
	TIME [epoch: 13.1 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524697462891524		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.2524697462891524 | validation: 0.28395744814821494]
	TIME [epoch: 13.1 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26331457423414695		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.26331457423414695 | validation: 0.2953650158980743]
	TIME [epoch: 13.1 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23635602630664826		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.23635602630664826 | validation: 0.25486779677825694]
	TIME [epoch: 13.1 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26516987036484135		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.26516987036484135 | validation: 0.2530702037337737]
	TIME [epoch: 13.1 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23290130328240768		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.23290130328240768 | validation: 0.25561164709647066]
	TIME [epoch: 13.1 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20537903643533373		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.20537903643533373 | validation: 0.2127165421637465]
	TIME [epoch: 13.1 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038526737947131		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.2038526737947131 | validation: 0.22896767208774255]
	TIME [epoch: 13.1 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19828752716138387		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.19828752716138387 | validation: 0.2228297826900181]
	TIME [epoch: 13.1 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091852766431106		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.2091852766431106 | validation: 0.27506993473774993]
	TIME [epoch: 13.1 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21585690679391048		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.21585690679391048 | validation: 0.22210286035215107]
	TIME [epoch: 13.1 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18397210183531665		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.18397210183531665 | validation: 0.23194362851112466]
	TIME [epoch: 13.1 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23616711724203693		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.23616711724203693 | validation: 0.2738840971885345]
	TIME [epoch: 13.1 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2320790275233577		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.2320790275233577 | validation: 0.2998568834547134]
	TIME [epoch: 13.1 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2826536522354495		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.2826536522354495 | validation: 0.380727300797301]
	TIME [epoch: 13.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410121911685163		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.3410121911685163 | validation: 0.30020191003606356]
	TIME [epoch: 13.1 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26742250954643987		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.26742250954643987 | validation: 0.2758122097486399]
	TIME [epoch: 13.1 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28286981263141625		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.28286981263141625 | validation: 0.28246171077557297]
	TIME [epoch: 13.1 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24807469406871868		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.24807469406871868 | validation: 0.2607849075787915]
	TIME [epoch: 13.1 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2242052968459617		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.2242052968459617 | validation: 0.25782664494450963]
	TIME [epoch: 13.1 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24069291646851204		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.24069291646851204 | validation: 0.27363229976138137]
	TIME [epoch: 13.1 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572726334838289		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.2572726334838289 | validation: 0.24742235775234725]
	TIME [epoch: 13.1 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21449804233397407		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.21449804233397407 | validation: 0.22860052375195877]
	TIME [epoch: 13.1 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20928874800113273		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.20928874800113273 | validation: 0.27843894902337535]
	TIME [epoch: 13.1 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23251078456948915		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.23251078456948915 | validation: 0.23386112312672785]
	TIME [epoch: 13.1 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028408564771768		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.2028408564771768 | validation: 0.22605739235430988]
	TIME [epoch: 13.1 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20705054514007395		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.20705054514007395 | validation: 0.29551691013972287]
	TIME [epoch: 13.1 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182052171343737		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.2182052171343737 | validation: 0.2259359291718237]
	TIME [epoch: 13.1 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21922652972991907		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.21922652972991907 | validation: 0.20554483312574484]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1205.pth
	Model improved!!!
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752810242591922		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.18752810242591922 | validation: 0.20352616062053344]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1206.pth
	Model improved!!!
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19150414542575664		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.19150414542575664 | validation: 0.22073307400572448]
	TIME [epoch: 13.1 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2177334990043995		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.2177334990043995 | validation: 0.2444089385684704]
	TIME [epoch: 13.1 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19479836948191737		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.19479836948191737 | validation: 0.22506583997594085]
	TIME [epoch: 13.1 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20041081106825506		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.20041081106825506 | validation: 0.2708082738138115]
	TIME [epoch: 13.1 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29803467210786655		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.29803467210786655 | validation: 0.21647264062418764]
	TIME [epoch: 13.1 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20546391359478572		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.20546391359478572 | validation: 0.25715730755412525]
	TIME [epoch: 13.1 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044329794395969		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.2044329794395969 | validation: 0.22674555703666385]
	TIME [epoch: 13.1 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21077469359242812		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.21077469359242812 | validation: 0.2598283982383739]
	TIME [epoch: 13.1 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24492552885742666		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.24492552885742666 | validation: 0.288926176249026]
	TIME [epoch: 13.1 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23684630393276226		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.23684630393276226 | validation: 0.2686719774313096]
	TIME [epoch: 13.1 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23814076735002412		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.23814076735002412 | validation: 0.30390827977849844]
	TIME [epoch: 13.1 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27414293379656396		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.27414293379656396 | validation: 0.2869410382989485]
	TIME [epoch: 13.1 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312524627432204		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.2312524627432204 | validation: 0.253561482856326]
	TIME [epoch: 13.1 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21134339164485946		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.21134339164485946 | validation: 0.22345520474117778]
	TIME [epoch: 13.1 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19961972321763116		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.19961972321763116 | validation: 0.23771631328672854]
	TIME [epoch: 13.1 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20852016993457134		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.20852016993457134 | validation: 0.24221008152844367]
	TIME [epoch: 13.1 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19133657380456176		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.19133657380456176 | validation: 0.23553663703539207]
	TIME [epoch: 13.1 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884779948511784		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.1884779948511784 | validation: 0.22555740800243235]
	TIME [epoch: 13.1 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19310539425357404		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.19310539425357404 | validation: 0.2649824038588789]
	TIME [epoch: 13.1 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22282005218669457		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.22282005218669457 | validation: 0.27217192064561246]
	TIME [epoch: 13.1 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21871561306265838		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.21871561306265838 | validation: 0.19983359764896272]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1227.pth
	Model improved!!!
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18044036638345795		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.18044036638345795 | validation: 0.22612979316718707]
	TIME [epoch: 13.1 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328582305471268		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.2328582305471268 | validation: 0.25110739475948207]
	TIME [epoch: 13.1 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2213149129383638		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.2213149129383638 | validation: 0.22066215721748006]
	TIME [epoch: 13.1 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19971233656872694		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.19971233656872694 | validation: 0.2603327799571829]
	TIME [epoch: 13.1 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31312407428435457		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.31312407428435457 | validation: 0.33357372064543916]
	TIME [epoch: 13.1 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26339631526304685		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.26339631526304685 | validation: 0.22857586793155094]
	TIME [epoch: 13.1 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19942117450206318		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.19942117450206318 | validation: 0.21523837527083028]
	TIME [epoch: 13.1 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18518244294845138		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.18518244294845138 | validation: 0.2582619904400217]
	TIME [epoch: 13.1 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21797640130213802		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.21797640130213802 | validation: 0.25325712376774173]
	TIME [epoch: 13.1 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100031829292888		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.2100031829292888 | validation: 0.2247864409013151]
	TIME [epoch: 13.1 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18459497721032744		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.18459497721032744 | validation: 0.25045416139180066]
	TIME [epoch: 13.1 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19824055039963512		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.19824055039963512 | validation: 0.2136467175047271]
	TIME [epoch: 13.1 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18580373866619102		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.18580373866619102 | validation: 0.20689823206572455]
	TIME [epoch: 13.1 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186802275002744		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.186802275002744 | validation: 0.2640118722385426]
	TIME [epoch: 13.1 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065790757431596		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.2065790757431596 | validation: 0.2152737641312536]
	TIME [epoch: 13.1 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19407694519201243		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.19407694519201243 | validation: 0.2499953685691381]
	TIME [epoch: 13.1 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21959683958538162		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.21959683958538162 | validation: 0.23460435816673353]
	TIME [epoch: 13.1 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21665554366586637		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.21665554366586637 | validation: 0.28904881028343987]
	TIME [epoch: 13.1 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259600033457587		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.259600033457587 | validation: 0.3642906454998965]
	TIME [epoch: 13.1 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27971869784379366		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.27971869784379366 | validation: 0.30045804882520216]
	TIME [epoch: 13.1 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25317558293584524		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.25317558293584524 | validation: 0.30026435896640763]
	TIME [epoch: 13.1 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24567381456360265		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.24567381456360265 | validation: 0.24756407157131635]
	TIME [epoch: 13.1 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22362259444374277		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.22362259444374277 | validation: 0.2558737531063126]
	TIME [epoch: 13.1 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21312188873155163		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.21312188873155163 | validation: 0.27536345191139594]
	TIME [epoch: 13.1 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22174770211061345		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.22174770211061345 | validation: 0.24993109828477433]
	TIME [epoch: 13.1 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22696887903792107		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.22696887903792107 | validation: 0.2200124261232533]
	TIME [epoch: 13.1 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1997967220995292		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.1997967220995292 | validation: 0.23500897140038274]
	TIME [epoch: 13.1 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19281719982016582		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.19281719982016582 | validation: 0.24154096402700612]
	TIME [epoch: 13.1 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19670295198676824		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.19670295198676824 | validation: 0.2452020035230357]
	TIME [epoch: 13.1 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202152222917511		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.202152222917511 | validation: 0.26366766033150346]
	TIME [epoch: 13.1 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18768057379568243		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.18768057379568243 | validation: 0.2250719693158424]
	TIME [epoch: 13.1 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950361976589981		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1950361976589981 | validation: 0.23504472241611957]
	TIME [epoch: 13.1 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023462451707346		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.2023462451707346 | validation: 0.23977698193986205]
	TIME [epoch: 13.1 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20089352537211785		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.20089352537211785 | validation: 0.2401337096528723]
	TIME [epoch: 13.1 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20726540639772748		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.20726540639772748 | validation: 0.24479410026754253]
	TIME [epoch: 13.1 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357540304085638		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.2357540304085638 | validation: 0.26171765072004605]
	TIME [epoch: 13.1 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22815899318781913		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.22815899318781913 | validation: 0.26305393833631846]
	TIME [epoch: 13.1 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21534275374770923		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.21534275374770923 | validation: 0.22202610503436124]
	TIME [epoch: 13.1 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20425665764760814		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.20425665764760814 | validation: 0.2382559205515742]
	TIME [epoch: 13.1 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19463182838533202		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.19463182838533202 | validation: 0.24609802990212756]
	TIME [epoch: 13.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20331323170427304		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.20331323170427304 | validation: 0.24357531099438093]
	TIME [epoch: 13.1 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20810183352132705		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.20810183352132705 | validation: 0.22896703340752492]
	TIME [epoch: 13.1 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19026351534361863		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.19026351534361863 | validation: 0.2579610443908403]
	TIME [epoch: 13.1 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054437750640428		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.2054437750640428 | validation: 0.25013948780207684]
	TIME [epoch: 13.2 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19182274555854617		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.19182274555854617 | validation: 0.22855732309252821]
	TIME [epoch: 13.1 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244932291892758		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.19244932291892758 | validation: 0.23787199068364473]
	TIME [epoch: 13.1 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19051251963325155		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.19051251963325155 | validation: 0.2519096084605023]
	TIME [epoch: 13.1 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24610555727065436		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.24610555727065436 | validation: 0.28693011592955603]
	TIME [epoch: 13.1 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066585184877322		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2066585184877322 | validation: 0.23696833793043187]
	TIME [epoch: 13.1 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21358614535309015		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.21358614535309015 | validation: 0.25543095839762814]
	TIME [epoch: 13.1 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22662079621919706		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.22662079621919706 | validation: 0.2622638955855182]
	TIME [epoch: 13.1 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24354290833740957		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.24354290833740957 | validation: 0.23256809598739508]
	TIME [epoch: 13.1 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039109354116414		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.2039109354116414 | validation: 0.22128353904041478]
	TIME [epoch: 13.1 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18610336431436433		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.18610336431436433 | validation: 0.23351135670272935]
	TIME [epoch: 13.1 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070225922073853		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.2070225922073853 | validation: 0.277742237486854]
	TIME [epoch: 13.1 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21891278974452688		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.21891278974452688 | validation: 0.24662333849694265]
	TIME [epoch: 13.1 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368644699226428		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.2368644699226428 | validation: 0.2428346521687567]
	TIME [epoch: 13.1 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22181506574722062		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.22181506574722062 | validation: 0.2430149736018064]
	TIME [epoch: 13.1 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.227465446138416		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.227465446138416 | validation: 0.2566279896634781]
	TIME [epoch: 13.1 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23229948097442976		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.23229948097442976 | validation: 0.2651457203133853]
	TIME [epoch: 13.1 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25211888439766217		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.25211888439766217 | validation: 0.2706310870764964]
	TIME [epoch: 13.1 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24794430245302296		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.24794430245302296 | validation: 0.27028406083827233]
	TIME [epoch: 13.1 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26104632581119536		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.26104632581119536 | validation: 0.27355053093233705]
	TIME [epoch: 13.1 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2345893504064073		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.2345893504064073 | validation: 0.25739121339890464]
	TIME [epoch: 13.1 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23120187258484956		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.23120187258484956 | validation: 0.2408874631548226]
	TIME [epoch: 13.1 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22234622573027146		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.22234622573027146 | validation: 0.25928448818796246]
	TIME [epoch: 13.1 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24105641436985942		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.24105641436985942 | validation: 0.2344592739103257]
	TIME [epoch: 13.1 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19390395723959586		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.19390395723959586 | validation: 0.2331953238710595]
	TIME [epoch: 13.1 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19578803828114053		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.19578803828114053 | validation: 0.2590329141286685]
	TIME [epoch: 13.1 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20523022725606305		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.20523022725606305 | validation: 0.23291916134435542]
	TIME [epoch: 13.1 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19295671404949805		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.19295671404949805 | validation: 0.2212116534230529]
	TIME [epoch: 13.1 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18924008689467503		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.18924008689467503 | validation: 0.2399429834477665]
	TIME [epoch: 13.1 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21707867849129775		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.21707867849129775 | validation: 0.27643849705895335]
	TIME [epoch: 13.1 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21312326262085846		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.21312326262085846 | validation: 0.22288328301547508]
	TIME [epoch: 13.1 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21066297445275933		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.21066297445275933 | validation: 0.23357446735877596]
	TIME [epoch: 13.1 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953033467320705		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.1953033467320705 | validation: 0.22511286304977063]
	TIME [epoch: 13.1 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21527968576224368		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.21527968576224368 | validation: 0.2240925469107098]
	TIME [epoch: 13.1 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21562287822540552		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.21562287822540552 | validation: 0.29460303349300543]
	TIME [epoch: 13.1 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539808125689194		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.2539808125689194 | validation: 0.2883331155944677]
	TIME [epoch: 13.1 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26569740801289077		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.26569740801289077 | validation: 0.2674703608050282]
	TIME [epoch: 13.1 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174653698285176		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.2174653698285176 | validation: 0.2635610240943702]
	TIME [epoch: 13.1 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21731135584849656		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.21731135584849656 | validation: 0.26321532167046346]
	TIME [epoch: 13.1 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146918500673886		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.2146918500673886 | validation: 0.25768073315384554]
	TIME [epoch: 13.1 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054986728899556		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.2054986728899556 | validation: 0.2527713909520424]
	TIME [epoch: 13.1 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20029659566651137		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.20029659566651137 | validation: 0.2255204690776614]
	TIME [epoch: 13.1 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19690915100124806		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.19690915100124806 | validation: 0.28771489295445773]
	TIME [epoch: 13.1 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21844094001355888		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.21844094001355888 | validation: 0.24689249775358943]
	TIME [epoch: 13.1 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19740389906349762		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.19740389906349762 | validation: 0.219844131436335]
	TIME [epoch: 13.1 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1834993530266604		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.1834993530266604 | validation: 0.24538997663764406]
	TIME [epoch: 13.1 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21680060989122624		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.21680060989122624 | validation: 0.23062677833744957]
	TIME [epoch: 13.1 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20476701954344212		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.20476701954344212 | validation: 0.2338816964330359]
	TIME [epoch: 13.1 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20504616070133053		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.20504616070133053 | validation: 0.24980756890151284]
	TIME [epoch: 13.1 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21741679725799837		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.21741679725799837 | validation: 0.26947360531352343]
	TIME [epoch: 13.1 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21329455695369925		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.21329455695369925 | validation: 0.2399747651424751]
	TIME [epoch: 13.1 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25216364819112735		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.25216364819112735 | validation: 0.287106899478461]
	TIME [epoch: 13.1 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21081853267368775		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.21081853267368775 | validation: 0.2520997024847233]
	TIME [epoch: 13.1 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21050669399279065		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.21050669399279065 | validation: 0.22537923798843962]
	TIME [epoch: 13.1 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19232585189735726		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.19232585189735726 | validation: 0.21867112248307818]
	TIME [epoch: 13.1 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19221959351567322		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.19221959351567322 | validation: 0.2059038860056306]
	TIME [epoch: 13.1 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22100504801189705		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.22100504801189705 | validation: 0.2641669263599823]
	TIME [epoch: 13.1 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23191055104028344		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.23191055104028344 | validation: 0.26127764514780166]
	TIME [epoch: 13.1 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22341861864354187		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.22341861864354187 | validation: 0.24425994261920994]
	TIME [epoch: 13.1 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21383706622425028		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.21383706622425028 | validation: 0.21954323765826567]
	TIME [epoch: 13.1 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19475554942838683		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.19475554942838683 | validation: 0.2222475799135492]
	TIME [epoch: 13.1 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19576873091231328		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.19576873091231328 | validation: 0.26012746600521935]
	TIME [epoch: 13.1 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20871095345397805		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.20871095345397805 | validation: 0.21952810178312399]
	TIME [epoch: 13.1 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20149778321248488		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.20149778321248488 | validation: 0.2510438572571542]
	TIME [epoch: 13.1 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20242293022832927		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.20242293022832927 | validation: 0.24938373096731745]
	TIME [epoch: 13.1 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21118405343346092		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.21118405343346092 | validation: 0.2534527624674039]
	TIME [epoch: 13.1 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20222258843190707		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.20222258843190707 | validation: 0.23102052146578048]
	TIME [epoch: 13.1 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20301638599534505		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.20301638599534505 | validation: 0.22003185501015984]
	TIME [epoch: 13.1 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20737202629178214		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.20737202629178214 | validation: 0.20855548089304823]
	TIME [epoch: 13.1 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812997965187882		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.1812997965187882 | validation: 0.21839467441125154]
	TIME [epoch: 13.1 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18230381619202543		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.18230381619202543 | validation: 0.22353810926260592]
	TIME [epoch: 13.1 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904894252598846		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.17904894252598846 | validation: 0.2389719004342107]
	TIME [epoch: 13.1 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19726771984140198		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.19726771984140198 | validation: 0.24055311329383286]
	TIME [epoch: 13.1 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086238286572117		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.2086238286572117 | validation: 0.2554688096320067]
	TIME [epoch: 13.1 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19874935726979526		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.19874935726979526 | validation: 0.2323319495267309]
	TIME [epoch: 13.1 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19435588454386937		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.19435588454386937 | validation: 0.23820860249948073]
	TIME [epoch: 13.1 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21265773699707496		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.21265773699707496 | validation: 0.2340546271866903]
	TIME [epoch: 13.1 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19760497210624678		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.19760497210624678 | validation: 0.22843408148636862]
	TIME [epoch: 13.1 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18123816757816646		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.18123816757816646 | validation: 0.2603737268938105]
	TIME [epoch: 13.1 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20783985408208466		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.20783985408208466 | validation: 0.21702007216504626]
	TIME [epoch: 13.1 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196408827454898		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.196408827454898 | validation: 0.24328627338590988]
	TIME [epoch: 13.1 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18787830722145837		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.18787830722145837 | validation: 0.2171808123506513]
	TIME [epoch: 13.1 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18793861628709574		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.18793861628709574 | validation: 0.22853367803241817]
	TIME [epoch: 13.1 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18528803070945618		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.18528803070945618 | validation: 0.23856364162924398]
	TIME [epoch: 13.1 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18452344118551045		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.18452344118551045 | validation: 0.2223027655312994]
	TIME [epoch: 13.1 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20768650934582727		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.20768650934582727 | validation: 0.2176161158848794]
	TIME [epoch: 13.1 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18615252841177093		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.18615252841177093 | validation: 0.20886993381448662]
	TIME [epoch: 13.1 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18659119093287718		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.18659119093287718 | validation: 0.22980909214017]
	TIME [epoch: 13.1 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19558375028178		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.19558375028178 | validation: 0.20867516116001383]
	TIME [epoch: 13.1 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18199601630553666		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.18199601630553666 | validation: 0.22538458594098168]
	TIME [epoch: 13.1 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18823412225114797		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.18823412225114797 | validation: 0.2027211499823173]
	TIME [epoch: 13.1 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18436487773735466		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.18436487773735466 | validation: 0.25865095897544543]
	TIME [epoch: 13.1 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20663052350906314		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.20663052350906314 | validation: 0.20982067950298644]
	TIME [epoch: 13.1 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887954210936208		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1887954210936208 | validation: 0.20479186849358894]
	TIME [epoch: 13.1 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18193658960979148		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.18193658960979148 | validation: 0.217916073097485]
	TIME [epoch: 13.1 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19158093735181803		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.19158093735181803 | validation: 0.20858720113622525]
	TIME [epoch: 13.1 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19167705913953328		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.19167705913953328 | validation: 0.21062517609338627]
	TIME [epoch: 13.1 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19332599010999113		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.19332599010999113 | validation: 0.19651363853800674]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1368.pth
	Model improved!!!
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744518361215118		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.1744518361215118 | validation: 0.2223805990867964]
	TIME [epoch: 13.1 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912896002953829		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.1912896002953829 | validation: 0.2250855639787637]
	TIME [epoch: 13.1 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830432448551764		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.1830432448551764 | validation: 0.2277332161004773]
	TIME [epoch: 13.1 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19991784890682837		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.19991784890682837 | validation: 0.20757479338709686]
	TIME [epoch: 13.1 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837124113149325		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.1837124113149325 | validation: 0.2062009183359869]
	TIME [epoch: 13.1 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.195787547954099		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.195787547954099 | validation: 0.23560556061058024]
	TIME [epoch: 13.1 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19279419244044688		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.19279419244044688 | validation: 0.22825812607668114]
	TIME [epoch: 13.1 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111221908575465		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.19111221908575465 | validation: 0.2529601255872169]
	TIME [epoch: 13.1 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20135763872899276		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.20135763872899276 | validation: 0.23168651763465462]
	TIME [epoch: 13.1 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17663451683646647		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.17663451683646647 | validation: 0.23060708753328812]
	TIME [epoch: 13.1 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19003213960263282		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.19003213960263282 | validation: 0.22190524959919772]
	TIME [epoch: 13.1 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1888323994864115		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.1888323994864115 | validation: 0.2351234094226841]
	TIME [epoch: 13.1 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1870992099996359		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.1870992099996359 | validation: 0.2185810884948334]
	TIME [epoch: 13.1 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20442370848179425		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.20442370848179425 | validation: 0.233687652311259]
	TIME [epoch: 13.1 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1875040898416989		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.1875040898416989 | validation: 0.21496746812202258]
	TIME [epoch: 13.1 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20277303952283043		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.20277303952283043 | validation: 0.2294926256600518]
	TIME [epoch: 13.1 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19191184630725		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.19191184630725 | validation: 0.21860168561252635]
	TIME [epoch: 13.1 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19531012260129899		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.19531012260129899 | validation: 0.23078667305402142]
	TIME [epoch: 13.1 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1860308515876981		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.1860308515876981 | validation: 0.25237980178593394]
	TIME [epoch: 13.1 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20687079579346532		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.20687079579346532 | validation: 0.21906795352724245]
	TIME [epoch: 13.1 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18604807847571228		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.18604807847571228 | validation: 0.22630656083995096]
	TIME [epoch: 13.1 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18989202393400922		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.18989202393400922 | validation: 0.20841544559620284]
	TIME [epoch: 13.1 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18476076029683805		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.18476076029683805 | validation: 0.22443345947573115]
	TIME [epoch: 13.1 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19030687228182105		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.19030687228182105 | validation: 0.25114038517132625]
	TIME [epoch: 13.1 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22660624182467387		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.22660624182467387 | validation: 0.2612761840359834]
	TIME [epoch: 13.1 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22443592596641906		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.22443592596641906 | validation: 0.23826232636402928]
	TIME [epoch: 13.1 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20052934943858303		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.20052934943858303 | validation: 0.24385581214674026]
	TIME [epoch: 13.1 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20492324371399773		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.20492324371399773 | validation: 0.23689533649851932]
	TIME [epoch: 13.1 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19040647468840155		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.19040647468840155 | validation: 0.2202669457673896]
	TIME [epoch: 13.1 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18267153566654662		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.18267153566654662 | validation: 0.22340172878550127]
	TIME [epoch: 13.1 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17980477250033228		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.17980477250033228 | validation: 0.23449921905525553]
	TIME [epoch: 13.1 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059294971021441		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.2059294971021441 | validation: 0.2851897019826372]
	TIME [epoch: 13.1 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27150928215479936		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.27150928215479936 | validation: 0.2373018483834165]
	TIME [epoch: 13.1 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20508103359231208		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.20508103359231208 | validation: 0.22238694914274912]
	TIME [epoch: 13.1 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1860990466247945		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.1860990466247945 | validation: 0.2275092053029404]
	TIME [epoch: 13.1 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892286504368953		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.1892286504368953 | validation: 0.2303138701106744]
	TIME [epoch: 13.1 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18870111732130354		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.18870111732130354 | validation: 0.23663781019257166]
	TIME [epoch: 13.1 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981072749038566		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.1981072749038566 | validation: 0.23341949048524227]
	TIME [epoch: 13.1 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085761786064783		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.18085761786064783 | validation: 0.2151023863235426]
	TIME [epoch: 13.1 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925358324808719		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.1925358324808719 | validation: 0.21639464140904732]
	TIME [epoch: 13.1 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18447150329207546		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.18447150329207546 | validation: 0.22065889858886564]
	TIME [epoch: 13.1 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18471720780889583		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.18471720780889583 | validation: 0.2175103602748653]
	TIME [epoch: 13.1 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18032038153933405		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.18032038153933405 | validation: 0.20607936432515608]
	TIME [epoch: 13.1 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879648715750165		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.1879648715750165 | validation: 0.23335736183197164]
	TIME [epoch: 13.1 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19820452539146655		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.19820452539146655 | validation: 0.2260572705406132]
	TIME [epoch: 13.1 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956722579323003		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.1956722579323003 | validation: 0.22152073635684344]
	TIME [epoch: 13.1 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18390163862714415		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.18390163862714415 | validation: 0.23440971256550175]
	TIME [epoch: 13.1 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966159621971676		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.1966159621971676 | validation: 0.21771931614498846]
	TIME [epoch: 13.1 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18834762427056173		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.18834762427056173 | validation: 0.23059928884614503]
	TIME [epoch: 13.1 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19077096905583638		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.19077096905583638 | validation: 0.22967886760387807]
	TIME [epoch: 13.1 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19370588583137993		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.19370588583137993 | validation: 0.2371352398515944]
	TIME [epoch: 13.1 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19194342130473852		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.19194342130473852 | validation: 0.24548252505505283]
	TIME [epoch: 13.1 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20348732467437194		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.20348732467437194 | validation: 0.2388282981848025]
	TIME [epoch: 13.1 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042410078726028		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.2042410078726028 | validation: 0.2586586321069585]
	TIME [epoch: 13.1 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23512365860215168		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.23512365860215168 | validation: 0.28766422133905517]
	TIME [epoch: 13.1 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24138398921354803		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.24138398921354803 | validation: 0.2847715429155454]
	TIME [epoch: 13.1 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23585419774567917		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.23585419774567917 | validation: 0.2805627704078993]
	TIME [epoch: 13.1 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23355615000295937		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.23355615000295937 | validation: 0.2838852509210362]
	TIME [epoch: 13.1 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23903015891887808		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.23903015891887808 | validation: 0.2667094442690775]
	TIME [epoch: 13.1 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23802955902574507		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.23802955902574507 | validation: 0.27617664892923116]
	TIME [epoch: 13.2 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23724092631201293		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.23724092631201293 | validation: 0.25833163508381707]
	TIME [epoch: 13.1 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20056834770296567		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.20056834770296567 | validation: 0.25979874227458577]
	TIME [epoch: 13.1 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22435002457005726		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.22435002457005726 | validation: 0.24537768469083973]
	TIME [epoch: 13.1 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22464861530691235		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.22464861530691235 | validation: 0.2797303321998298]
	TIME [epoch: 13.1 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23897379044461514		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.23897379044461514 | validation: 0.23074891448550502]
	TIME [epoch: 13.1 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2253768093897066		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.2253768093897066 | validation: 0.24661103459975423]
	TIME [epoch: 13.1 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048426079848819		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.2048426079848819 | validation: 0.2161095157725218]
	TIME [epoch: 13.1 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19321786257066648		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.19321786257066648 | validation: 0.21094813898638312]
	TIME [epoch: 13.1 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22219508730196608		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.22219508730196608 | validation: 0.2569450501549552]
	TIME [epoch: 13.1 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2048636039671866		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.2048636039671866 | validation: 0.2423870868509447]
	TIME [epoch: 13.1 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19477833659810995		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.19477833659810995 | validation: 0.2276455694576452]
	TIME [epoch: 13.1 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18861099714451957		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.18861099714451957 | validation: 0.2284312957366854]
	TIME [epoch: 13.1 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188965995807234		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.188965995807234 | validation: 0.21835462822541224]
	TIME [epoch: 13.1 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19702645138345895		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.19702645138345895 | validation: 0.24832509795905056]
	TIME [epoch: 13.1 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896727077113915		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.1896727077113915 | validation: 0.20014060463151762]
	TIME [epoch: 13.1 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818448745497177		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.1818448745497177 | validation: 0.22626961556333505]
	TIME [epoch: 13.1 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18725211539019487		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.18725211539019487 | validation: 0.24973342409861468]
	TIME [epoch: 13.1 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22440271523495534		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.22440271523495534 | validation: 0.25965444890868805]
	TIME [epoch: 13.1 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23476467947975962		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.23476467947975962 | validation: 0.23572163128481685]
	TIME [epoch: 13.1 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2019932425677485		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.2019932425677485 | validation: 0.20702502339601356]
	TIME [epoch: 13.1 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20589213858089828		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.20589213858089828 | validation: 0.2633412513898732]
	TIME [epoch: 13.1 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24654276354814186		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.24654276354814186 | validation: 0.2728198456371743]
	TIME [epoch: 13.1 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22406586003322934		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.22406586003322934 | validation: 0.2338681690304722]
	TIME [epoch: 13.1 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093380332618808		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.2093380332618808 | validation: 0.23477836720946482]
	TIME [epoch: 13.1 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21408548049215131		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.21408548049215131 | validation: 0.2158659103986172]
	TIME [epoch: 13.1 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19690383863792732		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.19690383863792732 | validation: 0.21651924919895243]
	TIME [epoch: 13.1 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210170878887931		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.2210170878887931 | validation: 0.24557423052443264]
	TIME [epoch: 13.1 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22149779461193583		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.22149779461193583 | validation: 0.2497749676488111]
	TIME [epoch: 13.1 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167396704812804		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.2167396704812804 | validation: 0.21770924883547452]
	TIME [epoch: 13.1 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18487298819517542		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.18487298819517542 | validation: 0.22802708923842488]
	TIME [epoch: 13.1 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1811207628966323		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.1811207628966323 | validation: 0.22562941741416936]
	TIME [epoch: 13.1 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18562378206628377		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.18562378206628377 | validation: 0.21777210185816528]
	TIME [epoch: 13.1 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18921794759302457		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.18921794759302457 | validation: 0.23362270718794503]
	TIME [epoch: 13.1 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1792506254717619		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.1792506254717619 | validation: 0.22325300995834194]
	TIME [epoch: 13.1 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18932570631029477		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.18932570631029477 | validation: 0.2257132254299863]
	TIME [epoch: 13.1 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19342564832480247		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.19342564832480247 | validation: 0.21957835191024092]
	TIME [epoch: 13.2 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1864194158404123		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.1864194158404123 | validation: 0.23933132827121134]
	TIME [epoch: 13.1 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1991830395129572		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.1991830395129572 | validation: 0.242673330765315]
	TIME [epoch: 13.1 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19311577525988022		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.19311577525988022 | validation: 0.19632866928292927]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1467.pth
	Model improved!!!
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18966321188423518		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.18966321188423518 | validation: 0.2097074086694159]
	TIME [epoch: 13.1 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17627462363586094		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.17627462363586094 | validation: 0.20049966160269125]
	TIME [epoch: 13.1 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17565515859886044		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.17565515859886044 | validation: 0.21643773400379843]
	TIME [epoch: 13.1 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19151522631322984		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.19151522631322984 | validation: 0.2131907719982664]
	TIME [epoch: 13.1 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206918015722098		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.206918015722098 | validation: 0.21844267847403856]
	TIME [epoch: 13.1 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19307077799258077		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.19307077799258077 | validation: 0.20419781680372187]
	TIME [epoch: 13.1 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1743813213256889		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.1743813213256889 | validation: 0.21959813649587304]
	TIME [epoch: 13.1 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18943294411553366		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.18943294411553366 | validation: 0.218755408164973]
	TIME [epoch: 13.1 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18814485548650417		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.18814485548650417 | validation: 0.21359960886957968]
	TIME [epoch: 13.1 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18741043658878934		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.18741043658878934 | validation: 0.20780451358240545]
	TIME [epoch: 13.1 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17283433948262902		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.17283433948262902 | validation: 0.20699756329191274]
	TIME [epoch: 13.1 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17780509318119642		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.17780509318119642 | validation: 0.20208566673403597]
	TIME [epoch: 13.1 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816122900558421		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.1816122900558421 | validation: 0.19345166866035232]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1480.pth
	Model improved!!!
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1789232755262751		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.1789232755262751 | validation: 0.20421131243666427]
	TIME [epoch: 13.1 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17425806831840868		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.17425806831840868 | validation: 0.20633738514193867]
	TIME [epoch: 13.1 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821098750405434		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.1821098750405434 | validation: 0.23853635621967642]
	TIME [epoch: 13.1 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18233828403669994		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.18233828403669994 | validation: 0.2311708238084497]
	TIME [epoch: 13.1 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18505037594025045		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.18505037594025045 | validation: 0.2179159418955239]
	TIME [epoch: 13.1 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17554994111274888		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.17554994111274888 | validation: 0.20003053998482478]
	TIME [epoch: 13.1 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379181930942303		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.17379181930942303 | validation: 0.22686359473656886]
	TIME [epoch: 13.1 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19402138910612335		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.19402138910612335 | validation: 0.23722012234044593]
	TIME [epoch: 13.1 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19842294502149635		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.19842294502149635 | validation: 0.2428039352862161]
	TIME [epoch: 13.1 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19726024907879675		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.19726024907879675 | validation: 0.22659199361600452]
	TIME [epoch: 13.1 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18957500329884527		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.18957500329884527 | validation: 0.21578793115939246]
	TIME [epoch: 13.1 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1897450674184232		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1897450674184232 | validation: 0.22698297108424015]
	TIME [epoch: 13.1 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18331318881144307		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.18331318881144307 | validation: 0.19717364648529845]
	TIME [epoch: 13.1 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18040812168436646		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.18040812168436646 | validation: 0.21800332478541987]
	TIME [epoch: 13.1 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19741883069513036		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.19741883069513036 | validation: 0.19899072326270145]
	TIME [epoch: 13.1 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17428098736349845		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.17428098736349845 | validation: 0.20113204739693108]
	TIME [epoch: 13.1 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17273224339903576		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.17273224339903576 | validation: 0.20094154352290794]
	TIME [epoch: 13.1 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17003606557106915		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.17003606557106915 | validation: 0.19170331438738467]
	TIME [epoch: 13.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r5_20240309_135637/states/model_tr_study3_1498.pth
	Model improved!!!
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17821403877206585		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.17821403877206585 | validation: 0.2009885205955731]
	TIME [epoch: 13.1 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19122622007768214		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.19122622007768214 | validation: 0.21556663539196386]
	TIME [epoch: 13.1 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18745642213445332		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.18745642213445332 | validation: 0.21045408648398437]
	TIME [epoch: 13.1 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18094324663702524		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.18094324663702524 | validation: 0.2172147188013506]
	TIME [epoch: 13.1 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19260808541059857		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.19260808541059857 | validation: 0.22894366245789247]
	TIME [epoch: 13.1 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19088500699528313		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.19088500699528313 | validation: 0.24634854953800897]
	TIME [epoch: 13.1 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1961594297442585		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.1961594297442585 | validation: 0.23328670850240132]
	TIME [epoch: 13.1 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19054798767151013		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.19054798767151013 | validation: 0.2099429989115275]
	TIME [epoch: 13.1 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20553201932581106		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.20553201932581106 | validation: 0.2400485220400762]
	TIME [epoch: 13.1 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21367868742471613		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.21367868742471613 | validation: 0.23944760516490454]
	TIME [epoch: 13.1 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19890302778607594		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.19890302778607594 | validation: 0.20101585568741165]
	TIME [epoch: 13.1 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724463170709417		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.1724463170709417 | validation: 0.21977390720282303]
	TIME [epoch: 13.1 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750411032755109		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.1750411032755109 | validation: 0.21128408108003918]
	TIME [epoch: 13.1 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18983590654219		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.18983590654219 | validation: 0.22546034259084521]
	TIME [epoch: 13.1 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18364223560788984		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.18364223560788984 | validation: 0.23578012889150834]
	TIME [epoch: 13.1 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093244540161881		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.2093244540161881 | validation: 0.23240531017892324]
	TIME [epoch: 13.1 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17973686157010466		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.17973686157010466 | validation: 0.21634812140920914]
	TIME [epoch: 13.1 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18233593464371733		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.18233593464371733 | validation: 0.20986607274497096]
	TIME [epoch: 13.1 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764047468133867		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.1764047468133867 | validation: 0.20763023536050873]
	TIME [epoch: 13.1 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18183305280973905		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.18183305280973905 | validation: 0.20598016028062652]
	TIME [epoch: 13.1 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17378100742530436		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.17378100742530436 | validation: 0.21745045212609695]
	TIME [epoch: 13.1 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17637734411593867		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.17637734411593867 | validation: 0.20013481601654373]
	TIME [epoch: 13.1 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17275432153918746		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.17275432153918746 | validation: 0.21097877488505565]
	TIME [epoch: 13.1 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17838960945059684		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.17838960945059684 | validation: 0.21679750299679776]
	TIME [epoch: 13.1 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178890910212102		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.178890910212102 | validation: 0.22956502632366538]
	TIME [epoch: 13.1 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16570170383973976		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.16570170383973976 | validation: 0.20882000366859463]
	TIME [epoch: 13.1 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719490011724655		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.1719490011724655 | validation: 0.22750047376592267]
	TIME [epoch: 13.1 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750208929906865		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.1750208929906865 | validation: 0.22729773939877532]
	TIME [epoch: 13.1 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862452802702846		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.1862452802702846 | validation: 0.25260301037172456]
	TIME [epoch: 13.1 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089722388981364		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.2089722388981364 | validation: 0.24017494816639187]
	TIME [epoch: 13.1 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19997340164160102		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.19997340164160102 | validation: 0.23576235595451045]
	TIME [epoch: 13.1 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184750214415498		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.184750214415498 | validation: 0.2303969765879834]
	TIME [epoch: 13.1 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17937112462761734		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.17937112462761734 | validation: 0.20720987448615857]
	TIME [epoch: 13.1 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17430477341105954		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.17430477341105954 | validation: 0.21884761507942999]
	TIME [epoch: 13.1 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948325254022943		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.1948325254022943 | validation: 0.19901989662183467]
	TIME [epoch: 13.1 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19287110512873115		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.19287110512873115 | validation: 0.22095794944446964]
	TIME [epoch: 13.1 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20403910905164993		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.20403910905164993 | validation: 0.22112011569470105]
	TIME [epoch: 13.1 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079107770718931		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.2079107770718931 | validation: 0.25319959547470355]
	TIME [epoch: 13.1 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25375093228109186		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.25375093228109186 | validation: 0.3038143018106356]
	TIME [epoch: 13.1 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26143133277244734		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.26143133277244734 | validation: 0.2515222540183381]
	TIME [epoch: 13.1 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21563471179934943		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.21563471179934943 | validation: 0.22965640843064847]
	TIME [epoch: 13.1 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17790375950771503		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.17790375950771503 | validation: 0.2248375281752317]
	TIME [epoch: 13.1 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18489826576545207		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.18489826576545207 | validation: 0.23658157099058413]
	TIME [epoch: 13.1 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18187598019937995		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.18187598019937995 | validation: 0.23705174660534373]
	TIME [epoch: 13.1 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18783096668754312		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.18783096668754312 | validation: 0.2138971377300475]
	TIME [epoch: 13.1 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18718565113714147		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.18718565113714147 | validation: 0.20573845216936015]
	TIME [epoch: 13.1 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19836954160148348		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.19836954160148348 | validation: 0.23970889801504378]
	TIME [epoch: 13.1 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148686439873025		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.2148686439873025 | validation: 0.21980322726967153]
	TIME [epoch: 13.1 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20464801770937086		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.20464801770937086 | validation: 0.22330606085859778]
	TIME [epoch: 13.1 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922354332187849		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.1922354332187849 | validation: 0.2054385664414487]
	TIME [epoch: 13.1 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18711940114341039		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.18711940114341039 | validation: 0.2217246189366976]
	TIME [epoch: 13.1 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853944255974984		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.1853944255974984 | validation: 0.23531047249195047]
	TIME [epoch: 13.1 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19516725803229829		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.19516725803229829 | validation: 0.2560850793331093]
	TIME [epoch: 13.1 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.205399308834359		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.205399308834359 | validation: 0.24397773262160433]
	TIME [epoch: 13.1 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18884469418317235		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.18884469418317235 | validation: 0.2116083398855742]
	TIME [epoch: 13.1 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17607316518426114		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.17607316518426114 | validation: 0.214816504348063]
	TIME [epoch: 13.1 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878219338007604		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1878219338007604 | validation: 0.22301611996645676]
	TIME [epoch: 13.1 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17861279952241454		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.17861279952241454 | validation: 0.2165467555544566]
	TIME [epoch: 13.1 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17437920350367314		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.17437920350367314 | validation: 0.20732927113891472]
	TIME [epoch: 13.1 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769901229158661		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.1769901229158661 | validation: 0.23659381910434607]
	TIME [epoch: 13.1 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1892178939383125		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.1892178939383125 | validation: 0.22061468875220283]
	TIME [epoch: 13.1 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18944497260620696		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.18944497260620696 | validation: 0.2069964744306746]
	TIME [epoch: 13.1 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18329386550585625		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.18329386550585625 | validation: 0.23213306201061087]
	TIME [epoch: 13.1 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18972001526781526		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.18972001526781526 | validation: 0.20843351858352754]
	TIME [epoch: 13.1 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1950779340421302		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.1950779340421302 | validation: 0.2468580239508629]
	TIME [epoch: 13.1 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19000118626574716		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.19000118626574716 | validation: 0.22787382558406688]
	TIME [epoch: 13.2 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981694724557096		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.1981694724557096 | validation: 0.2243284186812385]
	TIME [epoch: 13.1 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20445970606041786		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.20445970606041786 | validation: 0.25151286180719695]
	TIME [epoch: 13.1 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874571657983143		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.20874571657983143 | validation: 0.21782805142993245]
	TIME [epoch: 13.1 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18958161092489675		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.18958161092489675 | validation: 0.2204349550662184]
	TIME [epoch: 13.1 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795422593922816		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.1795422593922816 | validation: 0.1984099211030999]
	TIME [epoch: 13.1 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17864547340896486		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.17864547340896486 | validation: 0.22608426241174204]
	TIME [epoch: 13.1 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17341470323814273		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.17341470323814273 | validation: 0.20436235865130645]
	TIME [epoch: 13.1 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812467815114202		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.1812467815114202 | validation: 0.23222615622380968]
	TIME [epoch: 13.1 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17694360929723255		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.17694360929723255 | validation: 0.21594969496877844]
	TIME [epoch: 13.1 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17976913909451142		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.17976913909451142 | validation: 0.19340400580457562]
	TIME [epoch: 13.1 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786065365947772		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.1786065365947772 | validation: 0.20557792652766083]
	TIME [epoch: 13.1 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1922822608326814		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.1922822608326814 | validation: 0.21949654296873766]
	TIME [epoch: 13.1 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19578965736627363		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.19578965736627363 | validation: 0.22250684329949816]
	TIME [epoch: 13.1 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18099786767870285		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.18099786767870285 | validation: 0.22527440458849335]
	TIME [epoch: 13.1 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18140182878551112		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.18140182878551112 | validation: 0.21292477944118646]
	TIME [epoch: 13.1 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804274781762072		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.1804274781762072 | validation: 0.2226866530889585]
	TIME [epoch: 13.1 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773799251791622		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.17773799251791622 | validation: 0.21441925507334247]
	TIME [epoch: 13.1 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18561957308570987		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.18561957308570987 | validation: 0.2085292207413759]
	TIME [epoch: 13.1 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18388927829369198		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.18388927829369198 | validation: 0.20591545641015516]
	TIME [epoch: 13.1 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16903135931550625		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.16903135931550625 | validation: 0.22252155321934142]
	TIME [epoch: 13.1 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18032264874574383		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.18032264874574383 | validation: 0.21056673906019172]
	TIME [epoch: 13.1 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820020664952609		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.1820020664952609 | validation: 0.215157841745472]
	TIME [epoch: 13.1 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755787028638		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.17755787028638 | validation: 0.2089653364070815]
	TIME [epoch: 13.1 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1795841018753682		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.1795841018753682 | validation: 0.19859277653457277]
	TIME [epoch: 13.1 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18018232427468928		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.18018232427468928 | validation: 0.1997424464254184]
	TIME [epoch: 13.1 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16899511547435664		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.16899511547435664 | validation: 0.19510253465948907]
	TIME [epoch: 13.1 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16927187317902226		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.16927187317902226 | validation: 0.2204961535505648]
	TIME [epoch: 13.1 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18042545636100418		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.18042545636100418 | validation: 0.2296631038422575]
	TIME [epoch: 13.1 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18078697632373525		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.18078697632373525 | validation: 0.20667511153473223]
	TIME [epoch: 13.1 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18131122845723233		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.18131122845723233 | validation: 0.20091665410420426]
	TIME [epoch: 13.1 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17693880600701523		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.17693880600701523 | validation: 0.19905547150215835]
	TIME [epoch: 13.1 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18373517768040673		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.18373517768040673 | validation: 0.2199371556721588]
	TIME [epoch: 13.1 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18795165276063716		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.18795165276063716 | validation: 0.21130705490649226]
	TIME [epoch: 13.1 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17675989441924297		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.17675989441924297 | validation: 0.2203678535726346]
	TIME [epoch: 13.1 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17713234800795857		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.17713234800795857 | validation: 0.19604257245401685]
	TIME [epoch: 13.1 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18195430177604024		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.18195430177604024 | validation: 0.2137871959072298]
	TIME [epoch: 13.1 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18465684982518168		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.18465684982518168 | validation: 0.2140035551992824]
	TIME [epoch: 13.1 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726864144298727		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.1726864144298727 | validation: 0.21771731435760405]
	TIME [epoch: 13.1 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17359458206120826		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.17359458206120826 | validation: 0.22277519681432373]
	TIME [epoch: 13.1 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538622775442703		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.17538622775442703 | validation: 0.20668271257562032]
	TIME [epoch: 13.1 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766117196689409		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.1766117196689409 | validation: 0.2147123691452141]
	TIME [epoch: 13.1 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18374370480225866		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.18374370480225866 | validation: 0.24643258632032297]
	TIME [epoch: 13.1 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19200687509810926		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.19200687509810926 | validation: 0.23157474689058746]
	TIME [epoch: 13.1 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17691332852479996		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.17691332852479996 | validation: 0.20079013528193124]
	TIME [epoch: 13.1 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17899555305420223		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.17899555305420223 | validation: 0.19689994784828557]
	TIME [epoch: 13.2 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739284169019135		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.1739284169019135 | validation: 0.19770645840147896]
	TIME [epoch: 13.1 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793414893148009		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1793414893148009 | validation: 0.21979645740797935]
	TIME [epoch: 13.1 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770624327152686		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.1770624327152686 | validation: 0.20113903852716572]
	TIME [epoch: 13.1 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747694612064985		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.1747694612064985 | validation: 0.20026035703507]
	TIME [epoch: 13.1 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043186990855944		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.17043186990855944 | validation: 0.21498742772522228]
	TIME [epoch: 13.1 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19229232019687864		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.19229232019687864 | validation: 0.2184745709151474]
	TIME [epoch: 13.1 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19221200392843368		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.19221200392843368 | validation: 0.21568976203553047]
	TIME [epoch: 13.1 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19467290893357408		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.19467290893357408 | validation: 0.22423821507584163]
	TIME [epoch: 13.1 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20154602101867564		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.20154602101867564 | validation: 0.20569618581115684]
	TIME [epoch: 13.1 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18958323476526884		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.18958323476526884 | validation: 0.21481674877362314]
	TIME [epoch: 13.1 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18602809549317026		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.18602809549317026 | validation: 0.20170921082614293]
	TIME [epoch: 13.1 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18242026420059262		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.18242026420059262 | validation: 0.20486856031802267]
	TIME [epoch: 13.1 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17198657149904253		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.17198657149904253 | validation: 0.20976244043596334]
	TIME [epoch: 13.1 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17953749788165801		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.17953749788165801 | validation: 0.19792286952288385]
	TIME [epoch: 13.1 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1827919490237686		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.1827919490237686 | validation: 0.20365948721695104]
	TIME [epoch: 13.1 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18015542325657488		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.18015542325657488 | validation: 0.22164437689117109]
	TIME [epoch: 13.1 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18158151510472267		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.18158151510472267 | validation: 0.19869446648747144]
	TIME [epoch: 13.1 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16863590335965103		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.16863590335965103 | validation: 0.22211657666002424]
	TIME [epoch: 13.1 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826880064420613		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.1826880064420613 | validation: 0.2003739087652444]
	TIME [epoch: 13.1 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758336162189166		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.1758336162189166 | validation: 0.20912508808893535]
	TIME [epoch: 13.1 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17083550230449343		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.17083550230449343 | validation: 0.20224753138942106]
	TIME [epoch: 13.1 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17229873350853814		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.17229873350853814 | validation: 0.19800569888598646]
	TIME [epoch: 13.1 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706995768430607		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.1706995768430607 | validation: 0.2085605100207828]
	TIME [epoch: 13.1 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17416742533675877		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.17416742533675877 | validation: 0.21629687132131017]
	TIME [epoch: 13.1 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844044827467518		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.1844044827467518 | validation: 0.22631984971241528]
	TIME [epoch: 13.1 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20472899016984847		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.20472899016984847 | validation: 0.2062226710212888]
	TIME [epoch: 13.1 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18108836207829937		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.18108836207829937 | validation: 0.20258846499669694]
	TIME [epoch: 13.1 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18296075605419682		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.18296075605419682 | validation: 0.2038557702706742]
	TIME [epoch: 13.1 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17076499937410808		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.17076499937410808 | validation: 0.21163954932154944]
	TIME [epoch: 13.1 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16867660880407792		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.16867660880407792 | validation: 0.19793771026308896]
	TIME [epoch: 13.1 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033185984431485		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.18033185984431485 | validation: 0.20639645136374019]
	TIME [epoch: 13.1 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17974956166540276		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.17974956166540276 | validation: 0.20808301670429644]
	TIME [epoch: 13.1 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833004021376291		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.1833004021376291 | validation: 0.20410805643861665]
	TIME [epoch: 13.1 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1815004713205271		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.1815004713205271 | validation: 0.21456299775630766]
	TIME [epoch: 13.1 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.183272738360246		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.183272738360246 | validation: 0.2025047527895744]
	TIME [epoch: 13.1 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17708436568014801		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.17708436568014801 | validation: 0.21319307082368366]
	TIME [epoch: 13.1 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17965127807826725		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.17965127807826725 | validation: 0.21386468973252226]
	TIME [epoch: 13.1 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17814356366063863		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.17814356366063863 | validation: 0.21342658737322928]
	TIME [epoch: 13.1 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17661164897106787		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.17661164897106787 | validation: 0.20426521967002295]
	TIME [epoch: 13.1 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18818585903144094		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.18818585903144094 | validation: 0.2038423983311116]
	TIME [epoch: 13.1 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18924363852560855		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.18924363852560855 | validation: 0.21745638846104862]
	TIME [epoch: 13.1 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18594622311522804		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.18594622311522804 | validation: 0.19586261089243087]
	TIME [epoch: 13.1 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18100719847171928		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.18100719847171928 | validation: 0.21000199933908387]
	TIME [epoch: 13.1 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723649334958455		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.1723649334958455 | validation: 0.21185998957298083]
	TIME [epoch: 13.1 sec]
EPOCH 1654/2000:
	Training over batches...
