Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r1', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 416199573

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.482117133275676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.482117133275676 | validation: 9.574329660929946]
	TIME [epoch: 101 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.058971783558134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.058971783558134 | validation: 8.715435852021516]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.300536311258817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.300536311258817 | validation: 8.330528827062317]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.966893115830971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.966893115830971 | validation: 7.677699278507503]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.420184253827767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.420184253827767 | validation: 7.20190720214904]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.001286604478899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.001286604478899 | validation: 6.77022209582565]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6676167186520505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6676167186520505 | validation: 6.467823513483246]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.618872040659728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.618872040659728 | validation: 6.240374154311283]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.924110479439179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.924110479439179 | validation: 6.086376620581328]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.286426901917974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.286426901917974 | validation: 6.224616205539546]
	TIME [epoch: 11.6 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9861230668367345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9861230668367345 | validation: 5.910267534654945]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.894880571130516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.894880571130516 | validation: 5.8357757874739855]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859162447080313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.859162447080313 | validation: 5.822902461963934]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815568527913391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.815568527913391 | validation: 5.920869038485491]
	TIME [epoch: 11.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879749157918158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.879749157918158 | validation: 6.9206205364859]
	TIME [epoch: 11.5 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.177937338324896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.177937338324896 | validation: 5.9298355822766515]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7512363599127205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7512363599127205 | validation: 5.820003895484897]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.66990588260641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.66990588260641 | validation: 5.8501573195562075]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.72216183944867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.72216183944867 | validation: 6.026475967547035]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7178901285823045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7178901285823045 | validation: 5.985365014340255]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.775292640376301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.775292640376301 | validation: 5.82933323436747]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.621415232227972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.621415232227972 | validation: 5.851059953044153]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.655540721498913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.655540721498913 | validation: 5.761581491364117]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.622827440615426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.622827440615426 | validation: 5.826526816423251]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636172409379275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.636172409379275 | validation: 5.697599080105972]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.564693167486514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.564693167486514 | validation: 5.936092930112234]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.650236245313243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.650236245313243 | validation: 5.765060927917789]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.530642568572849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.530642568572849 | validation: 5.962917111795082]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.566367664337999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.566367664337999 | validation: 5.685673561858108]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.562139440567691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.562139440567691 | validation: 5.789501974639767]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.551791146164059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551791146164059 | validation: 5.37228639686306]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.651524565268392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.651524565268392 | validation: 5.527436359513827]
	TIME [epoch: 11.5 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.50876713240778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.50876713240778 | validation: 5.591014784953906]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.421197683731097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.421197683731097 | validation: 5.796388988519871]
	TIME [epoch: 11.5 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.967300945803499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.967300945803499 | validation: 5.371826560537884]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.314127942169997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.314127942169997 | validation: 5.826030922887009]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.498840991371377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.498840991371377 | validation: 5.429612628580724]
	TIME [epoch: 11.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.203608775427353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.203608775427353 | validation: 5.082123135176832]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.050157670816562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.050157670816562 | validation: 5.075857574388818]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.972283139985313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.972283139985313 | validation: 4.880649723110075]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.977446312799653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.977446312799653 | validation: 4.972478030820161]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.967736190544573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.967736190544573 | validation: 4.79338408077417]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.795234793684426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.795234793684426 | validation: 4.743966051553518]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.700194170998206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.700194170998206 | validation: 4.840521576546755]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.686062224323494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.686062224323494 | validation: 4.781209436098057]
	TIME [epoch: 11.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.715470666571367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.715470666571367 | validation: 5.447049038084952]
	TIME [epoch: 11.5 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.064405846476221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.064405846476221 | validation: 4.803882078903794]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.449679874673784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.449679874673784 | validation: 4.169030299803157]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.245992971739816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.245992971739816 | validation: 4.524196615295245]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.503600640590166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.503600640590166 | validation: 4.277144527498211]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.178548563978762		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.178548563978762 | validation: 4.000317269153795]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9928042368546697		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.9928042368546697 | validation: 3.7428744806902876]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.768576428084228		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.768576428084228 | validation: 3.5364449456573186]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7888951902375982		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.7888951902375982 | validation: 3.486818093557912]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4393198197831496		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.4393198197831496 | validation: 3.1146618891496476]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7853238385397425		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.7853238385397425 | validation: 2.9817049313668207]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5548550559075958		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.5548550559075958 | validation: 3.3200564149047596]
	TIME [epoch: 11.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.157676286740868		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.157676286740868 | validation: 3.01580463991747]
	TIME [epoch: 11.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4527508465403676		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.4527508465403676 | validation: 3.019960787257651]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9886092513497076		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.9886092513497076 | validation: 2.7049646727346057]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.801170923556304		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.801170923556304 | validation: 3.1791454139333717]
	TIME [epoch: 11.5 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.769926426452221		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.769926426452221 | validation: 2.553686763111218]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2632492609859587		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.2632492609859587 | validation: 2.458328982590561]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8006176461279733		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.8006176461279733 | validation: 2.429347178399087]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5240853944421153		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.5240853944421153 | validation: 2.6864880140604863]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4719897455304234		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.4719897455304234 | validation: 2.414063391527928]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2733357271198993		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.2733357271198993 | validation: 2.835749370196565]
	TIME [epoch: 11.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.677547285786744		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.677547285786744 | validation: 2.364857848590755]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4832771841212713		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.4832771841212713 | validation: 2.0793592364190956]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3920360744023133		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.3920360744023133 | validation: 2.1670211778535977]
	TIME [epoch: 11.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.284178084893556		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.284178084893556 | validation: 2.3536678243943716]
	TIME [epoch: 11.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097633546811551		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.097633546811551 | validation: 2.1905174846706776]
	TIME [epoch: 11.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.215188444701038		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.215188444701038 | validation: 2.380836242665613]
	TIME [epoch: 11.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7615625751999344		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.7615625751999344 | validation: 2.3621841164086788]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.272965520528068		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.272965520528068 | validation: 2.0862337639960016]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2840249270349338		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.2840249270349338 | validation: 2.214016933010249]
	TIME [epoch: 11.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093112958532326		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.093112958532326 | validation: 2.1163488386555436]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.061872204408535		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.061872204408535 | validation: 2.075312204104615]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0651589725378146		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.0651589725378146 | validation: 2.343469417557779]
	TIME [epoch: 11.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.085243376425051		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.085243376425051 | validation: 2.6051091721920843]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.224037565627474		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.224037565627474 | validation: 2.333418144054874]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9712201827342404		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9712201827342404 | validation: 2.1485588683363015]
	TIME [epoch: 11.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.078877987589176		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.078877987589176 | validation: 1.969641134585295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0625817600486025		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.0625817600486025 | validation: 2.232719911689374]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9988297621409898		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.9988297621409898 | validation: 2.203933750833162]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.951353322338237		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.951353322338237 | validation: 1.803642644969158]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7373476364819176		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.7373476364819176 | validation: 1.7321179175731858]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0701637872731697		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.0701637872731697 | validation: 2.3649591906568785]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1178967462855467		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.1178967462855467 | validation: 1.8667733603027967]
	TIME [epoch: 11.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8114466687076376		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.8114466687076376 | validation: 1.7090900487688407]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0758819728794577		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.0758819728794577 | validation: 1.7871391548554862]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8491892653749553		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.8491892653749553 | validation: 1.7679096415618694]
	TIME [epoch: 11.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1220375266028584		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.1220375266028584 | validation: 2.1880892147132935]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8358869191425886		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.8358869191425886 | validation: 2.463213984903066]
	TIME [epoch: 11.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9885632517556822		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.9885632517556822 | validation: 2.3292405840339763]
	TIME [epoch: 11.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8189997092789842		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.8189997092789842 | validation: 1.7319779201803789]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6463902990068227		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.6463902990068227 | validation: 1.9157494106506796]
	TIME [epoch: 11.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9290705645098896		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9290705645098896 | validation: 1.884888269330271]
	TIME [epoch: 11.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7397912116637604		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.7397912116637604 | validation: 2.136813302687339]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.939916086203915		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.939916086203915 | validation: 1.787488468783793]
	TIME [epoch: 11.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8069854075118297		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.8069854075118297 | validation: 2.0091272445135795]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.767470325198329		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.767470325198329 | validation: 1.8898263075327553]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7202534792480793		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.7202534792480793 | validation: 1.7429933308893442]
	TIME [epoch: 11.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6471892060266131		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.6471892060266131 | validation: 2.426114333579233]
	TIME [epoch: 11.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7084587009918204		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.7084587009918204 | validation: 1.8518916172704847]
	TIME [epoch: 11.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7424564903638846		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.7424564903638846 | validation: 1.3382362186851027]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7141152798524149		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7141152798524149 | validation: 1.7854836183315081]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3933076843138943		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.3933076843138943 | validation: 1.417508601525244]
	TIME [epoch: 11.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752303036090113		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.752303036090113 | validation: 1.4377407202556498]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341736445669008		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.341736445669008 | validation: 1.449045298032852]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4166297377674726		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.4166297377674726 | validation: 1.5455578135515016]
	TIME [epoch: 11.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733933683168023		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.733933683168023 | validation: 1.7190272154702189]
	TIME [epoch: 11.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.576257745758877		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.576257745758877 | validation: 1.4955068829756692]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7666831619915053		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.7666831619915053 | validation: 1.3447375935399715]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.96701281652206		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.96701281652206 | validation: 1.4729958650754122]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6687610546846474		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.6687610546846474 | validation: 1.9025686761947815]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6013513097241177		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.6013513097241177 | validation: 1.5330224165189108]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5526307339047365		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.5526307339047365 | validation: 1.4420071753793418]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2913938855709448		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.2913938855709448 | validation: 1.439740879696571]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.440772167809265		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.440772167809265 | validation: 1.817934923013086]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4678706040367773		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.4678706040367773 | validation: 1.3861312299705493]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9059243697522659		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.9059243697522659 | validation: 1.6152378473149764]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6307852008984325		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.6307852008984325 | validation: 1.6419056479080747]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3737769569974514		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.3737769569974514 | validation: 1.5684606779329975]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4782450011313983		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.4782450011313983 | validation: 1.2936931167136863]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2723882858395972		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.2723882858395972 | validation: 1.5561032954216807]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.218261293872238		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.218261293872238 | validation: 1.1735924148883246]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4236930515554047		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.4236930515554047 | validation: 1.4835808790526703]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4332402610872714		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4332402610872714 | validation: 1.7967438889895564]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3643676858945617		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.3643676858945617 | validation: 1.2762170721690493]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240941909501014		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.240941909501014 | validation: 1.2493180426615227]
	TIME [epoch: 11.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4957603714531609		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.4957603714531609 | validation: 2.69040201417859]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.605545097901091		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.605545097901091 | validation: 1.1679608051262127]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290282315544175		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.290282315544175 | validation: 1.2829737921483093]
	TIME [epoch: 11.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1772641756965656		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.1772641756965656 | validation: 2.1022521356009554]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.828390754069862		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.828390754069862 | validation: 1.2946952553682136]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3655317905845978		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3655317905845978 | validation: 1.3136623241076324]
	TIME [epoch: 11.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3908066265576249		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3908066265576249 | validation: 1.4171527731482336]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7479812551897287		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.7479812551897287 | validation: 1.8790251358200123]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4808626462796783		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4808626462796783 | validation: 1.2322001663421265]
	TIME [epoch: 11.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3229154475514693		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.3229154475514693 | validation: 1.3972584040888256]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.528619668599088		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.528619668599088 | validation: 1.7130165616928543]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3397521563620447		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3397521563620447 | validation: 1.7998716939293622]
	TIME [epoch: 11.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4832823346547475		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.4832823346547475 | validation: 1.5272687377061178]
	TIME [epoch: 11.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.366383731351193		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.366383731351193 | validation: 1.686070520539846]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.420210206843342		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.420210206843342 | validation: 1.4463378726857679]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.548178582852794		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.548178582852794 | validation: 2.2716944893711353]
	TIME [epoch: 11.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5751025364168008		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.5751025364168008 | validation: 1.4586315034654544]
	TIME [epoch: 11.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354202038659312		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.7354202038659312 | validation: 1.929553616691708]
	TIME [epoch: 11.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.485807448242532		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.485807448242532 | validation: 1.4430818253519828]
	TIME [epoch: 11.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2071282614131797		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2071282614131797 | validation: 1.6056984262246987]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6117812176479713		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.6117812176479713 | validation: 1.0720526873871294]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4949858354029872		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.4949858354029872 | validation: 1.5898699394462799]
	TIME [epoch: 11.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7354512561983908		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.7354512561983908 | validation: 1.3867836045763955]
	TIME [epoch: 11.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.618296054579913		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.618296054579913 | validation: 1.6350873396012764]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3465259351663017		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.3465259351663017 | validation: 1.8050747004062795]
	TIME [epoch: 11.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7508537339261245		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.7508537339261245 | validation: 1.627181448305119]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3866546718977788		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3866546718977788 | validation: 1.6780798203808018]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5097617696875756		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.5097617696875756 | validation: 1.521941079048172]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3370566422398982		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.3370566422398982 | validation: 2.3768120097535737]
	TIME [epoch: 11.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5529271798923723		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.5529271798923723 | validation: 1.9683065635153554]
	TIME [epoch: 11.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526072304047044		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.526072304047044 | validation: 1.3492349080971924]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1607346476766223		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.1607346476766223 | validation: 1.568614939651472]
	TIME [epoch: 11.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4821235531444654		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.4821235531444654 | validation: 1.416775378496634]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1785049573556428		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.1785049573556428 | validation: 1.1671877549261007]
	TIME [epoch: 11.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2482928715208716		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2482928715208716 | validation: 1.3498627008813813]
	TIME [epoch: 11.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2507723094338896		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.2507723094338896 | validation: 1.1679825217531197]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1459295320685463		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.1459295320685463 | validation: 1.2506062587822606]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1126487898098167		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.1126487898098167 | validation: 1.0493158795215547]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3529326406871651		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.3529326406871651 | validation: 1.673462759056879]
	TIME [epoch: 11.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178264832724565		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.178264832724565 | validation: 2.5852935442400202]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3830614117398883		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.3830614117398883 | validation: 1.1223294621872]
	TIME [epoch: 11.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2144357299649997		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.2144357299649997 | validation: 1.314353884734903]
	TIME [epoch: 11.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3353565563178678		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3353565563178678 | validation: 1.5398787103913145]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1504504232134896		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.1504504232134896 | validation: 1.2758932062022492]
	TIME [epoch: 11.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2107739054042992		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.2107739054042992 | validation: 1.4332168843032203]
	TIME [epoch: 11.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1095799666467527		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1095799666467527 | validation: 1.0360657964877436]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0437313222417672		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.0437313222417672 | validation: 1.3023871313961581]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1837763362781515		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.1837763362781515 | validation: 1.2471387383884383]
	TIME [epoch: 11.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1234818835903846		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.1234818835903846 | validation: 1.4422491723521842]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0515141812015023		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0515141812015023 | validation: 1.3519485451755475]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0456258912431948		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0456258912431948 | validation: 1.2540966621127057]
	TIME [epoch: 11.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0925337898519256		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.0925337898519256 | validation: 2.602015070469026]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8390373985111694		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.8390373985111694 | validation: 1.3578741783542816]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.039047019453471		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.039047019453471 | validation: 2.094006725650767]
	TIME [epoch: 11.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3210263713695203		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.3210263713695203 | validation: 2.1533911691988825]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4866124213229928		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.4866124213229928 | validation: 0.9767011970043755]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8922340733381824		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.8922340733381824 | validation: 1.096559303525069]
	TIME [epoch: 11.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0104434023454456		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0104434023454456 | validation: 1.2963709313083382]
	TIME [epoch: 11.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3583080809091352		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3583080809091352 | validation: 1.3416633303696162]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2645210375142029		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.2645210375142029 | validation: 1.4224827725648865]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3124865211193368		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.3124865211193368 | validation: 1.2403527546660236]
	TIME [epoch: 11.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9364888581778674		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.9364888581778674 | validation: 1.4234469510619976]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1072123840527677		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.1072123840527677 | validation: 1.092347248048281]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.956146829866444		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.956146829866444 | validation: 1.1868353242260938]
	TIME [epoch: 11.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0448447058065233		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.0448447058065233 | validation: 1.4896790386090752]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.234331219376868		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.234331219376868 | validation: 1.468577720558933]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2171170331803474		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.2171170331803474 | validation: 1.4710981267583259]
	TIME [epoch: 11.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1969444255640154		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.1969444255640154 | validation: 1.1803656478899869]
	TIME [epoch: 11.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587251584170826		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.587251584170826 | validation: 1.162992812933819]
	TIME [epoch: 11.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0195971323765316		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0195971323765316 | validation: 1.153121627347139]
	TIME [epoch: 11.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.037305336376651		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.037305336376651 | validation: 1.078696889879909]
	TIME [epoch: 11.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.123620030986948		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.123620030986948 | validation: 1.24722711311634]
	TIME [epoch: 11.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0711674781106768		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0711674781106768 | validation: 1.2231644731458717]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0741620766365074		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.0741620766365074 | validation: 1.0217707073061015]
	TIME [epoch: 11.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0474718228624904		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0474718228624904 | validation: 1.1395285951668752]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0523385499049995		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.0523385499049995 | validation: 0.9893858545903607]
	TIME [epoch: 11.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9915666773885736		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9915666773885736 | validation: 1.4300083168680013]
	TIME [epoch: 11.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3053490194784		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.3053490194784 | validation: 1.3765990662390954]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5581191320911278		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.5581191320911278 | validation: 2.888702367299369]
	TIME [epoch: 11.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6288967165268877		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6288967165268877 | validation: 1.620903299883782]
	TIME [epoch: 11.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.862076123012618		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.862076123012618 | validation: 2.445765134037833]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5041804861387411		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.5041804861387411 | validation: 1.3654940376202935]
	TIME [epoch: 11.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0276700379943504		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.0276700379943504 | validation: 1.444709019618133]
	TIME [epoch: 11.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0660437730829473		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0660437730829473 | validation: 1.45412858755392]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.308570659938889		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.308570659938889 | validation: 1.6605579835745732]
	TIME [epoch: 11.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112425764120713		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.112425764120713 | validation: 0.9370131514220095]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0032110477364604		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0032110477364604 | validation: 1.2440867087124345]
	TIME [epoch: 11.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9526847081925821		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9526847081925821 | validation: 1.625485530460215]
	TIME [epoch: 11.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.242761083222954		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.242761083222954 | validation: 0.9776493779816258]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0667503667354834		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.0667503667354834 | validation: 0.9882672676520163]
	TIME [epoch: 11.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.215179561063508		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.215179561063508 | validation: 0.8742169959347293]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374444721165732		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9374444721165732 | validation: 1.2999959675551391]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0853059561879297		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0853059561879297 | validation: 0.9892370075832958]
	TIME [epoch: 11.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1000807144133111		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.1000807144133111 | validation: 1.2487081084350595]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5368123839236039		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.5368123839236039 | validation: 1.0916080740209657]
	TIME [epoch: 11.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.362812631414697		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.362812631414697 | validation: 1.0748790990385448]
	TIME [epoch: 11.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1181987700935154		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.1181987700935154 | validation: 1.6806475114507315]
	TIME [epoch: 11.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2281630812404962		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.2281630812404962 | validation: 1.0634139241807445]
	TIME [epoch: 11.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0393436363038793		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0393436363038793 | validation: 1.0601685420765032]
	TIME [epoch: 11.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019325955251088		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.019325955251088 | validation: 1.3386399813982315]
	TIME [epoch: 11.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9371879046507445		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9371879046507445 | validation: 0.970442242008962]
	TIME [epoch: 11.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900568701262217		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.900568701262217 | validation: 1.0353772697364536]
	TIME [epoch: 11.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3481722806030638		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.3481722806030638 | validation: 3.9893698277905605]
	TIME [epoch: 11.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1406039434856967		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 2.1406039434856967 | validation: 1.356573679376748]
	TIME [epoch: 11.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1405202135291324		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.1405202135291324 | validation: 1.5410943401787407]
	TIME [epoch: 11.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0670515096591409		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.0670515096591409 | validation: 1.0547569207151455]
	TIME [epoch: 11.5 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0412769268693658		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.0412769268693658 | validation: 1.0647395779382423]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9611210869581277		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.9611210869581277 | validation: 1.8132006018181517]
	TIME [epoch: 11.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3546675836034223		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.3546675836034223 | validation: 0.9710693222485556]
	TIME [epoch: 11.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8118173382269901		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8118173382269901 | validation: 1.0019892909269215]
	TIME [epoch: 11.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.051399850151194		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.051399850151194 | validation: 1.3885739794471017]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2415183741559568		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.2415183741559568 | validation: 1.1200073099601933]
	TIME [epoch: 11.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048678299876735		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.048678299876735 | validation: 0.9037488780292989]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267738145277995		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.9267738145277995 | validation: 0.9297936159747542]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1919704886400626		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.1919704886400626 | validation: 1.1642111367655266]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8994574744717886		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8994574744717886 | validation: 1.0967162362216214]
	TIME [epoch: 11.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9996685068851998		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.9996685068851998 | validation: 1.0761071851677326]
	TIME [epoch: 11.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056436812279623		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.056436812279623 | validation: 1.4512790009575074]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604492405472816		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.0604492405472816 | validation: 0.9956122963251176]
	TIME [epoch: 11.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805837710744084		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8805837710744084 | validation: 0.928397617288786]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.196293198929551		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.196293198929551 | validation: 1.0887209263654585]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0108202491207054		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.0108202491207054 | validation: 1.1229538546882467]
	TIME [epoch: 11.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9616306545488267		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9616306545488267 | validation: 0.9724293859282125]
	TIME [epoch: 11.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8552966418519812		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.8552966418519812 | validation: 1.3038998503922097]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1400063559159466		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.1400063559159466 | validation: 0.9168383562419503]
	TIME [epoch: 11.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9555750381793225		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.9555750381793225 | validation: 0.9986418512392998]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0845143258549181		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.0845143258549181 | validation: 0.9514931944038466]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0456675025092168		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.0456675025092168 | validation: 1.8208882181339459]
	TIME [epoch: 11.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1133175591435598		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.1133175591435598 | validation: 1.367158569727929]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0141918879135234		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0141918879135234 | validation: 1.1439790640339371]
	TIME [epoch: 11.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.917930558557012		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.917930558557012 | validation: 1.3613104370596754]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0049977403805936		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.0049977403805936 | validation: 1.2403065261507318]
	TIME [epoch: 11.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2937129770971043		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.2937129770971043 | validation: 1.122555910290614]
	TIME [epoch: 11.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9184438717446665		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.9184438717446665 | validation: 1.069946074452728]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771192734272204		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7771192734272204 | validation: 1.6554614476202993]
	TIME [epoch: 11.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0330684560942702		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.0330684560942702 | validation: 1.7881879238177771]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1303269232700195		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.1303269232700195 | validation: 1.2741851337861068]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9276152284040997		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9276152284040997 | validation: 0.8284772347186733]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666376352006457		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.0666376352006457 | validation: 0.9025617221060912]
	TIME [epoch: 11.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371200987779872		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.0371200987779872 | validation: 1.139442004228512]
	TIME [epoch: 11.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9858124980208816		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.9858124980208816 | validation: 1.1524270385704956]
	TIME [epoch: 11.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519040321368417		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.1519040321368417 | validation: 1.235018153029536]
	TIME [epoch: 11.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9331012678105924		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9331012678105924 | validation: 1.195872257979303]
	TIME [epoch: 11.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9125334069052988		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.9125334069052988 | validation: 1.0076995270201174]
	TIME [epoch: 11.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0688485670274686		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.0688485670274686 | validation: 0.9246327189605232]
	TIME [epoch: 11.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2952934020821532		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.2952934020821532 | validation: 1.9649179592365504]
	TIME [epoch: 11.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6498478621675525		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.6498478621675525 | validation: 1.8205226428189842]
	TIME [epoch: 11.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2153139713918808		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.2153139713918808 | validation: 1.1214961289459038]
	TIME [epoch: 11.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0622101836356381		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.0622101836356381 | validation: 0.9177731492273665]
	TIME [epoch: 11.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1744217626453506		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1744217626453506 | validation: 0.9964822884624784]
	TIME [epoch: 11.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8400089106844125		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.8400089106844125 | validation: 0.9026589335828171]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8697853039679927		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8697853039679927 | validation: 0.8819586723248131]
	TIME [epoch: 11.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7202361029289784		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7202361029289784 | validation: 1.0598517808830525]
	TIME [epoch: 11.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1251290247321766		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1251290247321766 | validation: 1.008235742311177]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4961938339521703		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.4961938339521703 | validation: 1.3589373043115007]
	TIME [epoch: 11.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0802520053767874		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0802520053767874 | validation: 1.0210421748191942]
	TIME [epoch: 11.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9625911033614047		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9625911033614047 | validation: 1.0175340435188485]
	TIME [epoch: 11.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0826346788601426		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.0826346788601426 | validation: 1.2515457930613534]
	TIME [epoch: 11.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1101193378709449		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.1101193378709449 | validation: 2.8220978556620695]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8230742864934828		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.8230742864934828 | validation: 1.0959740697527047]
	TIME [epoch: 11.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8658136105869991		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.8658136105869991 | validation: 1.1896373233926658]
	TIME [epoch: 11.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9717749921207175		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.9717749921207175 | validation: 0.918598221705617]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0474516740623874		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.0474516740623874 | validation: 1.4800714593946531]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9874644304514548		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9874644304514548 | validation: 0.8308742910146255]
	TIME [epoch: 11.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8348735348656244		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.8348735348656244 | validation: 0.9437130941760534]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.958219071792392		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.958219071792392 | validation: 0.9042891217819323]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8631652354441588		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.8631652354441588 | validation: 1.2679936379783328]
	TIME [epoch: 11.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9001825847154163		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.9001825847154163 | validation: 1.1719975414697463]
	TIME [epoch: 11.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7862428287392229		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7862428287392229 | validation: 0.7083671626138269]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762056604781271		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.762056604781271 | validation: 0.8982037976761523]
	TIME [epoch: 11.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808629532216634		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7808629532216634 | validation: 0.8865693315855291]
	TIME [epoch: 11.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665157400222782		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7665157400222782 | validation: 1.1379741309479463]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2386426207678232		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.2386426207678232 | validation: 1.3875435829951306]
	TIME [epoch: 11.5 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.243946758271358		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.243946758271358 | validation: 0.9556390644126077]
	TIME [epoch: 11.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8633789946851302		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8633789946851302 | validation: 0.9873256954394674]
	TIME [epoch: 11.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8785515122020389		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.8785515122020389 | validation: 1.111229755100199]
	TIME [epoch: 11.5 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8415769376050182		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8415769376050182 | validation: 1.1082880444371785]
	TIME [epoch: 11.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8901640912141304		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.8901640912141304 | validation: 1.0854169517888996]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8552176850902814		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.8552176850902814 | validation: 0.8726904221348641]
	TIME [epoch: 11.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7244597871429693		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7244597871429693 | validation: 0.7093574368389214]
	TIME [epoch: 11.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7499114515149681		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7499114515149681 | validation: 0.9289352286462613]
	TIME [epoch: 11.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.191414082249962		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.191414082249962 | validation: 1.6253403372420565]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9886716953497698		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.9886716953497698 | validation: 1.0232010448949413]
	TIME [epoch: 11.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1361180202773706		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.1361180202773706 | validation: 0.9192552843833312]
	TIME [epoch: 11.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846970278384496		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7846970278384496 | validation: 0.7187450429864904]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986956691087178		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6986956691087178 | validation: 0.840649091259601]
	TIME [epoch: 11.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903437136104771		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.903437136104771 | validation: 0.7499994894414165]
	TIME [epoch: 11.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7129780901598562		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7129780901598562 | validation: 0.9726747874902885]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808035820088287		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6808035820088287 | validation: 1.0713655033231175]
	TIME [epoch: 11.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7106294445779198		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7106294445779198 | validation: 0.9069753817242997]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107171588990787		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7107171588990787 | validation: 1.009831879217844]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782079014020955		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.782079014020955 | validation: 1.0376478997425855]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292058921910088		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7292058921910088 | validation: 0.7587807553273053]
	TIME [epoch: 11.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837193372608059		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6837193372608059 | validation: 1.1122863097986855]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542265171057643		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.9542265171057643 | validation: 0.7708746573789231]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647639381591225		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6647639381591225 | validation: 0.8980305169262666]
	TIME [epoch: 11.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365941218961342		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.1365941218961342 | validation: 0.832230990519279]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842695864041639		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6842695864041639 | validation: 0.7711461776254862]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857765060842147		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.6857765060842147 | validation: 0.7581527702180756]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281327614019934		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6281327614019934 | validation: 1.4843693763151986]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8522068294476871		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8522068294476871 | validation: 1.3342281096838502]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555776236201781		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8555776236201781 | validation: 0.8007271132924573]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706498528122707		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6706498528122707 | validation: 0.6977977084389549]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.686171559162817		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.686171559162817 | validation: 0.726015092286161]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008881028173506		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7008881028173506 | validation: 2.1635084351130605]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1728897398636082		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.1728897398636082 | validation: 0.9549113025265876]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6549846661420938		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6549846661420938 | validation: 0.9479878714982016]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7191625295933879		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.7191625295933879 | validation: 0.853912081280102]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9403331835975044		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.9403331835975044 | validation: 1.018910988838009]
	TIME [epoch: 11.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4367447238943098		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.4367447238943098 | validation: 1.0463263049831957]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.941164809253636		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.941164809253636 | validation: 0.8786068276938932]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9829712322444799		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.9829712322444799 | validation: 0.8977847847632388]
	TIME [epoch: 11.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8557440941628365		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8557440941628365 | validation: 0.8722639074134432]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8371143290664469		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8371143290664469 | validation: 0.762223666012056]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.759051332432988		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.759051332432988 | validation: 0.7296769228453622]
	TIME [epoch: 11.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6528048615693067		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.6528048615693067 | validation: 1.5688738917688796]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9411750489219299		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.9411750489219299 | validation: 0.9409186995568378]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7028012918423145		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.7028012918423145 | validation: 0.7657725490672335]
	TIME [epoch: 11.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6881902728775409		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6881902728775409 | validation: 0.6646626044264525]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7416414567355836		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.7416414567355836 | validation: 1.0551552435418854]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319828971381608		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.0319828971381608 | validation: 0.748557999692341]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8211727844617249		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.8211727844617249 | validation: 1.042042447174495]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7307280131154603		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.7307280131154603 | validation: 0.767020207940404]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341567874520563		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.7341567874520563 | validation: 0.7401328319649321]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323976400467963		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6323976400467963 | validation: 0.9237424962220715]
	TIME [epoch: 11.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143241529914353		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.8143241529914353 | validation: 0.8865401208905789]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9790213094114588		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.9790213094114588 | validation: 0.8309146778204403]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7154769471144252		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.7154769471144252 | validation: 0.6698533977618483]
	TIME [epoch: 11.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372680001307921		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5372680001307921 | validation: 0.9260149414106846]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6546456868406099		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6546456868406099 | validation: 1.027269727036066]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8782014864006232		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.8782014864006232 | validation: 0.8195089070889924]
	TIME [epoch: 11.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8258054395558858		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.8258054395558858 | validation: 0.783310846546863]
	TIME [epoch: 11.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8310776597526739		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.8310776597526739 | validation: 0.9901078141963985]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7486455027892867		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.7486455027892867 | validation: 0.8874744636901334]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8289434046194221		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8289434046194221 | validation: 0.9252899222856042]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8703172180503603		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8703172180503603 | validation: 0.7910601484484056]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463762124051885		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6463762124051885 | validation: 0.923483485039245]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1680797298780532		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.1680797298780532 | validation: 1.1156340447657902]
	TIME [epoch: 11.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8209371121079332		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.8209371121079332 | validation: 0.6744863894003146]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8399554940707303		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.8399554940707303 | validation: 1.440869797575064]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8122885853154764		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8122885853154764 | validation: 0.6861462096135225]
	TIME [epoch: 11.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838822616647311		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.5838822616647311 | validation: 0.7105396646000174]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306435532130107		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7306435532130107 | validation: 1.0947939207127888]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7978335162697463		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7978335162697463 | validation: 0.7972085200011136]
	TIME [epoch: 11.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9675802664642537		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.9675802664642537 | validation: 0.6456867679617184]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8555977552295398		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8555977552295398 | validation: 0.8121556811227879]
	TIME [epoch: 11.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375757258832872		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7375757258832872 | validation: 0.7041935491389273]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8199797925911438		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8199797925911438 | validation: 0.79165401080781]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.671071154058982		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.671071154058982 | validation: 1.112159149849864]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8216319659584778		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.8216319659584778 | validation: 1.4675029639459496]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.933287819169405		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.933287819169405 | validation: 1.071030741682909]
	TIME [epoch: 11.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.764393109958831		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.764393109958831 | validation: 0.911667797020355]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6845892738111434		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6845892738111434 | validation: 0.8759638585554741]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757145498115192		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.6757145498115192 | validation: 0.9848703297128091]
	TIME [epoch: 11.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0286739768513002		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.0286739768513002 | validation: 0.7534119356255005]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7549260134226585		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.7549260134226585 | validation: 0.900247855273544]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7773984922629995		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.7773984922629995 | validation: 0.8725217520109422]
	TIME [epoch: 11.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118967795549489		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7118967795549489 | validation: 0.8722600573531152]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355081945757882		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7355081945757882 | validation: 0.9194622563345501]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7757351027289137		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.7757351027289137 | validation: 0.8964843359992827]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6991251576265567		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.6991251576265567 | validation: 0.9992420458843212]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6786031985697915		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.6786031985697915 | validation: 0.8231646175860706]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789967002177136		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6789967002177136 | validation: 1.8062509677315564]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0251417822749953		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.0251417822749953 | validation: 1.2460083162489124]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8472182597763785		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8472182597763785 | validation: 0.7082795503188803]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341225494014731		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.7341225494014731 | validation: 1.0271508722641505]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7890971177106959		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7890971177106959 | validation: 1.082008994568217]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117794839269084		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7117794839269084 | validation: 1.2466502565612214]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9386287779200093		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.9386287779200093 | validation: 1.1885659085177969]
	TIME [epoch: 11.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811953418022764		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.0811953418022764 | validation: 1.0218843600247243]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2296416918544777		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.2296416918544777 | validation: 0.6752366401680447]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6774095911886286		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.6774095911886286 | validation: 0.8546572691560484]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664134689839962		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.6664134689839962 | validation: 0.8487357789677296]
	TIME [epoch: 11.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6726034581960009		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6726034581960009 | validation: 1.0589752880824645]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474518300333317		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.7474518300333317 | validation: 0.867387241074136]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704642880047009		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6704642880047009 | validation: 0.7997406572686384]
	TIME [epoch: 11.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.66455706638452		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.66455706638452 | validation: 1.6575470860156816]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345547258446277		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.345547258446277 | validation: 0.8303883070819994]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7220740904286865		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.7220740904286865 | validation: 0.9046123900849622]
	TIME [epoch: 11.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8579171351811805		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.8579171351811805 | validation: 1.0789010279747138]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171464880403235		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7171464880403235 | validation: 0.7833543067801381]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6559478247745143		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6559478247745143 | validation: 1.336012251758719]
	TIME [epoch: 11.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9744560922420231		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.9744560922420231 | validation: 0.808356908164153]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7588693466816661		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7588693466816661 | validation: 0.780207124531306]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808610121656073		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6808610121656073 | validation: 0.7094964315864044]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118627599750577		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7118627599750577 | validation: 0.6691622415019434]
	TIME [epoch: 11.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291394026610045		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6291394026610045 | validation: 0.8617806428225412]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6987968840553215		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6987968840553215 | validation: 0.65280169713824]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418492461670795		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.6418492461670795 | validation: 0.8192217028021008]
	TIME [epoch: 11.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7719359023408128		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7719359023408128 | validation: 0.8505109712167063]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545657351780343		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6545657351780343 | validation: 0.8335310647218603]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1591875489713441		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.1591875489713441 | validation: 0.7983506783068325]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515734424674973		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6515734424674973 | validation: 0.747209833794626]
	TIME [epoch: 11.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7206601805397661		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7206601805397661 | validation: 0.6990276540645075]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909001833139654		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.5909001833139654 | validation: 0.8501512612307269]
	TIME [epoch: 11.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706960203972516		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.6706960203972516 | validation: 0.9263871670934265]
	TIME [epoch: 11.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6904139088419148		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.6904139088419148 | validation: 0.7885839690761236]
	TIME [epoch: 11.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0766611048977917		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.0766611048977917 | validation: 0.9995714285556057]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8222689394022715		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.8222689394022715 | validation: 0.7251366049550941]
	TIME [epoch: 11.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7463920032267668		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7463920032267668 | validation: 0.8201207947551475]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680545641854506		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6680545641854506 | validation: 0.7181456429354235]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777633076487686		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.777633076487686 | validation: 0.8369405871850575]
	TIME [epoch: 11.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7767952337668349		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7767952337668349 | validation: 0.883889310229176]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790234372654056		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6790234372654056 | validation: 0.6508755796056575]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406461460467768		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6406461460467768 | validation: 0.7630025983015202]
	TIME [epoch: 11.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9774770873742966		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.9774770873742966 | validation: 1.2651247413470748]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055042920542356		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.8055042920542356 | validation: 0.7576645569155417]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6311641847560128		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6311641847560128 | validation: 0.6180900646414874]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_439.pth
	Model improved!!!
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414715014109572		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.5414715014109572 | validation: 0.7798068126182472]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7098562546779108		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.7098562546779108 | validation: 1.1770513325756033]
	TIME [epoch: 11.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635345873933423		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7635345873933423 | validation: 0.8985314926849314]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958695417902341		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.6958695417902341 | validation: 1.0650632068883479]
	TIME [epoch: 11.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7114159753444148		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.7114159753444148 | validation: 0.659196060870446]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727220944922707		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.6727220944922707 | validation: 0.7790447314234293]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671335341427743		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6671335341427743 | validation: 0.6721889314256515]
	TIME [epoch: 11.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248380812817823		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6248380812817823 | validation: 0.7754672477836565]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885250053512562		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7885250053512562 | validation: 0.9209357626897188]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333167799860538		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.6333167799860538 | validation: 1.2661844352928098]
	TIME [epoch: 11.5 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7947528998695189		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.7947528998695189 | validation: 1.0628409945010402]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.680564691108978		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.680564691108978 | validation: 0.6372978299879553]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953431776090696		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7953431776090696 | validation: 0.7699004384227652]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697801180407187		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.6697801180407187 | validation: 0.7730706582739407]
	TIME [epoch: 11.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790455941480411		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.5790455941480411 | validation: 1.5250496841817112]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.019267110061356		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.019267110061356 | validation: 1.0333406195357921]
	TIME [epoch: 11.5 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083843664488937		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.6083843664488937 | validation: 0.735427665634237]
	TIME [epoch: 11.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383145270432916		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.6383145270432916 | validation: 0.8707982289478068]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8916101994459374		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.8916101994459374 | validation: 1.1257419732455216]
	TIME [epoch: 11.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797010315033398		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.6797010315033398 | validation: 0.6514890530066597]
	TIME [epoch: 11.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330009636462942		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.5330009636462942 | validation: 0.6245804997687551]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5285603192099214		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.5285603192099214 | validation: 0.8218212400938274]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6572201070123501		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.6572201070123501 | validation: 0.711050790893798]
	TIME [epoch: 11.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.603358108807446		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.603358108807446 | validation: 0.9227566478352409]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975632505477964		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.5975632505477964 | validation: 0.6452919698325802]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458501796961108		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.5458501796961108 | validation: 0.7255749161621966]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939314169144058		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5939314169144058 | validation: 0.7116677020420461]
	TIME [epoch: 11.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6395247493715803		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6395247493715803 | validation: 0.6096683495418774]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859709485503171		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5859709485503171 | validation: 0.972086986503612]
	TIME [epoch: 11.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6639597418060234		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.6639597418060234 | validation: 0.6650303324477309]
	TIME [epoch: 11.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957252164169153		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.5957252164169153 | validation: 0.7946318838641168]
	TIME [epoch: 11.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.588388965146337		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.588388965146337 | validation: 0.6963746367097483]
	TIME [epoch: 11.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565014052061636		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5565014052061636 | validation: 0.8325434537604981]
	TIME [epoch: 11.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7567567775658923		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7567567775658923 | validation: 1.2719503365166591]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531956748050818		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7531956748050818 | validation: 0.7809873670111509]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556527107412218		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.556527107412218 | validation: 0.7141432220871454]
	TIME [epoch: 11.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5999014899509558		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.5999014899509558 | validation: 0.661358396086695]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399025791486177		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5399025791486177 | validation: 0.7650922947117793]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.587473636968645		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.587473636968645 | validation: 0.666788366584023]
	TIME [epoch: 11.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568015235097165		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.568015235097165 | validation: 0.7128273399237565]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49821858047572026		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.49821858047572026 | validation: 0.7898188689509542]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398630953353756		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5398630953353756 | validation: 0.796382586707513]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174287206782174		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.6174287206782174 | validation: 0.7105135866916418]
	TIME [epoch: 11.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5767931343968006		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5767931343968006 | validation: 0.8744417703417817]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388466938285338		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.6388466938285338 | validation: 0.7623862646062357]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669747148403922		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5669747148403922 | validation: 0.8730441588274528]
	TIME [epoch: 11.5 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965297662244242		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6965297662244242 | validation: 0.9714566076145704]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132041046452328		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6132041046452328 | validation: 0.8960249743594897]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851571994012106		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5851571994012106 | validation: 0.747295016818781]
	TIME [epoch: 11.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047297783815445		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.5047297783815445 | validation: 1.0837696509118806]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540699976052751		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.6540699976052751 | validation: 0.6592034404357753]
	TIME [epoch: 11.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4871406309035358		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.4871406309035358 | validation: 0.6855510157696826]
	TIME [epoch: 11.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947623779112681		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5947623779112681 | validation: 0.8696995226115618]
	TIME [epoch: 11.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013364083938345		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6013364083938345 | validation: 0.9660709399501126]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042896103036208		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.6042896103036208 | validation: 0.6221353204382427]
	TIME [epoch: 11.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508943751267349		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6508943751267349 | validation: 0.6312080583130988]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48220401461596457		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.48220401461596457 | validation: 0.6740638158290121]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49216059632996034		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.49216059632996034 | validation: 0.8669230976266823]
	TIME [epoch: 11.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749650623976866		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5749650623976866 | validation: 0.6737015169869445]
	TIME [epoch: 11.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542961696191697		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.5542961696191697 | validation: 0.5679882603074315]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6459891613841664		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.6459891613841664 | validation: 1.1313465320742737]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344131654463709		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6344131654463709 | validation: 0.7384798496161613]
	TIME [epoch: 11.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532035980554755		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.6532035980554755 | validation: 0.5412803908117957]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_502.pth
	Model improved!!!
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533997962421223		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.4533997962421223 | validation: 0.5530941730635914]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5249194934880517		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.5249194934880517 | validation: 0.6063083155586926]
	TIME [epoch: 11.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598718495552715		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.598718495552715 | validation: 0.7795232993483256]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5184310685338555		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.5184310685338555 | validation: 0.5808550964485479]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138756351441938		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5138756351441938 | validation: 0.5867416035803218]
	TIME [epoch: 11.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46429470288670666		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.46429470288670666 | validation: 0.4959440938464343]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492096434018245		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5492096434018245 | validation: 0.5742769762379616]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.506867207473727		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.506867207473727 | validation: 0.7666890636365807]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135477656991215		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5135477656991215 | validation: 0.5927181394773042]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057710652978966		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5057710652978966 | validation: 0.7773594723201177]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865066945332911		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.5865066945332911 | validation: 0.8823704268460049]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170249916565175		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.7170249916565175 | validation: 0.5274425732967911]
	TIME [epoch: 11.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029960066304576		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5029960066304576 | validation: 0.7676315663551625]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6028462891878021		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.6028462891878021 | validation: 0.8049102723920086]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199208377016908		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5199208377016908 | validation: 0.5500007941036452]
	TIME [epoch: 11.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102330290202664		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6102330290202664 | validation: 0.7078273579713499]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072114653456229		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5072114653456229 | validation: 0.5484278339359726]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167592856516334		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5167592856516334 | validation: 0.7012695397068415]
	TIME [epoch: 11.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157627061485392		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6157627061485392 | validation: 0.6820000965904243]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590138036916446		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.590138036916446 | validation: 1.0419945954602563]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817071903559195		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6817071903559195 | validation: 1.0444460227149315]
	TIME [epoch: 11.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8317628467633038		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.8317628467633038 | validation: 0.5945707665357568]
	TIME [epoch: 11.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854915208109617		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.6854915208109617 | validation: 0.5884301372631265]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.470958626367649		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.470958626367649 | validation: 0.859246572298088]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112357818028394		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.6112357818028394 | validation: 0.5277653329932634]
	TIME [epoch: 11.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740679704916385		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.4740679704916385 | validation: 0.5895239817506233]
	TIME [epoch: 11.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278543264009167		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5278543264009167 | validation: 0.8226656775450443]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6013868231985942		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6013868231985942 | validation: 0.6950078744548963]
	TIME [epoch: 11.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6093776351287684		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6093776351287684 | validation: 0.7921636111062094]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091041636055319		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5091041636055319 | validation: 0.8560814466123842]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684393519908849		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.5684393519908849 | validation: 0.8391094464896768]
	TIME [epoch: 11.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800030472503707		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5800030472503707 | validation: 0.5927282343461534]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5959472169356994		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.5959472169356994 | validation: 1.1019025753494376]
	TIME [epoch: 11.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183374561529249		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.6183374561529249 | validation: 0.6662906369585002]
	TIME [epoch: 11.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075152429254436		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.6075152429254436 | validation: 0.7297681657575342]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5286594287078784		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5286594287078784 | validation: 0.6624698303233899]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257794703349602		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.5257794703349602 | validation: 0.554120958620472]
	TIME [epoch: 11.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463850200463732		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6463850200463732 | validation: 0.6796063771366297]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6009638293423176		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6009638293423176 | validation: 0.6698386949412387]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158895308843827		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5158895308843827 | validation: 0.745940115002808]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937668469512956		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.5937668469512956 | validation: 0.6243832330216019]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5977884759173648		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5977884759173648 | validation: 0.765540654793977]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685896087605115		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6685896087605115 | validation: 0.52472088627846]
	TIME [epoch: 11.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6029634626633218		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6029634626633218 | validation: 0.5261083505923055]
	TIME [epoch: 11.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493487999610704		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.493487999610704 | validation: 0.654922408322864]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686380606310826		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.4686380606310826 | validation: 0.4962664352032655]
	TIME [epoch: 11.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5268067009433249		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5268067009433249 | validation: 0.5581224816472811]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126643255957375		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.5126643255957375 | validation: 0.5907083175223898]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43974433286962133		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.43974433286962133 | validation: 0.6517117791801641]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047751170906773		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.5047751170906773 | validation: 0.620068035403932]
	TIME [epoch: 11.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49685063701961085		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.49685063701961085 | validation: 0.5878213687895188]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6288188121800072		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6288188121800072 | validation: 0.6300864473289765]
	TIME [epoch: 11.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46991022471443		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.46991022471443 | validation: 0.5352081919716342]
	TIME [epoch: 11.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606845699450977		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.5606845699450977 | validation: 0.5904027175674723]
	TIME [epoch: 11.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609233760283432		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.4609233760283432 | validation: 0.5022681265433704]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4592217247864861		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.4592217247864861 | validation: 0.6854153897996789]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49382889394009943		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.49382889394009943 | validation: 0.5566328400784734]
	TIME [epoch: 11.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429220032733795		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5429220032733795 | validation: 0.6754441234101702]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48917777847943844		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.48917777847943844 | validation: 0.5660564149398074]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4630418196783592		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.4630418196783592 | validation: 0.8355585370527706]
	TIME [epoch: 11.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7914262028082275		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7914262028082275 | validation: 0.7548285609953564]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772496213602647		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5772496213602647 | validation: 0.5449274305280684]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6478742072533799		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6478742072533799 | validation: 0.6270946324804647]
	TIME [epoch: 11.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4829061694671849		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.4829061694671849 | validation: 0.5561637497780895]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5804663321453933		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5804663321453933 | validation: 0.5438109147153747]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176524003200262		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5176524003200262 | validation: 0.6418070611683233]
	TIME [epoch: 11.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5312045113737192		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5312045113737192 | validation: 0.779125509197748]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936042230432359		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5936042230432359 | validation: 1.01017782786424]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598619055109216		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.6598619055109216 | validation: 1.026942080450169]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615770994751593		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6615770994751593 | validation: 0.7080295249764168]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078770383389779		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.5078770383389779 | validation: 0.6253651615003541]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49798741776638566		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.49798741776638566 | validation: 0.5139150016499733]
	TIME [epoch: 11.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42549753696570614		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.42549753696570614 | validation: 0.7067643718823143]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686720688539763		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.4686720688539763 | validation: 0.5714956586753767]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969052351706683		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4969052351706683 | validation: 0.5447143443701016]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42238948448399927		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.42238948448399927 | validation: 0.8074752690714456]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039023102251216		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5039023102251216 | validation: 0.6919863449176492]
	TIME [epoch: 11.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912512419276605		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.5912512419276605 | validation: 0.600327970645108]
	TIME [epoch: 11.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5715905251769148		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5715905251769148 | validation: 0.8738008769969472]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126469670674588		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6126469670674588 | validation: 0.9609322049279243]
	TIME [epoch: 11.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677579665591084		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5677579665591084 | validation: 0.710931578611914]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6514877546951698		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6514877546951698 | validation: 0.7967443858037928]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743243190339546		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5743243190339546 | validation: 0.6251150624852376]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423539482037302		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5423539482037302 | validation: 0.62462076405591]
	TIME [epoch: 11.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849816992633246		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.4849816992633246 | validation: 0.7003893725082451]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4844715737440935		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.4844715737440935 | validation: 1.4790441887347954]
	TIME [epoch: 11.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9807744472566873		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.9807744472566873 | validation: 0.6828931635541633]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43743326308702124		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.43743326308702124 | validation: 0.594712037232396]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44744498718343717		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.44744498718343717 | validation: 0.5453118885232713]
	TIME [epoch: 11.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48699796872100837		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.48699796872100837 | validation: 0.5897266393479418]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48690839841375666		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.48690839841375666 | validation: 0.6675247565226845]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441139723636066		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5441139723636066 | validation: 0.571437654200244]
	TIME [epoch: 11.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4465702372978708		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.4465702372978708 | validation: 0.5347814697856529]
	TIME [epoch: 11.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650793559590181		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.4650793559590181 | validation: 0.5045497977488451]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4307618804436013		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.4307618804436013 | validation: 0.7898610188547381]
	TIME [epoch: 11.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5146838467598809		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.5146838467598809 | validation: 0.5458447970908715]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524719483175339		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.4524719483175339 | validation: 1.1341895610754065]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984161948777304		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6984161948777304 | validation: 0.4909237032558492]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774505182673483		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5774505182673483 | validation: 0.5244220136354284]
	TIME [epoch: 11.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49755489671165615		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.49755489671165615 | validation: 0.48896717667611145]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_602.pth
	Model improved!!!
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121418782120528		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5121418782120528 | validation: 0.5201044828940702]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055736997857869		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5055736997857869 | validation: 0.6666467669217805]
	TIME [epoch: 11.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206476165870638		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.5206476165870638 | validation: 0.6439328529690564]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4298793790881811		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.4298793790881811 | validation: 0.5379313946216301]
	TIME [epoch: 11.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520179690843885		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5520179690843885 | validation: 0.6970619905583725]
	TIME [epoch: 11.5 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521896012937624		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.5521896012937624 | validation: 0.5784645583866022]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299690910524025		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5299690910524025 | validation: 0.6187391477711064]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4329563136208272		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.4329563136208272 | validation: 0.5877896635153443]
	TIME [epoch: 11.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756444424178219		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5756444424178219 | validation: 0.6269052196500744]
	TIME [epoch: 11.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908301966063804		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3908301966063804 | validation: 0.4971569899899313]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037735046365559		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5037735046365559 | validation: 0.6409303848280472]
	TIME [epoch: 11.5 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4103757815385474		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4103757815385474 | validation: 0.4974447535408931]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448012365541109		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.3448012365541109 | validation: 0.5540662600943015]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3880262186632293		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3880262186632293 | validation: 0.5731874252084254]
	TIME [epoch: 11.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147228679366282		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5147228679366282 | validation: 0.495550910717298]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.459815608572959		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.459815608572959 | validation: 0.4726360040271092]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4136117116682935		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.4136117116682935 | validation: 0.5237926848278855]
	TIME [epoch: 11.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39308358944556127		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.39308358944556127 | validation: 0.47718798053500094]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012499852814508		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.4012499852814508 | validation: 0.6628476453313951]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446995579630407		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5446995579630407 | validation: 0.47290334281981083]
	TIME [epoch: 11.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48113822813240836		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.48113822813240836 | validation: 0.5237520204391568]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42670228204845434		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.42670228204845434 | validation: 0.46924376635240167]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_624.pth
	Model improved!!!
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39635604862626916		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.39635604862626916 | validation: 0.5133586939911712]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40606925992873866		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.40606925992873866 | validation: 0.5224660743905862]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969371696937916		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.4969371696937916 | validation: 0.5341127321334848]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.557740130549386		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.557740130549386 | validation: 0.5976508145096124]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4539905015260344		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.4539905015260344 | validation: 0.4923456574007649]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4968968327076174		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.4968968327076174 | validation: 0.5891676069457752]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40328358220818084		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.40328358220818084 | validation: 0.7809467746520679]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068383492982764		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5068383492982764 | validation: 0.5893252601953332]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887615319117513		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5887615319117513 | validation: 0.48425500568291074]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42154870998863203		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.42154870998863203 | validation: 0.465143564473555]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4167313745851409		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.4167313745851409 | validation: 0.42996159720780924]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088406245261361		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.4088406245261361 | validation: 0.49115698156545073]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42830656628756436		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.42830656628756436 | validation: 0.5953931304727142]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40028213500576976		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.40028213500576976 | validation: 0.5279830199633422]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4184958764392316		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.4184958764392316 | validation: 0.6535681484796748]
	TIME [epoch: 11.5 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509438718228965		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.4509438718228965 | validation: 0.6195590113085956]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48940878252921155		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.48940878252921155 | validation: 0.6615748689621026]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631530246413219		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.4631530246413219 | validation: 0.5079640374264939]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47250236384806166		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.47250236384806166 | validation: 0.6116904682334934]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4775103353850378		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.4775103353850378 | validation: 0.5037030452264533]
	TIME [epoch: 11.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48743505471573056		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.48743505471573056 | validation: 0.49672665367879576]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492142896597349		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.4492142896597349 | validation: 0.5072502752659631]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42079601458600147		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.42079601458600147 | validation: 0.5267339268234956]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.397911699285847		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.397911699285847 | validation: 0.6150928864077057]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820177943001112		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.4820177943001112 | validation: 0.5497015465956412]
	TIME [epoch: 11.5 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44127613320039133		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.44127613320039133 | validation: 0.5121707573403069]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409868180332402		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.409868180332402 | validation: 0.537085311099793]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4534575855895652		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.4534575855895652 | validation: 0.4853304655369098]
	TIME [epoch: 11.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474930040925045		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3474930040925045 | validation: 0.46095852153894556]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631856520513421		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3631856520513421 | validation: 0.47983091594569616]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3996768452618271		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.3996768452618271 | validation: 0.44122267075809407]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37675111566624714		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.37675111566624714 | validation: 0.45857673363838347]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3558497165435316		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3558497165435316 | validation: 0.5384141045624096]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41345655088489064		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.41345655088489064 | validation: 1.2699888859476192]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7566863221918512		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.7566863221918512 | validation: 0.5193220638591621]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910764222271548		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3910764222271548 | validation: 0.5166656178787163]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687370261854569		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3687370261854569 | validation: 0.49623872710829453]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40973333540846446		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.40973333540846446 | validation: 0.5405200256372591]
	TIME [epoch: 11.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41278592573771006		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.41278592573771006 | validation: 0.46634180417977694]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164439421324268		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5164439421324268 | validation: 0.4386441413038242]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44221295412125594		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.44221295412125594 | validation: 0.6101606030815063]
	TIME [epoch: 11.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140269471612258		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5140269471612258 | validation: 0.8437173732702864]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48461739086373046		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.48461739086373046 | validation: 0.7014828845304429]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499956448368611		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5499956448368611 | validation: 0.5809742308339404]
	TIME [epoch: 11.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39313580199523246		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.39313580199523246 | validation: 0.5815584366704308]
	TIME [epoch: 11.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48643841763256357		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.48643841763256357 | validation: 0.5223485904226548]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47870171563283354		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.47870171563283354 | validation: 0.4955569521639428]
	TIME [epoch: 11.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46830048503069055		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.46830048503069055 | validation: 0.4729085272585832]
	TIME [epoch: 11.5 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3515766374135279		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3515766374135279 | validation: 0.5180390222243403]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753461778729319		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3753461778729319 | validation: 0.5705130954022489]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44983551720618975		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.44983551720618975 | validation: 1.2502824743551566]
	TIME [epoch: 11.5 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269517888482682		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.7269517888482682 | validation: 0.48208074258253447]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49015537338295534		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.49015537338295534 | validation: 0.5830659337704799]
	TIME [epoch: 11.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886436770767857		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3886436770767857 | validation: 0.5467219016164689]
	TIME [epoch: 11.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36617048720477413		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.36617048720477413 | validation: 0.43518297515851234]
	TIME [epoch: 11.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42219524392199403		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.42219524392199403 | validation: 0.4397038687722965]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234557115986098		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.4234557115986098 | validation: 0.6886400994161991]
	TIME [epoch: 11.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4290307939259478		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.4290307939259478 | validation: 0.5345723664396954]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4208687925449561		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.4208687925449561 | validation: 0.6735544128963175]
	TIME [epoch: 11.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085772826021153		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.4085772826021153 | validation: 0.5252886586361742]
	TIME [epoch: 11.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39991280822452785		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.39991280822452785 | validation: 0.6475501298770854]
	TIME [epoch: 11.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6336027477356545		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.6336027477356545 | validation: 0.4982370942947172]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47270332383134955		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.47270332383134955 | validation: 0.5677172705676172]
	TIME [epoch: 11.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43036029982664925		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.43036029982664925 | validation: 0.4702046324901605]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3915072620778854		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.3915072620778854 | validation: 0.4707779889836616]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40349812468455787		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.40349812468455787 | validation: 0.6578045219968164]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49470298788888606		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.49470298788888606 | validation: 0.49899782029998774]
	TIME [epoch: 11.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38119366460815923		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.38119366460815923 | validation: 0.46034848900342823]
	TIME [epoch: 11.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364015156145994		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.4364015156145994 | validation: 0.4474674128399325]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4570677633752383		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4570677633752383 | validation: 0.49144548226842644]
	TIME [epoch: 11.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40126055401393323		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.40126055401393323 | validation: 0.5389872950882584]
	TIME [epoch: 11.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47928639406856466		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.47928639406856466 | validation: 0.45353430942690465]
	TIME [epoch: 11.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492978209891893		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3492978209891893 | validation: 0.5796877293784353]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39187888357856104		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.39187888357856104 | validation: 0.5749502948640758]
	TIME [epoch: 11.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38580737098930845		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.38580737098930845 | validation: 0.5374606738736717]
	TIME [epoch: 11.5 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3553930508148055		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.3553930508148055 | validation: 0.4710957447081196]
	TIME [epoch: 11.5 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822560864261364		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3822560864261364 | validation: 0.538060434149062]
	TIME [epoch: 11.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36690839203191966		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.36690839203191966 | validation: 0.4967708245156203]
	TIME [epoch: 11.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3603383793915767		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3603383793915767 | validation: 0.4723155599852734]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35845034576278223		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.35845034576278223 | validation: 0.700919392279965]
	TIME [epoch: 11.5 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903043232188552		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.4903043232188552 | validation: 0.6140133751118696]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43111113420402275		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.43111113420402275 | validation: 0.47307018101501463]
	TIME [epoch: 11.5 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3421446932845764		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.3421446932845764 | validation: 0.540021316821342]
	TIME [epoch: 11.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975552956503803		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3975552956503803 | validation: 0.6699414396838111]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4328910736982277		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.4328910736982277 | validation: 0.5768577961246284]
	TIME [epoch: 11.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42108136852108796		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.42108136852108796 | validation: 0.49567569370026204]
	TIME [epoch: 11.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.637341714392007		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.637341714392007 | validation: 0.45262775252118387]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40780839224849885		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.40780839224849885 | validation: 0.6656210045765459]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4424087352407628		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.4424087352407628 | validation: 0.4816635876553443]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4008721596820732		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.4008721596820732 | validation: 0.5720135081665199]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35797842346714687		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.35797842346714687 | validation: 0.4581221046491876]
	TIME [epoch: 11.5 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3791583959149205		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.3791583959149205 | validation: 0.4565508743747424]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533499142812926		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.4533499142812926 | validation: 0.5394243659694363]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764414857254612		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3764414857254612 | validation: 0.5584291225726191]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39229900595550293		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.39229900595550293 | validation: 0.4939270342710709]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3917229945464809		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3917229945464809 | validation: 0.5334680977652438]
	TIME [epoch: 11.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683464974107089		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.4683464974107089 | validation: 0.5372040030648803]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727277913429606		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4727277913429606 | validation: 0.5579296010843207]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186365055515008		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.4186365055515008 | validation: 0.5289041701173594]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36469171847898685		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.36469171847898685 | validation: 0.5097090857614961]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776509147804775		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3776509147804775 | validation: 0.5061688878721897]
	TIME [epoch: 11.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40437485163727066		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.40437485163727066 | validation: 0.48580422378358434]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933026275655656		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.3933026275655656 | validation: 0.5010433143077073]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495582168046288		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.3495582168046288 | validation: 0.4986419748796234]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38391424561373994		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.38391424561373994 | validation: 0.5045355295691892]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3694199350716312		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3694199350716312 | validation: 0.48712263189881155]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936236949640845		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.3936236949640845 | validation: 0.5306600932276087]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39152618156498264		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.39152618156498264 | validation: 0.5438924430934355]
	TIME [epoch: 11.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498383148963776		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4498383148963776 | validation: 0.5787589586760057]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44319704095680296		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.44319704095680296 | validation: 0.47438785922787885]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44196326884752896		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.44196326884752896 | validation: 0.49669919001641843]
	TIME [epoch: 11.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695183194046206		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.3695183194046206 | validation: 0.5892784227068085]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4050512657749793		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.4050512657749793 | validation: 0.4557902728903459]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43372112219132		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.43372112219132 | validation: 0.6099047213180091]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4008517846535862		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.4008517846535862 | validation: 0.5594205125422722]
	TIME [epoch: 11.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4260726450680024		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.4260726450680024 | validation: 0.48071002187219336]
	TIME [epoch: 11.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5079570576188464		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5079570576188464 | validation: 0.4669971978865472]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36820752142800395		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.36820752142800395 | validation: 0.5248706593109316]
	TIME [epoch: 11.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3585043613826536		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3585043613826536 | validation: 0.5566659148711083]
	TIME [epoch: 11.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34131780376176857		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.34131780376176857 | validation: 0.5636257860806504]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673006351909994		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3673006351909994 | validation: 0.5079437817040807]
	TIME [epoch: 11.5 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321214187375841		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.3321214187375841 | validation: 0.5352178343405088]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38490570137662866		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.38490570137662866 | validation: 0.5132386080469169]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828803837608981		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.3828803837608981 | validation: 0.6598185084372162]
	TIME [epoch: 11.5 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660667902954885		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4660667902954885 | validation: 0.5618888482703559]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37110585023701564		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.37110585023701564 | validation: 0.5683527541933652]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860020133898645		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3860020133898645 | validation: 0.47266090581262904]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039719674929983		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4039719674929983 | validation: 0.5049025019804573]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226289369032111		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4226289369032111 | validation: 0.7218528069020623]
	TIME [epoch: 11.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49158868337339584		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.49158868337339584 | validation: 0.5035279128609707]
	TIME [epoch: 11.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3493344687023416		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.3493344687023416 | validation: 0.491450571596505]
	TIME [epoch: 11.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3826056889565964		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3826056889565964 | validation: 0.5296511325191394]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43019764053722487		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.43019764053722487 | validation: 0.6502030626286809]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455156475494578		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5455156475494578 | validation: 0.571243777809469]
	TIME [epoch: 11.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359008690426187		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4359008690426187 | validation: 0.5558811863860824]
	TIME [epoch: 11.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4109909475737801		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.4109909475737801 | validation: 0.486863666839985]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43414217523913035		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.43414217523913035 | validation: 0.44657845139760993]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758820356640893		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.3758820356640893 | validation: 0.47186505105985327]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38641562387808615		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.38641562387808615 | validation: 0.6091097357486729]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42273698554472877		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.42273698554472877 | validation: 0.44355188262705014]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35057278638427286		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.35057278638427286 | validation: 0.5143764550994703]
	TIME [epoch: 11.5 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36759893017676826		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.36759893017676826 | validation: 0.5597697874696967]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.377982934497024		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.377982934497024 | validation: 0.4819656178997782]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35832021340995374		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.35832021340995374 | validation: 0.43424326192515517]
	TIME [epoch: 11.5 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3596126071597339		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.3596126071597339 | validation: 0.46314983533249116]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36129386026568977		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.36129386026568977 | validation: 0.5753722890062346]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36086311630134205		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.36086311630134205 | validation: 0.5777160872510951]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901994275571937		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.3901994275571937 | validation: 0.4631896517773179]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37422612935442423		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.37422612935442423 | validation: 0.5287257213703128]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121274478076931		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4121274478076931 | validation: 0.4523276865273047]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317934882918695		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.3317934882918695 | validation: 0.4730277918932744]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507077657004931		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.507077657004931 | validation: 0.587484983416026]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4329453089872417		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4329453089872417 | validation: 0.44917429476053294]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3226363513825416		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.3226363513825416 | validation: 0.5129013793115106]
	TIME [epoch: 11.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39540620759860035		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.39540620759860035 | validation: 0.5360579729107887]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938133728052331		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3938133728052331 | validation: 0.41839328823732075]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_780.pth
	Model improved!!!
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408485379934405		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3408485379934405 | validation: 0.5399820617884311]
	TIME [epoch: 11.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40625180240832504		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.40625180240832504 | validation: 0.5501058779245284]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36064450870518494		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.36064450870518494 | validation: 0.47022880614245255]
	TIME [epoch: 11.5 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37685459454885606		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.37685459454885606 | validation: 0.4983954894301138]
	TIME [epoch: 11.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013801073646859		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4013801073646859 | validation: 0.49014457928667354]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39608830313335974		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.39608830313335974 | validation: 0.4236207739220156]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3495844772117347		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3495844772117347 | validation: 0.4428730089977465]
	TIME [epoch: 11.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33809673784044875		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.33809673784044875 | validation: 0.45235957287768197]
	TIME [epoch: 11.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33301781340634334		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.33301781340634334 | validation: 0.520117138377311]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41005058531213023		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.41005058531213023 | validation: 0.4756011825804398]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927030016581686		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4927030016581686 | validation: 0.5873631380236467]
	TIME [epoch: 11.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40659374480379545		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.40659374480379545 | validation: 0.49805561623200534]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368451379090804		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.368451379090804 | validation: 0.47202346937927636]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759309217455575		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.3759309217455575 | validation: 0.4637225740567497]
	TIME [epoch: 11.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732044948430591		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3732044948430591 | validation: 0.5417318934760939]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473238925864961		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.3473238925864961 | validation: 0.43977946738302337]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31393494210983736		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.31393494210983736 | validation: 0.43395876865782756]
	TIME [epoch: 11.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34336731088890926		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.34336731088890926 | validation: 0.4599848373149562]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082438781527368		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.3082438781527368 | validation: 0.47012335375699266]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35458971045846804		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.35458971045846804 | validation: 0.4265158926771601]
	TIME [epoch: 11.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503666033666383		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3503666033666383 | validation: 0.44541067282215274]
	TIME [epoch: 11.5 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274046154139262		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.3274046154139262 | validation: 0.4411878583127276]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3488980301567636		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.3488980301567636 | validation: 0.524087809589378]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42091385879410376		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.42091385879410376 | validation: 0.42699705589937126]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35778715712546416		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.35778715712546416 | validation: 0.4350093182973084]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3195467223984008		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.3195467223984008 | validation: 0.44017503786797435]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289820870694251		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3289820870694251 | validation: 0.4259297467661509]
	TIME [epoch: 11.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3382520076729322		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3382520076729322 | validation: 0.42562831851252386]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259845310714749		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.3259845310714749 | validation: 0.5060786338211319]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3427939912224312		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3427939912224312 | validation: 0.4483778999213739]
	TIME [epoch: 11.5 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431947587630965		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3431947587630965 | validation: 0.6361624777808933]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.483793355515494		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.483793355515494 | validation: 0.47721196172151653]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3382428011952585		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.3382428011952585 | validation: 0.49822183669435377]
	TIME [epoch: 11.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3321100498039237		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.3321100498039237 | validation: 0.4554422700311747]
	TIME [epoch: 11.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34569166724287376		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.34569166724287376 | validation: 0.4836051616693282]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353408108821944		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.3353408108821944 | validation: 0.4035461389825095]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_816.pth
	Model improved!!!
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4409290077959872		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4409290077959872 | validation: 0.6529136466264283]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853565079601524		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3853565079601524 | validation: 0.4550051358283471]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3649150554367946		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3649150554367946 | validation: 0.48379102550109393]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4245267339010663		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.4245267339010663 | validation: 0.6250321520532294]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37474532163281693		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.37474532163281693 | validation: 0.46274017949974006]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622395539291906		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3622395539291906 | validation: 0.5728275867309665]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36663063372872684		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.36663063372872684 | validation: 0.41895866650858876]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37427890976235045		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.37427890976235045 | validation: 0.4782893587120367]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30725561911675126		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.30725561911675126 | validation: 0.4632456000752575]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31636386037277003		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.31636386037277003 | validation: 0.41745914666991335]
	TIME [epoch: 11.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899717065757768		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.2899717065757768 | validation: 0.4641972627378376]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33133318103784626		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.33133318103784626 | validation: 0.4317131001861204]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31974133056231635		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.31974133056231635 | validation: 0.43822349305067143]
	TIME [epoch: 11.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33222416073638117		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.33222416073638117 | validation: 0.43126125330948084]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30503152022706737		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.30503152022706737 | validation: 0.38743582322062864]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881355599042942		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.2881355599042942 | validation: 0.4561288056802763]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3147514740871522		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.3147514740871522 | validation: 0.6475829739618698]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993653491179714		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4993653491179714 | validation: 0.3958421494506776]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43589914008533925		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.43589914008533925 | validation: 0.40784941111128264]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391912338801041		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.3391912338801041 | validation: 0.4265453263403046]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29201203499259076		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.29201203499259076 | validation: 0.3774507257811098]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981837962605699		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.2981837962605699 | validation: 0.5617332438906391]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33487334421126835		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.33487334421126835 | validation: 0.39719411720569525]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31380782226768245		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.31380782226768245 | validation: 0.44225050724455517]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3127320432541598		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.3127320432541598 | validation: 0.39244559448133937]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061657380604942		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.3061657380604942 | validation: 0.403524181371285]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4224559430079989		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4224559430079989 | validation: 0.39971264522424277]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3703916657455045		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.3703916657455045 | validation: 0.38583722520413544]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31657876081752956		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.31657876081752956 | validation: 0.41037036906122354]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36081602518557326		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.36081602518557326 | validation: 0.5159106629208148]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32160090654789186		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.32160090654789186 | validation: 0.4206347510971252]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32406125817762144		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.32406125817762144 | validation: 0.45415093081275765]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34033629343421407		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.34033629343421407 | validation: 0.4201640794953353]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987202456091485		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.2987202456091485 | validation: 0.597292096415634]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38531438419195363		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.38531438419195363 | validation: 0.4003026899128026]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31998301822336295		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.31998301822336295 | validation: 0.379509749656089]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475367488379154		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.3475367488379154 | validation: 0.3877934872965564]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3002299708721664		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.3002299708721664 | validation: 0.44104953655726414]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810137570519721		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3810137570519721 | validation: 0.43035339220356206]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43892565314221627		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.43892565314221627 | validation: 0.45938314755318]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3181301389207774		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.3181301389207774 | validation: 0.4556304188575504]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30449576126584876		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.30449576126584876 | validation: 0.4233297101003112]
	TIME [epoch: 11.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31069486151584924		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.31069486151584924 | validation: 0.40508820634183773]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2978052175770791		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2978052175770791 | validation: 0.40346839744617463]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931575619416906		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.3931575619416906 | validation: 0.40051453972086565]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717403238877353		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.3717403238877353 | validation: 0.44723198266488207]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3162691335785042		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.3162691335785042 | validation: 0.4574723820495285]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219820875526767		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.3219820875526767 | validation: 0.42588954820295855]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215730894788446		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.3215730894788446 | validation: 0.4739690963064394]
	TIME [epoch: 11.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320863222476488		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.320863222476488 | validation: 0.39910011140601925]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245113333662419		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.3245113333662419 | validation: 0.47165042388141415]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141092682646845		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.3141092682646845 | validation: 0.44478258802741444]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29576203698437115		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.29576203698437115 | validation: 0.3981747197876439]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29228876823064925		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.29228876823064925 | validation: 0.46446164000211443]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3608830881924513		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.3608830881924513 | validation: 0.4766324233937982]
	TIME [epoch: 11.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333067075202024		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.333067075202024 | validation: 0.5044116228226949]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35849340862428275		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.35849340862428275 | validation: 0.37505256771166584]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2916529754828455		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2916529754828455 | validation: 0.5524635478875491]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3868710670046673		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.3868710670046673 | validation: 0.5398850015666727]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33787354663215746		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.33787354663215746 | validation: 0.4056304734512268]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338908365943327		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.3338908365943327 | validation: 0.4939267772936634]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176679087529501		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.3176679087529501 | validation: 0.389606504280748]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27364777604159035		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.27364777604159035 | validation: 0.39041681403745615]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29735887816104295		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.29735887816104295 | validation: 0.4137403996926318]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30111971309785224		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.30111971309785224 | validation: 0.3957375585114575]
	TIME [epoch: 11.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30783245490186767		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.30783245490186767 | validation: 0.4190120461014727]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30570572772498616		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.30570572772498616 | validation: 0.40611638729805194]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30565669280770486		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.30565669280770486 | validation: 0.4252731082488397]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36029046872720133		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.36029046872720133 | validation: 0.42509408261045933]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3498689940599649		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3498689940599649 | validation: 0.38191299391839295]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31811064936706335		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.31811064936706335 | validation: 0.45495048482015876]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3168097255146514		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.3168097255146514 | validation: 0.4207242220770124]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3081645477135019		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.3081645477135019 | validation: 0.41237809086411054]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38378902542985016		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.38378902542985016 | validation: 0.4304971083053597]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35407020208880446		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.35407020208880446 | validation: 0.367641055319983]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771672320459213		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2771672320459213 | validation: 0.3990855996335965]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2942456423738252		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.2942456423738252 | validation: 0.42183650929613054]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998469905516748		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.2998469905516748 | validation: 0.39797098183038204]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.322318283552936		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.322318283552936 | validation: 0.4125585095532365]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30180755595838327		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.30180755595838327 | validation: 0.47507641656130206]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43312604654279185		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.43312604654279185 | validation: 0.41011341766336146]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3088495788248625		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3088495788248625 | validation: 0.37850517099948955]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846131684142031		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2846131684142031 | validation: 0.41292906645033783]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31472101415204673		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.31472101415204673 | validation: 0.5049696407108264]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3345519892102464		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3345519892102464 | validation: 0.48033379854349617]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3196474337983503		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.3196474337983503 | validation: 0.5083809090022051]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39129476509126504		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.39129476509126504 | validation: 0.43701520829938817]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35677186801346783		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.35677186801346783 | validation: 0.41886810288012366]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881496061497577		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.2881496061497577 | validation: 0.49763019578293843]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3302228587452748		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.3302228587452748 | validation: 0.45091064164692024]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28497810202525636		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.28497810202525636 | validation: 0.3649943416834037]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811583805825091		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.2811583805825091 | validation: 0.39023403856037747]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29239629536423173		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.29239629536423173 | validation: 0.3774055953244219]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736425945205023		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.2736425945205023 | validation: 0.3633167293897355]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_910.pth
	Model improved!!!
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36530649759936046		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.36530649759936046 | validation: 0.5043595781641949]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341878744868431		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3341878744868431 | validation: 0.491827504349352]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424319854484803		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.3424319854484803 | validation: 0.5230568705202081]
	TIME [epoch: 11.5 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547234085674175		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.3547234085674175 | validation: 0.3636009312917937]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27813202126000935		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.27813202126000935 | validation: 0.40731829466122454]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29454679891669444		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.29454679891669444 | validation: 0.3632535088397218]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2656337644223346		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.2656337644223346 | validation: 0.4029094168616488]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013167748376226		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3013167748376226 | validation: 0.44686398245052544]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035932746369098		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.3035932746369098 | validation: 0.37404981254220615]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961530956802646		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.2961530956802646 | validation: 0.3911598369536695]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871218397273432		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.2871218397273432 | validation: 0.3913121959624983]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29543355140186595		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.29543355140186595 | validation: 0.3910943447341885]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26071118901048695		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.26071118901048695 | validation: 0.43234985512189616]
	TIME [epoch: 11.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815200510918493		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2815200510918493 | validation: 0.3736085128349065]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3238780017328471		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3238780017328471 | validation: 0.5664812685007349]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34336961369977953		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.34336961369977953 | validation: 0.4014091726422299]
	TIME [epoch: 11.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30301859473570636		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.30301859473570636 | validation: 0.3697203717840256]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824355335394161		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.2824355335394161 | validation: 0.4829187995502895]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29422487613213266		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.29422487613213266 | validation: 0.3897991588528468]
	TIME [epoch: 11.5 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27897152918078366		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.27897152918078366 | validation: 0.411114706094989]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013456207347743		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.3013456207347743 | validation: 0.3784905559651837]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669875930517978		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.2669875930517978 | validation: 0.4115313819888094]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26381210747286105		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.26381210747286105 | validation: 0.39775753147072335]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000102306278769		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.3000102306278769 | validation: 0.37667768908793536]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30506064554567797		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.30506064554567797 | validation: 0.41737420091649313]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748697389914506		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.2748697389914506 | validation: 0.386066380894585]
	TIME [epoch: 11.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920284922344652		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.2920284922344652 | validation: 0.3934120607554207]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275830805915877		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.275830805915877 | validation: 0.40825351979529984]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275739208730991		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.275739208730991 | validation: 0.3673377508503045]
	TIME [epoch: 11.5 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29312470265421275		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.29312470265421275 | validation: 0.43588399533809724]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29560742877814145		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.29560742877814145 | validation: 0.36550556812377183]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845369704840384		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.2845369704840384 | validation: 0.441478348281325]
	TIME [epoch: 11.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3079613274156894		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.3079613274156894 | validation: 0.3913017921897181]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246659658177002		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.3246659658177002 | validation: 0.5257804596559249]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37506348262454897		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.37506348262454897 | validation: 0.5214979906903672]
	TIME [epoch: 11.5 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31962118571645065		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.31962118571645065 | validation: 0.397779782246635]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126496876143316		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.3126496876143316 | validation: 0.4225712253356552]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28092505439724846		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.28092505439724846 | validation: 0.36029319600233295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_948.pth
	Model improved!!!
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26593133714885636		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.26593133714885636 | validation: 0.3994601811753262]
	TIME [epoch: 11.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012982668819888		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.4012982668819888 | validation: 0.4745899731052134]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29580764394060605		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.29580764394060605 | validation: 0.4304459298917923]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796857943765578		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.2796857943765578 | validation: 0.39560759665586825]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725459452487309		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.2725459452487309 | validation: 0.3983996563925754]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137413584647361		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.3137413584647361 | validation: 0.38597028884759715]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29990013474953703		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.29990013474953703 | validation: 0.3614948927452283]
	TIME [epoch: 11.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645970153403532		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.2645970153403532 | validation: 0.4087988667764864]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2955125821670791		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2955125821670791 | validation: 0.423575901054788]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30922234906434143		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.30922234906434143 | validation: 0.40877704687131705]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938132009903973		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2938132009903973 | validation: 0.4119779144186623]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31552594214875757		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.31552594214875757 | validation: 0.3837163305920172]
	TIME [epoch: 11.5 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27791414452007274		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.27791414452007274 | validation: 0.3628924040337847]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831234304463235		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.2831234304463235 | validation: 0.42933138339021115]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776216451233235		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2776216451233235 | validation: 0.4256418774244179]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27703120368260326		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.27703120368260326 | validation: 0.5206020528123458]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37011535582627364		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.37011535582627364 | validation: 0.4393350265346673]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31765901622730935		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.31765901622730935 | validation: 0.37434917476741747]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3248651329953466		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.3248651329953466 | validation: 0.46171742997046994]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098844611169196		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.3098844611169196 | validation: 0.4056388699807046]
	TIME [epoch: 11.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33643327872178536		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.33643327872178536 | validation: 0.43013675059484185]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113506608685128		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.3113506608685128 | validation: 0.39457228540081174]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.283496057077678		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.283496057077678 | validation: 0.36490639304419104]
	TIME [epoch: 11.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602753512718772		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2602753512718772 | validation: 0.5402919073960607]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301871230791382		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.3301871230791382 | validation: 0.3829254108465339]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572214660147194		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.2572214660147194 | validation: 0.345779599981458]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_974.pth
	Model improved!!!
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30728520143753457		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.30728520143753457 | validation: 0.400665959785508]
	TIME [epoch: 11.5 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28666273822324045		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.28666273822324045 | validation: 0.3652048573735746]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275624784555141		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.275624784555141 | validation: 0.3447227208897625]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_977.pth
	Model improved!!!
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27162988811726707		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.27162988811726707 | validation: 0.3503227139340311]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530496439136483		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.2530496439136483 | validation: 0.3860205188871122]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2646052266741642		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.2646052266741642 | validation: 0.43040250677080777]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31298083848194985		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.31298083848194985 | validation: 0.402054592446697]
	TIME [epoch: 11.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30657333771478407		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.30657333771478407 | validation: 0.34064251772261783]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_982.pth
	Model improved!!!
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30886889100305004		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.30886889100305004 | validation: 0.43738044631052314]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962105335744063		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.2962105335744063 | validation: 0.3676765943354508]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721042056077296		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.2721042056077296 | validation: 0.37127874190581395]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590707149619112		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.3590707149619112 | validation: 0.4437104330372319]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30706333150921433		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.30706333150921433 | validation: 0.3781890728278507]
	TIME [epoch: 11.5 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27363119128993274		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.27363119128993274 | validation: 0.38143606228311683]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29194458418490876		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.29194458418490876 | validation: 0.3888090638486948]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26190025045823007		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.26190025045823007 | validation: 0.3703482773637145]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28296881197813295		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.28296881197813295 | validation: 0.3420181673904358]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26865810278035185		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.26865810278035185 | validation: 0.4006108987099756]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2971478268232034		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.2971478268232034 | validation: 0.4692333393821682]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364784832240889		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.364784832240889 | validation: 0.371707336891603]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681417508647721		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2681417508647721 | validation: 0.3660636297842207]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294543856575943		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.294543856575943 | validation: 0.36139711560850246]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30201968161061343		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.30201968161061343 | validation: 0.35635821381777943]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26357187327981757		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.26357187327981757 | validation: 0.3409427566522156]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549419938116649		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.2549419938116649 | validation: 0.34913500944859605]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2548618769692399		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.2548618769692399 | validation: 0.37298913946484347]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26398221878167444		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.26398221878167444 | validation: 0.3574516075848508]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29660842332582665		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.29660842332582665 | validation: 0.407479027217004]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602803914471172		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.2602803914471172 | validation: 0.36606003610014254]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27475889452247243		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.27475889452247243 | validation: 0.40664938406797957]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784697349833937		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2784697349833937 | validation: 0.3696836723555405]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264954154075072		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3264954154075072 | validation: 0.3676056546973193]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26300472262909863		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.26300472262909863 | validation: 0.343925729263542]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666180079187188		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.2666180079187188 | validation: 0.3967187094530514]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2757786615009461		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.2757786615009461 | validation: 0.38303149426419636]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662552637112121		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.2662552637112121 | validation: 0.3437157955854758]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556620401740502		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.2556620401740502 | validation: 0.34431775619346916]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632319100900347		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.2632319100900347 | validation: 0.35285137235298286]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25635906074888964		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.25635906074888964 | validation: 0.37140171070512495]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26370816195658986		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.26370816195658986 | validation: 0.3768919672098263]
	TIME [epoch: 11.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3100831096388703		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.3100831096388703 | validation: 0.39541403360244554]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812513284474655		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.2812513284474655 | validation: 0.34568615355796484]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2942938475482471		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.2942938475482471 | validation: 0.450343211989038]
	TIME [epoch: 11.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2869500977906138		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.2869500977906138 | validation: 0.36230039964956834]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535395984926672		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.2535395984926672 | validation: 0.4242384104393123]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30857662264354097		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.30857662264354097 | validation: 0.3908300032936715]
	TIME [epoch: 11.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27591644017132494		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.27591644017132494 | validation: 0.404883346681061]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29984962305130614		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.29984962305130614 | validation: 0.41044826615394786]
	TIME [epoch: 11.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27348758725468975		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.27348758725468975 | validation: 0.4014883503865802]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2487070646357767		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.2487070646357767 | validation: 0.34767943829384934]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573270346793767		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2573270346793767 | validation: 0.40709075186086585]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2898430644958968		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.2898430644958968 | validation: 0.3589526915044117]
	TIME [epoch: 11.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709192119809865		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2709192119809865 | validation: 0.3499169538150432]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26912363949725654		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.26912363949725654 | validation: 0.445362267467072]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3848981814461496		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3848981814461496 | validation: 0.37504368703226876]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576464664296131		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2576464664296131 | validation: 0.37753953449398536]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897977108878107		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2897977108878107 | validation: 0.3928450772792527]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944266489670941		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2944266489670941 | validation: 0.3525592727349817]
	TIME [epoch: 11.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251553527985338		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.251553527985338 | validation: 0.33966632613248476]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672946019780689		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2672946019780689 | validation: 0.36515815582664324]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3129948642368284		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3129948642368284 | validation: 0.422900414766084]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28568140522413404		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.28568140522413404 | validation: 0.3859327006956605]
	TIME [epoch: 11.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25717522688411776		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.25717522688411776 | validation: 0.3655224116296775]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25551511866409554		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.25551511866409554 | validation: 0.4024614960268082]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592032338610857		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.2592032338610857 | validation: 0.3738133454531692]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29417519675117065		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.29417519675117065 | validation: 0.3925110291846346]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691886300726583		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.2691886300726583 | validation: 0.37223299559141765]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25574026668644173		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.25574026668644173 | validation: 0.39234419273843585]
	TIME [epoch: 11.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720983332098648		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2720983332098648 | validation: 0.46053806819327614]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29839955426700276		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.29839955426700276 | validation: 0.36151613277075184]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27798272743056124		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.27798272743056124 | validation: 0.3489822153409233]
	TIME [epoch: 11.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726410360895829		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.2726410360895829 | validation: 0.3479703869150863]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500851481672798		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2500851481672798 | validation: 0.330247223425109]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1047.pth
	Model improved!!!
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24065426553094402		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.24065426553094402 | validation: 0.42486505542356784]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27618077198918534		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.27618077198918534 | validation: 0.38537382822685545]
	TIME [epoch: 11.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2949879934845643		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2949879934845643 | validation: 0.35909481624959866]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071908875818883		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.3071908875818883 | validation: 0.5744812087638838]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35838194773178		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.35838194773178 | validation: 0.3590305950163008]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2712891981984733		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2712891981984733 | validation: 0.41856513061548095]
	TIME [epoch: 11.5 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31808957469821436		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.31808957469821436 | validation: 0.3953129418712398]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116322261086061		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.3116322261086061 | validation: 0.3706380125944414]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25099349542304317		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.25099349542304317 | validation: 0.3288025590382175]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1056.pth
	Model improved!!!
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25907893287727807		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.25907893287727807 | validation: 0.340430340198764]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664610509487689		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.2664610509487689 | validation: 0.3821397559425578]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28862642532410065		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.28862642532410065 | validation: 0.41584514946006196]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26796980663871184		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.26796980663871184 | validation: 0.35290636238780715]
	TIME [epoch: 11.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701165334680205		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.2701165334680205 | validation: 0.3624956893289425]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513814360248505		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.2513814360248505 | validation: 0.36645819518349576]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28447098172412966		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.28447098172412966 | validation: 0.3618002518557871]
	TIME [epoch: 11.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981074230552858		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.2981074230552858 | validation: 0.33443499987550096]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27917240081771866		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.27917240081771866 | validation: 0.427263923671274]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28949322607838524		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.28949322607838524 | validation: 0.4126912226565797]
	TIME [epoch: 11.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27273302923461046		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.27273302923461046 | validation: 0.33630636750840126]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461815503526278		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.2461815503526278 | validation: 0.43600084965083014]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28115953320012166		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.28115953320012166 | validation: 0.35898161262024764]
	TIME [epoch: 11.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28142298655025966		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.28142298655025966 | validation: 0.447512401780052]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30626050571921415		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.30626050571921415 | validation: 0.3603715837008779]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239665921273031		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.239665921273031 | validation: 0.3643585511810111]
	TIME [epoch: 11.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280456815361037		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.280456815361037 | validation: 0.37650187709195826]
	TIME [epoch: 11.5 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518487326825993		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.2518487326825993 | validation: 0.3533724125140924]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2596779159739672		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.2596779159739672 | validation: 0.34829059155718595]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24739606510966133		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.24739606510966133 | validation: 0.35789379691322326]
	TIME [epoch: 11.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25553807373361204		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.25553807373361204 | validation: 0.31915380790883274]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1077.pth
	Model improved!!!
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23867400035396147		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.23867400035396147 | validation: 0.33413032689859906]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30090835653017556		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.30090835653017556 | validation: 0.42573514057882167]
	TIME [epoch: 11.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881344975941812		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.2881344975941812 | validation: 0.3833390497533746]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30755781061179666		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.30755781061179666 | validation: 0.3403388522054436]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29797432791255696		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.29797432791255696 | validation: 0.41752923467605413]
	TIME [epoch: 11.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3005708582330825		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.3005708582330825 | validation: 0.3480386964729979]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26988383362402957		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.26988383362402957 | validation: 0.36353479503249]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25716389456596833		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.25716389456596833 | validation: 0.37737054451247376]
	TIME [epoch: 11.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27034967117179887		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.27034967117179887 | validation: 0.33999079797954734]
	TIME [epoch: 11.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23972241993607735		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.23972241993607735 | validation: 0.3541079766852457]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2562115403599697		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.2562115403599697 | validation: 0.3411410354970283]
	TIME [epoch: 11.5 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413128914623461		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.2413128914623461 | validation: 0.3597984658958652]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2689570223304773		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.2689570223304773 | validation: 0.35102855644285114]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24441484287608098		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.24441484287608098 | validation: 0.38189730275747574]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2806097841573376		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.2806097841573376 | validation: 0.3624883462586939]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24616532107818198		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.24616532107818198 | validation: 0.3452611013353117]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26025764637116305		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.26025764637116305 | validation: 0.35844223908717154]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2870894952068791		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2870894952068791 | validation: 0.3726230697256529]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703251299599764		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2703251299599764 | validation: 0.42201232349818574]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897929889451404		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.2897929889451404 | validation: 0.38759631133647476]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853572684422612		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.2853572684422612 | validation: 0.42050439290814356]
	TIME [epoch: 11.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26773248882084566		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.26773248882084566 | validation: 0.33452137780370966]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23759596439439376		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.23759596439439376 | validation: 0.34205294644201273]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935451912346611		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.2935451912346611 | validation: 0.38322427134142845]
	TIME [epoch: 11.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587009870165248		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.2587009870165248 | validation: 0.3825529511798108]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31526407132087586		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.31526407132087586 | validation: 0.3658881814898718]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866916459122217		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.2866916459122217 | validation: 0.37793720012398974]
	TIME [epoch: 11.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288729627424328		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.288729627424328 | validation: 0.3489542054347098]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2511023488489103		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.2511023488489103 | validation: 0.39868833565516343]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29222208759700213		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.29222208759700213 | validation: 0.32734705618516896]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24007331676008084		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.24007331676008084 | validation: 0.3511038938630215]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779572191286071		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.2779572191286071 | validation: 0.35349335955086475]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532892926361025		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.2532892926361025 | validation: 0.34587805509307645]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409939629962396		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.2409939629962396 | validation: 0.3456417131105608]
	TIME [epoch: 11.5 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586369253853618		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.2586369253853618 | validation: 0.3876628608374411]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604980384057861		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.2604980384057861 | validation: 0.3400404096900909]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26117798844882023		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.26117798844882023 | validation: 0.3300119274296129]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682043425619543		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2682043425619543 | validation: 0.3569356257118562]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559167720515511		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2559167720515511 | validation: 0.3488274509081497]
	TIME [epoch: 11.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24547948570832898		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.24547948570832898 | validation: 0.3270684989405658]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531068664888504		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.2531068664888504 | validation: 0.3408119679218261]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24427464612691416		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.24427464612691416 | validation: 0.32182932873042847]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24132740405878295		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.24132740405878295 | validation: 0.37964294998363574]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2495635748419835		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.2495635748419835 | validation: 0.3365004284267357]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25341262880866827		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.25341262880866827 | validation: 0.36012011691562107]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23608803232108838		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.23608803232108838 | validation: 0.3502325127073248]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24330030506151518		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.24330030506151518 | validation: 0.40441406823801557]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755034238324131		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.2755034238324131 | validation: 0.36044716640705704]
	TIME [epoch: 11.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26571423251562276		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.26571423251562276 | validation: 0.4071165112511622]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27910444032218384		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.27910444032218384 | validation: 0.36782918569875883]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28215284558618614		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.28215284558618614 | validation: 0.3901606625054931]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25227188870987505		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.25227188870987505 | validation: 0.329792139661614]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24032717340677834		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.24032717340677834 | validation: 0.3282076840533928]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23738166173442932		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.23738166173442932 | validation: 0.3544905712216345]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25458967097142965		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.25458967097142965 | validation: 0.3321060165629034]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325420519258638		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2325420519258638 | validation: 0.35318277200690795]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780054448616805		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2780054448616805 | validation: 0.48177986325642913]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34696084147870393		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.34696084147870393 | validation: 0.3411404819904537]
	TIME [epoch: 11.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24560410385039463		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.24560410385039463 | validation: 0.37228226888634547]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24147002395402978		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.24147002395402978 | validation: 0.3563587683106043]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530899330680734		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.2530899330680734 | validation: 0.352633920336239]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25424725507883844		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.25424725507883844 | validation: 0.40030187111937965]
	TIME [epoch: 11.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2849238642587031		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.2849238642587031 | validation: 0.3738767125432205]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27298880427865935		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.27298880427865935 | validation: 0.3807709846104633]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687260822846745		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.2687260822846745 | validation: 0.3901256814211408]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2725246825436186		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.2725246825436186 | validation: 0.3517080398235147]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552351303809062		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.2552351303809062 | validation: 0.33975135330303724]
	TIME [epoch: 11.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24676487435486885		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.24676487435486885 | validation: 0.3820296679338125]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33556988370380514		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.33556988370380514 | validation: 0.42766755287174774]
	TIME [epoch: 11.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727707967080276		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.2727707967080276 | validation: 0.3443837618766864]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427489275307134		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2427489275307134 | validation: 0.32274351671721035]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25469584923145183		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.25469584923145183 | validation: 0.3405504510032467]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24226609844215977		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.24226609844215977 | validation: 0.3537507206806489]
	TIME [epoch: 11.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25102270162943047		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.25102270162943047 | validation: 0.3693207913342738]
	TIME [epoch: 11.5 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2899555996172683		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2899555996172683 | validation: 0.33049828509732915]
	TIME [epoch: 11.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23630325586173606		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.23630325586173606 | validation: 0.3293987629847236]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24737235071114985		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.24737235071114985 | validation: 0.3485995061933362]
	TIME [epoch: 11.5 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29902102925520824		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.29902102925520824 | validation: 0.4527817951218017]
	TIME [epoch: 11.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33681646503373736		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.33681646503373736 | validation: 0.40904632973506394]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2838105680691696		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.2838105680691696 | validation: 0.35369868286809697]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530883187920456		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.2530883187920456 | validation: 0.35267994973572303]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25585876504409594		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.25585876504409594 | validation: 0.32548079765696114]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24775983583538913		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.24775983583538913 | validation: 0.32924640134068056]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23313291127242386		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.23313291127242386 | validation: 0.33351694052686737]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24278810194927808		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.24278810194927808 | validation: 0.39195270840860047]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764642622141806		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.2764642622141806 | validation: 0.35721031839118295]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28573298222538296		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.28573298222538296 | validation: 0.4594466577132954]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28646008879908264		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.28646008879908264 | validation: 0.3508629777560405]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24410553301790938		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.24410553301790938 | validation: 0.3358488589680666]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25114264982783874		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.25114264982783874 | validation: 0.3566800205223487]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558464858388507		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.2558464858388507 | validation: 0.32619414391129153]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387806124957068		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.2387806124957068 | validation: 0.33986365215151537]
	TIME [epoch: 11.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23873549213708248		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.23873549213708248 | validation: 0.3714907755095827]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718265588891867		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.2718265588891867 | validation: 0.353278583657853]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23454033400226693		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.23454033400226693 | validation: 0.3265649016192954]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23768994056499695		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.23768994056499695 | validation: 0.35777914201839706]
	TIME [epoch: 11.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24264344219022188		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.24264344219022188 | validation: 0.34328283090173195]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2484708348368035		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.2484708348368035 | validation: 0.34898657724464927]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2706973516780107		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.2706973516780107 | validation: 0.32592102682252816]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23292807267065835		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.23292807267065835 | validation: 0.34026156782844647]
	TIME [epoch: 11.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26261453818057656		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.26261453818057656 | validation: 0.43972632021324587]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36814637429182523		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.36814637429182523 | validation: 0.3915106990823422]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25917618892319993		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.25917618892319993 | validation: 0.3390875394216707]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24236482556682667		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.24236482556682667 | validation: 0.39604497979892417]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634107483078068		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.2634107483078068 | validation: 0.33954177197478763]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2384505002549885		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.2384505002549885 | validation: 0.3816567407819089]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25388115087647484		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.25388115087647484 | validation: 0.33605359691055015]
	TIME [epoch: 11.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23506651234227316		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.23506651234227316 | validation: 0.33332591679610746]
	TIME [epoch: 11.5 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25256445612678075		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.25256445612678075 | validation: 0.32520935030158554]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23350179079880495		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.23350179079880495 | validation: 0.3353628283209232]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2337218177285476		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.2337218177285476 | validation: 0.3438457503444072]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537009748832668		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.2537009748832668 | validation: 0.34078114328678527]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25142300208147417		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.25142300208147417 | validation: 0.3398535870773449]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24103834030315407		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.24103834030315407 | validation: 0.3466962906267422]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401162917761303		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.2401162917761303 | validation: 0.32559656976392737]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311706901839815		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.2311706901839815 | validation: 0.3487500948561808]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405440090589103		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.2405440090589103 | validation: 0.3480152099852141]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23515060119662085		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.23515060119662085 | validation: 0.3451544782335862]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23580957681491893		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.23580957681491893 | validation: 0.3393446996709588]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503349701667693		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.2503349701667693 | validation: 0.34296436692538057]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23186425685178053		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.23186425685178053 | validation: 0.33320734128415347]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539732819453751		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.2539732819453751 | validation: 0.3689656211352264]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25146743632958957		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.25146743632958957 | validation: 0.37446617059738674]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729247845898619		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.2729247845898619 | validation: 0.3660674105910762]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2520230485093591		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.2520230485093591 | validation: 0.3867910939388534]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27008477726851543		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.27008477726851543 | validation: 0.3150573465537053]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22891837860490336		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.22891837860490336 | validation: 0.3443577772636251]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23872232815566657		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.23872232815566657 | validation: 0.34304448061144827]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2277403783780142		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.2277403783780142 | validation: 0.3234622762923668]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2496359195903207		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.2496359195903207 | validation: 0.3485272642333766]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25520911625369463		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.25520911625369463 | validation: 0.3471974823076539]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409726745417489		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.2409726745417489 | validation: 0.33799256973353126]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23187384147790988		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.23187384147790988 | validation: 0.336878176754736]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24225148047164377		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.24225148047164377 | validation: 0.3462937355519145]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23291140411273914		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.23291140411273914 | validation: 0.32807623553827187]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23001468677861175		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.23001468677861175 | validation: 0.32170076632048195]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25946592417099135		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.25946592417099135 | validation: 0.3748778734669109]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719798334815557		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.2719798334815557 | validation: 0.3308889957354702]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23463188124703763		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.23463188124703763 | validation: 0.3530456214705767]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24505428434638715		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.24505428434638715 | validation: 0.3359502850163621]
	TIME [epoch: 11.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23392065833736697		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.23392065833736697 | validation: 0.32752548691271427]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25730403139484054		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.25730403139484054 | validation: 0.3314967051272795]
	TIME [epoch: 11.5 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538482796455546		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.2538482796455546 | validation: 0.3299317002192693]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24515113238131864		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.24515113238131864 | validation: 0.32781501076498615]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23063546398359125		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.23063546398359125 | validation: 0.32897957833419944]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401757014789424		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.2401757014789424 | validation: 0.3338949346651351]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365641361878849		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.2365641361878849 | validation: 0.32636126794798315]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601713011849603		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.2601713011849603 | validation: 0.3511349869861913]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721721256400548		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.2721721256400548 | validation: 0.34870586186777675]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25118969511494715		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.25118969511494715 | validation: 0.3194436840063282]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23058054480083412		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.23058054480083412 | validation: 0.3324238115391263]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23157038751186446		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.23157038751186446 | validation: 0.32482295015182494]
	TIME [epoch: 11.5 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22824242078437226		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.22824242078437226 | validation: 0.33247591223742673]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22829155340551135		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.22829155340551135 | validation: 0.32899452580306615]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2325796009072848		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.2325796009072848 | validation: 0.3195682492642337]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24307137672212675		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.24307137672212675 | validation: 0.3357553257806605]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2742938089202561		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.2742938089202561 | validation: 0.36280594318783094]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27609696587838917		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.27609696587838917 | validation: 0.35212477391304625]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23841416003014532		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.23841416003014532 | validation: 0.3390700333666671]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23387770680747733		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.23387770680747733 | validation: 0.3618407586655077]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24413067093142227		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.24413067093142227 | validation: 0.3395151762314596]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23161976759020497		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.23161976759020497 | validation: 0.3521057727568367]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2368624143235744		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.2368624143235744 | validation: 0.3259962354813618]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22475343482003698		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.22475343482003698 | validation: 0.3109748513466472]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1241.pth
	Model improved!!!
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23787406033745356		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.23787406033745356 | validation: 0.3405746526544418]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23859871949677014		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.23859871949677014 | validation: 0.3430963895047567]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22370868172598474		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.22370868172598474 | validation: 0.3124594687935272]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22296220178473303		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.22296220178473303 | validation: 0.32072549059914324]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21885669554950143		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.21885669554950143 | validation: 0.3168617423849868]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760264613675662		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.21760264613675662 | validation: 0.31768901370990793]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24822128462511214		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.24822128462511214 | validation: 0.33695802120563884]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24942162123585826		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.24942162123585826 | validation: 0.32898135727190164]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24207796415774024		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.24207796415774024 | validation: 0.3442425931464366]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26022334398390456		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.26022334398390456 | validation: 0.3418311591014417]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25028000981698006		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.25028000981698006 | validation: 0.3273720058116447]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23838302392546235		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.23838302392546235 | validation: 0.32410144332275975]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23120203510448778		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.23120203510448778 | validation: 0.3186951302106933]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22257117615643224		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.22257117615643224 | validation: 0.3418806578411794]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26552470119045896		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.26552470119045896 | validation: 0.3679175525068364]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529036394025951		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.2529036394025951 | validation: 0.3322081828830527]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23738917073758348		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.23738917073758348 | validation: 0.3163167035820723]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23647069668842638		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.23647069668842638 | validation: 0.33293000001514406]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607904223834761		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.2607904223834761 | validation: 0.34884702354034147]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23144150221308407		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.23144150221308407 | validation: 0.30999460067386464]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1261.pth
	Model improved!!!
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22688122737553473		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.22688122737553473 | validation: 0.3183272952789114]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23174120631730913		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.23174120631730913 | validation: 0.30676611101250933]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1263.pth
	Model improved!!!
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22318289295124877		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.22318289295124877 | validation: 0.3205204341687751]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23139429060320665		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.23139429060320665 | validation: 0.34638998356530143]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297828268303281		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.2297828268303281 | validation: 0.31122383108657276]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22594844402367859		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.22594844402367859 | validation: 0.32416984873620514]
	TIME [epoch: 11.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22695772777936127		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.22695772777936127 | validation: 0.334668499322475]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296607370715007		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.2296607370715007 | validation: 0.3294821023769737]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329897907147734		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.2329897907147734 | validation: 0.3406977214452065]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23488030830623752		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.23488030830623752 | validation: 0.3189273424118709]
	TIME [epoch: 11.5 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23096019362020745		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.23096019362020745 | validation: 0.32629872517923697]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23474350784930786		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.23474350784930786 | validation: 0.3351962416440054]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2446865153118574		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.2446865153118574 | validation: 0.3147187581416984]
	TIME [epoch: 11.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22234613435550246		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.22234613435550246 | validation: 0.31405789458899824]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22601178748321094		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.22601178748321094 | validation: 0.3397435487306356]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24830739792081774		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.24830739792081774 | validation: 0.35100172530806517]
	TIME [epoch: 11.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23482073765209885		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.23482073765209885 | validation: 0.32888621056222134]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22643937959028915		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.22643937959028915 | validation: 0.3146725724877067]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23262068710081907		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.23262068710081907 | validation: 0.34542583518441283]
	TIME [epoch: 11.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355584652321116		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.2355584652321116 | validation: 0.3347953598986848]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2311276038181265		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.2311276038181265 | validation: 0.31229473099411836]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21934106411313023		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.21934106411313023 | validation: 0.3163284811557647]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22083428778442254		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.22083428778442254 | validation: 0.3389274640381022]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547151005342203		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.2547151005342203 | validation: 0.33940991410285587]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23466215048330244		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.23466215048330244 | validation: 0.31395846317112236]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23758492253322072		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.23758492253322072 | validation: 0.36337678440335697]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711707991524467		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.2711707991524467 | validation: 0.3491366575818452]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22846670984912595		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.22846670984912595 | validation: 0.3140140694316589]
	TIME [epoch: 11.5 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22651285530410767		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.22651285530410767 | validation: 0.3180397937090359]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23846187206092728		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.23846187206092728 | validation: 0.3092602827330456]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174341881453077		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.2174341881453077 | validation: 0.3383531862394332]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23466962204717615		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.23466962204717615 | validation: 0.31992589100666724]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2178699045395837		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.2178699045395837 | validation: 0.3234401066202991]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23464024057632699		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.23464024057632699 | validation: 0.31983086804991223]
	TIME [epoch: 11.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22815249012190975		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.22815249012190975 | validation: 0.32654219271885637]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300600131810719		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.2300600131810719 | validation: 0.30895768960709014]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23049805946605437		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.23049805946605437 | validation: 0.3353750856540728]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26233004932440573		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.26233004932440573 | validation: 0.3335932420490844]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24521198465744498		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.24521198465744498 | validation: 0.32770370932815013]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22397784295257572		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.22397784295257572 | validation: 0.32897978428087316]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23296771695761498		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.23296771695761498 | validation: 0.3328239255719096]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22988085035671765		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.22988085035671765 | validation: 0.33057984219311093]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595650816711996		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.2595650816711996 | validation: 0.35490354897512705]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24670344494522875		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.24670344494522875 | validation: 0.32342407048343963]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22075310907316786		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.22075310907316786 | validation: 0.31114199049299557]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.222137496585535		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.222137496585535 | validation: 0.3156452380251231]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21999055082998875		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.21999055082998875 | validation: 0.3288491967146664]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24833282650633456		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.24833282650633456 | validation: 0.3384963353412022]
	TIME [epoch: 11.5 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2340169827329126		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.2340169827329126 | validation: 0.31266732802946307]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22417567479594336		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.22417567479594336 | validation: 0.3464838717164136]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23582295031826594		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.23582295031826594 | validation: 0.34865880654138737]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22794292965403284		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.22794292965403284 | validation: 0.31762167928312734]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22667417902241027		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.22667417902241027 | validation: 0.3140872369738021]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2221011010740383		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.2221011010740383 | validation: 0.3151838323543861]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22826539236387758		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.22826539236387758 | validation: 0.32501726615623966]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23264549064631027		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.23264549064631027 | validation: 0.3178135823326404]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22581063033991952		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.22581063033991952 | validation: 0.3220368615754018]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301322308284179		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.2301322308284179 | validation: 0.33414664387285875]
	TIME [epoch: 11.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23900744954858505		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.23900744954858505 | validation: 0.30534867403272037]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1320.pth
	Model improved!!!
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211477460275475		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.2211477460275475 | validation: 0.31607966719966146]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23643153128012506		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.23643153128012506 | validation: 0.30016098982755707]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1322.pth
	Model improved!!!
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23006048874758742		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.23006048874758742 | validation: 0.34205116350600867]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23283346507550023		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.23283346507550023 | validation: 0.32053826220914533]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22248049959856075		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.22248049959856075 | validation: 0.3277769807154002]
	TIME [epoch: 11.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336155968500933		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.2336155968500933 | validation: 0.3258209237841878]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23531492043246216		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.23531492043246216 | validation: 0.317419278939916]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222333130617956		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.2222333130617956 | validation: 0.31658803696176857]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422815900298837		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.2422815900298837 | validation: 0.347967489208322]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273569139253317		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.2273569139253317 | validation: 0.3307466775683474]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24049117883069698		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.24049117883069698 | validation: 0.3472174577465902]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24042323232348253		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.24042323232348253 | validation: 0.3655967157608172]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641095192708227		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.2641095192708227 | validation: 0.3612372506839146]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247831149579503		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.247831149579503 | validation: 0.33991540885539306]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2275856603580801		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.2275856603580801 | validation: 0.33069342321885]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22716899048523642		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.22716899048523642 | validation: 0.3193698724012993]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244563377986532		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.244563377986532 | validation: 0.37748391297235656]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25766568443684007		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.25766568443684007 | validation: 0.3092617542938867]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22762871135849366		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.22762871135849366 | validation: 0.30559748366243195]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22932374955712753		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.22932374955712753 | validation: 0.30698231323257225]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2154587430239939		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.2154587430239939 | validation: 0.3344733732803277]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405405812571353		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.2405405812571353 | validation: 0.3341806590505007]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348723779978092		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.2348723779978092 | validation: 0.31187627325767414]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22455199714690127		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.22455199714690127 | validation: 0.3216304608609902]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23703092873841267		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.23703092873841267 | validation: 0.34527520784473964]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23348676955243194		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.23348676955243194 | validation: 0.35602381976290276]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24406721420072894		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.24406721420072894 | validation: 0.33382422991706817]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22662795448052317		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.22662795448052317 | validation: 0.3277209241858093]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22364504396628393		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.22364504396628393 | validation: 0.3221077134606112]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22111343845080617		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.22111343845080617 | validation: 0.3343191108808448]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23727234600622432		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.23727234600622432 | validation: 0.32642068421696224]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22797786729751324		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.22797786729751324 | validation: 0.32347994404854336]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23798488598403225		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.23798488598403225 | validation: 0.31522747356773584]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22488441160545913		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.22488441160545913 | validation: 0.3223800897445901]
	TIME [epoch: 11.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22960906073095744		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.22960906073095744 | validation: 0.3379524500760418]
	TIME [epoch: 11.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2318268568302539		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.2318268568302539 | validation: 0.32180344261928134]
	TIME [epoch: 11.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22917979359001583		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.22917979359001583 | validation: 0.3255773948709723]
	TIME [epoch: 11.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24328176274959457		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.24328176274959457 | validation: 0.35458706501232945]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360796176599479		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.2360796176599479 | validation: 0.325148608941613]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24760490002781105		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.24760490002781105 | validation: 0.32614480396513384]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227232868702766		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.2227232868702766 | validation: 0.3260118155814658]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22620024190781624		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.22620024190781624 | validation: 0.31561911853963975]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255773716612078		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.2255773716612078 | validation: 0.3378338969483468]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23749690327006093		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.23749690327006093 | validation: 0.3649719173971628]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601586973286323		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.2601586973286323 | validation: 0.3543766872332361]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24100834603234994		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.24100834603234994 | validation: 0.33012130185654337]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352936449920964		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.2352936449920964 | validation: 0.3136693027391058]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22599998129430937		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.22599998129430937 | validation: 0.333505608854902]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441084612721733		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.2441084612721733 | validation: 0.33838710063889865]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23606814286654798		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.23606814286654798 | validation: 0.3368257020441726]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23329251352319255		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.23329251352319255 | validation: 0.3172867335608713]
	TIME [epoch: 11.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21950944706006817		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.21950944706006817 | validation: 0.3173143019988925]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21673051930894816		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.21673051930894816 | validation: 0.3212262598761743]
	TIME [epoch: 11.5 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22494654853823953		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.22494654853823953 | validation: 0.32328879108471376]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22204928947131544		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.22204928947131544 | validation: 0.3256531563803511]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21961122898997262		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.21961122898997262 | validation: 0.3043598822856328]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22155827881200127		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.22155827881200127 | validation: 0.31270524676256345]
	TIME [epoch: 11.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226935300706088		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.2226935300706088 | validation: 0.3387168336521419]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2178866340161429		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.2178866340161429 | validation: 0.32692271129603556]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22018009298886668		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.22018009298886668 | validation: 0.3203915266036988]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22513442296134709		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.22513442296134709 | validation: 0.30556246756270333]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22369675928063698		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.22369675928063698 | validation: 0.31228395281154553]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22747744235699693		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.22747744235699693 | validation: 0.3185452329099415]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22874691286938195		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.22874691286938195 | validation: 0.3368232159563281]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26873907055555296		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.26873907055555296 | validation: 0.33708328895786055]
	TIME [epoch: 11.5 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2369017415799678		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.2369017415799678 | validation: 0.3146968187275221]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21948254646308774		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.21948254646308774 | validation: 0.30970989050872577]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21855389009535586		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.21855389009535586 | validation: 0.3219723999222156]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21816748032262107		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.21816748032262107 | validation: 0.3023636560549327]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22090974343338293		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.22090974343338293 | validation: 0.31840392052917976]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22328088743329022		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.22328088743329022 | validation: 0.3153562814211638]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22429521016824047		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.22429521016824047 | validation: 0.33282546034329263]
	TIME [epoch: 11.5 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2263178540500553		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.2263178540500553 | validation: 0.3162350888312782]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21857039533835845		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.21857039533835845 | validation: 0.3150484765226583]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23998539885331377		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.23998539885331377 | validation: 0.32278629582706336]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255247641489784		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.2255247641489784 | validation: 0.3101344917797053]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164382655507208		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.2164382655507208 | validation: 0.306888099437757]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21576110079433658		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.21576110079433658 | validation: 0.3003561934432473]
	TIME [epoch: 11.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21755680297286556		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.21755680297286556 | validation: 0.31199526333407507]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22143116142245825		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.22143116142245825 | validation: 0.31109785712589355]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218049212848256		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.218049212848256 | validation: 0.311811517636118]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22039479154866454		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.22039479154866454 | validation: 0.3149735396805254]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172011587660203		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.2172011587660203 | validation: 0.31315872458932725]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22683340480926206		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.22683340480926206 | validation: 0.31817439225089095]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22308851726058634		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.22308851726058634 | validation: 0.3096497789357013]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22449812344103395		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.22449812344103395 | validation: 0.29914097226505343]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1406.pth
	Model improved!!!
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21587219166907579		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.21587219166907579 | validation: 0.32835659508270026]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22201751664955358		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.22201751664955358 | validation: 0.3001674924774915]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2239947754422586		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.2239947754422586 | validation: 0.31773730094547]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22415288541040618		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.22415288541040618 | validation: 0.33376852468507606]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22178883482271217		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.22178883482271217 | validation: 0.31698435168999495]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23140010461317437		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.23140010461317437 | validation: 0.30683653937927086]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204945353060748		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.2204945353060748 | validation: 0.31793081067169876]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22263304259953676		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.22263304259953676 | validation: 0.3011191735756139]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215852970516316		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.215852970516316 | validation: 0.30981978725541653]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21714557946209836		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.21714557946209836 | validation: 0.3266629791774652]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22115720017832907		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.22115720017832907 | validation: 0.31062053007026147]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22497885913717355		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.22497885913717355 | validation: 0.31732002062906256]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23101816879923465		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.23101816879923465 | validation: 0.33553269368310595]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22004173346930977		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.22004173346930977 | validation: 0.3045023458631724]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21823185898677894		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.21823185898677894 | validation: 0.31864051995095377]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2235557846184552		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.2235557846184552 | validation: 0.32292657193178614]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22153685537621126		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.22153685537621126 | validation: 0.3020409758297687]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22500678067816038		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.22500678067816038 | validation: 0.31373681296203]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22631447491828574		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.22631447491828574 | validation: 0.3172027557627525]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2350173522721536		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.2350173522721536 | validation: 0.30584915311324135]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22112819752482224		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.22112819752482224 | validation: 0.3022395840979331]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22383181937557356		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.22383181937557356 | validation: 0.3216324650310742]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23051641248304594		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.23051641248304594 | validation: 0.30451137264915196]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21669769090048946		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.21669769090048946 | validation: 0.3114520048237463]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21512434085122178		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.21512434085122178 | validation: 0.3052137503391664]
	TIME [epoch: 11.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21868185315630834		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.21868185315630834 | validation: 0.3108069249848083]
	TIME [epoch: 11.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214212097412289		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.2214212097412289 | validation: 0.30997384099163133]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21629723007124893		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.21629723007124893 | validation: 0.3186766569430569]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2181726139427211		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.2181726139427211 | validation: 0.32114607964546105]
	TIME [epoch: 11.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22763127053522308		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.22763127053522308 | validation: 0.3222548472088467]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2300758389775922		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.2300758389775922 | validation: 0.31689609746998176]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21179960043540685		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.21179960043540685 | validation: 0.31489234048556586]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21175928388835705		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.21175928388835705 | validation: 0.30980549424124426]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21459805933989395		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.21459805933989395 | validation: 0.3076238983487438]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22300851796758114		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.22300851796758114 | validation: 0.3049604973256024]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22197422211579748		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.22197422211579748 | validation: 0.3173959083934868]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23165787460180345		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.23165787460180345 | validation: 0.31819789306806207]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22434349429831024		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.22434349429831024 | validation: 0.2994832762922683]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082839193396528		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.2082839193396528 | validation: 0.3072835753462316]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22134458326792056		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.22134458326792056 | validation: 0.3121632375015253]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23095069010600083		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.23095069010600083 | validation: 0.32283559516056115]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23732680840803527		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.23732680840803527 | validation: 0.31710395728410684]
	TIME [epoch: 11.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23077703430174484		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.23077703430174484 | validation: 0.32317022820368557]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22366993567599552		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.22366993567599552 | validation: 0.31842657899315485]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21732727062210608		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.21732727062210608 | validation: 0.30312975275383364]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22333489045999322		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.22333489045999322 | validation: 0.3042398936668165]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176134109888516		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.2176134109888516 | validation: 0.30223527249383125]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21410289412765893		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.21410289412765893 | validation: 0.31106671464172186]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21922246138766924		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.21922246138766924 | validation: 0.32289896745369545]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23182298824024838		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.23182298824024838 | validation: 0.3296849241177761]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22094113998111348		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.22094113998111348 | validation: 0.31389900950232275]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21818697737705042		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.21818697737705042 | validation: 0.3092772767210679]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21688919573120866		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.21688919573120866 | validation: 0.30349935806598877]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21767464261725966		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.21767464261725966 | validation: 0.29885342953893007]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1460.pth
	Model improved!!!
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21995418962617952		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.21995418962617952 | validation: 0.31333020838548337]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21928066618602876		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.21928066618602876 | validation: 0.311505640553046]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2194519371321915		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.2194519371321915 | validation: 0.31318322209324084]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21394699975729195		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.21394699975729195 | validation: 0.31981916819841744]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144263607066381		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.2144263607066381 | validation: 0.309200056902631]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21283251042148107		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.21283251042148107 | validation: 0.3283419297627338]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332873972988802		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.2332873972988802 | validation: 0.34998422426716375]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503539024988143		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.2503539024988143 | validation: 0.3394391946413199]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2481772759067673		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.2481772759067673 | validation: 0.3215678033184227]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224629514023976		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.224629514023976 | validation: 0.3032231214422327]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21028462568491516		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.21028462568491516 | validation: 0.30001613839027125]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21509545456344248		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.21509545456344248 | validation: 0.29405472750241496]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1472.pth
	Model improved!!!
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222702521526158		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.2222702521526158 | validation: 0.31271960790085807]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142687553997443		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.2142687553997443 | validation: 0.3116297363494163]
	TIME [epoch: 11.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21486139791053382		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.21486139791053382 | validation: 0.3047842830744967]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21832742364660515		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.21832742364660515 | validation: 0.3255072415150144]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22686949016564184		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.22686949016564184 | validation: 0.3216636045983849]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23769806422158274		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.23769806422158274 | validation: 0.3220869804604391]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23883102121415462		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.23883102121415462 | validation: 0.322182656964478]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556407830223002		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.2556407830223002 | validation: 0.3292598610172119]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23698222976017128		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.23698222976017128 | validation: 0.31919001063137087]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22536901240805896		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.22536901240805896 | validation: 0.3358423432354658]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23061653637638388		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.23061653637638388 | validation: 0.310242850254237]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21542649907579045		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.21542649907579045 | validation: 0.31834833893622444]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22116162255407873		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.22116162255407873 | validation: 0.309131379835589]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21413106983628846		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.21413106983628846 | validation: 0.3011088000294783]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22926968282361557		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.22926968282361557 | validation: 0.31451524611381426]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22105294760723845		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.22105294760723845 | validation: 0.32344237985394925]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22237782391659067		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.22237782391659067 | validation: 0.30750186039916266]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146605051828375		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.2146605051828375 | validation: 0.3045805724830673]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21489368673349363		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.21489368673349363 | validation: 0.30893549104064205]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21543283708478464		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.21543283708478464 | validation: 0.30526983610388597]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21873220128150744		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.21873220128150744 | validation: 0.30763268035672475]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22209056400929247		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.22209056400929247 | validation: 0.3168278374289532]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2187503339476991		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.2187503339476991 | validation: 0.3074614750193327]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21949737358715907		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.21949737358715907 | validation: 0.32786694684965495]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163759993181089		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.2163759993181089 | validation: 0.31746954028579005]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22084528211078241		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.22084528211078241 | validation: 0.3138354940711478]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21507443266321558		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.21507443266321558 | validation: 0.30509627355964003]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182464384786221		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.2182464384786221 | validation: 0.31244345797257483]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183964382546326		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.2183964382546326 | validation: 0.3127392484414579]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21659553326367162		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.21659553326367162 | validation: 0.2973757433465201]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21828510858931724		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.21828510858931724 | validation: 0.3095837590360567]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125352592655651		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.2125352592655651 | validation: 0.32236587105063563]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21937412642834836		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.21937412642834836 | validation: 0.32331320900640875]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21710607412154076		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.21710607412154076 | validation: 0.30939794191551095]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21489408566003018		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.21489408566003018 | validation: 0.30344797366223425]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22501770026324508		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.22501770026324508 | validation: 0.31968644189504347]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22524485750603654		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.22524485750603654 | validation: 0.30227594444943784]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21379357116200404		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.21379357116200404 | validation: 0.31244110506468253]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21305315321643536		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.21305315321643536 | validation: 0.31323027507791806]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151497972974024		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.2151497972974024 | validation: 0.2991412191677333]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22064254597258426		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.22064254597258426 | validation: 0.30553794602498835]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234635910490325		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.2234635910490325 | validation: 0.2891437274264861]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1514.pth
	Model improved!!!
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131948321013982		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.2131948321013982 | validation: 0.29884507515839565]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21971984953149418		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.21971984953149418 | validation: 0.30724579809836]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22254711211033057		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.22254711211033057 | validation: 0.31672591223300073]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22322635211258743		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.22322635211258743 | validation: 0.29636057151128814]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22515104630525629		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.22515104630525629 | validation: 0.29341513809645414]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21931368835327752		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.21931368835327752 | validation: 0.30380881940690385]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21460122863989445		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.21460122863989445 | validation: 0.30289577606172097]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22276575589340422		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.22276575589340422 | validation: 0.34051416323326694]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23103426343817585		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.23103426343817585 | validation: 0.30893599634753893]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21549588809313727		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.21549588809313727 | validation: 0.3072898974456461]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22265620074577744		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.22265620074577744 | validation: 0.30275719123233363]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21558897423711482		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.21558897423711482 | validation: 0.30714239009282557]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20976017653293536		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.20976017653293536 | validation: 0.30692402607003444]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21371393447650627		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.21371393447650627 | validation: 0.3073617136851089]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21510489542627315		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.21510489542627315 | validation: 0.3030812921746511]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077501119239753		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.2077501119239753 | validation: 0.3024732739645877]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171501550648368		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.2171501550648368 | validation: 0.29884762600239]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21105633867385895		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.21105633867385895 | validation: 0.3067328733546885]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21815967274713083		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.21815967274713083 | validation: 0.31171563114787665]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22353164985895776		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.22353164985895776 | validation: 0.3142151750100543]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211994368385875		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.211994368385875 | validation: 0.2929586670300408]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114489424189418		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.2114489424189418 | validation: 0.30598873078325356]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21276302811592487		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.21276302811592487 | validation: 0.3041133801370933]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21381528183649348		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.21381528183649348 | validation: 0.3074060738185006]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2233634130438077		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.2233634130438077 | validation: 0.2997531302751192]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22404203664988387		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.22404203664988387 | validation: 0.30748490956136765]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2263460805976602		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.2263460805976602 | validation: 0.3176565888965748]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21397990078119286		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.21397990078119286 | validation: 0.2964523820278302]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21088133025891595		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.21088133025891595 | validation: 0.31631855562601824]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21980605798778216		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.21980605798778216 | validation: 0.3048475435462126]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21320839954942683		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.21320839954942683 | validation: 0.3043219688253101]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113278281282596		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.2113278281282596 | validation: 0.30588136446520303]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22036861061321794		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.22036861061321794 | validation: 0.31689537802351725]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21613186793702024		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.21613186793702024 | validation: 0.30221954178703275]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196058393849925		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.2196058393849925 | validation: 0.30472395290297355]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21564463919620164		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.21564463919620164 | validation: 0.3141642078741919]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21881247422458763		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.21881247422458763 | validation: 0.3079977105000442]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21421256117244047		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.21421256117244047 | validation: 0.2999754017497693]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21795251716620664		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.21795251716620664 | validation: 0.2900085739319189]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112326957438272		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.2112326957438272 | validation: 0.2937498488440605]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113235763634602		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.2113235763634602 | validation: 0.30482404844954225]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771332112020274		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.20771332112020274 | validation: 0.30151733954662446]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21766470837910493		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.21766470837910493 | validation: 0.29409151135604517]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21222883628920652		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.21222883628920652 | validation: 0.315821734097378]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21847159628627905		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.21847159628627905 | validation: 0.3122815206423934]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196916853362161		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.2196916853362161 | validation: 0.3088366241156011]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22545818052933414		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.22545818052933414 | validation: 0.3198253299819713]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23006212464671513		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.23006212464671513 | validation: 0.30517176050232214]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144764201752978		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.2144764201752978 | validation: 0.3175621843117872]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216773461647932		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.216773461647932 | validation: 0.3218319537345101]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22140683545655782		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.22140683545655782 | validation: 0.3110244825640808]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21674171859528407		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.21674171859528407 | validation: 0.3052044740487915]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21192513448607475		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.21192513448607475 | validation: 0.31186053019026644]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21317401484392984		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.21317401484392984 | validation: 0.30096462198468765]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21355232256731035		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.21355232256731035 | validation: 0.3050949437657485]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22021135739017186		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.22021135739017186 | validation: 0.32122472398982843]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22131744468023984		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.22131744468023984 | validation: 0.30922874754406887]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21632328900255263		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.21632328900255263 | validation: 0.30632222837581685]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21611941924199815		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.21611941924199815 | validation: 0.3094319502819739]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2260706079724069		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.2260706079724069 | validation: 0.32628088958108775]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2394083752866007		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.2394083752866007 | validation: 0.3197072695552765]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204812622442161		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.2204812622442161 | validation: 0.31181165485429446]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21361145976874898		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.21361145976874898 | validation: 0.3158623212005322]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21694046848354887		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.21694046848354887 | validation: 0.3116280363421653]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760262406940978		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.21760262406940978 | validation: 0.2962686378359259]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21500181050535652		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.21500181050535652 | validation: 0.29916385815462987]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21088232639765345		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.21088232639765345 | validation: 0.285269927705214]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1581.pth
	Model improved!!!
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20761346077087467		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.20761346077087467 | validation: 0.2949975018195654]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21082458228398923		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.21082458228398923 | validation: 0.3037634199605492]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21172298436716216		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.21172298436716216 | validation: 0.29410895338817833]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21645130120959663		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.21645130120959663 | validation: 0.2980585620740289]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22061883756751646		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.22061883756751646 | validation: 0.30301548803401235]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21464253502302266		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.21464253502302266 | validation: 0.2949047275772418]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219197217385479		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.219197217385479 | validation: 0.299464868536636]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22041109859608435		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.22041109859608435 | validation: 0.30515132040989035]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21676792824439062		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.21676792824439062 | validation: 0.30479077400531235]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112525534434668		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.2112525534434668 | validation: 0.2853223614606594]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21249364328735942		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.21249364328735942 | validation: 0.2965605510035797]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20760793725909668		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.20760793725909668 | validation: 0.3012051187810388]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21416056661706429		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.21416056661706429 | validation: 0.30676378451970004]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21482829554723198		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.21482829554723198 | validation: 0.30855209129965283]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21024866951975335		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.21024866951975335 | validation: 0.2939591105942158]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20936013079207255		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.20936013079207255 | validation: 0.30360433992032065]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20859467639969873		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.20859467639969873 | validation: 0.30290270955095877]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21152813123474726		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.21152813123474726 | validation: 0.30856822422089525]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22052626526031516		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.22052626526031516 | validation: 0.31598971732345377]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21366146885982337		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.21366146885982337 | validation: 0.31251458790697745]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20801645889742898		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.20801645889742898 | validation: 0.3074889559803338]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21276541344463065		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.21276541344463065 | validation: 0.29576861319068476]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21967474041451399		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.21967474041451399 | validation: 0.3197934316818115]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22731034068387224		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.22731034068387224 | validation: 0.30433660162312326]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227374987638964		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.2227374987638964 | validation: 0.30451809862630935]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138050481156516		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.2138050481156516 | validation: 0.30356505524530575]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21435311170485943		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.21435311170485943 | validation: 0.29842535528725195]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21512807656746483		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.21512807656746483 | validation: 0.29186346051937434]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21403286709541047		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.21403286709541047 | validation: 0.3072864156235138]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20972750182323296		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.20972750182323296 | validation: 0.3040415392079231]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2129364962413053		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.2129364962413053 | validation: 0.3037059310208353]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148981748564932		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.2148981748564932 | validation: 0.3283090330108746]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22583214394877393		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.22583214394877393 | validation: 0.3207688044001208]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22253263519379635		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.22253263519379635 | validation: 0.31101512071818366]
	TIME [epoch: 11.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20868226360474063		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.20868226360474063 | validation: 0.3075562285024889]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21225874628650485		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.21225874628650485 | validation: 0.3039965880911104]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20516453191373246		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.20516453191373246 | validation: 0.29746867905373914]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20849869878759703		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.20849869878759703 | validation: 0.29823394423777166]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21332055436905192		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.21332055436905192 | validation: 0.3040466954897053]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21334250456073411		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.21334250456073411 | validation: 0.3030039463569294]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21640660023889619		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.21640660023889619 | validation: 0.2972380230660089]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20595764719555618		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.20595764719555618 | validation: 0.30823606420273747]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112919853828736		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.2112919853828736 | validation: 0.30245717547461676]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21644467503408224		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.21644467503408224 | validation: 0.30613579197350915]
	TIME [epoch: 11.5 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21663303856336402		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.21663303856336402 | validation: 0.30771359403243276]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21695146660681072		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.21695146660681072 | validation: 0.3101752674799285]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20972904910852422		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.20972904910852422 | validation: 0.31170385735697786]
	TIME [epoch: 11.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123287895974555		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.2123287895974555 | validation: 0.310408096035463]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22263111469037025		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.22263111469037025 | validation: 0.3096494149457153]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133837825656854		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.2133837825656854 | validation: 0.29637689199619877]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21690045434872704		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.21690045434872704 | validation: 0.2986643041209471]
	TIME [epoch: 11.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21367849842053072		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.21367849842053072 | validation: 0.2983928321617368]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21319882327756057		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.21319882327756057 | validation: 0.2952359388564587]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2091319036611214		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.2091319036611214 | validation: 0.296288184897902]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21473347844804036		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.21473347844804036 | validation: 0.2986994378704036]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21811660042234665		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.21811660042234665 | validation: 0.2992905502811749]
	TIME [epoch: 11.5 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21643822370143284		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.21643822370143284 | validation: 0.29865587283107053]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21121309457176532		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.21121309457176532 | validation: 0.29450885024011686]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21133153276683114		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.21133153276683114 | validation: 0.3029370991004519]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21473959970199513		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.21473959970199513 | validation: 0.30386847792621996]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21354802147435092		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.21354802147435092 | validation: 0.304370010819509]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2124732296957205		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.2124732296957205 | validation: 0.3081595178846056]
	TIME [epoch: 11.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113434765220389		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.2113434765220389 | validation: 0.30943834747462157]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2208317976632944		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.2208317976632944 | validation: 0.3036591698885168]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145877864813352		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.2145877864813352 | validation: 0.3113632031112619]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21319847462857552		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.21319847462857552 | validation: 0.31596241040405426]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139700951750127		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.2139700951750127 | validation: 0.3137427651415237]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21409585585834018		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.21409585585834018 | validation: 0.31394275229658125]
	TIME [epoch: 11.5 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226829273613017		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.2226829273613017 | validation: 0.31950180789791277]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221374889566051		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.221374889566051 | validation: 0.3051441359307623]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21712129598891106		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.21712129598891106 | validation: 0.31003848562430647]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21180794047086093		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.21180794047086093 | validation: 0.2927486683602597]
	TIME [epoch: 11.5 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21400608566578372		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.21400608566578372 | validation: 0.31172057156172855]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22397509336349727		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.22397509336349727 | validation: 0.3217728274084252]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209343629819121		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.2209343629819121 | validation: 0.3159232994722962]
	TIME [epoch: 11.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21855282995343098		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.21855282995343098 | validation: 0.3097490469849284]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21314074928050408		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.21314074928050408 | validation: 0.29499577167366103]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2074935916399185		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.2074935916399185 | validation: 0.29426642026772704]
	TIME [epoch: 11.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20965159146245976		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.20965159146245976 | validation: 0.2985267279251025]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21158544274394114		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.21158544274394114 | validation: 0.2951651699045752]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21143019677051622		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.21143019677051622 | validation: 0.30987784221055]
	TIME [epoch: 11.5 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21487528075439394		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.21487528075439394 | validation: 0.29707043451119475]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21216165128344228		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.21216165128344228 | validation: 0.28854866278280206]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20911084977586564		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.20911084977586564 | validation: 0.30741064484874103]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21375602816408645		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.21375602816408645 | validation: 0.29287099900730235]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20917973696645953		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.20917973696645953 | validation: 0.2946928350574162]
	TIME [epoch: 11.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20792452388535146		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.20792452388535146 | validation: 0.30279478782781993]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21477550204474677		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.21477550204474677 | validation: 0.3048950943134484]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21439380972216798		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.21439380972216798 | validation: 0.29739102231241693]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21226264109271628		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.21226264109271628 | validation: 0.28916184081805557]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117669505839005		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.2117669505839005 | validation: 0.3087257166107875]
	TIME [epoch: 11.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21110183497465942		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.21110183497465942 | validation: 0.30367230138256984]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21835727237622807		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.21835727237622807 | validation: 0.2932495085360424]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21671565084596683		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.21671565084596683 | validation: 0.29911457381579254]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2166339673329828		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.2166339673329828 | validation: 0.3054827995643574]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195869690956746		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.2195869690956746 | validation: 0.3078474355658767]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22135350130408138		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.22135350130408138 | validation: 0.30429411488995434]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21125692258676926		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.21125692258676926 | validation: 0.299377536004653]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078014418283387		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.2078014418283387 | validation: 0.2996912394354188]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21542039123052972		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.21542039123052972 | validation: 0.3160989669955942]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21970217316353038		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.21970217316353038 | validation: 0.3061322057093915]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2269426897363587		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.2269426897363587 | validation: 0.31675164140000917]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22162489041231237		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.22162489041231237 | validation: 0.3058141920996517]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22198057956816045		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.22198057956816045 | validation: 0.3001313580200069]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22117451485616718		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.22117451485616718 | validation: 0.30075810924258034]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2062802483885049		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.2062802483885049 | validation: 0.30044152281291475]
	TIME [epoch: 11.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20952435016150314		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.20952435016150314 | validation: 0.3071054567999608]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20893802067024397		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.20893802067024397 | validation: 0.30076435893315334]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20713055074170916		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.20713055074170916 | validation: 0.2989748666635853]
	TIME [epoch: 11.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21421350438606893		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.21421350438606893 | validation: 0.29405486445064194]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098716491818128		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.2098716491818128 | validation: 0.3005881099218252]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21134482803705223		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.21134482803705223 | validation: 0.30268617122983016]
	TIME [epoch: 11.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20858589897144608		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.20858589897144608 | validation: 0.306714116714172]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2129002761799745		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.2129002761799745 | validation: 0.3029554396737627]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21533392122305153		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.21533392122305153 | validation: 0.3141794248056322]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22334336251647718		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.22334336251647718 | validation: 0.29828848826570725]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21858238936562457		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.21858238936562457 | validation: 0.3024461735349706]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173022498255194		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.2173022498255194 | validation: 0.3114614483671928]
	TIME [epoch: 11.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133659666109993		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.2133659666109993 | validation: 0.3128220493527293]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171186211132732		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.2171186211132732 | validation: 0.2986393473790184]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20814768978901405		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.20814768978901405 | validation: 0.2932055916962045]
	TIME [epoch: 11.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21112290037307782		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.21112290037307782 | validation: 0.30054284838959716]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20823055107574961		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.20823055107574961 | validation: 0.3135545906890493]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20987736478455873		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.20987736478455873 | validation: 0.3070886179535787]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21552341079298282		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.21552341079298282 | validation: 0.31352730542672136]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2149765216063783		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.2149765216063783 | validation: 0.3101864070635063]
	TIME [epoch: 11.5 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2213572473385675		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.2213572473385675 | validation: 0.3154524685779644]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205074021728775		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.2205074021728775 | validation: 0.3042319428550029]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2218059402287152		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.2218059402287152 | validation: 0.3128722819469909]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.217998261470992		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.217998261470992 | validation: 0.3161938146309291]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21667096122823273		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.21667096122823273 | validation: 0.3049179056059362]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21163472068676514		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.21163472068676514 | validation: 0.3122250659780504]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107510979721499		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.2107510979721499 | validation: 0.3039430112111633]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21384915012419395		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.21384915012419395 | validation: 0.2976479234827002]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21471481934044742		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.21471481934044742 | validation: 0.29640627276708]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2119674243331211		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.2119674243331211 | validation: 0.3123605453014279]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21765029962268495		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.21765029962268495 | validation: 0.3155857771352956]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22206216687535096		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.22206216687535096 | validation: 0.3000455060227767]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2192722799662234		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.2192722799662234 | validation: 0.3010567441561038]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219586900569483		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.219586900569483 | validation: 0.32057247828556756]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2238278342204302		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.2238278342204302 | validation: 0.3171356135265129]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21960729957512948		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.21960729957512948 | validation: 0.30961585516819573]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22507748033405955		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.22507748033405955 | validation: 0.32118028659602926]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22122195488905366		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.22122195488905366 | validation: 0.3070855419948794]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2162250842885357		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.2162250842885357 | validation: 0.3065012941495239]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21338849617713984		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.21338849617713984 | validation: 0.3130885927586079]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134342388376628		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.2134342388376628 | validation: 0.3059360364523833]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2121167337353848		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.2121167337353848 | validation: 0.3093705267996788]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2099949083740432		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.2099949083740432 | validation: 0.29704192255866463]
	TIME [epoch: 11.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21264091846481628		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.21264091846481628 | validation: 0.2933862058723623]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20964198092390168		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.20964198092390168 | validation: 0.2917624767143929]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21103344105199381		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.21103344105199381 | validation: 0.30088808858627913]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065226740738971		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.2065226740738971 | validation: 0.29303218606450065]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21042430993839378		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.21042430993839378 | validation: 0.2951439269103237]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596849578038945		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.20596849578038945 | validation: 0.29786924158589884]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21212929336044792		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.21212929336044792 | validation: 0.30260692494724745]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21415840097063793		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.21415840097063793 | validation: 0.2937044876601103]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20754400685748048		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.20754400685748048 | validation: 0.29616800812110816]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2115005957009621		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.2115005957009621 | validation: 0.29945438505537564]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20808685802115628		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.20808685802115628 | validation: 0.3005295244581094]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20966085356311492		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.20966085356311492 | validation: 0.2849589136709237]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1742.pth
	Model improved!!!
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20948964223772742		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.20948964223772742 | validation: 0.29157886869517]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20915502399571792		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.20915502399571792 | validation: 0.2948708178484142]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21403035695907036		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.21403035695907036 | validation: 0.3005096787842133]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21554404635156893		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.21554404635156893 | validation: 0.29984476820804584]
	TIME [epoch: 11.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078122729143737		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.2078122729143737 | validation: 0.29245860957284436]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20600832260766389		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.20600832260766389 | validation: 0.3006790830558893]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093380006081508		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.2093380006081508 | validation: 0.2905481788973324]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117365274227664		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.2117365274227664 | validation: 0.29374680525932173]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20766223922080912		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.20766223922080912 | validation: 0.28998977164071926]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20513560045953613		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.20513560045953613 | validation: 0.2934136794477306]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20980295304688384		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.20980295304688384 | validation: 0.2890674869469985]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21570980644696722		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.21570980644696722 | validation: 0.2902283332832408]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21103996243906314		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.21103996243906314 | validation: 0.2871826497267842]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138343515438049		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.2138343515438049 | validation: 0.29470921263355676]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21203450609694902		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.21203450609694902 | validation: 0.2908650110552317]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2110412976894559		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.2110412976894559 | validation: 0.2870022468800432]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21044111938462234		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.21044111938462234 | validation: 0.29825201098486753]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593766286076923		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.20593766286076923 | validation: 0.3000422204569477]
	TIME [epoch: 11.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068158759837467		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.2068158759837467 | validation: 0.2994138007111586]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068710730991027		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.2068710730991027 | validation: 0.2934642390343153]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20629448230989128		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.20629448230989128 | validation: 0.2974468466647967]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21049849543957494		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.21049849543957494 | validation: 0.3042707870738159]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096798614962267		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.2096798614962267 | validation: 0.29403486353274644]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083054822729583		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.2083054822729583 | validation: 0.2923272653527479]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20854935460185436		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.20854935460185436 | validation: 0.3009235340244445]
	TIME [epoch: 11.5 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20953467065610562		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.20953467065610562 | validation: 0.29497539285130353]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843591979832066		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.20843591979832066 | validation: 0.2959876381304678]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20529551886423408		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.20529551886423408 | validation: 0.2820355447067144]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1770.pth
	Model improved!!!
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20746627860682615		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.20746627860682615 | validation: 0.28341111825884807]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20789273694436428		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.20789273694436428 | validation: 0.2911198765753016]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2102882974544922		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.2102882974544922 | validation: 0.3020783761939371]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089766251665847		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.2089766251665847 | validation: 0.29374895953377966]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20876372402116453		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.20876372402116453 | validation: 0.30934488201144317]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21819175227399423		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.21819175227399423 | validation: 0.2994340546748709]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21453053884743387		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.21453053884743387 | validation: 0.3059197819660717]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21597487481756844		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.21597487481756844 | validation: 0.30853419344608507]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20829804589640905		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.20829804589640905 | validation: 0.29938778277990985]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20916263014948894		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.20916263014948894 | validation: 0.3011215146302328]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20846740367456837		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.20846740367456837 | validation: 0.30038401243744334]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20885283378668051		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.20885283378668051 | validation: 0.30086156146818044]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20807420635633647		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.20807420635633647 | validation: 0.29343960931609747]
	TIME [epoch: 11.5 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20824699990050824		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.20824699990050824 | validation: 0.3004529344183081]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20415773288654643		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.20415773288654643 | validation: 0.2963579733553657]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20832035605046467		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.20832035605046467 | validation: 0.2955793891279952]
	TIME [epoch: 11.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21033700236880865		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.21033700236880865 | validation: 0.2881877736812078]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21332963833286278		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.21332963833286278 | validation: 0.2987187490797979]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2056835530961519		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.2056835530961519 | validation: 0.29911860042334537]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20756487153185743		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.20756487153185743 | validation: 0.29330989215948344]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20889525954928254		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.20889525954928254 | validation: 0.30432077326846424]
	TIME [epoch: 11.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593915990187198		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.20593915990187198 | validation: 0.2965475274935654]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082589153493028		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.2082589153493028 | validation: 0.289752359846974]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20921200146867197		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.20921200146867197 | validation: 0.29760119188628703]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21325069637120728		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.21325069637120728 | validation: 0.29909583477369206]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20921665678682563		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.20921665678682563 | validation: 0.29699425700210663]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059684298093647		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.2059684298093647 | validation: 0.29760358147325666]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21145043716498088		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.21145043716498088 | validation: 0.3036803028937244]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20955792073510002		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.20955792073510002 | validation: 0.2926026535262907]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21042182485750005		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.21042182485750005 | validation: 0.29920600898013033]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20620728208957842		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.20620728208957842 | validation: 0.29529836407397464]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20831493949053492		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.20831493949053492 | validation: 0.29144781643201345]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21159541488569436		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.21159541488569436 | validation: 0.28742032432602005]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20800762735109082		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.20800762735109082 | validation: 0.2905171570888418]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20986768004695258		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.20986768004695258 | validation: 0.29510028054277115]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20685927816923927		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.20685927816923927 | validation: 0.2968110146016288]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108912503204493		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.2108912503204493 | validation: 0.2953581838344214]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20814662602946948		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.20814662602946948 | validation: 0.29652599150792086]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20114410530561658		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.20114410530561658 | validation: 0.2917794242227619]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21064208175875504		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.21064208175875504 | validation: 0.2991693126749707]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20923643568084277		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.20923643568084277 | validation: 0.30215038310922987]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2071984077571228		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.2071984077571228 | validation: 0.2877126892100982]
	TIME [epoch: 11.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20573746954178215		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.20573746954178215 | validation: 0.2931802460652207]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20995526065168987		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.20995526065168987 | validation: 0.2904552522428048]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21085011093197728		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.21085011093197728 | validation: 0.2903132840005145]
	TIME [epoch: 11.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21073688074851726		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.21073688074851726 | validation: 0.28804690020272256]
	TIME [epoch: 11.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2097656055197344		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.2097656055197344 | validation: 0.2988098847993052]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086755243270054		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.2086755243270054 | validation: 0.29841991563114567]
	TIME [epoch: 11.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20966519831617855		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.20966519831617855 | validation: 0.27796842232167346]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r1_20240309_135637/states/model_tr_study3_1819.pth
	Model improved!!!
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098724350665409		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.2098724350665409 | validation: 0.2864740541574037]
	TIME [epoch: 11.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058394653682331		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.2058394653682331 | validation: 0.2905108448024856]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061194789760334		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.2061194789760334 | validation: 0.2960664908510325]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030239999319262		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.2030239999319262 | validation: 0.2876866807851799]
	TIME [epoch: 11.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20701791287259275		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.20701791287259275 | validation: 0.2871254086028628]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20572527923258455		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.20572527923258455 | validation: 0.29465899892286795]
	TIME [epoch: 11.5 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20749425432068408		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.20749425432068408 | validation: 0.2996957953843022]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20934920974289034		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.20934920974289034 | validation: 0.29500372781605605]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073671202960678		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.2073671202960678 | validation: 0.28752889541872473]
	TIME [epoch: 11.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072694035410835		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.2072694035410835 | validation: 0.2951357453478037]
	TIME [epoch: 11.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20429856794644585		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.20429856794644585 | validation: 0.3057681851813372]
	TIME [epoch: 11.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20963586151494695		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.20963586151494695 | validation: 0.3042548988063234]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20543178966302797		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.20543178966302797 | validation: 0.29969404019346507]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20761949264585855		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.20761949264585855 | validation: 0.3085224722724669]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20559272563475262		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.20559272563475262 | validation: 0.29957692584329154]
	TIME [epoch: 11.5 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211474564343826		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.211474564343826 | validation: 0.29789577637202214]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20197128886215385		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.20197128886215385 | validation: 0.3021707165470427]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20309468220170296		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.20309468220170296 | validation: 0.29359109839132447]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20643415242588437		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.20643415242588437 | validation: 0.3048667541483339]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886782992736483		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.20886782992736483 | validation: 0.29794936292050933]
	TIME [epoch: 11.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20804562247994274		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.20804562247994274 | validation: 0.2938912785999204]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20764311581235012		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.20764311581235012 | validation: 0.3002772816088234]
	TIME [epoch: 11.5 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20493831330049667		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.20493831330049667 | validation: 0.2919896516002366]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21353711874925613		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.21353711874925613 | validation: 0.2918803718065051]
	TIME [epoch: 11.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20654972836673352		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.20654972836673352 | validation: 0.3001439222455419]
	TIME [epoch: 11.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20385339509829298		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.20385339509829298 | validation: 0.3079257901695588]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20632847105418653		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.20632847105418653 | validation: 0.3008806830545455]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2109338670341218		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.2109338670341218 | validation: 0.3020190131961057]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21108104548558326		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.21108104548558326 | validation: 0.304544036871445]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20882056942650568		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.20882056942650568 | validation: 0.30700283661615196]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20751849306381778		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.20751849306381778 | validation: 0.2992326650367155]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2118144646360669		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.2118144646360669 | validation: 0.29512193871708403]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20900568332177058		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.20900568332177058 | validation: 0.2972026716546911]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20832770668924952		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.20832770668924952 | validation: 0.30403781273122776]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20762554309716347		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.20762554309716347 | validation: 0.2864841539606359]
	TIME [epoch: 11.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20836571228334622		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.20836571228334622 | validation: 0.30363727661501755]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21090232441178647		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.21090232441178647 | validation: 0.31373862051483037]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2081314337609422		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.2081314337609422 | validation: 0.3010810370636315]
	TIME [epoch: 11.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20678728107018018		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.20678728107018018 | validation: 0.2989474228419336]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20877337974551413		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.20877337974551413 | validation: 0.2933894536488404]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20583338866294837		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.20583338866294837 | validation: 0.28844420300069545]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20470161324638209		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.20470161324638209 | validation: 0.2949867450660079]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065255981466346		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.2065255981466346 | validation: 0.28976764603542915]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114851005501556		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.2114851005501556 | validation: 0.30961514267356477]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068121759673297		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.2068121759673297 | validation: 0.3015178324173533]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21152531515340145		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.21152531515340145 | validation: 0.28604725760822786]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21216536097206112		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.21216536097206112 | validation: 0.2966292857996484]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21629682619809748		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.21629682619809748 | validation: 0.29468864544635043]
	TIME [epoch: 11.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20678722706975375		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.20678722706975375 | validation: 0.29934904473554663]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090049887674847		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.2090049887674847 | validation: 0.2898194562393192]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20811634038160076		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.20811634038160076 | validation: 0.2859389160955058]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075859102552178		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.2075859102552178 | validation: 0.3000780429460134]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.203018979568056		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.203018979568056 | validation: 0.3026082798325323]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089930068814569		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.2089930068814569 | validation: 0.296808347110919]
	TIME [epoch: 11.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2158651127336629		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.2158651127336629 | validation: 0.2927900995858162]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20961900770685843		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.20961900770685843 | validation: 0.28679484528599253]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086343840003406		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.2086343840003406 | validation: 0.29897958526573953]
	TIME [epoch: 11.5 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20762899103313898		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.20762899103313898 | validation: 0.2888659301151993]
	TIME [epoch: 11.5 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21041983376879464		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.21041983376879464 | validation: 0.29745917147273143]
	TIME [epoch: 11.5 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596166569958893		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.20596166569958893 | validation: 0.29029390453992726]
	TIME [epoch: 11.5 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20618270290570176		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.20618270290570176 | validation: 0.29310235822947706]
	TIME [epoch: 11.5 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596950317410812		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.20596950317410812 | validation: 0.28342973984515224]
	TIME [epoch: 11.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20598223941744734		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.20598223941744734 | validation: 0.29890611490161634]
	TIME [epoch: 11.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21057458266010282		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.21057458266010282 | validation: 0.2895431189304691]
	TIME [epoch: 11.5 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20579265947154726		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.20579265947154726 | validation: 0.29166166053910575]
	TIME [epoch: 11.5 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20501381900507426		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.20501381900507426 | validation: 0.29041223144239303]
	TIME [epoch: 11.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069226261680832		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.2069226261680832 | validation: 0.3086969040736152]
	TIME [epoch: 11.5 sec]
EPOCH 1887/2000:
	Training over batches...
