Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r0', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3047393677

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.568501891262779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.568501891262779 | validation: 9.776887008879024]
	TIME [epoch: 99.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.338280240845748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.338280240845748 | validation: 8.961731527607013]
	TIME [epoch: 11.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.813852964594778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.813852964594778 | validation: 8.805832195034409]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.461501922087677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.461501922087677 | validation: 8.593769025411866]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.352035909830173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.352035909830173 | validation: 9.998122713326216]
	TIME [epoch: 11.6 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.8912513876975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.8912513876975 | validation: 8.396115363803046]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.038755175146159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.038755175146159 | validation: 7.956935570256095]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.625728152254302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.625728152254302 | validation: 7.190959274434524]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.133624756618809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.133624756618809 | validation: 6.746501143058484]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.482457505744157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.482457505744157 | validation: 6.290219002859496]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.473445822177716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.473445822177716 | validation: 6.0188896423058065]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.003501580272919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.003501580272919 | validation: 6.03627647106412]
	TIME [epoch: 11.5 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.871800136177638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.871800136177638 | validation: 5.902360722537658]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.783539509498131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.783539509498131 | validation: 5.897463073300921]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.820784209336494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.820784209336494 | validation: 5.891047738736082]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.68472970225085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.68472970225085 | validation: 5.749003949758043]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.586490407967114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.586490407967114 | validation: 5.667292977080592]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.629640531954243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.629640531954243 | validation: 5.787547344674724]
	TIME [epoch: 11.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.648231711651631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.648231711651631 | validation: 5.5792337351976515]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.602736965951035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.602736965951035 | validation: 5.640393530440504]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.541371229049166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.541371229049166 | validation: 5.659072626641122]
	TIME [epoch: 11.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638359270189223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.638359270189223 | validation: 5.630308268833018]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.499404365243486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.499404365243486 | validation: 5.584498880922902]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4631273190370315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4631273190370315 | validation: 5.582560447960243]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.753279933944309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.753279933944309 | validation: 5.6480668523323425]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.475089928759877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.475089928759877 | validation: 5.469089064362227]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.471517273634075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.471517273634075 | validation: 5.458394084379834]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.486806815778122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.486806815778122 | validation: 5.474398590365228]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.42658083575557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.42658083575557 | validation: 5.533850109286715]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.529025347772131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529025347772131 | validation: 5.883790319970833]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.461275306688687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.461275306688687 | validation: 5.318428623663452]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.384492660772729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.384492660772729 | validation: 5.5400137596466585]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.419271689501018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.419271689501018 | validation: 5.378310233712073]
	TIME [epoch: 11.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.30828932853399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.30828932853399 | validation: 5.464821273869041]
	TIME [epoch: 11.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.279444425290525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.279444425290525 | validation: 5.478480099452455]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.32927777498268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.32927777498268 | validation: 5.271224821195212]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.20521511137448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.20521511137448 | validation: 5.235011244106829]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.25008123537819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.25008123537819 | validation: 5.465297084000361]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.266764290925673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.266764290925673 | validation: 5.345147711444208]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3677881335048365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3677881335048365 | validation: 5.308211613519553]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.261738707783946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.261738707783946 | validation: 5.161046678703932]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9603130532477975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9603130532477975 | validation: 5.081694349740351]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.055925966674384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.055925966674384 | validation: 4.994601859032391]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.883192936649198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.883192936649198 | validation: 4.820394505392279]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.297739890413675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.297739890413675 | validation: 4.582402847752458]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.506184422169327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.506184422169327 | validation: 7.47656838313901]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.517667668325729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.517667668325729 | validation: 4.6935039497656765]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6803858203076025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6803858203076025 | validation: 4.518951412284538]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.614471664851437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.614471664851437 | validation: 4.405049519209629]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.291398189329962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.291398189329962 | validation: 4.480614453506241]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076841781194771		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 4.076841781194771 | validation: 4.447135554810642]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.401220814990302		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.401220814990302 | validation: 4.222569762589863]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.065705212068369		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.065705212068369 | validation: 3.8421853087033893]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5814387033064663		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.5814387033064663 | validation: 3.799804040274442]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5663065802564318		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.5663065802564318 | validation: 5.381887255549891]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.851373576992366		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.851373576992366 | validation: 7.1242029768563935]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.818239366408211		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.818239366408211 | validation: 5.117410494904465]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.319233762520219		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.319233762520219 | validation: 4.912072456473184]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.039219764315627		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.039219764315627 | validation: 4.690030680673573]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1578608769726175		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.1578608769726175 | validation: 5.630600800347181]
	TIME [epoch: 11.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.201923909364656		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.201923909364656 | validation: 4.6222974076619066]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.758837536312847		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.758837536312847 | validation: 4.541812323141325]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.909820227073446		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.909820227073446 | validation: 4.796523348271499]
	TIME [epoch: 11.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8158388044950495		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.8158388044950495 | validation: 4.44230280186446]
	TIME [epoch: 11.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.600487607853507		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.600487607853507 | validation: 4.257543914196511]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.711885092213182		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.711885092213182 | validation: 3.9074993560216114]
	TIME [epoch: 11.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.771188320176285		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.771188320176285 | validation: 3.232996684488094]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.945175261178891		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.945175261178891 | validation: 2.6583815106793587]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5548910168832424		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.5548910168832424 | validation: 2.3682371481780695]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.531745385647438		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.531745385647438 | validation: 2.5944552747076965]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48506576317849		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.48506576317849 | validation: 2.350926327011754]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780969481819974		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.780969481819974 | validation: 2.589157515997951]
	TIME [epoch: 11.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1618225468660808		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.1618225468660808 | validation: 3.2742589227339387]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3631529296535962		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.3631529296535962 | validation: 1.9877224423648836]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9132557025319494		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.9132557025319494 | validation: 1.862276374036469]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0849219279086624		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.0849219279086624 | validation: 2.519560181625637]
	TIME [epoch: 11.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0351029996450545		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.0351029996450545 | validation: 1.933913265505579]
	TIME [epoch: 11.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8619171370899057		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.8619171370899057 | validation: 1.6343808869838454]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9309355861740887		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9309355861740887 | validation: 2.009300622610384]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8699443950649997		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.8699443950649997 | validation: 2.0270844193143827]
	TIME [epoch: 11.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.865127948806994		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.865127948806994 | validation: 2.292651898350538]
	TIME [epoch: 11.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.130112523717396		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.130112523717396 | validation: 2.26709172902317]
	TIME [epoch: 11.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5746094847485033		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.5746094847485033 | validation: 1.973106409665864]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9076072560125714		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9076072560125714 | validation: 1.854034840213335]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6787436016106105		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.6787436016106105 | validation: 1.9063432540537872]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7597447386764271		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.7597447386764271 | validation: 1.7977272579835966]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.721924810621614		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.721924810621614 | validation: 1.858514868241063]
	TIME [epoch: 11.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7795060182755904		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.7795060182755904 | validation: 1.7994672514929324]
	TIME [epoch: 11.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390323723810392		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.7390323723810392 | validation: 1.6866693922060814]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5868078739215656		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.5868078739215656 | validation: 1.6095239363693463]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5955046643473803		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5955046643473803 | validation: 1.43797668391572]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8242138253305857		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.8242138253305857 | validation: 1.8947359115231068]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7342023240904934		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.7342023240904934 | validation: 2.038744671886642]
	TIME [epoch: 11.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.681972804055954		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.681972804055954 | validation: 2.002168631229689]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9018487086796554		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.9018487086796554 | validation: 1.914898447191817]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7890218263939173		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.7890218263939173 | validation: 1.516252287075821]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.442342535921115		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.442342535921115 | validation: 1.9113661727992122]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7378205726860019		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.7378205726860019 | validation: 1.6933187661958136]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5350882184707841		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.5350882184707841 | validation: 1.4433208248811076]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48443850432112		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.48443850432112 | validation: 1.6826268035252117]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4886911518017256		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.4886911518017256 | validation: 1.5574161151769164]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6315075215575778		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.6315075215575778 | validation: 2.680459728422185]
	TIME [epoch: 11.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.826563911430384		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.826563911430384 | validation: 1.5587041158762043]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5088733138004367		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.5088733138004367 | validation: 1.7960816473959074]
	TIME [epoch: 11.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5091132913278882		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.5091132913278882 | validation: 1.33031502853029]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4026110432533165		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.4026110432533165 | validation: 1.5436403647709973]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5077046407020511		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.5077046407020511 | validation: 1.7832752043193119]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5357911360459706		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.5357911360459706 | validation: 1.9529709292496342]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6498608467917344		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.6498608467917344 | validation: 1.537472822424578]
	TIME [epoch: 11.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.496504596948533		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.496504596948533 | validation: 1.5085841894963212]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3602474422150421		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.3602474422150421 | validation: 1.4481140116871847]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4417843063308298		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.4417843063308298 | validation: 1.645949260808783]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.672518149624183		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.672518149624183 | validation: 1.4190727140374964]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5702491691566973		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.5702491691566973 | validation: 1.5542182774414277]
	TIME [epoch: 11.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.494220081440455		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.494220081440455 | validation: 2.3337205431566037]
	TIME [epoch: 11.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8135140946912465		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.8135140946912465 | validation: 1.3728007444819033]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.527184895915343		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.527184895915343 | validation: 1.716649208807043]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5177185145359673		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.5177185145359673 | validation: 2.172089979201408]
	TIME [epoch: 11.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7294436237268667		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.7294436237268667 | validation: 1.3393447977786324]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4552932018341165		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.4552932018341165 | validation: 1.8799412610655675]
	TIME [epoch: 11.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.371858919931424		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.371858919931424 | validation: 1.134188087831064]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4077257840984772		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.4077257840984772 | validation: 2.2409365692186975]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5299510913383005		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.5299510913383005 | validation: 1.5895492760267482]
	TIME [epoch: 11.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4807112560475626		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.4807112560475626 | validation: 1.6414191471170423]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3214644273072071		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.3214644273072071 | validation: 1.185462815708346]
	TIME [epoch: 11.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3892520499245573		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.3892520499245573 | validation: 2.7153232345419465]
	TIME [epoch: 11.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.542623196272079		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.542623196272079 | validation: 2.2228893855394545]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.624631667402911		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.624631667402911 | validation: 2.2665178212168096]
	TIME [epoch: 11.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6815122353815024		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.6815122353815024 | validation: 1.3411236998471459]
	TIME [epoch: 11.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.506108005299348		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.506108005299348 | validation: 1.680924417854469]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4288213083305814		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.4288213083305814 | validation: 1.360496788986889]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3045625338991793		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.3045625338991793 | validation: 1.2961962287998277]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2888217305841918		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.2888217305841918 | validation: 1.0271550575359325]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6507564785909854		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.6507564785909854 | validation: 1.1132604280798486]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3486933050037533		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.3486933050037533 | validation: 1.162031080497635]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.884077167549189		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.884077167549189 | validation: 2.0589278198539684]
	TIME [epoch: 11.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6169546530187937		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.6169546530187937 | validation: 1.4834903547774543]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3796381421124067		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3796381421124067 | validation: 1.927184411882252]
	TIME [epoch: 11.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4921725247210766		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.4921725247210766 | validation: 1.3471400720173994]
	TIME [epoch: 11.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4612029113373959		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4612029113373959 | validation: 1.389613425750737]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419537168685449		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.419537168685449 | validation: 1.3559319323587544]
	TIME [epoch: 11.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.347383324078367		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.347383324078367 | validation: 1.561973508737571]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5421219469392633		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.5421219469392633 | validation: 1.7270042067039422]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509870807972725		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.509870807972725 | validation: 1.422512104411244]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3225257406635271		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3225257406635271 | validation: 1.7603127798684604]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6373970391742936		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.6373970391742936 | validation: 1.376314390177078]
	TIME [epoch: 11.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.386904588149866		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.386904588149866 | validation: 1.6291163554242831]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3761045290248366		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.3761045290248366 | validation: 1.29633467354549]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.224496143764027		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.224496143764027 | validation: 1.5695680944261392]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.320302279395512		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.320302279395512 | validation: 1.1805248001415758]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2121559884222934		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2121559884222934 | validation: 2.270263086163663]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5645388656997143		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.5645388656997143 | validation: 1.188440756029023]
	TIME [epoch: 11.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1283317158692903		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.1283317158692903 | validation: 0.9456446545444399]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1941229581431865		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.1941229581431865 | validation: 1.0145961393874228]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03720415815888		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.03720415815888 | validation: 1.2444733586005339]
	TIME [epoch: 11.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4546443909180484		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.4546443909180484 | validation: 1.4038784183320678]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1079387311871358		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.1079387311871358 | validation: 0.8493944969706327]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0493086056496757		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0493086056496757 | validation: 1.0815692609528598]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155673762120795		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.155673762120795 | validation: 0.9477542938442306]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1506969397871945		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.1506969397871945 | validation: 0.9790989705184173]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0432321008238663		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0432321008238663 | validation: 1.2241169353870398]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713680990784719		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.9713680990784719 | validation: 1.3355308360505915]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0527933810063543		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0527933810063543 | validation: 1.5102279482461345]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.249940673568539		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.249940673568539 | validation: 1.2769453603444223]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094280837920513		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.094280837920513 | validation: 1.0327620422821526]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9309460091378494		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.9309460091378494 | validation: 1.0702800733619047]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.113259393411589		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.113259393411589 | validation: 1.2959417586307498]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2449538465383592		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.2449538465383592 | validation: 1.3570377825355255]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4402060120185411		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.4402060120185411 | validation: 1.357444093628278]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2218823180384601		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2218823180384601 | validation: 1.1640058560381723]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0726035388393957		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0726035388393957 | validation: 1.461725841731378]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1247977402654905		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.1247977402654905 | validation: 1.127261993513091]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9905655303822145		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.9905655303822145 | validation: 2.3550137695217463]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5654150399767335		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.5654150399767335 | validation: 1.0764961612340025]
	TIME [epoch: 11.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1061886702763164		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.1061886702763164 | validation: 0.9263247009166672]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4825967982699764		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.4825967982699764 | validation: 1.7936050607292335]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2840334958554513		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.2840334958554513 | validation: 1.046369742224448]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0375982552426901		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.0375982552426901 | validation: 0.963837183649967]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1987625931928219		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.1987625931928219 | validation: 1.3855624121451784]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.223822557742947		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.223822557742947 | validation: 1.3433159747310879]
	TIME [epoch: 11.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0779582583119272		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0779582583119272 | validation: 1.0174694138668083]
	TIME [epoch: 11.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1702846842649195		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1702846842649195 | validation: 1.0007838817379198]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1308277779725127		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.1308277779725127 | validation: 0.9856627697088824]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.541397084827474		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.541397084827474 | validation: 0.8719519902384758]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740442611369938		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.8740442611369938 | validation: 1.2695272996802052]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0133273171856545		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.0133273171856545 | validation: 1.1548267959706489]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000636688904948		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.000636688904948 | validation: 0.7907448689858083]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7948658686114807		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.7948658686114807 | validation: 1.4028795035296715]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0290989469815297		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0290989469815297 | validation: 1.018791207449047]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9363293080015552		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9363293080015552 | validation: 1.0147883455381983]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047607663558338		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.047607663558338 | validation: 1.4905473638205995]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1351075683834542		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.1351075683834542 | validation: 0.974241925717965]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.902299570230465		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.902299570230465 | validation: 0.7538656767418946]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9053904777682509		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.9053904777682509 | validation: 0.701771250427274]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9842368705323743		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.9842368705323743 | validation: 1.967360257871635]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0890987183876013		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0890987183876013 | validation: 1.0687086978673794]
	TIME [epoch: 11.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1142904159469147		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.1142904159469147 | validation: 0.9899167489969734]
	TIME [epoch: 11.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8500319453652246		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.8500319453652246 | validation: 1.448232216971677]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3997733163151345		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.3997733163151345 | validation: 1.2103163206430323]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1893933209893444		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1893933209893444 | validation: 1.563624064411572]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2426419330635055		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.2426419330635055 | validation: 1.0230594590464994]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0344484287857942		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.0344484287857942 | validation: 0.9637066201691474]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8967645666968959		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8967645666968959 | validation: 1.5690889247037618]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4868763845363437		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.4868763845363437 | validation: 1.089878800023719]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9415358324619788		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.9415358324619788 | validation: 1.0200068724762954]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0343494414731258		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0343494414731258 | validation: 0.987791251981651]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2039601306987495		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.2039601306987495 | validation: 0.9911429446502595]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0510190461106392		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.0510190461106392 | validation: 0.8116204274253037]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0559310720065187		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.0559310720065187 | validation: 0.9550937897525895]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067794945904151		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9067794945904151 | validation: 0.7806526949861848]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7825825498093902		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7825825498093902 | validation: 0.9256893741722906]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8612394280316651		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8612394280316651 | validation: 0.7248869582521792]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.91191420868319		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.91191420868319 | validation: 1.0675002840192502]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.181105285765778		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.181105285765778 | validation: 0.8663587107448593]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9480266944707807		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.9480266944707807 | validation: 1.0587472516517924]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1659476909051132		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.1659476909051132 | validation: 0.8166935211779551]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1002308961999945		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.1002308961999945 | validation: 0.8006768164633493]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8810932298049536		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8810932298049536 | validation: 0.6723201474754407]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8475363576712779		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8475363576712779 | validation: 1.0422669692682625]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9729296790320976		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9729296790320976 | validation: 0.8989177116302941]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9370854416368426		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9370854416368426 | validation: 0.6709248843152762]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8988226362545049		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8988226362545049 | validation: 1.9851875248072715]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2857613734191116		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2857613734191116 | validation: 0.8477468112470428]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1438648605524753		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.1438648605524753 | validation: 1.1158492284631967]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9628260551743805		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.9628260551743805 | validation: 1.0294857965300552]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346086839067449		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.9346086839067449 | validation: 0.9238632217337402]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8132781499706608		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.8132781499706608 | validation: 0.8699419450696303]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9962364352294725		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9962364352294725 | validation: 1.445488383304338]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9556480086506709		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.9556480086506709 | validation: 0.7695745304633852]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8638990631843132		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8638990631843132 | validation: 1.4562260577456272]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.320455797701718		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.320455797701718 | validation: 0.9610836244915478]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9791162143795498		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9791162143795498 | validation: 0.7518444106622978]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197559386711343		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7197559386711343 | validation: 0.906175338000407]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9484243918011301		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.9484243918011301 | validation: 1.2462487388385795]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125118242553555		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.125118242553555 | validation: 0.8128425575263905]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309588613032759		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.0309588613032759 | validation: 1.0148394863348613]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8463457224591477		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.8463457224591477 | validation: 0.7453316093409363]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9045693655295657		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.9045693655295657 | validation: 1.0692658138747038]
	TIME [epoch: 11.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8744479470600637		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8744479470600637 | validation: 0.7788593673988475]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1327812294666684		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.1327812294666684 | validation: 1.2397157870938176]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9820467104594265		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.9820467104594265 | validation: 0.9038160179678478]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8274485849814754		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.8274485849814754 | validation: 1.0182960558006275]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8718492945705821		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.8718492945705821 | validation: 0.7421411866150749]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705324012209183		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.0705324012209183 | validation: 0.6755324862151646]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8300809061597678		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8300809061597678 | validation: 0.7733060654421634]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790876396026922		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7790876396026922 | validation: 1.1935463133458517]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9167807804250139		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.9167807804250139 | validation: 0.9161631077504798]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8769157291917419		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8769157291917419 | validation: 0.9926812334043086]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1876998108747536		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.1876998108747536 | validation: 0.8693433898789733]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8053138989121866		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.8053138989121866 | validation: 0.7286152302615941]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9017264058915184		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.9017264058915184 | validation: 0.9016338026962991]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8714265500590108		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.8714265500590108 | validation: 0.8500720475021638]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8093721406185814		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8093721406185814 | validation: 1.3600377421568215]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694612471255863		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9694612471255863 | validation: 0.7987519931894699]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8777286174764334		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.8777286174764334 | validation: 0.6415626899360964]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.814681068106019		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.814681068106019 | validation: 0.78036467690717]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7873204339862594		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7873204339862594 | validation: 0.7095160165226452]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944425383233461		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6944425383233461 | validation: 1.0199692197086179]
	TIME [epoch: 11.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346960999199107		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8346960999199107 | validation: 0.9929170509164004]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7937130839507419		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7937130839507419 | validation: 0.726052574144562]
	TIME [epoch: 11.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0464798268233286		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.0464798268233286 | validation: 0.9470561705667752]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7620348976581895		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7620348976581895 | validation: 0.5971031859816421]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6923493299200308		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6923493299200308 | validation: 1.1151106340097436]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143936699685394		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.143936699685394 | validation: 0.8803630376032652]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0147022602649285		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.0147022602649285 | validation: 0.9247191876530383]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347326744466816		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.9347326744466816 | validation: 0.6581989200104853]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488555271531423		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.8488555271531423 | validation: 0.735739469562185]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916270819565625		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7916270819565625 | validation: 0.9095396283067467]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.931617632135219		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.931617632135219 | validation: 1.1113418928376235]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202283481955		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.9202283481955 | validation: 0.8007361240459572]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7406853851884548		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7406853851884548 | validation: 1.0128804540832126]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9568036619112235		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.9568036619112235 | validation: 0.6398241916420189]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8945365610173268		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.8945365610173268 | validation: 0.9408229196464305]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8387845394297591		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8387845394297591 | validation: 0.8693240849986217]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652041767734593		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.8652041767734593 | validation: 0.6918487100850561]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8567111186824049		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.8567111186824049 | validation: 0.6326561982330942]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563463835255143		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6563463835255143 | validation: 1.0298758009225475]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.010691509555539		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.010691509555539 | validation: 0.9112131464627394]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8694399976996949		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.8694399976996949 | validation: 0.6059695568238915]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875637843868043		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6875637843868043 | validation: 0.5899023904224275]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115703556895541		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7115703556895541 | validation: 1.0214318151882213]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8828092639373513		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.8828092639373513 | validation: 0.549803724659987]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7700654053776603		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7700654053776603 | validation: 0.6807073562626315]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7636883946165391		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7636883946165391 | validation: 0.5488892768126915]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7389564347407604		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7389564347407604 | validation: 0.6025626671455205]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257295112828228		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.7257295112828228 | validation: 0.6610850968093746]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778926267718		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6778926267718 | validation: 0.6292618182106748]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079059861894723		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7079059861894723 | validation: 0.6559326972955347]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7305723086373703		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7305723086373703 | validation: 0.6320989133780867]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485480610535994		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6485480610535994 | validation: 0.6089608036788332]
	TIME [epoch: 11.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065099018692874		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7065099018692874 | validation: 0.6136416970532036]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.788986843459518		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.788986843459518 | validation: 0.9496144385700329]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8697260224739827		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8697260224739827 | validation: 0.8963922785407326]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8899257432734005		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8899257432734005 | validation: 0.7921534759224304]
	TIME [epoch: 11.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7702639204285329		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.7702639204285329 | validation: 1.2809375526634375]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.321554867852155		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.321554867852155 | validation: 1.090738145639112]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169757025726992		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.8169757025726992 | validation: 0.6922063083319904]
	TIME [epoch: 11.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7636351551184182		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7636351551184182 | validation: 1.121385624386624]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9353145359845723		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.9353145359845723 | validation: 0.8001950074385686]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8423869564175976		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8423869564175976 | validation: 0.9213205856430179]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089984336298038		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8089984336298038 | validation: 0.6317429919790648]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8423551258341717		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.8423551258341717 | validation: 0.7186466282625427]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7358108533791687		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7358108533791687 | validation: 1.1329922156344998]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221194527522159		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9221194527522159 | validation: 0.677499381965736]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7928229116565572		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7928229116565572 | validation: 1.05270026678046]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794291927316168		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.9794291927316168 | validation: 0.6951304417642118]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6331390939364295		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6331390939364295 | validation: 0.66541222334362]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177946042594995		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8177946042594995 | validation: 0.6529543869034933]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877169246263046		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6877169246263046 | validation: 0.6444551655634334]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068838783569351		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7068838783569351 | validation: 0.5599690888174533]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7980424980679769		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7980424980679769 | validation: 0.6942942324186779]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6769679346753184		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.6769679346753184 | validation: 0.6304826171616851]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6822060657391956		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6822060657391956 | validation: 0.6915497472467572]
	TIME [epoch: 11.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6971293856972367		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6971293856972367 | validation: 0.8528991043068058]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7479534504125767		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7479534504125767 | validation: 0.818361612855046]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111288830203883		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.7111288830203883 | validation: 0.6118948959082957]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075511198637978		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.6075511198637978 | validation: 1.0502707296922584]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0633338310391531		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.0633338310391531 | validation: 1.0604160789987]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9194205450898554		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9194205450898554 | validation: 0.9660783373898306]
	TIME [epoch: 11.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8860112929400616		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.8860112929400616 | validation: 0.977809175334799]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.810951457828369		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.810951457828369 | validation: 0.8082502785065125]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9424459675786003		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.9424459675786003 | validation: 0.7786224645357811]
	TIME [epoch: 11.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399863425760151		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7399863425760151 | validation: 0.7578941444319278]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106992549407499		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.8106992549407499 | validation: 1.173695207231141]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8809985041684716		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8809985041684716 | validation: 0.7245545991766028]
	TIME [epoch: 11.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000755329542184		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.7000755329542184 | validation: 0.693054878850836]
	TIME [epoch: 11.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351873018781743		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.7351873018781743 | validation: 0.87049917055894]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8667242988221344		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.8667242988221344 | validation: 0.662792578815461]
	TIME [epoch: 11.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509185234235965		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6509185234235965 | validation: 0.6973636753671322]
	TIME [epoch: 11.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079101445865699		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.7079101445865699 | validation: 0.8115120898614565]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0502613779086236		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.0502613779086236 | validation: 0.8840959572929644]
	TIME [epoch: 11.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071040825748953		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8071040825748953 | validation: 0.6301984639373515]
	TIME [epoch: 11.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744638025912849		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.744638025912849 | validation: 0.6140410586191538]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426114104855056		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.7426114104855056 | validation: 0.930479803780068]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623516663632062		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.7623516663632062 | validation: 0.553630462752296]
	TIME [epoch: 11.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6569364214398619		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6569364214398619 | validation: 0.7866889499008737]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7249549038347423		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7249549038347423 | validation: 0.7347052478339507]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386954214568142		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7386954214568142 | validation: 0.6698117728097173]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6636750630345859		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6636750630345859 | validation: 0.8709592516056256]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575997963207907		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6575997963207907 | validation: 0.6260359902057743]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5610873179919069		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5610873179919069 | validation: 1.2913243141443504]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0448036292328677		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.0448036292328677 | validation: 1.2449973598116704]
	TIME [epoch: 11.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926782431110673		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.7926782431110673 | validation: 1.0057841603932518]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7396551722207109		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.7396551722207109 | validation: 0.6305257518492519]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9658514589722103		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9658514589722103 | validation: 1.0078883863262746]
	TIME [epoch: 11.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7150550109904931		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7150550109904931 | validation: 0.6204571473495842]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965472620265343		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.6965472620265343 | validation: 0.5950320999797707]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074252575774682		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6074252575774682 | validation: 0.6466808903215291]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7658008434031249		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.7658008434031249 | validation: 0.6106406136056112]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609736083339834		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.609736083339834 | validation: 0.614399867578504]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6182057676514872		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.6182057676514872 | validation: 0.5008430186193864]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577120134620291		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.6577120134620291 | validation: 0.6232353165007278]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8393226435742773		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.8393226435742773 | validation: 1.139872831492656]
	TIME [epoch: 11.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.73178087968135		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.73178087968135 | validation: 0.7443412952918002]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6665996361581149		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.6665996361581149 | validation: 0.6064586775641858]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443834531336803		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6443834531336803 | validation: 0.7905650668789465]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7026057734234932		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7026057734234932 | validation: 0.6370774896696029]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421925563480335		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6421925563480335 | validation: 0.5852124050231025]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.664150898314031		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.664150898314031 | validation: 0.6469415794373222]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229021268180651		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6229021268180651 | validation: 0.6044252151094677]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645530484977377		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5645530484977377 | validation: 0.6868331760777897]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995888300951785		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5995888300951785 | validation: 0.6061739142400796]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314277207148568		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6314277207148568 | validation: 0.5312678381676441]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5906879977540944		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5906879977540944 | validation: 0.555640919012468]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530440634908128		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6530440634908128 | validation: 0.7899120234747192]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092325416160118		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6092325416160118 | validation: 0.6194277591283127]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829820981946051		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6829820981946051 | validation: 0.6928260456936645]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962905465774004		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5962905465774004 | validation: 0.49015454668408104]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748915640297814		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5748915640297814 | validation: 0.5941059004625804]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.960688126882347		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.960688126882347 | validation: 0.7440639660001286]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6464212218308834		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6464212218308834 | validation: 0.6338027914321405]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6210419340311336		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6210419340311336 | validation: 0.561936683849119]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165329687648666		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.8165329687648666 | validation: 0.7128136360523277]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6110201357539411		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.6110201357539411 | validation: 0.5218189656029822]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743641526614534		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5743641526614534 | validation: 0.6999726527288458]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615624415213778		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.6615624415213778 | validation: 0.6665301066586542]
	TIME [epoch: 11.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7483377589387129		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7483377589387129 | validation: 0.5703304436546229]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204091481713033		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.6204091481713033 | validation: 0.5058311642502716]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8312866333361659		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8312866333361659 | validation: 0.6057837031914756]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890944822968982		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5890944822968982 | validation: 0.6138007563574098]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612757562605177		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5612757562605177 | validation: 0.5169557630292646]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5305355684938888		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5305355684938888 | validation: 0.47007956492379416]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470926095531004		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.6470926095531004 | validation: 0.5758967283952257]
	TIME [epoch: 11.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6780706836662111		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6780706836662111 | validation: 0.5182932887281902]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5797534057571656		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5797534057571656 | validation: 0.4933738308699512]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49833547325985883		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.49833547325985883 | validation: 0.5747306356706119]
	TIME [epoch: 11.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6164912711200949		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6164912711200949 | validation: 0.5065783016616959]
	TIME [epoch: 11.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642106837187011		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5642106837187011 | validation: 0.5609849660789762]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6187016782234525		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.6187016782234525 | validation: 0.8628385535239231]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6718291758907994		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.6718291758907994 | validation: 0.5198776868788126]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122206607205613		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.5122206607205613 | validation: 0.5467314750689458]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755093061934149		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5755093061934149 | validation: 0.6554609134125863]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5759704715397047		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.5759704715397047 | validation: 0.6043062857731453]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640233007240443		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.5640233007240443 | validation: 0.6154526520204299]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324548207759071		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7324548207759071 | validation: 0.6291670245065732]
	TIME [epoch: 11.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065023327694596		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6065023327694596 | validation: 0.4792744108167195]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6879682817305339		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.6879682817305339 | validation: 0.5958134555566865]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790687709566951		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5790687709566951 | validation: 0.4758550297699826]
	TIME [epoch: 11.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5097541244098984		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5097541244098984 | validation: 0.5506800599828605]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220453012878326		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5220453012878326 | validation: 0.8659555222178057]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104509514996607		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.6104509514996607 | validation: 0.5101842790492193]
	TIME [epoch: 11.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788877316574419		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5788877316574419 | validation: 0.6748924144953267]
	TIME [epoch: 11.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543985946371949		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.6543985946371949 | validation: 0.6179148243440672]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5872028772644475		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5872028772644475 | validation: 0.6321443971955018]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222862070054131		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5222862070054131 | validation: 0.8795368950017906]
	TIME [epoch: 11.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8476683739697592		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.8476683739697592 | validation: 0.7927987339276402]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297719110977006		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.6297719110977006 | validation: 0.5132782371030576]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668652627491921		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5668652627491921 | validation: 0.5226117172801252]
	TIME [epoch: 11.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337210417375161		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7337210417375161 | validation: 0.566483671639309]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130951282247695		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.6130951282247695 | validation: 0.6259040721285242]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5371164363594176		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5371164363594176 | validation: 0.5438991153596354]
	TIME [epoch: 11.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833056624835179		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5833056624835179 | validation: 0.5265785113627395]
	TIME [epoch: 11.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072201236170326		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5072201236170326 | validation: 0.5298191918053339]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680679253051879		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.6680679253051879 | validation: 0.4973743278579114]
	TIME [epoch: 11.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6977034403545184		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.6977034403545184 | validation: 0.874555976171803]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6740450269487692		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.6740450269487692 | validation: 0.6104531840156346]
	TIME [epoch: 11.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298519794198123		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.6298519794198123 | validation: 0.5931880576991537]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142703230461057		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6142703230461057 | validation: 0.5822964989200382]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327621311711962		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6327621311711962 | validation: 0.5738921803264876]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390076665776433		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5390076665776433 | validation: 0.5572520306902071]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057990532301802		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.6057990532301802 | validation: 0.6169821408086581]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135232210594531		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6135232210594531 | validation: 0.4755207780431976]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905117163822932		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5905117163822932 | validation: 0.5192924175692673]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463862379524884		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.6463862379524884 | validation: 0.4503801607403135]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473117200802341		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.5473117200802341 | validation: 0.5577335690971659]
	TIME [epoch: 11.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887658398489892		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.5887658398489892 | validation: 0.704822298906899]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593376846251328		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.5593376846251328 | validation: 0.5349855702513464]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5419594483410315		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5419594483410315 | validation: 0.5445790032569992]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924326181073862		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.5924326181073862 | validation: 0.48523924279114183]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48194660093074526		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.48194660093074526 | validation: 0.5634549995050281]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462408192570078		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5462408192570078 | validation: 0.5455619396083511]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5524432004202091		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5524432004202091 | validation: 0.6318570088706951]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410498826427522		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.7410498826427522 | validation: 0.6227401005265688]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708604618444183		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5708604618444183 | validation: 0.47206460866965116]
	TIME [epoch: 11.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163897644603578		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5163897644603578 | validation: 0.6476865967334315]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530340876877623		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6530340876877623 | validation: 0.5780225691314838]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59909919738349		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.59909919738349 | validation: 0.5561551162509296]
	TIME [epoch: 11.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698390742580457		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.5698390742580457 | validation: 0.5151010865035598]
	TIME [epoch: 11.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674992390193925		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5674992390193925 | validation: 0.6677636229197357]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6368917897037419		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.6368917897037419 | validation: 0.651585406121639]
	TIME [epoch: 11.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.592075930826012		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.592075930826012 | validation: 0.4046208961258272]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5215473044667756		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5215473044667756 | validation: 0.6658730902365545]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810388468749441		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5810388468749441 | validation: 0.5653773804395147]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.574912973536081		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.574912973536081 | validation: 0.4612463655354418]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5294678738218285		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5294678738218285 | validation: 0.49872359789370324]
	TIME [epoch: 11.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45270445814661864		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.45270445814661864 | validation: 0.39013628321950655]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936266909646748		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.4936266909646748 | validation: 0.4587199922552287]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483366508632716		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.4483366508632716 | validation: 0.37779609866170305]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726466323947792		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.5726466323947792 | validation: 0.5460040920698449]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961785441445705		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.5961785441445705 | validation: 0.5739336037942597]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123747770083331		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.5123747770083331 | validation: 0.5061409557196414]
	TIME [epoch: 11.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895187159949803		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4895187159949803 | validation: 0.45093446747549315]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800148698168601		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4800148698168601 | validation: 0.46586984083146904]
	TIME [epoch: 11.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834971835793329		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4834971835793329 | validation: 0.46021385389551017]
	TIME [epoch: 11.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487414436899688		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.487414436899688 | validation: 0.4386634552819601]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5242793644530578		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5242793644530578 | validation: 0.4575744372662166]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5746914021700066		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5746914021700066 | validation: 0.609148013461938]
	TIME [epoch: 11.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293178194489403		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5293178194489403 | validation: 0.4346709143078802]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914717028131912		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.4914717028131912 | validation: 0.6428052586166493]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527518230600353		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.5527518230600353 | validation: 0.5028013246203318]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46723126833110834		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.46723126833110834 | validation: 0.5732811583067575]
	TIME [epoch: 11.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5239261851156638		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.5239261851156638 | validation: 0.5621876437375852]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4718135525310865		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.4718135525310865 | validation: 0.46622099442340015]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51611079684337		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.51611079684337 | validation: 0.4329774856488875]
	TIME [epoch: 11.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4475195460934069		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4475195460934069 | validation: 0.4480855018451287]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4363985796720008		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4363985796720008 | validation: 0.4570602931094041]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4435779295842825		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.4435779295842825 | validation: 0.547819765984838]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501641564962002		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.501641564962002 | validation: 0.4790128879323971]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44616090234057737		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.44616090234057737 | validation: 0.38848015397645036]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916872605227705		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3916872605227705 | validation: 0.5708912073363973]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.520350488358627		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.520350488358627 | validation: 0.46441285147149053]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553031352617115		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.4553031352617115 | validation: 0.5536713776056442]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846893025703026		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5846893025703026 | validation: 1.0391935143377515]
	TIME [epoch: 11.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8416614532509077		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.8416614532509077 | validation: 0.6502165990634023]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570330372703408		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.570330372703408 | validation: 0.45651758200045023]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4385850719534981		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4385850719534981 | validation: 0.5921038865403768]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100080907751544		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5100080907751544 | validation: 0.47504848052818843]
	TIME [epoch: 11.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45529019599312975		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.45529019599312975 | validation: 0.5198702544502602]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5187592385762555		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5187592385762555 | validation: 0.3901439660997781]
	TIME [epoch: 11.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054516481363701		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.5054516481363701 | validation: 0.49192801865666286]
	TIME [epoch: 11.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302459260935035		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5302459260935035 | validation: 0.38808376983547627]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4441375538669319		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4441375538669319 | validation: 0.4633349928173415]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741175540981822		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4741175540981822 | validation: 0.393687670613392]
	TIME [epoch: 11.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45746764123451406		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.45746764123451406 | validation: 0.5904872556370778]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5670214546095516		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5670214546095516 | validation: 0.5370684125045695]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637458721764337		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.4637458721764337 | validation: 0.5087983310685822]
	TIME [epoch: 11.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165107228342157		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6165107228342157 | validation: 0.8200278555037659]
	TIME [epoch: 11.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224962357831778		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.6224962357831778 | validation: 0.3549576961711728]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417997097691124		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.4417997097691124 | validation: 0.7916340265677687]
	TIME [epoch: 11.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5173641453184111		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5173641453184111 | validation: 0.48462449985567974]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540974431164103		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.4540974431164103 | validation: 0.49767895672927726]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753988481161967		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4753988481161967 | validation: 0.4480744018812565]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4935705037983751		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4935705037983751 | validation: 0.4144328605285255]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190392545391583		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4190392545391583 | validation: 0.44924373873541285]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560599051871136		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4560599051871136 | validation: 0.3821723404283208]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571386236206346		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.4571386236206346 | validation: 0.4783185543634443]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478051139776288		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.478051139776288 | validation: 0.3625951476322567]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4109647768020538		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.4109647768020538 | validation: 0.4563135718740419]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4369182576682291		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4369182576682291 | validation: 0.5532496115444666]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472077163626198		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.4472077163626198 | validation: 0.5373113812017389]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681644506919306		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.4681644506919306 | validation: 0.3728032906088468]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507781173323649		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.507781173323649 | validation: 0.46036740058110104]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4539125809121748		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.4539125809121748 | validation: 0.4819213776695888]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4287419932356491		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.4287419932356491 | validation: 0.5237551115082072]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967593907429989		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5967593907429989 | validation: 0.6210548915695118]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45785260479906376		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.45785260479906376 | validation: 0.5685766214665846]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5715216083072083		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5715216083072083 | validation: 0.37602558596768765]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48120386736561305		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.48120386736561305 | validation: 0.43057680566562745]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43109385130256284		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.43109385130256284 | validation: 0.4021305539917367]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122273041574036		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.5122273041574036 | validation: 0.4043133337405725]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47646848153580196		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.47646848153580196 | validation: 0.4492111915714827]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518704970686384		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.518704970686384 | validation: 0.5572675643677539]
	TIME [epoch: 11.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100619456294847		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.5100619456294847 | validation: 0.4028407303988384]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471875631327238		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5471875631327238 | validation: 0.49455130892063703]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49662019185766676		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.49662019185766676 | validation: 0.37828286578304243]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3967644707164933		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.3967644707164933 | validation: 0.4863052033312556]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089443248448361		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.4089443248448361 | validation: 0.4395128626888806]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471072354906539		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.471072354906539 | validation: 0.3603856850734772]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.366575925243827		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.366575925243827 | validation: 0.42730635144220097]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41548219775780093		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.41548219775780093 | validation: 0.36852472042706785]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36408114478848524		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.36408114478848524 | validation: 0.3971526725793807]
	TIME [epoch: 11.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771159588600009		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.4771159588600009 | validation: 0.4213208510432939]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36676137594956204		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.36676137594956204 | validation: 0.41282953852325466]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.482461498941918		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.482461498941918 | validation: 0.6549471617382366]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713021137598734		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4713021137598734 | validation: 0.3959836568527983]
	TIME [epoch: 11.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451372875356268		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.451372875356268 | validation: 0.48537437970312847]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44358930298101185		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.44358930298101185 | validation: 0.414745018727817]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778295701980151		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3778295701980151 | validation: 0.3326342591468132]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086861084487423		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6086861084487423 | validation: 0.4203511304681121]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4541549013479652		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.4541549013479652 | validation: 0.4529330952761484]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4658780198982279		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4658780198982279 | validation: 0.3889506547163959]
	TIME [epoch: 11.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099158980605557		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.5099158980605557 | validation: 0.43012726053286776]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43739310780030727		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.43739310780030727 | validation: 0.3844448283488711]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394606315179748		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.394606315179748 | validation: 0.45837933060113556]
	TIME [epoch: 11.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412525933678409		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.412525933678409 | validation: 0.32092329183452223]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35954392857416295		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.35954392857416295 | validation: 0.3467937616799726]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841773560616403		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.3841773560616403 | validation: 0.4023949312082844]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41702380196574224		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.41702380196574224 | validation: 0.42464222000219776]
	TIME [epoch: 11.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3985670612105192		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3985670612105192 | validation: 0.3741302218334701]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4381450766347539		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.4381450766347539 | validation: 0.4779437111914938]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42455480570837767		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.42455480570837767 | validation: 0.35061088024432674]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38955248769029005		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.38955248769029005 | validation: 0.4150578010508276]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813783637046776		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.4813783637046776 | validation: 0.38184544796768977]
	TIME [epoch: 11.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45855979243325456		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.45855979243325456 | validation: 0.5918438747563493]
	TIME [epoch: 11.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44180345665077747		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.44180345665077747 | validation: 0.3340371289366054]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470875554703734		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3470875554703734 | validation: 0.3178020567630051]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_546.pth
	Model improved!!!
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35642434119718003		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.35642434119718003 | validation: 0.36812575912701034]
	TIME [epoch: 11.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442984824314714		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3442984824314714 | validation: 0.30171069184071464]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535575607805676		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.4535575607805676 | validation: 0.5369721952154278]
	TIME [epoch: 11.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45646632927555275		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.45646632927555275 | validation: 0.4371030203676513]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763721132075688		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3763721132075688 | validation: 0.34685378309078063]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989912233306021		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3989912233306021 | validation: 0.39916105818159536]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44821283403829176		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.44821283403829176 | validation: 0.33132036275366955]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3763320329639868		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3763320329639868 | validation: 0.40672249398097643]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399556963418189		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.399556963418189 | validation: 0.3663770190651103]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348594906605985		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.3348594906605985 | validation: 0.32189511249839003]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42756606094756455		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.42756606094756455 | validation: 0.36775987968100593]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440669064041675		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.6440669064041675 | validation: 0.492009661740029]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119228940114797		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.5119228940114797 | validation: 0.4192092505969331]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42130619776824046		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.42130619776824046 | validation: 0.5661910729969837]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40990910900757366		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.40990910900757366 | validation: 0.45863303840849357]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732562699672527		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3732562699672527 | validation: 0.3239260759575484]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609902986964823		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3609902986964823 | validation: 0.4516482474022195]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40536544541182434		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.40536544541182434 | validation: 0.39162050565088474]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41275611285787805		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.41275611285787805 | validation: 0.31889955705626166]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889678907024714		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3889678907024714 | validation: 0.3535661211354945]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4347719697880621		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.4347719697880621 | validation: 0.49254792288046395]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.434367542722235		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.434367542722235 | validation: 0.36285377463903634]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4033079629742604		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.4033079629742604 | validation: 0.31311516541224554]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3646103607592672		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3646103607592672 | validation: 0.4162020735619235]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35269079515436097		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.35269079515436097 | validation: 0.3547451024509509]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44514001161056355		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.44514001161056355 | validation: 0.8861692101060225]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123185228838035		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6123185228838035 | validation: 0.3864889918735122]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37225842697352907		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.37225842697352907 | validation: 0.3704926177175225]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181020007342667		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5181020007342667 | validation: 0.34623009434564084]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4380462261444549		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.4380462261444549 | validation: 0.3646627207943018]
	TIME [epoch: 11.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34386976974881883		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.34386976974881883 | validation: 0.32952310548001884]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35243159794312506		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.35243159794312506 | validation: 0.4026163692580528]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39839227476554895		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.39839227476554895 | validation: 0.37457330051406457]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42745255334700216		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.42745255334700216 | validation: 0.30825999844473934]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118571784403106		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.3118571784403106 | validation: 0.3487674226190394]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391237891892326		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.391237891892326 | validation: 0.3584277878971329]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37962445012330664		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.37962445012330664 | validation: 0.40423664841774054]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153810818598531		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.4153810818598531 | validation: 0.4216787196990157]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38630263418654537		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.38630263418654537 | validation: 0.38316297314601583]
	TIME [epoch: 11.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380230393010566		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3380230393010566 | validation: 0.30710376532835826]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3503968582257671		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.3503968582257671 | validation: 0.4038727568141286]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368232929559492		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.368232929559492 | validation: 0.37509292073766615]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706968431147637		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.3706968431147637 | validation: 0.39032030893387265]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375451996889581		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.4375451996889581 | validation: 0.41962449212828845]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37775884621422096		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.37775884621422096 | validation: 0.32830215813489605]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3685171040235136		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3685171040235136 | validation: 0.44958140112282025]
	TIME [epoch: 11.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43126709525286916		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.43126709525286916 | validation: 0.3239300907898459]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036520309707632		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.4036520309707632 | validation: 0.33786301858599177]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35255455975417876		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.35255455975417876 | validation: 0.2772973275090733]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32567293156963095		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.32567293156963095 | validation: 0.4632827622522466]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42677984802352015		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.42677984802352015 | validation: 0.3233535778220102]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35739284731555154		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.35739284731555154 | validation: 0.31825403327804674]
	TIME [epoch: 11.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357798833526834		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3357798833526834 | validation: 0.3024980104368944]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632186464826602		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3632186464826602 | validation: 0.3714344096884189]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37776682763837227		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.37776682763837227 | validation: 0.3012503405574916]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31168718952826996		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.31168718952826996 | validation: 0.5345898622439473]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38979334018018835		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.38979334018018835 | validation: 0.33269394134037245]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44928422989389666		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.44928422989389666 | validation: 0.38640622188118656]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38054061465266664		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.38054061465266664 | validation: 0.32991996149529024]
	TIME [epoch: 11.5 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40972796316625276		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.40972796316625276 | validation: 0.3335775156919557]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36367586010893016		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.36367586010893016 | validation: 0.3593117132431201]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35670762048562155		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.35670762048562155 | validation: 0.2736738770112568]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229975370184901		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3229975370184901 | validation: 0.355247334562375]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479264498161168		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.3479264498161168 | validation: 0.29356163385228773]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32161587731549074		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.32161587731549074 | validation: 0.5178492371049179]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3947349050521055		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3947349050521055 | validation: 0.4050196530907641]
	TIME [epoch: 11.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34674034455987207		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.34674034455987207 | validation: 0.26070748369672525]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31639560151604174		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.31639560151604174 | validation: 0.2542254150292162]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27801766462739264		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.27801766462739264 | validation: 0.414282661846957]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356331115331034		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.3356331115331034 | validation: 0.6463773133435581]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4908685915975486		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.4908685915975486 | validation: 0.5309367206923271]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760995474667575		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.4760995474667575 | validation: 0.3175109882136145]
	TIME [epoch: 11.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31889693425406346		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.31889693425406346 | validation: 0.297631361309328]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33537650828084764		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.33537650828084764 | validation: 0.33498002481238787]
	TIME [epoch: 11.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.320434621676076		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.320434621676076 | validation: 0.29128012500976874]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3180716964290911		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.3180716964290911 | validation: 0.3480708275267081]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30373286389334814		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.30373286389334814 | validation: 0.281119471412706]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3039720939267123		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.3039720939267123 | validation: 0.42023546445194726]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316563320940774		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3316563320940774 | validation: 0.3880405170112263]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977700735890862		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.2977700735890862 | validation: 0.2739615353322335]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2887517981083688		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2887517981083688 | validation: 0.3299371897857549]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47440629999363365		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.47440629999363365 | validation: 0.48426241109336]
	TIME [epoch: 11.5 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3629593065754684		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3629593065754684 | validation: 0.2562850965844525]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26628499123296223		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.26628499123296223 | validation: 0.30085446769724555]
	TIME [epoch: 11.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919041014820526		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.3919041014820526 | validation: 0.23837065878269187]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300028194122366		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.300028194122366 | validation: 0.30004394387764005]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356399014173913		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3356399014173913 | validation: 0.2915768436957191]
	TIME [epoch: 11.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151579067361237		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.3151579067361237 | validation: 0.2936292744176867]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3670528456895563		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.3670528456895563 | validation: 0.3860222800260343]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220707095470059		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.3220707095470059 | validation: 0.25025214439217625]
	TIME [epoch: 11.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3084456439075531		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3084456439075531 | validation: 0.3277613462195862]
	TIME [epoch: 11.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3601595609469415		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3601595609469415 | validation: 0.25829158081275067]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653269308631		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2653269308631 | validation: 0.27639465931402024]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34917645449448803		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.34917645449448803 | validation: 0.3891830201022396]
	TIME [epoch: 11.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35637513448755875		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.35637513448755875 | validation: 0.26679316155903954]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834914430390306		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2834914430390306 | validation: 0.2742751179782589]
	TIME [epoch: 11.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3600065682747773		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.3600065682747773 | validation: 0.2740557773298383]
	TIME [epoch: 11.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3248513739387128		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.3248513739387128 | validation: 0.2437426505022194]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24670822803787718		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.24670822803787718 | validation: 0.2595034344590727]
	TIME [epoch: 11.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30297998390641157		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.30297998390641157 | validation: 0.37873668501893576]
	TIME [epoch: 11.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28439566703029856		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.28439566703029856 | validation: 0.2353284222559379]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_647.pth
	Model improved!!!
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28288595592546595		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.28288595592546595 | validation: 0.2785082581566079]
	TIME [epoch: 11.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32824218922688136		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.32824218922688136 | validation: 0.3765757231453182]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27634697609031367		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.27634697609031367 | validation: 0.2596546405100337]
	TIME [epoch: 11.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26868369288695326		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.26868369288695326 | validation: 0.28312360467039255]
	TIME [epoch: 11.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071695630973572		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.3071695630973572 | validation: 0.3499546040642938]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3413242151478602		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3413242151478602 | validation: 0.36688600555980444]
	TIME [epoch: 11.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3320073589789241		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3320073589789241 | validation: 0.343777484886317]
	TIME [epoch: 11.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.321435828679971		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.321435828679971 | validation: 0.3252410746055298]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32151410463742275		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.32151410463742275 | validation: 0.2807501308448185]
	TIME [epoch: 11.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34237846519637183		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.34237846519637183 | validation: 0.3472729110152918]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891813594602186		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.2891813594602186 | validation: 0.23369477332467845]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095361502937207		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3095361502937207 | validation: 0.23377222130251027]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27849636209609263		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.27849636209609263 | validation: 0.3569467329825807]
	TIME [epoch: 11.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746407964609364		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.3746407964609364 | validation: 0.2783020010707602]
	TIME [epoch: 11.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753847013265347		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2753847013265347 | validation: 0.2726344812522157]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632342006405866		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.2632342006405866 | validation: 0.2459264012878108]
	TIME [epoch: 11.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3227215603471285		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.3227215603471285 | validation: 0.4183702669870194]
	TIME [epoch: 11.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32349937578294596		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.32349937578294596 | validation: 0.3429024610654611]
	TIME [epoch: 11.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284481632786714		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.284481632786714 | validation: 0.2537045222291398]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26088062083367963		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.26088062083367963 | validation: 0.271503227905525]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31606609239152983		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.31606609239152983 | validation: 0.2892492533362334]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32065351957224436		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.32065351957224436 | validation: 0.312926439559094]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27030499174431943		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.27030499174431943 | validation: 0.21691928764189874]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652100228599582		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2652100228599582 | validation: 0.2217203572683018]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24712578275835265		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.24712578275835265 | validation: 0.28647103767326926]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3157810360885332		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3157810360885332 | validation: 0.2913619782225492]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2369992267138798		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2369992267138798 | validation: 0.2466135289279155]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2715297690021834		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.2715297690021834 | validation: 0.4366064964999756]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32750194955130213		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.32750194955130213 | validation: 0.3773751749512715]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3470711310488196		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.3470711310488196 | validation: 0.2343632175848294]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41839553302285704		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.41839553302285704 | validation: 0.3916869283931965]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119014259518809		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3119014259518809 | validation: 0.2768388472444056]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27914326810580575		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.27914326810580575 | validation: 0.3686939008682443]
	TIME [epoch: 11.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37497259851100484		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.37497259851100484 | validation: 0.36597213591180505]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28849376662775583		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.28849376662775583 | validation: 0.24682722956262296]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24474387006106446		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.24474387006106446 | validation: 0.20437697245646363]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23535959448458466		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.23535959448458466 | validation: 0.3368635131983192]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809901136858926		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.2809901136858926 | validation: 0.22481319352513343]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499964395881373		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.2499964395881373 | validation: 0.23596717170742212]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526729426105062		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2526729426105062 | validation: 0.38173432367492655]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30283869474649533		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.30283869474649533 | validation: 0.2834216817591996]
	TIME [epoch: 11.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641289780735949		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2641289780735949 | validation: 0.2848713066949688]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26017240050639895		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.26017240050639895 | validation: 0.27192765168206423]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24112340564313556		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.24112340564313556 | validation: 0.2476734654390472]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305155424687781		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2305155424687781 | validation: 0.2504949113867214]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835193569708187		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.2835193569708187 | validation: 0.29888169175847185]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764680174282989		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2764680174282989 | validation: 0.24216421519212808]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139201372837843		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2139201372837843 | validation: 0.21130539781605223]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2871259799723999		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.2871259799723999 | validation: 0.2764176316149863]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22932967558513143		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.22932967558513143 | validation: 0.28387490197567344]
	TIME [epoch: 11.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25029292418262467		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.25029292418262467 | validation: 0.24276820650358796]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940840291635859		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2940840291635859 | validation: 0.6945747219392412]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46817581364823047		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.46817581364823047 | validation: 0.28827144666268334]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28147530303687684		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.28147530303687684 | validation: 0.2148355297392625]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2193578030176015		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.2193578030176015 | validation: 0.23440660890246093]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2860158746808923		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.2860158746808923 | validation: 0.25697837095715714]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2459472374486053		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.2459472374486053 | validation: 0.20534889320005006]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584068624710269		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.2584068624710269 | validation: 0.22287343880924282]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799427316480459		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.2799427316480459 | validation: 0.20389708361437578]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26680486217010635		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.26680486217010635 | validation: 0.2810191970224532]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23794037896467246		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.23794037896467246 | validation: 0.1830297286748341]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627297258298028		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.2627297258298028 | validation: 0.17383504266763575]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22476716389670015		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.22476716389670015 | validation: 0.199245734011214]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23727932389952083		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.23727932389952083 | validation: 0.24255590294489487]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2384978492596217		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2384978492596217 | validation: 0.23708969415709594]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29754917644395606		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.29754917644395606 | validation: 0.23521731859495895]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25944395988825886		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.25944395988825886 | validation: 0.21463056556900376]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24183478633489727		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.24183478633489727 | validation: 0.23590910659062503]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24693585375394198		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.24693585375394198 | validation: 0.2288992025560214]
	TIME [epoch: 11.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19971639981777461		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.19971639981777461 | validation: 0.22327994603534657]
	TIME [epoch: 11.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789695459516142		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.2789695459516142 | validation: 0.22146760454127523]
	TIME [epoch: 11.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24547736193656494		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.24547736193656494 | validation: 0.1939270643078114]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2330007312758433		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.2330007312758433 | validation: 0.35161402423272575]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707285861497014		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.2707285861497014 | validation: 0.20438510426621115]
	TIME [epoch: 11.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22467914690548774		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.22467914690548774 | validation: 0.24702172995381844]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22216670755907836		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.22216670755907836 | validation: 0.21470682613244566]
	TIME [epoch: 11.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20638029839321262		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.20638029839321262 | validation: 0.19157053767587984]
	TIME [epoch: 11.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23376656810777358		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.23376656810777358 | validation: 0.21432057015077483]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19950121925236175		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.19950121925236175 | validation: 0.2645367165302282]
	TIME [epoch: 11.5 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28292953156427764		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.28292953156427764 | validation: 0.1968748634484259]
	TIME [epoch: 11.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092231689900688		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2092231689900688 | validation: 0.2202636122763085]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22462219690102234		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.22462219690102234 | validation: 0.4193872440262662]
	TIME [epoch: 11.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306200023473584		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.306200023473584 | validation: 0.24394482395013142]
	TIME [epoch: 11.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21805740423972245		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.21805740423972245 | validation: 0.2302453171538991]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2604901458307768		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.2604901458307768 | validation: 0.27458165989424416]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25000280143999853		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.25000280143999853 | validation: 0.2634727834865041]
	TIME [epoch: 11.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24524958224471877		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.24524958224471877 | validation: 0.2402392088091156]
	TIME [epoch: 11.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24077020818217237		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.24077020818217237 | validation: 0.38964088375121775]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812069047018423		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.2812069047018423 | validation: 0.21601562652684309]
	TIME [epoch: 11.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24459054359119897		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.24459054359119897 | validation: 0.3812181856220983]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2979019931262266		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2979019931262266 | validation: 0.267919943994502]
	TIME [epoch: 11.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252253122702252		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.252253122702252 | validation: 0.27993259617377403]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22972191584503884		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.22972191584503884 | validation: 0.24290625769274254]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24129462287640746		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.24129462287640746 | validation: 0.18706384247397068]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914507908843844		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1914507908843844 | validation: 0.22974477842907626]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27568343295423575		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.27568343295423575 | validation: 0.18792187111274192]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23290083116798		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.23290083116798 | validation: 0.241667702817231]
	TIME [epoch: 11.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148839269306339		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.2148839269306339 | validation: 0.21378822579053125]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24579129666406505		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.24579129666406505 | validation: 0.2870775298204834]
	TIME [epoch: 11.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2278774683194567		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.2278774683194567 | validation: 0.2166770682503223]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21611839459367405		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.21611839459367405 | validation: 0.16479465613832317]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19161123892566875		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.19161123892566875 | validation: 0.2335688004799519]
	TIME [epoch: 11.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24539896790291377		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.24539896790291377 | validation: 0.279860189159592]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264839826672533		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.264839826672533 | validation: 0.24939713970948799]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3027903917033681		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3027903917033681 | validation: 0.3217654593549538]
	TIME [epoch: 11.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387556165059955		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.2387556165059955 | validation: 0.21042657701745499]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1902999619905758		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.1902999619905758 | validation: 0.21286546165549855]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204633910619721		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2204633910619721 | validation: 0.18879138485717548]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741159975191113		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.1741159975191113 | validation: 0.2570081426357741]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24453258741808484		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.24453258741808484 | validation: 0.27788338065481094]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2244587073392015		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.2244587073392015 | validation: 0.22050029093351411]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2573792923626739		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.2573792923626739 | validation: 0.19570890253772014]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20878548712707753		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.20878548712707753 | validation: 0.17370429314854197]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1812066043848351		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1812066043848351 | validation: 0.1767902989130492]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20378685189436113		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.20378685189436113 | validation: 0.20404840613742528]
	TIME [epoch: 11.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22270219280355186		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.22270219280355186 | validation: 0.27653802173345693]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22671254834387533		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.22671254834387533 | validation: 0.1865550497823719]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16850902802963688		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.16850902802963688 | validation: 0.16280067394692171]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_765.pth
	Model improved!!!
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18649843470429608		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.18649843470429608 | validation: 0.1491790754479954]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20292935102252357		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.20292935102252357 | validation: 0.19757448254255758]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18469354320677656		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.18469354320677656 | validation: 0.21644858533680658]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21889990068733914		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.21889990068733914 | validation: 0.16768635735446225]
	TIME [epoch: 11.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18025033094868928		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.18025033094868928 | validation: 0.18396466152678817]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505578733947004		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2505578733947004 | validation: 0.20111763631970225]
	TIME [epoch: 11.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20613905333095045		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.20613905333095045 | validation: 0.1903828229132704]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2127645303638493		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2127645303638493 | validation: 0.20366826009859287]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18742729927179128		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.18742729927179128 | validation: 0.1720492919376905]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949699160880912		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1949699160880912 | validation: 0.26362558946874126]
	TIME [epoch: 11.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21390057011316008		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.21390057011316008 | validation: 0.29864758201975]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32853667953384835		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.32853667953384835 | validation: 0.18936687386675602]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2349294694124641		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2349294694124641 | validation: 0.21556904385260459]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19727749386976254		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.19727749386976254 | validation: 0.15150055179176622]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801959989342659		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.1801959989342659 | validation: 0.2257277348599969]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913986526876819		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1913986526876819 | validation: 0.1408860147043126]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18143161173469594		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.18143161173469594 | validation: 0.15137847190046047]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15255401741106894		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.15255401741106894 | validation: 0.29761790502635976]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2841347646053207		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2841347646053207 | validation: 0.1891474831165222]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18271859232789622		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.18271859232789622 | validation: 0.18189712806221714]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2087240809042556		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.2087240809042556 | validation: 0.2558950197252327]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22062287580395262		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.22062287580395262 | validation: 0.23468118739319657]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19107287079942228		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.19107287079942228 | validation: 0.19886733861883804]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1928513230858715		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1928513230858715 | validation: 0.1627351356923173]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805352986367352		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1805352986367352 | validation: 0.16486876199128322]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20457960134882136		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.20457960134882136 | validation: 0.18932220429562005]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17739691822658024		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.17739691822658024 | validation: 0.18439170238049726]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001152449436353		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.2001152449436353 | validation: 0.2709493207427886]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21484157031001683		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.21484157031001683 | validation: 0.14939038894271747]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16867958576927602		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.16867958576927602 | validation: 0.15782402345616003]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19428878336773533		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.19428878336773533 | validation: 0.15710851489769959]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16449040178512958		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.16449040178512958 | validation: 0.18409685735418946]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18742370526036037		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.18742370526036037 | validation: 0.22365110909214367]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036185415512699		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2036185415512699 | validation: 0.17451183354562624]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22884778528625688		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.22884778528625688 | validation: 0.23273497351823325]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21781800949433		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.21781800949433 | validation: 0.21570243287983829]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21843561128995595		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.21843561128995595 | validation: 0.21394362004171016]
	TIME [epoch: 11.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2356958645643968		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2356958645643968 | validation: 0.30148779031617934]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22572092216350792		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.22572092216350792 | validation: 0.1574358641235749]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859333387295707		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1859333387295707 | validation: 0.23629144705860783]
	TIME [epoch: 11.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088481282977984		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.2088481282977984 | validation: 0.22214496148533772]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206767637599626		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.206767637599626 | validation: 0.1579342852102783]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21446426892176879		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.21446426892176879 | validation: 0.15041977241486035]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901205733428519		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1901205733428519 | validation: 0.17450606480168177]
	TIME [epoch: 11.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17148232850575862		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.17148232850575862 | validation: 0.14821076056111776]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16472501955248753		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.16472501955248753 | validation: 0.14377047350421]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17783084891826356		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.17783084891826356 | validation: 0.18392773834310908]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20512329800450507		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.20512329800450507 | validation: 0.18831200740214946]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16464997679857965		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.16464997679857965 | validation: 0.18193082303275676]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17387810697184278		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.17387810697184278 | validation: 0.1352701221112796]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22737667504021997		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.22737667504021997 | validation: 0.16733448242281207]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18220283974776336		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.18220283974776336 | validation: 0.2227053050844206]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19381724179760468		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.19381724179760468 | validation: 0.1881449903126722]
	TIME [epoch: 11.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172916833490819		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2172916833490819 | validation: 0.16754540717825858]
	TIME [epoch: 11.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17855776100791987		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.17855776100791987 | validation: 0.15233558104021327]
	TIME [epoch: 11.5 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616844041195412		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1616844041195412 | validation: 0.14263597400758454]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16192222691530284		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.16192222691530284 | validation: 0.2402456072544808]
	TIME [epoch: 11.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18972725239223193		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.18972725239223193 | validation: 0.21396940833682124]
	TIME [epoch: 11.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22335085802468715		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.22335085802468715 | validation: 0.2758959023953994]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19928919957320881		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.19928919957320881 | validation: 0.14850220571117043]
	TIME [epoch: 11.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462417975164331		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.1462417975164331 | validation: 0.16700948608430885]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643221910308677		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.15643221910308677 | validation: 0.15282650932960454]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15202326434123414		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.15202326434123414 | validation: 0.16115059313018132]
	TIME [epoch: 11.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566171587144286		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.1566171587144286 | validation: 0.1998429592241565]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17671231587045666		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.17671231587045666 | validation: 0.1630249268606198]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15861688848704567		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.15861688848704567 | validation: 0.18800428805365763]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17504995307993793		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.17504995307993793 | validation: 0.12141216051825489]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_832.pth
	Model improved!!!
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15664649733195657		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.15664649733195657 | validation: 0.1577878127127781]
	TIME [epoch: 11.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363524562424834		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.1363524562424834 | validation: 0.14383913515369792]
	TIME [epoch: 11.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611035944174984		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1611035944174984 | validation: 0.18918362650883122]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558873644297646		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.17558873644297646 | validation: 0.15375372187907224]
	TIME [epoch: 11.5 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743118630702097		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.16743118630702097 | validation: 0.14987089769707182]
	TIME [epoch: 11.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466882088290752		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1466882088290752 | validation: 0.16883407139599294]
	TIME [epoch: 11.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18534429683519224		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.18534429683519224 | validation: 0.2016007468617564]
	TIME [epoch: 11.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19521974219170926		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.19521974219170926 | validation: 0.14863970165169035]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16016400838826966		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.16016400838826966 | validation: 0.17356799286940522]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677800449406153		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.1677800449406153 | validation: 0.1546195485684197]
	TIME [epoch: 11.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21193937089486362		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.21193937089486362 | validation: 0.2452708257299909]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251932595876167		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2251932595876167 | validation: 0.2777846073476504]
	TIME [epoch: 11.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24448201245218665		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.24448201245218665 | validation: 0.15582924413496116]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19576229617477497		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.19576229617477497 | validation: 0.2117710955894951]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22123796516551578		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.22123796516551578 | validation: 0.18190331782510683]
	TIME [epoch: 11.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473436702363733		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.1473436702363733 | validation: 0.17049746563142584]
	TIME [epoch: 11.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2087763373919604		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.2087763373919604 | validation: 0.16748273412730305]
	TIME [epoch: 11.5 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19897311335645035		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.19897311335645035 | validation: 0.2193878051606901]
	TIME [epoch: 11.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142939518767953		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.21142939518767953 | validation: 0.14619585853483658]
	TIME [epoch: 11.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193839975544302		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.193839975544302 | validation: 0.1624874154297184]
	TIME [epoch: 11.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16736735875216485		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.16736735875216485 | validation: 0.16479639526845627]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18008452210673492		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.18008452210673492 | validation: 0.16433913949895235]
	TIME [epoch: 11.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18452573210965437		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.18452573210965437 | validation: 0.19174202510104502]
	TIME [epoch: 11.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17250871145449276		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.17250871145449276 | validation: 0.13635204983342333]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1800273202327583		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.1800273202327583 | validation: 0.15225804339235802]
	TIME [epoch: 11.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675682692246728		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.14675682692246728 | validation: 0.21527634738429954]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17972545477410914		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.17972545477410914 | validation: 0.23183828507297605]
	TIME [epoch: 11.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17318928007350964		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.17318928007350964 | validation: 0.14527796077302305]
	TIME [epoch: 11.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19750496440210236		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.19750496440210236 | validation: 0.21759795374161542]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20483128797965552		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.20483128797965552 | validation: 0.13605059028733524]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14533353742756822		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.14533353742756822 | validation: 0.20297003343670622]
	TIME [epoch: 11.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612999105887121		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.1612999105887121 | validation: 0.1531301448781975]
	TIME [epoch: 11.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19307322101892513		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.19307322101892513 | validation: 0.1536055103496966]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14230532632832216		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.14230532632832216 | validation: 0.1535249989038825]
	TIME [epoch: 11.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752551579548847		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.2752551579548847 | validation: 0.19051418347033086]
	TIME [epoch: 11.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16536457970544605		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.16536457970544605 | validation: 0.192612129027154]
	TIME [epoch: 11.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18923471506342063		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.18923471506342063 | validation: 0.13597154191896835]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17143569369957434		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.17143569369957434 | validation: 0.14414897196301366]
	TIME [epoch: 11.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494669310276307		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.1494669310276307 | validation: 0.11969536879044265]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14977845850558305		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.14977845850558305 | validation: 0.17885870212388164]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20839974183359894		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.20839974183359894 | validation: 0.19623885540404548]
	TIME [epoch: 11.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635293872600297		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.1635293872600297 | validation: 0.20673961749183328]
	TIME [epoch: 11.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17927756147102292		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.17927756147102292 | validation: 0.17914938056226404]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16940628548999426		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.16940628548999426 | validation: 0.19597659618845584]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564205629697581		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1564205629697581 | validation: 0.17231576180796337]
	TIME [epoch: 11.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23303168387003143		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.23303168387003143 | validation: 0.17547812275392902]
	TIME [epoch: 11.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476610406791396		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.1476610406791396 | validation: 0.11312876325359385]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13372249728205854		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.13372249728205854 | validation: 0.11939993959908893]
	TIME [epoch: 11.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385870853826374		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.1385870853826374 | validation: 0.11218879459902503]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_881.pth
	Model improved!!!
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13517970121608777		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.13517970121608777 | validation: 0.17864526062837813]
	TIME [epoch: 11.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.175793042791082		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.175793042791082 | validation: 0.18600205165791384]
	TIME [epoch: 11.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20593894574555294		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.20593894574555294 | validation: 0.17147486604697185]
	TIME [epoch: 11.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15614709411664124		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.15614709411664124 | validation: 0.187426795059544]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15093790833049095		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.15093790833049095 | validation: 0.13394929564124072]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558918108834125		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.13558918108834125 | validation: 0.12657813830316686]
	TIME [epoch: 11.5 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13661442777987914		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.13661442777987914 | validation: 0.1601378599905773]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1545718337633976		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.1545718337633976 | validation: 0.11585257933308796]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13009873369421693		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.13009873369421693 | validation: 0.1363255259706785]
	TIME [epoch: 11.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452553775559319		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1452553775559319 | validation: 0.1302322862963166]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819606433178576		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.12819606433178576 | validation: 0.19478743934117163]
	TIME [epoch: 11.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18669598349661262		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.18669598349661262 | validation: 0.1385407545660389]
	TIME [epoch: 11.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420167578641497		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1420167578641497 | validation: 0.13861828374606114]
	TIME [epoch: 11.5 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15830664245734172		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.15830664245734172 | validation: 0.14907416520327826]
	TIME [epoch: 11.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14325638492389578		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.14325638492389578 | validation: 0.15382097850577567]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14534022855940934		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.14534022855940934 | validation: 0.1900221104511526]
	TIME [epoch: 11.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15536214309164215		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.15536214309164215 | validation: 0.1391948589516234]
	TIME [epoch: 11.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1719499650186012		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.1719499650186012 | validation: 0.13299202961242343]
	TIME [epoch: 11.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15169421069287214		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.15169421069287214 | validation: 0.11345892761502327]
	TIME [epoch: 11.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162759373601788		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.12162759373601788 | validation: 0.1832293309054568]
	TIME [epoch: 11.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379173445677873		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.17379173445677873 | validation: 0.1289091637472345]
	TIME [epoch: 11.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13663915527321788		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.13663915527321788 | validation: 0.1541400392641593]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16073076350591092		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.16073076350591092 | validation: 0.13958785096583295]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12277220448963613		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.12277220448963613 | validation: 0.11306269722929567]
	TIME [epoch: 11.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080929198352819		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.12080929198352819 | validation: 0.13519025224464068]
	TIME [epoch: 11.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404605421714194		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.13404605421714194 | validation: 0.12364996760854922]
	TIME [epoch: 11.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20830592897769012		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.20830592897769012 | validation: 0.24866910169646686]
	TIME [epoch: 11.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677616845537269		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.1677616845537269 | validation: 0.1568560341838903]
	TIME [epoch: 11.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16095292117686638		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.16095292117686638 | validation: 0.13203309068777197]
	TIME [epoch: 11.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318656902002933		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1318656902002933 | validation: 0.12184172564871083]
	TIME [epoch: 11.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13380691188429386		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.13380691188429386 | validation: 0.11189303777828084]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_912.pth
	Model improved!!!
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988274777878592		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.12988274777878592 | validation: 0.1527158305780531]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625404175362353		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.14625404175362353 | validation: 0.1439978054587832]
	TIME [epoch: 11.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13598952224865837		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.13598952224865837 | validation: 0.1634477545978215]
	TIME [epoch: 11.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310265892016242		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.15310265892016242 | validation: 0.17081743816745396]
	TIME [epoch: 11.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382114693831861		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1382114693831861 | validation: 0.14490191475156075]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1258816378653759		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.1258816378653759 | validation: 0.1252690331656067]
	TIME [epoch: 11.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13032160197361106		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.13032160197361106 | validation: 0.20438294872392285]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1784397806610049		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.1784397806610049 | validation: 0.13451620944423806]
	TIME [epoch: 11.5 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526260941777564		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.1526260941777564 | validation: 0.17047724795024288]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13880594921484385		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.13880594921484385 | validation: 0.1631366158071514]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18464696727393362		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.18464696727393362 | validation: 0.20961195759914972]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18856816466332837		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.18856816466332837 | validation: 0.15455112408957278]
	TIME [epoch: 11.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13541995397851891		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.13541995397851891 | validation: 0.12586498548937824]
	TIME [epoch: 11.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461114758445717		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.12461114758445717 | validation: 0.1072407362584655]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_926.pth
	Model improved!!!
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193528324438089		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.1193528324438089 | validation: 0.10815948059067351]
	TIME [epoch: 11.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12517701065882225		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.12517701065882225 | validation: 0.11967812861673574]
	TIME [epoch: 11.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1199957925166669		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.1199957925166669 | validation: 0.11740221896163339]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13750633728580489		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.13750633728580489 | validation: 0.12399374695462863]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883853598116742		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.14883853598116742 | validation: 0.19521669385728188]
	TIME [epoch: 11.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707930854453043		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.1707930854453043 | validation: 0.12726495261722767]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439897304311605		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.1439897304311605 | validation: 0.10283218626589669]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_933.pth
	Model improved!!!
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12453944007981303		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12453944007981303 | validation: 0.1671722649853583]
	TIME [epoch: 11.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14625695431508626		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.14625695431508626 | validation: 0.11726397591294366]
	TIME [epoch: 11.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200391935167964		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.1200391935167964 | validation: 0.12779416241511948]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965563136089452		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.14965563136089452 | validation: 0.17113528261991942]
	TIME [epoch: 11.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14802366256882643		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.14802366256882643 | validation: 0.1262828240461143]
	TIME [epoch: 11.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11411411972335718		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.11411411972335718 | validation: 0.1260455485894545]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13829936566650802		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.13829936566650802 | validation: 0.1311833666414473]
	TIME [epoch: 11.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15295533344913717		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.15295533344913717 | validation: 0.15912691645093094]
	TIME [epoch: 11.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17849573697701415		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.17849573697701415 | validation: 0.1184770469565801]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17801863917188074		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.17801863917188074 | validation: 0.14686855287529452]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18300938993800073		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.18300938993800073 | validation: 0.13506560516645955]
	TIME [epoch: 11.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14524608495336216		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.14524608495336216 | validation: 0.19991761798844707]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17319093219780135		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.17319093219780135 | validation: 0.15250265465259333]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150449372924838		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.150449372924838 | validation: 0.14059095590692294]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13158823940806352		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.13158823940806352 | validation: 0.12313502523525519]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477804605398682		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12477804605398682 | validation: 0.11203623313073231]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13105577726567788		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.13105577726567788 | validation: 0.18667140301966292]
	TIME [epoch: 11.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16806980734189342		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.16806980734189342 | validation: 0.14692145135335902]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621689363326863		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1621689363326863 | validation: 0.1563263235662904]
	TIME [epoch: 11.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14826618584650902		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.14826618584650902 | validation: 0.13717123567801146]
	TIME [epoch: 11.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530753687508289		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.1530753687508289 | validation: 0.11009364457477018]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398004702610995		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1398004702610995 | validation: 0.13409195736968155]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397332152600469		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.1397332152600469 | validation: 0.17518057395826211]
	TIME [epoch: 11.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16687464626712883		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.16687464626712883 | validation: 0.13136244746917444]
	TIME [epoch: 11.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14624328033238876		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.14624328033238876 | validation: 0.12526787717252272]
	TIME [epoch: 11.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13011966998955096		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.13011966998955096 | validation: 0.12797394024464726]
	TIME [epoch: 11.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989721722663215		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.13989721722663215 | validation: 0.12074001422751025]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13958823622876126		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.13958823622876126 | validation: 0.111006662296266]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231127165512375		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.12231127165512375 | validation: 0.1329444552980529]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044414305954833		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.14044414305954833 | validation: 0.11134931231469533]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11985591342777172		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.11985591342777172 | validation: 0.11786465590937974]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384083263078674		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.12384083263078674 | validation: 0.1105100719579345]
	TIME [epoch: 11.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12013271603918363		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.12013271603918363 | validation: 0.10287211841508796]
	TIME [epoch: 11.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13420274953953817		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.13420274953953817 | validation: 0.14602366377875078]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379359416892068		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1379359416892068 | validation: 0.10268018199939574]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_968.pth
	Model improved!!!
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10501655267763961		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10501655267763961 | validation: 0.1070274096936051]
	TIME [epoch: 11.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377664018915078		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.1377664018915078 | validation: 0.14159450712288876]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12352144384158194		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.12352144384158194 | validation: 0.15286705804592166]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13547875994163194		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.13547875994163194 | validation: 0.1272437965129068]
	TIME [epoch: 11.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14584884895607686		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.14584884895607686 | validation: 0.23149977318095302]
	TIME [epoch: 11.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19723491740800797		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.19723491740800797 | validation: 0.13999280748575443]
	TIME [epoch: 11.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515640216251547		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.12515640216251547 | validation: 0.11055788087626786]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16905711940684687		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.16905711940684687 | validation: 0.17904475972600403]
	TIME [epoch: 11.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13699214770762133		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.13699214770762133 | validation: 0.1398698327959147]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13840121813983777		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.13840121813983777 | validation: 0.15451701463074777]
	TIME [epoch: 11.5 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17506057461928431		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.17506057461928431 | validation: 0.23526292670809093]
	TIME [epoch: 11.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18347872653171765		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.18347872653171765 | validation: 0.12004055134875205]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12256711686562541		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.12256711686562541 | validation: 0.10047914603882294]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_981.pth
	Model improved!!!
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857597024624882		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.10857597024624882 | validation: 0.09998783937286737]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_982.pth
	Model improved!!!
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586486554652566		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.10586486554652566 | validation: 0.11845303387192925]
	TIME [epoch: 11.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327616264690676		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.1327616264690676 | validation: 0.143780789276746]
	TIME [epoch: 11.5 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436343442584113		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1436343442584113 | validation: 0.10276491097224273]
	TIME [epoch: 11.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026285074310403		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.12026285074310403 | validation: 0.12267706629612424]
	TIME [epoch: 11.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11526302099339766		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.11526302099339766 | validation: 0.09175788319140163]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11059068918876813		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.11059068918876813 | validation: 0.11785181053702229]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11250288549762634		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11250288549762634 | validation: 0.13413429709505517]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833948301790966		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.1833948301790966 | validation: 0.18652832094179503]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13934829140006733		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.13934829140006733 | validation: 0.12354516697579765]
	TIME [epoch: 11.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11652779040645345		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.11652779040645345 | validation: 0.11775159367588163]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13167129732037375		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.13167129732037375 | validation: 0.11551793674899977]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565781665046832		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.1565781665046832 | validation: 0.11793860024191627]
	TIME [epoch: 11.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11481316930982317		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.11481316930982317 | validation: 0.12221287508742065]
	TIME [epoch: 11.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12501024012256204		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.12501024012256204 | validation: 0.12253799589797644]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12113080787972966		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.12113080787972966 | validation: 0.10773655161021843]
	TIME [epoch: 11.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482093665040544		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.11482093665040544 | validation: 0.11168106757789042]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12908426735941733		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.12908426735941733 | validation: 0.12623621296175952]
	TIME [epoch: 11.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13672467159503895		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.13672467159503895 | validation: 0.11864842965586853]
	TIME [epoch: 11.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11948225801611001		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.11948225801611001 | validation: 0.10773402565210156]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390879051769636		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.1390879051769636 | validation: 0.09715896811622504]
	TIME [epoch: 11.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13070483324271986		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.13070483324271986 | validation: 0.12763009525415542]
	TIME [epoch: 11.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681778314657188		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.12681778314657188 | validation: 0.12123708953407494]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299548005976832		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.12299548005976832 | validation: 0.17813562773667055]
	TIME [epoch: 11.6 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17303324727074554		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.17303324727074554 | validation: 0.20271867983928377]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16874144368006824		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.16874144368006824 | validation: 0.1621694671870705]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13732123877010005		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.13732123877010005 | validation: 0.12723056633281085]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343350917465662		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1343350917465662 | validation: 0.13337406182020492]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14136034751790863		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.14136034751790863 | validation: 0.14334066139500073]
	TIME [epoch: 11.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12643997399934173		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.12643997399934173 | validation: 0.11525257812642561]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300520546539393		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.11300520546539393 | validation: 0.11801401425230981]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283481046993564		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.1283481046993564 | validation: 0.192630568157778]
	TIME [epoch: 11.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16378976060389291		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.16378976060389291 | validation: 0.13726804072610344]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13554384203972047		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.13554384203972047 | validation: 0.12957074198543034]
	TIME [epoch: 11.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231058438728001		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.12231058438728001 | validation: 0.13510898407122113]
	TIME [epoch: 11.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196976156904587		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1196976156904587 | validation: 0.11820921038547631]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11929026321715916		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.11929026321715916 | validation: 0.10690895884047805]
	TIME [epoch: 11.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237361401153313		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.12237361401153313 | validation: 0.16312810433687908]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331750832780247		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1331750832780247 | validation: 0.12335375304307386]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837411654676155		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.10837411654676155 | validation: 0.11291633760710733]
	TIME [epoch: 11.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11983404173347263		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.11983404173347263 | validation: 0.10480913730197063]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023554554216662		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.1023554554216662 | validation: 0.10853481390389888]
	TIME [epoch: 11.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086988538995402		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.10086988538995402 | validation: 0.1012134484542374]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11386385491737969		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.11386385491737969 | validation: 0.09536916125274403]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012346839196792		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.1012346839196792 | validation: 0.10430892374835167]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689603605545431		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.09689603605545431 | validation: 0.10947517280611294]
	TIME [epoch: 11.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947179174637856		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.11947179174637856 | validation: 0.10069481789290397]
	TIME [epoch: 11.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452109898453354		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.10452109898453354 | validation: 0.10688567563555555]
	TIME [epoch: 11.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11316334700866026		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.11316334700866026 | validation: 0.12164694509216599]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12312863729569845		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.12312863729569845 | validation: 0.11931619575262543]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786855764430891		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.13786855764430891 | validation: 0.13164904353863752]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16432692871346438		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.16432692871346438 | validation: 0.10806787664427737]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11860622667630244		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.11860622667630244 | validation: 0.1151445905145034]
	TIME [epoch: 11.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12059176187139273		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.12059176187139273 | validation: 0.108315140745484]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612755932484434		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.11612755932484434 | validation: 0.11018445329042464]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11104220038733711		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.11104220038733711 | validation: 0.12346031689562441]
	TIME [epoch: 11.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925632435212674		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.11925632435212674 | validation: 0.10008546643669658]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12054704946536511		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.12054704946536511 | validation: 0.12458239365354404]
	TIME [epoch: 11.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11746599389026705		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.11746599389026705 | validation: 0.11206733474502294]
	TIME [epoch: 11.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685785945508251		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.11685785945508251 | validation: 0.19372861100574235]
	TIME [epoch: 11.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13949033934598573		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.13949033934598573 | validation: 0.12964151086065173]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11890243063109306		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.11890243063109306 | validation: 0.09911483175017242]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09800403465017346		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.09800403465017346 | validation: 0.1002505032373587]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111957318078318		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.10111957318078318 | validation: 0.08795491165268368]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09970492167564887		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.09970492167564887 | validation: 0.12313543456491197]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1107148270910493		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1107148270910493 | validation: 0.07411915646016343]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1047.pth
	Model improved!!!
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09396460826319616		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.09396460826319616 | validation: 0.1165729475907828]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14316139792628152		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.14316139792628152 | validation: 0.14782925222313525]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301643540806184		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.1301643540806184 | validation: 0.09131237182561343]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956931076673994		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.12956931076673994 | validation: 0.13373670657497133]
	TIME [epoch: 11.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12535739032773174		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.12535739032773174 | validation: 0.09828357658466821]
	TIME [epoch: 11.5 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006908860789468		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.1006908860789468 | validation: 0.10720122374826555]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056390666956658		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1056390666956658 | validation: 0.09944721196031232]
	TIME [epoch: 11.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002276497251903		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.1002276497251903 | validation: 0.08971226756263163]
	TIME [epoch: 11.5 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770658188344719		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10770658188344719 | validation: 0.11020298991272034]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10644447097675655		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.10644447097675655 | validation: 0.1166666978391056]
	TIME [epoch: 11.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957641403752512		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.10957641403752512 | validation: 0.09734850759107527]
	TIME [epoch: 11.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11525927268312788		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.11525927268312788 | validation: 0.1328461335034411]
	TIME [epoch: 11.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11847814052268935		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.11847814052268935 | validation: 0.10638451738202317]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065838874437477		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.1065838874437477 | validation: 0.10428006488544142]
	TIME [epoch: 11.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989581558575863		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.10989581558575863 | validation: 0.1280817987535503]
	TIME [epoch: 11.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13137104067199235		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.13137104067199235 | validation: 0.10430632538437565]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12174709058539658		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.12174709058539658 | validation: 0.13893777922634523]
	TIME [epoch: 11.5 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13363598689687498		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.13363598689687498 | validation: 0.14162069777264266]
	TIME [epoch: 11.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470504597167261		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.1470504597167261 | validation: 0.13101200577193198]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521355317461626		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.11521355317461626 | validation: 0.10826126966540574]
	TIME [epoch: 11.5 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11342543079221556		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.11342543079221556 | validation: 0.12898014580315872]
	TIME [epoch: 11.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718421308671442		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.11718421308671442 | validation: 0.09779282661415048]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374114784313772		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.10374114784313772 | validation: 0.09709151003391962]
	TIME [epoch: 11.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161516045365881		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1161516045365881 | validation: 0.10455325443313761]
	TIME [epoch: 11.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206649033266206		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.15206649033266206 | validation: 0.1786947869082669]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586969012334607		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.1586969012334607 | validation: 0.12231513755117301]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435030331144825		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.12435030331144825 | validation: 0.1571233114807075]
	TIME [epoch: 11.5 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11984865249510808		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.11984865249510808 | validation: 0.09898563898962279]
	TIME [epoch: 11.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09745003658408134		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.09745003658408134 | validation: 0.11500134190350472]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093578096266035		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.11093578096266035 | validation: 0.09629119700459007]
	TIME [epoch: 11.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767996844989673		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.10767996844989673 | validation: 0.11160335592645171]
	TIME [epoch: 11.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10614598307356948		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.10614598307356948 | validation: 0.10274033366810753]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11116192336409816		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.11116192336409816 | validation: 0.12267603147025956]
	TIME [epoch: 11.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11295438209151501		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.11295438209151501 | validation: 0.11879806513390058]
	TIME [epoch: 11.5 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277956383075017		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.1277956383075017 | validation: 0.09212921511698607]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471860014376304		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.10471860014376304 | validation: 0.1085395112403641]
	TIME [epoch: 11.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11658589558941082		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.11658589558941082 | validation: 0.09643111983983897]
	TIME [epoch: 11.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695894835996836		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.10695894835996836 | validation: 0.1382582892264782]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467907062200953		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1467907062200953 | validation: 0.12342936039815518]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13500543632794804		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.13500543632794804 | validation: 0.10948342932169162]
	TIME [epoch: 11.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10997785125636877		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.10997785125636877 | validation: 0.10483806496137937]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10152472646938297		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.10152472646938297 | validation: 0.10354539410234168]
	TIME [epoch: 11.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054049541218735		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.10054049541218735 | validation: 0.10823946580559422]
	TIME [epoch: 11.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10187511625922652		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.10187511625922652 | validation: 0.10589141276086692]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683489818037628		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.10683489818037628 | validation: 0.09184566921987415]
	TIME [epoch: 11.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10475161010706532		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.10475161010706532 | validation: 0.12062403723838384]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12133092422006596		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.12133092422006596 | validation: 0.11453652513131381]
	TIME [epoch: 11.5 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973640351632107		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.0973640351632107 | validation: 0.10238092924619585]
	TIME [epoch: 11.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10228350732428572		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.10228350732428572 | validation: 0.12919932570604165]
	TIME [epoch: 11.5 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390594154774868		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1390594154774868 | validation: 0.13712047453290363]
	TIME [epoch: 11.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12064621328758604		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.12064621328758604 | validation: 0.1156821706987154]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11324940894274461		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11324940894274461 | validation: 0.09749947811730782]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10807540181072732		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.10807540181072732 | validation: 0.11351907270961807]
	TIME [epoch: 11.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861579507219543		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.10861579507219543 | validation: 0.1050019647827771]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10186759234052942		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.10186759234052942 | validation: 0.09829219069380792]
	TIME [epoch: 11.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501091997638416		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.11501091997638416 | validation: 0.09413507777305484]
	TIME [epoch: 11.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034327807743856		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.10034327807743856 | validation: 0.09173566426589776]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658769452693246		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09658769452693246 | validation: 0.10639125943521116]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10873290068650461		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.10873290068650461 | validation: 0.10214272982660706]
	TIME [epoch: 11.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556315445817565		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.09556315445817565 | validation: 0.08953571885357345]
	TIME [epoch: 11.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139690980201463		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.10139690980201463 | validation: 0.09227609075980236]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10250149844659594		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.10250149844659594 | validation: 0.09003874973240551]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220061490337144		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.10220061490337144 | validation: 0.11556054490929572]
	TIME [epoch: 11.5 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034752693609911		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.12034752693609911 | validation: 0.13332503953710523]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725626622343994		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.10725626622343994 | validation: 0.09587867650318103]
	TIME [epoch: 11.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974198466662506		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.11974198466662506 | validation: 0.1085148586625332]
	TIME [epoch: 11.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433719849553883		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.11433719849553883 | validation: 0.11056636794995224]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10872488899369301		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.10872488899369301 | validation: 0.1312818885673014]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12930369530012206		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.12930369530012206 | validation: 0.10608092253284351]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037778374263696		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.10037778374263696 | validation: 0.09850535347265002]
	TIME [epoch: 11.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1045301741689095		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.1045301741689095 | validation: 0.15427651154711117]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509084300870217		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.1509084300870217 | validation: 0.1070715586671861]
	TIME [epoch: 11.5 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13602526571442414		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.13602526571442414 | validation: 0.10971308881943692]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036002376568244		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.10036002376568244 | validation: 0.09717085585674445]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10428029654637944		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.10428029654637944 | validation: 0.0968502248829689]
	TIME [epoch: 11.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663564540665628		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.10663564540665628 | validation: 0.09450321807618492]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044847202146191		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.11044847202146191 | validation: 0.12210035816128123]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13055115161071373		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.13055115161071373 | validation: 0.10432576380536705]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11396558854835968		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.11396558854835968 | validation: 0.0920850098169603]
	TIME [epoch: 11.5 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10106915588862425		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.10106915588862425 | validation: 0.12088942504429284]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12224433685388213		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.12224433685388213 | validation: 0.1133895065004954]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296469970031637		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.1296469970031637 | validation: 0.13502371788014386]
	TIME [epoch: 11.5 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12085425564970213		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.12085425564970213 | validation: 0.08697127573981363]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09752188180546555		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.09752188180546555 | validation: 0.10292757464760122]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793321563152751		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.09793321563152751 | validation: 0.08516534382163334]
	TIME [epoch: 11.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09487377570410713		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.09487377570410713 | validation: 0.09102249073538562]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10189091368225907		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.10189091368225907 | validation: 0.0930669757344472]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10929204871565026		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.10929204871565026 | validation: 0.1226993994996245]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190171502994815		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.12190171502994815 | validation: 0.10039213505720311]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452073349799682		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.11452073349799682 | validation: 0.10771697631271238]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522162240118775		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.11522162240118775 | validation: 0.14927535726752753]
	TIME [epoch: 11.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13779971877259437		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.13779971877259437 | validation: 0.09262665359079884]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188154686384026		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.09188154686384026 | validation: 0.10710802689283275]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866728655677267		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.10866728655677267 | validation: 0.09718242164713081]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09949719127160811		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.09949719127160811 | validation: 0.09668758256670117]
	TIME [epoch: 11.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658168784012142		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.09658168784012142 | validation: 0.09056666558006629]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09033145267831755		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.09033145267831755 | validation: 0.08981156705520663]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09142907429105027		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.09142907429105027 | validation: 0.10559058049412393]
	TIME [epoch: 11.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10218701091151144		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.10218701091151144 | validation: 0.10981348361992786]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832433896836755		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.10832433896836755 | validation: 0.08203887915537653]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909894822877867		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.08909894822877867 | validation: 0.0933986188299621]
	TIME [epoch: 11.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0975478537424638		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0975478537424638 | validation: 0.10277236058082605]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409932810759058		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.10409932810759058 | validation: 0.08901984611122504]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111474898737795		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10111474898737795 | validation: 0.0917551509991049]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09363439513694707		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09363439513694707 | validation: 0.0784126753577307]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093484534941222		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.09093484534941222 | validation: 0.09769205042946438]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736865597176871		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.10736865597176871 | validation: 0.0955302514907428]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.094544233105125		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.094544233105125 | validation: 0.07915096472297088]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880747973286263		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.08880747973286263 | validation: 0.08510603373575186]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09549761893386616		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.09549761893386616 | validation: 0.134952065447289]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287358725233541		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.11287358725233541 | validation: 0.07783590921358932]
	TIME [epoch: 11.5 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948269102743442		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.0948269102743442 | validation: 0.0854906464279808]
	TIME [epoch: 11.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10006047106256039		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.10006047106256039 | validation: 0.09700489250258881]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122360966078108		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.11122360966078108 | validation: 0.12566773607933265]
	TIME [epoch: 11.5 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870911190270739		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.10870911190270739 | validation: 0.11029888103787917]
	TIME [epoch: 11.5 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065225276333963		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.1065225276333963 | validation: 0.08862758805789021]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09539742767575372		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.09539742767575372 | validation: 0.11652740978012467]
	TIME [epoch: 11.5 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09624053539978787		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.09624053539978787 | validation: 0.08700267816076312]
	TIME [epoch: 11.5 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660094988480188		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.08660094988480188 | validation: 0.08066439777862364]
	TIME [epoch: 11.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384938171067099		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.09384938171067099 | validation: 0.09915820918583297]
	TIME [epoch: 11.5 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005424225249761		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.1005424225249761 | validation: 0.12502495267648894]
	TIME [epoch: 11.5 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11222760452320107		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.11222760452320107 | validation: 0.09623502165284725]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10515259234680008		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.10515259234680008 | validation: 0.1070067956868891]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10553070745988427		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.10553070745988427 | validation: 0.09922589486145678]
	TIME [epoch: 11.5 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10589853954520326		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.10589853954520326 | validation: 0.10369785876339173]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10270101542342268		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.10270101542342268 | validation: 0.10263470182125307]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10783292595832487		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.10783292595832487 | validation: 0.09854361798778259]
	TIME [epoch: 11.5 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09294229017228177		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.09294229017228177 | validation: 0.08879521322939274]
	TIME [epoch: 11.5 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838065209909184		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.08838065209909184 | validation: 0.07776153187739053]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984617619077623		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.08984617619077623 | validation: 0.0902109094402028]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050187325063062		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.10050187325063062 | validation: 0.09589720673521525]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192826807291167		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.1192826807291167 | validation: 0.0886577395714664]
	TIME [epoch: 11.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09572708522578574		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.09572708522578574 | validation: 0.08850685737022165]
	TIME [epoch: 11.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08884640998721025		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.08884640998721025 | validation: 0.08963218242855112]
	TIME [epoch: 11.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09368114463361843		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.09368114463361843 | validation: 0.10666314949029898]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09729287754020961		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.09729287754020961 | validation: 0.0981538403038427]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09485962117685687		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.09485962117685687 | validation: 0.06746721367262597]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1184.pth
	Model improved!!!
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09160382825338054		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.09160382825338054 | validation: 0.08598485484319934]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09055763078992071		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.09055763078992071 | validation: 0.07313811216601422]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08987483470420402		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.08987483470420402 | validation: 0.08416804238928054]
	TIME [epoch: 11.5 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742365630451547		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.09742365630451547 | validation: 0.14833251241403209]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479731256826483		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.13479731256826483 | validation: 0.09730544419514033]
	TIME [epoch: 11.6 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078114084381694		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.09078114084381694 | validation: 0.09879283608272584]
	TIME [epoch: 11.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10336440492595109		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.10336440492595109 | validation: 0.08047074357159988]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270585452152584		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.09270585452152584 | validation: 0.09412000500157686]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08968078134810664		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.08968078134810664 | validation: 0.11317597933978413]
	TIME [epoch: 11.5 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156776816811753		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.11156776816811753 | validation: 0.12349876688635554]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595849426296899		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.11595849426296899 | validation: 0.1219729084171924]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11776052318547825		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.11776052318547825 | validation: 0.1062804617774475]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673217283871985		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.09673217283871985 | validation: 0.07986250049449943]
	TIME [epoch: 11.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08826112404867116		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08826112404867116 | validation: 0.07739154427582413]
	TIME [epoch: 11.6 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08231942887922923		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08231942887922923 | validation: 0.07638658147307291]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09237217583080487		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.09237217583080487 | validation: 0.09468843604419526]
	TIME [epoch: 11.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09893782569696943		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.09893782569696943 | validation: 0.07885440906741784]
	TIME [epoch: 11.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09179047403786264		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.09179047403786264 | validation: 0.08283020903524552]
	TIME [epoch: 11.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09100239842554454		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.09100239842554454 | validation: 0.08109630870440562]
	TIME [epoch: 11.5 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09054145596232487		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.09054145596232487 | validation: 0.09468084358904001]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875709497663115		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.09875709497663115 | validation: 0.08896572962861782]
	TIME [epoch: 11.6 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09466304301453195		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.09466304301453195 | validation: 0.08992314496975688]
	TIME [epoch: 11.5 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109072458504449		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.109072458504449 | validation: 0.11693020742047708]
	TIME [epoch: 11.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561486322188842		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.09561486322188842 | validation: 0.08257673156148806]
	TIME [epoch: 11.6 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09138146281567573		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.09138146281567573 | validation: 0.11065707290606529]
	TIME [epoch: 11.5 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12496364100461232		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.12496364100461232 | validation: 0.13523789194196625]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124224121121712		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.11124224121121712 | validation: 0.09808054689792822]
	TIME [epoch: 11.6 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09469279774744338		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.09469279774744338 | validation: 0.08828223470109445]
	TIME [epoch: 11.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09621572242757234		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.09621572242757234 | validation: 0.07947567876868314]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0933280060084604		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0933280060084604 | validation: 0.09434974051806688]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10136218493058989		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.10136218493058989 | validation: 0.09868513419050545]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181347978010977		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.10181347978010977 | validation: 0.08621823537356221]
	TIME [epoch: 11.5 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08735436964331093		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.08735436964331093 | validation: 0.09619898452376976]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09847684279568318		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.09847684279568318 | validation: 0.10028126759505213]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09473178513257566		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.09473178513257566 | validation: 0.09187455083497177]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09660545004607654		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.09660545004607654 | validation: 0.10064702505000889]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0959395314375948		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.0959395314375948 | validation: 0.10178121201375544]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09742003335704655		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09742003335704655 | validation: 0.09114538596137038]
	TIME [epoch: 11.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10368917797099247		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.10368917797099247 | validation: 0.14039895495600982]
	TIME [epoch: 11.5 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11352750322877839		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.11352750322877839 | validation: 0.0889101029555162]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08670351043312316		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.08670351043312316 | validation: 0.08131508159827681]
	TIME [epoch: 11.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09243867799634121		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.09243867799634121 | validation: 0.09515754780490127]
	TIME [epoch: 11.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916461132363326		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.09916461132363326 | validation: 0.0957557850024236]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119975024236308		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.1119975024236308 | validation: 0.11479757287712206]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0997923110541004		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0997923110541004 | validation: 0.09232113036526716]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721787634129722		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.09721787634129722 | validation: 0.08363848051948423]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08940018079857377		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.08940018079857377 | validation: 0.08763739776865358]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09402065867245901		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.09402065867245901 | validation: 0.11559189384211119]
	TIME [epoch: 11.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084508283113689		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.1084508283113689 | validation: 0.09931471912442613]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805858072397246		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.09805858072397246 | validation: 0.0873807388589914]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627461751294375		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.08627461751294375 | validation: 0.0859418742612553]
	TIME [epoch: 11.5 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475913118447112		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.08475913118447112 | validation: 0.09512398274289123]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900013367301135		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.09900013367301135 | validation: 0.08533026986286568]
	TIME [epoch: 11.6 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642148732985043		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.08642148732985043 | validation: 0.09909511270582952]
	TIME [epoch: 11.5 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09350977549016316		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.09350977549016316 | validation: 0.08506634318770907]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08932445097038173		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.08932445097038173 | validation: 0.08754435489652951]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10031171662769664		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.10031171662769664 | validation: 0.104965239147025]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09290211280144901		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.09290211280144901 | validation: 0.08349192952300566]
	TIME [epoch: 11.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433057971254153		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.08433057971254153 | validation: 0.08321070271552322]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08609094997151974		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.08609094997151974 | validation: 0.08738399323992478]
	TIME [epoch: 11.6 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553012127567887		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.08553012127567887 | validation: 0.07947604202589259]
	TIME [epoch: 11.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08347120241044936		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.08347120241044936 | validation: 0.07782283482958728]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607336842038751		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.08607336842038751 | validation: 0.08886411909094319]
	TIME [epoch: 11.6 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939256233131036		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0939256233131036 | validation: 0.09037637006708588]
	TIME [epoch: 11.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461646647999464		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.09461646647999464 | validation: 0.09634574860507648]
	TIME [epoch: 11.6 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11224927413345462		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.11224927413345462 | validation: 0.1352815981489054]
	TIME [epoch: 11.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11803405087271625		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.11803405087271625 | validation: 0.07245273779411916]
	TIME [epoch: 11.5 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098014990429125		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.08098014990429125 | validation: 0.10029819249693749]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278769592763865		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.11278769592763865 | validation: 0.11056411483112083]
	TIME [epoch: 11.6 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09209055647396204		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.09209055647396204 | validation: 0.07707937026533963]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251585916566842		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.09251585916566842 | validation: 0.09177652214132782]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0991726199917243		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.0991726199917243 | validation: 0.09418177771328803]
	TIME [epoch: 11.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10144219770992163		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.10144219770992163 | validation: 0.102315361845187]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929198970763325		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.08929198970763325 | validation: 0.0869162737951083]
	TIME [epoch: 11.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462891348154436		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.08462891348154436 | validation: 0.07374932303782933]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104189523368381		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.08104189523368381 | validation: 0.07377492675279858]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911235505446798		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.07911235505446798 | validation: 0.07832072904074183]
	TIME [epoch: 11.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08794961962015754		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.08794961962015754 | validation: 0.08347847548624422]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003376310320037		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.08003376310320037 | validation: 0.07933231242725564]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010629308473492		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09010629308473492 | validation: 0.07977747444518003]
	TIME [epoch: 11.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263469338974151		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.08263469338974151 | validation: 0.06711977042251559]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1265.pth
	Model improved!!!
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08208179987113351		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.08208179987113351 | validation: 0.08502561553043958]
	TIME [epoch: 11.6 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482608238595236		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.09482608238595236 | validation: 0.10411788164234555]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09702794352730038		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.09702794352730038 | validation: 0.08279487284487265]
	TIME [epoch: 11.6 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09766115843270151		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.09766115843270151 | validation: 0.11040587338566332]
	TIME [epoch: 11.6 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10990572001497666		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.10990572001497666 | validation: 0.08148825814155945]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08426619716767682		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.08426619716767682 | validation: 0.07881873551668861]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08976657102044841		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.08976657102044841 | validation: 0.0842725724182834]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09199079893472835		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.09199079893472835 | validation: 0.08251910840378456]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09727988118410744		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.09727988118410744 | validation: 0.08033663828184924]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08515447198922385		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.08515447198922385 | validation: 0.10858472922114906]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10794785021088238		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.10794785021088238 | validation: 0.09623854233006884]
	TIME [epoch: 11.6 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516263849051119		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.08516263849051119 | validation: 0.08267402122111245]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08660502964454998		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.08660502964454998 | validation: 0.0950332136058583]
	TIME [epoch: 11.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452998518059452		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.09452998518059452 | validation: 0.0820376968261712]
	TIME [epoch: 11.6 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639963261938446		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.09639963261938446 | validation: 0.08394744364908846]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104000464796894		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.104000464796894 | validation: 0.13286166627295246]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13161405754705766		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.13161405754705766 | validation: 0.08705213421789801]
	TIME [epoch: 11.6 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08919336507615569		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.08919336507615569 | validation: 0.07974594739794628]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658974336214246		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.09658974336214246 | validation: 0.08459868669510826]
	TIME [epoch: 11.5 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09346569022434273		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.09346569022434273 | validation: 0.08622525113959778]
	TIME [epoch: 11.6 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09379422747638477		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.09379422747638477 | validation: 0.09405001172630754]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10212670953389962		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.10212670953389962 | validation: 0.08876793203557796]
	TIME [epoch: 11.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810346044394493		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.08810346044394493 | validation: 0.0799753574963051]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08453881874385129		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.08453881874385129 | validation: 0.09057476284868582]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09072872651920168		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.09072872651920168 | validation: 0.08422856617750761]
	TIME [epoch: 11.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603035267373743		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.08603035267373743 | validation: 0.08659477356583052]
	TIME [epoch: 11.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09275483122376886		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.09275483122376886 | validation: 0.08337049720769235]
	TIME [epoch: 11.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356753446325752		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.09356753446325752 | validation: 0.09081369002021121]
	TIME [epoch: 11.5 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09078344675687326		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.09078344675687326 | validation: 0.09222894843278866]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08812041638978751		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.08812041638978751 | validation: 0.09058606894338238]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08889114122336633		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.08889114122336633 | validation: 0.09090763704689188]
	TIME [epoch: 11.5 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734667202994356		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.08734667202994356 | validation: 0.08775311874010075]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08293858900676589		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.08293858900676589 | validation: 0.07556801448472462]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07579262551664517		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.07579262551664517 | validation: 0.07025666564755462]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07820301250730383		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.07820301250730383 | validation: 0.09145930685885516]
	TIME [epoch: 11.5 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09018056932073143		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.09018056932073143 | validation: 0.08373774718236436]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08649772561446525		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.08649772561446525 | validation: 0.09390841339543897]
	TIME [epoch: 11.6 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202689282463997		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.09202689282463997 | validation: 0.07874371595787973]
	TIME [epoch: 11.5 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771904759340804		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.08771904759340804 | validation: 0.07033564029482346]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0834847110892445		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.0834847110892445 | validation: 0.07393454531314429]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157849994675512		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.08157849994675512 | validation: 0.07225280929613882]
	TIME [epoch: 11.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08397054004249208		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.08397054004249208 | validation: 0.07427164930591665]
	TIME [epoch: 11.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813893299167286		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.0813893299167286 | validation: 0.072433995807502]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764441442075906		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.07764441442075906 | validation: 0.07999404796304992]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305700365315319		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.08305700365315319 | validation: 0.08670077117273227]
	TIME [epoch: 11.6 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223432627576798		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.10223432627576798 | validation: 0.14342640030123094]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11654489438742358		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.11654489438742358 | validation: 0.09100580650551303]
	TIME [epoch: 11.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0815448665385706		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.0815448665385706 | validation: 0.08028445230083836]
	TIME [epoch: 11.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08008605034190035		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.08008605034190035 | validation: 0.08721166019942458]
	TIME [epoch: 11.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833624363492075		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.0833624363492075 | validation: 0.07934491293022726]
	TIME [epoch: 11.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08432505732487183		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.08432505732487183 | validation: 0.07749669794896914]
	TIME [epoch: 11.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08133869048734117		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.08133869048734117 | validation: 0.0716821820275675]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08160104236133166		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.08160104236133166 | validation: 0.07417364339484482]
	TIME [epoch: 11.6 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07808150200598159		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.07808150200598159 | validation: 0.06704894829438096]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1319.pth
	Model improved!!!
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08302333874485127		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.08302333874485127 | validation: 0.08294145012213919]
	TIME [epoch: 11.6 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928703330999226		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.08928703330999226 | validation: 0.09001853304870185]
	TIME [epoch: 11.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09850460452643275		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.09850460452643275 | validation: 0.10379432404442572]
	TIME [epoch: 11.5 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09034634788892604		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.09034634788892604 | validation: 0.07615415745664059]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802987130151412		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.07802987130151412 | validation: 0.07069268524582933]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08191534247131796		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.08191534247131796 | validation: 0.08203700809856718]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054090241602523		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.08054090241602523 | validation: 0.0712875145317707]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762871588793746		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.07762871588793746 | validation: 0.0754173241308934]
	TIME [epoch: 11.6 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032502566958691		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.08032502566958691 | validation: 0.06397405037172726]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1328.pth
	Model improved!!!
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07682407326642995		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.07682407326642995 | validation: 0.06779469843333585]
	TIME [epoch: 11.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08356994583955003		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.08356994583955003 | validation: 0.08548869934852714]
	TIME [epoch: 11.6 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799287367904426		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0799287367904426 | validation: 0.07608546454521513]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08383003397283904		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.08383003397283904 | validation: 0.08993490550229913]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10459523515311411		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.10459523515311411 | validation: 0.09617661353874425]
	TIME [epoch: 11.6 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08861279151966865		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.08861279151966865 | validation: 0.0745757708644791]
	TIME [epoch: 11.6 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867155734981		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.0867155734981 | validation: 0.0782242559269165]
	TIME [epoch: 11.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08701167682246465		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.08701167682246465 | validation: 0.08388379472203042]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09412565823082916		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.09412565823082916 | validation: 0.07566190086121022]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634898747481065		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.08634898747481065 | validation: 0.07587942408855705]
	TIME [epoch: 11.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668453456770918		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.08668453456770918 | validation: 0.06717588101172217]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063498451626547		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.08063498451626547 | validation: 0.07958902271472407]
	TIME [epoch: 11.6 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08638169304319103		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.08638169304319103 | validation: 0.07513603310525477]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771988303493786		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.0771988303493786 | validation: 0.08673601493034087]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08453536960496333		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.08453536960496333 | validation: 0.08870721476888356]
	TIME [epoch: 11.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08895110272518993		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.08895110272518993 | validation: 0.08801784100802319]
	TIME [epoch: 11.6 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09446303164955744		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.09446303164955744 | validation: 0.10823269731405312]
	TIME [epoch: 11.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10481903722177506		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.10481903722177506 | validation: 0.09538716911871124]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08602825910524127		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08602825910524127 | validation: 0.0746249034259969]
	TIME [epoch: 11.6 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233094863128933		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08233094863128933 | validation: 0.08071700307219873]
	TIME [epoch: 11.5 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08234420702376215		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.08234420702376215 | validation: 0.07842541362122081]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08280399128203733		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.08280399128203733 | validation: 0.072467450618409]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07767943548219865		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.07767943548219865 | validation: 0.08018378779946764]
	TIME [epoch: 11.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939468830386356		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.07939468830386356 | validation: 0.08833944727397756]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07843251266676837		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.07843251266676837 | validation: 0.08049911302870683]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07717015521808787		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.07717015521808787 | validation: 0.0771533127072271]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243941781868602		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.08243941781868602 | validation: 0.08077010746727313]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427863171224179		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.07427863171224179 | validation: 0.08211312411204404]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142080015692059		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.08142080015692059 | validation: 0.10750612114302513]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09636644669594176		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.09636644669594176 | validation: 0.08325446449117839]
	TIME [epoch: 11.6 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084690580944681		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.084690580944681 | validation: 0.08301428153783721]
	TIME [epoch: 11.6 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08128587113966165		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.08128587113966165 | validation: 0.08748755514849688]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08380365068934884		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.08380365068934884 | validation: 0.08221178308692748]
	TIME [epoch: 11.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732770910506789		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.08732770910506789 | validation: 0.08159465993753683]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118388698636624		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.08118388698636624 | validation: 0.09245116489376436]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08628042912119059		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.08628042912119059 | validation: 0.08313834765717756]
	TIME [epoch: 11.5 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154624277410884		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.08154624277410884 | validation: 0.0811035028108614]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737646068704259		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.08737646068704259 | validation: 0.07071612360828936]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121886938194281		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08121886938194281 | validation: 0.07669170860933976]
	TIME [epoch: 11.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046929219693601		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.08046929219693601 | validation: 0.07455926335709454]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08114065028477957		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.08114065028477957 | validation: 0.0799802254617495]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137282641677177		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.08137282641677177 | validation: 0.06962501411791458]
	TIME [epoch: 11.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032227893249222		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.08032227893249222 | validation: 0.07442766788797954]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07671800862050326		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.07671800862050326 | validation: 0.07501324828317067]
	TIME [epoch: 11.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714135048353621		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.07714135048353621 | validation: 0.08900220678866509]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052740452945212		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.08052740452945212 | validation: 0.08535887982639892]
	TIME [epoch: 11.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513325088452492		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.08513325088452492 | validation: 0.0904041394628206]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09161592707511187		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.09161592707511187 | validation: 0.0790275634983304]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157958863764447		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.08157958863764447 | validation: 0.0706818446916372]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07899208852351476		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.07899208852351476 | validation: 0.07534940942685535]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318130259090625		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.08318130259090625 | validation: 0.07656563017772931]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0758068328107789		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.0758068328107789 | validation: 0.07233096916498793]
	TIME [epoch: 11.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07711347638685388		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.07711347638685388 | validation: 0.06984539022468081]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725769394161728		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.0725769394161728 | validation: 0.06021541502621574]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1382.pth
	Model improved!!!
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830710934126834		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.0830710934126834 | validation: 0.08248759732187225]
	TIME [epoch: 11.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087689648616016		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.087689648616016 | validation: 0.08350931766811799]
	TIME [epoch: 11.5 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0845373061352052		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.0845373061352052 | validation: 0.07183845402695897]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08096636350152733		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.08096636350152733 | validation: 0.0754126936381817]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08489699591906102		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.08489699591906102 | validation: 0.06620307583044356]
	TIME [epoch: 11.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08205721334243689		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.08205721334243689 | validation: 0.08205771010656808]
	TIME [epoch: 11.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07710115936998353		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.07710115936998353 | validation: 0.07759571660928853]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820207885735913		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.0820207885735913 | validation: 0.07353877548963916]
	TIME [epoch: 11.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07992311477549327		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.07992311477549327 | validation: 0.07860850201719333]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757723888736864		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.07757723888736864 | validation: 0.07850122915682055]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0790236429313195		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.0790236429313195 | validation: 0.07114162939800746]
	TIME [epoch: 11.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775219259300759		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.07775219259300759 | validation: 0.0710622502117353]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811423630663128		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.0811423630663128 | validation: 0.08580244001602927]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08162916412177913		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.08162916412177913 | validation: 0.06470942313440901]
	TIME [epoch: 11.5 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08092885348840825		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.08092885348840825 | validation: 0.0742870496379092]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820584468133923		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.0820584468133923 | validation: 0.07856774935042583]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07658397160930361		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.07658397160930361 | validation: 0.07649733113597262]
	TIME [epoch: 11.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08605448999284633		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.08605448999284633 | validation: 0.07668699897787842]
	TIME [epoch: 11.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08051058610313333		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.08051058610313333 | validation: 0.08205007221062853]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08827856839213118		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.08827856839213118 | validation: 0.08767183777297617]
	TIME [epoch: 11.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953498452376327		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.08953498452376327 | validation: 0.06717870522771895]
	TIME [epoch: 11.5 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408234507227608		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.07408234507227608 | validation: 0.07694694385120286]
	TIME [epoch: 11.6 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200569419963934		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.08200569419963934 | validation: 0.08366102872050206]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930364760991788		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.07930364760991788 | validation: 0.07608704992604218]
	TIME [epoch: 11.5 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108263286870762		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.08108263286870762 | validation: 0.07951672250085992]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08170073641790271		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.08170073641790271 | validation: 0.07598667886677055]
	TIME [epoch: 11.6 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08207650911937232		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.08207650911937232 | validation: 0.08610562883775316]
	TIME [epoch: 11.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0918144435153256		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.0918144435153256 | validation: 0.07881539651305185]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849110602663722		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.0849110602663722 | validation: 0.07550938444346775]
	TIME [epoch: 11.6 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955336395648568		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.07955336395648568 | validation: 0.08135335003741714]
	TIME [epoch: 11.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533236820194724		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.08533236820194724 | validation: 0.08380760511047627]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08483148903358045		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.08483148903358045 | validation: 0.0817665051041691]
	TIME [epoch: 11.6 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914890541982904		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.09914890541982904 | validation: 0.10154065537026755]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841804885501274		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.09841804885501274 | validation: 0.08032587848630449]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08134720512159077		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.08134720512159077 | validation: 0.07316499539123308]
	TIME [epoch: 11.6 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0842006087926435		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0842006087926435 | validation: 0.0843545490550425]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909252775407327		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.07909252775407327 | validation: 0.076961369766681]
	TIME [epoch: 11.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297573896076166		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.07297573896076166 | validation: 0.06382159917112952]
	TIME [epoch: 11.6 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715846064644668		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.0715846064644668 | validation: 0.0688317495010696]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780101515403937		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.0780101515403937 | validation: 0.08157599956559963]
	TIME [epoch: 11.5 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07971505724523138		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.07971505724523138 | validation: 0.0698508528741285]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911338694136932		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.07911338694136932 | validation: 0.06823281992511054]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07681060826325045		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.07681060826325045 | validation: 0.06879805629036644]
	TIME [epoch: 11.5 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676985050400625		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.07676985050400625 | validation: 0.06755615826441509]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07746121226922989		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.07746121226922989 | validation: 0.06072513846490079]
	TIME [epoch: 11.6 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450498981878004		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.07450498981878004 | validation: 0.06901524035477619]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07570425797385905		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.07570425797385905 | validation: 0.0689220400491669]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07549736539081772		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.07549736539081772 | validation: 0.06199944545054446]
	TIME [epoch: 11.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039972818007204		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.08039972818007204 | validation: 0.0744971948426531]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688076667715499		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.07688076667715499 | validation: 0.06627254804724743]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07971539433684427		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.07971539433684427 | validation: 0.0684988247055079]
	TIME [epoch: 11.6 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07822469067322615		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.07822469067322615 | validation: 0.07029975263641115]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863674401746507		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.0863674401746507 | validation: 0.08091410136681265]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820257244014308		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.0820257244014308 | validation: 0.07720501862383039]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812425078428321		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.0812425078428321 | validation: 0.08113022950800769]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09259769358690255		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.09259769358690255 | validation: 0.07664708669647076]
	TIME [epoch: 11.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222673425134328		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.08222673425134328 | validation: 0.0675002738826781]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08192365378147728		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.08192365378147728 | validation: 0.0657437404620567]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672182145564449		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.07672182145564449 | validation: 0.07195227304336427]
	TIME [epoch: 11.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312409723172053		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.07312409723172053 | validation: 0.0761712620087079]
	TIME [epoch: 11.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08024174018849543		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.08024174018849543 | validation: 0.06589471452419055]
	TIME [epoch: 11.6 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07608646421845636		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.07608646421845636 | validation: 0.07458236682748293]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07901436068568429		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.07901436068568429 | validation: 0.08202944611158358]
	TIME [epoch: 11.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07834378063879338		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.07834378063879338 | validation: 0.07954229711662303]
	TIME [epoch: 11.6 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08141930124269697		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.08141930124269697 | validation: 0.07391613822178221]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046222566536115		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.08046222566536115 | validation: 0.05874973677109429]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1448.pth
	Model improved!!!
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022101931595318		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08022101931595318 | validation: 0.0715444415424107]
	TIME [epoch: 11.6 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08066867807117221		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.08066867807117221 | validation: 0.06983494049813142]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08005232977848964		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.08005232977848964 | validation: 0.08703812378617545]
	TIME [epoch: 11.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10275743995060724		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.10275743995060724 | validation: 0.08094629757093749]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08769234026817417		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.08769234026817417 | validation: 0.07752092781071758]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07993079538090009		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.07993079538090009 | validation: 0.06634935596213408]
	TIME [epoch: 11.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07397712739585158		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.07397712739585158 | validation: 0.07527621689540002]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07634252084840777		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.07634252084840777 | validation: 0.07357524027910228]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776438889212186		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.0776438889212186 | validation: 0.06703399620890445]
	TIME [epoch: 11.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523490272969897		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.07523490272969897 | validation: 0.06689455490631596]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07587911964159623		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.07587911964159623 | validation: 0.06927150202980017]
	TIME [epoch: 11.6 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849624791507775		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.0849624791507775 | validation: 0.06775857154487058]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08210405613256844		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.08210405613256844 | validation: 0.060651943895715606]
	TIME [epoch: 11.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0750196269691252		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.0750196269691252 | validation: 0.06946796770855032]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757305842830753		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.07757305842830753 | validation: 0.07078052778313473]
	TIME [epoch: 11.6 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07553668757133185		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.07553668757133185 | validation: 0.06805714448258865]
	TIME [epoch: 11.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07685549726162295		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.07685549726162295 | validation: 0.07347609554828477]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07298023625326566		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.07298023625326566 | validation: 0.05998655037024227]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07432228321685255		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.07432228321685255 | validation: 0.06216864225603338]
	TIME [epoch: 11.5 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07448538130887834		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.07448538130887834 | validation: 0.07407441104761843]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08477052106131225		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.08477052106131225 | validation: 0.07637005521302419]
	TIME [epoch: 11.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07489802073458918		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.07489802073458918 | validation: 0.07279892464885887]
	TIME [epoch: 11.5 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07577072705417406		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.07577072705417406 | validation: 0.07789472239773503]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0805727274974133		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.0805727274974133 | validation: 0.07060914797877121]
	TIME [epoch: 11.6 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07585973460787826		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.07585973460787826 | validation: 0.07586807252056604]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555362341756165		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.07555362341756165 | validation: 0.07045472113534007]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076480890737761		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.076480890737761 | validation: 0.07674761262297526]
	TIME [epoch: 11.6 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07980528324228695		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.07980528324228695 | validation: 0.07054281460956308]
	TIME [epoch: 11.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07744429198627195		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.07744429198627195 | validation: 0.07002781187834113]
	TIME [epoch: 11.5 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805897850161499		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.07805897850161499 | validation: 0.0754322940916059]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07074793628308268		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.07074793628308268 | validation: 0.0671088586483846]
	TIME [epoch: 11.6 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07384540390440257		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.07384540390440257 | validation: 0.07348975690167218]
	TIME [epoch: 11.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408914549203317		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.07408914549203317 | validation: 0.07449259489752172]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467460007531714		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.07467460007531714 | validation: 0.0753024781021404]
	TIME [epoch: 11.6 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07373586312082142		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.07373586312082142 | validation: 0.07304296537376892]
	TIME [epoch: 11.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08037570989818407		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.08037570989818407 | validation: 0.07898177513006754]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824197781910846		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0824197781910846 | validation: 0.08841970446468682]
	TIME [epoch: 11.6 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08981448003408818		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.08981448003408818 | validation: 0.0858100021291035]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793284206280465		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.0793284206280465 | validation: 0.06614311942758377]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07780015417435555		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.07780015417435555 | validation: 0.07729573979298357]
	TIME [epoch: 11.6 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07579018038304756		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.07579018038304756 | validation: 0.06703111309380946]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0807453855719285		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.0807453855719285 | validation: 0.08476251536425142]
	TIME [epoch: 11.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121104494916898		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.08121104494916898 | validation: 0.07739812161815686]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08014953026111372		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.08014953026111372 | validation: 0.07926071734547492]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08049805136827479		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.08049805136827479 | validation: 0.07763381782423982]
	TIME [epoch: 11.5 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022226235753256		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.08022226235753256 | validation: 0.07718271573669543]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07858348794146888		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.07858348794146888 | validation: 0.08240258521860294]
	TIME [epoch: 11.6 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661629778999765		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.07661629778999765 | validation: 0.06878014874085828]
	TIME [epoch: 11.5 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08038270721596767		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.08038270721596767 | validation: 0.0700453155426529]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07518490796386729		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.07518490796386729 | validation: 0.06612301310305266]
	TIME [epoch: 11.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07463606797387827		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.07463606797387827 | validation: 0.06897383949452046]
	TIME [epoch: 11.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0722983511616151		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.0722983511616151 | validation: 0.07027700298344187]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561869418081693		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.07561869418081693 | validation: 0.0766971633626626]
	TIME [epoch: 11.6 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07310588624690009		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.07310588624690009 | validation: 0.07232957253147433]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350835066416866		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.07350835066416866 | validation: 0.07112232750821]
	TIME [epoch: 11.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07631429326692946		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.07631429326692946 | validation: 0.07689299955877887]
	TIME [epoch: 11.6 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644770681420254		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.07644770681420254 | validation: 0.0681535054592486]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07739211009092752		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.07739211009092752 | validation: 0.07558826207863982]
	TIME [epoch: 11.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07673177722654437		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.07673177722654437 | validation: 0.07697023894566206]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07404036865078334		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.07404036865078334 | validation: 0.07599586371095426]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07470807818133897		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.07470807818133897 | validation: 0.07166663339890471]
	TIME [epoch: 11.5 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07572525873846477		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.07572525873846477 | validation: 0.07732873722190943]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07670920205812681		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.07670920205812681 | validation: 0.07666445108697129]
	TIME [epoch: 11.6 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730007653975476		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.07730007653975476 | validation: 0.07311127678022299]
	TIME [epoch: 11.5 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118020673293212		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.08118020673293212 | validation: 0.07332300607592988]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.076184666249759		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.076184666249759 | validation: 0.07257027851924129]
	TIME [epoch: 11.6 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07732898759223357		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.07732898759223357 | validation: 0.06637504104147238]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809813580014906		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.06809813580014906 | validation: 0.07254916199181137]
	TIME [epoch: 11.5 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07551730595948927		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.07551730595948927 | validation: 0.07213058901072607]
	TIME [epoch: 11.6 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824199678705305		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0824199678705305 | validation: 0.07048376705760348]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697075779454088		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.07697075779454088 | validation: 0.07174695262320288]
	TIME [epoch: 11.5 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07380195968977879		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.07380195968977879 | validation: 0.08136473408218091]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880515374494185		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.07880515374494185 | validation: 0.06888748985505753]
	TIME [epoch: 11.6 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07781865020443271		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.07781865020443271 | validation: 0.08297359948263935]
	TIME [epoch: 11.5 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795363968907654		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.0795363968907654 | validation: 0.07320226426288197]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280432529719272		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.07280432529719272 | validation: 0.07676780847054225]
	TIME [epoch: 11.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07638498464490856		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.07638498464490856 | validation: 0.0659619417278348]
	TIME [epoch: 11.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07654694776644752		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.07654694776644752 | validation: 0.07439759441023817]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07623067804226204		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.07623067804226204 | validation: 0.06979343732098693]
	TIME [epoch: 11.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817561119332123		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0817561119332123 | validation: 0.07907793507179667]
	TIME [epoch: 11.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07371875604403945		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.07371875604403945 | validation: 0.07016499406429891]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727074230288134		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.0727074230288134 | validation: 0.07063878279373534]
	TIME [epoch: 11.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07200882520205924		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.07200882520205924 | validation: 0.07476155579323766]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075164604288664		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.07075164604288664 | validation: 0.0693986482295039]
	TIME [epoch: 11.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779051390868816		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.0779051390868816 | validation: 0.07482924116669577]
	TIME [epoch: 11.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07398462296101313		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.07398462296101313 | validation: 0.06558280369898886]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07550725134842327		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.07550725134842327 | validation: 0.07120052555999688]
	TIME [epoch: 11.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07016648272027816		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.07016648272027816 | validation: 0.07479883890558214]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07588355221082818		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.07588355221082818 | validation: 0.093336132625432]
	TIME [epoch: 11.6 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08835376169189645		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.08835376169189645 | validation: 0.0868898620402863]
	TIME [epoch: 11.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08962759321020786		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.08962759321020786 | validation: 0.07658217186464572]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07938281944698172		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.07938281944698172 | validation: 0.07195077418894257]
	TIME [epoch: 11.6 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07428874809691555		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.07428874809691555 | validation: 0.06694922704856493]
	TIME [epoch: 11.5 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07137393570621413		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.07137393570621413 | validation: 0.07488707965098788]
	TIME [epoch: 11.6 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07178944297437877		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.07178944297437877 | validation: 0.07141280649393843]
	TIME [epoch: 11.6 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545772418175269		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.07545772418175269 | validation: 0.07567969632673158]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695807440711594		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.07695807440711594 | validation: 0.07845752530469012]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07764481398096228		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.07764481398096228 | validation: 0.0721194134793671]
	TIME [epoch: 11.6 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615788324479894		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.07615788324479894 | validation: 0.0736895734136278]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534201270391705		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.07534201270391705 | validation: 0.07387481669083132]
	TIME [epoch: 11.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07474701505911897		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.07474701505911897 | validation: 0.06099139442497063]
	TIME [epoch: 11.6 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652622328500326		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.07652622328500326 | validation: 0.06951887639238648]
	TIME [epoch: 11.6 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086568339679912		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.08086568339679912 | validation: 0.07564153291623785]
	TIME [epoch: 11.5 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07733522200421465		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.07733522200421465 | validation: 0.07270571016370259]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789495384243025		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.0789495384243025 | validation: 0.08028418642851119]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650468872542697		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.07650468872542697 | validation: 0.07254909292966161]
	TIME [epoch: 11.5 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438805493254262		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.07438805493254262 | validation: 0.07491408451592578]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07547742440194435		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.07547742440194435 | validation: 0.06019368498396809]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07447447140337399		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.07447447140337399 | validation: 0.06743411489441459]
	TIME [epoch: 11.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07343439328306449		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.07343439328306449 | validation: 0.0642297957426827]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689632764174373		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.0689632764174373 | validation: 0.0688689912024156]
	TIME [epoch: 11.6 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593805691890639		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.07593805691890639 | validation: 0.0730103864007894]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704255412003508		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.07704255412003508 | validation: 0.07204271273003031]
	TIME [epoch: 11.5 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08091583767105759		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.08091583767105759 | validation: 0.07017958439629873]
	TIME [epoch: 11.6 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0770878750086363		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.0770878750086363 | validation: 0.07636081257073736]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675072595054329		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.07675072595054329 | validation: 0.06619236927427315]
	TIME [epoch: 11.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452232685517961		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.07452232685517961 | validation: 0.059562801872951515]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530547392687789		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.07530547392687789 | validation: 0.06439745729730136]
	TIME [epoch: 11.6 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07492792965969608		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.07492792965969608 | validation: 0.06884595107565102]
	TIME [epoch: 11.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0773827582989713		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.0773827582989713 | validation: 0.06670798563106126]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07321301013939337		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.07321301013939337 | validation: 0.06441038166119605]
	TIME [epoch: 11.6 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07118791457570506		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.07118791457570506 | validation: 0.06037412801859627]
	TIME [epoch: 11.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07406481859131148		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.07406481859131148 | validation: 0.06897320608149979]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578763757606284		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.07578763757606284 | validation: 0.0710089958913078]
	TIME [epoch: 11.6 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439813442567447		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.07439813442567447 | validation: 0.07112666592711868]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07853373968636844		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.07853373968636844 | validation: 0.06663041145633172]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022354584029301		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.08022354584029301 | validation: 0.071467942721245]
	TIME [epoch: 11.6 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07598157605819533		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.07598157605819533 | validation: 0.06995776483410815]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695715913967523		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.07695715913967523 | validation: 0.06787090204019426]
	TIME [epoch: 11.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07435611819469069		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.07435611819469069 | validation: 0.06722575230526484]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07453171413862211		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.07453171413862211 | validation: 0.06694951111972014]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07382060190834497		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.07382060190834497 | validation: 0.07710012098907668]
	TIME [epoch: 11.5 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07277890134681356		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.07277890134681356 | validation: 0.07584066775521292]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486444228874115		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.07486444228874115 | validation: 0.0649496962688418]
	TIME [epoch: 11.6 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07260860735699572		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.07260860735699572 | validation: 0.06066965543127301]
	TIME [epoch: 11.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443440285949873		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.07443440285949873 | validation: 0.07233168362843456]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06987838697473199		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.06987838697473199 | validation: 0.06223940714371314]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408611146974753		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.07408611146974753 | validation: 0.06582677679190642]
	TIME [epoch: 11.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774327761342091		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.0774327761342091 | validation: 0.07016281496185925]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723457942335535		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0723457942335535 | validation: 0.07167688891582522]
	TIME [epoch: 11.6 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719304211885414		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.0719304211885414 | validation: 0.06171637765267333]
	TIME [epoch: 11.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06729804427387709		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.06729804427387709 | validation: 0.05927325524678535]
	TIME [epoch: 11.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06788052083387733		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.06788052083387733 | validation: 0.05375434808349296]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r0_20240309_135637/states/model_tr_study3_1591.pth
	Model improved!!!
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751186580611011		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.0751186580611011 | validation: 0.07123586640383593]
	TIME [epoch: 11.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07413219460438866		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.07413219460438866 | validation: 0.07045840763403666]
	TIME [epoch: 11.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07429365110008568		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.07429365110008568 | validation: 0.07148814631588282]
	TIME [epoch: 11.6 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07135265625229004		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.07135265625229004 | validation: 0.07255211310053024]
	TIME [epoch: 11.6 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07165305171158416		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.07165305171158416 | validation: 0.06700763806167799]
	TIME [epoch: 11.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07079988571646416		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.07079988571646416 | validation: 0.06197134003255291]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186021873003115		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.07186021873003115 | validation: 0.07283851763088825]
	TIME [epoch: 11.6 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06881496088564404		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.06881496088564404 | validation: 0.0689648116430674]
	TIME [epoch: 11.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07447565762404199		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.07447565762404199 | validation: 0.05834665531480688]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163064259247814		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.07163064259247814 | validation: 0.06725261397244123]
	TIME [epoch: 11.6 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728411756398722		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.0728411756398722 | validation: 0.05696651220337648]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07153406449535897		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.07153406449535897 | validation: 0.06294769225936882]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06929049316149885		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.06929049316149885 | validation: 0.06231700540892513]
	TIME [epoch: 11.6 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07335732562334682		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.07335732562334682 | validation: 0.07030047786957973]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07010963165046419		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.07010963165046419 | validation: 0.058762513374374]
	TIME [epoch: 11.5 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093540974406602		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.07093540974406602 | validation: 0.07078423600585125]
	TIME [epoch: 11.6 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0691646052234741		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.0691646052234741 | validation: 0.06336352065529384]
	TIME [epoch: 11.6 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07299975944748002		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.07299975944748002 | validation: 0.060003026773716356]
	TIME [epoch: 11.5 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07296114868330708		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.07296114868330708 | validation: 0.05980742364537015]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982651014393196		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.06982651014393196 | validation: 0.06754715041289487]
	TIME [epoch: 11.6 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07538002508055729		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.07538002508055729 | validation: 0.06880895532156707]
	TIME [epoch: 11.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07266206654244471		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.07266206654244471 | validation: 0.06498273659717894]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07656674596128463		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.07656674596128463 | validation: 0.06715459280382585]
	TIME [epoch: 11.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07658209445431063		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.07658209445431063 | validation: 0.061160820223296816]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07240773786033977		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.07240773786033977 | validation: 0.06811067179983954]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07314158336662785		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.07314158336662785 | validation: 0.06814782980192297]
	TIME [epoch: 11.6 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07386485984728122		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.07386485984728122 | validation: 0.06189891335294245]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995224500048722		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.06995224500048722 | validation: 0.06835283323246526]
	TIME [epoch: 11.5 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450008198489518		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.07450008198489518 | validation: 0.07353388322108678]
	TIME [epoch: 11.6 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07173012246491807		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.07173012246491807 | validation: 0.0675371241975005]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07427499534671535		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.07427499534671535 | validation: 0.06829648770946871]
	TIME [epoch: 11.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07066507770891378		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.07066507770891378 | validation: 0.0767500609309526]
	TIME [epoch: 11.6 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07623835764534855		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.07623835764534855 | validation: 0.06961347143219496]
	TIME [epoch: 11.6 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07617370465322691		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.07617370465322691 | validation: 0.06459093416325482]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013848070188335		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.07013848070188335 | validation: 0.0581165131919744]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239059607855003		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.07239059607855003 | validation: 0.07248330628573453]
	TIME [epoch: 11.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07603345804736598		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.07603345804736598 | validation: 0.06357782772506733]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399295986710872		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.07399295986710872 | validation: 0.06429346130333002]
	TIME [epoch: 11.6 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468702496677013		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.07468702496677013 | validation: 0.062304004036242734]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543440695659465		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.07543440695659465 | validation: 0.06694671017181686]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727827363318113		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.07727827363318113 | validation: 0.0727509878080769]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07452570287405116		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.07452570287405116 | validation: 0.06334623642002571]
	TIME [epoch: 11.6 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07074367137666393		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.07074367137666393 | validation: 0.06224484829893693]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06879539973934806		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.06879539973934806 | validation: 0.07476925127294085]
	TIME [epoch: 11.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07328061474501482		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.07328061474501482 | validation: 0.06206224270902567]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07328901129391202		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.07328901129391202 | validation: 0.06237657293013109]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028303921970374		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.08028303921970374 | validation: 0.0707617525790628]
	TIME [epoch: 11.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905039907999103		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.07905039907999103 | validation: 0.07398481240137383]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877165946569749		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0877165946569749 | validation: 0.08663365713322962]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08619542926503712		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.08619542926503712 | validation: 0.07966995199976581]
	TIME [epoch: 11.5 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0867889457026472		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.0867889457026472 | validation: 0.07380953410192485]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153247363002275		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.08153247363002275 | validation: 0.06994637094556361]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119446387438016		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.08119446387438016 | validation: 0.0692226609952171]
	TIME [epoch: 11.5 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718117269119627		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.07718117269119627 | validation: 0.0708423490211043]
	TIME [epoch: 11.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815591088420838		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.07815591088420838 | validation: 0.07047065993357399]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07978082203167768		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.07978082203167768 | validation: 0.06355417322343837]
	TIME [epoch: 11.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07774898357868315		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.07774898357868315 | validation: 0.07053588005650639]
	TIME [epoch: 11.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07400345661009052		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.07400345661009052 | validation: 0.0805501701540075]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07238445932787754		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.07238445932787754 | validation: 0.061816071723483024]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715306726293584		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.0715306726293584 | validation: 0.07104158163887529]
	TIME [epoch: 11.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07187956943053933		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.07187956943053933 | validation: 0.06127415796898124]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023426947304721		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.07023426947304721 | validation: 0.06612270131904913]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07088871944336805		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.07088871944336805 | validation: 0.06645623030712454]
	TIME [epoch: 11.5 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07012592313829433		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.07012592313829433 | validation: 0.0630542091801153]
	TIME [epoch: 11.5 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.068979969190883		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.068979969190883 | validation: 0.0690260080183212]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07888540750940656		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.07888540750940656 | validation: 0.07640305802826866]
	TIME [epoch: 11.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011077082907259		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.08011077082907259 | validation: 0.06810280905454347]
	TIME [epoch: 11.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08182645809423321		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.08182645809423321 | validation: 0.06753661189569751]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813161426869706		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.0813161426869706 | validation: 0.06751660968583754]
	TIME [epoch: 11.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07503882301562534		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.07503882301562534 | validation: 0.06863065258690869]
	TIME [epoch: 11.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928564550621718		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.07928564550621718 | validation: 0.06407953313153229]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07647794675190973		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.07647794675190973 | validation: 0.06723239407744154]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07657661241268765		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07657661241268765 | validation: 0.06713451790151044]
	TIME [epoch: 11.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578713093034847		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.07578713093034847 | validation: 0.057145947722862495]
	TIME [epoch: 11.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07036443602314749		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.07036443602314749 | validation: 0.07145852390692739]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07076819038959702		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.07076819038959702 | validation: 0.06126823136123624]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07365369288781387		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.07365369288781387 | validation: 0.06985002214778455]
	TIME [epoch: 11.5 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07932112961182915		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.07932112961182915 | validation: 0.06928950531038416]
	TIME [epoch: 11.6 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07645083837182724		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.07645083837182724 | validation: 0.06417103175638951]
	TIME [epoch: 11.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297734811922901		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.07297734811922901 | validation: 0.06491343591233224]
	TIME [epoch: 11.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972933729254527		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.06972933729254527 | validation: 0.06741089080144891]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017114576654904		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.07017114576654904 | validation: 0.06621290572427084]
	TIME [epoch: 11.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378650451380411		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.07378650451380411 | validation: 0.06232406082060523]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460051822597677		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.07460051822597677 | validation: 0.061960686653205914]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761013545597646		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.0761013545597646 | validation: 0.06422479536391168]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749714199713275		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.0749714199713275 | validation: 0.06622101986007076]
	TIME [epoch: 11.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727308407429398		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.0727308407429398 | validation: 0.06872326412681118]
	TIME [epoch: 11.6 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749278138274983		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.0749278138274983 | validation: 0.07126698300968722]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07699210821662764		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.07699210821662764 | validation: 0.06527138500063762]
	TIME [epoch: 11.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07250785085741297		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.07250785085741297 | validation: 0.06332969099959689]
	TIME [epoch: 11.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07061373720330663		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.07061373720330663 | validation: 0.06397314240040759]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738251394871352		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.0738251394871352 | validation: 0.06980099961140612]
	TIME [epoch: 11.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351393713964804		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.07351393713964804 | validation: 0.06323622953783851]
	TIME [epoch: 11.6 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06912252286967646		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.06912252286967646 | validation: 0.0670696668178962]
	TIME [epoch: 11.6 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013242953191733		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.07013242953191733 | validation: 0.06307118374173465]
	TIME [epoch: 11.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0745687297678812		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.0745687297678812 | validation: 0.05842135550547063]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07461703850275833		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.07461703850275833 | validation: 0.06951043421166635]
	TIME [epoch: 11.6 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07213647497237718		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.07213647497237718 | validation: 0.06293511096983888]
	TIME [epoch: 11.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851496728900277		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.07851496728900277 | validation: 0.0666335111808525]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07614729041560059		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.07614729041560059 | validation: 0.05622086065423888]
	TIME [epoch: 11.6 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07469506915891244		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.07469506915891244 | validation: 0.05868200214987504]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07338573774288966		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.07338573774288966 | validation: 0.06331600017587455]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293537427407888		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.07293537427407888 | validation: 0.07079959472082838]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729927351054043		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.0729927351054043 | validation: 0.06647711405089762]
	TIME [epoch: 11.6 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254489277878073		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.07254489277878073 | validation: 0.064561261955524]
	TIME [epoch: 11.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06994769264069475		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.06994769264069475 | validation: 0.06724506774345054]
	TIME [epoch: 11.6 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07249636799444494		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.07249636799444494 | validation: 0.06920090438008003]
	TIME [epoch: 11.6 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530786564374374		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.07530786564374374 | validation: 0.06259165540488004]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006402868215433		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.07006402868215433 | validation: 0.06672549417048326]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07146170205361405		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.07146170205361405 | validation: 0.06704819182994771]
	TIME [epoch: 11.6 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101886636670376		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.07101886636670376 | validation: 0.07036398056740734]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077864240343579		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.07077864240343579 | validation: 0.06517105599971769]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.071323625434394		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.071323625434394 | validation: 0.07032224609488873]
	TIME [epoch: 11.6 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07577654244631854		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.07577654244631854 | validation: 0.06252155931912418]
	TIME [epoch: 11.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0693233514924643		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.0693233514924643 | validation: 0.06084680650105393]
	TIME [epoch: 11.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06848387310018363		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.06848387310018363 | validation: 0.06836209486300873]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684411283059657		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.07684411283059657 | validation: 0.0682487729634299]
	TIME [epoch: 11.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472335504340055		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.07472335504340055 | validation: 0.06644863327208246]
	TIME [epoch: 11.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07157011096931132		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.07157011096931132 | validation: 0.06605398870577261]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108095758026528		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.07108095758026528 | validation: 0.0705198513585613]
	TIME [epoch: 11.6 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07334457949265877		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.07334457949265877 | validation: 0.06924644217730656]
	TIME [epoch: 11.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07348356727462446		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.07348356727462446 | validation: 0.06765019250013855]
	TIME [epoch: 11.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500806011735692		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.07500806011735692 | validation: 0.07904518907170095]
	TIME [epoch: 11.6 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07064394545021463		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.07064394545021463 | validation: 0.06893280716626796]
	TIME [epoch: 11.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07675519412359413		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.07675519412359413 | validation: 0.07168663911733184]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07299832525760412		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.07299832525760412 | validation: 0.06939695660717277]
	TIME [epoch: 11.6 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07326975349745278		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.07326975349745278 | validation: 0.05868418231167976]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07252599534032328		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.07252599534032328 | validation: 0.07164631739211993]
	TIME [epoch: 11.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06872495931039108		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.06872495931039108 | validation: 0.062093611333898194]
	TIME [epoch: 11.6 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724077214864462		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.0724077214864462 | validation: 0.06592857485193059]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07325115506254279		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.07325115506254279 | validation: 0.06763131991867834]
	TIME [epoch: 11.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06926910793519353		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.06926910793519353 | validation: 0.05732431024507461]
	TIME [epoch: 11.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015142001535106		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.07015142001535106 | validation: 0.0744799322951165]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297003643261424		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.07297003643261424 | validation: 0.05817607400640856]
	TIME [epoch: 11.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736974490054464		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.0736974490054464 | validation: 0.062026646286436046]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07469813126232544		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.07469813126232544 | validation: 0.07027128994607157]
	TIME [epoch: 11.6 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07536460481847791		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.07536460481847791 | validation: 0.06659649187691624]
	TIME [epoch: 11.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07272842208856646		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.07272842208856646 | validation: 0.07831756884675217]
	TIME [epoch: 11.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785262933047438		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.0785262933047438 | validation: 0.06259514171424892]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304012181726863		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.07304012181726863 | validation: 0.0751834860312235]
	TIME [epoch: 11.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07626141003888495		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.07626141003888495 | validation: 0.06681948548691775]
	TIME [epoch: 11.5 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295001676786543		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.07295001676786543 | validation: 0.06434509635658155]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033573943757336		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.07033573943757336 | validation: 0.05508009707340635]
	TIME [epoch: 11.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07315749369830378		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.07315749369830378 | validation: 0.06928912461260461]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0740026063747006		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.0740026063747006 | validation: 0.06459676181083344]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07188407755964245		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.07188407755964245 | validation: 0.07417713521131226]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164967735024122		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.07164967735024122 | validation: 0.0681504273970723]
	TIME [epoch: 11.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0723268453207343		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.0723268453207343 | validation: 0.062063516985653405]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505279458515687		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.07505279458515687 | validation: 0.07566898022061923]
	TIME [epoch: 11.6 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07139906171217579		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.07139906171217579 | validation: 0.06465557984850838]
	TIME [epoch: 11.5 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144354499610077		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.07144354499610077 | validation: 0.06692523385031875]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0721788869406044		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.0721788869406044 | validation: 0.06445560852280921]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07023369023280526		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.07023369023280526 | validation: 0.06465871772190201]
	TIME [epoch: 11.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203701983280332		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.07203701983280332 | validation: 0.06559713589776081]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06816778184124367		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.06816778184124367 | validation: 0.06676112991344521]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07198256350278948		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.07198256350278948 | validation: 0.05994680530121932]
	TIME [epoch: 11.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972850801661169		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.06972850801661169 | validation: 0.06852512364338842]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06642853178191313		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.06642853178191313 | validation: 0.07057164999413086]
	TIME [epoch: 11.6 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07099986257968674		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.07099986257968674 | validation: 0.060534679234350505]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07043770782194886		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.07043770782194886 | validation: 0.06673957184333548]
	TIME [epoch: 11.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0731641549728864		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.0731641549728864 | validation: 0.07221248354744404]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293265456591233		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.07293265456591233 | validation: 0.06092125201839047]
	TIME [epoch: 11.6 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07204282316988078		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.07204282316988078 | validation: 0.06713040223718718]
	TIME [epoch: 11.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493458474461639		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.06493458474461639 | validation: 0.05713321161832049]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06980391695634822		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.06980391695634822 | validation: 0.061059681336111664]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520526614025932		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.06520526614025932 | validation: 0.05702472949738778]
	TIME [epoch: 11.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0738150292532564		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.0738150292532564 | validation: 0.05839600417515776]
	TIME [epoch: 11.6 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07205384833089737		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.07205384833089737 | validation: 0.06348199046399851]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07036539202903827		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.07036539202903827 | validation: 0.06796638505967206]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06891457836392874		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.06891457836392874 | validation: 0.0627764442326445]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07205323519175703		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.07205323519175703 | validation: 0.06301788199722971]
	TIME [epoch: 11.6 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0701660502813844		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.0701660502813844 | validation: 0.0629283689521419]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06992533900566802		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.06992533900566802 | validation: 0.06558321327000291]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07434302072027549		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.07434302072027549 | validation: 0.06649536688333522]
	TIME [epoch: 11.6 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144786275146738		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.07144786275146738 | validation: 0.06106332380378297]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07121971098517468		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.07121971098517468 | validation: 0.06019062245234574]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727699502285901		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.0727699502285901 | validation: 0.06320973247850771]
	TIME [epoch: 11.6 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07004859554539082		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.07004859554539082 | validation: 0.06345085349532795]
	TIME [epoch: 11.6 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749274613085876		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.0749274613085876 | validation: 0.06393391535398156]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07396291296362584		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.07396291296362584 | validation: 0.059506733658525254]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07365014941587994		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.07365014941587994 | validation: 0.06824096778046906]
	TIME [epoch: 11.6 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07636055740566572		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.07636055740566572 | validation: 0.06662104835041908]
	TIME [epoch: 11.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07204898904841509		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.07204898904841509 | validation: 0.06375671478464576]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954290263933424		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.06954290263933424 | validation: 0.07152499941920544]
	TIME [epoch: 11.6 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142439183360681		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.07142439183360681 | validation: 0.060441300997279186]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06907932866505409		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.06907932866505409 | validation: 0.0654373726645985]
	TIME [epoch: 11.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945165138337203		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.06945165138337203 | validation: 0.06274956032039451]
	TIME [epoch: 11.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995614662008919		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.06995614662008919 | validation: 0.06380959455249235]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06874674271131535		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.06874674271131535 | validation: 0.06084806717181987]
	TIME [epoch: 11.5 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07054465328310928		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.07054465328310928 | validation: 0.06442219141633877]
	TIME [epoch: 11.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07125509470017745		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.07125509470017745 | validation: 0.058275328417172804]
	TIME [epoch: 11.6 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07430638940535952		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.07430638940535952 | validation: 0.05825355438661933]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07279575472450997		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.07279575472450997 | validation: 0.06048616722663498]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07213352738486323		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.07213352738486323 | validation: 0.06558488711755465]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366138352721209		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.07366138352721209 | validation: 0.07029377546232074]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802313186165196		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.06802313186165196 | validation: 0.07256845505687326]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901441770088028		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.06901441770088028 | validation: 0.07071289734535066]
	TIME [epoch: 11.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06507085135284091		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.06507085135284091 | validation: 0.060230701134393265]
	TIME [epoch: 11.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07165864436350876		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.07165864436350876 | validation: 0.06192089573546671]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941695714737704		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.06941695714737704 | validation: 0.06331361107744536]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226510522598116		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.07226510522598116 | validation: 0.06075358137809765]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736150920743886		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.0736150920743886 | validation: 0.07179132963095107]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07142021054483964		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.07142021054483964 | validation: 0.06594446668940138]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07215381072216351		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.07215381072216351 | validation: 0.07293145999532136]
	TIME [epoch: 11.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597917652873921		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.07597917652873921 | validation: 0.06315424898097521]
	TIME [epoch: 11.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07014496023569822		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.07014496023569822 | validation: 0.07225286061643]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273359727813915		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.07273359727813915 | validation: 0.06335017972328284]
	TIME [epoch: 11.6 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06942549397067292		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.06942549397067292 | validation: 0.06952475843779243]
	TIME [epoch: 11.5 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07072129719327214		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.07072129719327214 | validation: 0.06068342129000844]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06937387669795521		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.06937387669795521 | validation: 0.06997044020634105]
	TIME [epoch: 11.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07087327154470101		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.07087327154470101 | validation: 0.06157928561499627]
	TIME [epoch: 11.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07067578222481527		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.07067578222481527 | validation: 0.0594079874326356]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687682530483731		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.0687682530483731 | validation: 0.06268487410513522]
	TIME [epoch: 11.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07010261116107216		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.07010261116107216 | validation: 0.06233562576635816]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0720533637103371		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.0720533637103371 | validation: 0.06118972996237851]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07022918984634391		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.07022918984634391 | validation: 0.06415085226007439]
	TIME [epoch: 11.6 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176214429845217		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.07176214429845217 | validation: 0.05936139743826267]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715709701921983		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.0715709701921983 | validation: 0.06636377510483761]
	TIME [epoch: 11.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147926636269336		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.07147926636269336 | validation: 0.060293770737801476]
	TIME [epoch: 11.6 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07237193084128757		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.07237193084128757 | validation: 0.05913808975866593]
	TIME [epoch: 11.6 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07165388545986676		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.07165388545986676 | validation: 0.06335122667240042]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06956907308182052		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.06956907308182052 | validation: 0.0610912473350947]
	TIME [epoch: 11.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06895981047250224		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.06895981047250224 | validation: 0.05985446223064214]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0729018814793258		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.0729018814793258 | validation: 0.06543834871918264]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189768123001578		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.07189768123001578 | validation: 0.06346710802200085]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07053386557140023		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.07053386557140023 | validation: 0.07144639963839276]
	TIME [epoch: 11.6 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06889288667121785		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.06889288667121785 | validation: 0.072673238736447]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07307344720014025		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.07307344720014025 | validation: 0.0646163533852171]
	TIME [epoch: 11.6 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741922418790846		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.0741922418790846 | validation: 0.07273313656886256]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07562911212592438		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.07562911212592438 | validation: 0.07280823765732435]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0715360855338592		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0715360855338592 | validation: 0.06816367913699783]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181268828321787		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.07181268828321787 | validation: 0.07571867819279528]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07105183432881174		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.07105183432881174 | validation: 0.06385091345901009]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06994900164444323		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.06994900164444323 | validation: 0.0651292079595264]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07460581957819615		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.07460581957819615 | validation: 0.06713608378344436]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07203516663140636		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.07203516663140636 | validation: 0.0670088262447354]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017632009712463		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.07017632009712463 | validation: 0.06662657315850815]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07295681087814579		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.07295681087814579 | validation: 0.06991527588796698]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752975846289438		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.06752975846289438 | validation: 0.056432568614125045]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840395010102314		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.06840395010102314 | validation: 0.07076900853663318]
	TIME [epoch: 11.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935378489529789		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.06935378489529789 | validation: 0.06196613594431428]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894138688020125		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.06894138688020125 | validation: 0.05938895231220616]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0689279123241698		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.0689279123241698 | validation: 0.06061190295321655]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06595547105526943		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.06595547105526943 | validation: 0.06614411880336632]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06945698819057447		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.06945698819057447 | validation: 0.06936454084070523]
	TIME [epoch: 11.6 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06755629711674463		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.06755629711674463 | validation: 0.06328871105923005]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840905610422848		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.06840905610422848 | validation: 0.06948259353944408]
	TIME [epoch: 11.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07132590632310186		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.07132590632310186 | validation: 0.05764794573004028]
	TIME [epoch: 11.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07201546352165558		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.07201546352165558 | validation: 0.06203769744997942]
	TIME [epoch: 11.6 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704990538925844		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.06704990538925844 | validation: 0.07034410971848405]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0686745207523747		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.0686745207523747 | validation: 0.06581559644602354]
	TIME [epoch: 11.6 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0692775186105413		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.0692775186105413 | validation: 0.06290272357072821]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894696213792995		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.06894696213792995 | validation: 0.05865975507346631]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07025112601839481		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.07025112601839481 | validation: 0.07066822388033103]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06897636839096302		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.06897636839096302 | validation: 0.05774304115451542]
	TIME [epoch: 11.6 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07232382823919437		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.07232382823919437 | validation: 0.05655756603506241]
	TIME [epoch: 11.5 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07264734283922106		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.07264734283922106 | validation: 0.07099654784610093]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07145031094676833		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.07145031094676833 | validation: 0.06980464633226513]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07403780787362993		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.07403780787362993 | validation: 0.0736252658180057]
	TIME [epoch: 11.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0705218950287396		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.0705218950287396 | validation: 0.06090094062384339]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07508489720670147		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.07508489720670147 | validation: 0.06838700645836678]
	TIME [epoch: 11.6 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0710519103574361		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.0710519103574361 | validation: 0.07032757615000071]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439651651959936		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.07439651651959936 | validation: 0.07432648689865283]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0717833255901656		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.0717833255901656 | validation: 0.06927531400032884]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379724368690661		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.07379724368690661 | validation: 0.06331295947098788]
	TIME [epoch: 11.6 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0675498185541588		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.0675498185541588 | validation: 0.07958046191105052]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07107273361930791		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.07107273361930791 | validation: 0.056101113675808265]
	TIME [epoch: 11.6 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0679949430452263		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.0679949430452263 | validation: 0.07083017922718084]
	TIME [epoch: 11.6 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07419708809720209		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.07419708809720209 | validation: 0.05960023355682768]
	TIME [epoch: 11.5 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856207366775748		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.06856207366775748 | validation: 0.063040497026725]
	TIME [epoch: 11.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108935908860298		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.07108935908860298 | validation: 0.061630000307338506]
	TIME [epoch: 11.6 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07013139591477004		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.07013139591477004 | validation: 0.06855574978249199]
	TIME [epoch: 11.5 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06863448421572464		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.06863448421572464 | validation: 0.06062960801490942]
	TIME [epoch: 11.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06993925007056256		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.06993925007056256 | validation: 0.06330880967072139]
	TIME [epoch: 11.6 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07387666308237993		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.07387666308237993 | validation: 0.05629961105023071]
	TIME [epoch: 11.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485140909458919		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.07485140909458919 | validation: 0.05887172879342473]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210821807812691		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.07210821807812691 | validation: 0.06404356273903837]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934164023853179		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.06934164023853179 | validation: 0.067076839658242]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07015054176151041		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.07015054176151041 | validation: 0.0650273085003094]
	TIME [epoch: 11.5 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954226717615918		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.06954226717615918 | validation: 0.06483418099024901]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
