Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r3', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1754615776

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.218492851468602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.218492851468602 | validation: 9.821262273215988]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.28629407411841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.28629407411841 | validation: 9.406300406728715]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.413915542827997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.413915542827997 | validation: 8.356588680700499]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.598923525432848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.598923525432848 | validation: 7.892922842886901]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.858673234904298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.858673234904298 | validation: 7.100215897600326]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.1860578795237995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1860578795237995 | validation: 6.575321933372543]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.72859404396034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.72859404396034 | validation: 6.390798666840622]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.609650844002774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.609650844002774 | validation: 6.053419360632715]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.334746433442624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.334746433442624 | validation: 5.983750959774528]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.300806167179707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.300806167179707 | validation: 6.003863954663936]
	TIME [epoch: 11.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.177413420763674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.177413420763674 | validation: 5.864871076642974]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962955755984957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.962955755984957 | validation: 5.873585959109801]
	TIME [epoch: 11.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.029355286915838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.029355286915838 | validation: 5.708344358544901]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.896165128477543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.896165128477543 | validation: 5.779939098547232]
	TIME [epoch: 11.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.508167518539691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.508167518539691 | validation: 6.12966489145475]
	TIME [epoch: 11.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.982931481605395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.982931481605395 | validation: 5.75471973379369]
	TIME [epoch: 11.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852783725169973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852783725169973 | validation: 5.653766464673096]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.869376965513474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.869376965513474 | validation: 5.564455414962705]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8027135495638404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8027135495638404 | validation: 5.555250627084257]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.897413775360208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.897413775360208 | validation: 5.731158957083275]
	TIME [epoch: 11.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8693984548244345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8693984548244345 | validation: 5.771047170275734]
	TIME [epoch: 11.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96178379883563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96178379883563 | validation: 5.698723708198412]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703540176471158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.703540176471158 | validation: 5.7172249498681165]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.880293806776212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.880293806776212 | validation: 5.686113253014241]
	TIME [epoch: 11.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8044967999514405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8044967999514405 | validation: 5.614088756699865]
	TIME [epoch: 11.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8088560114592624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8088560114592624 | validation: 5.6220829566531245]
	TIME [epoch: 11.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.751137064607514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.751137064607514 | validation: 5.611106710897846]
	TIME [epoch: 11.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.309871815085078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.309871815085078 | validation: 6.152359306981714]
	TIME [epoch: 11.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.933293784315413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.933293784315413 | validation: 5.561682785987604]
	TIME [epoch: 11.5 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.70729102728677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.70729102728677 | validation: 5.611665829912912]
	TIME [epoch: 11.5 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.640068139763729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.640068139763729 | validation: 5.689939041378404]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.703291748181629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703291748181629 | validation: 5.486932166116755]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.653136554429476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.653136554429476 | validation: 5.568621996637658]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768106318854615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.768106318854615 | validation: 5.300508032468363]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.538150629856151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.538150629856151 | validation: 5.499222546568249]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4958416081343815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4958416081343815 | validation: 6.460189845623091]
	TIME [epoch: 11.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96355590567736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96355590567736 | validation: 5.268800706292326]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.358994936366957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.358994936366957 | validation: 5.809017562043594]
	TIME [epoch: 11.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.767322629067735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.767322629067735 | validation: 5.210190576504058]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.465624185735628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.465624185735628 | validation: 5.329415171094081]
	TIME [epoch: 11.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2305798359260685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2305798359260685 | validation: 5.221710250327613]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.138339269417214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.138339269417214 | validation: 4.911537848288692]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.566338717300574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.566338717300574 | validation: 5.875620316305779]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.510293593057926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.510293593057926 | validation: 4.922564538573714]
	TIME [epoch: 11.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.358805114829118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.358805114829118 | validation: 7.914015170098901]
	TIME [epoch: 11.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.03620611704998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.03620611704998 | validation: 5.275251913943253]
	TIME [epoch: 11.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.077830027241194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.077830027241194 | validation: 5.633828383555509]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.237954679176176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.237954679176176 | validation: 4.842395744806493]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.85434640249526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.85434640249526 | validation: 5.837986314177449]
	TIME [epoch: 11.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.171575032493975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.171575032493975 | validation: 4.865353602877709]
	TIME [epoch: 11.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.228738904624219		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.228738904624219 | validation: 4.790369145440881]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.807641401275335		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 4.807641401275335 | validation: 4.835420277679561]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.836434248071766		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.836434248071766 | validation: 4.874261581731741]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.91732652593484		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.91732652593484 | validation: 4.884994528290015]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.793593176203248		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.793593176203248 | validation: 4.56971866329897]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5992079639428365		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.5992079639428365 | validation: 4.709261878608839]
	TIME [epoch: 11.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.621054424770608		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.621054424770608 | validation: 4.4672722386964]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.610488894881866		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.610488894881866 | validation: 4.422077981023978]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.239450628484829		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.239450628484829 | validation: 4.637960592077449]
	TIME [epoch: 11.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.366807385360461		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.366807385360461 | validation: 4.403360478452999]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.042670932673808		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.042670932673808 | validation: 3.874498483614122]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.173215744311307		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.173215744311307 | validation: 4.198098408480125]
	TIME [epoch: 11.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9427245783725735		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.9427245783725735 | validation: 3.5936225743645585]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5685507591267944		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.5685507591267944 | validation: 3.5828022104881616]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4507208506424414		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.4507208506424414 | validation: 3.6095316698161657]
	TIME [epoch: 11.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.531768863342881		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.531768863342881 | validation: 3.544587545529653]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.368881631090653		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.368881631090653 | validation: 3.381512207037564]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.170537238900355		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.170537238900355 | validation: 3.2156313357856137]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.225491773594857		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.225491773594857 | validation: 3.5528033114591917]
	TIME [epoch: 11.5 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5496069782525486		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.5496069782525486 | validation: 3.2525315796657956]
	TIME [epoch: 11.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9714512528450454		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.9714512528450454 | validation: 2.7551118732114084]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0034099168050727		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.0034099168050727 | validation: 2.5851298370894864]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8091292757223307		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.8091292757223307 | validation: 3.542029685853371]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9772855502795537		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.9772855502795537 | validation: 3.265916880542014]
	TIME [epoch: 11.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.921035219268048		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.921035219268048 | validation: 2.656420074459606]
	TIME [epoch: 11.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4969858652316805		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.4969858652316805 | validation: 2.4362999392468656]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7961103677545616		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.7961103677545616 | validation: 2.4255051688840754]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7189895635017045		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.7189895635017045 | validation: 2.3436137241733244]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.849458416990878		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.849458416990878 | validation: 2.3586619510460802]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.46094886892256		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.46094886892256 | validation: 2.1237313812568046]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.097386719989143		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.097386719989143 | validation: 2.067787285202212]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0992179479959474		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.0992179479959474 | validation: 2.065010815566454]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.938966708284895		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.938966708284895 | validation: 2.119141899407546]
	TIME [epoch: 11.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0906229120737763		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.0906229120737763 | validation: 2.1836310836190904]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0197328630842826		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.0197328630842826 | validation: 1.8343716851328151]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8611310144795217		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.8611310144795217 | validation: 2.2617046369669853]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2285126588311446		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.2285126588311446 | validation: 1.7024610473789659]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9928076818671563		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.9928076818671563 | validation: 1.4861645644667214]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6288102490204803		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.6288102490204803 | validation: 1.3851812032194901]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2727976032978736		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.2727976032978736 | validation: 1.6292548007934866]
	TIME [epoch: 11.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8105652404404282		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.8105652404404282 | validation: 1.6389221150230477]
	TIME [epoch: 11.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.279770728265527		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.279770728265527 | validation: 3.322207743511019]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.234661841164421		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.234661841164421 | validation: 1.9620620139525105]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008885279823073		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.008885279823073 | validation: 2.688686466547018]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.443682413695805		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.443682413695805 | validation: 2.007913396601518]
	TIME [epoch: 11.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0596607025574203		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.0596607025574203 | validation: 1.7729786356251682]
	TIME [epoch: 11.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0306776377839375		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.0306776377839375 | validation: 1.7728508732029327]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8883450758664577		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.8883450758664577 | validation: 4.998921031271268]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.512041349270289		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.512041349270289 | validation: 2.1462174738113355]
	TIME [epoch: 11.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9249213666821		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.9249213666821 | validation: 1.8829035142894315]
	TIME [epoch: 11.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0763754562790657		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.0763754562790657 | validation: 1.7869134648133138]
	TIME [epoch: 11.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8910326999318552		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.8910326999318552 | validation: 1.6201652394086161]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6239070279046772		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.6239070279046772 | validation: 1.4226671221865608]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5451297888079853		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.5451297888079853 | validation: 1.2801611736359295]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7178273272160138		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.7178273272160138 | validation: 1.136995559579287]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5745101302877123		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.5745101302877123 | validation: 1.0277150251328009]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3262258030281697		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.3262258030281697 | validation: 2.5371039617550672]
	TIME [epoch: 11.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9306318893875942		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.9306318893875942 | validation: 1.1992800968835389]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3819480042676306		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.3819480042676306 | validation: 1.1469979003469508]
	TIME [epoch: 11.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4692623920478662		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4692623920478662 | validation: 1.459275174127708]
	TIME [epoch: 11.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5027952641363531		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5027952641363531 | validation: 1.921791212571025]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4747930644681206		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.4747930644681206 | validation: 1.1251655390781625]
	TIME [epoch: 11.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.450938354893832		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.450938354893832 | validation: 1.2146400242705835]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5458288860458294		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.5458288860458294 | validation: 1.0722950876786448]
	TIME [epoch: 11.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3760225367467895		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3760225367467895 | validation: 2.091394583548249]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8606796933803067		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.8606796933803067 | validation: 2.3054822752443824]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6953978084513484		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.6953978084513484 | validation: 1.934607562732328]
	TIME [epoch: 11.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523157868963556		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.523157868963556 | validation: 2.3545258592374396]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.759327463466749		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.759327463466749 | validation: 1.1912838431941395]
	TIME [epoch: 11.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4742563123797958		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.4742563123797958 | validation: 1.413976562135413]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275772946222232		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.275772946222232 | validation: 1.4869689988148065]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5422223354128455		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.5422223354128455 | validation: 1.9042531071800861]
	TIME [epoch: 11.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8393459376629382		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8393459376629382 | validation: 1.0975642569106745]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4582724650572203		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.4582724650572203 | validation: 1.0459171726307588]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3275468269435844		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.3275468269435844 | validation: 3.9627401181065527]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4387219131064835		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.4387219131064835 | validation: 1.6186706101368475]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6667205612009768		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.6667205612009768 | validation: 1.2081692463500124]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3161284118735135		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3161284118735135 | validation: 1.0720067514888338]
	TIME [epoch: 11.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5577820019817898		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.5577820019817898 | validation: 1.2547484078531248]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3045398823543568		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.3045398823543568 | validation: 1.1298395232982095]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2135737033538538		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.2135737033538538 | validation: 1.187455736781308]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2945286983601414		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.2945286983601414 | validation: 2.2885396174327184]
	TIME [epoch: 11.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7811532827225294		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.7811532827225294 | validation: 1.1366512183298676]
	TIME [epoch: 11.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7291024935961055		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7291024935961055 | validation: 1.7101063701092052]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5099048343336063		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.5099048343336063 | validation: 1.216059721316017]
	TIME [epoch: 11.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1897932277287784		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.1897932277287784 | validation: 1.0814340130233335]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.329087049401069		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.329087049401069 | validation: 1.2730679585193807]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3076621773290893		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3076621773290893 | validation: 1.2238669338112422]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4860563981531805		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.4860563981531805 | validation: 1.0304215611124437]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4459354738084416		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4459354738084416 | validation: 0.9239855424491182]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5013155122248283		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.5013155122248283 | validation: 1.9606779687611124]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.403289903524798		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.403289903524798 | validation: 1.6751779453725224]
	TIME [epoch: 11.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3351457413696637		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3351457413696637 | validation: 1.7929149812761234]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938090306664922		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2938090306664922 | validation: 1.6820926112445285]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3569624184028113		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3569624184028113 | validation: 1.3588439673593222]
	TIME [epoch: 11.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.397083805078562		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.397083805078562 | validation: 1.354019239775562]
	TIME [epoch: 11.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.209055278692863		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.209055278692863 | validation: 1.0839167650997097]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0663006665016388		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0663006665016388 | validation: 1.0319249686884422]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.272145752461777		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.272145752461777 | validation: 0.8274155953508955]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2294956251277487		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.2294956251277487 | validation: 0.7503205988178426]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3533692229165206		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3533692229165206 | validation: 0.9293278081919464]
	TIME [epoch: 11.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2734630347849425		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.2734630347849425 | validation: 1.9242984770148996]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2488560099876285		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.2488560099876285 | validation: 1.5391492294545857]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.553622442409338		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.553622442409338 | validation: 1.6525288606789772]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1845075552140107		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.1845075552140107 | validation: 0.7753084494548047]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0645809129673542		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.0645809129673542 | validation: 1.1428589049525153]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4440001796323303		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.4440001796323303 | validation: 1.7676861422208583]
	TIME [epoch: 11.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6411793215165646		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.6411793215165646 | validation: 1.1377306802110188]
	TIME [epoch: 11.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1506635159716307		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1506635159716307 | validation: 1.6637015031025066]
	TIME [epoch: 11.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.396683593588989		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.396683593588989 | validation: 1.2364390143243176]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2985019202803443		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.2985019202803443 | validation: 1.0893185746225922]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1431627553653159		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.1431627553653159 | validation: 1.1908924020169094]
	TIME [epoch: 11.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1519771211051073		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.1519771211051073 | validation: 0.8682302963662718]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9824563970452082		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9824563970452082 | validation: 0.7161923265856506]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4666185252261785		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.4666185252261785 | validation: 1.1842745415369837]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2067759825845168		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2067759825845168 | validation: 1.0108975833726987]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1567984866327974		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1567984866327974 | validation: 1.8073575345146946]
	TIME [epoch: 11.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4031967521591047		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.4031967521591047 | validation: 0.8730388873111354]
	TIME [epoch: 11.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153696298876599		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.153696298876599 | validation: 0.7807725323328176]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340083326879335		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.0340083326879335 | validation: 1.0631520517909356]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1993786330449412		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.1993786330449412 | validation: 0.7536702387574843]
	TIME [epoch: 11.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9568340859123324		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.9568340859123324 | validation: 1.0503974503896751]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0834258335444653		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0834258335444653 | validation: 1.6152994227292674]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0507655240152647		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0507655240152647 | validation: 0.8191897844596135]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9706457740467369		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.9706457740467369 | validation: 0.7454024487187322]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054089182612744		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.054089182612744 | validation: 1.4063245415871766]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578384721830053		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1578384721830053 | validation: 0.8744827191924742]
	TIME [epoch: 11.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0140469018979053		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.0140469018979053 | validation: 0.967373546181698]
	TIME [epoch: 11.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.067309235871385		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.067309235871385 | validation: 0.8462896181212247]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0070074819529982		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0070074819529982 | validation: 1.5034060045072994]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0593381323337763		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0593381323337763 | validation: 0.8819193760959988]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8897628479695212		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8897628479695212 | validation: 0.7658603710480943]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2421358417050523		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2421358417050523 | validation: 1.5857196912049214]
	TIME [epoch: 11.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1844831824792588		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.1844831824792588 | validation: 0.7936892793361809]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0754392357634357		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.0754392357634357 | validation: 1.4258661200812606]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1661009934256472		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.1661009934256472 | validation: 0.9950547809572043]
	TIME [epoch: 11.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0054309062194413		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.0054309062194413 | validation: 0.6980097767914301]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0977375465022696		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0977375465022696 | validation: 1.329324807118962]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2878124045961603		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.2878124045961603 | validation: 1.259445477301128]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3156752869506207		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3156752869506207 | validation: 1.7154642234855204]
	TIME [epoch: 11.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6232466559911254		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.6232466559911254 | validation: 1.1151106355443816]
	TIME [epoch: 11.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2787902603543173		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.2787902603543173 | validation: 0.8588921369289545]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0809341681262392		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0809341681262392 | validation: 1.4455879765438124]
	TIME [epoch: 11.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3259350942425874		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.3259350942425874 | validation: 1.003085014492087]
	TIME [epoch: 11.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.303105626865009		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.303105626865009 | validation: 0.8878369740287231]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9409110973959895		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9409110973959895 | validation: 0.9645121656233001]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.987196285508663		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.987196285508663 | validation: 0.8588786704937785]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9807820813858276		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9807820813858276 | validation: 0.7391564064883377]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8533132881705346		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8533132881705346 | validation: 0.8204455692279418]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8729617226290234		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.8729617226290234 | validation: 0.6704977179997736]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0053705035573046		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0053705035573046 | validation: 0.7560980496662673]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036066826676377		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8036066826676377 | validation: 0.5865863446295769]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8745849752022876		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8745849752022876 | validation: 0.8689350540577826]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.094153000239633		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.094153000239633 | validation: 1.4894438451777965]
	TIME [epoch: 11.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1301326336691293		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.1301326336691293 | validation: 1.2129951151382168]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.315166152843584		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.315166152843584 | validation: 0.9016530234417494]
	TIME [epoch: 11.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.99560891526389		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.99560891526389 | validation: 0.7606101949240227]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8759288324539535		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8759288324539535 | validation: 0.7127853437837908]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9317985199990689		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.9317985199990689 | validation: 0.5974938490988392]
	TIME [epoch: 11.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1368357460977565		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.1368357460977565 | validation: 1.1112529656768118]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0234708188373316		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.0234708188373316 | validation: 1.3352928451126116]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.377755417876061		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.377755417876061 | validation: 1.0569018436508166]
	TIME [epoch: 11.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0863736182664268		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.0863736182664268 | validation: 0.8368566401378158]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.158059564543216		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.158059564543216 | validation: 1.9677871105793991]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3593701608336874		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.3593701608336874 | validation: 0.875008624434133]
	TIME [epoch: 11.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9054214250080392		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9054214250080392 | validation: 0.8324087517846286]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9369144739698245		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9369144739698245 | validation: 0.9514152899854841]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0456196729630678		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.0456196729630678 | validation: 0.8996135221485948]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9311778264509488		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9311778264509488 | validation: 0.7672549203211945]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.842696599203113		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.842696599203113 | validation: 0.6863631239012813]
	TIME [epoch: 11.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900387351392798		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.900387351392798 | validation: 0.8813370274691658]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8821056585991132		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8821056585991132 | validation: 1.2605634256509308]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9481012105508911		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9481012105508911 | validation: 0.9527220077865798]
	TIME [epoch: 11.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4824716622987446		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.4824716622987446 | validation: 0.9581079982883617]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2421567972959595		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.2421567972959595 | validation: 0.9796415890095052]
	TIME [epoch: 11.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.309518374314028		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.309518374314028 | validation: 1.0512217438735143]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.216992910459574		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.216992910459574 | validation: 1.145923656916347]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2212942390083272		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.2212942390083272 | validation: 0.8497783399844206]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8407993105626668		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8407993105626668 | validation: 0.9474727634788985]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9209335331629098		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9209335331629098 | validation: 0.7605547355922633]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8917940395192013		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8917940395192013 | validation: 0.6021332283568863]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8601061006395188		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8601061006395188 | validation: 0.5825836534500756]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8141686317586472		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.8141686317586472 | validation: 0.5262849703361383]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9084796224447411		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.9084796224447411 | validation: 0.7982235225974899]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9912371450253312		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.9912371450253312 | validation: 1.0172067370552211]
	TIME [epoch: 11.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0059924892148322		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.0059924892148322 | validation: 0.6796874619103395]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7344542033719955		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7344542033719955 | validation: 0.5672498576437377]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493898352511371		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6493898352511371 | validation: 0.689718444661631]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8279637769245253		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8279637769245253 | validation: 0.6837363540795937]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8167120492612367		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.8167120492612367 | validation: 1.9513701752655426]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4084530925069894		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.4084530925069894 | validation: 0.7829730542658478]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8290355960452471		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.8290355960452471 | validation: 0.7923811896143248]
	TIME [epoch: 11.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240903403343522		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7240903403343522 | validation: 0.9427580917558855]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8398356227683645		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8398356227683645 | validation: 0.615780879382912]
	TIME [epoch: 11.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8260544058468136		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8260544058468136 | validation: 1.0904074952343914]
	TIME [epoch: 11.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9337635003099097		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.9337635003099097 | validation: 0.7682990515269573]
	TIME [epoch: 11.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8849626746667443		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8849626746667443 | validation: 0.5883311217079427]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241133665497881		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7241133665497881 | validation: 0.5446042778360328]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683490993795904		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.8683490993795904 | validation: 0.9749883611317963]
	TIME [epoch: 11.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.85878515924026		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.85878515924026 | validation: 0.6824147999572818]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0184275396002134		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.0184275396002134 | validation: 0.7936927450469891]
	TIME [epoch: 11.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7694638466233837		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.7694638466233837 | validation: 1.0011812668977178]
	TIME [epoch: 11.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8982302096218836		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.8982302096218836 | validation: 0.7834433731586099]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0089006065248205		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.0089006065248205 | validation: 0.8130989262572527]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8042124898168572		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.8042124898168572 | validation: 0.6942774783800815]
	TIME [epoch: 11.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034350751962819		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7034350751962819 | validation: 0.9503058677328212]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8115402102435179		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8115402102435179 | validation: 1.0345013542266113]
	TIME [epoch: 11.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8453889384292432		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8453889384292432 | validation: 0.8864342154047151]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7269202732376178		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7269202732376178 | validation: 0.6837873235003974]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8021027909063873		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.8021027909063873 | validation: 0.9668552045033993]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904114750640248		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7904114750640248 | validation: 1.0036488083122157]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8270747616405327		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.8270747616405327 | validation: 0.5501381826766342]
	TIME [epoch: 11.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7596471748624576		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7596471748624576 | validation: 0.5246817033783081]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9403825015268129		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.9403825015268129 | validation: 0.7416008978774941]
	TIME [epoch: 11.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040901988413638		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7040901988413638 | validation: 0.6659731417788483]
	TIME [epoch: 11.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023336231243573		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7023336231243573 | validation: 1.6873547920106682]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.223431757424745		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.223431757424745 | validation: 0.9393226373587524]
	TIME [epoch: 11.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845046734366004		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7845046734366004 | validation: 0.7005665120302246]
	TIME [epoch: 11.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820821747485361		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.820821747485361 | validation: 1.294723276628741]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221637119616218		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.9221637119616218 | validation: 0.5341909174350511]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6969840933263567		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6969840933263567 | validation: 0.8220054429547367]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.892210537334246		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.892210537334246 | validation: 1.2288181951846917]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2602478609139716		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2602478609139716 | validation: 1.2242561437723478]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8915448158250321		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8915448158250321 | validation: 0.7016480789064482]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6675044120768139		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6675044120768139 | validation: 0.5460188660546011]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7582866594915318		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7582866594915318 | validation: 0.654655247554728]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.796944173967133		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.796944173967133 | validation: 0.8142984549324781]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161307362281114		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7161307362281114 | validation: 0.8108025292814517]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.711755942840844		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.711755942840844 | validation: 0.9468999792816907]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711830054167669		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6711830054167669 | validation: 0.8320323207324108]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.943704313673563		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.943704313673563 | validation: 1.5506015690358392]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419031373729527		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.1419031373729527 | validation: 0.7282349473980595]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5793282593606541		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.5793282593606541 | validation: 1.4202074077615106]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3577622184453828		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.3577622184453828 | validation: 0.9257208853026121]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8717684018943617		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8717684018943617 | validation: 1.5415931635175826]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685766540163357		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9685766540163357 | validation: 0.741497341338141]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938255189076603		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6938255189076603 | validation: 0.6633143496849792]
	TIME [epoch: 11.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7784328463212674		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7784328463212674 | validation: 0.5435268868603148]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6343677696223269		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.6343677696223269 | validation: 0.6125084706013887]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6602986400821773		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6602986400821773 | validation: 0.5714660549875061]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002485797570753		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7002485797570753 | validation: 0.7265642702916207]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8466484849961111		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.8466484849961111 | validation: 0.8506787864103376]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7329031366116714		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7329031366116714 | validation: 0.7500044599303638]
	TIME [epoch: 11.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074963881118053		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7074963881118053 | validation: 0.46571054415740876]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852138080696232		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6852138080696232 | validation: 0.5334893091485138]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7553881772503171		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7553881772503171 | validation: 0.760500222702947]
	TIME [epoch: 11.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7108425719776494		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7108425719776494 | validation: 0.5172890902165004]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014639415458579		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6014639415458579 | validation: 0.7269125986068068]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681546623988621		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6681546623988621 | validation: 0.7624873845705429]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7161351762314316		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.7161351762314316 | validation: 0.7906727121903879]
	TIME [epoch: 11.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265325164540001		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7265325164540001 | validation: 0.679414270249109]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6450810639012468		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6450810639012468 | validation: 0.6007197236067643]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6959425066125902		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6959425066125902 | validation: 0.5460655647392627]
	TIME [epoch: 11.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337171367224131		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7337171367224131 | validation: 0.527293047127586]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991301629404185		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5991301629404185 | validation: 1.6304522803777022]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9584345816004125		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.9584345816004125 | validation: 0.9768328407901481]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7186277846922788		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7186277846922788 | validation: 0.8541321401332421]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9591900691307029		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.9591900691307029 | validation: 0.6600536395057262]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6537096729882159		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6537096729882159 | validation: 0.6664756650197746]
	TIME [epoch: 11.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918695281745732		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5918695281745732 | validation: 0.48769872228618993]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5783232174757629		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5783232174757629 | validation: 0.5361847823039363]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311007006166386		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5311007006166386 | validation: 0.541412360038799]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883721450372722		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6883721450372722 | validation: 0.5097099865765939]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500544925941117		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.500544925941117 | validation: 0.6097365730389533]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352601967026315		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6352601967026315 | validation: 0.6230043812430412]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287656918465505		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6287656918465505 | validation: 0.5297803396368261]
	TIME [epoch: 11.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843353218423639		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5843353218423639 | validation: 0.5617904907650371]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807068006341167		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5807068006341167 | validation: 0.8958700946373296]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823711881055057		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.7823711881055057 | validation: 0.8749342320783623]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778405419581187		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6778405419581187 | validation: 0.5881330624065284]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120315150047909		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7120315150047909 | validation: 0.5061708241552849]
	TIME [epoch: 11.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860970115994764		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6860970115994764 | validation: 0.7450792133345017]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245007710864028		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6245007710864028 | validation: 0.6487333304756336]
	TIME [epoch: 11.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871712979919137		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5871712979919137 | validation: 0.8425380426632696]
	TIME [epoch: 11.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508635067446443		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.6508635067446443 | validation: 0.41871902999903654]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166153028011783		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5166153028011783 | validation: 0.40023304183300773]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609955704866632		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.4609955704866632 | validation: 0.33091673269375366]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004110260021188		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5004110260021188 | validation: 0.4056300178981802]
	TIME [epoch: 11.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341491453691558		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7341491453691558 | validation: 0.45863800460661197]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5991605229801609		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5991605229801609 | validation: 0.41403138108041704]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5275754397937894		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5275754397937894 | validation: 0.5402884352626075]
	TIME [epoch: 11.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49764235313758615		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.49764235313758615 | validation: 0.8977078864247803]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232242765401098		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6232242765401098 | validation: 0.7787600921738207]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957101911940044		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5957101911940044 | validation: 0.47666018001091137]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788844127636859		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5788844127636859 | validation: 0.6034881930835895]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7868236031991497		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.7868236031991497 | validation: 0.36179072087064157]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886971743852729		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.5886971743852729 | validation: 0.6443975346259875]
	TIME [epoch: 11.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085873269970256		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6085873269970256 | validation: 0.7589412633872786]
	TIME [epoch: 11.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470316707677197		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6470316707677197 | validation: 0.501177012965744]
	TIME [epoch: 11.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000732918772116		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5000732918772116 | validation: 0.5601230017057142]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6538230265518714		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6538230265518714 | validation: 0.3781629299543133]
	TIME [epoch: 11.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442627951821444		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.442627951821444 | validation: 0.43639943312448964]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6714558603321654		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.6714558603321654 | validation: 0.5273666494911972]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230723355475674		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.6230723355475674 | validation: 0.5864733294537149]
	TIME [epoch: 11.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337069424132674		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6337069424132674 | validation: 0.420449326024823]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005259642351755		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5005259642351755 | validation: 0.3975545484572346]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480833042225524		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.4480833042225524 | validation: 0.42075451968252386]
	TIME [epoch: 11.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004755437918151		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.7004755437918151 | validation: 0.43640149480412704]
	TIME [epoch: 11.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934567459866455		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6934567459866455 | validation: 0.46333673404474307]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325442511825443		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5325442511825443 | validation: 0.38154387591148436]
	TIME [epoch: 11.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554437198278088		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.554437198278088 | validation: 0.5352344524149762]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5427758155507885		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5427758155507885 | validation: 0.5199163582784473]
	TIME [epoch: 11.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42994582390714464		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.42994582390714464 | validation: 0.7687947326179452]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521713302855926		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5521713302855926 | validation: 0.519477967677819]
	TIME [epoch: 11.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452897610481293		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.4452897610481293 | validation: 0.3691367657033932]
	TIME [epoch: 11.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259431301454013		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6259431301454013 | validation: 0.5430642639632237]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676354908312613		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5676354908312613 | validation: 0.4996362497363002]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.579471385674668		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.579471385674668 | validation: 0.385386493220837]
	TIME [epoch: 11.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025625436938514		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.6025625436938514 | validation: 0.4315473936550485]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631866088456647		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4631866088456647 | validation: 0.6846731383259501]
	TIME [epoch: 11.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551690034111572		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.551690034111572 | validation: 0.38637125477471373]
	TIME [epoch: 11.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681987600672242		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4681987600672242 | validation: 0.6693921125690909]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4848544437662758		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.4848544437662758 | validation: 0.5672956593803108]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037850160042322		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5037850160042322 | validation: 0.6261488444889842]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49678195917845297		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.49678195917845297 | validation: 0.40374642337009403]
	TIME [epoch: 11.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40171227514724966		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.40171227514724966 | validation: 0.41478935015338686]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036320121431999		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.5036320121431999 | validation: 0.7303974122596485]
	TIME [epoch: 11.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831492258027319		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6831492258027319 | validation: 0.49720650380809683]
	TIME [epoch: 11.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47515279378124214		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.47515279378124214 | validation: 0.5739833184192221]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000804727415842		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5000804727415842 | validation: 0.41083661519364817]
	TIME [epoch: 11.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4330227258062473		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.4330227258062473 | validation: 0.47793240143285504]
	TIME [epoch: 11.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44210608865737633		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.44210608865737633 | validation: 0.36102177323725115]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4193738473785564		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.4193738473785564 | validation: 0.42582092393164944]
	TIME [epoch: 11.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988872233094949		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.3988872233094949 | validation: 0.5818575765783092]
	TIME [epoch: 11.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488208382761093		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5488208382761093 | validation: 0.4521959655013667]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7107074560155168		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.7107074560155168 | validation: 0.5596617291751936]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722861433725632		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5722861433725632 | validation: 0.31129191200853]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48811737571948427		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.48811737571948427 | validation: 0.9311525148877956]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5855345851128433		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5855345851128433 | validation: 0.39205183414583533]
	TIME [epoch: 11.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118178635720297		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5118178635720297 | validation: 0.5465727998398792]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528237158868684		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.528237158868684 | validation: 0.33313813143262194]
	TIME [epoch: 11.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44169526269134957		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.44169526269134957 | validation: 0.49260344340003115]
	TIME [epoch: 11.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7071201092143055		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.7071201092143055 | validation: 0.6180705737813839]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4922582432877516		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4922582432877516 | validation: 0.399458229043109]
	TIME [epoch: 11.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545675002125437		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.4545675002125437 | validation: 0.7180719867454672]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986050405021501		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.4986050405021501 | validation: 0.5676770551997945]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166937403468155		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.4166937403468155 | validation: 0.3605281513099209]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48435865234716435		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.48435865234716435 | validation: 0.48945934916046585]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48196492476365416		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.48196492476365416 | validation: 0.38072147396027356]
	TIME [epoch: 11.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.384042453697696		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.384042453697696 | validation: 0.4104563935815564]
	TIME [epoch: 11.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4187480548224217		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4187480548224217 | validation: 0.3671949726790837]
	TIME [epoch: 11.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39647673714327736		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.39647673714327736 | validation: 0.3581043564437472]
	TIME [epoch: 11.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44149661637635523		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.44149661637635523 | validation: 0.3528622884496571]
	TIME [epoch: 11.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40776452130528035		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.40776452130528035 | validation: 0.4148339200028412]
	TIME [epoch: 11.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291327518309526		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.6291327518309526 | validation: 0.447713809506932]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36381738212708814		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.36381738212708814 | validation: 0.4608793215940887]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3610385004855913		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.3610385004855913 | validation: 0.32222872859534585]
	TIME [epoch: 11.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42782829336086		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.42782829336086 | validation: 0.3860913626264788]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41961861706416254		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.41961861706416254 | validation: 0.3982413377378989]
	TIME [epoch: 11.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409795690371787		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.409795690371787 | validation: 0.2610766015478069]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258927711418423		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.4258927711418423 | validation: 0.2577951840107345]
	TIME [epoch: 11.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306920913762833		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.306920913762833 | validation: 0.37412959520229777]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38768927426652694		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.38768927426652694 | validation: 0.4121509048736376]
	TIME [epoch: 11.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8111874305629369		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8111874305629369 | validation: 0.6739375955126891]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45200568885353803		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.45200568885353803 | validation: 0.40706021876545934]
	TIME [epoch: 11.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3964357821478728		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.3964357821478728 | validation: 0.4613030702669881]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104298308347338		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5104298308347338 | validation: 0.31662241216373654]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.370552937906502		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.370552937906502 | validation: 0.2519502096512237]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36438201823487254		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.36438201823487254 | validation: 0.801544471145364]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45975152767457483		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.45975152767457483 | validation: 0.4508768104388969]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36590964621496297		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.36590964621496297 | validation: 0.3671790934774685]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43765078512206224		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.43765078512206224 | validation: 0.3827216596357148]
	TIME [epoch: 11.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39851680961051283		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.39851680961051283 | validation: 0.3207376561245562]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36450274861951243		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.36450274861951243 | validation: 0.38977830981346456]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721469705718603		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3721469705718603 | validation: 0.28406326633440293]
	TIME [epoch: 11.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957979607098078		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3957979607098078 | validation: 0.4461719096988432]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36399620358385465		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.36399620358385465 | validation: 0.2384832172507474]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672674201798617		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2672674201798617 | validation: 0.2760801408634656]
	TIME [epoch: 11.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29358798901463234		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.29358798901463234 | validation: 0.2917816673142545]
	TIME [epoch: 11.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3935832118227549		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3935832118227549 | validation: 0.2518388787820466]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28412085445502167		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.28412085445502167 | validation: 0.37305605251103524]
	TIME [epoch: 11.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163623000734652		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.4163623000734652 | validation: 0.5437354064597618]
	TIME [epoch: 11.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44304517460997656		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.44304517460997656 | validation: 0.6232277961051379]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447140419391368		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4447140419391368 | validation: 0.2826892111575721]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172909508187029		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.3172909508187029 | validation: 0.28867212867498643]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29333299659248474		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.29333299659248474 | validation: 0.3120374015259006]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35132754057143656		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.35132754057143656 | validation: 0.3828345886771146]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40204985542879723		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.40204985542879723 | validation: 0.2575339925951499]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4428430940075729		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.4428430940075729 | validation: 0.3981057648521164]
	TIME [epoch: 11.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35618537872609324		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.35618537872609324 | validation: 0.33974478510079664]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771562713758214		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.4771562713758214 | validation: 0.29008553783080593]
	TIME [epoch: 11.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304293078504186		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.304293078504186 | validation: 0.3469495748259186]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550806988209694		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3550806988209694 | validation: 0.41111595224802217]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31075237172886383		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.31075237172886383 | validation: 0.35961540133901965]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33443004877686683		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.33443004877686683 | validation: 0.2754143880899842]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815283729854032		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.2815283729854032 | validation: 0.25892924848020493]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29192700468142463		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.29192700468142463 | validation: 0.27729890411289687]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3867754462573374		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.3867754462573374 | validation: 0.32647753253638656]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.380389245486128		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.380389245486128 | validation: 0.2848321097976701]
	TIME [epoch: 11.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380263401441277		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3380263401441277 | validation: 0.3219649416853232]
	TIME [epoch: 11.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185382841852946		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3185382841852946 | validation: 0.21500476997309367]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27637441694557197		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.27637441694557197 | validation: 0.5061031276110154]
	TIME [epoch: 11.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3274176655348203		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3274176655348203 | validation: 0.2923986579046364]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071907111664659		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.4071907111664659 | validation: 0.32533917641679155]
	TIME [epoch: 11.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976777071816613		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3976777071816613 | validation: 0.4968765388344687]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660694656319965		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3660694656319965 | validation: 0.445359845528156]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3865494934996322		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.3865494934996322 | validation: 0.2720252126539829]
	TIME [epoch: 11.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31234306545600166		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.31234306545600166 | validation: 0.2662363049019317]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32799217478677306		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.32799217478677306 | validation: 0.4065910952888042]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35332057960702823		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.35332057960702823 | validation: 0.503614264090878]
	TIME [epoch: 11.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3659245236743457		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.3659245236743457 | validation: 0.6347728887852955]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44604329832756295		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.44604329832756295 | validation: 0.38618922875474454]
	TIME [epoch: 11.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668611416660461		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3668611416660461 | validation: 0.22266169362154273]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29801228507372635		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.29801228507372635 | validation: 0.23523440548193436]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2879277897190299		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.2879277897190299 | validation: 0.3539495991340111]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3284869462087787		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.3284869462087787 | validation: 0.3316129936637867]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30796388844899975		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.30796388844899975 | validation: 0.35857873087729625]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988220122256599		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3988220122256599 | validation: 0.19118475075530203]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884296819908491		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.3884296819908491 | validation: 0.28655256374224813]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3562810446426071		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3562810446426071 | validation: 0.28249298949976526]
	TIME [epoch: 11.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33928479352006496		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.33928479352006496 | validation: 0.2875126077159801]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37684153730083353		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.37684153730083353 | validation: 0.38326070711047927]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256642543066872		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3256642543066872 | validation: 0.26270996496962185]
	TIME [epoch: 11.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3638765989550318		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.3638765989550318 | validation: 0.5279604552502091]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920523916251094		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3920523916251094 | validation: 0.20230562610445282]
	TIME [epoch: 11.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2990016072352393		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.2990016072352393 | validation: 0.23603303011366797]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28760217283881057		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.28760217283881057 | validation: 0.35923397656003686]
	TIME [epoch: 11.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28624049800552087		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.28624049800552087 | validation: 0.3038579835813238]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26011241924360756		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.26011241924360756 | validation: 0.2304419280332315]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25829756369242907		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.25829756369242907 | validation: 0.28509365578082113]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.298214072834926		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.298214072834926 | validation: 0.36320523817190603]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047487439465599		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.3047487439465599 | validation: 0.32036300779137605]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071906721213656		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.4071906721213656 | validation: 0.4402973476899012]
	TIME [epoch: 11.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627882258817473		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5627882258817473 | validation: 0.497953097118196]
	TIME [epoch: 11.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498107419616084		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4498107419616084 | validation: 0.2514384096151162]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206429685650005		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4206429685650005 | validation: 0.41373816391271384]
	TIME [epoch: 11.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4410163519945288		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4410163519945288 | validation: 0.3991475717277399]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3007099025044606		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.3007099025044606 | validation: 0.3988539393270358]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30753449569843766		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.30753449569843766 | validation: 0.40695907385445373]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576908170651144		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.3576908170651144 | validation: 0.32926853520101446]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29418430304172044		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.29418430304172044 | validation: 0.3452746161420216]
	TIME [epoch: 11.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27203472150693175		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.27203472150693175 | validation: 0.23764131214524647]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288209782305555		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.288209782305555 | validation: 0.4759912047888711]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5660747600999195		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5660747600999195 | validation: 0.371507582722069]
	TIME [epoch: 11.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27577051037004485		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.27577051037004485 | validation: 0.17839471478443314]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22813222718946402		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.22813222718946402 | validation: 0.19024823915803765]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968014281393533		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.21968014281393533 | validation: 0.2693406788125803]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31139042837131026		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.31139042837131026 | validation: 0.43614889764587206]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32433980231069093		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.32433980231069093 | validation: 0.42150896902321466]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3250399521109831		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3250399521109831 | validation: 0.21962924605091524]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28255760487451764		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.28255760487451764 | validation: 0.2602887820551012]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29326216371154634		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.29326216371154634 | validation: 0.20259919203734078]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28243701276586475		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.28243701276586475 | validation: 0.2689294739848667]
	TIME [epoch: 11.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24742375619480922		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.24742375619480922 | validation: 0.45969552798654384]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34980703732094015		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.34980703732094015 | validation: 0.3483211309465472]
	TIME [epoch: 11.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30364667823518604		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.30364667823518604 | validation: 0.2136002837505226]
	TIME [epoch: 11.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25557563382335535		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.25557563382335535 | validation: 0.6283238621232322]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35524207254582923		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.35524207254582923 | validation: 0.153665465803939]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21083215377456332		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.21083215377456332 | validation: 0.18533099586774904]
	TIME [epoch: 11.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24804084801320414		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.24804084801320414 | validation: 0.33771129381422954]
	TIME [epoch: 11.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30866552052124474		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.30866552052124474 | validation: 0.3251986932730061]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2764265137333513		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2764265137333513 | validation: 0.35356163451745753]
	TIME [epoch: 11.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24570174364888028		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.24570174364888028 | validation: 0.5121606289050127]
	TIME [epoch: 11.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32695098898836955		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.32695098898836955 | validation: 0.23106922704281324]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22367044685395318		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.22367044685395318 | validation: 0.28659367232858335]
	TIME [epoch: 11.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309086717051754		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2309086717051754 | validation: 0.38427351422234735]
	TIME [epoch: 11.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25690044900619846		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.25690044900619846 | validation: 0.18750907715919723]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23147401227315678		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.23147401227315678 | validation: 0.1558691330919034]
	TIME [epoch: 11.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3298297404741575		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3298297404741575 | validation: 0.16272654754157911]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3307008551091002		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.3307008551091002 | validation: 0.2016229448834328]
	TIME [epoch: 11.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512098373170154		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.2512098373170154 | validation: 0.2259153673949592]
	TIME [epoch: 11.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713475454702297		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.3713475454702297 | validation: 0.2516990612142553]
	TIME [epoch: 11.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4455702469976794		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.4455702469976794 | validation: 0.22154592968358805]
	TIME [epoch: 11.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21612426262630613		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.21612426262630613 | validation: 0.33095126235535305]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756331630391718		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2756331630391718 | validation: 0.2599464011692071]
	TIME [epoch: 11.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28196217920058697		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.28196217920058697 | validation: 0.26062958303279415]
	TIME [epoch: 11.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254408474483934		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.254408474483934 | validation: 0.23612747433580872]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730125190580525		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2730125190580525 | validation: 0.3122747012853388]
	TIME [epoch: 11.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613963390278465		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2613963390278465 | validation: 0.28325719115020603]
	TIME [epoch: 11.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23124585797574648		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.23124585797574648 | validation: 0.17152596629016154]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29831884443005663		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.29831884443005663 | validation: 0.25062589996403456]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23996611166005863		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.23996611166005863 | validation: 0.23188311120560234]
	TIME [epoch: 11.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685295214464066		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2685295214464066 | validation: 0.26089908106322635]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778767078300343		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2778767078300343 | validation: 0.2648586915737534]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23207613144571448		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.23207613144571448 | validation: 0.30819652303910494]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3303699456878096		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3303699456878096 | validation: 0.523626881583889]
	TIME [epoch: 11.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34522313607893507		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.34522313607893507 | validation: 0.2500316088476647]
	TIME [epoch: 11.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21942816305995844		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.21942816305995844 | validation: 0.3220118308331101]
	TIME [epoch: 11.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947456181589209		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2947456181589209 | validation: 0.27801233031421957]
	TIME [epoch: 11.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32578913448093505		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.32578913448093505 | validation: 0.28314587163409793]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28076673759095294		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.28076673759095294 | validation: 0.21178388484430372]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23669966063979306		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.23669966063979306 | validation: 0.22914815755792772]
	TIME [epoch: 11.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23985634558439026		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.23985634558439026 | validation: 0.22159375109146287]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20355547591995093		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.20355547591995093 | validation: 0.4613363520576303]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43328407663899093		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.43328407663899093 | validation: 0.2830221782281641]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4330264671809637		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.4330264671809637 | validation: 0.4265781772414643]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32662951006020474		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.32662951006020474 | validation: 0.23845806798777014]
	TIME [epoch: 11.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114285870644172		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.2114285870644172 | validation: 0.18947563251679986]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21192193840945128		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.21192193840945128 | validation: 0.2705760671406396]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30239332938617847		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.30239332938617847 | validation: 0.3298008652859194]
	TIME [epoch: 11.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29714683325229857		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.29714683325229857 | validation: 0.26071340934711307]
	TIME [epoch: 11.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22628026693349892		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.22628026693349892 | validation: 0.3054039863503772]
	TIME [epoch: 11.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628426692739081		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2628426692739081 | validation: 0.22251660953860122]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513545957140706		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2513545957140706 | validation: 0.3486302827208872]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24996780186760756		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.24996780186760756 | validation: 0.28655157021155314]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24939230713796798		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.24939230713796798 | validation: 0.32618142797372335]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541032967360962		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.3541032967360962 | validation: 0.3586318655051791]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22874687165302768		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.22874687165302768 | validation: 0.2525743024950459]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20398046136696762		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.20398046136696762 | validation: 0.2248413093695438]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26286014844408173		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.26286014844408173 | validation: 0.3208975072341413]
	TIME [epoch: 11.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922593941057789		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.2922593941057789 | validation: 0.5795297822116973]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30782195881707536		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.30782195881707536 | validation: 0.4464916114847872]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876575101914297		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.2876575101914297 | validation: 0.3306290784409955]
	TIME [epoch: 11.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889384911745086		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.2889384911745086 | validation: 0.32452621161138157]
	TIME [epoch: 11.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055937362008716		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.3055937362008716 | validation: 0.2183687880561206]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1999995858554801		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1999995858554801 | validation: 0.20158859715552624]
	TIME [epoch: 11.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036800977344952		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.2036800977344952 | validation: 0.24359265542703892]
	TIME [epoch: 11.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23532255288658516		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.23532255288658516 | validation: 0.20969020907418856]
	TIME [epoch: 11.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444235844588089		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2444235844588089 | validation: 0.19077536064077855]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23637019354770913		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.23637019354770913 | validation: 0.20920321313546864]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22456824900465933		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.22456824900465933 | validation: 0.2712136425559955]
	TIME [epoch: 11.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23541767027098362		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.23541767027098362 | validation: 0.21664282569264492]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20595305215598347		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.20595305215598347 | validation: 0.19985363008112347]
	TIME [epoch: 11.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20585140954205872		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.20585140954205872 | validation: 0.2641872281233564]
	TIME [epoch: 11.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23588112943056552		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.23588112943056552 | validation: 0.2046782694785531]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24226497859208		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.24226497859208 | validation: 0.14535761427548088]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20367907907844499		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.20367907907844499 | validation: 0.17361029520501953]
	TIME [epoch: 11.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2858210254452535		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2858210254452535 | validation: 0.20076271264862697]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20746034211129435		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.20746034211129435 | validation: 0.2658335773581053]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24628322986917642		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.24628322986917642 | validation: 0.22599278358272132]
	TIME [epoch: 11.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3259464682351075		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.3259464682351075 | validation: 0.22164267414709046]
	TIME [epoch: 11.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28328066295615045		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.28328066295615045 | validation: 0.27883329986327154]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34244919592551815		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.34244919592551815 | validation: 0.19933836526241722]
	TIME [epoch: 11.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28323334491100904		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.28323334491100904 | validation: 0.21480285590662582]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.246118245843117		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.246118245843117 | validation: 0.16886488838017058]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21781624052881965		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.21781624052881965 | validation: 0.20237500171510853]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23288629205617983		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.23288629205617983 | validation: 0.196393027829546]
	TIME [epoch: 11.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23625484336100272		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.23625484336100272 | validation: 0.1889113157820126]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24341070983569824		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.24341070983569824 | validation: 0.22829519695635]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2140384757030751		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.2140384757030751 | validation: 0.25459021694298206]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297404108037178		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.2297404108037178 | validation: 0.1983179151177157]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1983489857505705		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.1983489857505705 | validation: 0.20087445743273968]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18965912224600368		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.18965912224600368 | validation: 0.3514878005520242]
	TIME [epoch: 11.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22946247430187372		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.22946247430187372 | validation: 0.17367291837021231]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22919716770738077		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.22919716770738077 | validation: 0.230586528175811]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23603875006228056		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.23603875006228056 | validation: 0.2313970326475959]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22139264665586977		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.22139264665586977 | validation: 0.23682829799462074]
	TIME [epoch: 11.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23628062622756588		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.23628062622756588 | validation: 0.24444984882586146]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21128396137150124		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.21128396137150124 | validation: 0.23472244018313962]
	TIME [epoch: 11.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21729621374912425		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.21729621374912425 | validation: 0.22225336002782178]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20701919586415918		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.20701919586415918 | validation: 0.20485720724860287]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19140098224101096		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.19140098224101096 | validation: 0.31845837211194017]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27558722472202996		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.27558722472202996 | validation: 0.2370222396651941]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24860332197935242		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.24860332197935242 | validation: 0.3307777378745555]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20916440919212315		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.20916440919212315 | validation: 0.31659496079358335]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227913864765395		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2227913864765395 | validation: 0.18732726543485215]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21468162046062814		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.21468162046062814 | validation: 0.24688268395937848]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906794888664302		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.1906794888664302 | validation: 0.23002029564342558]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19064551663445767		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.19064551663445767 | validation: 0.22907322111915285]
	TIME [epoch: 11.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24827795140749156		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.24827795140749156 | validation: 0.4759850692859806]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643359216489825		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.3643359216489825 | validation: 0.24936598236438628]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24594473036152692		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.24594473036152692 | validation: 0.3043524522550205]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24507219400800595		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.24507219400800595 | validation: 0.16889260977447587]
	TIME [epoch: 11.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17846776535167588		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.17846776535167588 | validation: 0.19175028867471663]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16884539191416525		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.16884539191416525 | validation: 0.2836664134817102]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18753626228142045		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.18753626228142045 | validation: 0.16864642645775094]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771449329733358		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.1771449329733358 | validation: 0.16929836704093623]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17271794418178898		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.17271794418178898 | validation: 0.16594202553006432]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15267996352669205		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.15267996352669205 | validation: 0.15456882397449034]
	TIME [epoch: 11.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1952647691701735		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1952647691701735 | validation: 0.1869203100728759]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23067161779391884		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.23067161779391884 | validation: 0.15079340516362608]
	TIME [epoch: 11.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18435313188294947		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.18435313188294947 | validation: 0.12123389277255468]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_612.pth
	Model improved!!!
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575968556484929		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1575968556484929 | validation: 0.31905484624082037]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20633752033904518		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.20633752033904518 | validation: 0.2033447817330675]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16920947357711033		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.16920947357711033 | validation: 0.23099719927590961]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18567749236370426		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.18567749236370426 | validation: 0.15885024530209205]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18459466345955539		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.18459466345955539 | validation: 0.17134652257960242]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146324969710562		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2146324969710562 | validation: 0.21872049015065415]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19521046278627735		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.19521046278627735 | validation: 0.14127774325375764]
	TIME [epoch: 11.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20373472730093653		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.20373472730093653 | validation: 0.21998151319014383]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21101775171626339		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.21101775171626339 | validation: 0.20006634859095773]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21672275901139124		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.21672275901139124 | validation: 0.18654381079205068]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20377643674268608		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.20377643674268608 | validation: 0.199260289453387]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1992555104067854		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.1992555104067854 | validation: 0.23040532409706538]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24263174081125888		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.24263174081125888 | validation: 0.17196755190259808]
	TIME [epoch: 11.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17932227132615258		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.17932227132615258 | validation: 0.18510457018444726]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753543513263848		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1753543513263848 | validation: 0.15437105997155257]
	TIME [epoch: 11.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17719304688284265		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.17719304688284265 | validation: 0.21753356796292012]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23610471664831967		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23610471664831967 | validation: 0.1308973199421347]
	TIME [epoch: 11.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17755711942823516		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.17755711942823516 | validation: 0.28680487858610315]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23039828680552957		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.23039828680552957 | validation: 0.14065447513054108]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19097073640436915		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.19097073640436915 | validation: 0.17293120004229928]
	TIME [epoch: 11.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23721395947919527		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.23721395947919527 | validation: 0.17650261629515043]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18499460693220568		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.18499460693220568 | validation: 0.20624523838744138]
	TIME [epoch: 11.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15455085716244232		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15455085716244232 | validation: 0.1757223851386071]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267837580275056		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.2267837580275056 | validation: 0.17222507333214881]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747649056629288		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.1747649056629288 | validation: 0.19625798452555235]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40846531068615266		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.40846531068615266 | validation: 0.26344712317718627]
	TIME [epoch: 11.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26515746145310504		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.26515746145310504 | validation: 0.14571404574608393]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20379860707865022		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.20379860707865022 | validation: 0.24387734688566695]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965708558703121		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.1965708558703121 | validation: 0.3628645859650805]
	TIME [epoch: 11.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2403150019574452		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2403150019574452 | validation: 0.15310591053505165]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156934588691292		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.156934588691292 | validation: 0.24455770949474867]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21703545911404115		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.21703545911404115 | validation: 0.14960486345639123]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442170685125604		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1442170685125604 | validation: 0.2026665205739011]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20927371297402772		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.20927371297402772 | validation: 0.16511042757219227]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955133568340128		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.19955133568340128 | validation: 0.21700180508910005]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20957185075450266		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.20957185075450266 | validation: 0.22890550255535133]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15746059801754653		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.15746059801754653 | validation: 0.15659667475035166]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17041073116416453		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.17041073116416453 | validation: 0.13353414009554102]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15831221647495528		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.15831221647495528 | validation: 0.14226120998823263]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18559325012734107		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.18559325012734107 | validation: 0.1664068283400413]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16008972178709502		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.16008972178709502 | validation: 0.1466334921307393]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910869475523615		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.15910869475523615 | validation: 0.15416627248376466]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18905121267179748		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.18905121267179748 | validation: 0.22910923913744255]
	TIME [epoch: 11.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17603422411428676		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.17603422411428676 | validation: 0.17988260772275286]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704176083859826		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.2704176083859826 | validation: 0.2106140573371884]
	TIME [epoch: 11.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20679725553764033		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.20679725553764033 | validation: 0.20660627018685343]
	TIME [epoch: 11.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19402328867564994		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.19402328867564994 | validation: 0.20874885989670103]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19524355337745342		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.19524355337745342 | validation: 0.17642904722823816]
	TIME [epoch: 11.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17957337209267804		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.17957337209267804 | validation: 0.25219629185106873]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19473185419844624		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.19473185419844624 | validation: 0.1193405087388949]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438371866240128		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.1438371866240128 | validation: 0.15171587861958252]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13558890877123259		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.13558890877123259 | validation: 0.13107613306499669]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251037541073114		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14251037541073114 | validation: 0.11516587195040473]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328001927373763		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.15328001927373763 | validation: 0.17191940641570888]
	TIME [epoch: 11.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13646443064563452		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.13646443064563452 | validation: 0.15926363249302983]
	TIME [epoch: 11.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14853402471114532		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.14853402471114532 | validation: 0.3909761514197024]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31440657067983513		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.31440657067983513 | validation: 0.18467821809376062]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515282796664264		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.2515282796664264 | validation: 0.4233949833283671]
	TIME [epoch: 11.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23634017400539878		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.23634017400539878 | validation: 0.17024543876252582]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171345284645241		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.171345284645241 | validation: 0.15123244830557994]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396323677972575		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.14396323677972575 | validation: 0.15536102775388888]
	TIME [epoch: 11.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18248334197570215		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.18248334197570215 | validation: 0.18258521806138678]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22487220967579125		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.22487220967579125 | validation: 0.3259221734746157]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2247298272899165		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.2247298272899165 | validation: 0.17976222015016227]
	TIME [epoch: 11.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151805250819757		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.151805250819757 | validation: 0.17211078498973909]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15813869693147264		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.15813869693147264 | validation: 0.14716054998711767]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16084215740341068		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.16084215740341068 | validation: 0.18718269833733878]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889944211161306		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1889944211161306 | validation: 0.11501980076901762]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20984855504610428		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.20984855504610428 | validation: 0.2713082033279239]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17631613937527907		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.17631613937527907 | validation: 0.15146612349447175]
	TIME [epoch: 11.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444794903775869		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.1444794903775869 | validation: 0.16878875993188536]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453204075972193		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.1453204075972193 | validation: 0.14590515550962882]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865069351501156		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1865069351501156 | validation: 0.20924147348497577]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109517543292326		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.16109517543292326 | validation: 0.1260227420514045]
	TIME [epoch: 11.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391269406641577		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1391269406641577 | validation: 0.1468132094564745]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871884996601891		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.1871884996601891 | validation: 0.17758724235574425]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17450044753805155		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.17450044753805155 | validation: 0.12240999281935178]
	TIME [epoch: 11.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577889611396089		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1577889611396089 | validation: 0.15125755521915973]
	TIME [epoch: 11.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18546381832953523		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.18546381832953523 | validation: 0.13225512378190601]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22611563947403523		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.22611563947403523 | validation: 0.15543452730951435]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128371259291927		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.128371259291927 | validation: 0.15294332055586096]
	TIME [epoch: 11.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13644011629051286		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.13644011629051286 | validation: 0.13324613037965385]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16803439064012637		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.16803439064012637 | validation: 0.13504773318774133]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16187602699965		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.16187602699965 | validation: 0.1824261124929183]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215735978637917		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14215735978637917 | validation: 0.13298835314561258]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2162322393741773		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2162322393741773 | validation: 0.16447754248787075]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16742470433980758		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.16742470433980758 | validation: 0.14657714260301863]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244916799610556		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.1244916799610556 | validation: 0.15671721725946744]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17575409792512178		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.17575409792512178 | validation: 0.15389429088951068]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496003983594674		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.20496003983594674 | validation: 0.13272296004489284]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20996062320017042		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.20996062320017042 | validation: 0.1457615043914113]
	TIME [epoch: 11.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282623107760874		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1282623107760874 | validation: 0.19582997901464694]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15378765683181841		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.15378765683181841 | validation: 0.18879924902038728]
	TIME [epoch: 11.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483898693263387		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.1483898693263387 | validation: 0.1548720156184887]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652497181205505		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.12652497181205505 | validation: 0.21579910726360005]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459957408591941		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.1459957408591941 | validation: 0.14198165252232678]
	TIME [epoch: 11.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320829336958173		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.19320829336958173 | validation: 0.3162556873580964]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20653690276728698		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.20653690276728698 | validation: 0.15124384094287724]
	TIME [epoch: 11.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14892870412240725		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.14892870412240725 | validation: 0.17351952598001577]
	TIME [epoch: 11.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14769485848797492		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.14769485848797492 | validation: 0.16433967483680545]
	TIME [epoch: 11.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539044001827068		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1539044001827068 | validation: 0.18310347127380852]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19472146695673043		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.19472146695673043 | validation: 0.21722887700594648]
	TIME [epoch: 11.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16017091472250844		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.16017091472250844 | validation: 0.1593377000636259]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17743401782728868		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.17743401782728868 | validation: 0.1302346685914164]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370142491669644		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.14370142491669644 | validation: 0.18554419935549268]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22433391523566282		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.22433391523566282 | validation: 0.17460939982489354]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17816308081455134		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.17816308081455134 | validation: 0.12534894150531856]
	TIME [epoch: 11.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17716301876349183		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.17716301876349183 | validation: 0.13062462509630846]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159385656116647		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.159385656116647 | validation: 0.1776294704031096]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20281822927784615		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.20281822927784615 | validation: 0.21244197740299]
	TIME [epoch: 11.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2056357588100256		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2056357588100256 | validation: 0.1850394471861243]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22018922120871448		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.22018922120871448 | validation: 0.16311512974612136]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18256080337994063		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.18256080337994063 | validation: 0.13470486718224814]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18457770804222776		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.18457770804222776 | validation: 0.14211772905821596]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13683252933382345		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.13683252933382345 | validation: 0.14830160229520556]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14194275109722274		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.14194275109722274 | validation: 0.13748597369809504]
	TIME [epoch: 11.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12653856493816507		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.12653856493816507 | validation: 0.14797867334996678]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13533869620209157		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.13533869620209157 | validation: 0.12344282356384352]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920081102921116		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.12920081102921116 | validation: 0.14497865982731967]
	TIME [epoch: 11.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342060447516974		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1342060447516974 | validation: 0.12653564740601636]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15397084660521654		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.15397084660521654 | validation: 0.21649717116179573]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18289352882263266		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.18289352882263266 | validation: 0.1439473594122489]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168290022669479		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.168290022669479 | validation: 0.15097318715193064]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535173573328072		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.11535173573328072 | validation: 0.16065466897284683]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048238293032668		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.13048238293032668 | validation: 0.1316979031072614]
	TIME [epoch: 11.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16353587947368972		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.16353587947368972 | validation: 0.1098627885630929]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14506160027128315		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.14506160027128315 | validation: 0.1306079101436741]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071781746553359		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.12071781746553359 | validation: 0.12836836805444574]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270264346170848		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1270264346170848 | validation: 0.2088755283786568]
	TIME [epoch: 11.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214954097218454		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.16214954097218454 | validation: 0.20872978540691606]
	TIME [epoch: 11.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411175733241464		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1411175733241464 | validation: 0.17656513352523462]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16676619882244043		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.16676619882244043 | validation: 0.2428438493442049]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16403878912311035		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.16403878912311035 | validation: 0.12983840411847333]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432523814139384		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1432523814139384 | validation: 0.19945291329630033]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15606072743975988		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.15606072743975988 | validation: 0.12666653937811428]
	TIME [epoch: 11.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12871773581014856		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.12871773581014856 | validation: 0.13968659272274137]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957578674883136		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.12957578674883136 | validation: 0.18473437575701504]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159251361443606		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.159251361443606 | validation: 0.19562716941213576]
	TIME [epoch: 11.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603251434891285		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1603251434891285 | validation: 0.16781340057360414]
	TIME [epoch: 11.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396425614055718		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.1396425614055718 | validation: 0.1539900449597449]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900611599065557		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.11900611599065557 | validation: 0.13644518550980994]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153553226508165		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.153553226508165 | validation: 0.12513689462119207]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332179243862454		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.1332179243862454 | validation: 0.13311074639471998]
	TIME [epoch: 11.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13657741319590375		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.13657741319590375 | validation: 0.15648955518070656]
	TIME [epoch: 11.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147446746906273		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.14147446746906273 | validation: 0.15600684892609482]
	TIME [epoch: 11.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423779870500222		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.12423779870500222 | validation: 0.11682933038082804]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432970247841625		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.1432970247841625 | validation: 0.12172144707360591]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14977573750788453		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14977573750788453 | validation: 0.13773093700568415]
	TIME [epoch: 11.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1114675036551482		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.1114675036551482 | validation: 0.12483091059730501]
	TIME [epoch: 11.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14499612366421039		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.14499612366421039 | validation: 0.25194263047253446]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21641146375901474		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.21641146375901474 | validation: 0.12214860562392334]
	TIME [epoch: 11.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093883448549259		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.12093883448549259 | validation: 0.1330574989793103]
	TIME [epoch: 11.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15454856853172255		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15454856853172255 | validation: 0.17291199446163666]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14773203341684948		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.14773203341684948 | validation: 0.10522072837148652]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_766.pth
	Model improved!!!
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11261759938457955		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.11261759938457955 | validation: 0.14667364507675293]
	TIME [epoch: 11.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13623087850356883		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.13623087850356883 | validation: 0.10290604706649756]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_768.pth
	Model improved!!!
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11514302242581088		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.11514302242581088 | validation: 0.12316489166646363]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14937951061436464		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.14937951061436464 | validation: 0.14403296059909002]
	TIME [epoch: 11.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122265329554495		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.14122265329554495 | validation: 0.12926257648818126]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272443473334018		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1272443473334018 | validation: 0.16345928049555553]
	TIME [epoch: 11.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15615682854171034		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.15615682854171034 | validation: 0.14110095961622993]
	TIME [epoch: 11.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15413885843832098		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.15413885843832098 | validation: 0.15586319369119786]
	TIME [epoch: 11.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250335210305446		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1250335210305446 | validation: 0.12450517693135042]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392811310260425		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1392811310260425 | validation: 0.2328168097507619]
	TIME [epoch: 11.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15428421968459594		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.15428421968459594 | validation: 0.11374396987796753]
	TIME [epoch: 11.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409105356535233		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.1409105356535233 | validation: 0.13236328394398675]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13321840709276597		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.13321840709276597 | validation: 0.1271579872044508]
	TIME [epoch: 11.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12923407713235377		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.12923407713235377 | validation: 0.13902762243153868]
	TIME [epoch: 11.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11377595201985848		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.11377595201985848 | validation: 0.12057236891897301]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14182442656377783		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.14182442656377783 | validation: 0.12084155239765203]
	TIME [epoch: 11.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13243933678932066		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.13243933678932066 | validation: 0.1849868404404618]
	TIME [epoch: 11.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15768841914556142		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.15768841914556142 | validation: 0.13918456366229778]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13680844033087242		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.13680844033087242 | validation: 0.12253684373508521]
	TIME [epoch: 11.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11916597477672482		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.11916597477672482 | validation: 0.13678912181680322]
	TIME [epoch: 11.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13614131260834217		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.13614131260834217 | validation: 0.158862655953079]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16132851883228644		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.16132851883228644 | validation: 0.2878509793426395]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17606248424647727		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.17606248424647727 | validation: 0.15283585274352615]
	TIME [epoch: 11.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14009963876068315		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.14009963876068315 | validation: 0.13073725865872887]
	TIME [epoch: 11.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869093212842047		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11869093212842047 | validation: 0.1525381613678276]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12058877501227774		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12058877501227774 | validation: 0.1589304795967567]
	TIME [epoch: 11.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486849632350684		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.13486849632350684 | validation: 0.1390244614449028]
	TIME [epoch: 11.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18004066326670343		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.18004066326670343 | validation: 0.10759297006117015]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12665713805584905		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.12665713805584905 | validation: 0.11828302776246823]
	TIME [epoch: 11.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908639204493763		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1908639204493763 | validation: 0.25782619904240234]
	TIME [epoch: 11.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728605349700683		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.1728605349700683 | validation: 0.15074438297371562]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561094543416205		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.1561094543416205 | validation: 0.14196627285184574]
	TIME [epoch: 11.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353288928439586		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.1353288928439586 | validation: 0.1850368189724]
	TIME [epoch: 11.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647156009087646		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1647156009087646 | validation: 0.12736015728317768]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13580640884148712		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.13580640884148712 | validation: 0.14710092441661446]
	TIME [epoch: 11.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435983252111619		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.1435983252111619 | validation: 0.15660424777905058]
	TIME [epoch: 11.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14144235673970226		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.14144235673970226 | validation: 0.16142585921957894]
	TIME [epoch: 11.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1374861333509268		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1374861333509268 | validation: 0.10873358039920918]
	TIME [epoch: 11.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065378534537396		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.11065378534537396 | validation: 0.1649533731942831]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16323941983747003		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.16323941983747003 | validation: 0.1402605761800308]
	TIME [epoch: 11.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543424602703289		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1543424602703289 | validation: 0.12389048010652452]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154870683492962		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1154870683492962 | validation: 0.12639911324611183]
	TIME [epoch: 11.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334919165867828		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1334919165867828 | validation: 0.13017466245752835]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16049022288237078		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.16049022288237078 | validation: 0.16545354051898875]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128846393578322		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.128846393578322 | validation: 0.15232151084214127]
	TIME [epoch: 11.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319953183683249		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.1319953183683249 | validation: 0.1646747969000265]
	TIME [epoch: 11.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15326455554813173		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.15326455554813173 | validation: 0.11060312880779727]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13364345218836082		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.13364345218836082 | validation: 0.2085082631420746]
	TIME [epoch: 11.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14960693732098046		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.14960693732098046 | validation: 0.13720759477300645]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073642132684137		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.1073642132684137 | validation: 0.12502633131113708]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11559028625192413		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.11559028625192413 | validation: 0.1629250652863192]
	TIME [epoch: 11.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316313389906326		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.13316313389906326 | validation: 0.11389891978234068]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379555604252216		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1379555604252216 | validation: 0.10832804301791743]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213490958826876		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1213490958826876 | validation: 0.11978341240292448]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323880008917444		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.1323880008917444 | validation: 0.13632633145670806]
	TIME [epoch: 11.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13063089637652103		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.13063089637652103 | validation: 0.1149719822291323]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11982093022563649		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.11982093022563649 | validation: 0.14382312041396636]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203699164553546		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.14203699164553546 | validation: 0.12306643644060991]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523165437171527		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1523165437171527 | validation: 0.10267283869751292]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918293415894725		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.10918293415894725 | validation: 0.11361152419231649]
	TIME [epoch: 11.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424108985590904		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.1424108985590904 | validation: 0.18504128723223245]
	TIME [epoch: 11.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217157745799366		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.14217157745799366 | validation: 0.11783925126664965]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605968263479707		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.14605968263479707 | validation: 0.10852732777161003]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108407445790202		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.10108407445790202 | validation: 0.1442505448258868]
	TIME [epoch: 11.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12790558027976176		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.12790558027976176 | validation: 0.11947020288986107]
	TIME [epoch: 11.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212061270430998		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.1212061270430998 | validation: 0.17181004375579512]
	TIME [epoch: 11.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17787456993588394		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.17787456993588394 | validation: 0.1530877207776314]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15824694585760163		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.15824694585760163 | validation: 0.19124976059672383]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14275434641762233		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.14275434641762233 | validation: 0.11487910474115204]
	TIME [epoch: 11.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11395991592945535		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.11395991592945535 | validation: 0.11264078870646796]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159550769815369		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.1159550769815369 | validation: 0.15618812870767224]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481233825718513		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.1481233825718513 | validation: 0.15382454817170144]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13292258949532498		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.13292258949532498 | validation: 0.22123314551153855]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13376027127237503		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.13376027127237503 | validation: 0.09770823501052077]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_840.pth
	Model improved!!!
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523630351277636		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.11523630351277636 | validation: 0.1580146360008849]
	TIME [epoch: 11.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443935501344018		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.1443935501344018 | validation: 0.1594072215601521]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475996310538888		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.14475996310538888 | validation: 0.11657051581207796]
	TIME [epoch: 11.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248851846113057		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.12248851846113057 | validation: 0.12409873593173865]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13492773557083337		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.13492773557083337 | validation: 0.19802074507171596]
	TIME [epoch: 11.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19661627473163612		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.19661627473163612 | validation: 0.17907167001051272]
	TIME [epoch: 11.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15836700553072602		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.15836700553072602 | validation: 0.1286857501414171]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11508064006988827		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.11508064006988827 | validation: 0.11454226988685258]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037019500133394		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.1037019500133394 | validation: 0.10488964376217087]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12580917957521606		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.12580917957521606 | validation: 0.16440476735648635]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573574158319936		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.1573574158319936 | validation: 0.11579185166063935]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543778175634164		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10543778175634164 | validation: 0.14446904589668497]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17132731241506666		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.17132731241506666 | validation: 0.18427578890358484]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15785824407108545		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.15785824407108545 | validation: 0.10839425385671465]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989088476739041		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.10989088476739041 | validation: 0.11365626952253781]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142451112095986		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.11142451112095986 | validation: 0.13984151043917056]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15929730045387086		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.15929730045387086 | validation: 0.22072804175420635]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094177867095861		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2094177867095861 | validation: 0.15105604542313197]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104543406172914		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.13104543406172914 | validation: 0.1296940645719691]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252221053495455		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.16252221053495455 | validation: 0.17717464263048677]
	TIME [epoch: 11.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387920740148732		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.1387920740148732 | validation: 0.14385918147579063]
	TIME [epoch: 11.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15500588668236856		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.15500588668236856 | validation: 0.1463417426191769]
	TIME [epoch: 11.5 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425343429114871		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.12425343429114871 | validation: 0.20920560197224036]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496547715252723		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.1496547715252723 | validation: 0.12818001586814856]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057653323772804		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.11057653323772804 | validation: 0.12592102611132755]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903828514235257		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.11903828514235257 | validation: 0.11990929685165998]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702127211119822		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.10702127211119822 | validation: 0.13426389931246732]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438018966262888		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.10438018966262888 | validation: 0.12793818904859333]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13606891114289416		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.13606891114289416 | validation: 0.139163706651242]
	TIME [epoch: 11.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10075949790117056		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.10075949790117056 | validation: 0.13623418343743285]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877955839198012		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.11877955839198012 | validation: 0.12310268475868164]
	TIME [epoch: 11.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13185804477846494		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.13185804477846494 | validation: 0.14890584719308503]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295688539167691		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.1295688539167691 | validation: 0.17107726111384214]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597133093125376		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.12597133093125376 | validation: 0.15780070145272132]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11828815299182618		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.11828815299182618 | validation: 0.1237918380331029]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11556776541234522		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.11556776541234522 | validation: 0.10879775007892872]
	TIME [epoch: 11.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899715225979468		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.09899715225979468 | validation: 0.11943869358578901]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12888653253431678		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.12888653253431678 | validation: 0.10573954977724664]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12748015449671604		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.12748015449671604 | validation: 0.18524513202805235]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12708173682499568		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.12708173682499568 | validation: 0.12850495791985306]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12276999606478621		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.12276999606478621 | validation: 0.11158576615004866]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071915040012166		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.1071915040012166 | validation: 0.10812098222497145]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530891263257637		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11530891263257637 | validation: 0.12712293223268978]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13780915354788684		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.13780915354788684 | validation: 0.11495329906495856]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10478467458658364		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.10478467458658364 | validation: 0.1435214506725092]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13847060504449554		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.13847060504449554 | validation: 0.12690834976083848]
	TIME [epoch: 11.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12412721591788564		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.12412721591788564 | validation: 0.10967465914114026]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09867809217969767		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.09867809217969767 | validation: 0.09971265361798123]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031601241783628		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.11031601241783628 | validation: 0.12681078306385404]
	TIME [epoch: 11.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15656221938625328		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.15656221938625328 | validation: 0.19818830236251628]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624241809243669		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.1624241809243669 | validation: 0.16938191423008156]
	TIME [epoch: 11.5 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14115431901403266		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.14115431901403266 | validation: 0.13676584261291708]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153306406658615		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.12153306406658615 | validation: 0.11556872498518604]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305237325060093		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.10305237325060093 | validation: 0.12542337122550237]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13749499758111336		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.13749499758111336 | validation: 0.131544578985698]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11833918720475758		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.11833918720475758 | validation: 0.17362933255123572]
	TIME [epoch: 11.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505215325813362		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.11505215325813362 | validation: 0.13876287568072654]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199959932873426		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.10199959932873426 | validation: 0.1089158108176913]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09661158705092487		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.09661158705092487 | validation: 0.10870227617611111]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657790077399367		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.09657790077399367 | validation: 0.11299371333248438]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534013323958522		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.10534013323958522 | validation: 0.12405308599420713]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006315567488081		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.11006315567488081 | validation: 0.126282179073376]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10986964558415598		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.10986964558415598 | validation: 0.12974602196435372]
	TIME [epoch: 11.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10885939508261018		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.10885939508261018 | validation: 0.1105902396973509]
	TIME [epoch: 11.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10127158316253826		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.10127158316253826 | validation: 0.10760064474606004]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280614681153308		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.09280614681153308 | validation: 0.1063773224590171]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11150022222749577		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.11150022222749577 | validation: 0.10011035403135353]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10273879055465464		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.10273879055465464 | validation: 0.1087641698698555]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005079359981207		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11005079359981207 | validation: 0.10770007379465796]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13867667026288927		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.13867667026288927 | validation: 0.12192981261072387]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10946609010768181		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.10946609010768181 | validation: 0.12342739197375512]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318448411617099		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.12318448411617099 | validation: 0.13228428229642458]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285597063674523		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.11285597063674523 | validation: 0.09955252175327424]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11263692449394314		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.11263692449394314 | validation: 0.10919767901139199]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977911664582668		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09977911664582668 | validation: 0.10778684380277496]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10493642544045735		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.10493642544045735 | validation: 0.12570840357352148]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12610825802746445		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.12610825802746445 | validation: 0.14693198900896767]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13524177928376147		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.13524177928376147 | validation: 0.128573106407901]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12884359777201876		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.12884359777201876 | validation: 0.10557310792457292]
	TIME [epoch: 11.5 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192904934877071		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.11192904934877071 | validation: 0.11051123648850222]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11175144014756479		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.11175144014756479 | validation: 0.14761260774445892]
	TIME [epoch: 11.5 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576595001200847		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.12576595001200847 | validation: 0.12192573842134703]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12669408173775504		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.12669408173775504 | validation: 0.12591582306350899]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11036573588976496		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.11036573588976496 | validation: 0.12394585624542555]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424296334926714		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.10424296334926714 | validation: 0.13112981386451505]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10908930631075743		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.10908930631075743 | validation: 0.14332462408160504]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10391079817165455		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.10391079817165455 | validation: 0.12954151122094473]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200692958560416		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.10200692958560416 | validation: 0.111916307104621]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09984596846647226		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.09984596846647226 | validation: 0.11079903656154462]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10405598088383189		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.10405598088383189 | validation: 0.19572650693431753]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144889853960559		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.144889853960559 | validation: 0.13728917150707873]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11025478767608228		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.11025478767608228 | validation: 0.11412625889360857]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10206217998027688		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.10206217998027688 | validation: 0.12880354032804425]
	TIME [epoch: 11.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14537763342698523		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.14537763342698523 | validation: 0.17902194596734006]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13515963061284073		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.13515963061284073 | validation: 0.10747875914003151]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104770650409797		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.104770650409797 | validation: 0.1301924687850693]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778356204062885		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.12778356204062885 | validation: 0.14258325863591245]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11462553975221904		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.11462553975221904 | validation: 0.10965107081135926]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333444377036582		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.1333444377036582 | validation: 0.10716107828848259]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110510562556288		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.10110510562556288 | validation: 0.10531465196014496]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092176591533755		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.10092176591533755 | validation: 0.10897595291249129]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09975343874674322		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.09975343874674322 | validation: 0.13892438927613338]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735251548840588		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.10735251548840588 | validation: 0.13206317941632154]
	TIME [epoch: 11.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13991349921059076		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.13991349921059076 | validation: 0.1648415459659382]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278910068821892		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.1278910068821892 | validation: 0.13923969254062385]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10724858501318285		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10724858501318285 | validation: 0.12963053783168701]
	TIME [epoch: 11.5 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10926490117309742		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.10926490117309742 | validation: 0.17191238676811765]
	TIME [epoch: 11.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12159416620605787		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.12159416620605787 | validation: 0.16176594455025378]
	TIME [epoch: 11.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12143560147078587		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.12143560147078587 | validation: 0.14564668917593435]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178443990965809		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1178443990965809 | validation: 0.16490142904330576]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12614681807844608		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.12614681807844608 | validation: 0.15084099327174116]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11774851422968041		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.11774851422968041 | validation: 0.1492855941724236]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168531118796125		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1168531118796125 | validation: 0.14035537816997912]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11237546032259188		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.11237546032259188 | validation: 0.1399990607507572]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070496964282867		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1070496964282867 | validation: 0.13060406458293589]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11473223347940022		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.11473223347940022 | validation: 0.13088458609723053]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567960041363827		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.10567960041363827 | validation: 0.12257620105746984]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10464032797227223		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.10464032797227223 | validation: 0.1282946433474371]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10476976397346177		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.10476976397346177 | validation: 0.14013230688757403]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050930997803217		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.10050930997803217 | validation: 0.13462509013656246]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308369359526881		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.10308369359526881 | validation: 0.12634183084150602]
	TIME [epoch: 11.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11424449577882667		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.11424449577882667 | validation: 0.11415752177253939]
	TIME [epoch: 11.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10799332342527523		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.10799332342527523 | validation: 0.1032216777568903]
	TIME [epoch: 11.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039042157841667		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.1039042157841667 | validation: 0.14450474375411068]
	TIME [epoch: 11.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11661128189283002		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.11661128189283002 | validation: 0.12515528644352106]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10427660578150426		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.10427660578150426 | validation: 0.10160076023279586]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11176996743824617		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.11176996743824617 | validation: 0.10624727276447228]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206951197343681		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.11206951197343681 | validation: 0.13970384035678596]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695654386838616		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.10695654386838616 | validation: 0.1501247137490485]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13236971823740099		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.13236971823740099 | validation: 0.11423558295405464]
	TIME [epoch: 11.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264729108083859		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.09264729108083859 | validation: 0.10549355313650248]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09621899266708513		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.09621899266708513 | validation: 0.11960243154988202]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12816571235215293		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.12816571235215293 | validation: 0.1560778534683033]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433498758559421		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.1433498758559421 | validation: 0.09725175357618557]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_974.pth
	Model improved!!!
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09808521135549297		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.09808521135549297 | validation: 0.11842570100096386]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525770935970591		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.10525770935970591 | validation: 0.11573255204877018]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810073567743173		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.10810073567743173 | validation: 0.11775990876319399]
	TIME [epoch: 11.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09436372653999768		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.09436372653999768 | validation: 0.11897151223871565]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674281159227186		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.10674281159227186 | validation: 0.11120815836821749]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10110611885302409		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.10110611885302409 | validation: 0.10785766027137292]
	TIME [epoch: 11.5 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10042564398992404		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.10042564398992404 | validation: 0.10495159271238497]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1047596975913568		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.1047596975913568 | validation: 0.12508760755677026]
	TIME [epoch: 11.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1142272241383912		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.1142272241383912 | validation: 0.10200118482617597]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10215968236920658		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.10215968236920658 | validation: 0.1325981719576808]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795976763710221		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.11795976763710221 | validation: 0.11355410237391317]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338618036660536		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.1338618036660536 | validation: 0.17626718960074622]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970186109745967		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.11970186109745967 | validation: 0.10328580914060684]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09696844684819543		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.09696844684819543 | validation: 0.1035427857075631]
	TIME [epoch: 11.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1130020262302935		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.1130020262302935 | validation: 0.15930177846320073]
	TIME [epoch: 11.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14858268904305516		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.14858268904305516 | validation: 0.10232744464053585]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958960726678963		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.09958960726678963 | validation: 0.10657387062116501]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11080280340636128		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.11080280340636128 | validation: 0.10666396584881578]
	TIME [epoch: 11.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09778021885400884		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.09778021885400884 | validation: 0.09913401780750863]
	TIME [epoch: 11.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949984468341468		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0949984468341468 | validation: 0.11388890953357955]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08671393651605491		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.08671393651605491 | validation: 0.10648022136628679]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09121144483855032		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.09121144483855032 | validation: 0.11016152573761355]
	TIME [epoch: 11.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08651094654044035		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.08651094654044035 | validation: 0.09457324122362039]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_997.pth
	Model improved!!!
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09095158419356161		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.09095158419356161 | validation: 0.10275287959386525]
	TIME [epoch: 11.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863629553814453		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.0863629553814453 | validation: 0.09874236023806802]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09317492084540034		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.09317492084540034 | validation: 0.12254752882301868]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620103439343966		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.09620103439343966 | validation: 0.13019652127018783]
	TIME [epoch: 11.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12945660618001723		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.12945660618001723 | validation: 0.22503864791578415]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17108309157376086		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.17108309157376086 | validation: 0.13755805241822888]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734665382408525		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.12734665382408525 | validation: 0.14765179154303]
	TIME [epoch: 11.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125051571892168		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.1125051571892168 | validation: 0.10279936291458489]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947200476400584		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.0947200476400584 | validation: 0.10975045062395303]
	TIME [epoch: 11.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09670671372513298		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.09670671372513298 | validation: 0.11223565456549515]
	TIME [epoch: 11.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11898178656898642		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.11898178656898642 | validation: 0.1455134366347996]
	TIME [epoch: 11.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639153976990212		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.10639153976990212 | validation: 0.11825073432887565]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977290323177846		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.0977290323177846 | validation: 0.10047625550458435]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1001666796316318		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.1001666796316318 | validation: 0.12506196563931257]
	TIME [epoch: 11.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212591754016909		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.1212591754016909 | validation: 0.12432258487075747]
	TIME [epoch: 11.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09772932908604817		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.09772932908604817 | validation: 0.10083888030440746]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08886067943377286		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08886067943377286 | validation: 0.10291547871091991]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0894220754282768		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.0894220754282768 | validation: 0.10464127772881446]
	TIME [epoch: 11.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10296400472384327		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.10296400472384327 | validation: 0.11876915164404936]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249379212111517		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.10249379212111517 | validation: 0.10439363849034933]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033058982150057		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.1033058982150057 | validation: 0.10435190057573791]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10811166510936557		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.10811166510936557 | validation: 0.1272251849416154]
	TIME [epoch: 11.5 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09958386129955385		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.09958386129955385 | validation: 0.12667612457543845]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13503004702663668		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.13503004702663668 | validation: 0.13478318233025283]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15602089075935566		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.15602089075935566 | validation: 0.16919337867638493]
	TIME [epoch: 11.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12895836271329064		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.12895836271329064 | validation: 0.13531977725000743]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10257378187469764		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.10257378187469764 | validation: 0.11256172015554175]
	TIME [epoch: 11.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0911661388304636		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.0911661388304636 | validation: 0.11624599139891544]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0925036575306034		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.0925036575306034 | validation: 0.10217842155592481]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10256111181627538		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.10256111181627538 | validation: 0.10567822494598432]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633957986432152		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.10633957986432152 | validation: 0.18331887857866233]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17811135388287738		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.17811135388287738 | validation: 0.19479570788501244]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12686050999599707		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.12686050999599707 | validation: 0.10383251181651713]
	TIME [epoch: 11.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09149157948603008		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.09149157948603008 | validation: 0.10959525543844453]
	TIME [epoch: 11.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09758916420167373		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.09758916420167373 | validation: 0.11383124793691161]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660474393512928		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.10660474393512928 | validation: 0.09034911813437146]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09590596968279957		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.09590596968279957 | validation: 0.10519987922387397]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10430951043739842		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.10430951043739842 | validation: 0.09177660554377352]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08855453207177477		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.08855453207177477 | validation: 0.10587017369237291]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09194074434822791		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09194074434822791 | validation: 0.10290823677161573]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11636971326251491		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.11636971326251491 | validation: 0.16563151109129198]
	TIME [epoch: 11.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14123313277756055		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.14123313277756055 | validation: 0.11461546070468849]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10016586574090143		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.10016586574090143 | validation: 0.12105263332943927]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10330256580833991		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.10330256580833991 | validation: 0.1026519785042925]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648803421148411		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.09648803421148411 | validation: 0.09717507523049354]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09153113836801055		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.09153113836801055 | validation: 0.12026694910034173]
	TIME [epoch: 11.6 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11309101796338386		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.11309101796338386 | validation: 0.12074998822568221]
	TIME [epoch: 11.6 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643939987184903		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.09643939987184903 | validation: 0.10154017821712423]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09881822522830076		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.09881822522830076 | validation: 0.11699110791027872]
	TIME [epoch: 11.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11985831625090763		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.11985831625090763 | validation: 0.12398179584253693]
	TIME [epoch: 11.6 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381050758641082		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.10381050758641082 | validation: 0.11965110630229264]
	TIME [epoch: 11.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024863988309668		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1024863988309668 | validation: 0.10618463999587732]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633648229512078		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.10633648229512078 | validation: 0.1500705413161705]
	TIME [epoch: 11.6 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12093144904482735		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.12093144904482735 | validation: 0.10784946373524257]
	TIME [epoch: 11.6 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240020381393027		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.09240020381393027 | validation: 0.0982534420295711]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09706309846812682		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.09706309846812682 | validation: 0.0941567610914441]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09915028881065799		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.09915028881065799 | validation: 0.11392619655940077]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10349046218533417		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.10349046218533417 | validation: 0.1077040557267555]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860716026448453		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.10860716026448453 | validation: 0.113560944033379]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09074122848453478		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.09074122848453478 | validation: 0.09396041370098906]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984812426701466		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0984812426701466 | validation: 0.1102797616349016]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09278161616752935		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.09278161616752935 | validation: 0.10277767241260305]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10164245789528484		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.10164245789528484 | validation: 0.09345361416911489]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09576471231224745		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.09576471231224745 | validation: 0.13754845942750893]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1470101762658278		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.1470101762658278 | validation: 0.1581919691205564]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1457454709241272		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.1457454709241272 | validation: 0.10795518601569193]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09626840461576364		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.09626840461576364 | validation: 0.11015894929392106]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211676881316008		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1211676881316008 | validation: 0.12272146952966612]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10765767365389464		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.10765767365389464 | validation: 0.0925300491603429]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08237006887911598		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.08237006887911598 | validation: 0.0932801053017166]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08891018457517805		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.08891018457517805 | validation: 0.10481760629944191]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09390277586675007		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.09390277586675007 | validation: 0.10578604447125367]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09404577691892897		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.09404577691892897 | validation: 0.098984952638887]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09144621998493815		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.09144621998493815 | validation: 0.09535427465162791]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09517321381234745		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.09517321381234745 | validation: 0.12349388179100881]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10373614961006966		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.10373614961006966 | validation: 0.12160205887859697]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09876110882084584		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.09876110882084584 | validation: 0.1124534845039577]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10007469269533939		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.10007469269533939 | validation: 0.12197865603141576]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690661752147401		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.11690661752147401 | validation: 0.11485601452084504]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156754668847224		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.11156754668847224 | validation: 0.11733643863970365]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.102882180007676		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.102882180007676 | validation: 0.09156576193428306]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09582392384637438		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.09582392384637438 | validation: 0.1073039881546114]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332271053889382		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.10332271053889382 | validation: 0.09517099915536673]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477354000710243		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.10477354000710243 | validation: 0.11639903173338371]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11970026155790123		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.11970026155790123 | validation: 0.1364873435058803]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338030690155174		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.10338030690155174 | validation: 0.10601103181677451]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163076464807494		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.10163076464807494 | validation: 0.11797023226655658]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12048660880104671		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.12048660880104671 | validation: 0.10832621630100095]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1006803540254761		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.1006803540254761 | validation: 0.10410244251198243]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542785940819182		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.09542785940819182 | validation: 0.0903257475694617]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09894441064531276		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.09894441064531276 | validation: 0.11107932699939556]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10348439693199782		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.10348439693199782 | validation: 0.14172365368356776]
	TIME [epoch: 11.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844876122694056		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.11844876122694056 | validation: 0.1191261312440016]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145864404286841		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.1145864404286841 | validation: 0.14362469723343874]
	TIME [epoch: 11.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578309283162175		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.14578309283162175 | validation: 0.11174124151087732]
	TIME [epoch: 11.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11730035076820941		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.11730035076820941 | validation: 0.10943054160778935]
	TIME [epoch: 11.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089807749036192		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.1089807749036192 | validation: 0.11714862437891732]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685531232032976		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.09685531232032976 | validation: 0.09198665822239643]
	TIME [epoch: 11.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779007071776263		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.09779007071776263 | validation: 0.11255146624520501]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073076173834655		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1073076173834655 | validation: 0.11097366952888603]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09503821093364995		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.09503821093364995 | validation: 0.09567566885694972]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11341095757862128		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11341095757862128 | validation: 0.11363571474946742]
	TIME [epoch: 11.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075324357996536		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.1075324357996536 | validation: 0.10703014457542191]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10704975647062145		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.10704975647062145 | validation: 0.10121878303965932]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09430929834367133		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.09430929834367133 | validation: 0.10283302973005753]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09891994721806875		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.09891994721806875 | validation: 0.09687746806705079]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09705014533107759		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09705014533107759 | validation: 0.0934749457707927]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09829225584827549		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.09829225584827549 | validation: 0.09298733081231779]
	TIME [epoch: 11.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0924245959619597		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0924245959619597 | validation: 0.08803367998394027]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1106.pth
	Model improved!!!
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251765427054737		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.09251765427054737 | validation: 0.08752593025439719]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1107.pth
	Model improved!!!
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09613618971255902		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.09613618971255902 | validation: 0.10922974428508067]
	TIME [epoch: 11.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10747609357348961		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.10747609357348961 | validation: 0.11432756806883591]
	TIME [epoch: 11.5 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11104119270377887		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.11104119270377887 | validation: 0.0996452873317981]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091327055008293		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.1091327055008293 | validation: 0.09397672007161978]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997842848218252		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08997842848218252 | validation: 0.10722014998880613]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10219537973886592		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.10219537973886592 | validation: 0.11378715979139564]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10449013229611513		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.10449013229611513 | validation: 0.09664739649921972]
	TIME [epoch: 11.5 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534352739649084		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.08534352739649084 | validation: 0.09499627170101554]
	TIME [epoch: 11.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09235082189722729		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.09235082189722729 | validation: 0.10643746299378179]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09028330333586837		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.09028330333586837 | validation: 0.10476927055363212]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09553216173994306		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.09553216173994306 | validation: 0.09769974945815477]
	TIME [epoch: 11.5 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08371375250090689		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.08371375250090689 | validation: 0.09944432774988425]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941241392974536		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.0941241392974536 | validation: 0.10386922723391952]
	TIME [epoch: 11.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544482770590881		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.09544482770590881 | validation: 0.1047849869462524]
	TIME [epoch: 11.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10452450426209087		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.10452450426209087 | validation: 0.12362868154528318]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841718491403258		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.09841718491403258 | validation: 0.09842822823256406]
	TIME [epoch: 11.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09048556714227894		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.09048556714227894 | validation: 0.11076255732403038]
	TIME [epoch: 11.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099758445166452		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.099758445166452 | validation: 0.08681638384859296]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1125.pth
	Model improved!!!
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09577882641916344		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.09577882641916344 | validation: 0.09463332995597469]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124943583369535		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.09124943583369535 | validation: 0.09403719184159828]
	TIME [epoch: 11.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843349579052955		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0843349579052955 | validation: 0.09386163869290368]
	TIME [epoch: 11.5 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08909422100994677		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.08909422100994677 | validation: 0.09367359953636062]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08609296291594913		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.08609296291594913 | validation: 0.10040238403212698]
	TIME [epoch: 11.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09510853086456357		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.09510853086456357 | validation: 0.10095992068583495]
	TIME [epoch: 11.5 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08606290391091483		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08606290391091483 | validation: 0.10727943468565836]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09289519937395264		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.09289519937395264 | validation: 0.12173382966861673]
	TIME [epoch: 11.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10234989643691242		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.10234989643691242 | validation: 0.10971935458933835]
	TIME [epoch: 11.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09219519005556692		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.09219519005556692 | validation: 0.11503814895534956]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060327658168682		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.09060327658168682 | validation: 0.11137568356049807]
	TIME [epoch: 11.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09199705111330868		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.09199705111330868 | validation: 0.11080540473204523]
	TIME [epoch: 11.5 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09067116436055708		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.09067116436055708 | validation: 0.09826336167135372]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0926152342809127		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0926152342809127 | validation: 0.09880582301387214]
	TIME [epoch: 11.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022263393748861		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.09022263393748861 | validation: 0.09893700176534673]
	TIME [epoch: 11.5 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068478561015831		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.08068478561015831 | validation: 0.09568148313495278]
	TIME [epoch: 11.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09388382101222031		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.09388382101222031 | validation: 0.10105949177861029]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358762048846405		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.08358762048846405 | validation: 0.08917733251484525]
	TIME [epoch: 11.5 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08454495436764642		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.08454495436764642 | validation: 0.1062104183734693]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09600748355321315		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.09600748355321315 | validation: 0.09026317350840088]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863117091968988		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.0863117091968988 | validation: 0.09509108173049252]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824404743233286		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.0824404743233286 | validation: 0.10917956416298501]
	TIME [epoch: 11.5 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09431474547836032		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.09431474547836032 | validation: 0.11803406530309721]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09127882311094634		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.09127882311094634 | validation: 0.11238355225323268]
	TIME [epoch: 11.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09495935066876036		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.09495935066876036 | validation: 0.11130082355520056]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620313387555264		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10620313387555264 | validation: 0.13067044295076685]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09397693563170785		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.09397693563170785 | validation: 0.12002076138250405]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379129834509969		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.10379129834509969 | validation: 0.11928632684855067]
	TIME [epoch: 11.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375429252278953		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.10375429252278953 | validation: 0.10805937315653]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08570188985685223		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.08570188985685223 | validation: 0.09361042585519685]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847588393270402		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0847588393270402 | validation: 0.08920040917812784]
	TIME [epoch: 11.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944231250570115		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.0944231250570115 | validation: 0.10640475386025985]
	TIME [epoch: 11.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09533004461287233		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.09533004461287233 | validation: 0.10593298524312146]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08648795771697873		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.08648795771697873 | validation: 0.10945714811505688]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351833353078272		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.09351833353078272 | validation: 0.1030495210826997]
	TIME [epoch: 11.5 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09432275706387747		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.09432275706387747 | validation: 0.09645706889237006]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088843082982198		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.09088843082982198 | validation: 0.09670863404781105]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10238320792840994		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.10238320792840994 | validation: 0.12290483484403349]
	TIME [epoch: 11.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10722398927137107		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.10722398927137107 | validation: 0.1037027117200469]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710150375269086		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.08710150375269086 | validation: 0.10560062690960564]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089479474040368		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.09089479474040368 | validation: 0.09694148372899251]
	TIME [epoch: 11.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09330867078889715		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.09330867078889715 | validation: 0.09733684173308181]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08783500757504527		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.08783500757504527 | validation: 0.09532770832553265]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08481026170451911		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.08481026170451911 | validation: 0.12332817286460841]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317059792432368		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.10317059792432368 | validation: 0.12736558636300122]
	TIME [epoch: 11.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10193822103567993		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.10193822103567993 | validation: 0.1050439046174996]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872587143001475		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.0872587143001475 | validation: 0.11006499549186356]
	TIME [epoch: 11.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09347689761088573		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.09347689761088573 | validation: 0.09528781992422769]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827248027362037		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.0827248027362037 | validation: 0.08863573214148535]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08782274404826097		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.08782274404826097 | validation: 0.09746457507486059]
	TIME [epoch: 11.6 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563689632711588		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.08563689632711588 | validation: 0.08961630277482882]
	TIME [epoch: 11.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08622118375137991		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.08622118375137991 | validation: 0.10476278681171261]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09060669423755703		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.09060669423755703 | validation: 0.09628924782645396]
	TIME [epoch: 11.5 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08526620240811848		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.08526620240811848 | validation: 0.09694641257738462]
	TIME [epoch: 11.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323849732797865		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.08323849732797865 | validation: 0.08720103215951693]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257305531298886		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.08257305531298886 | validation: 0.08916245490271697]
	TIME [epoch: 11.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08298846492186937		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.08298846492186937 | validation: 0.09851539793845415]
	TIME [epoch: 11.5 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08990011916061773		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.08990011916061773 | validation: 0.08733338196125161]
	TIME [epoch: 11.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08711781743583333		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.08711781743583333 | validation: 0.09029067253611096]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0858550236405914		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0858550236405914 | validation: 0.09551941944742233]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342585122249665		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.09342585122249665 | validation: 0.1460862363287592]
	TIME [epoch: 11.5 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10286996573396107		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.10286996573396107 | validation: 0.08651299987411629]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1187.pth
	Model improved!!!
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422187610374213		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.08422187610374213 | validation: 0.08952212552928718]
	TIME [epoch: 11.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08707174308391052		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.08707174308391052 | validation: 0.09701034845927098]
	TIME [epoch: 11.5 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08752770256509837		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.08752770256509837 | validation: 0.08272799185235594]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1190.pth
	Model improved!!!
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278589574624284		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.08278589574624284 | validation: 0.09591102378876705]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.093492734609043		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.093492734609043 | validation: 0.09149505315909508]
	TIME [epoch: 11.5 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09796602639336477		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.09796602639336477 | validation: 0.10049336599638861]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0921541931254976		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.0921541931254976 | validation: 0.09609611451717957]
	TIME [epoch: 11.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0891616491302031		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0891616491302031 | validation: 0.09951000774738238]
	TIME [epoch: 11.6 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108716682016088		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.09108716682016088 | validation: 0.09003671127572634]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08903431767322084		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.08903431767322084 | validation: 0.08793869147364147]
	TIME [epoch: 11.6 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821874889100095		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.08821874889100095 | validation: 0.09396499263176585]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623377354326214		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.08623377354326214 | validation: 0.09705747878998772]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832240590634326		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.08832240590634326 | validation: 0.10138210827931352]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08822321459464813		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.08822321459464813 | validation: 0.08791187110058679]
	TIME [epoch: 11.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052202943367291		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.08052202943367291 | validation: 0.09200935648725522]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330482874326936		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.08330482874326936 | validation: 0.08530670524532209]
	TIME [epoch: 11.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313420017395985		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.08313420017395985 | validation: 0.08995797311036453]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09614854393637638		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.09614854393637638 | validation: 0.09885039390487275]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09913647071299334		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.09913647071299334 | validation: 0.0926028575291165]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09383965850093011		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.09383965850093011 | validation: 0.09244510301421896]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08728127876909739		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.08728127876909739 | validation: 0.10415956555915601]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08806467833478444		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.08806467833478444 | validation: 0.10356048606576193]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08424190696929687		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.08424190696929687 | validation: 0.09642543873768687]
	TIME [epoch: 11.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593698369368963		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.08593698369368963 | validation: 0.09934249790285576]
	TIME [epoch: 11.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838078426678092		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.08838078426678092 | validation: 0.11385462451115455]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09069797573300013		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.09069797573300013 | validation: 0.09997304670632919]
	TIME [epoch: 11.5 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864783699888936		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.0864783699888936 | validation: 0.10054810511612358]
	TIME [epoch: 11.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09667671466081873		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.09667671466081873 | validation: 0.10791569341159306]
	TIME [epoch: 11.5 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181763119592004		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.09181763119592004 | validation: 0.10045281541374157]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971616956609345		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.08971616956609345 | validation: 0.09792769407251106]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0927083354503858		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.0927083354503858 | validation: 0.11066468142473791]
	TIME [epoch: 11.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09362437447535248		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.09362437447535248 | validation: 0.09478236897626374]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826329639035742		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0826329639035742 | validation: 0.1026832829049437]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09513488803289002		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.09513488803289002 | validation: 0.10122024438903793]
	TIME [epoch: 11.5 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09345899489186824		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.09345899489186824 | validation: 0.09722980723245646]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804796419700661		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.08804796419700661 | validation: 0.09644749469174854]
	TIME [epoch: 11.6 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09253113717851866		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.09253113717851866 | validation: 0.10677215112599886]
	TIME [epoch: 11.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09762469447832064		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.09762469447832064 | validation: 0.11851041757317754]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11440077426608294		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.11440077426608294 | validation: 0.12188766673604827]
	TIME [epoch: 11.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335176409978646		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.10335176409978646 | validation: 0.11002500920144172]
	TIME [epoch: 11.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10242403416566666		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.10242403416566666 | validation: 0.10590234419443288]
	TIME [epoch: 11.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09653102205445403		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.09653102205445403 | validation: 0.11359893450556077]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964214723310406		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.0964214723310406 | validation: 0.108831658759306]
	TIME [epoch: 11.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1063501448419809		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1063501448419809 | validation: 0.1112640055395075]
	TIME [epoch: 11.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09607677819559643		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.09607677819559643 | validation: 0.10512265802871279]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09844523104076569		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.09844523104076569 | validation: 0.13861398162178679]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854223594373898		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10854223594373898 | validation: 0.11175558304750809]
	TIME [epoch: 11.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0974085553205679		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.0974085553205679 | validation: 0.10439355104762521]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08975956801372188		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.08975956801372188 | validation: 0.10762711920791958]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08626267040930499		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.08626267040930499 | validation: 0.09829318019372735]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09132782710670359		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.09132782710670359 | validation: 0.1142166143487454]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08806309681451786		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.08806309681451786 | validation: 0.09675507172439414]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08951416322940492		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.08951416322940492 | validation: 0.0929098503302267]
	TIME [epoch: 11.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08187831908491304		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.08187831908491304 | validation: 0.1035579103443405]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09188571817747074		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.09188571817747074 | validation: 0.10235173160864157]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915277197697445		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.0915277197697445 | validation: 0.10088521935208723]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08833106515464498		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.08833106515464498 | validation: 0.10574906593571086]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09703507407478008		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.09703507407478008 | validation: 0.10980797384976353]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09552396433113296		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.09552396433113296 | validation: 0.09696200432867047]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09349677193805232		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.09349677193805232 | validation: 0.10593148225396248]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582111421789472		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.08582111421789472 | validation: 0.10134813883443389]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908309717348382		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.08908309717348382 | validation: 0.08833343539631319]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886377973055193		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.0886377973055193 | validation: 0.10104455122501735]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499688814521229		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.09499688814521229 | validation: 0.09558441724842986]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936283526914162		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0936283526914162 | validation: 0.0915932490028055]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09593031948323094		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.09593031948323094 | validation: 0.11066750232325859]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353655171089236		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.10353655171089236 | validation: 0.12441430908337626]
	TIME [epoch: 11.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10530127112507687		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.10530127112507687 | validation: 0.09568765303584251]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0879615549027022		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.0879615549027022 | validation: 0.08713837100637477]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08033341932391		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.08033341932391 | validation: 0.09603968163646165]
	TIME [epoch: 11.5 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09257849181237138		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.09257849181237138 | validation: 0.11436958059186834]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10667922463441314		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.10667922463441314 | validation: 0.10865901517295981]
	TIME [epoch: 11.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380183588934523		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.10380183588934523 | validation: 0.10217141941952958]
	TIME [epoch: 11.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09644805901416915		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.09644805901416915 | validation: 0.1091776368131548]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09086964030473649		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.09086964030473649 | validation: 0.0945313258661976]
	TIME [epoch: 11.6 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08410257998871418		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.08410257998871418 | validation: 0.09431466443873208]
	TIME [epoch: 11.6 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010741061962846		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.09010741061962846 | validation: 0.08985500098308476]
	TIME [epoch: 11.6 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08499622760713546		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.08499622760713546 | validation: 0.08509178374254843]
	TIME [epoch: 11.6 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512825636044996		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.08512825636044996 | validation: 0.0863249937969893]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08728523584542815		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.08728523584542815 | validation: 0.09235529457536351]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09390133882114354		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.09390133882114354 | validation: 0.11875826637126878]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10681029777416427		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.10681029777416427 | validation: 0.12269499432533833]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10830543102876881		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.10830543102876881 | validation: 0.10985104173080093]
	TIME [epoch: 11.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756658565197787		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.10756658565197787 | validation: 0.11067821699302918]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951915280472917		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.10951915280472917 | validation: 0.09662132473261104]
	TIME [epoch: 11.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09509479328550957		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.09509479328550957 | validation: 0.09435009136309891]
	TIME [epoch: 11.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09251055392088652		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.09251055392088652 | validation: 0.08724896136946007]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726610747083015		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.08726610747083015 | validation: 0.10638016036218588]
	TIME [epoch: 11.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09857346838263764		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.09857346838263764 | validation: 0.1075921665464998]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856981622347818		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.0856981622347818 | validation: 0.09119425222746978]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08796971723593335		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.08796971723593335 | validation: 0.10470202434161882]
	TIME [epoch: 11.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126231381401231		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.09126231381401231 | validation: 0.10289373943274244]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939141440968369		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.0939141440968369 | validation: 0.0960623107473066]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08289056360393016		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.08289056360393016 | validation: 0.08274646654737797]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019447791698811		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.08019447791698811 | validation: 0.09890941145958274]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09336115953586888		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.09336115953586888 | validation: 0.1140442877438802]
	TIME [epoch: 11.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10805735548805091		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.10805735548805091 | validation: 0.12522418200039723]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090146622055084		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.10090146622055084 | validation: 0.11062659512378073]
	TIME [epoch: 11.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173132637667082		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.10173132637667082 | validation: 0.11174443695780589]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038169239447064		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.1038169239447064 | validation: 0.09561858224758649]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09273388620805881		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.09273388620805881 | validation: 0.09552729317942722]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08878206006277813		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.08878206006277813 | validation: 0.07963405663437617]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1289.pth
	Model improved!!!
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.090542620148687		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.090542620148687 | validation: 0.10100069670891466]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09718886194681312		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.09718886194681312 | validation: 0.10042043578611551]
	TIME [epoch: 11.6 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08808277033817345		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.08808277033817345 | validation: 0.08815693258890886]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08117926179699812		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.08117926179699812 | validation: 0.07883002056759135]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1293.pth
	Model improved!!!
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535288828968439		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.08535288828968439 | validation: 0.08207315396822214]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.087838046880882		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.087838046880882 | validation: 0.09025288020136975]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573697662465596		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.08573697662465596 | validation: 0.08663699267918151]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08038394225950937		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.08038394225950937 | validation: 0.08910455806072974]
	TIME [epoch: 11.6 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0817684485026372		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0817684485026372 | validation: 0.09073000048473034]
	TIME [epoch: 11.6 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487349174284714		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.08487349174284714 | validation: 0.08713550093856874]
	TIME [epoch: 11.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08886437879184092		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.08886437879184092 | validation: 0.0875836413184114]
	TIME [epoch: 11.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08847171072379717		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.08847171072379717 | validation: 0.08553436530911014]
	TIME [epoch: 11.5 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408797608080396		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.08408797608080396 | validation: 0.09193901659353312]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089255462910262		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.089255462910262 | validation: 0.0869370939427304]
	TIME [epoch: 11.6 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08810537617510557		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.08810537617510557 | validation: 0.0977814611298793]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521094620069153		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.08521094620069153 | validation: 0.08400135191292707]
	TIME [epoch: 11.6 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596953032920107		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.08596953032920107 | validation: 0.09067139363670748]
	TIME [epoch: 11.6 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08805766208395528		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.08805766208395528 | validation: 0.08613295035899136]
	TIME [epoch: 11.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08031878754378419		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.08031878754378419 | validation: 0.09471930682910945]
	TIME [epoch: 11.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08236708694068481		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.08236708694068481 | validation: 0.094894052343817]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368117019411088		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.08368117019411088 | validation: 0.09980830236216708]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08333155300123637		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.08333155300123637 | validation: 0.08703676867419707]
	TIME [epoch: 11.6 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822385580870152		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0822385580870152 | validation: 0.09195438110826232]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0843685770134965		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.0843685770134965 | validation: 0.09917445082435129]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08711745107237424		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.08711745107237424 | validation: 0.1161469060528589]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09369948339758291		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.09369948339758291 | validation: 0.11488503774185191]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10143466289623729		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.10143466289623729 | validation: 0.11295158597143697]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0984395965804196		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.0984395965804196 | validation: 0.10745846655365464]
	TIME [epoch: 11.6 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408513757407178		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.08408513757407178 | validation: 0.09633848045182189]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142865149060506		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.08142865149060506 | validation: 0.08385506985877399]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174920135488224		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.08174920135488224 | validation: 0.08934372941471935]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07931025451522083		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.07931025451522083 | validation: 0.08696018589068194]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080483590372857		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.08080483590372857 | validation: 0.09675818416125127]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07951316699572171		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07951316699572171 | validation: 0.08925860420477393]
	TIME [epoch: 11.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012271218158386		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.08012271218158386 | validation: 0.08753191959915078]
	TIME [epoch: 11.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07760579211259541		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.07760579211259541 | validation: 0.09026323086121252]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08732437696048675		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.08732437696048675 | validation: 0.09926380997357777]
	TIME [epoch: 11.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639946287067919		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.08639946287067919 | validation: 0.0842048818306245]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793724783784554		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0793724783784554 | validation: 0.08678321288449999]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276801116671585		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.08276801116671585 | validation: 0.09250349641475569]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09038458286123388		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.09038458286123388 | validation: 0.09938984662989338]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0931524124895125		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.0931524124895125 | validation: 0.09498054585513327]
	TIME [epoch: 11.6 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09040788870905961		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.09040788870905961 | validation: 0.07952006358570907]
	TIME [epoch: 11.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07937050150220894		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.07937050150220894 | validation: 0.08378027345883998]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196124214965751		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.08196124214965751 | validation: 0.0879757433191873]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08425836120253563		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.08425836120253563 | validation: 0.0987822996612933]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08695075616176262		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.08695075616176262 | validation: 0.09072075383822409]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.082687297187525		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.082687297187525 | validation: 0.09621475930399827]
	TIME [epoch: 11.6 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877916657813607		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.0877916657813607 | validation: 0.09183156461958161]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08930172114873353		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.08930172114873353 | validation: 0.10118308586211072]
	TIME [epoch: 11.6 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085780878185924		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.085780878185924 | validation: 0.09229984955809314]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643203577077913		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.08643203577077913 | validation: 0.08863071238323537]
	TIME [epoch: 11.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09217828753911397		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.09217828753911397 | validation: 0.08788377224842796]
	TIME [epoch: 11.5 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765394980588262		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.08765394980588262 | validation: 0.08589225852105802]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997164088322045		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.07997164088322045 | validation: 0.0839999306580179]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962615827555627		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.07962615827555627 | validation: 0.08253068224934249]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073835404927604		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.08073835404927604 | validation: 0.09263451813548933]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575580300366144		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.08575580300366144 | validation: 0.09997021698341187]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351308350671073		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.08351308350671073 | validation: 0.09001277977462141]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08462719516811111		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.08462719516811111 | validation: 0.0950193755486615]
	TIME [epoch: 11.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.081080672107346		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.081080672107346 | validation: 0.09465135017812762]
	TIME [epoch: 11.5 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321526398817297		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.08321526398817297 | validation: 0.09527031575899864]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243666820659735		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.08243666820659735 | validation: 0.09858311025096558]
	TIME [epoch: 11.5 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08767978594491357		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.08767978594491357 | validation: 0.10609317606518129]
	TIME [epoch: 11.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08809148151427795		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.08809148151427795 | validation: 0.09932604744092206]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0825890836854366		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.0825890836854366 | validation: 0.10658334979320877]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743577582811478		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.08743577582811478 | validation: 0.11037464123579778]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634907687167329		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.08634907687167329 | validation: 0.09820773007081494]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08474014442711972		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.08474014442711972 | validation: 0.09194165308257192]
	TIME [epoch: 11.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08818892088394892		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.08818892088394892 | validation: 0.09662696431848897]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08296553748457908		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.08296553748457908 | validation: 0.09566463660653947]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09519913865085845		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.09519913865085845 | validation: 0.09434569762667183]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841251698660377		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.08841251698660377 | validation: 0.09083308517226991]
	TIME [epoch: 11.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08511486844439281		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.08511486844439281 | validation: 0.09490434009124148]
	TIME [epoch: 11.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08995007217663345		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.08995007217663345 | validation: 0.09232152607654019]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08170258550801932		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.08170258550801932 | validation: 0.08672125610091172]
	TIME [epoch: 11.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08841193552233298		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.08841193552233298 | validation: 0.0885929068786416]
	TIME [epoch: 11.6 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08368123103109781		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.08368123103109781 | validation: 0.09709260112424938]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209615103597823		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.08209615103597823 | validation: 0.08742116068554863]
	TIME [epoch: 11.6 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08398839060724969		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.08398839060724969 | validation: 0.10187526128623844]
	TIME [epoch: 11.6 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08328624751204386		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.08328624751204386 | validation: 0.09880845694531058]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08541848525439319		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.08541848525439319 | validation: 0.10336209254822515]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083055917181532		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.083055917181532 | validation: 0.09631433988236601]
	TIME [epoch: 11.6 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533076069901228		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.08533076069901228 | validation: 0.08827393992572798]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0830711249838473		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.0830711249838473 | validation: 0.08949670926490091]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0896165833763504		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.0896165833763504 | validation: 0.09656204563257265]
	TIME [epoch: 11.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916597949865174		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.0916597949865174 | validation: 0.09749206823425066]
	TIME [epoch: 11.6 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08522724522350225		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.08522724522350225 | validation: 0.10055802653841918]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232097265545624		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.08232097265545624 | validation: 0.09183065809835966]
	TIME [epoch: 11.6 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08477565088384856		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.08477565088384856 | validation: 0.0871938892505711]
	TIME [epoch: 11.6 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08383517787399178		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.08383517787399178 | validation: 0.11357386273977334]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09324551062409923		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.09324551062409923 | validation: 0.10133861030284629]
	TIME [epoch: 11.6 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730055553360128		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.08730055553360128 | validation: 0.08415151596638352]
	TIME [epoch: 11.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08162037976307585		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.08162037976307585 | validation: 0.08454652733531955]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0841439163902268		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.0841439163902268 | validation: 0.09254480254275883]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641518946944227		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.08641518946944227 | validation: 0.09640600132384743]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607062253339229		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.08607062253339229 | validation: 0.1022589933245476]
	TIME [epoch: 11.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0866725666824344		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.0866725666824344 | validation: 0.09929676821735171]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08146953227798168		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.08146953227798168 | validation: 0.09750358664068606]
	TIME [epoch: 11.6 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07909144033587732		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.07909144033587732 | validation: 0.08857582028171831]
	TIME [epoch: 11.6 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08332033265625578		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.08332033265625578 | validation: 0.0848036871554525]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07863419405751162		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.07863419405751162 | validation: 0.09098595958047433]
	TIME [epoch: 11.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08209598820677984		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.08209598820677984 | validation: 0.09628382812136511]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348504594907427		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.08348504594907427 | validation: 0.097569867397913]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753854134884874		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.08753854134884874 | validation: 0.08439058140706283]
	TIME [epoch: 11.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08297615651326189		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.08297615651326189 | validation: 0.090478410892873]
	TIME [epoch: 11.6 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08476401428412267		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.08476401428412267 | validation: 0.0816510767310194]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08254695667296996		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.08254695667296996 | validation: 0.08507470536808125]
	TIME [epoch: 11.6 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354261936981727		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.08354261936981727 | validation: 0.0916193426008331]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08793711095876873		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.08793711095876873 | validation: 0.09134825529015675]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08759367665596517		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.08759367665596517 | validation: 0.08574605378112034]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535074166059041		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.08535074166059041 | validation: 0.09238524451288324]
	TIME [epoch: 11.6 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753078481792154		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.08753078481792154 | validation: 0.09853892804150592]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08656815471175182		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.08656815471175182 | validation: 0.09394308474065594]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08659020544461518		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.08659020544461518 | validation: 0.09451034086838563]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873412427453471		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.0873412427453471 | validation: 0.08403655682141882]
	TIME [epoch: 11.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607731498913748		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.08607731498913748 | validation: 0.09684775068280246]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0852970217979948		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.0852970217979948 | validation: 0.08747485774905832]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08618490181129934		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.08618490181129934 | validation: 0.08912909439514698]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507183538595758		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.08507183538595758 | validation: 0.08093156561822287]
	TIME [epoch: 11.6 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301314649795145		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.08301314649795145 | validation: 0.08164401405486825]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361681963058692		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.08361681963058692 | validation: 0.09073956379686031]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470072895410426		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.08470072895410426 | validation: 0.09836147056908777]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266836323554239		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.08266836323554239 | validation: 0.09042868486238423]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08319947787220697		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.08319947787220697 | validation: 0.08896449990456905]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08011844829766183		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.08011844829766183 | validation: 0.084405790292863]
	TIME [epoch: 11.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812520984594014		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.0812520984594014 | validation: 0.09361817798150669]
	TIME [epoch: 11.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.083874961305175		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.083874961305175 | validation: 0.09137786573895024]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856990035783979		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.0856990035783979 | validation: 0.09818750476056677]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08351017189722554		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.08351017189722554 | validation: 0.08182868872214076]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975337750364149		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.07975337750364149 | validation: 0.09733835116603867]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08065152963321842		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.08065152963321842 | validation: 0.08785226742302517]
	TIME [epoch: 11.6 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08068850887311532		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.08068850887311532 | validation: 0.08978914501917597]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08796735439659209		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.08796735439659209 | validation: 0.0822421526261659]
	TIME [epoch: 11.6 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08392270680585269		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.08392270680585269 | validation: 0.08835608791295056]
	TIME [epoch: 11.6 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734207049516811		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.08734207049516811 | validation: 0.0875054316801853]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084898502037961		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.084898502037961 | validation: 0.09373265223628668]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361510122962759		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.08361510122962759 | validation: 0.09408940881121973]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08395254216940702		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.08395254216940702 | validation: 0.0992272439323219]
	TIME [epoch: 11.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999893324662713		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.07999893324662713 | validation: 0.08294430876402202]
	TIME [epoch: 11.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08313864506394662		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.08313864506394662 | validation: 0.09092370574004269]
	TIME [epoch: 11.6 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331712182911125		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.08331712182911125 | validation: 0.09208097156436455]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08558146645693382		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.08558146645693382 | validation: 0.1005978085921494]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08092484716566596		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.08092484716566596 | validation: 0.09475438867339994]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08547339521750685		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.08547339521750685 | validation: 0.09025842864964277]
	TIME [epoch: 11.6 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08203486587153637		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.08203486587153637 | validation: 0.0938642990695778]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.085146870374891		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.085146870374891 | validation: 0.10243097306705569]
	TIME [epoch: 11.6 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094963434462293		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.09094963434462293 | validation: 0.1027291732613215]
	TIME [epoch: 11.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09005435691561137		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.09005435691561137 | validation: 0.09411850967530506]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046261176568585		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.09046261176568585 | validation: 0.10532630591207895]
	TIME [epoch: 11.6 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08953050570779393		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.08953050570779393 | validation: 0.09784867290733741]
	TIME [epoch: 11.6 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09125520068871988		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.09125520068871988 | validation: 0.09638086727232309]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340561031023483		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.08340561031023483 | validation: 0.08980269654464611]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07982652036028422		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.07982652036028422 | validation: 0.08888343934076356]
	TIME [epoch: 11.6 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08193930305454421		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.08193930305454421 | validation: 0.09236367800461728]
	TIME [epoch: 11.5 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08468015467356493		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.08468015467356493 | validation: 0.09318496549334392]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774876694312991		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.08774876694312991 | validation: 0.0989080188694858]
	TIME [epoch: 11.6 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734182483855289		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.08734182483855289 | validation: 0.09541694597407134]
	TIME [epoch: 11.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08409967553718006		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.08409967553718006 | validation: 0.09052755338005504]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507607221048619		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.08507607221048619 | validation: 0.09391446941251289]
	TIME [epoch: 11.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137698587797011		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.08137698587797011 | validation: 0.0918542315892945]
	TIME [epoch: 11.6 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824561114834983		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.08824561114834983 | validation: 0.0847096727308001]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08034728599299665		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.08034728599299665 | validation: 0.08262340470868558]
	TIME [epoch: 11.6 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898404072053736		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.07898404072053736 | validation: 0.08159064632079793]
	TIME [epoch: 11.6 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08287733639546045		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.08287733639546045 | validation: 0.08458153320065266]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07853618698658052		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.07853618698658052 | validation: 0.08679863547956923]
	TIME [epoch: 11.6 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08331341004160137		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.08331341004160137 | validation: 0.08343104303869371]
	TIME [epoch: 11.6 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0802630702225311		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.0802630702225311 | validation: 0.08334221892686179]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08384904978929773		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.08384904978929773 | validation: 0.08181645115584374]
	TIME [epoch: 11.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346855422726354		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.08346855422726354 | validation: 0.08629425284927278]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08373556915699126		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.08373556915699126 | validation: 0.08750396829924731]
	TIME [epoch: 11.5 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08534838552007817		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.08534838552007817 | validation: 0.09803304744677281]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771199757715833		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.08771199757715833 | validation: 0.09008988576949957]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08232465701619615		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.08232465701619615 | validation: 0.08386616325063319]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0811959962111162		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.0811959962111162 | validation: 0.08525922725023417]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08286139348469157		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.08286139348469157 | validation: 0.08960406469595275]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08155376832412572		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.08155376832412572 | validation: 0.09176297042935955]
	TIME [epoch: 11.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828295265068296		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.0828295265068296 | validation: 0.08380768397521943]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08197240467357386		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.08197240467357386 | validation: 0.08734236819627626]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08044578241021681		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.08044578241021681 | validation: 0.0773578743751842]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1469.pth
	Model improved!!!
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0792660021824956		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.0792660021824956 | validation: 0.08947024361927179]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07995953248516394		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.07995953248516394 | validation: 0.10101577740270773]
	TIME [epoch: 11.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847118881505167		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.0847118881505167 | validation: 0.09580681411394316]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08440921005235097		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.08440921005235097 | validation: 0.0947974401395468]
	TIME [epoch: 11.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08233404032593954		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.08233404032593954 | validation: 0.0931398562188101]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08121694290687599		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.08121694290687599 | validation: 0.08783549020429517]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782738951673856		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.0782738951673856 | validation: 0.08775364217957649]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08078776216752645		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.08078776216752645 | validation: 0.0890634222279429]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08696191045069403		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.08696191045069403 | validation: 0.09246378884839718]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693575965360942		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.08693575965360942 | validation: 0.09205791357311953]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08322298024317738		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.08322298024317738 | validation: 0.08098807543355624]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08096091440156657		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.08096091440156657 | validation: 0.08902262599460825]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08545368956949831		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.08545368956949831 | validation: 0.0915101101542085]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785265419707802		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0785265419707802 | validation: 0.08839164866303678]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08470421384953909		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.08470421384953909 | validation: 0.09614314647025302]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839784721179147		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.0839784721179147 | validation: 0.09243746230945832]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030815829553906		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.08030815829553906 | validation: 0.08599269607250747]
	TIME [epoch: 11.5 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263058165294117		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.08263058165294117 | validation: 0.09538990486779765]
	TIME [epoch: 11.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07904424370939295		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.07904424370939295 | validation: 0.08807974548301163]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795770610293085		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.0795770610293085 | validation: 0.08628843565652598]
	TIME [epoch: 11.5 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07576313905015998		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.07576313905015998 | validation: 0.09367138351326115]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08229713113806017		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.08229713113806017 | validation: 0.08658457326418248]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851289866961465		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.08851289866961465 | validation: 0.08748427876633574]
	TIME [epoch: 11.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593732555500226		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.08593732555500226 | validation: 0.08801407474506757]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07741528614904447		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.07741528614904447 | validation: 0.08784831583886003]
	TIME [epoch: 11.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594819548191073		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.07594819548191073 | validation: 0.08012420181627228]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156870437709797		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.08156870437709797 | validation: 0.0902183090529285]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08603747396986061		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.08603747396986061 | validation: 0.09133724451986985]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08442543357852875		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.08442543357852875 | validation: 0.0867332430531501]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868190341326321		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.0868190341326321 | validation: 0.08657248023184408]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08250794192584153		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.08250794192584153 | validation: 0.09229137426585922]
	TIME [epoch: 11.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08749208595366095		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.08749208595366095 | validation: 0.08946117270006321]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08098170810568248		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.08098170810568248 | validation: 0.08609148591654353]
	TIME [epoch: 11.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157922010064761		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.08157922010064761 | validation: 0.07934200724389001]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821487656889813		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.0821487656889813 | validation: 0.0849273603938917]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735963557491403		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.07735963557491403 | validation: 0.08846423565030322]
	TIME [epoch: 11.5 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07665836185374644		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.07665836185374644 | validation: 0.09094147038254902]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997509601708544		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.07997509601708544 | validation: 0.08991899938953676]
	TIME [epoch: 11.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08002875202480192		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.08002875202480192 | validation: 0.08811330159588207]
	TIME [epoch: 11.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349492797447189		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.08349492797447189 | validation: 0.09766063166387838]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013111580731429		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.08013111580731429 | validation: 0.09336213313018159]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08630995974386836		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.08630995974386836 | validation: 0.09866015512044898]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08588875016855813		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.08588875016855813 | validation: 0.11102843306571884]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08783119188947733		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.08783119188947733 | validation: 0.09538385800508176]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274846651905275		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.08274846651905275 | validation: 0.09211413654676814]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157396487412072		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.08157396487412072 | validation: 0.09966842945463006]
	TIME [epoch: 11.5 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542341254356428		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.08542341254356428 | validation: 0.0858677500428745]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08978710198738031		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.08978710198738031 | validation: 0.09492713933654581]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08538916799695437		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.08538916799695437 | validation: 0.09058167229662593]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202120264019581		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.08202120264019581 | validation: 0.08675501724646541]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809630950360764		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.07809630950360764 | validation: 0.09536487470074638]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07879719399607768		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.07879719399607768 | validation: 0.08341962973158182]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235332947438137		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.08235332947438137 | validation: 0.09073769855301868]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07976476979303301		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.07976476979303301 | validation: 0.08908658837278376]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824224874046204		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.0824224874046204 | validation: 0.07702116200675546]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1524.pth
	Model improved!!!
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07982700629942138		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.07982700629942138 | validation: 0.08846191847283535]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054554003316276		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.08054554003316276 | validation: 0.0898100355426315]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105419789375763		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.08105419789375763 | validation: 0.08910858674501619]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08554491298975925		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.08554491298975925 | validation: 0.09254786282559581]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341021154860445		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.08341021154860445 | validation: 0.08840895713876944]
	TIME [epoch: 11.5 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639266582081775		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.08639266582081775 | validation: 0.09007147111111317]
	TIME [epoch: 11.5 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08062080028949914		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.08062080028949914 | validation: 0.0862693099134073]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08340436422935482		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.08340436422935482 | validation: 0.09392564150206456]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361674391365492		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.08361674391365492 | validation: 0.08612053722142111]
	TIME [epoch: 11.5 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08151735556732473		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.08151735556732473 | validation: 0.08237087714313705]
	TIME [epoch: 11.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07739647035951691		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.07739647035951691 | validation: 0.08875128592769603]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.081932244921195		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.081932244921195 | validation: 0.09201701802245499]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08081948568011649		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.08081948568011649 | validation: 0.08375711558700892]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281964142715012		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.08281964142715012 | validation: 0.08542099005720052]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104077671769415		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.08104077671769415 | validation: 0.08635101415292566]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924316836558348		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.07924316836558348 | validation: 0.08347802399448587]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784838952132635		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.0784838952132635 | validation: 0.08956543351510593]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922490651609183		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.07922490651609183 | validation: 0.09172292531753008]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08291191380659642		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.08291191380659642 | validation: 0.08212325207271647]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07682425819555169		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.07682425819555169 | validation: 0.09369132779856885]
	TIME [epoch: 11.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08013488135869568		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.08013488135869568 | validation: 0.08186604977076237]
	TIME [epoch: 11.6 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07766437358961437		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.07766437358961437 | validation: 0.08163007446690183]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767644408922935		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.0767644408922935 | validation: 0.08176105131223116]
	TIME [epoch: 11.5 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07923839828506761		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.07923839828506761 | validation: 0.08304920960339487]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08137449202386		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.08137449202386 | validation: 0.07876623260254104]
	TIME [epoch: 11.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08084910005873748		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.08084910005873748 | validation: 0.08532839347470032]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920466914202971		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.07920466914202971 | validation: 0.08393787291608731]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08225646530335878		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.08225646530335878 | validation: 0.08966604924892886]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07903520907283318		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.07903520907283318 | validation: 0.07985689016601182]
	TIME [epoch: 11.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0780991012305028		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.0780991012305028 | validation: 0.07435422387221945]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1554.pth
	Model improved!!!
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07833161016410624		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.07833161016410624 | validation: 0.08777056011970469]
	TIME [epoch: 11.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872909501531483		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.07872909501531483 | validation: 0.08426307117995553]
	TIME [epoch: 11.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07772694712634476		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.07772694712634476 | validation: 0.0778568614863153]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07899582273344018		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.07899582273344018 | validation: 0.08780458283815522]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08302593796218871		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.08302593796218871 | validation: 0.08355548867989536]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07468337657173875		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.07468337657173875 | validation: 0.08602993395319435]
	TIME [epoch: 11.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467184457330657		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.07467184457330657 | validation: 0.07869110041288795]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012343122320727		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.08012343122320727 | validation: 0.09497679962457131]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07829203029461919		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.07829203029461919 | validation: 0.08863854713513193]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08000732065038466		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.08000732065038466 | validation: 0.08415654528266896]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08251669448188353		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.08251669448188353 | validation: 0.08673360176895631]
	TIME [epoch: 11.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263956413452028		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.08263956413452028 | validation: 0.08871071220535874]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148806885694339		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.08148806885694339 | validation: 0.08771621044706511]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08140566742716421		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.08140566742716421 | validation: 0.09265877862120095]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936540647434236		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.07936540647434236 | validation: 0.08662015299274885]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08359105276228021		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.08359105276228021 | validation: 0.08438402706489245]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127592494519799		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.08127592494519799 | validation: 0.0822089072365191]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07545702298091908		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.07545702298091908 | validation: 0.08893742059763014]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07705221191976987		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.07705221191976987 | validation: 0.0780399053750316]
	TIME [epoch: 11.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07907007670974898		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.07907007670974898 | validation: 0.09064829337652679]
	TIME [epoch: 11.6 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826355439713789		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.07826355439713789 | validation: 0.08089252401383565]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824706192445625		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.07824706192445625 | validation: 0.09033005935536871]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07869873115560429		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.07869873115560429 | validation: 0.11387461818879224]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950699419114896		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.07950699419114896 | validation: 0.07992027440748581]
	TIME [epoch: 11.6 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063620553783954		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.08063620553783954 | validation: 0.07989655471761073]
	TIME [epoch: 11.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678006124343592		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.07678006124343592 | validation: 0.08021451830041869]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763808171633743		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.0763808171633743 | validation: 0.09483302604053005]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08090759070454565		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.08090759070454565 | validation: 0.09839662883351029]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08088290307617524		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.08088290307617524 | validation: 0.09098484818742295]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0814886585228254		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.0814886585228254 | validation: 0.09883153525545602]
	TIME [epoch: 11.6 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08165240432604666		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.08165240432604666 | validation: 0.0817483424927781]
	TIME [epoch: 11.5 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149747330545777		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.08149747330545777 | validation: 0.08442862289140216]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073678780936483		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.08073678780936483 | validation: 0.08262760518093482]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988250341027983		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.07988250341027983 | validation: 0.09278351062610318]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690077023377448		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.07690077023377448 | validation: 0.0897523442328944]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07556920378914786		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.07556920378914786 | validation: 0.08187453030716607]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08092810672143605		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.08092810672143605 | validation: 0.08223606794308086]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730179563977489		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.07730179563977489 | validation: 0.08148562769656448]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773130667884223		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.07773130667884223 | validation: 0.08006876600124066]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642066035904772		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.07642066035904772 | validation: 0.08325384898923371]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966049293472365		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.07966049293472365 | validation: 0.07055181839297689]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r3_20240309_135637/states/model_tr_study3_1595.pth
	Model improved!!!
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725539704399711		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.07725539704399711 | validation: 0.08645298870219201]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022842459356477		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.08022842459356477 | validation: 0.08661554587889563]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07587654343833929		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.07587654343833929 | validation: 0.08070942584738923]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07571477296664293		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.07571477296664293 | validation: 0.08671919328953902]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.077041428505173		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.077041428505173 | validation: 0.08713773183458358]
	TIME [epoch: 11.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767746036683846		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.0767746036683846 | validation: 0.0853968075315963]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07867802702356579		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.07867802702356579 | validation: 0.09084345276434583]
	TIME [epoch: 11.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063254342983973		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.08063254342983973 | validation: 0.0927109380395101]
	TIME [epoch: 11.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07885241068269627		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.07885241068269627 | validation: 0.0868953696607947]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060270372794888		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.08060270372794888 | validation: 0.08416068653896701]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07773005974289696		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.07773005974289696 | validation: 0.08467844259103594]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629247969746301		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.07629247969746301 | validation: 0.09125970729557327]
	TIME [epoch: 11.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697240661348141		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.07697240661348141 | validation: 0.07567938951005697]
	TIME [epoch: 11.6 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688602992440896		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.07688602992440896 | validation: 0.08482673587656521]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07859392116986333		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.07859392116986333 | validation: 0.08533003223425752]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800953916858887		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.0800953916858887 | validation: 0.08513777020368642]
	TIME [epoch: 11.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866301751169755		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.07866301751169755 | validation: 0.09428990108252867]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.079910480287101		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.079910480287101 | validation: 0.08728976509087605]
	TIME [epoch: 11.5 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07662442709790897		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.07662442709790897 | validation: 0.0864081469621961]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07469297905412906		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.07469297905412906 | validation: 0.08516714048112467]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594259047263806		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.07594259047263806 | validation: 0.09107866546887138]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07889287191191882		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.07889287191191882 | validation: 0.08648027378937116]
	TIME [epoch: 11.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919457920793471		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.07919457920793471 | validation: 0.08061729217919532]
	TIME [epoch: 11.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957715374247354		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.07957715374247354 | validation: 0.08615540927190196]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799835904939418		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.0799835904939418 | validation: 0.08901938048468284]
	TIME [epoch: 11.6 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709464578217928		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.07709464578217928 | validation: 0.08649382404004911]
	TIME [epoch: 11.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030680641878814		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.08030680641878814 | validation: 0.09658665623104842]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08138927098021788		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.08138927098021788 | validation: 0.09375675704675901]
	TIME [epoch: 11.5 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323106239738834		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.08323106239738834 | validation: 0.0895153297080993]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080916677247411		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.080916677247411 | validation: 0.09196776426592282]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07702992962595755		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.07702992962595755 | validation: 0.09290943031539563]
	TIME [epoch: 11.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767539561801183		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.0767539561801183 | validation: 0.08696500317008683]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040784741746934		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.08040784741746934 | validation: 0.09545886217930802]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08125653691325573		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.08125653691325573 | validation: 0.08972203930381671]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018583004218782		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.08018583004218782 | validation: 0.0897944930997242]
	TIME [epoch: 11.5 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154590924649494		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.08154590924649494 | validation: 0.09633438160043793]
	TIME [epoch: 11.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08186691032529894		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.08186691032529894 | validation: 0.10007556029253975]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07689056672479991		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.07689056672479991 | validation: 0.08074124458005262]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08030906567119983		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.08030906567119983 | validation: 0.076327715712156]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08012164489823737		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.08012164489823737 | validation: 0.08820676885383393]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07817418310828998		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.07817418310828998 | validation: 0.0898055091568197]
	TIME [epoch: 11.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07665078751996082		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.07665078751996082 | validation: 0.08992308795861463]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952933749869895		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.07952933749869895 | validation: 0.08680405812179244]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807972170814463		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.07807972170814463 | validation: 0.08917687809071186]
	TIME [epoch: 11.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790758224270469		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.07790758224270469 | validation: 0.08310601303002493]
	TIME [epoch: 11.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713270249703041		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.07713270249703041 | validation: 0.0863382142011592]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07578048056460632		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.07578048056460632 | validation: 0.08116899839332263]
	TIME [epoch: 11.6 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07742106779853054		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.07742106779853054 | validation: 0.0854904905948556]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876426866353947		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.07876426866353947 | validation: 0.08195171598418421]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07765053402509159		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.07765053402509159 | validation: 0.09190591791730146]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795089470549685		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.0795089470549685 | validation: 0.07859341010035933]
	TIME [epoch: 11.6 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747998011469691		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.07747998011469691 | validation: 0.08576829061545505]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07555555434713138		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.07555555434713138 | validation: 0.09151029807645393]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944911814303725		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.07944911814303725 | validation: 0.09832328074874677]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795855258760315		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.07795855258760315 | validation: 0.08703360719376786]
	TIME [epoch: 11.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07769131367739975		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.07769131367739975 | validation: 0.08175779314261757]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914972877947793		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.07914972877947793 | validation: 0.09645045064646779]
	TIME [epoch: 11.6 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175856518838047		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.08175856518838047 | validation: 0.09119166594754159]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07983374801758741		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.07983374801758741 | validation: 0.0839904277546231]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104066335277949		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.08104066335277949 | validation: 0.07780921293276512]
	TIME [epoch: 11.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966654806193765		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.07966654806193765 | validation: 0.08289604267522012]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07989452472656955		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.07989452472656955 | validation: 0.09094930301225077]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08052416692012539		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.08052416692012539 | validation: 0.0886376051684299]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07995129560641127		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.07995129560641127 | validation: 0.08186449500916436]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08115158243585952		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.08115158243585952 | validation: 0.0891356440586626]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07761326751220848		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.07761326751220848 | validation: 0.08799915969960596]
	TIME [epoch: 11.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787133513748044		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.0787133513748044 | validation: 0.08598500319402354]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304360476003571		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.07304360476003571 | validation: 0.07626849501419444]
	TIME [epoch: 11.6 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709865569811745		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.07709865569811745 | validation: 0.0957079771456504]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712473327400428		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.07712473327400428 | validation: 0.09737594553995088]
	TIME [epoch: 11.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07666423443420778		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.07666423443420778 | validation: 0.0964351761572233]
	TIME [epoch: 11.6 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08191099435415086		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.08191099435415086 | validation: 0.09464893231927313]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755374847494528		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.07755374847494528 | validation: 0.0900642214418553]
	TIME [epoch: 11.6 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07815137286263468		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.07815137286263468 | validation: 0.08549152337688126]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07793926236445116		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.07793926236445116 | validation: 0.08744488114773734]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259276565644694		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.08259276565644694 | validation: 0.08597551897732754]
	TIME [epoch: 11.6 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08349160711886235		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.08349160711886235 | validation: 0.10366573880978792]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08183200023634145		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.08183200023634145 | validation: 0.08822986921449025]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08074020088890374		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.08074020088890374 | validation: 0.08576003432329468]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08198017122453358		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.08198017122453358 | validation: 0.09007594397946672]
	TIME [epoch: 11.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08204010678561552		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.08204010678561552 | validation: 0.09338247627013119]
	TIME [epoch: 11.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08165414820367665		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.08165414820367665 | validation: 0.0889568511594733]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07669553928960995		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.07669553928960995 | validation: 0.08938359389717217]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08090793289909726		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.08090793289909726 | validation: 0.08378264701708851]
	TIME [epoch: 11.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08139236037177579		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.08139236037177579 | validation: 0.08625964576086205]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719382998199951		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.07719382998199951 | validation: 0.0809452788376346]
	TIME [epoch: 11.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08216265565437528		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.08216265565437528 | validation: 0.07999159137156868]
	TIME [epoch: 11.5 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07787580276196286		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.07787580276196286 | validation: 0.08665084499193881]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07771999898226167		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.07771999898226167 | validation: 0.08704206143037775]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784718784049355		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.0784718784049355 | validation: 0.08160841718798346]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07510293814732893		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.07510293814732893 | validation: 0.08802697321914252]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0767525663363201		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.0767525663363201 | validation: 0.08710411402844959]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782407608512659		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.07782407608512659 | validation: 0.09016365942975746]
	TIME [epoch: 11.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07723528644346961		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.07723528644346961 | validation: 0.08468569003911008]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08053960281554301		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.08053960281554301 | validation: 0.09580761594145078]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898510378740314		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.07898510378740314 | validation: 0.0863512076957089]
	TIME [epoch: 11.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720484138479985		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.07720484138479985 | validation: 0.0752730111778212]
	TIME [epoch: 11.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07793000720510881		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.07793000720510881 | validation: 0.08153429090160844]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07901552767712225		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.07901552767712225 | validation: 0.08441057113693574]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07467408655731278		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.07467408655731278 | validation: 0.08626193076320963]
	TIME [epoch: 11.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08043777223715697		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.08043777223715697 | validation: 0.08259275463648041]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07583158361261462		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.07583158361261462 | validation: 0.0815075414397559]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08031656932435238		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.08031656932435238 | validation: 0.07935835717092421]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385711689368106		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.07385711689368106 | validation: 0.09500231469018822]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07296766901131128		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.07296766901131128 | validation: 0.08947402122361656]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653719848596711		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.07653719848596711 | validation: 0.08139901524046377]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07752074485691128		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.07752074485691128 | validation: 0.0871932261527601]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07484102473017343		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.07484102473017343 | validation: 0.0970630329331111]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08102019221014256		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.08102019221014256 | validation: 0.09229996289017368]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245939616997881		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.08245939616997881 | validation: 0.08927778974483878]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08245522390194243		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.08245522390194243 | validation: 0.09512126480328767]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973458518760138		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.07973458518760138 | validation: 0.08907797600262946]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08103600414478745		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.08103600414478745 | validation: 0.09311019487498015]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281015673323339		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.08281015673323339 | validation: 0.09110131267524599]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07755661187504483		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.07755661187504483 | validation: 0.08397055883456146]
	TIME [epoch: 11.5 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07648307944882293		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.07648307944882293 | validation: 0.09211360058085045]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810764833079515		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.0810764833079515 | validation: 0.07990369564289036]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600836792282693		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.07600836792282693 | validation: 0.07964766671341293]
	TIME [epoch: 11.6 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768576444310131		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.0768576444310131 | validation: 0.0829966548500545]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605279915496893		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.07605279915496893 | validation: 0.08827911130022625]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07765799623109754		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.07765799623109754 | validation: 0.08368869308188391]
	TIME [epoch: 11.6 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07321757634887269		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.07321757634887269 | validation: 0.08294501959900968]
	TIME [epoch: 11.6 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07947608528114922		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.07947608528114922 | validation: 0.08740768721756453]
	TIME [epoch: 11.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604561415199498		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.07604561415199498 | validation: 0.08212977010660684]
	TIME [epoch: 11.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07836611570144009		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.07836611570144009 | validation: 0.08454376325856601]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07916484297091197		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.07916484297091197 | validation: 0.07659741233368336]
	TIME [epoch: 11.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591773393777697		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.07591773393777697 | validation: 0.08096557236619253]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421565688341555		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.07421565688341555 | validation: 0.08141184711050505]
	TIME [epoch: 11.5 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07423919063153571		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.07423919063153571 | validation: 0.08036792441284366]
	TIME [epoch: 11.6 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07850462831779206		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.07850462831779206 | validation: 0.09378366469416044]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07599368455600275		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.07599368455600275 | validation: 0.0893208983865884]
	TIME [epoch: 11.6 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661652625592996		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.07661652625592996 | validation: 0.08860162237346525]
	TIME [epoch: 11.6 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08089426001498085		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.08089426001498085 | validation: 0.08797448564393516]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918469096621186		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.07918469096621186 | validation: 0.08086806131727434]
	TIME [epoch: 11.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07516417787112266		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.07516417787112266 | validation: 0.07867255513720765]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734891319748063		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0734891319748063 | validation: 0.08247257692340221]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07424478632763079		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.07424478632763079 | validation: 0.07195165045665011]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07846687117334948		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.07846687117334948 | validation: 0.08472003683762021]
	TIME [epoch: 11.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779958046516854		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.0779958046516854 | validation: 0.08473566179016878]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958143937733869		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.07958143937733869 | validation: 0.09021472801967431]
	TIME [epoch: 11.6 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709876399625085		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.07709876399625085 | validation: 0.08325514496645262]
	TIME [epoch: 11.6 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480978983680736		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.07480978983680736 | validation: 0.0908438169704109]
	TIME [epoch: 11.6 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07904464722138084		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.07904464722138084 | validation: 0.09539117841040597]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730719981913402		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.07730719981913402 | validation: 0.08234129043653325]
	TIME [epoch: 11.6 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07598868399460251		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.07598868399460251 | validation: 0.07275130286322845]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07921211555896587		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.07921211555896587 | validation: 0.08510537495379476]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777134303983077		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.0777134303983077 | validation: 0.08423605627894994]
	TIME [epoch: 11.6 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800078039454927		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.0800078039454927 | validation: 0.08976691743221211]
	TIME [epoch: 11.6 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779909722040518		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.0779909722040518 | validation: 0.09228319554073178]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07497912743972658		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.07497912743972658 | validation: 0.07804982960355247]
	TIME [epoch: 11.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07924800536004796		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.07924800536004796 | validation: 0.0841562912877286]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07663565035340236		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.07663565035340236 | validation: 0.0888728972849463]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07365997181028272		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.07365997181028272 | validation: 0.07711789896691924]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615817475058326		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.07615817475058326 | validation: 0.0816465456619466]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755514404294208		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.0755514404294208 | validation: 0.09146877033720326]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747315740672409		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.0747315740672409 | validation: 0.09548691978698713]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07725585046926559		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.07725585046926559 | validation: 0.08267368513492952]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701793569789066		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.07701793569789066 | validation: 0.08673240615402485]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07569679749199655		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.07569679749199655 | validation: 0.08605087632080795]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07325848887451739		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.07325848887451739 | validation: 0.08869737270453307]
	TIME [epoch: 11.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07358782344093384		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.07358782344093384 | validation: 0.0890838322746772]
	TIME [epoch: 11.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796917201033823		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.07796917201033823 | validation: 0.08531847292929953]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08019537952234743		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.08019537952234743 | validation: 0.0843317929741109]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07928670280675124		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.07928670280675124 | validation: 0.08509356831862296]
	TIME [epoch: 11.6 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809246686009513		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.07809246686009513 | validation: 0.09632794210990105]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740321148273116		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.07740321148273116 | validation: 0.0891272307843333]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07685857393141957		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.07685857393141957 | validation: 0.08668974912767335]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07686035925827656		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.07686035925827656 | validation: 0.08783525830196508]
	TIME [epoch: 11.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740488979350749		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.07740488979350749 | validation: 0.0887226693497485]
	TIME [epoch: 11.6 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0752117738872023		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.0752117738872023 | validation: 0.08283015393349881]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07473486709752673		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.07473486709752673 | validation: 0.07597408767010222]
	TIME [epoch: 11.5 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07610758647161124		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.07610758647161124 | validation: 0.08061394660586484]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756493470612346		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.0756493470612346 | validation: 0.07682235945254813]
	TIME [epoch: 11.6 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07591280468288754		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.07591280468288754 | validation: 0.08786366405117349]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07631567568141782		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.07631567568141782 | validation: 0.08123621932736111]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892486241486335		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.07892486241486335 | validation: 0.09149624019886307]
	TIME [epoch: 11.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07471638726272103		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.07471638726272103 | validation: 0.09321825721400519]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478278502471669		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.07478278502471669 | validation: 0.08146952418286768]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07197560039887005		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.07197560039887005 | validation: 0.09011225994838007]
	TIME [epoch: 11.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07559457362116517		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.07559457362116517 | validation: 0.0811898745368437]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07797301245032354		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.07797301245032354 | validation: 0.08654942616202395]
	TIME [epoch: 11.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534279446754588		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.07534279446754588 | validation: 0.08934153620526017]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.074361071773701		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.074361071773701 | validation: 0.08495131524381956]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730620038596844		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.07730620038596844 | validation: 0.09103518512286521]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07932673475643691		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.07932673475643691 | validation: 0.08027356418961479]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07854934315891557		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.07854934315891557 | validation: 0.08408763974149862]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709646793201894		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.07709646793201894 | validation: 0.08316802130050661]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537089835528825		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.07537089835528825 | validation: 0.08356227133341702]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803574734624981		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.0803574734624981 | validation: 0.0783369865591894]
	TIME [epoch: 11.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768077971944379		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.0768077971944379 | validation: 0.08793643005568297]
	TIME [epoch: 11.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07472618168618891		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.07472618168618891 | validation: 0.08587346972729]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08080609039439957		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.08080609039439957 | validation: 0.08449160720015982]
	TIME [epoch: 11.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07958966425583842		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.07958966425583842 | validation: 0.08062803744875746]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105646438162101		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.08105646438162101 | validation: 0.08463983204378143]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425011154423103		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.07425011154423103 | validation: 0.0824858319900183]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635474209574804		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.07635474209574804 | validation: 0.07772419800182348]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07845561659178166		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.07845561659178166 | validation: 0.07579689972416354]
	TIME [epoch: 11.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644330527792047		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.07644330527792047 | validation: 0.08758997797492281]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0800227963062134		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.0800227963062134 | validation: 0.0803342508378784]
	TIME [epoch: 11.5 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07669175771519193		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.07669175771519193 | validation: 0.08050233060276654]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07442352639923372		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.07442352639923372 | validation: 0.07689744945497375]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07639445591074881		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.07639445591074881 | validation: 0.08903868297506211]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07736995402569946		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.07736995402569946 | validation: 0.08434908352385076]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527886941399915		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.07527886941399915 | validation: 0.07887216720234537]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07588642953013001		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.07588642953013001 | validation: 0.07484936508975841]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627860799771202		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.07627860799771202 | validation: 0.0901636556829716]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07809183281269444		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.07809183281269444 | validation: 0.07515203387995963]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0756386538378086		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.0756386538378086 | validation: 0.08938616336921706]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07323120570881816		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.07323120570881816 | validation: 0.08194717863981714]
	TIME [epoch: 11.5 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07868850027416634		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.07868850027416634 | validation: 0.08521721029846424]
	TIME [epoch: 11.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796547067959345		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.07796547067959345 | validation: 0.08587763086240884]
	TIME [epoch: 11.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537571760385872		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.07537571760385872 | validation: 0.0844409482345149]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07352906069025958		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.07352906069025958 | validation: 0.08742905038156952]
	TIME [epoch: 11.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418492335419227		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.07418492335419227 | validation: 0.08338720254034829]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07669831062058703		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.07669831062058703 | validation: 0.07711321505078324]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07826584104257929		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.07826584104257929 | validation: 0.08718988901631022]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580452103489538		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.07580452103489538 | validation: 0.08410333141608922]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07847833440711088		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.07847833440711088 | validation: 0.08642488101022924]
	TIME [epoch: 11.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534123488516359		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.07534123488516359 | validation: 0.08319288399557903]
	TIME [epoch: 11.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07793579229516744		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.07793579229516744 | validation: 0.08897765079061733]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724675473575379		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.07724675473575379 | validation: 0.08340780211870763]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07918010601575662		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.07918010601575662 | validation: 0.08822441640415632]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0813818745680134		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.0813818745680134 | validation: 0.09265450117115105]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07651107461816213		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.07651107461816213 | validation: 0.08748185038378231]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07658923522599545		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.07658923522599545 | validation: 0.08572887968818764]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07964262679645792		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.07964262679645792 | validation: 0.08016727480956667]
	TIME [epoch: 11.5 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771629724330271		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.0771629724330271 | validation: 0.08875925687135579]
	TIME [epoch: 11.6 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718755093119457		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.07718755093119457 | validation: 0.07276641721783433]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07577004425660029		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.07577004425660029 | validation: 0.08337221293637559]
	TIME [epoch: 11.6 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690731187917163		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.07690731187917163 | validation: 0.08415699890691773]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0745822865311851		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.0745822865311851 | validation: 0.08607352891800318]
	TIME [epoch: 11.6 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07563044408893008		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.07563044408893008 | validation: 0.09132353778289552]
	TIME [epoch: 11.6 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07659462424733918		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.07659462424733918 | validation: 0.09408219885976654]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07316081881030924		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.07316081881030924 | validation: 0.08761012160426974]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748075183864762		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.07748075183864762 | validation: 0.08493353882082781]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789923122076581		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.0789923122076581 | validation: 0.08107789845749735]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07656638854656866		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.07656638854656866 | validation: 0.07338088406529271]
	TIME [epoch: 11.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766041679437614		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.0766041679437614 | validation: 0.08757304052191099]
	TIME [epoch: 11.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866195562877201		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.07866195562877201 | validation: 0.08021456819419978]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07580966594357152		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.07580966594357152 | validation: 0.07685301654856218]
	TIME [epoch: 11.6 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07794471245899028		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.07794471245899028 | validation: 0.08971386214859411]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07878292606513776		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.07878292606513776 | validation: 0.0783592766467269]
	TIME [epoch: 11.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07767543973488963		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.07767543973488963 | validation: 0.08688223539919271]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630258024170887		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.07630258024170887 | validation: 0.07928660374880402]
	TIME [epoch: 11.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028034031391695		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.08028034031391695 | validation: 0.070917771894356]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07573016762035337		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.07573016762035337 | validation: 0.07994666280080494]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189716211407791		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.07189716211407791 | validation: 0.07747068396703195]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07477504932115776		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.07477504932115776 | validation: 0.08251847625882544]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329074107756169		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.07329074107756169 | validation: 0.08262267901180924]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07280781526638051		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.07280781526638051 | validation: 0.08098621402064762]
	TIME [epoch: 11.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08070996194295946		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.08070996194295946 | validation: 0.07831053289110888]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07828646051501185		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.07828646051501185 | validation: 0.07649422267123106]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07762972078229179		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.07762972078229179 | validation: 0.08627654889195605]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07891116857676878		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.07891116857676878 | validation: 0.08683019064535184]
	TIME [epoch: 11.6 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07727051400127224		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.07727051400127224 | validation: 0.0795229655624838]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713811851514085		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.07713811851514085 | validation: 0.08525774564799658]
	TIME [epoch: 11.6 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743622747385284		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.0743622747385284 | validation: 0.07992697642010285]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605363907341771		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.07605363907341771 | validation: 0.07701120166890088]
	TIME [epoch: 11.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768122550317575		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.0768122550317575 | validation: 0.08638146539773808]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07647306638688738		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.07647306638688738 | validation: 0.08606317326218864]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753725034939803		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.0753725034939803 | validation: 0.08319670114008507]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07480043831298387		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.07480043831298387 | validation: 0.07750779334480067]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690591939491555		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.07690591939491555 | validation: 0.08650334081541654]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07342444094652906		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.07342444094652906 | validation: 0.08727906567576621]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771348313875923		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.0771348313875923 | validation: 0.08000358596944997]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07760314915487472		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.07760314915487472 | validation: 0.07388214342619111]
	TIME [epoch: 11.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385950881856106		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.07385950881856106 | validation: 0.07577383015111619]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07705493108588349		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.07705493108588349 | validation: 0.08521445068804942]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07438928890770813		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.07438928890770813 | validation: 0.08344948475880415]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0777360897909828		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.0777360897909828 | validation: 0.07708525614611693]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0769974003904028		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.0769974003904028 | validation: 0.0820167028918721]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753585599696148		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.0753585599696148 | validation: 0.0748641213602468]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07538292209404676		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.07538292209404676 | validation: 0.08759132807051852]
	TIME [epoch: 11.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820491239990731		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.0820491239990731 | validation: 0.08165329876141049]
	TIME [epoch: 11.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07498426991125803		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.07498426991125803 | validation: 0.08681117099791136]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07562543855906612		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.07562543855906612 | validation: 0.0859387435736554]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789602370815692		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.07789602370815692 | validation: 0.08533783897655899]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764137351158139		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.0764137351158139 | validation: 0.083285828651071]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07786637944640586		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.07786637944640586 | validation: 0.0760207571067269]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07333672072225675		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.07333672072225675 | validation: 0.08522608957348494]
	TIME [epoch: 11.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006081536022135		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.08006081536022135 | validation: 0.07606371211710782]
	TIME [epoch: 11.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751001891855633		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.0751001891855633 | validation: 0.08020170093032125]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07552864672036463		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.07552864672036463 | validation: 0.08398618817916167]
	TIME [epoch: 11.6 sec]
EPOCH 1879/2000:
	Training over batches...
