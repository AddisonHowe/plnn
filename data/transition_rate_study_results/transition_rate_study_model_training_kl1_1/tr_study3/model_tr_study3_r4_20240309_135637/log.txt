Args:
Namespace(name='model_tr_study3', outdir='out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4', training_data='data/transition_rate_studies/tr_study3/tr_study3_training/r4', validation_data='data/transition_rate_studies/tr_study3/tr_study3_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3927134263

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.243848914723745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.243848914723745 | validation: 9.51793399048422]
	TIME [epoch: 100 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.188550553134124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.188550553134124 | validation: 8.116269380148436]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.401170458766506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.401170458766506 | validation: 7.857778896665288]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.180641798132491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.180641798132491 | validation: 7.655397198791613]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.93159000450829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.93159000450829 | validation: 7.409308762830128]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.63199434621364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.63199434621364 | validation: 7.300492780575644]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.35607851663644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.35607851663644 | validation: 7.081628418992115]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.360551313962867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.360551313962867 | validation: 6.660653430750151]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.276119882270699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.276119882270699 | validation: 6.738214776067443]
	TIME [epoch: 11.6 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.977784313172863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.977784313172863 | validation: 6.567888827104298]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.888137477051609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.888137477051609 | validation: 8.232903581332401]
	TIME [epoch: 11.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6883617179683466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6883617179683466 | validation: 6.252579414085826]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.96696551412739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.96696551412739 | validation: 6.363949320844412]
	TIME [epoch: 11.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.990606717547137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.990606717547137 | validation: 6.357287178557881]
	TIME [epoch: 11.6 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8784978976239035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8784978976239035 | validation: 6.096006088422674]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.837646433112959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.837646433112959 | validation: 6.199313873136987]
	TIME [epoch: 11.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.842268865983312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.842268865983312 | validation: 6.501970420503697]
	TIME [epoch: 11.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.957327067083854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.957327067083854 | validation: 6.273346900679533]
	TIME [epoch: 11.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0614590944082085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0614590944082085 | validation: 6.161483966107777]
	TIME [epoch: 11.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78172404226399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.78172404226399 | validation: 6.145830081082849]
	TIME [epoch: 11.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930097055123348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.930097055123348 | validation: 6.128258543572032]
	TIME [epoch: 11.5 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.901999742517188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.901999742517188 | validation: 6.096839741177866]
	TIME [epoch: 11.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7859115996597215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7859115996597215 | validation: 6.572767938599627]
	TIME [epoch: 11.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.197385078595266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.197385078595266 | validation: 6.179507222910172]
	TIME [epoch: 11.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.972659142562177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.972659142562177 | validation: 6.135208571496679]
	TIME [epoch: 11.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.757335248822161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.757335248822161 | validation: 5.972975508824521]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8247444784601345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8247444784601345 | validation: 6.1480898037914]
	TIME [epoch: 11.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.883605933513769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.883605933513769 | validation: 6.072838660555335]
	TIME [epoch: 11.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.785630889373168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.785630889373168 | validation: 5.827560477294328]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.918805828870083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.918805828870083 | validation: 5.947010878904478]
	TIME [epoch: 11.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.631274460735355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.631274460735355 | validation: 6.190451886458551]
	TIME [epoch: 11.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.732356060362183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.732356060362183 | validation: 5.9400392017076795]
	TIME [epoch: 11.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.996189233076629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.996189233076629 | validation: 5.829980473366986]
	TIME [epoch: 11.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.575611227747047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.575611227747047 | validation: 5.753224864081727]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6016253776091025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6016253776091025 | validation: 5.820577950168688]
	TIME [epoch: 11.6 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6392231858477375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6392231858477375 | validation: 6.041522296187891]
	TIME [epoch: 11.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.485124437834322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.485124437834322 | validation: 5.6838661073461045]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.419576508052111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.419576508052111 | validation: 5.6589237525645855]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.563145909262635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.563145909262635 | validation: 5.76643661016658]
	TIME [epoch: 11.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.490054078498126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.490054078498126 | validation: 5.840138516692844]
	TIME [epoch: 11.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879796906049458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.879796906049458 | validation: 7.235106462204933]
	TIME [epoch: 11.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786239690488567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.786239690488567 | validation: 5.597493439682445]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.613178831013357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.613178831013357 | validation: 6.786046447590784]
	TIME [epoch: 11.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.662782168986855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.662782168986855 | validation: 5.347519378105201]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.240848452918419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.240848452918419 | validation: 5.08091392989957]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.085576663343118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.085576663343118 | validation: 4.973812940012235]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.299300940540791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.299300940540791 | validation: 5.640940526297778]
	TIME [epoch: 11.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.288779625392309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.288779625392309 | validation: 5.010947736180995]
	TIME [epoch: 11.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.71374468835581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.71374468835581 | validation: 7.274120225653647]
	TIME [epoch: 11.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.664879906320718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.664879906320718 | validation: 5.392334538346811]
	TIME [epoch: 11.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.053026893019906		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.053026893019906 | validation: 4.992480280998928]
	TIME [epoch: 11.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.064385226550854		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.064385226550854 | validation: 5.231971571983756]
	TIME [epoch: 11.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1758322464545214		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.1758322464545214 | validation: 5.311952597011891]
	TIME [epoch: 11.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.971038029740196		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.971038029740196 | validation: 5.14824444049198]
	TIME [epoch: 11.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.787800395805314		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 4.787800395805314 | validation: 4.820333587947403]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.879037079537152		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.879037079537152 | validation: 4.7610934605694455]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.784608375565259		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.784608375565259 | validation: 4.739166916456802]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7197254148500285		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.7197254148500285 | validation: 4.911815916274281]
	TIME [epoch: 11.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6114441893757325		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.6114441893757325 | validation: 4.746699664462685]
	TIME [epoch: 11.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454412696092288		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 4.454412696092288 | validation: 4.397912004322263]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.316206496703297		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.316206496703297 | validation: 4.6121830621239335]
	TIME [epoch: 11.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.483539278421583		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.483539278421583 | validation: 4.0791437221880695]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1380030731437785		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.1380030731437785 | validation: 4.067158442265497]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.910616782993732		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.910616782993732 | validation: 3.7236975486727277]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8026354214222513		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.8026354214222513 | validation: 3.9601168055999483]
	TIME [epoch: 11.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.298528530207976		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.298528530207976 | validation: 3.3411913976481125]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.415892208849429		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.415892208849429 | validation: 3.6444355196321396]
	TIME [epoch: 11.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3929398121637546		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.3929398121637546 | validation: 3.376812352100959]
	TIME [epoch: 11.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5601085212865047		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.5601085212865047 | validation: 3.9442430329775067]
	TIME [epoch: 11.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.909984382742185		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.909984382742185 | validation: 6.059126034665939]
	TIME [epoch: 11.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.354560953136807		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.354560953136807 | validation: 3.2796542854448774]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1468973304773002		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.1468973304773002 | validation: 2.9783328321868603]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.974154456770882		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.974154456770882 | validation: 4.15381836913833]
	TIME [epoch: 11.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.172005859766124		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.172005859766124 | validation: 2.897052477430946]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6791274837561523		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.6791274837561523 | validation: 2.719482326941535]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1527970298214005		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.1527970298214005 | validation: 2.6817504339856164]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.945670265096642		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.945670265096642 | validation: 2.706013239389829]
	TIME [epoch: 11.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.655925798699988		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.655925798699988 | validation: 3.5615190609314307]
	TIME [epoch: 11.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.917033622181198		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.917033622181198 | validation: 2.9143609158304207]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.690059909989385		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.690059909989385 | validation: 2.3771793375912944]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5470985817525866		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.5470985817525866 | validation: 2.688824189790289]
	TIME [epoch: 11.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396272665549166		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.396272665549166 | validation: 2.0265335218973126]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.164226950567289		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.164226950567289 | validation: 1.8997864089505725]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4952055118753873		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.4952055118753873 | validation: 2.9532530869658764]
	TIME [epoch: 11.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6694830995066194		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.6694830995066194 | validation: 1.9705414123154623]
	TIME [epoch: 11.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.506918150287076		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.506918150287076 | validation: 2.427010843146282]
	TIME [epoch: 11.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4532244859120795		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.4532244859120795 | validation: 2.2447894446520897]
	TIME [epoch: 11.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.216677958315805		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.216677958315805 | validation: 2.6640944886779363]
	TIME [epoch: 11.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.307233464112355		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.307233464112355 | validation: 2.3924552090668065]
	TIME [epoch: 11.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9394408189552679		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.9394408189552679 | validation: 1.9850255005810824]
	TIME [epoch: 11.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.074837022069209		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.074837022069209 | validation: 3.151825861769111]
	TIME [epoch: 11.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3976938385075415		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.3976938385075415 | validation: 2.121946110808919]
	TIME [epoch: 11.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062073577982922		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.062073577982922 | validation: 2.1067965889326064]
	TIME [epoch: 11.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9534892193526887		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.9534892193526887 | validation: 2.669476676590215]
	TIME [epoch: 11.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.291686732543069		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.291686732543069 | validation: 1.7013741765881594]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067960639228994		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.067960639228994 | validation: 2.1735201962032558]
	TIME [epoch: 11.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.231521744795808		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.231521744795808 | validation: 1.84496233242012]
	TIME [epoch: 11.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.993854550663138		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.993854550663138 | validation: 2.1137678103068818]
	TIME [epoch: 11.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0120498733408603		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.0120498733408603 | validation: 1.60558129869612]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.888040880447262		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.888040880447262 | validation: 1.501382698832411]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07691600145338		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.07691600145338 | validation: 1.504251977596781]
	TIME [epoch: 11.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8065520819222254		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.8065520819222254 | validation: 2.5748394406486885]
	TIME [epoch: 11.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1180561123350694		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.1180561123350694 | validation: 2.432471937670289]
	TIME [epoch: 11.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042336333303774		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.042336333303774 | validation: 1.4355230317250658]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6180016202476724		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.6180016202476724 | validation: 1.602776291271656]
	TIME [epoch: 11.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.871818243832852		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.871818243832852 | validation: 1.7876805574154224]
	TIME [epoch: 11.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7015187876844655		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7015187876844655 | validation: 1.599488246599028]
	TIME [epoch: 11.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.980506943379496		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.980506943379496 | validation: 1.55500353083894]
	TIME [epoch: 11.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.745419224543184		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.745419224543184 | validation: 1.3911470388347655]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.736483593633968		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.736483593633968 | validation: 1.8124017854427354]
	TIME [epoch: 11.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8487009763730702		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.8487009763730702 | validation: 1.7788419408700349]
	TIME [epoch: 11.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6507803771134644		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6507803771134644 | validation: 1.2731116478688278]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74765107689625		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.74765107689625 | validation: 1.4056891872790291]
	TIME [epoch: 11.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.540468938789606		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.540468938789606 | validation: 1.2045448392094897]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7202407601410963		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.7202407601410963 | validation: 1.2382248877696316]
	TIME [epoch: 11.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4308044758692333		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.4308044758692333 | validation: 1.2430766483376403]
	TIME [epoch: 11.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5867557965765458		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.5867557965765458 | validation: 1.4567956366601849]
	TIME [epoch: 11.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7943021204539191		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.7943021204539191 | validation: 2.8276857654983933]
	TIME [epoch: 11.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.062845822409953		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.062845822409953 | validation: 1.608943481557514]
	TIME [epoch: 11.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5332003217270074		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.5332003217270074 | validation: 1.3408915238538837]
	TIME [epoch: 11.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.859649520162815		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.859649520162815 | validation: 1.2515220702972027]
	TIME [epoch: 11.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5387862507717252		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.5387862507717252 | validation: 3.0594379457754752]
	TIME [epoch: 11.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495662774122644		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.7495662774122644 | validation: 2.1574027838193963]
	TIME [epoch: 11.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9190736391566006		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.9190736391566006 | validation: 1.577980319397653]
	TIME [epoch: 11.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5067930765723436		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.5067930765723436 | validation: 1.3086335017147734]
	TIME [epoch: 11.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5501485354132252		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.5501485354132252 | validation: 1.7868784575823735]
	TIME [epoch: 11.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8013105242753338		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.8013105242753338 | validation: 1.2954718669647785]
	TIME [epoch: 11.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4305961491134478		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.4305961491134478 | validation: 1.4082411229620044]
	TIME [epoch: 11.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5801233868079576		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.5801233868079576 | validation: 1.7111529486769974]
	TIME [epoch: 11.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.566698613302766		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.566698613302766 | validation: 1.243853347590525]
	TIME [epoch: 11.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.325464619835631		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.325464619835631 | validation: 2.7003161496536654]
	TIME [epoch: 11.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.187080145586789		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.187080145586789 | validation: 2.041726178543829]
	TIME [epoch: 11.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5338456947831671		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.5338456947831671 | validation: 1.933189742932031]
	TIME [epoch: 11.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.793741552113207		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.793741552113207 | validation: 1.8476681660698941]
	TIME [epoch: 11.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6685988722438236		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6685988722438236 | validation: 1.991380889001219]
	TIME [epoch: 11.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7134405673154829		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.7134405673154829 | validation: 1.2233797387130296]
	TIME [epoch: 11.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3956467776366466		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3956467776366466 | validation: 2.1757080782942415]
	TIME [epoch: 11.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5216459041372747		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.5216459041372747 | validation: 1.6600801556003695]
	TIME [epoch: 11.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3429592057991093		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.3429592057991093 | validation: 1.7320196056258976]
	TIME [epoch: 11.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8635382254674209		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.8635382254674209 | validation: 2.793072639228651]
	TIME [epoch: 11.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.306983469997997		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.306983469997997 | validation: 2.12420820694691]
	TIME [epoch: 11.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8419367101158342		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.8419367101158342 | validation: 1.6178337011951964]
	TIME [epoch: 11.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5493164106868542		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.5493164106868542 | validation: 1.594259198591759]
	TIME [epoch: 11.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4880389297924417		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.4880389297924417 | validation: 1.4972665048495275]
	TIME [epoch: 11.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3392998818556343		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3392998818556343 | validation: 1.1992503866716948]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4356217804585167		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.4356217804585167 | validation: 1.0446740715986909]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4525373673006716		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.4525373673006716 | validation: 1.3927791297929792]
	TIME [epoch: 11.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5632300496289426		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.5632300496289426 | validation: 1.4468892615605597]
	TIME [epoch: 11.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6377742562571622		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.6377742562571622 | validation: 1.4102464771776602]
	TIME [epoch: 11.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1643546716429953		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1643546716429953 | validation: 1.458201063433644]
	TIME [epoch: 11.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2416367195377338		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2416367195377338 | validation: 1.8987788168348334]
	TIME [epoch: 11.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4819103842246266		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.4819103842246266 | validation: 1.1254700941133984]
	TIME [epoch: 11.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3204080828634588		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.3204080828634588 | validation: 1.38319556410649]
	TIME [epoch: 11.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5086361626070663		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.5086361626070663 | validation: 1.0537669063117054]
	TIME [epoch: 11.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.337463588049376		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.337463588049376 | validation: 1.8664136602097927]
	TIME [epoch: 11.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2209691858499792		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.2209691858499792 | validation: 1.3075474729476515]
	TIME [epoch: 11.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4023359303478191		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.4023359303478191 | validation: 0.9527665452905663]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3147834971897348		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3147834971897348 | validation: 1.1952350824830904]
	TIME [epoch: 11.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8130684923772513		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.8130684923772513 | validation: 1.7869650101486891]
	TIME [epoch: 11.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4974147822210107		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 2.4974147822210107 | validation: 1.512820116510031]
	TIME [epoch: 11.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4218565638895613		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.4218565638895613 | validation: 1.2683732348090784]
	TIME [epoch: 11.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3159651541580148		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3159651541580148 | validation: 3.871730715712563]
	TIME [epoch: 11.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3296117535652474		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.3296117535652474 | validation: 1.9379810416104812]
	TIME [epoch: 11.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6126790865143272		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.6126790865143272 | validation: 1.4406607752537313]
	TIME [epoch: 11.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5169632850243857		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.5169632850243857 | validation: 1.6458851298010475]
	TIME [epoch: 11.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.453609983307034		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.453609983307034 | validation: 1.462939930822026]
	TIME [epoch: 11.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5512407269189623		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.5512407269189623 | validation: 1.4860631626043832]
	TIME [epoch: 11.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3665603135171331		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3665603135171331 | validation: 1.1030772368123676]
	TIME [epoch: 11.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1497296515152753		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.1497296515152753 | validation: 1.398402003370533]
	TIME [epoch: 11.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3002441687775028		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.3002441687775028 | validation: 1.0573150133535654]
	TIME [epoch: 11.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3398497359682333		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.3398497359682333 | validation: 1.4012543364178465]
	TIME [epoch: 11.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.273066752294595		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.273066752294595 | validation: 1.2307979547696812]
	TIME [epoch: 11.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2050095044438367		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.2050095044438367 | validation: 1.952498329876863]
	TIME [epoch: 11.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3619688957562057		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3619688957562057 | validation: 1.136742762956223]
	TIME [epoch: 11.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.447396635701304		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.447396635701304 | validation: 1.3308018281593708]
	TIME [epoch: 11.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1146159822575388		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.1146159822575388 | validation: 1.085612224149015]
	TIME [epoch: 11.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4737137719087166		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.4737137719087166 | validation: 1.3331231532895103]
	TIME [epoch: 11.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3233310072400444		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.3233310072400444 | validation: 1.0688862879575112]
	TIME [epoch: 11.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4798421052492303		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.4798421052492303 | validation: 1.8591776934400464]
	TIME [epoch: 11.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3459515848576957		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.3459515848576957 | validation: 1.1426043712990963]
	TIME [epoch: 11.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1896065950843753		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.1896065950843753 | validation: 1.7000307662131755]
	TIME [epoch: 11.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4786980540928143		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.4786980540928143 | validation: 1.106209765346427]
	TIME [epoch: 11.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1063643110643064		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.1063643110643064 | validation: 1.6634824045946004]
	TIME [epoch: 11.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269294980919611		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.269294980919611 | validation: 1.2772518774156394]
	TIME [epoch: 11.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043385979414371		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.043385979414371 | validation: 1.8219423892249993]
	TIME [epoch: 11.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480538369766681		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.480538369766681 | validation: 1.4722803167722571]
	TIME [epoch: 11.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274400482812359		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.274400482812359 | validation: 1.3671891825334286]
	TIME [epoch: 11.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3007262454478346		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.3007262454478346 | validation: 1.1848193857069327]
	TIME [epoch: 11.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2519925335193087		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.2519925335193087 | validation: 1.5148335695307193]
	TIME [epoch: 11.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3629401943313941		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3629401943313941 | validation: 1.3956744738895481]
	TIME [epoch: 11.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341478868382352		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.341478868382352 | validation: 1.4443140369360403]
	TIME [epoch: 11.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1721927437465416		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.1721927437465416 | validation: 1.1275717618212493]
	TIME [epoch: 11.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4121647838655473		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.4121647838655473 | validation: 1.69926359675924]
	TIME [epoch: 11.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230864028506943		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.230864028506943 | validation: 0.918254500357649]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2392145870735192		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.2392145870735192 | validation: 0.9687996310481404]
	TIME [epoch: 11.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1931940851864458		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.1931940851864458 | validation: 1.3952307949965574]
	TIME [epoch: 11.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2090158464659546		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.2090158464659546 | validation: 1.4707451545106036]
	TIME [epoch: 11.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1793558838453375		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.1793558838453375 | validation: 1.1407260745816301]
	TIME [epoch: 11.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2140100538068406		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.2140100538068406 | validation: 1.036786114732011]
	TIME [epoch: 11.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086222209017936		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.086222209017936 | validation: 1.1669484416260694]
	TIME [epoch: 11.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.125376157835162		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.125376157835162 | validation: 0.9694829015083534]
	TIME [epoch: 11.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9977019663330824		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.9977019663330824 | validation: 1.045095487876557]
	TIME [epoch: 11.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2899623787097847		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.2899623787097847 | validation: 2.3219345049592515]
	TIME [epoch: 11.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.833554631406593		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.833554631406593 | validation: 1.5864994295809514]
	TIME [epoch: 11.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3684747729055404		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.3684747729055404 | validation: 1.3556614945716665]
	TIME [epoch: 11.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4907990106399605		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.4907990106399605 | validation: 1.2734250768497237]
	TIME [epoch: 11.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2446656936190719		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.2446656936190719 | validation: 1.1111157598515633]
	TIME [epoch: 11.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2529789247680476		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.2529789247680476 | validation: 1.0711886275681812]
	TIME [epoch: 11.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.021059045345713		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.021059045345713 | validation: 1.2056134172688782]
	TIME [epoch: 11.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2303237349530063		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.2303237349530063 | validation: 1.1646056557121984]
	TIME [epoch: 11.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9780590496979352		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9780590496979352 | validation: 0.9618263536776515]
	TIME [epoch: 11.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2186489148865256		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.2186489148865256 | validation: 0.9570444643319388]
	TIME [epoch: 11.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.074249751108454		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.074249751108454 | validation: 0.98429581915338]
	TIME [epoch: 11.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1260774226752113		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.1260774226752113 | validation: 1.0968266142743262]
	TIME [epoch: 11.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0382274603710366		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0382274603710366 | validation: 1.1214444352343236]
	TIME [epoch: 11.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9510934733529506		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9510934733529506 | validation: 1.2109416264766968]
	TIME [epoch: 11.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1039680688269962		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.1039680688269962 | validation: 1.2944994601153332]
	TIME [epoch: 11.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2931850227320054		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.2931850227320054 | validation: 1.2794332490099865]
	TIME [epoch: 11.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3014702097069057		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.3014702097069057 | validation: 1.20525584604976]
	TIME [epoch: 11.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.131174908825934		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.131174908825934 | validation: 0.8997816177289772]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8933903207526581		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8933903207526581 | validation: 0.9230159607873912]
	TIME [epoch: 11.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0537913251455606		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.0537913251455606 | validation: 1.4359858364402147]
	TIME [epoch: 11.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1516820959791003		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1516820959791003 | validation: 0.8694399905026632]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9853825837228836		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9853825837228836 | validation: 1.1807322653016132]
	TIME [epoch: 11.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3159478187783773		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.3159478187783773 | validation: 1.219147492207991]
	TIME [epoch: 11.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2065370123512986		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.2065370123512986 | validation: 1.1081539544049708]
	TIME [epoch: 11.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0214475763822077		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.0214475763822077 | validation: 0.990200759436715]
	TIME [epoch: 11.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0604151145200655		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.0604151145200655 | validation: 1.1908723646214452]
	TIME [epoch: 11.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.134226423269704		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.134226423269704 | validation: 1.1036523946647896]
	TIME [epoch: 11.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9786442857840375		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9786442857840375 | validation: 0.8843359916171291]
	TIME [epoch: 11.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0129933518524588		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.0129933518524588 | validation: 1.1022471860682177]
	TIME [epoch: 11.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146193254663103		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.146193254663103 | validation: 0.9000489764578337]
	TIME [epoch: 11.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9128814263027389		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9128814263027389 | validation: 1.1196768283655592]
	TIME [epoch: 11.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1970284166317238		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.1970284166317238 | validation: 1.052682765033143]
	TIME [epoch: 11.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.119616843381347		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.119616843381347 | validation: 0.8524708790642467]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8642154090959038		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.8642154090959038 | validation: 2.305383628887777]
	TIME [epoch: 11.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7825198976271674		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.7825198976271674 | validation: 1.403074237606537]
	TIME [epoch: 11.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153043930638418		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.153043930638418 | validation: 1.6558163388780447]
	TIME [epoch: 11.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3383624260215852		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.3383624260215852 | validation: 0.8828673642353876]
	TIME [epoch: 11.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0407631233407921		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.0407631233407921 | validation: 1.2365427060038874]
	TIME [epoch: 11.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.199397439972624		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.199397439972624 | validation: 0.9950942468177875]
	TIME [epoch: 11.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0101106431861206		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.0101106431861206 | validation: 0.9130970572557864]
	TIME [epoch: 11.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9185668409618891		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.9185668409618891 | validation: 0.9677104845214206]
	TIME [epoch: 11.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0838420883145226		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.0838420883145226 | validation: 1.1712406670184288]
	TIME [epoch: 11.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3416251787141658		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.3416251787141658 | validation: 1.0963505398161846]
	TIME [epoch: 11.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053472003887422		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.053472003887422 | validation: 0.8669134293342831]
	TIME [epoch: 11.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3605223212277604		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.3605223212277604 | validation: 1.3561322493179213]
	TIME [epoch: 11.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4287453469093205		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.4287453469093205 | validation: 1.6529648682724876]
	TIME [epoch: 11.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5698322085163858		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.5698322085163858 | validation: 2.314298147197734]
	TIME [epoch: 11.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4873124969287017		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.4873124969287017 | validation: 1.1321679566665739]
	TIME [epoch: 11.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6556150920749866		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.6556150920749866 | validation: 1.2689021574266854]
	TIME [epoch: 11.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3587576956551737		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.3587576956551737 | validation: 1.0660538276491538]
	TIME [epoch: 11.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0669281929948768		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.0669281929948768 | validation: 1.1010464294256235]
	TIME [epoch: 11.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091222862597891		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.091222862597891 | validation: 1.3231458309735376]
	TIME [epoch: 11.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13455165302377		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.13455165302377 | validation: 0.9850811200397689]
	TIME [epoch: 11.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9250674691388994		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.9250674691388994 | validation: 0.9612130336131116]
	TIME [epoch: 11.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0110537366520262		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.0110537366520262 | validation: 0.9022297811097946]
	TIME [epoch: 11.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8627215096094608		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.8627215096094608 | validation: 0.9491981773319695]
	TIME [epoch: 11.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202124943018992		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.202124943018992 | validation: 0.9729801225072484]
	TIME [epoch: 11.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7299617473321276		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.7299617473321276 | validation: 1.4021430540011666]
	TIME [epoch: 11.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4351881846890502		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.4351881846890502 | validation: 1.0896250366712001]
	TIME [epoch: 11.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9567623499868371		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.9567623499868371 | validation: 1.1640606433971596]
	TIME [epoch: 11.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9750636469329408		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.9750636469329408 | validation: 1.5468982026516398]
	TIME [epoch: 11.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2213825531199791		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.2213825531199791 | validation: 0.7929093511705552]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9034075441504025		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.9034075441504025 | validation: 1.1740433022587098]
	TIME [epoch: 11.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2189510788731948		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.2189510788731948 | validation: 1.242317932005803]
	TIME [epoch: 11.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1550239806083813		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.1550239806083813 | validation: 0.947443062215984]
	TIME [epoch: 11.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9212929650518903		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.9212929650518903 | validation: 0.9591451388952725]
	TIME [epoch: 11.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9249343223888569		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.9249343223888569 | validation: 0.7776724256899155]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9157081812609001		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.9157081812609001 | validation: 0.8225123227840478]
	TIME [epoch: 11.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0634436167499535		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.0634436167499535 | validation: 1.1852139042703118]
	TIME [epoch: 11.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2702184951429702		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.2702184951429702 | validation: 1.1298596067752782]
	TIME [epoch: 11.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2704022759216325		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2704022759216325 | validation: 0.9807367252820332]
	TIME [epoch: 11.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2677667258395395		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.2677667258395395 | validation: 1.931970941656132]
	TIME [epoch: 11.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.439673890114808		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.439673890114808 | validation: 1.3448413026190786]
	TIME [epoch: 11.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0549217363342032		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.0549217363342032 | validation: 0.9582311396489678]
	TIME [epoch: 11.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9010760059237963		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.9010760059237963 | validation: 1.1297717512158139]
	TIME [epoch: 11.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2960247649812233		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.2960247649812233 | validation: 1.1843935089801474]
	TIME [epoch: 11.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4013362143013026		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.4013362143013026 | validation: 1.1799501587375185]
	TIME [epoch: 11.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0605543113254305		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.0605543113254305 | validation: 0.8506256225448451]
	TIME [epoch: 11.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1017648659648023		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1017648659648023 | validation: 0.9322883506899067]
	TIME [epoch: 11.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759571297562516		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.9759571297562516 | validation: 0.8856196498338323]
	TIME [epoch: 11.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0583408718177911		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.0583408718177911 | validation: 0.9671212179186829]
	TIME [epoch: 11.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9999402396588712		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9999402396588712 | validation: 0.8035768110526619]
	TIME [epoch: 11.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0195359302114446		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.0195359302114446 | validation: 0.8531854242394218]
	TIME [epoch: 11.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.026171667039145		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.026171667039145 | validation: 0.8168417977194902]
	TIME [epoch: 11.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0249972839955244		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0249972839955244 | validation: 0.7544753712462425]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9454278852315428		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9454278852315428 | validation: 0.8276106103343901]
	TIME [epoch: 11.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8638733421256348		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.8638733421256348 | validation: 2.0213638026008898]
	TIME [epoch: 11.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.451969774092324		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.451969774092324 | validation: 0.9115331885345299]
	TIME [epoch: 11.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9300634304738633		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.9300634304738633 | validation: 1.1717957826735017]
	TIME [epoch: 11.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0367088346512823		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.0367088346512823 | validation: 0.7562277855426135]
	TIME [epoch: 11.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9078052745572767		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.9078052745572767 | validation: 0.9743204097184003]
	TIME [epoch: 11.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9224715891140493		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.9224715891140493 | validation: 0.9466215388326239]
	TIME [epoch: 11.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573013086117885		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9573013086117885 | validation: 0.9800180465780517]
	TIME [epoch: 11.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3770234577744116		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.3770234577744116 | validation: 1.110206332599931]
	TIME [epoch: 11.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9282591601854846		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.9282591601854846 | validation: 0.9466574826354378]
	TIME [epoch: 11.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8613887279117848		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.8613887279117848 | validation: 1.1284489637185713]
	TIME [epoch: 11.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0110812539953908		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.0110812539953908 | validation: 2.2208359420479202]
	TIME [epoch: 11.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.430952725387846		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.430952725387846 | validation: 0.9987144078508056]
	TIME [epoch: 11.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8429657038494434		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8429657038494434 | validation: 0.8678049777337882]
	TIME [epoch: 11.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617131290622525		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.9617131290622525 | validation: 0.9989386270859296]
	TIME [epoch: 11.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8708028912034957		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.8708028912034957 | validation: 0.9037290333770676]
	TIME [epoch: 11.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9486886465241587		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9486886465241587 | validation: 1.1228668783052302]
	TIME [epoch: 11.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8958846248129497		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8958846248129497 | validation: 0.96164479025682]
	TIME [epoch: 11.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532252817932799		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.8532252817932799 | validation: 1.269218640713225]
	TIME [epoch: 11.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0104532095100915		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.0104532095100915 | validation: 1.3071915519985353]
	TIME [epoch: 11.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3931428722480756		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.3931428722480756 | validation: 1.1723352457715597]
	TIME [epoch: 11.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1714307157525847		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.1714307157525847 | validation: 0.9924507246295826]
	TIME [epoch: 11.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9814224017502702		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.9814224017502702 | validation: 0.8354032061154368]
	TIME [epoch: 11.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346380495313567		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.8346380495313567 | validation: 0.789008438025945]
	TIME [epoch: 11.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891774283685832		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.9891774283685832 | validation: 0.9050358320842918]
	TIME [epoch: 11.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8742253491982974		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.8742253491982974 | validation: 1.3691936505003464]
	TIME [epoch: 11.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9829502178522174		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.9829502178522174 | validation: 1.0481895571338418]
	TIME [epoch: 11.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9710984923847625		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.9710984923847625 | validation: 0.7881476013688768]
	TIME [epoch: 11.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8244544708998119		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8244544708998119 | validation: 0.9587631197452133]
	TIME [epoch: 11.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545321277409147		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7545321277409147 | validation: 0.9193338152752663]
	TIME [epoch: 11.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9193895695098644		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.9193895695098644 | validation: 0.7945131715987884]
	TIME [epoch: 11.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9260212227822606		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.9260212227822606 | validation: 1.4439597296892601]
	TIME [epoch: 11.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9859231529566312		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.9859231529566312 | validation: 0.8684850363171348]
	TIME [epoch: 11.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8146093095484342		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.8146093095484342 | validation: 0.8169588491543277]
	TIME [epoch: 11.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7204883937236455		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.7204883937236455 | validation: 0.9016322677738242]
	TIME [epoch: 11.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7261445844725611		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7261445844725611 | validation: 0.7734127465925116]
	TIME [epoch: 11.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9989995067848708		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.9989995067848708 | validation: 0.7212471541225323]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7603738752395482		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.7603738752395482 | validation: 0.9161857220621681]
	TIME [epoch: 11.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0561539335196646		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.0561539335196646 | validation: 1.276239289668305]
	TIME [epoch: 11.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1732185699654856		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.1732185699654856 | validation: 1.0886649719922827]
	TIME [epoch: 11.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688769868032431		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.7688769868032431 | validation: 0.7039569752729312]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190604536074432		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7190604536074432 | validation: 1.339250259050212]
	TIME [epoch: 11.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.048041929903236		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.048041929903236 | validation: 0.8737954694508585]
	TIME [epoch: 11.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7713330853518813		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.7713330853518813 | validation: 0.6796427403514216]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445692113439502		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8445692113439502 | validation: 0.8389113139435378]
	TIME [epoch: 11.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2799168890472439		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.2799168890472439 | validation: 1.0911859556093704]
	TIME [epoch: 11.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077445319917627		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.8077445319917627 | validation: 1.359500672181303]
	TIME [epoch: 11.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9828145578586444		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.9828145578586444 | validation: 0.8159540732364307]
	TIME [epoch: 11.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9140419871849612		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.9140419871849612 | validation: 1.2306213966531478]
	TIME [epoch: 11.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9818352777777788		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.9818352777777788 | validation: 0.7617167075680362]
	TIME [epoch: 11.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726769582514016		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7726769582514016 | validation: 1.078556305490317]
	TIME [epoch: 11.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839952890811782		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.839952890811782 | validation: 0.8266356214210174]
	TIME [epoch: 11.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77707158953607		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.77707158953607 | validation: 0.9027732673304409]
	TIME [epoch: 11.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8533569114390267		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.8533569114390267 | validation: 1.2529260405517]
	TIME [epoch: 11.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347089698394883		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.9347089698394883 | validation: 0.8404671072370417]
	TIME [epoch: 11.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1752391057925953		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.1752391057925953 | validation: 0.8623316346742934]
	TIME [epoch: 11.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8035579170006467		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.8035579170006467 | validation: 1.2612076703643205]
	TIME [epoch: 11.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0379344868626392		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.0379344868626392 | validation: 0.9731747508743988]
	TIME [epoch: 11.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7289296884493233		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7289296884493233 | validation: 0.8030290953996942]
	TIME [epoch: 11.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1114693845116383		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.1114693845116383 | validation: 1.349622506932898]
	TIME [epoch: 11.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.417735059047741		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.417735059047741 | validation: 1.6466742434262365]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.302710287342887		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.302710287342887 | validation: 0.9395972641826137]
	TIME [epoch: 11.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9462124847091906		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.9462124847091906 | validation: 0.860629485470644]
	TIME [epoch: 11.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8150564641021699		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.8150564641021699 | validation: 1.1608260098939536]
	TIME [epoch: 11.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0908570216292386		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.0908570216292386 | validation: 0.9639773336583738]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2116144615889146		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.2116144615889146 | validation: 1.8411825410356528]
	TIME [epoch: 11.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1775138676854295		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.1775138676854295 | validation: 0.9468817466514544]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8069732734087738		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.8069732734087738 | validation: 1.3923661447570135]
	TIME [epoch: 11.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0023216936533799		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.0023216936533799 | validation: 0.7042922290860661]
	TIME [epoch: 11.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7979168352166625		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7979168352166625 | validation: 1.0275286327768753]
	TIME [epoch: 11.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242062242360988		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.0242062242360988 | validation: 0.9136540089763105]
	TIME [epoch: 11.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8882383587961336		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8882383587961336 | validation: 0.7495991360426922]
	TIME [epoch: 11.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941678725965359		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6941678725965359 | validation: 0.7829384143145757]
	TIME [epoch: 11.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968090452064974		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6968090452064974 | validation: 0.7754927528760855]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7114818024044447		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.7114818024044447 | validation: 0.8211149795060817]
	TIME [epoch: 11.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.896773525709513		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.896773525709513 | validation: 0.773415541425316]
	TIME [epoch: 11.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7687485960811904		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7687485960811904 | validation: 0.7586415298275295]
	TIME [epoch: 11.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609873524790195		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.8609873524790195 | validation: 0.7064650004255796]
	TIME [epoch: 11.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.874938557915638		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.874938557915638 | validation: 0.9443599986211596]
	TIME [epoch: 11.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8349551527511523		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.8349551527511523 | validation: 0.790856522927582]
	TIME [epoch: 11.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844501710648883		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.6844501710648883 | validation: 0.729693708202714]
	TIME [epoch: 11.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7081863834773666		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.7081863834773666 | validation: 0.8948925518269093]
	TIME [epoch: 11.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380036266786736		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7380036266786736 | validation: 0.8591699857470769]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7578017945386405		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.7578017945386405 | validation: 0.9165109104371466]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085854106865991		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.8085854106865991 | validation: 1.329368734428764]
	TIME [epoch: 11.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9203075264694903		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.9203075264694903 | validation: 0.778854699840497]
	TIME [epoch: 11.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796826537916999		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7796826537916999 | validation: 0.9322744816669442]
	TIME [epoch: 11.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7608070824073503		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.7608070824073503 | validation: 1.0299199431269728]
	TIME [epoch: 11.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8036605676793519		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.8036605676793519 | validation: 1.1229486876992323]
	TIME [epoch: 11.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7781001891438839		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7781001891438839 | validation: 0.8583728317749282]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.740464328603155		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.740464328603155 | validation: 0.8849647501856452]
	TIME [epoch: 11.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336828120673325		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.7336828120673325 | validation: 1.290042043833521]
	TIME [epoch: 11.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978346275254958		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.8978346275254958 | validation: 0.9938919776101802]
	TIME [epoch: 11.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9602047547694423		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.9602047547694423 | validation: 1.2241047248160992]
	TIME [epoch: 11.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.760991585758843		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.760991585758843 | validation: 0.6414295082082007]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685888209582987		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.685888209582987 | validation: 0.7179703754239982]
	TIME [epoch: 11.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083732262775144		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.7083732262775144 | validation: 0.9109590819506975]
	TIME [epoch: 11.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7954292251595073		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.7954292251595073 | validation: 0.7566119094631282]
	TIME [epoch: 11.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7115478812069743		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7115478812069743 | validation: 0.7235599682402815]
	TIME [epoch: 11.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5990790426519619		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.5990790426519619 | validation: 1.0592013956460888]
	TIME [epoch: 11.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0668516969829613		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.0668516969829613 | validation: 0.8512309407058885]
	TIME [epoch: 11.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390624493677478		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.6390624493677478 | validation: 0.8302781004859222]
	TIME [epoch: 11.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333998692681499		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.7333998692681499 | validation: 0.7270150519058061]
	TIME [epoch: 11.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8195854599189275		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.8195854599189275 | validation: 1.0592581271256527]
	TIME [epoch: 11.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8287019234188754		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.8287019234188754 | validation: 1.603630100989836]
	TIME [epoch: 11.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9225632629945075		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9225632629945075 | validation: 0.8107874660675793]
	TIME [epoch: 11.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250680412735242		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7250680412735242 | validation: 1.1341047730259954]
	TIME [epoch: 11.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832985485139291		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.832985485139291 | validation: 1.11315073231029]
	TIME [epoch: 11.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8357445269675075		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8357445269675075 | validation: 0.8154823324980032]
	TIME [epoch: 11.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699148320657869		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.699148320657869 | validation: 0.7531464090338207]
	TIME [epoch: 11.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509848297462785		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6509848297462785 | validation: 0.8189938925871324]
	TIME [epoch: 11.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6768134158806293		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6768134158806293 | validation: 0.7367797624681974]
	TIME [epoch: 11.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475764326964024		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.7475764326964024 | validation: 0.7923115631065792]
	TIME [epoch: 11.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884684222082083		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7884684222082083 | validation: 0.7583522644497214]
	TIME [epoch: 11.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9131734147226301		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.9131734147226301 | validation: 0.7540086529733049]
	TIME [epoch: 11.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699841583948551		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.699841583948551 | validation: 0.7360445127255741]
	TIME [epoch: 11.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883931144665758		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.6883931144665758 | validation: 0.7038650887902839]
	TIME [epoch: 11.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.622588748010231		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.622588748010231 | validation: 0.6406905151662786]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177575478512686		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.6177575478512686 | validation: 0.6916303736481763]
	TIME [epoch: 11.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312732730426573		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7312732730426573 | validation: 0.8661387721676963]
	TIME [epoch: 11.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375570057001507		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.8375570057001507 | validation: 1.0357126525673659]
	TIME [epoch: 11.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402458321466016		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7402458321466016 | validation: 0.6961483425703422]
	TIME [epoch: 11.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113194419829986		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.6113194419829986 | validation: 0.7395959469909907]
	TIME [epoch: 11.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401197058058839		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.7401197058058839 | validation: 0.9782610284695268]
	TIME [epoch: 11.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0057663587451953		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.0057663587451953 | validation: 0.6169850700214383]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962446548314471		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5962446548314471 | validation: 0.6331145159804102]
	TIME [epoch: 11.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7605358357854692		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7605358357854692 | validation: 0.6684107906245581]
	TIME [epoch: 11.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265872341711883		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7265872341711883 | validation: 0.9823636108508818]
	TIME [epoch: 11.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030919073885756		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7030919073885756 | validation: 0.7893233478525631]
	TIME [epoch: 11.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7354700036052993		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.7354700036052993 | validation: 0.8166411763171776]
	TIME [epoch: 11.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217764039115462		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6217764039115462 | validation: 0.8765507494888789]
	TIME [epoch: 11.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463975398261887		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.6463975398261887 | validation: 1.0380687862870805]
	TIME [epoch: 11.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545994449622205		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8545994449622205 | validation: 0.803503790204285]
	TIME [epoch: 11.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9863378963535808		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.9863378963535808 | validation: 1.5946552343040798]
	TIME [epoch: 11.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8667186451341378		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8667186451341378 | validation: 1.013214868309148]
	TIME [epoch: 11.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0961444259143152		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.0961444259143152 | validation: 1.3358553502331387]
	TIME [epoch: 11.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.053121397204178		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.053121397204178 | validation: 0.919763231881648]
	TIME [epoch: 11.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7464001577282487		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.7464001577282487 | validation: 0.6943549463346907]
	TIME [epoch: 11.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7540908449589745		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7540908449589745 | validation: 0.7553972657843275]
	TIME [epoch: 11.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355889355440306		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.7355889355440306 | validation: 0.7411959887525558]
	TIME [epoch: 11.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6568617042683124		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.6568617042683124 | validation: 0.9757309481695674]
	TIME [epoch: 11.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9452762580029239		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.9452762580029239 | validation: 1.0481746340348042]
	TIME [epoch: 11.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7123709587792437		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7123709587792437 | validation: 0.7553097569748926]
	TIME [epoch: 11.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750755238107683		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.750755238107683 | validation: 0.8714490345293758]
	TIME [epoch: 11.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6938096664600734		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6938096664600734 | validation: 0.6973829978970211]
	TIME [epoch: 11.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6024757029924361		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.6024757029924361 | validation: 0.6355768099644573]
	TIME [epoch: 11.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8327657922189191		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.8327657922189191 | validation: 0.7958649807100986]
	TIME [epoch: 11.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198825542449426		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.7198825542449426 | validation: 0.6887143567055043]
	TIME [epoch: 11.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856118353227143		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6856118353227143 | validation: 0.8044786089134287]
	TIME [epoch: 11.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7198291698155042		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7198291698155042 | validation: 0.8315250088873228]
	TIME [epoch: 11.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6715974689967512		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.6715974689967512 | validation: 0.7063990839685191]
	TIME [epoch: 11.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682366352046526		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.6682366352046526 | validation: 0.7498983472233105]
	TIME [epoch: 11.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654385221895031		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.654385221895031 | validation: 0.5615456073192597]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5963818045935797		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.5963818045935797 | validation: 0.6374340702084356]
	TIME [epoch: 11.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5971504922840776		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5971504922840776 | validation: 1.4959489808369488]
	TIME [epoch: 11.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9032036286124762		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.9032036286124762 | validation: 0.6291404522356028]
	TIME [epoch: 11.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57664777583338		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.57664777583338 | validation: 0.7966121934464014]
	TIME [epoch: 11.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491475797071449		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.6491475797071449 | validation: 0.6768558244456716]
	TIME [epoch: 11.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065070887310076		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.6065070887310076 | validation: 0.6184593216933082]
	TIME [epoch: 11.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6719920281345013		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.6719920281345013 | validation: 0.6077160455062827]
	TIME [epoch: 11.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803171460938594		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.5803171460938594 | validation: 0.6777572294998649]
	TIME [epoch: 11.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590239087823772		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.590239087823772 | validation: 0.725726066127825]
	TIME [epoch: 11.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6330574727232391		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.6330574727232391 | validation: 0.7304642073040983]
	TIME [epoch: 11.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6002874400819634		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6002874400819634 | validation: 0.5920317668196193]
	TIME [epoch: 11.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.594397720394188		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.594397720394188 | validation: 0.9072332504743023]
	TIME [epoch: 11.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.656878549819502		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.656878549819502 | validation: 0.6267539791956136]
	TIME [epoch: 11.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563791022771178		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.563791022771178 | validation: 0.6559853949951137]
	TIME [epoch: 11.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682438579184752		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.6682438579184752 | validation: 0.7865195030481633]
	TIME [epoch: 11.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615387136946737		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.615387136946737 | validation: 0.6134055613926279]
	TIME [epoch: 11.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5910955061329783		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.5910955061329783 | validation: 0.7816179416239081]
	TIME [epoch: 11.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6502480049978068		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.6502480049978068 | validation: 0.72576194077357]
	TIME [epoch: 11.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104747788720776		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.6104747788720776 | validation: 0.6239036693072381]
	TIME [epoch: 11.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342054350038157		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6342054350038157 | validation: 0.6184985279674602]
	TIME [epoch: 11.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615179304693424		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.615179304693424 | validation: 0.7192358178336129]
	TIME [epoch: 11.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.771505219071224		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.771505219071224 | validation: 0.8642778872932984]
	TIME [epoch: 11.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608977363016805		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.608977363016805 | validation: 0.7179805378679879]
	TIME [epoch: 11.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265718728134607		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7265718728134607 | validation: 0.7080974444850152]
	TIME [epoch: 11.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229502934693814		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.6229502934693814 | validation: 0.615333258254735]
	TIME [epoch: 11.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6112426714237936		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.6112426714237936 | validation: 0.5740679817336602]
	TIME [epoch: 11.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939080740457995		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5939080740457995 | validation: 0.697212149678179]
	TIME [epoch: 11.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.591122774570263		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.591122774570263 | validation: 0.8203579461423951]
	TIME [epoch: 11.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677711279483286		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.677711279483286 | validation: 0.848519752912589]
	TIME [epoch: 11.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6356948739262064		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6356948739262064 | validation: 0.6174571646846464]
	TIME [epoch: 11.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6787322638918554		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6787322638918554 | validation: 0.5746219462057882]
	TIME [epoch: 11.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378020143115689		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.7378020143115689 | validation: 0.7814536472938041]
	TIME [epoch: 11.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453966246177213		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.6453966246177213 | validation: 0.5080013811513509]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676613634504988		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.5676613634504988 | validation: 0.7350625055104755]
	TIME [epoch: 11.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4894356278842851		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4894356278842851 | validation: 0.7140145503344003]
	TIME [epoch: 11.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939317498672714		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.4939317498672714 | validation: 0.6669956711676918]
	TIME [epoch: 11.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764479381660526		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5764479381660526 | validation: 0.5209112261193071]
	TIME [epoch: 11.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44494165196540847		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.44494165196540847 | validation: 0.6009237321458752]
	TIME [epoch: 11.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5841612540834942		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.5841612540834942 | validation: 0.5878949887682309]
	TIME [epoch: 11.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763379542725533		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.4763379542725533 | validation: 0.683441911708062]
	TIME [epoch: 11.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071668544325434		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.8071668544325434 | validation: 0.6117345857978964]
	TIME [epoch: 11.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441332491992283		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5441332491992283 | validation: 0.7171232378903709]
	TIME [epoch: 11.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9032346351932463		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.9032346351932463 | validation: 1.0515555823816523]
	TIME [epoch: 11.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683835268382996		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.683835268382996 | validation: 1.0125865335884698]
	TIME [epoch: 11.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345206681311752		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.6345206681311752 | validation: 0.6987413898837349]
	TIME [epoch: 11.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6578307887194744		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6578307887194744 | validation: 0.612880266824088]
	TIME [epoch: 11.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003228257853141		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.7003228257853141 | validation: 0.588239175868266]
	TIME [epoch: 11.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278799391134346		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.5278799391134346 | validation: 0.7374326730297192]
	TIME [epoch: 11.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671703657441309		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6671703657441309 | validation: 1.0916799925917955]
	TIME [epoch: 11.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698885681536299		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.698885681536299 | validation: 0.7751937333808351]
	TIME [epoch: 11.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346032841440863		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.5346032841440863 | validation: 0.6060071374912732]
	TIME [epoch: 11.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311972308869319		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.5311972308869319 | validation: 0.6186598984186223]
	TIME [epoch: 11.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460408564307373		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.5460408564307373 | validation: 0.7208649983800745]
	TIME [epoch: 11.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446724966210323		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5446724966210323 | validation: 0.5153879212340005]
	TIME [epoch: 11.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5296739138540502		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.5296739138540502 | validation: 0.8528661553819324]
	TIME [epoch: 11.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524603546958709		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6524603546958709 | validation: 0.5360339314873279]
	TIME [epoch: 11.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6054459005783317		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6054459005783317 | validation: 1.9041326036235162]
	TIME [epoch: 11.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0873420073912663		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.0873420073912663 | validation: 0.6817158927611842]
	TIME [epoch: 11.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6627844642524215		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6627844642524215 | validation: 0.7135754753245334]
	TIME [epoch: 11.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8037177769288857		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.8037177769288857 | validation: 0.8764677660844414]
	TIME [epoch: 11.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359874767789753		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6359874767789753 | validation: 0.5811723298371577]
	TIME [epoch: 11.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786441636475836		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5786441636475836 | validation: 0.5864193448804312]
	TIME [epoch: 11.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399485768504986		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.5399485768504986 | validation: 0.5670828327794792]
	TIME [epoch: 11.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457169815102596		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.457169815102596 | validation: 0.546477405556738]
	TIME [epoch: 11.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.588115711153122		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.588115711153122 | validation: 0.6720518534490316]
	TIME [epoch: 11.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4990489098198154		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.4990489098198154 | validation: 0.7147694283489489]
	TIME [epoch: 11.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246645308532382		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.5246645308532382 | validation: 0.6658918462077031]
	TIME [epoch: 11.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142688367864972		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.6142688367864972 | validation: 0.7828570889048553]
	TIME [epoch: 11.6 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928556059370992		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5928556059370992 | validation: 0.7671297486896024]
	TIME [epoch: 11.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6662003546753446		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6662003546753446 | validation: 0.7091098771122814]
	TIME [epoch: 11.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957978506801579		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5957978506801579 | validation: 0.6358450536962873]
	TIME [epoch: 11.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48618948598418044		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.48618948598418044 | validation: 0.49199406166785403]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512643969699014		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.5512643969699014 | validation: 1.3281648328411257]
	TIME [epoch: 11.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0278189468693237		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.0278189468693237 | validation: 0.6008176739014893]
	TIME [epoch: 11.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393402060496834		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.6393402060496834 | validation: 0.6946859668582449]
	TIME [epoch: 11.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624430980798036		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5624430980798036 | validation: 0.6038238254274942]
	TIME [epoch: 11.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515799529543292		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5515799529543292 | validation: 0.5821136298284926]
	TIME [epoch: 11.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802739005979785		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.5802739005979785 | validation: 0.5048070929778916]
	TIME [epoch: 11.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543267813618261		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5543267813618261 | validation: 0.5560946758773911]
	TIME [epoch: 11.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820272615984958		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5820272615984958 | validation: 0.5075917883315887]
	TIME [epoch: 11.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5935678471861285		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5935678471861285 | validation: 0.5702097486952582]
	TIME [epoch: 11.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5551965995848634		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.5551965995848634 | validation: 0.7446039823012766]
	TIME [epoch: 11.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003351975225887		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.5003351975225887 | validation: 0.7148817346782947]
	TIME [epoch: 11.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066659090752331		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.8066659090752331 | validation: 0.6855880229393359]
	TIME [epoch: 11.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7404204682165968		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.7404204682165968 | validation: 0.7177531787769226]
	TIME [epoch: 11.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270930959156223		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.7270930959156223 | validation: 0.5822665434087599]
	TIME [epoch: 11.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691581982898659		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.5691581982898659 | validation: 0.4784828092777793]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188776632834051		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6188776632834051 | validation: 0.46911744529704136]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257087582321054		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5257087582321054 | validation: 0.5310111594086336]
	TIME [epoch: 11.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48656967307249815		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.48656967307249815 | validation: 0.4853360983045859]
	TIME [epoch: 11.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755388809224944		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.5755388809224944 | validation: 0.8923521200521759]
	TIME [epoch: 11.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154761970892935		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.6154761970892935 | validation: 0.6232073787517417]
	TIME [epoch: 11.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174231175741112		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6174231175741112 | validation: 0.5397577912240952]
	TIME [epoch: 11.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508573642559242		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5508573642559242 | validation: 0.6361922301238524]
	TIME [epoch: 11.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542387981482724		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.542387981482724 | validation: 0.6790939835089363]
	TIME [epoch: 11.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871516173531397		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5871516173531397 | validation: 0.734464798998799]
	TIME [epoch: 11.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166275897056217		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.5166275897056217 | validation: 0.5868514186596916]
	TIME [epoch: 11.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704752163605237		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.4704752163605237 | validation: 0.5591613884928411]
	TIME [epoch: 11.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694088237050929		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.4694088237050929 | validation: 0.570902992350209]
	TIME [epoch: 11.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063910116557363		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6063910116557363 | validation: 0.7221175409245427]
	TIME [epoch: 11.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1022156782301185		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.1022156782301185 | validation: 0.7378238993746632]
	TIME [epoch: 11.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610525850578209		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.6610525850578209 | validation: 0.527609503745957]
	TIME [epoch: 11.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45193318061271537		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.45193318061271537 | validation: 0.5320513887948267]
	TIME [epoch: 11.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789638203174658		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5789638203174658 | validation: 0.5293813662629405]
	TIME [epoch: 11.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501776773966482		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.501776773966482 | validation: 0.5532694691134056]
	TIME [epoch: 11.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5027059334668502		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.5027059334668502 | validation: 0.7443351351343523]
	TIME [epoch: 11.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418309976917033		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6418309976917033 | validation: 0.6084159084167926]
	TIME [epoch: 11.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653872649027868		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5653872649027868 | validation: 0.599543364501956]
	TIME [epoch: 11.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269453304802625		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5269453304802625 | validation: 0.6054512032835279]
	TIME [epoch: 11.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7516479870704824		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7516479870704824 | validation: 0.540095710355539]
	TIME [epoch: 11.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091035410311809		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.6091035410311809 | validation: 0.5704420347277716]
	TIME [epoch: 11.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105992917445848		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6105992917445848 | validation: 0.7093380287832471]
	TIME [epoch: 11.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527425357569233		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.5527425357569233 | validation: 0.6290926008789011]
	TIME [epoch: 11.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314148585852326		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6314148585852326 | validation: 0.4599689373149595]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_554.pth
	Model improved!!!
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6324699831976902		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6324699831976902 | validation: 1.137855912776561]
	TIME [epoch: 11.6 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264623156776082		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6264623156776082 | validation: 0.4285776297765702]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4893300835986543		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.4893300835986543 | validation: 0.5645724319620168]
	TIME [epoch: 11.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45178047349426836		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.45178047349426836 | validation: 0.508462650018223]
	TIME [epoch: 11.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598774749550933		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.4598774749550933 | validation: 0.5307476148016178]
	TIME [epoch: 11.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104669201555363		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.5104669201555363 | validation: 0.5895790036435429]
	TIME [epoch: 11.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.513951407775251		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.513951407775251 | validation: 0.7534613805541125]
	TIME [epoch: 11.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760815151668944		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.6760815151668944 | validation: 0.710495296798622]
	TIME [epoch: 11.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852138373431091		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.6852138373431091 | validation: 0.8919056292246144]
	TIME [epoch: 11.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.588224514970624		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.588224514970624 | validation: 0.7711746029249167]
	TIME [epoch: 11.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540543573480234		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.5540543573480234 | validation: 0.756022800275428]
	TIME [epoch: 11.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5529693500061953		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.5529693500061953 | validation: 0.7857885999554282]
	TIME [epoch: 11.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909744375218005		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5909744375218005 | validation: 0.5777399976882789]
	TIME [epoch: 11.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.520368893974583		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.520368893974583 | validation: 0.5303323829070662]
	TIME [epoch: 11.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188316019459509		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.5188316019459509 | validation: 0.6949641886358725]
	TIME [epoch: 11.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565393358299672		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.5565393358299672 | validation: 0.6543357541711283]
	TIME [epoch: 11.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475287460402877		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5475287460402877 | validation: 0.5302246616057896]
	TIME [epoch: 11.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4795579250068066		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.4795579250068066 | validation: 0.5065478496105351]
	TIME [epoch: 11.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40199941322894306		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.40199941322894306 | validation: 0.48532159119073587]
	TIME [epoch: 11.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49078543030532473		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.49078543030532473 | validation: 0.7001659307386257]
	TIME [epoch: 11.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931920653440623		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5931920653440623 | validation: 0.7041146897899399]
	TIME [epoch: 11.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402584367101579		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.5402584367101579 | validation: 0.5289277278982405]
	TIME [epoch: 11.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4775253694206656		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4775253694206656 | validation: 0.5544515375572674]
	TIME [epoch: 11.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46395632113098517		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.46395632113098517 | validation: 0.6912608916684593]
	TIME [epoch: 11.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6103711954115141		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6103711954115141 | validation: 0.8043735621206594]
	TIME [epoch: 11.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972959370960285		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.5972959370960285 | validation: 0.6145482453469203]
	TIME [epoch: 11.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194745457326717		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5194745457326717 | validation: 0.4847520279411311]
	TIME [epoch: 11.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4386609030704983		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.4386609030704983 | validation: 0.7449985058966883]
	TIME [epoch: 11.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346388711590228		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5346388711590228 | validation: 0.7312073565377405]
	TIME [epoch: 11.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438912404866034		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.438912404866034 | validation: 0.522454537546843]
	TIME [epoch: 11.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.435898514780863		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.435898514780863 | validation: 0.4679674158781022]
	TIME [epoch: 11.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48117418438462956		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.48117418438462956 | validation: 0.6009221176442769]
	TIME [epoch: 11.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47528726450178804		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.47528726450178804 | validation: 0.5093363709493468]
	TIME [epoch: 11.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44631698389355534		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.44631698389355534 | validation: 0.6500872700675342]
	TIME [epoch: 11.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47770887089486813		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.47770887089486813 | validation: 0.5443559784978514]
	TIME [epoch: 11.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45360112346069215		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.45360112346069215 | validation: 0.5515529066840742]
	TIME [epoch: 11.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41308636902054496		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.41308636902054496 | validation: 0.4918039419199125]
	TIME [epoch: 11.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45996285436231227		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.45996285436231227 | validation: 0.902205648315032]
	TIME [epoch: 11.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8994751422913554		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.8994751422913554 | validation: 0.47122215466382467]
	TIME [epoch: 11.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45127981455499433		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.45127981455499433 | validation: 0.6519030097243903]
	TIME [epoch: 11.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121909158040082		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.6121909158040082 | validation: 0.7280663809441427]
	TIME [epoch: 11.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066989267473637		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.5066989267473637 | validation: 0.5649969708730602]
	TIME [epoch: 11.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46728406759793173		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.46728406759793173 | validation: 0.6000702013290011]
	TIME [epoch: 11.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47927995935805995		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.47927995935805995 | validation: 0.5107664552322128]
	TIME [epoch: 11.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42257337832290964		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.42257337832290964 | validation: 0.6012495323403265]
	TIME [epoch: 11.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946647168370967		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.3946647168370967 | validation: 0.5825083806128553]
	TIME [epoch: 11.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771362028670536		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.4771362028670536 | validation: 0.668949013877313]
	TIME [epoch: 11.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4896892604253526		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.4896892604253526 | validation: 0.4973776813608581]
	TIME [epoch: 11.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.414982580767726		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.414982580767726 | validation: 0.5927253620163505]
	TIME [epoch: 11.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47442256426241886		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.47442256426241886 | validation: 0.48582801404089887]
	TIME [epoch: 11.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45772991498444704		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.45772991498444704 | validation: 0.6643552481347124]
	TIME [epoch: 11.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.513640969903665		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.513640969903665 | validation: 0.6260957006762057]
	TIME [epoch: 11.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4203455277392642		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.4203455277392642 | validation: 0.9445937418965131]
	TIME [epoch: 11.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6012182280400026		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.6012182280400026 | validation: 0.5750897721552665]
	TIME [epoch: 11.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44457629389953685		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.44457629389953685 | validation: 0.6049503269298331]
	TIME [epoch: 11.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6622731192977037		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6622731192977037 | validation: 0.5371423584548688]
	TIME [epoch: 11.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42549707734551306		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.42549707734551306 | validation: 0.38488800628606257]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4161940940054367		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.4161940940054367 | validation: 0.4838988292582251]
	TIME [epoch: 11.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695691162961271		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.4695691162961271 | validation: 0.4533887032620207]
	TIME [epoch: 11.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204270825930497		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.4204270825930497 | validation: 0.5961982943815168]
	TIME [epoch: 11.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44699111277678016		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.44699111277678016 | validation: 0.4888135027665343]
	TIME [epoch: 11.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5928547663194913		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5928547663194913 | validation: 0.6960792425623421]
	TIME [epoch: 11.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5513083282253411		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5513083282253411 | validation: 0.5649138725404916]
	TIME [epoch: 11.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46774966629715276		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.46774966629715276 | validation: 0.6334103465354326]
	TIME [epoch: 11.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43937202798140423		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.43937202798140423 | validation: 0.3609810754403249]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3536464276166393		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.3536464276166393 | validation: 0.5335412294670264]
	TIME [epoch: 11.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4950857485218833		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.4950857485218833 | validation: 0.5925758313154609]
	TIME [epoch: 11.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464501366978074		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.464501366978074 | validation: 0.4593158527411873]
	TIME [epoch: 11.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.433003134446545		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.433003134446545 | validation: 0.5302543812234614]
	TIME [epoch: 11.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134574697958759		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.4134574697958759 | validation: 0.3920879766424972]
	TIME [epoch: 11.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3706422361065919		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.3706422361065919 | validation: 0.46806956028900204]
	TIME [epoch: 11.5 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4783079748248609		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.4783079748248609 | validation: 0.8058569212705198]
	TIME [epoch: 11.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799964696169487		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.6799964696169487 | validation: 0.5194975991955287]
	TIME [epoch: 11.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42498240733272374		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.42498240733272374 | validation: 0.38140042650803124]
	TIME [epoch: 11.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4376729370689761		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.4376729370689761 | validation: 0.38550577770315403]
	TIME [epoch: 11.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440028203139436		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.440028203139436 | validation: 0.5117416970413067]
	TIME [epoch: 11.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47471009543013143		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.47471009543013143 | validation: 0.3664112532673561]
	TIME [epoch: 11.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45087443157797225		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.45087443157797225 | validation: 0.7454683712430328]
	TIME [epoch: 11.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.664248984414755		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.664248984414755 | validation: 0.594843406624657]
	TIME [epoch: 11.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673591592984324		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.4673591592984324 | validation: 0.4667320119282131]
	TIME [epoch: 11.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4159764591985282		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.4159764591985282 | validation: 0.49023788433589494]
	TIME [epoch: 11.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43040521319170766		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.43040521319170766 | validation: 0.6407592367226767]
	TIME [epoch: 11.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753655029852978		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.4753655029852978 | validation: 0.41864677413238827]
	TIME [epoch: 11.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002620393738193		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.4002620393738193 | validation: 0.48989732594046687]
	TIME [epoch: 11.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48202069313012974		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.48202069313012974 | validation: 0.4966678623399233]
	TIME [epoch: 11.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43754195791591166		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.43754195791591166 | validation: 0.408297418830975]
	TIME [epoch: 11.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642904643835558		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.4642904643835558 | validation: 0.4342020679894701]
	TIME [epoch: 11.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39066766521404317		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.39066766521404317 | validation: 0.5593598040868285]
	TIME [epoch: 11.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428260527792385		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5428260527792385 | validation: 0.6564314484437757]
	TIME [epoch: 11.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4851000301449717		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.4851000301449717 | validation: 0.5886751963996999]
	TIME [epoch: 11.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5472628457733427		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5472628457733427 | validation: 0.4333963062519577]
	TIME [epoch: 11.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43422163739036523		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.43422163739036523 | validation: 0.5002247542226202]
	TIME [epoch: 11.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37903952461947543		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.37903952461947543 | validation: 0.4102498797923096]
	TIME [epoch: 11.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3714728173017252		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.3714728173017252 | validation: 0.4959578702162952]
	TIME [epoch: 11.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4165731684219497		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.4165731684219497 | validation: 0.5042959466472412]
	TIME [epoch: 11.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44145074139343116		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.44145074139343116 | validation: 0.4113579302507078]
	TIME [epoch: 11.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5408931378153196		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5408931378153196 | validation: 0.5502165098428068]
	TIME [epoch: 11.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738652454115287		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5738652454115287 | validation: 0.4565917002934974]
	TIME [epoch: 11.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3791175262434879		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3791175262434879 | validation: 0.5873604203802839]
	TIME [epoch: 11.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43841885070384906		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.43841885070384906 | validation: 0.7179286772430706]
	TIME [epoch: 11.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280299568669392		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.7280299568669392 | validation: 0.5963227980949172]
	TIME [epoch: 11.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44689007466156416		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.44689007466156416 | validation: 0.5514875779477371]
	TIME [epoch: 11.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39404553369570616		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.39404553369570616 | validation: 0.4641476264924303]
	TIME [epoch: 11.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42136837517025566		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.42136837517025566 | validation: 0.5284067106390807]
	TIME [epoch: 11.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4407396741717443		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.4407396741717443 | validation: 0.5523775925603035]
	TIME [epoch: 11.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47150883659433823		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.47150883659433823 | validation: 0.33168015081480307]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_660.pth
	Model improved!!!
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41649674660971603		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.41649674660971603 | validation: 0.39604476488963786]
	TIME [epoch: 11.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4333203260421103		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.4333203260421103 | validation: 0.4462256405544883]
	TIME [epoch: 11.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.463103364262332		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.463103364262332 | validation: 0.4610815649643137]
	TIME [epoch: 11.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495886374242961		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.4495886374242961 | validation: 0.48503061998367275]
	TIME [epoch: 11.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3801446282224541		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.3801446282224541 | validation: 0.32865362256478997]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44671903805520696		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.44671903805520696 | validation: 0.5369703122690668]
	TIME [epoch: 11.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533954141093557		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.533954141093557 | validation: 0.5049705685190731]
	TIME [epoch: 11.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46836632063914657		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.46836632063914657 | validation: 0.4353066522405126]
	TIME [epoch: 11.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4442073097288368		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.4442073097288368 | validation: 0.3928052846987855]
	TIME [epoch: 11.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462075960374138		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.462075960374138 | validation: 0.4930334323232307]
	TIME [epoch: 11.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39867151654936983		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.39867151654936983 | validation: 0.5129586679030637]
	TIME [epoch: 11.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45805831288570087		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.45805831288570087 | validation: 0.45317367462138164]
	TIME [epoch: 11.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3735226411233178		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3735226411233178 | validation: 0.4576245688465844]
	TIME [epoch: 11.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41761160594813834		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.41761160594813834 | validation: 0.38019785392300653]
	TIME [epoch: 11.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4107586285766218		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.4107586285766218 | validation: 0.39859297038166447]
	TIME [epoch: 11.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44472873387207856		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.44472873387207856 | validation: 0.33832519053800253]
	TIME [epoch: 11.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47040249571938814		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.47040249571938814 | validation: 0.5391898610223222]
	TIME [epoch: 11.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41225415836870866		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.41225415836870866 | validation: 0.3518104581205623]
	TIME [epoch: 11.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3861662929705686		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3861662929705686 | validation: 0.39746335013195955]
	TIME [epoch: 11.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925353990131656		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.3925353990131656 | validation: 0.40169786538277924]
	TIME [epoch: 11.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813172509124323		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.3813172509124323 | validation: 0.3412561718002594]
	TIME [epoch: 11.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36043644194937663		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.36043644194937663 | validation: 0.37463291148233946]
	TIME [epoch: 11.5 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36772776205796154		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.36772776205796154 | validation: 0.3504086495946861]
	TIME [epoch: 11.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3286748866415202		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.3286748866415202 | validation: 0.3805805419800868]
	TIME [epoch: 11.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4239335336115394		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.4239335336115394 | validation: 0.5632324260078216]
	TIME [epoch: 11.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44834122543083155		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.44834122543083155 | validation: 0.5542695311616743]
	TIME [epoch: 11.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518390030182554		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.4518390030182554 | validation: 0.43916100821600224]
	TIME [epoch: 11.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40076043911595965		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.40076043911595965 | validation: 0.40758119495747325]
	TIME [epoch: 11.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401380843228751		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.6401380843228751 | validation: 0.4108719158837022]
	TIME [epoch: 11.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4770714486501121		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.4770714486501121 | validation: 0.4441142037270812]
	TIME [epoch: 11.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46805471523329584		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.46805471523329584 | validation: 0.48377308958099763]
	TIME [epoch: 11.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662028950773909		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.4662028950773909 | validation: 0.40836023063526794]
	TIME [epoch: 11.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39396000865392866		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.39396000865392866 | validation: 0.4837850625451442]
	TIME [epoch: 11.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46074949436958756		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.46074949436958756 | validation: 0.3743268261208082]
	TIME [epoch: 11.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3543577704222598		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.3543577704222598 | validation: 0.3412845243776411]
	TIME [epoch: 11.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775802759988425		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.3775802759988425 | validation: 0.4680783267865985]
	TIME [epoch: 11.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40137788223750814		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.40137788223750814 | validation: 0.48201523028495546]
	TIME [epoch: 11.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3863054026711892		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.3863054026711892 | validation: 0.4311627510468496]
	TIME [epoch: 11.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40349101735353987		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.40349101735353987 | validation: 0.5530732132150871]
	TIME [epoch: 11.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194883029346784		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5194883029346784 | validation: 0.42571372025622595]
	TIME [epoch: 11.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41558502784253726		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.41558502784253726 | validation: 0.35661604560596916]
	TIME [epoch: 11.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3417924306914778		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3417924306914778 | validation: 0.4420245140053542]
	TIME [epoch: 11.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45188380384353555		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.45188380384353555 | validation: 0.46197709550519184]
	TIME [epoch: 11.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43623414804041105		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.43623414804041105 | validation: 0.37244345156474795]
	TIME [epoch: 11.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886659353122785		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.3886659353122785 | validation: 0.3813207722064004]
	TIME [epoch: 11.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919685728334828		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3919685728334828 | validation: 0.4007124935966346]
	TIME [epoch: 11.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4284757923269381		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.4284757923269381 | validation: 0.4746287252483799]
	TIME [epoch: 11.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3627054794158572		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.3627054794158572 | validation: 0.42681755372434155]
	TIME [epoch: 11.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36666659645667565		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.36666659645667565 | validation: 0.46495796308777265]
	TIME [epoch: 11.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35895162701734856		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.35895162701734856 | validation: 0.32385456872522234]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3493319058032107		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.3493319058032107 | validation: 0.45135587038087305]
	TIME [epoch: 11.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38943954151755833		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.38943954151755833 | validation: 0.3894985637364063]
	TIME [epoch: 11.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40358933912422046		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.40358933912422046 | validation: 0.4678285463764091]
	TIME [epoch: 11.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152008915524554		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.6152008915524554 | validation: 0.9813993392885044]
	TIME [epoch: 11.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904276074301434		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.4904276074301434 | validation: 0.4639196322513894]
	TIME [epoch: 11.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46374536930754073		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.46374536930754073 | validation: 0.7230516905025082]
	TIME [epoch: 11.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554393217578534		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5554393217578534 | validation: 0.46072661967158846]
	TIME [epoch: 11.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423781104507057		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.4423781104507057 | validation: 0.4376057409669632]
	TIME [epoch: 11.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39375766705385795		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.39375766705385795 | validation: 0.6311782228588754]
	TIME [epoch: 11.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42458334905662976		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.42458334905662976 | validation: 0.43983884025045755]
	TIME [epoch: 11.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40003640743713603		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.40003640743713603 | validation: 0.4480195218248309]
	TIME [epoch: 11.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844853841181546		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.3844853841181546 | validation: 0.4314631805599244]
	TIME [epoch: 11.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37606986577299184		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.37606986577299184 | validation: 0.4279689764057422]
	TIME [epoch: 11.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3828451662995047		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.3828451662995047 | validation: 0.5237403401972262]
	TIME [epoch: 11.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3621494488084356		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3621494488084356 | validation: 0.3785173471713329]
	TIME [epoch: 11.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37342315781893837		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.37342315781893837 | validation: 0.5716053565525391]
	TIME [epoch: 11.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42319078517645814		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.42319078517645814 | validation: 0.5441957581831213]
	TIME [epoch: 11.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886949360498575		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.3886949360498575 | validation: 0.47865212905028065]
	TIME [epoch: 11.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3699852341397371		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.3699852341397371 | validation: 0.38594345961864096]
	TIME [epoch: 11.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38334917164097904		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.38334917164097904 | validation: 0.4509812807883502]
	TIME [epoch: 11.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36740905081344405		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.36740905081344405 | validation: 0.3502883816379888]
	TIME [epoch: 11.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32952070715446663		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.32952070715446663 | validation: 0.339511239985699]
	TIME [epoch: 11.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35557600738829254		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.35557600738829254 | validation: 0.47237025552268863]
	TIME [epoch: 11.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3794546971388415		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.3794546971388415 | validation: 0.42551196864366925]
	TIME [epoch: 11.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3542697348675559		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.3542697348675559 | validation: 0.45655513015911875]
	TIME [epoch: 11.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380795888179041		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.3380795888179041 | validation: 0.4553819935886456]
	TIME [epoch: 11.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820111160770159		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.3820111160770159 | validation: 0.41603585821497996]
	TIME [epoch: 11.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3987189388088327		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.3987189388088327 | validation: 0.38665542685023746]
	TIME [epoch: 11.5 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36212628114560014		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.36212628114560014 | validation: 0.48781684367461386]
	TIME [epoch: 11.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3948398179641003		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.3948398179641003 | validation: 0.4433936015643281]
	TIME [epoch: 11.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607119043320115		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.3607119043320115 | validation: 0.534949368315614]
	TIME [epoch: 11.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4038391055691859		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4038391055691859 | validation: 0.3191369864055554]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3841276875813477		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3841276875813477 | validation: 0.42894846853177515]
	TIME [epoch: 11.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929231829094835		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.3929231829094835 | validation: 0.5100306552621398]
	TIME [epoch: 11.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3909656167217717		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.3909656167217717 | validation: 0.4521228948396271]
	TIME [epoch: 11.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43599125682643647		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.43599125682643647 | validation: 0.40991323644520367]
	TIME [epoch: 11.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36087795281122936		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.36087795281122936 | validation: 0.5674539715933511]
	TIME [epoch: 11.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470877538709662		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5470877538709662 | validation: 0.5493505740037483]
	TIME [epoch: 11.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38513663802712694		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.38513663802712694 | validation: 0.4191969958872992]
	TIME [epoch: 11.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3954307764991971		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.3954307764991971 | validation: 0.33620611939492906]
	TIME [epoch: 11.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386419471503391		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.3386419471503391 | validation: 0.5438594353983743]
	TIME [epoch: 11.5 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125920418907032		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.4125920418907032 | validation: 0.3938775798231464]
	TIME [epoch: 11.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3847243193859594		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.3847243193859594 | validation: 0.36814661594211645]
	TIME [epoch: 11.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983140428196634		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.3983140428196634 | validation: 0.535040744681454]
	TIME [epoch: 11.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44096977332472886		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.44096977332472886 | validation: 0.4087783219071703]
	TIME [epoch: 11.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3557529323348565		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.3557529323348565 | validation: 0.4773165779994367]
	TIME [epoch: 11.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40586967147458564		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.40586967147458564 | validation: 0.5292233862506633]
	TIME [epoch: 11.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152965678588858		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4152965678588858 | validation: 0.39398935381397776]
	TIME [epoch: 11.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35139064966895717		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.35139064966895717 | validation: 0.39836771355842965]
	TIME [epoch: 11.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32884852831384864		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.32884852831384864 | validation: 0.42101696951278683]
	TIME [epoch: 11.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879974368172976		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.3879974368172976 | validation: 0.37194186333140056]
	TIME [epoch: 11.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793972523114641		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.3793972523114641 | validation: 0.41938134113693387]
	TIME [epoch: 11.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279554474728344		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.3279554474728344 | validation: 0.4080045015715754]
	TIME [epoch: 11.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333103102584662		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.333103102584662 | validation: 0.3749773747696108]
	TIME [epoch: 11.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3956122236129689		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.3956122236129689 | validation: 0.3202095778388067]
	TIME [epoch: 11.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491528843602776		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.3491528843602776 | validation: 0.44192967724171395]
	TIME [epoch: 11.5 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38086149934758096		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.38086149934758096 | validation: 0.4264738384783066]
	TIME [epoch: 11.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35755919548641923		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.35755919548641923 | validation: 0.35961985456276424]
	TIME [epoch: 11.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3835094615351321		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.3835094615351321 | validation: 0.35050904781778713]
	TIME [epoch: 11.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39092011185628606		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.39092011185628606 | validation: 0.7388127364721788]
	TIME [epoch: 11.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4708301573383005		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4708301573383005 | validation: 0.3391488169037132]
	TIME [epoch: 11.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32890366351048944		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.32890366351048944 | validation: 0.33231526493273267]
	TIME [epoch: 11.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32886041924179343		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.32886041924179343 | validation: 0.4779744361048336]
	TIME [epoch: 11.5 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540472541961811		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.3540472541961811 | validation: 0.35742529695128866]
	TIME [epoch: 11.5 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33755425161880875		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.33755425161880875 | validation: 0.3831590608011677]
	TIME [epoch: 11.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3734554966255643		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.3734554966255643 | validation: 0.4977011168202662]
	TIME [epoch: 11.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3796827437983853		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.3796827437983853 | validation: 0.40395279622406294]
	TIME [epoch: 11.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549883818200118		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.3549883818200118 | validation: 0.4434354114028662]
	TIME [epoch: 11.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908884310121245		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.3908884310121245 | validation: 0.44928114038384986]
	TIME [epoch: 11.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883018256552473		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.3883018256552473 | validation: 0.41887293228174494]
	TIME [epoch: 11.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3727592893587958		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.3727592893587958 | validation: 0.39045437855323856]
	TIME [epoch: 11.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702191954960091		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3702191954960091 | validation: 0.3462895203477626]
	TIME [epoch: 11.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3855673815363212		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.3855673815363212 | validation: 0.31431879557205583]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35172281513110937		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.35172281513110937 | validation: 0.3890542658655177]
	TIME [epoch: 11.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466164488040843		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.3466164488040843 | validation: 0.3800246815795542]
	TIME [epoch: 11.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3232540851856347		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.3232540851856347 | validation: 0.3622292536661347]
	TIME [epoch: 11.5 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3477082281678631		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.3477082281678631 | validation: 0.5221287499213851]
	TIME [epoch: 11.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37525617818768364		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.37525617818768364 | validation: 0.32288570515279474]
	TIME [epoch: 11.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31558557682088345		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.31558557682088345 | validation: 0.3692314571380021]
	TIME [epoch: 11.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3309534296835791		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.3309534296835791 | validation: 0.4273215145382498]
	TIME [epoch: 11.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39033904859582663		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.39033904859582663 | validation: 0.4668524068298239]
	TIME [epoch: 11.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40419250801135115		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.40419250801135115 | validation: 0.44340016817372446]
	TIME [epoch: 11.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38252098364060183		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.38252098364060183 | validation: 0.3792771709938261]
	TIME [epoch: 11.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3600857420567187		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.3600857420567187 | validation: 0.3358496292869803]
	TIME [epoch: 11.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443444820050209		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.3443444820050209 | validation: 0.3387625383792017]
	TIME [epoch: 11.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2964904737182635		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.2964904737182635 | validation: 0.3476754320872512]
	TIME [epoch: 11.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3364592615828387		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.3364592615828387 | validation: 0.37637664945965316]
	TIME [epoch: 11.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185717987003975		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3185717987003975 | validation: 0.4615653229163035]
	TIME [epoch: 11.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44721648075734294		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.44721648075734294 | validation: 0.6292602422690277]
	TIME [epoch: 11.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5090288268492452		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.5090288268492452 | validation: 0.4679159152098144]
	TIME [epoch: 11.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497689100694669		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.3497689100694669 | validation: 0.28084609170067715]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962280035752706		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2962280035752706 | validation: 0.41053182487473394]
	TIME [epoch: 11.5 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38820628570090643		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.38820628570090643 | validation: 0.3147075891233635]
	TIME [epoch: 11.5 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001458307582261		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.3001458307582261 | validation: 0.32121427709606126]
	TIME [epoch: 11.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32671339578901987		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.32671339578901987 | validation: 0.3567968527340995]
	TIME [epoch: 11.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661114766076262		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.3661114766076262 | validation: 0.4444338123890432]
	TIME [epoch: 11.5 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41832940907805866		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.41832940907805866 | validation: 0.35448871313746794]
	TIME [epoch: 11.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36900273321100435		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.36900273321100435 | validation: 0.4763145827164385]
	TIME [epoch: 11.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38285942552755525		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.38285942552755525 | validation: 0.3119809709889955]
	TIME [epoch: 11.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3363187096059007		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.3363187096059007 | validation: 0.3261341662015757]
	TIME [epoch: 11.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35627123334524124		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.35627123334524124 | validation: 0.3224805256891257]
	TIME [epoch: 11.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34242379646271065		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.34242379646271065 | validation: 0.33483162366932734]
	TIME [epoch: 11.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32959983744685006		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.32959983744685006 | validation: 0.31589350454801995]
	TIME [epoch: 11.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472384488562826		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.3472384488562826 | validation: 0.2741286000423924]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_814.pth
	Model improved!!!
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32025688223181703		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.32025688223181703 | validation: 0.31415987293217795]
	TIME [epoch: 11.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072293792335985		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.3072293792335985 | validation: 0.3031020446404664]
	TIME [epoch: 11.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34130977070061486		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.34130977070061486 | validation: 0.3716766164256238]
	TIME [epoch: 11.5 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3784449651988683		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.3784449651988683 | validation: 0.3204694867728625]
	TIME [epoch: 11.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726705273974063		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.3726705273974063 | validation: 0.291907654081278]
	TIME [epoch: 11.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737046675110437		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.3737046675110437 | validation: 0.3434516314768621]
	TIME [epoch: 11.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3556058709839724		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3556058709839724 | validation: 0.2769263531709329]
	TIME [epoch: 11.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501924042290882		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3501924042290882 | validation: 0.31014589960670774]
	TIME [epoch: 11.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3114172432371456		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.3114172432371456 | validation: 0.28178622380853957]
	TIME [epoch: 11.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3651477164571193		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.3651477164571193 | validation: 0.33272884924101975]
	TIME [epoch: 11.5 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3443334450284001		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.3443334450284001 | validation: 0.3347054349170702]
	TIME [epoch: 11.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3246496923738429		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.3246496923738429 | validation: 0.26069135053598724]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3161922876540719		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3161922876540719 | validation: 0.2725944611625646]
	TIME [epoch: 11.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29051888271156506		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.29051888271156506 | validation: 0.30434212648106335]
	TIME [epoch: 11.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933930502260141		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.2933930502260141 | validation: 0.28041746121553246]
	TIME [epoch: 11.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2715093387306888		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2715093387306888 | validation: 0.2653153623303833]
	TIME [epoch: 11.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333949732946794		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.333949732946794 | validation: 0.31548235976550415]
	TIME [epoch: 11.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28851355068404866		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.28851355068404866 | validation: 0.2923929962100961]
	TIME [epoch: 11.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30435655381337856		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.30435655381337856 | validation: 0.2968945274827076]
	TIME [epoch: 11.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32328571809757545		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.32328571809757545 | validation: 0.3117529097013948]
	TIME [epoch: 11.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756632445863853		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2756632445863853 | validation: 0.275797582869206]
	TIME [epoch: 11.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34197464956988977		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.34197464956988977 | validation: 0.43345585778237444]
	TIME [epoch: 11.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2960977653637499		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.2960977653637499 | validation: 0.4191393199295337]
	TIME [epoch: 11.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.331159189868418		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.331159189868418 | validation: 0.28617173470704566]
	TIME [epoch: 11.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30696955953106214		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.30696955953106214 | validation: 0.3787154857313902]
	TIME [epoch: 11.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948738450041764		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.2948738450041764 | validation: 0.3367899066373643]
	TIME [epoch: 11.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29769895694943077		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.29769895694943077 | validation: 0.2704238505605306]
	TIME [epoch: 11.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37801027713707025		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.37801027713707025 | validation: 0.4512277510090331]
	TIME [epoch: 11.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748311573631104		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.3748311573631104 | validation: 0.2997316834489327]
	TIME [epoch: 11.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944168558409289		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.2944168558409289 | validation: 0.28626404876026457]
	TIME [epoch: 11.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30129896219088437		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.30129896219088437 | validation: 0.40012211179080653]
	TIME [epoch: 11.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3484587999046231		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.3484587999046231 | validation: 0.32037458739703584]
	TIME [epoch: 11.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28551529975130957		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.28551529975130957 | validation: 0.307830654288078]
	TIME [epoch: 11.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29420039619850724		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.29420039619850724 | validation: 0.298057853623024]
	TIME [epoch: 11.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29325709774276654		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.29325709774276654 | validation: 0.31740492817733096]
	TIME [epoch: 11.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31287162692928816		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.31287162692928816 | validation: 0.3625352211796517]
	TIME [epoch: 11.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30955661332853185		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.30955661332853185 | validation: 0.26155943680553084]
	TIME [epoch: 11.5 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28877479756656066		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.28877479756656066 | validation: 0.2712075984265351]
	TIME [epoch: 11.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641834688465205		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2641834688465205 | validation: 0.31986831972278973]
	TIME [epoch: 11.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31042460710746356		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.31042460710746356 | validation: 0.3222848749674822]
	TIME [epoch: 11.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3050148687213079		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.3050148687213079 | validation: 0.30981710135455953]
	TIME [epoch: 11.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33066231990091943		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.33066231990091943 | validation: 0.3344519093420648]
	TIME [epoch: 11.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32447608024625285		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.32447608024625285 | validation: 0.3044877728474232]
	TIME [epoch: 11.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893423428904191		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.2893423428904191 | validation: 0.2763110783471261]
	TIME [epoch: 11.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2946799728947552		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.2946799728947552 | validation: 0.2773602141479962]
	TIME [epoch: 11.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766065996651521		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.2766065996651521 | validation: 0.24815978395960095]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2912110019543959		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.2912110019543959 | validation: 0.3294191086416815]
	TIME [epoch: 11.5 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29621708162678323		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.29621708162678323 | validation: 0.270889462398785]
	TIME [epoch: 11.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913233527915058		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.2913233527915058 | validation: 0.26885483588978026]
	TIME [epoch: 11.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778097523527127		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.2778097523527127 | validation: 0.26985077428254045]
	TIME [epoch: 11.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29988891329214623		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.29988891329214623 | validation: 0.24979554445785898]
	TIME [epoch: 11.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27235667990631685		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.27235667990631685 | validation: 0.3145036384092759]
	TIME [epoch: 11.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31261873945197377		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.31261873945197377 | validation: 0.2695426722682602]
	TIME [epoch: 11.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008801320606957		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.3008801320606957 | validation: 0.2644443380784911]
	TIME [epoch: 11.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30101110547222887		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.30101110547222887 | validation: 0.24476468412892488]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_869.pth
	Model improved!!!
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27755486690021286		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.27755486690021286 | validation: 0.28735810682658397]
	TIME [epoch: 11.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28616436935116857		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.28616436935116857 | validation: 0.22780655490440432]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_871.pth
	Model improved!!!
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2948019391663699		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2948019391663699 | validation: 0.23599996521360753]
	TIME [epoch: 11.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103291522313328		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.3103291522313328 | validation: 0.24180335529192648]
	TIME [epoch: 11.5 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2981955010028891		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2981955010028891 | validation: 0.311152340501096]
	TIME [epoch: 11.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32900136919367196		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.32900136919367196 | validation: 0.31896977359987083]
	TIME [epoch: 11.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136464037101854		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.3136464037101854 | validation: 0.2531785620588591]
	TIME [epoch: 11.5 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28566767886029004		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.28566767886029004 | validation: 0.29687365688151657]
	TIME [epoch: 11.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3118667787975599		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.3118667787975599 | validation: 0.3050917180668112]
	TIME [epoch: 11.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28575769457956135		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.28575769457956135 | validation: 0.26144949491881697]
	TIME [epoch: 11.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26544757678856673		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.26544757678856673 | validation: 0.24805412170684293]
	TIME [epoch: 11.5 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3068534500424307		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.3068534500424307 | validation: 0.2874381135544758]
	TIME [epoch: 11.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094378420908609		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.3094378420908609 | validation: 0.32881782759478834]
	TIME [epoch: 11.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29324849538672426		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.29324849538672426 | validation: 0.27896076373830325]
	TIME [epoch: 11.5 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2987982406808273		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.2987982406808273 | validation: 0.2539296394990162]
	TIME [epoch: 11.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703936983878852		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.2703936983878852 | validation: 0.2437994370010398]
	TIME [epoch: 11.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3053038244852387		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.3053038244852387 | validation: 0.3268184332613774]
	TIME [epoch: 11.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3394042711362676		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.3394042711362676 | validation: 0.29426574310255177]
	TIME [epoch: 11.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2809791596644726		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.2809791596644726 | validation: 0.2592652989941741]
	TIME [epoch: 11.5 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814000921136713		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.2814000921136713 | validation: 0.2679902709285545]
	TIME [epoch: 11.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686036537202041		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.2686036537202041 | validation: 0.257313784782447]
	TIME [epoch: 11.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29602391211929346		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.29602391211929346 | validation: 0.24238952270648573]
	TIME [epoch: 11.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676227959337766		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2676227959337766 | validation: 0.2799361871002731]
	TIME [epoch: 11.5 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32209655781754315		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.32209655781754315 | validation: 0.32114334302492936]
	TIME [epoch: 11.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30007772655682174		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.30007772655682174 | validation: 0.3639477271559081]
	TIME [epoch: 11.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086669978317073		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.3086669978317073 | validation: 0.30161375533719764]
	TIME [epoch: 11.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29503024271821665		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.29503024271821665 | validation: 0.3223435854765344]
	TIME [epoch: 11.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32530953262341056		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.32530953262341056 | validation: 0.3216553742681201]
	TIME [epoch: 11.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3205816123129628		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.3205816123129628 | validation: 0.29040075163894213]
	TIME [epoch: 11.5 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29223390619117096		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.29223390619117096 | validation: 0.268990838271852]
	TIME [epoch: 11.5 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011900830309486		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.3011900830309486 | validation: 0.3801019492791066]
	TIME [epoch: 11.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3236344615207971		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.3236344615207971 | validation: 0.23848168542168033]
	TIME [epoch: 11.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2769130619133311		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.2769130619133311 | validation: 0.2493568542365164]
	TIME [epoch: 11.5 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784020778903087		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.2784020778903087 | validation: 0.266633488427194]
	TIME [epoch: 11.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2761012118356921		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.2761012118356921 | validation: 0.3010057032008588]
	TIME [epoch: 11.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003301780520906		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.3003301780520906 | validation: 0.27906758606744797]
	TIME [epoch: 11.5 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29906276647098645		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.29906276647098645 | validation: 0.2659969895226145]
	TIME [epoch: 11.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613608519082682		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.2613608519082682 | validation: 0.2484596662100331]
	TIME [epoch: 11.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270268562275345		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.270268562275345 | validation: 0.2809103915217155]
	TIME [epoch: 11.5 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951339959078519		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.2951339959078519 | validation: 0.28416999175963736]
	TIME [epoch: 11.5 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3142893459390603		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.3142893459390603 | validation: 0.3511527732108934]
	TIME [epoch: 11.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3239131631713182		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.3239131631713182 | validation: 0.3290454533737217]
	TIME [epoch: 11.5 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3107817887890747		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.3107817887890747 | validation: 0.30265020644922597]
	TIME [epoch: 11.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29342754575713736		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.29342754575713736 | validation: 0.3108005815987286]
	TIME [epoch: 11.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31111308532436976		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.31111308532436976 | validation: 0.2738501800279559]
	TIME [epoch: 11.5 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2938061527162517		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.2938061527162517 | validation: 0.4113767196672166]
	TIME [epoch: 11.5 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30872248912283906		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.30872248912283906 | validation: 0.270965225026306]
	TIME [epoch: 11.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.332902768175929		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.332902768175929 | validation: 0.31760078513134227]
	TIME [epoch: 11.5 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3122242974847527		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.3122242974847527 | validation: 0.2933866468032442]
	TIME [epoch: 11.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29119024124863524		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.29119024124863524 | validation: 0.3494431311094823]
	TIME [epoch: 11.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27241436102799205		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.27241436102799205 | validation: 0.31326275995652253]
	TIME [epoch: 11.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823053216181808		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.2823053216181808 | validation: 0.28016203649067023]
	TIME [epoch: 11.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729283402121044		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.2729283402121044 | validation: 0.27154663906154375]
	TIME [epoch: 11.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28401403044689016		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.28401403044689016 | validation: 0.3866836605439606]
	TIME [epoch: 11.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972898427726707		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.2972898427726707 | validation: 0.3043423694940391]
	TIME [epoch: 11.5 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645876000435521		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.2645876000435521 | validation: 0.270717592115282]
	TIME [epoch: 11.5 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760743938257697		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.2760743938257697 | validation: 0.2883214670445216]
	TIME [epoch: 11.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28755871901048435		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.28755871901048435 | validation: 0.28287633497800396]
	TIME [epoch: 11.5 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837675770110134		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.2837675770110134 | validation: 0.32601004124992616]
	TIME [epoch: 11.5 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041904382114432		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.3041904382114432 | validation: 0.33202469113462757]
	TIME [epoch: 11.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3095340444149187		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.3095340444149187 | validation: 0.27050996078696754]
	TIME [epoch: 11.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3024057200614724		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.3024057200614724 | validation: 0.3345509077946641]
	TIME [epoch: 11.5 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28314889289062395		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.28314889289062395 | validation: 0.25630631187473746]
	TIME [epoch: 11.5 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614993909607974		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.2614993909607974 | validation: 0.285767331781457]
	TIME [epoch: 11.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640048414081083		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2640048414081083 | validation: 0.24565952800334237]
	TIME [epoch: 11.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011727320546588		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.3011727320546588 | validation: 0.28628262006822464]
	TIME [epoch: 11.5 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824458633099208		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.2824458633099208 | validation: 0.27454654166609943]
	TIME [epoch: 11.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29532113750374805		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.29532113750374805 | validation: 0.24906426873552887]
	TIME [epoch: 11.5 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26483068981083774		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.26483068981083774 | validation: 0.24975400022066985]
	TIME [epoch: 11.5 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27231154241307537		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.27231154241307537 | validation: 0.2706162361638305]
	TIME [epoch: 11.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640394655867974		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.2640394655867974 | validation: 0.2471327971683719]
	TIME [epoch: 11.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28416237550813234		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.28416237550813234 | validation: 0.2822338533826245]
	TIME [epoch: 11.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614595050240632		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.2614595050240632 | validation: 0.28147457631631734]
	TIME [epoch: 11.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25635122344019656		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.25635122344019656 | validation: 0.30581378967763984]
	TIME [epoch: 11.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29156183476788683		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.29156183476788683 | validation: 0.24884892377827875]
	TIME [epoch: 11.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.269974243858964		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.269974243858964 | validation: 0.2298761702437797]
	TIME [epoch: 11.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24989325159474648		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.24989325159474648 | validation: 0.25590242791542345]
	TIME [epoch: 11.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25576688927469143		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.25576688927469143 | validation: 0.2712178201589949]
	TIME [epoch: 11.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.295414027115437		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.295414027115437 | validation: 0.25964666366271716]
	TIME [epoch: 11.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723972224710819		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.2723972224710819 | validation: 0.3902777720572061]
	TIME [epoch: 11.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3117161027815846		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3117161027815846 | validation: 0.23994278789734072]
	TIME [epoch: 11.5 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629781919414148		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.2629781919414148 | validation: 0.35286653232630744]
	TIME [epoch: 11.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958302396174047		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.2958302396174047 | validation: 0.24297884674104325]
	TIME [epoch: 11.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25616091971703564		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.25616091971703564 | validation: 0.229038958991567]
	TIME [epoch: 11.5 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793165806187508		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.2793165806187508 | validation: 0.3325243469584799]
	TIME [epoch: 11.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3245084924291467		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.3245084924291467 | validation: 0.37700601985921384]
	TIME [epoch: 11.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38048558309405744		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.38048558309405744 | validation: 0.3097726997288215]
	TIME [epoch: 11.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27591948733006383		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.27591948733006383 | validation: 0.2592355361897735]
	TIME [epoch: 11.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789354421820367		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.2789354421820367 | validation: 0.23603412026046794]
	TIME [epoch: 11.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629524675908472		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2629524675908472 | validation: 0.2747682526359637]
	TIME [epoch: 11.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711455802171385		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.2711455802171385 | validation: 0.2361046348462677]
	TIME [epoch: 11.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24680678211528823		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.24680678211528823 | validation: 0.2893687722473517]
	TIME [epoch: 11.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24718382760855354		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.24718382760855354 | validation: 0.20866231236033395]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_962.pth
	Model improved!!!
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29057809423249586		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.29057809423249586 | validation: 0.26556524559161054]
	TIME [epoch: 11.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939767646843521		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.2939767646843521 | validation: 0.22774731671845186]
	TIME [epoch: 11.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2988886734585119		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.2988886734585119 | validation: 0.22232980326732993]
	TIME [epoch: 11.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25632794153405836		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.25632794153405836 | validation: 0.21892305265033699]
	TIME [epoch: 11.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531976076248094		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.2531976076248094 | validation: 0.23516623621155233]
	TIME [epoch: 11.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501886166597346		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.2501886166597346 | validation: 0.23119328878713455]
	TIME [epoch: 11.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2539825086823231		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.2539825086823231 | validation: 0.2281204538006125]
	TIME [epoch: 11.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2701393888069689		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.2701393888069689 | validation: 0.31843812550068623]
	TIME [epoch: 11.5 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28009758374501437		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.28009758374501437 | validation: 0.22795617429403414]
	TIME [epoch: 11.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2928099608639436		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2928099608639436 | validation: 0.34248820140935016]
	TIME [epoch: 11.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33195100690318136		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.33195100690318136 | validation: 0.26405482022058346]
	TIME [epoch: 11.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27900638567515423		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.27900638567515423 | validation: 0.2788548538362824]
	TIME [epoch: 11.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26497600803957233		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.26497600803957233 | validation: 0.23343484234433035]
	TIME [epoch: 11.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24966965461991886		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.24966965461991886 | validation: 0.27483353044992603]
	TIME [epoch: 11.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707821466953587		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.2707821466953587 | validation: 0.21490232156232913]
	TIME [epoch: 11.5 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28330275305943303		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.28330275305943303 | validation: 0.2549423507481857]
	TIME [epoch: 11.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922014400318077		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.2922014400318077 | validation: 0.2760925800397528]
	TIME [epoch: 11.5 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734142377065888		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.2734142377065888 | validation: 0.25587067325308627]
	TIME [epoch: 11.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27833601818055764		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.27833601818055764 | validation: 0.26068831658229236]
	TIME [epoch: 11.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30217302383598377		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.30217302383598377 | validation: 0.2511977400856243]
	TIME [epoch: 11.5 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26920123880251934		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.26920123880251934 | validation: 0.2363836889384045]
	TIME [epoch: 11.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510031012443718		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.2510031012443718 | validation: 0.22437376568627224]
	TIME [epoch: 11.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711454649980088		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.2711454649980088 | validation: 0.23184787634789814]
	TIME [epoch: 11.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798071980483764		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.2798071980483764 | validation: 0.25805349213149287]
	TIME [epoch: 11.5 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27513880002278274		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.27513880002278274 | validation: 0.2760993615865519]
	TIME [epoch: 11.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29496372484353384		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.29496372484353384 | validation: 0.2417888182093496]
	TIME [epoch: 11.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823457823523673		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2823457823523673 | validation: 0.3588708261526683]
	TIME [epoch: 11.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2992545166573623		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.2992545166573623 | validation: 0.27236630521962146]
	TIME [epoch: 11.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28815684595082075		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.28815684595082075 | validation: 0.28652714830200976]
	TIME [epoch: 11.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566312738062384		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.2566312738062384 | validation: 0.23726793149363193]
	TIME [epoch: 11.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23943543953549146		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.23943543953549146 | validation: 0.20916584597791882]
	TIME [epoch: 11.5 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23728158905964522		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.23728158905964522 | validation: 0.21540418671968092]
	TIME [epoch: 11.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2421480571132631		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2421480571132631 | validation: 0.227752934915769]
	TIME [epoch: 11.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23764157634933522		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.23764157634933522 | validation: 0.22859917456705675]
	TIME [epoch: 11.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23870178634511413		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.23870178634511413 | validation: 0.23726353820404605]
	TIME [epoch: 11.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25621143646428657		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.25621143646428657 | validation: 0.2625912050628985]
	TIME [epoch: 11.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619902688112271		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.2619902688112271 | validation: 0.21974347697838806]
	TIME [epoch: 11.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26260354670090935		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.26260354670090935 | validation: 0.22010338985506878]
	TIME [epoch: 11.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600454526896398		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.2600454526896398 | validation: 0.23529003689653408]
	TIME [epoch: 11.6 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26935447663167367		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.26935447663167367 | validation: 0.2893885600682561]
	TIME [epoch: 11.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650463922483681		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.2650463922483681 | validation: 0.22314539653888146]
	TIME [epoch: 11.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26508045773451944		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.26508045773451944 | validation: 0.21311383086826274]
	TIME [epoch: 11.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24858217669432275		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.24858217669432275 | validation: 0.2402310725173811]
	TIME [epoch: 11.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523912982493272		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.2523912982493272 | validation: 0.20917774840589395]
	TIME [epoch: 11.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721189576068037		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2721189576068037 | validation: 0.25110411526908755]
	TIME [epoch: 11.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103313600300234		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.3103313600300234 | validation: 0.26772832280456005]
	TIME [epoch: 11.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708448921219183		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.2708448921219183 | validation: 0.2575536585636439]
	TIME [epoch: 11.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26289863445444467		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.26289863445444467 | validation: 0.2366958372936834]
	TIME [epoch: 11.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664325275268744		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.2664325275268744 | validation: 0.23640735951498845]
	TIME [epoch: 11.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217543127297275		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.24217543127297275 | validation: 0.24245586855023551]
	TIME [epoch: 11.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24430325237011857		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.24430325237011857 | validation: 0.23991118521256355]
	TIME [epoch: 11.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872723089997956		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.2872723089997956 | validation: 0.2128510281491816]
	TIME [epoch: 11.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2645115661377901		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.2645115661377901 | validation: 0.20587809808716653]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1015.pth
	Model improved!!!
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24291815932171656		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.24291815932171656 | validation: 0.26735281191000154]
	TIME [epoch: 11.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529954736216063		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.2529954736216063 | validation: 0.21639245532284243]
	TIME [epoch: 11.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25020099367783605		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.25020099367783605 | validation: 0.2776929398750691]
	TIME [epoch: 11.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27715528450675625		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.27715528450675625 | validation: 0.28023641863911036]
	TIME [epoch: 11.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2707771588552416		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.2707771588552416 | validation: 0.23549306431687314]
	TIME [epoch: 11.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26349612010841106		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.26349612010841106 | validation: 0.2360927917718565]
	TIME [epoch: 11.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23921876181244273		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.23921876181244273 | validation: 0.2002564766165841]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1022.pth
	Model improved!!!
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23612437016603682		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.23612437016603682 | validation: 0.2211485269283488]
	TIME [epoch: 11.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621484198449916		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.2621484198449916 | validation: 0.20691735087497784]
	TIME [epoch: 11.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558805358513031		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.2558805358513031 | validation: 0.22386289224919143]
	TIME [epoch: 11.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24993920557398558		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.24993920557398558 | validation: 0.2645035230229483]
	TIME [epoch: 11.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852460332201825		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.2852460332201825 | validation: 0.33633662008892684]
	TIME [epoch: 11.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3032768250277002		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3032768250277002 | validation: 0.25098312489239133]
	TIME [epoch: 11.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31189363344548127		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.31189363344548127 | validation: 0.23730525760922777]
	TIME [epoch: 11.6 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729499618340395		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.2729499618340395 | validation: 0.23691247722945202]
	TIME [epoch: 11.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505275609071629		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.2505275609071629 | validation: 0.25369904446883]
	TIME [epoch: 11.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544467321226291		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.2544467321226291 | validation: 0.23934745181684924]
	TIME [epoch: 11.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499687274568747		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.2499687274568747 | validation: 0.20390351777350638]
	TIME [epoch: 11.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.250720240057754		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.250720240057754 | validation: 0.26801077972083454]
	TIME [epoch: 11.5 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2490469768204311		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.2490469768204311 | validation: 0.2463070790948237]
	TIME [epoch: 11.5 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2420007048676731		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.2420007048676731 | validation: 0.270116421920375]
	TIME [epoch: 11.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544929028761481		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.2544929028761481 | validation: 0.23712830292332993]
	TIME [epoch: 11.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2451013901804469		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.2451013901804469 | validation: 0.24383899342462279]
	TIME [epoch: 11.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25013913490646494		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.25013913490646494 | validation: 0.21945035768864138]
	TIME [epoch: 11.6 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23031925653272178		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.23031925653272178 | validation: 0.21094165144816057]
	TIME [epoch: 11.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22931399451312834		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.22931399451312834 | validation: 0.24615504724815487]
	TIME [epoch: 11.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365731278318228		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.2365731278318228 | validation: 0.24067572000842052]
	TIME [epoch: 11.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2479740273305195		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2479740273305195 | validation: 0.28004966932326497]
	TIME [epoch: 11.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547470926104356		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.2547470926104356 | validation: 0.23287077674638784]
	TIME [epoch: 11.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24727106000788818		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.24727106000788818 | validation: 0.220184687422376]
	TIME [epoch: 11.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396582053483099		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.2396582053483099 | validation: 0.2506246333764095]
	TIME [epoch: 11.5 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2630937833420715		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.2630937833420715 | validation: 0.27448464381362064]
	TIME [epoch: 11.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24050219752172872		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.24050219752172872 | validation: 0.21197462487587232]
	TIME [epoch: 11.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235559673863542		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.235559673863542 | validation: 0.23796568099836662]
	TIME [epoch: 11.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2638249386525187		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.2638249386525187 | validation: 0.26602946719630605]
	TIME [epoch: 11.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257079058780965		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.257079058780965 | validation: 0.19307044678233656]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1051.pth
	Model improved!!!
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25228922476987964		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.25228922476987964 | validation: 0.22120557917778982]
	TIME [epoch: 11.6 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23526303686086927		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.23526303686086927 | validation: 0.22169276333085525]
	TIME [epoch: 11.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2353570086221655		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.2353570086221655 | validation: 0.27762254215970544]
	TIME [epoch: 11.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24953929983418313		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.24953929983418313 | validation: 0.2833579993375388]
	TIME [epoch: 11.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26307278616895075		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.26307278616895075 | validation: 0.2400089726086479]
	TIME [epoch: 11.6 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571430123866791		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.2571430123866791 | validation: 0.29913742159147844]
	TIME [epoch: 11.6 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25749216914920303		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.25749216914920303 | validation: 0.2378384789141151]
	TIME [epoch: 11.6 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2453841392653322		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.2453841392653322 | validation: 0.2303215922004139]
	TIME [epoch: 11.6 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24864918913645834		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.24864918913645834 | validation: 0.26028522500157797]
	TIME [epoch: 11.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639899536799287		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.2639899536799287 | validation: 0.2472525002634198]
	TIME [epoch: 11.6 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515648380907458		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.2515648380907458 | validation: 0.2687288739019972]
	TIME [epoch: 11.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25043546394122196		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.25043546394122196 | validation: 0.2067279388950631]
	TIME [epoch: 11.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23877639519837235		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.23877639519837235 | validation: 0.21576622849163918]
	TIME [epoch: 11.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24859385103782572		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.24859385103782572 | validation: 0.21528089512165616]
	TIME [epoch: 11.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267403590807556		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.2267403590807556 | validation: 0.2063770937671847]
	TIME [epoch: 11.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24466027057638423		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.24466027057638423 | validation: 0.19728826092508903]
	TIME [epoch: 11.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23291909914475828		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.23291909914475828 | validation: 0.2374735550214389]
	TIME [epoch: 11.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24815113255570104		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.24815113255570104 | validation: 0.23694943729459667]
	TIME [epoch: 11.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24544718993096587		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.24544718993096587 | validation: 0.22524355393494194]
	TIME [epoch: 11.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468315833608855		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2468315833608855 | validation: 0.20157098705961943]
	TIME [epoch: 11.6 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22929218363163714		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.22929218363163714 | validation: 0.19783118477396522]
	TIME [epoch: 11.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2296260838863921		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.2296260838863921 | validation: 0.23322058531738016]
	TIME [epoch: 11.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2363792337308382		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.2363792337308382 | validation: 0.2555098318012329]
	TIME [epoch: 11.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24251402420526458		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.24251402420526458 | validation: 0.25533647004925886]
	TIME [epoch: 11.6 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24076115052819774		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.24076115052819774 | validation: 0.2123563657710689]
	TIME [epoch: 11.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23716010546817382		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.23716010546817382 | validation: 0.2228175188110394]
	TIME [epoch: 11.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23796001425877636		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.23796001425877636 | validation: 0.21630228486635253]
	TIME [epoch: 11.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25118310220824996		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.25118310220824996 | validation: 0.2528965745188393]
	TIME [epoch: 11.6 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515038293215145		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.2515038293215145 | validation: 0.21282676212008939]
	TIME [epoch: 11.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23713708730383384		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.23713708730383384 | validation: 0.26394322156984495]
	TIME [epoch: 11.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2437320394589903		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2437320394589903 | validation: 0.25391135357490635]
	TIME [epoch: 11.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24025166104723164		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.24025166104723164 | validation: 0.2422647548143618]
	TIME [epoch: 11.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23383127458550684		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.23383127458550684 | validation: 0.26786970134837396]
	TIME [epoch: 11.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26450203283933116		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.26450203283933116 | validation: 0.28201367654264814]
	TIME [epoch: 11.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.241633108896527		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.241633108896527 | validation: 0.2766675726951376]
	TIME [epoch: 11.6 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25872366723436985		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.25872366723436985 | validation: 0.2610764877430699]
	TIME [epoch: 11.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27513398631189034		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.27513398631189034 | validation: 0.2779684431539459]
	TIME [epoch: 11.6 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259170445266915		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.259170445266915 | validation: 0.20768108942812177]
	TIME [epoch: 11.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524932180682899		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.2524932180682899 | validation: 0.22426753013366338]
	TIME [epoch: 11.6 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24429093169928856		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.24429093169928856 | validation: 0.22859352016485981]
	TIME [epoch: 11.6 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24231640359006726		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.24231640359006726 | validation: 0.24637635839106278]
	TIME [epoch: 11.6 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569556397103236		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.2569556397103236 | validation: 0.23895801312100834]
	TIME [epoch: 11.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251732700906182		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.251732700906182 | validation: 0.2259019069872072]
	TIME [epoch: 11.6 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24107044646476739		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.24107044646476739 | validation: 0.25128712687521715]
	TIME [epoch: 11.6 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543709373953329		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.2543709373953329 | validation: 0.27493509607005456]
	TIME [epoch: 11.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2665961482275183		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.2665961482275183 | validation: 0.29365629365777296]
	TIME [epoch: 11.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259118439630925		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.259118439630925 | validation: 0.246976893138317]
	TIME [epoch: 11.6 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2631934321274908		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.2631934321274908 | validation: 0.2791006856528573]
	TIME [epoch: 11.6 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27433501156667717		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.27433501156667717 | validation: 0.2865612284799817]
	TIME [epoch: 11.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270978567968518		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.270978567968518 | validation: 0.2717074414318338]
	TIME [epoch: 11.6 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25907184127468524		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.25907184127468524 | validation: 0.21909142844176066]
	TIME [epoch: 11.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23553572040360451		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.23553572040360451 | validation: 0.22004532369287574]
	TIME [epoch: 11.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391196492763316		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.2391196492763316 | validation: 0.23308543293938477]
	TIME [epoch: 11.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27666499899745456		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.27666499899745456 | validation: 0.25480085928190976]
	TIME [epoch: 11.6 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2722153696753364		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.2722153696753364 | validation: 0.31176660550598256]
	TIME [epoch: 11.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2608794167396885		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.2608794167396885 | validation: 0.2481686346601361]
	TIME [epoch: 11.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2432117126928256		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.2432117126928256 | validation: 0.2475449382872796]
	TIME [epoch: 11.6 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26457503597738036		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.26457503597738036 | validation: 0.30058733365671264]
	TIME [epoch: 11.6 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.251682347453497		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.251682347453497 | validation: 0.26325070094524305]
	TIME [epoch: 11.6 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25109919370150807		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.25109919370150807 | validation: 0.24825118176747943]
	TIME [epoch: 11.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24392652133092818		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.24392652133092818 | validation: 0.22405114180717772]
	TIME [epoch: 11.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24462801400111578		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.24462801400111578 | validation: 0.27217528145266295]
	TIME [epoch: 11.6 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801887935160646		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.2801887935160646 | validation: 0.2595417901749151]
	TIME [epoch: 11.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2571694946942586		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2571694946942586 | validation: 0.23789722526908713]
	TIME [epoch: 11.6 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24873134096056504		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.24873134096056504 | validation: 0.20175958884719106]
	TIME [epoch: 11.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24785845283642707		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.24785845283642707 | validation: 0.2683345699180442]
	TIME [epoch: 11.6 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2735345007752907		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.2735345007752907 | validation: 0.25567968706603716]
	TIME [epoch: 11.6 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543675111376115		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.2543675111376115 | validation: 0.21329258146400734]
	TIME [epoch: 11.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22858902289755265		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.22858902289755265 | validation: 0.20679080283457915]
	TIME [epoch: 11.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22188738808155006		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.22188738808155006 | validation: 0.21414097952758393]
	TIME [epoch: 11.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24143300300207046		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.24143300300207046 | validation: 0.21756317745682047]
	TIME [epoch: 11.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298725326417955		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.2298725326417955 | validation: 0.2085085432665885]
	TIME [epoch: 11.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280128019473019		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.2280128019473019 | validation: 0.20472070266475625]
	TIME [epoch: 11.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23489823161684464		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.23489823161684464 | validation: 0.20237280252674048]
	TIME [epoch: 11.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22207662260053126		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.22207662260053126 | validation: 0.21784806433477621]
	TIME [epoch: 11.6 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319629418683228		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.2319629418683228 | validation: 0.23895797005237118]
	TIME [epoch: 11.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305801494403352		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.2305801494403352 | validation: 0.21909022107269757]
	TIME [epoch: 11.6 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24495251295640783		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.24495251295640783 | validation: 0.2576270001867452]
	TIME [epoch: 11.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23570419276490875		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.23570419276490875 | validation: 0.26740011062623886]
	TIME [epoch: 11.6 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549880027901563		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.2549880027901563 | validation: 0.3021107197435175]
	TIME [epoch: 11.6 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29760076923078127		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.29760076923078127 | validation: 0.2417370116906734]
	TIME [epoch: 11.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2401557637419832		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.2401557637419832 | validation: 0.2246428648430913]
	TIME [epoch: 11.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294966603315466		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.2294966603315466 | validation: 0.20730251543810332]
	TIME [epoch: 11.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23178985552148246		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.23178985552148246 | validation: 0.20645543982239162]
	TIME [epoch: 11.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24026800772920878		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.24026800772920878 | validation: 0.23907646502254984]
	TIME [epoch: 11.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2405666338183302		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.2405666338183302 | validation: 0.20818492656705442]
	TIME [epoch: 11.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24074463452283698		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.24074463452283698 | validation: 0.22581542884975492]
	TIME [epoch: 11.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24537981805012354		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.24537981805012354 | validation: 0.1874902138783392]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1139.pth
	Model improved!!!
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22644311507425863		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.22644311507425863 | validation: 0.2248103397792088]
	TIME [epoch: 11.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24392332646044984		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.24392332646044984 | validation: 0.22673872782961194]
	TIME [epoch: 11.6 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2613933528254624		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.2613933528254624 | validation: 0.2589622402204409]
	TIME [epoch: 11.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622605547077542		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.2622605547077542 | validation: 0.2283126726324626]
	TIME [epoch: 11.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2775678532673952		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.2775678532673952 | validation: 0.2440681738530924]
	TIME [epoch: 11.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2758491665368331		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.2758491665368331 | validation: 0.24707498093376765]
	TIME [epoch: 11.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24450807796207652		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.24450807796207652 | validation: 0.2301361942798332]
	TIME [epoch: 11.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23322441306079963		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.23322441306079963 | validation: 0.22443524245937915]
	TIME [epoch: 11.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2352637122299958		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.2352637122299958 | validation: 0.21079276721843077]
	TIME [epoch: 11.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304827206541143		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.2304827206541143 | validation: 0.20406146684139992]
	TIME [epoch: 11.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21440778167947075		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.21440778167947075 | validation: 0.21199421459806508]
	TIME [epoch: 11.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2288598033426796		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.2288598033426796 | validation: 0.22973962671245232]
	TIME [epoch: 11.6 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2262247902424005		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.2262247902424005 | validation: 0.20453535773103393]
	TIME [epoch: 11.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23549171298488852		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.23549171298488852 | validation: 0.21983373046492624]
	TIME [epoch: 11.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23102652231171625		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.23102652231171625 | validation: 0.1974683453748277]
	TIME [epoch: 11.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22767538871520313		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.22767538871520313 | validation: 0.25348748585126357]
	TIME [epoch: 11.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553153502967445		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.2553153502967445 | validation: 0.23846321260981843]
	TIME [epoch: 11.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.242015477827085		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.242015477827085 | validation: 0.22972431172428756]
	TIME [epoch: 11.6 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24931812680060156		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.24931812680060156 | validation: 0.2705211446841886]
	TIME [epoch: 11.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504916381550697		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.2504916381550697 | validation: 0.2605197787303566]
	TIME [epoch: 11.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23580769606571272		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.23580769606571272 | validation: 0.2547280212511291]
	TIME [epoch: 11.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26275004742017405		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.26275004742017405 | validation: 0.21338419070418213]
	TIME [epoch: 11.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23202330616380706		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.23202330616380706 | validation: 0.28581582839361125]
	TIME [epoch: 11.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26248113576562443		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.26248113576562443 | validation: 0.23024035089060835]
	TIME [epoch: 11.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24815069907800485		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.24815069907800485 | validation: 0.24419048935205048]
	TIME [epoch: 11.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647828833814379		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.2647828833814379 | validation: 0.21544655381593797]
	TIME [epoch: 11.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24008509333593744		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.24008509333593744 | validation: 0.19602708941663274]
	TIME [epoch: 11.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22735672411850236		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.22735672411850236 | validation: 0.21318137077088659]
	TIME [epoch: 11.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22052892872372293		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.22052892872372293 | validation: 0.21945820775314873]
	TIME [epoch: 11.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22172653588443983		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.22172653588443983 | validation: 0.20252572414506506]
	TIME [epoch: 11.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22648859352603865		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.22648859352603865 | validation: 0.2502178999892267]
	TIME [epoch: 11.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25309168363592144		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.25309168363592144 | validation: 0.24010354693914024]
	TIME [epoch: 11.6 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434515450535039		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.2434515450535039 | validation: 0.22015123117565258]
	TIME [epoch: 11.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22918955609381989		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.22918955609381989 | validation: 0.21325974180180451]
	TIME [epoch: 11.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23542476089493183		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.23542476089493183 | validation: 0.19661310992239514]
	TIME [epoch: 11.6 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22906534963454975		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.22906534963454975 | validation: 0.2099880743595559]
	TIME [epoch: 11.6 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22596405874010322		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.22596405874010322 | validation: 0.22534920157813837]
	TIME [epoch: 11.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23608367427179877		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.23608367427179877 | validation: 0.22525635972156374]
	TIME [epoch: 11.6 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23862080608230168		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.23862080608230168 | validation: 0.20314728142437247]
	TIME [epoch: 11.6 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22519960049607562		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.22519960049607562 | validation: 0.18839150574163796]
	TIME [epoch: 11.6 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23157733569029088		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.23157733569029088 | validation: 0.22201787183991906]
	TIME [epoch: 11.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23465408891851453		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.23465408891851453 | validation: 0.23138254653570683]
	TIME [epoch: 11.6 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23592512640434615		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.23592512640434615 | validation: 0.22539863617626094]
	TIME [epoch: 11.6 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24195646601873344		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.24195646601873344 | validation: 0.22632732897268276]
	TIME [epoch: 11.6 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22787142651829737		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.22787142651829737 | validation: 0.2150885762137834]
	TIME [epoch: 11.6 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22293000178324424		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.22293000178324424 | validation: 0.20635954381409938]
	TIME [epoch: 11.6 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22273943892435447		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.22273943892435447 | validation: 0.2044340806476426]
	TIME [epoch: 11.6 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22428796827082428		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.22428796827082428 | validation: 0.18853961517217382]
	TIME [epoch: 11.6 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2165661812319502		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.2165661812319502 | validation: 0.1980841028961843]
	TIME [epoch: 11.6 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21234908252703566		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.21234908252703566 | validation: 0.18253544180457973]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1189.pth
	Model improved!!!
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2186959616833913		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.2186959616833913 | validation: 0.19674461008697847]
	TIME [epoch: 11.6 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22197982301860653		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.22197982301860653 | validation: 0.20927915893478444]
	TIME [epoch: 11.5 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22263791021583904		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.22263791021583904 | validation: 0.2249349321587964]
	TIME [epoch: 11.6 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22728968416452133		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.22728968416452133 | validation: 0.20248664084039583]
	TIME [epoch: 11.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24638862077493628		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.24638862077493628 | validation: 0.19335080722476988]
	TIME [epoch: 11.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23102070820051754		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.23102070820051754 | validation: 0.21013780759278192]
	TIME [epoch: 11.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22814495351452646		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.22814495351452646 | validation: 0.21058333336699858]
	TIME [epoch: 11.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24141994216659313		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.24141994216659313 | validation: 0.18200755698037202]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1197.pth
	Model improved!!!
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22331512948874785		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.22331512948874785 | validation: 0.2087638332456406]
	TIME [epoch: 11.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22916919657453239		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.22916919657453239 | validation: 0.18233540377040178]
	TIME [epoch: 11.5 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21627053002274335		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.21627053002274335 | validation: 0.19754508437363072]
	TIME [epoch: 11.6 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229572781244175		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.2229572781244175 | validation: 0.1784276859987238]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1201.pth
	Model improved!!!
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21533078025189836		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.21533078025189836 | validation: 0.18395883141003425]
	TIME [epoch: 11.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214985191132805		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.2214985191132805 | validation: 0.17811142704882726]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21848825241629496		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.21848825241629496 | validation: 0.17880632690265888]
	TIME [epoch: 11.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21404771668685857		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.21404771668685857 | validation: 0.1814379526789691]
	TIME [epoch: 11.5 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21752911633841282		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.21752911633841282 | validation: 0.19899778238152743]
	TIME [epoch: 11.6 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103009103353644		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.2103009103353644 | validation: 0.17937046398444736]
	TIME [epoch: 11.6 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22871292187713996		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.22871292187713996 | validation: 0.2198504944750475]
	TIME [epoch: 11.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298964994824055		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.2298964994824055 | validation: 0.18444666258733622]
	TIME [epoch: 11.6 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22675303939757196		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.22675303939757196 | validation: 0.2046220216336516]
	TIME [epoch: 11.6 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171025179072199		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.2171025179072199 | validation: 0.1713709795611146]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1211.pth
	Model improved!!!
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22028350579349346		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.22028350579349346 | validation: 0.18335330800761726]
	TIME [epoch: 11.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2143539428930074		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.2143539428930074 | validation: 0.21005871970225998]
	TIME [epoch: 11.6 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21845593917405504		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.21845593917405504 | validation: 0.19568881813199213]
	TIME [epoch: 11.6 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21934430962553772		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.21934430962553772 | validation: 0.19109077151465603]
	TIME [epoch: 11.6 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24409591620882543		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.24409591620882543 | validation: 0.22096848408582545]
	TIME [epoch: 11.6 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25730609412415		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.25730609412415 | validation: 0.22315958835854843]
	TIME [epoch: 11.6 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27992689045375646		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.27992689045375646 | validation: 0.21665882339824596]
	TIME [epoch: 11.6 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2451698554449407		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.2451698554449407 | validation: 0.17159546724251257]
	TIME [epoch: 11.6 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290584078024635		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.2290584078024635 | validation: 0.1763611076786578]
	TIME [epoch: 11.5 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23528687639045165		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.23528687639045165 | validation: 0.17511053584220868]
	TIME [epoch: 11.6 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21879658766147458		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.21879658766147458 | validation: 0.1739424824993062]
	TIME [epoch: 11.6 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22001668443925074		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.22001668443925074 | validation: 0.1697058021688198]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1223.pth
	Model improved!!!
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20882476594355798		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.20882476594355798 | validation: 0.20534200063432423]
	TIME [epoch: 11.6 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22047769420900565		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.22047769420900565 | validation: 0.20126249511530148]
	TIME [epoch: 11.6 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22758517135256423		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.22758517135256423 | validation: 0.23726341253314726]
	TIME [epoch: 11.6 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25178986116948493		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.25178986116948493 | validation: 0.2551623464795814]
	TIME [epoch: 11.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24406332342049153		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.24406332342049153 | validation: 0.21947223195034235]
	TIME [epoch: 11.6 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23100992392092862		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.23100992392092862 | validation: 0.18759308354649712]
	TIME [epoch: 11.6 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23552583631826973		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.23552583631826973 | validation: 0.17949143788200558]
	TIME [epoch: 11.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22966575201578632		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.22966575201578632 | validation: 0.17862297892616716]
	TIME [epoch: 11.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22758198292545156		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.22758198292545156 | validation: 0.2057700154205628]
	TIME [epoch: 11.6 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23193040341913107		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.23193040341913107 | validation: 0.20501963821865204]
	TIME [epoch: 11.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2290003811097333		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.2290003811097333 | validation: 0.20851363752205074]
	TIME [epoch: 11.6 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22433945493835375		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.22433945493835375 | validation: 0.18613737646225367]
	TIME [epoch: 11.6 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21665459207099264		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.21665459207099264 | validation: 0.18324111009277622]
	TIME [epoch: 11.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21243537388312045		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.21243537388312045 | validation: 0.18301266485095707]
	TIME [epoch: 11.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172592100540715		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.2172592100540715 | validation: 0.20019306460003428]
	TIME [epoch: 11.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2121458755420285		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.2121458755420285 | validation: 0.19037651768623232]
	TIME [epoch: 11.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20662819218403936		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.20662819218403936 | validation: 0.2180252053174143]
	TIME [epoch: 11.6 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24309091684964146		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.24309091684964146 | validation: 0.23996286643469694]
	TIME [epoch: 11.5 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25749672147691716		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.25749672147691716 | validation: 0.23333770813340557]
	TIME [epoch: 11.6 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2482299489742819		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.2482299489742819 | validation: 0.21918654961226344]
	TIME [epoch: 11.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23033616336887783		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.23033616336887783 | validation: 0.19537420157807606]
	TIME [epoch: 11.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312879378283237		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.2312879378283237 | validation: 0.17574519514340278]
	TIME [epoch: 11.6 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21758055223204603		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.21758055223204603 | validation: 0.1936514063340788]
	TIME [epoch: 11.5 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22368571048711006		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.22368571048711006 | validation: 0.18310380313767866]
	TIME [epoch: 11.5 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205478783122454		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.2205478783122454 | validation: 0.18404806728859396]
	TIME [epoch: 11.6 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22783212000510616		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.22783212000510616 | validation: 0.20484616473136774]
	TIME [epoch: 11.5 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26072582956955104		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.26072582956955104 | validation: 0.2249540237242047]
	TIME [epoch: 11.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25121263268943583		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.25121263268943583 | validation: 0.23891054777274345]
	TIME [epoch: 11.6 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23777470181770188		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.23777470181770188 | validation: 0.218050628426247]
	TIME [epoch: 11.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22586320549396507		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.22586320549396507 | validation: 0.2039978352012357]
	TIME [epoch: 11.5 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2197932810586523		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.2197932810586523 | validation: 0.20387088988265475]
	TIME [epoch: 11.6 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2235104642751663		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.2235104642751663 | validation: 0.1961180377548297]
	TIME [epoch: 11.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2225713895207756		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.2225713895207756 | validation: 0.18184114056217346]
	TIME [epoch: 11.5 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22289230659205347		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.22289230659205347 | validation: 0.2044511553133205]
	TIME [epoch: 11.6 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2158629015733788		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.2158629015733788 | validation: 0.22142156460687498]
	TIME [epoch: 11.6 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23151381290312575		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.23151381290312575 | validation: 0.229785324722086]
	TIME [epoch: 11.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24915122491124692		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.24915122491124692 | validation: 0.21390157335257662]
	TIME [epoch: 11.5 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22753601185360048		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.22753601185360048 | validation: 0.22962406715429737]
	TIME [epoch: 11.6 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23870542788880758		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.23870542788880758 | validation: 0.24640402173899034]
	TIME [epoch: 11.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22741551063888596		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.22741551063888596 | validation: 0.18804583523893584]
	TIME [epoch: 11.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21080961698326164		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.21080961698326164 | validation: 0.16673205690441767]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1264.pth
	Model improved!!!
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21830840285668823		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.21830840285668823 | validation: 0.18240666049862106]
	TIME [epoch: 11.5 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2211622358420504		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.2211622358420504 | validation: 0.18577407266326673]
	TIME [epoch: 11.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23240289313863083		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.23240289313863083 | validation: 0.19139826192189546]
	TIME [epoch: 11.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22627368110603333		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.22627368110603333 | validation: 0.1912899169146148]
	TIME [epoch: 11.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21749277213178614		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.21749277213178614 | validation: 0.1979857798112221]
	TIME [epoch: 11.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21027260045507334		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.21027260045507334 | validation: 0.18832729661435782]
	TIME [epoch: 11.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21740109680085107		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.21740109680085107 | validation: 0.2066062770945421]
	TIME [epoch: 11.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2277387726161429		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.2277387726161429 | validation: 0.21062253940737635]
	TIME [epoch: 11.6 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22360052770274014		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.22360052770274014 | validation: 0.20628187193736416]
	TIME [epoch: 11.6 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22229385922715683		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.22229385922715683 | validation: 0.21264923122646706]
	TIME [epoch: 11.6 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22123484620312178		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.22123484620312178 | validation: 0.19091565260378024]
	TIME [epoch: 11.6 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2207347743167422		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.2207347743167422 | validation: 0.1817271082580739]
	TIME [epoch: 11.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21577997988976388		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.21577997988976388 | validation: 0.19612141288986504]
	TIME [epoch: 11.6 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21737680777234736		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.21737680777234736 | validation: 0.17592768354700147]
	TIME [epoch: 11.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21511573008292442		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.21511573008292442 | validation: 0.19883835592143093]
	TIME [epoch: 11.5 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22535189505616526		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.22535189505616526 | validation: 0.188501649608402]
	TIME [epoch: 11.6 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2364241208715805		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.2364241208715805 | validation: 0.18197591795848783]
	TIME [epoch: 11.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22088229906015064		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.22088229906015064 | validation: 0.19305274661065228]
	TIME [epoch: 11.5 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2162361699071483		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.2162361699071483 | validation: 0.20612568489033692]
	TIME [epoch: 11.6 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22072677540499938		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.22072677540499938 | validation: 0.1927270046251625]
	TIME [epoch: 11.6 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21971254563536452		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.21971254563536452 | validation: 0.18937935198846462]
	TIME [epoch: 11.6 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20942132796416307		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.20942132796416307 | validation: 0.18706330104534225]
	TIME [epoch: 11.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191410182928592		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.2191410182928592 | validation: 0.17628169295946255]
	TIME [epoch: 11.6 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21807848226246365		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.21807848226246365 | validation: 0.17148063656620252]
	TIME [epoch: 11.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22496929875760951		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.22496929875760951 | validation: 0.17114787196183912]
	TIME [epoch: 11.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22428719485863927		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.22428719485863927 | validation: 0.1670379371253432]
	TIME [epoch: 11.6 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21678076937450183		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.21678076937450183 | validation: 0.18276456800664623]
	TIME [epoch: 11.6 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22403679668247672		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.22403679668247672 | validation: 0.18685286437940357]
	TIME [epoch: 11.5 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21246578140179956		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.21246578140179956 | validation: 0.20507118407986638]
	TIME [epoch: 11.6 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21945934223924946		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.21945934223924946 | validation: 0.1970487517720445]
	TIME [epoch: 11.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21352948006878467		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.21352948006878467 | validation: 0.2037851691288752]
	TIME [epoch: 11.6 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21942154949617454		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.21942154949617454 | validation: 0.20013239330024035]
	TIME [epoch: 11.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21726237507532115		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.21726237507532115 | validation: 0.2038806823145473]
	TIME [epoch: 11.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22016337200048666		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.22016337200048666 | validation: 0.18403523249379014]
	TIME [epoch: 11.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21676011395085146		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.21676011395085146 | validation: 0.17963732408574404]
	TIME [epoch: 11.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2157282384630919		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.2157282384630919 | validation: 0.18201898227691515]
	TIME [epoch: 11.6 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2140284747887458		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.2140284747887458 | validation: 0.18852209198574488]
	TIME [epoch: 11.6 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22512391234005064		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.22512391234005064 | validation: 0.19488594487128943]
	TIME [epoch: 11.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21363533235176324		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.21363533235176324 | validation: 0.18634260287436696]
	TIME [epoch: 11.6 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21947815572424445		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.21947815572424445 | validation: 0.21595236619667174]
	TIME [epoch: 11.5 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22272689278786342		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.22272689278786342 | validation: 0.20642028411016558]
	TIME [epoch: 11.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21746996161491333		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.21746996161491333 | validation: 0.18275821136431944]
	TIME [epoch: 11.6 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.219208469151552		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.219208469151552 | validation: 0.19212693915162682]
	TIME [epoch: 11.6 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171914873186525		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.2171914873186525 | validation: 0.20000288486910822]
	TIME [epoch: 11.6 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21977995342715706		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.21977995342715706 | validation: 0.1962013329106003]
	TIME [epoch: 11.6 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22485533657465043		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.22485533657465043 | validation: 0.22018272614258705]
	TIME [epoch: 11.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2196842587026419		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.2196842587026419 | validation: 0.19465138408257207]
	TIME [epoch: 11.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21342110542226775		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.21342110542226775 | validation: 0.18365145639842104]
	TIME [epoch: 11.6 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2135401181117258		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.2135401181117258 | validation: 0.1916574861218996]
	TIME [epoch: 11.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21158473652682097		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.21158473652682097 | validation: 0.1790739151890145]
	TIME [epoch: 11.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21856653683186106		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.21856653683186106 | validation: 0.1974311748706037]
	TIME [epoch: 11.6 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22156559652695013		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.22156559652695013 | validation: 0.18785743995322549]
	TIME [epoch: 11.6 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21642621235910064		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.21642621235910064 | validation: 0.18395263954368848]
	TIME [epoch: 11.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21170212938744026		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.21170212938744026 | validation: 0.17916878172218006]
	TIME [epoch: 11.5 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20765097348236475		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.20765097348236475 | validation: 0.1726453749452503]
	TIME [epoch: 11.6 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2159311206062303		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.2159311206062303 | validation: 0.18545660562048077]
	TIME [epoch: 11.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20977545472886336		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.20977545472886336 | validation: 0.1787983626510858]
	TIME [epoch: 11.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171462542271764		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.2171462542271764 | validation: 0.1918849836345445]
	TIME [epoch: 11.6 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2177784711847412		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.2177784711847412 | validation: 0.1773340136457557]
	TIME [epoch: 11.6 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2101281771481442		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.2101281771481442 | validation: 0.17673056389909902]
	TIME [epoch: 11.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21424244551520388		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.21424244551520388 | validation: 0.19858555543197262]
	TIME [epoch: 11.6 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21919424019753858		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.21919424019753858 | validation: 0.20360208234455113]
	TIME [epoch: 11.6 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21614385900696026		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.21614385900696026 | validation: 0.1750508544275068]
	TIME [epoch: 11.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20798851512307862		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.20798851512307862 | validation: 0.18350404268213238]
	TIME [epoch: 11.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21345566847040684		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.21345566847040684 | validation: 0.18507479098018703]
	TIME [epoch: 11.6 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21494261055369812		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.21494261055369812 | validation: 0.17813969938686997]
	TIME [epoch: 11.5 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2093421379519265		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.2093421379519265 | validation: 0.19292556337730915]
	TIME [epoch: 11.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2183309412526353		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.2183309412526353 | validation: 0.1723729021511293]
	TIME [epoch: 11.6 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21657963394064908		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.21657963394064908 | validation: 0.17936137650160955]
	TIME [epoch: 11.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22022644339257444		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.22022644339257444 | validation: 0.21872840036986252]
	TIME [epoch: 11.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22290921239692002		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.22290921239692002 | validation: 0.19482488916532092]
	TIME [epoch: 11.6 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22486557362561166		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.22486557362561166 | validation: 0.20396425907728696]
	TIME [epoch: 11.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22530789395810855		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.22530789395810855 | validation: 0.18860218912797913]
	TIME [epoch: 11.5 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22483819304108463		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.22483819304108463 | validation: 0.18594293856193425]
	TIME [epoch: 11.6 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22519974039622012		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.22519974039622012 | validation: 0.21696703620654595]
	TIME [epoch: 11.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23449062307735752		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.23449062307735752 | validation: 0.17967520765769593]
	TIME [epoch: 11.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22136937161893555		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.22136937161893555 | validation: 0.2000105916485558]
	TIME [epoch: 11.6 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22182021186002768		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.22182021186002768 | validation: 0.18970748988693742]
	TIME [epoch: 11.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2156195505943041		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.2156195505943041 | validation: 0.186046352666822]
	TIME [epoch: 11.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20907836016505965		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.20907836016505965 | validation: 0.17989239261324275]
	TIME [epoch: 11.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21696767016194834		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.21696767016194834 | validation: 0.1705191765365177]
	TIME [epoch: 11.6 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134004118436149		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.2134004118436149 | validation: 0.18477418500375542]
	TIME [epoch: 11.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21837699865265509		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.21837699865265509 | validation: 0.1851049768995288]
	TIME [epoch: 11.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22218576805722326		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.22218576805722326 | validation: 0.1807580827031932]
	TIME [epoch: 11.6 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22458475715230927		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.22458475715230927 | validation: 0.1861881804336538]
	TIME [epoch: 11.6 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2255488593797928		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.2255488593797928 | validation: 0.1780400488096079]
	TIME [epoch: 11.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22581222169719548		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.22581222169719548 | validation: 0.19217620665247986]
	TIME [epoch: 11.6 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218758574843562		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.218758574843562 | validation: 0.17363465771491599]
	TIME [epoch: 11.6 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2187636140391402		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.2187636140391402 | validation: 0.18763776835829446]
	TIME [epoch: 11.6 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23283298078825404		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.23283298078825404 | validation: 0.18053299409644133]
	TIME [epoch: 11.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22246345625277672		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.22246345625277672 | validation: 0.17481166874356824]
	TIME [epoch: 11.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22357501256371817		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.22357501256371817 | validation: 0.1710188230935507]
	TIME [epoch: 11.6 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22726944360478646		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.22726944360478646 | validation: 0.17416016970457876]
	TIME [epoch: 11.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23911463371970304		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.23911463371970304 | validation: 0.16500381624295707]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1358.pth
	Model improved!!!
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230704710691988		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.2230704710691988 | validation: 0.17262258652722148]
	TIME [epoch: 11.5 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2223903624234481		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.2223903624234481 | validation: 0.17906190116599022]
	TIME [epoch: 11.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079877136344744		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.2079877136344744 | validation: 0.1749905220267236]
	TIME [epoch: 11.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21864844619161455		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.21864844619161455 | validation: 0.1914379998244545]
	TIME [epoch: 11.6 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2145868688861587		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.2145868688861587 | validation: 0.18563542868770636]
	TIME [epoch: 11.6 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21587405281561353		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.21587405281561353 | validation: 0.22007524428015168]
	TIME [epoch: 11.6 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21707196070754797		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.21707196070754797 | validation: 0.18791532673277028]
	TIME [epoch: 11.6 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146886110992685		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.2146886110992685 | validation: 0.1821677301372307]
	TIME [epoch: 11.5 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2103240940941976		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.2103240940941976 | validation: 0.17940674301614778]
	TIME [epoch: 11.6 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21325990892775482		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.21325990892775482 | validation: 0.17668726376482688]
	TIME [epoch: 11.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2157980432747699		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.2157980432747699 | validation: 0.17861961659586356]
	TIME [epoch: 11.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21504090417671892		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.21504090417671892 | validation: 0.186470758506862]
	TIME [epoch: 11.6 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.216045977433243		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.216045977433243 | validation: 0.178605325863647]
	TIME [epoch: 11.6 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2186904657829514		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.2186904657829514 | validation: 0.17910646405394304]
	TIME [epoch: 11.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21655799250990765		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.21655799250990765 | validation: 0.18390408411601986]
	TIME [epoch: 11.6 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760549035081939		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.21760549035081939 | validation: 0.1759948879854574]
	TIME [epoch: 11.6 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21891743779252604		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.21891743779252604 | validation: 0.17439384591634455]
	TIME [epoch: 11.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123798260071673		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.2123798260071673 | validation: 0.18280509770433237]
	TIME [epoch: 11.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21060599346612974		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.21060599346612974 | validation: 0.16753487036820353]
	TIME [epoch: 11.6 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20866960709392268		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.20866960709392268 | validation: 0.1701337166178728]
	TIME [epoch: 11.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21301685982318685		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.21301685982318685 | validation: 0.17475168612777708]
	TIME [epoch: 11.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21053342615093765		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.21053342615093765 | validation: 0.17193760080550738]
	TIME [epoch: 11.6 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22163011834841595		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.22163011834841595 | validation: 0.17758169010237132]
	TIME [epoch: 11.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268155356938745		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.2268155356938745 | validation: 0.1769246331078151]
	TIME [epoch: 11.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120739402164728		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.2120739402164728 | validation: 0.1809953706359492]
	TIME [epoch: 11.6 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083058727288211		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.2083058727288211 | validation: 0.18191566070504414]
	TIME [epoch: 11.6 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21218326407881416		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.21218326407881416 | validation: 0.18479550256574626]
	TIME [epoch: 11.6 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843899788399844		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.20843899788399844 | validation: 0.18244768248583687]
	TIME [epoch: 11.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107391388613894		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.2107391388613894 | validation: 0.1818407859915878]
	TIME [epoch: 11.6 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060806287139765		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.2060806287139765 | validation: 0.1866436145764721]
	TIME [epoch: 11.5 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138978573117445		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.2138978573117445 | validation: 0.17405832199860735]
	TIME [epoch: 11.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22091406521699425		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.22091406521699425 | validation: 0.1830164177999722]
	TIME [epoch: 11.6 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968992244987448		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.21968992244987448 | validation: 0.20598806459004088]
	TIME [epoch: 11.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22673998091503844		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.22673998091503844 | validation: 0.20279474488998223]
	TIME [epoch: 11.6 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21124854186624098		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.21124854186624098 | validation: 0.19072367395826692]
	TIME [epoch: 11.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20932676806111025		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.20932676806111025 | validation: 0.1798479826475918]
	TIME [epoch: 11.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21392463581215126		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.21392463581215126 | validation: 0.22205393072786417]
	TIME [epoch: 11.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22412834537575638		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.22412834537575638 | validation: 0.22555039175259212]
	TIME [epoch: 11.6 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23249484303387466		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.23249484303387466 | validation: 0.2410285908082794]
	TIME [epoch: 11.5 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2297302892822944		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.2297302892822944 | validation: 0.1902198920949589]
	TIME [epoch: 11.6 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22383729544800735		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.22383729544800735 | validation: 0.17905186990376137]
	TIME [epoch: 11.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2216549101575641		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.2216549101575641 | validation: 0.18925576005633496]
	TIME [epoch: 11.6 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182849338688667		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.2182849338688667 | validation: 0.18722875897556057]
	TIME [epoch: 11.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20947482766978678		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.20947482766978678 | validation: 0.1811910562150888]
	TIME [epoch: 11.6 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21906881938658054		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.21906881938658054 | validation: 0.17606872506822155]
	TIME [epoch: 11.6 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2156549401701109		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.2156549401701109 | validation: 0.18468852878028463]
	TIME [epoch: 11.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2156491182758152		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.2156491182758152 | validation: 0.1899050526447325]
	TIME [epoch: 11.6 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2179544253319891		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.2179544253319891 | validation: 0.19395911330506135]
	TIME [epoch: 11.6 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147423196361905		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.2147423196361905 | validation: 0.18615240061051588]
	TIME [epoch: 11.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21787094630866147		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.21787094630866147 | validation: 0.1759817988731481]
	TIME [epoch: 11.5 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20807958139092617		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.20807958139092617 | validation: 0.1637799867974578]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1409.pth
	Model improved!!!
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925062383167284		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.20925062383167284 | validation: 0.17497249440886686]
	TIME [epoch: 11.5 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21511518454202416		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.21511518454202416 | validation: 0.16847225655213635]
	TIME [epoch: 11.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21185506565414564		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.21185506565414564 | validation: 0.1747677653618502]
	TIME [epoch: 11.6 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21653220367137516		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.21653220367137516 | validation: 0.17798878603516552]
	TIME [epoch: 11.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22051709695305277		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.22051709695305277 | validation: 0.18444867485105543]
	TIME [epoch: 11.5 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22648011644475166		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.22648011644475166 | validation: 0.18776934838701675]
	TIME [epoch: 11.6 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22688660347168088		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.22688660347168088 | validation: 0.18842660397053487]
	TIME [epoch: 11.6 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21915952887864892		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.21915952887864892 | validation: 0.1915886242038969]
	TIME [epoch: 11.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2136071637299833		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.2136071637299833 | validation: 0.19063138018260398]
	TIME [epoch: 11.5 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138703147324306		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.2138703147324306 | validation: 0.18060643264194412]
	TIME [epoch: 11.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21149381173362156		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.21149381173362156 | validation: 0.16862258782837392]
	TIME [epoch: 11.5 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21060135082446585		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.21060135082446585 | validation: 0.1796019558412913]
	TIME [epoch: 11.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079871148599346		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.2079871148599346 | validation: 0.1702103088753712]
	TIME [epoch: 11.6 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055552953865042		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.2055552953865042 | validation: 0.16843516245380385]
	TIME [epoch: 11.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20872676595403974		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.20872676595403974 | validation: 0.17160269794485217]
	TIME [epoch: 11.5 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2008814332314883		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.2008814332314883 | validation: 0.19181712073239268]
	TIME [epoch: 11.6 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771897883871657		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.20771897883871657 | validation: 0.1821895250991387]
	TIME [epoch: 11.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20584228985959968		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.20584228985959968 | validation: 0.18904545517768406]
	TIME [epoch: 11.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21010731561500118		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.21010731561500118 | validation: 0.18229061600709504]
	TIME [epoch: 11.6 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21061717390650866		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.21061717390650866 | validation: 0.17232901934140643]
	TIME [epoch: 11.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20875446371714385		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.20875446371714385 | validation: 0.18263497706238135]
	TIME [epoch: 11.5 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20783314742954448		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.20783314742954448 | validation: 0.17813136982405667]
	TIME [epoch: 11.6 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20594347957146086		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.20594347957146086 | validation: 0.18842390538140572]
	TIME [epoch: 11.6 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106981059504517		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.2106981059504517 | validation: 0.19687642122754276]
	TIME [epoch: 11.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21406745345855488		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.21406745345855488 | validation: 0.18867098647089733]
	TIME [epoch: 11.5 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090076327121263		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.2090076327121263 | validation: 0.17978330331938197]
	TIME [epoch: 11.6 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20449842791884096		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.20449842791884096 | validation: 0.17692571971239546]
	TIME [epoch: 11.5 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20596987500530067		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.20596987500530067 | validation: 0.1957143445133469]
	TIME [epoch: 11.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058948901009222		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.2058948901009222 | validation: 0.18879975689009967]
	TIME [epoch: 11.6 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079427808146415		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.2079427808146415 | validation: 0.19343453619486897]
	TIME [epoch: 11.5 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21294673513733517		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.21294673513733517 | validation: 0.18973852663017848]
	TIME [epoch: 11.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108634466891226		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.2108634466891226 | validation: 0.18828091558239124]
	TIME [epoch: 11.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21135842919866676		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.21135842919866676 | validation: 0.19401134890869418]
	TIME [epoch: 11.6 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104143420435466		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.2104143420435466 | validation: 0.17180424259825608]
	TIME [epoch: 11.5 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2203773692025499		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.2203773692025499 | validation: 0.17465559525593588]
	TIME [epoch: 11.6 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2166213938680512		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.2166213938680512 | validation: 0.1695851527800656]
	TIME [epoch: 11.6 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20815732059905598		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.20815732059905598 | validation: 0.17866108740819978]
	TIME [epoch: 11.5 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017668867936879		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.2017668867936879 | validation: 0.17105432546741342]
	TIME [epoch: 11.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028207896599551		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.2028207896599551 | validation: 0.17546102960731033]
	TIME [epoch: 11.6 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20688765937204678		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.20688765937204678 | validation: 0.160922361209804]
	TIME [epoch: 11.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1449.pth
	Model improved!!!
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20613342798587275		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.20613342798587275 | validation: 0.18046217188403824]
	TIME [epoch: 11.5 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021294182726799		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.2021294182726799 | validation: 0.18639909299395602]
	TIME [epoch: 11.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082745063719586		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.2082745063719586 | validation: 0.18987365978572204]
	TIME [epoch: 11.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20873449089615703		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.20873449089615703 | validation: 0.1914770622926173]
	TIME [epoch: 11.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21306108049572808		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.21306108049572808 | validation: 0.18479485799125944]
	TIME [epoch: 11.6 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20374316253755792		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.20374316253755792 | validation: 0.1789738455924654]
	TIME [epoch: 11.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086476057189887		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.2086476057189887 | validation: 0.18757041236578942]
	TIME [epoch: 11.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20902331015594142		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.20902331015594142 | validation: 0.1912799463942166]
	TIME [epoch: 11.6 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21072284538690034		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.21072284538690034 | validation: 0.2066117065703894]
	TIME [epoch: 11.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168518025971951		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.2168518025971951 | validation: 0.1932540248426381]
	TIME [epoch: 11.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21411305886938903		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.21411305886938903 | validation: 0.18105468854954343]
	TIME [epoch: 11.6 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089552568574436		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.2089552568574436 | validation: 0.1800545856661679]
	TIME [epoch: 11.6 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21548852155655826		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.21548852155655826 | validation: 0.1880734467689491]
	TIME [epoch: 11.5 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20827059687130436		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.20827059687130436 | validation: 0.1798748784965915]
	TIME [epoch: 11.5 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21582473114757383		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.21582473114757383 | validation: 0.1785871830070255]
	TIME [epoch: 11.6 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22221326540676833		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.22221326540676833 | validation: 0.1786020114460259]
	TIME [epoch: 11.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2129246990051212		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.2129246990051212 | validation: 0.16941792585288368]
	TIME [epoch: 11.5 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20513456424157067		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.20513456424157067 | validation: 0.17051675690477316]
	TIME [epoch: 11.6 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21371467875062		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.21371467875062 | validation: 0.18375155173121102]
	TIME [epoch: 11.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21265749638316445		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.21265749638316445 | validation: 0.19235760233713792]
	TIME [epoch: 11.5 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22228979292205928		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.22228979292205928 | validation: 0.1974986128507463]
	TIME [epoch: 11.6 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175946828448012		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.2175946828448012 | validation: 0.1887881620758383]
	TIME [epoch: 11.6 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207475382659216		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.207475382659216 | validation: 0.19054587492782482]
	TIME [epoch: 11.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21515647029104915		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.21515647029104915 | validation: 0.19701735051714928]
	TIME [epoch: 11.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2194498467439775		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.2194498467439775 | validation: 0.19927435893725104]
	TIME [epoch: 11.6 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2251275738395068		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.2251275738395068 | validation: 0.20918505214890615]
	TIME [epoch: 11.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.222101785631035		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.222101785631035 | validation: 0.18482678177398001]
	TIME [epoch: 11.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21351939527523994		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.21351939527523994 | validation: 0.19392905563887305]
	TIME [epoch: 11.6 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21753623253989535		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.21753623253989535 | validation: 0.19934018159463482]
	TIME [epoch: 11.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21796721778320124		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.21796721778320124 | validation: 0.19712563407265957]
	TIME [epoch: 11.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21321920950274353		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.21321920950274353 | validation: 0.1867201250490476]
	TIME [epoch: 11.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075742502758283		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.2075742502758283 | validation: 0.1961983200051677]
	TIME [epoch: 11.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21279095345610155		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.21279095345610155 | validation: 0.19834820793152869]
	TIME [epoch: 11.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21514287032593654		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.21514287032593654 | validation: 0.18973963492541507]
	TIME [epoch: 11.6 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21313974924301815		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.21313974924301815 | validation: 0.1874665001129531]
	TIME [epoch: 11.5 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21432425240917613		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.21432425240917613 | validation: 0.1957069924948153]
	TIME [epoch: 11.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2140811313595258		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.2140811313595258 | validation: 0.1914150622779847]
	TIME [epoch: 11.6 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123777217869993		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.2123777217869993 | validation: 0.19041045608913598]
	TIME [epoch: 11.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21440541866147778		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.21440541866147778 | validation: 0.19015853502232977]
	TIME [epoch: 11.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172590851697127		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.2172590851697127 | validation: 0.18555972007277216]
	TIME [epoch: 11.6 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20933982129552103		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.20933982129552103 | validation: 0.18433067399892025]
	TIME [epoch: 11.6 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21357076334163824		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.21357076334163824 | validation: 0.1799098041627051]
	TIME [epoch: 11.5 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21331034574844437		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.21331034574844437 | validation: 0.1900745595602826]
	TIME [epoch: 11.6 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21279072014184353		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.21279072014184353 | validation: 0.1900655021842907]
	TIME [epoch: 11.6 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2149781778961396		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.2149781778961396 | validation: 0.1921494740394744]
	TIME [epoch: 11.6 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21672368522887614		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.21672368522887614 | validation: 0.20708369245506483]
	TIME [epoch: 11.5 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167985380431645		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.2167985380431645 | validation: 0.1872925737702723]
	TIME [epoch: 11.6 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21574023296973252		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.21574023296973252 | validation: 0.19392757914314232]
	TIME [epoch: 11.5 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21430388300519773		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.21430388300519773 | validation: 0.20131058864541146]
	TIME [epoch: 11.5 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21728754695491487		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.21728754695491487 | validation: 0.2093048849965466]
	TIME [epoch: 11.6 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21282911986811218		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.21282911986811218 | validation: 0.20492146013972531]
	TIME [epoch: 11.6 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21528269126205168		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.21528269126205168 | validation: 0.19216106592110505]
	TIME [epoch: 11.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2098303204439499		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.2098303204439499 | validation: 0.19297942987580377]
	TIME [epoch: 11.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2157233450117243		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.2157233450117243 | validation: 0.2020476255283301]
	TIME [epoch: 11.6 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21590284733986337		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.21590284733986337 | validation: 0.1820611728929]
	TIME [epoch: 11.5 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20874322159142666		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.20874322159142666 | validation: 0.1892740262851568]
	TIME [epoch: 11.6 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211545623923306		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.211545623923306 | validation: 0.18779075538037202]
	TIME [epoch: 11.6 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130163714952056		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.2130163714952056 | validation: 0.17347172962583166]
	TIME [epoch: 11.6 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113676124458458		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.2113676124458458 | validation: 0.16715999454930752]
	TIME [epoch: 11.6 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2163375355294851		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.2163375355294851 | validation: 0.17663431125355256]
	TIME [epoch: 11.6 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20419256283406478		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.20419256283406478 | validation: 0.16682494021204192]
	TIME [epoch: 11.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20690599121739678		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.20690599121739678 | validation: 0.1814823654596693]
	TIME [epoch: 11.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.215565715981438		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.215565715981438 | validation: 0.18806612727176933]
	TIME [epoch: 11.6 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2079928010817072		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.2079928010817072 | validation: 0.18422360613043937]
	TIME [epoch: 11.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2122946579362557		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.2122946579362557 | validation: 0.17803213074149601]
	TIME [epoch: 11.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843669614701696		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.20843669614701696 | validation: 0.16865832219448543]
	TIME [epoch: 11.6 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20970508585726946		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.20970508585726946 | validation: 0.16574691001537567]
	TIME [epoch: 11.6 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21330110914504874		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.21330110914504874 | validation: 0.1752882615447897]
	TIME [epoch: 11.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21865718023264175		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.21865718023264175 | validation: 0.17255312582584217]
	TIME [epoch: 11.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21535534338999365		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.21535534338999365 | validation: 0.16769925051433127]
	TIME [epoch: 11.6 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142943947848316		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.2142943947848316 | validation: 0.1714221148265198]
	TIME [epoch: 11.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21394929844987917		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.21394929844987917 | validation: 0.17146435020592463]
	TIME [epoch: 11.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21130933172838046		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.21130933172838046 | validation: 0.1695411621481688]
	TIME [epoch: 11.6 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20557733097260608		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.20557733097260608 | validation: 0.17506411420309057]
	TIME [epoch: 11.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20539186675190274		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.20539186675190274 | validation: 0.165043025167428]
	TIME [epoch: 11.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20115291675769617		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.20115291675769617 | validation: 0.1783792034305833]
	TIME [epoch: 11.6 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029171146700631		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.2029171146700631 | validation: 0.16724288240616975]
	TIME [epoch: 11.5 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20678843211089168		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.20678843211089168 | validation: 0.16732717350295562]
	TIME [epoch: 11.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20433135874091002		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.20433135874091002 | validation: 0.1702084809146386]
	TIME [epoch: 11.6 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21226781762505992		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.21226781762505992 | validation: 0.19298147247654648]
	TIME [epoch: 11.6 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206579694339257		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.206579694339257 | validation: 0.20053555355143204]
	TIME [epoch: 11.6 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20735311880192392		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.20735311880192392 | validation: 0.20007220427903272]
	TIME [epoch: 11.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21375729335481847		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.21375729335481847 | validation: 0.2120450675370488]
	TIME [epoch: 11.6 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21586582612266725		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.21586582612266725 | validation: 0.19234464695994832]
	TIME [epoch: 11.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21046629174666368		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.21046629174666368 | validation: 0.19189584533424994]
	TIME [epoch: 11.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061948662197125		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.2061948662197125 | validation: 0.19306180873122172]
	TIME [epoch: 11.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20958613734835493		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.20958613734835493 | validation: 0.18351621086435552]
	TIME [epoch: 11.5 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033440960124801		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.2033440960124801 | validation: 0.17692947784830568]
	TIME [epoch: 11.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050355755209109		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.2050355755209109 | validation: 0.18637109947700267]
	TIME [epoch: 11.6 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20205880956829686		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.20205880956829686 | validation: 0.16790849346194797]
	TIME [epoch: 11.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059475622027897		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.2059475622027897 | validation: 0.1791942187249015]
	TIME [epoch: 11.5 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2070041606331211		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.2070041606331211 | validation: 0.1687486945085332]
	TIME [epoch: 11.6 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20339320398665794		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.20339320398665794 | validation: 0.18411144770278853]
	TIME [epoch: 11.5 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20357812013870458		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.20357812013870458 | validation: 0.17408917098588655]
	TIME [epoch: 11.5 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066317120619239		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.2066317120619239 | validation: 0.18457343930145276]
	TIME [epoch: 11.6 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20751909588077977		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.20751909588077977 | validation: 0.18983090272220182]
	TIME [epoch: 11.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20170965608414418		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.20170965608414418 | validation: 0.18172832985419413]
	TIME [epoch: 11.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021771471817757		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.2021771471817757 | validation: 0.19500254996317978]
	TIME [epoch: 11.6 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2037445617619602		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.2037445617619602 | validation: 0.1842122910637888]
	TIME [epoch: 11.6 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20428309372790926		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.20428309372790926 | validation: 0.1721671952710711]
	TIME [epoch: 11.6 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20446237255764885		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.20446237255764885 | validation: 0.17793187236832075]
	TIME [epoch: 11.5 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20263924527854363		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.20263924527854363 | validation: 0.18719105456427565]
	TIME [epoch: 11.6 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496872421955092		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.20496872421955092 | validation: 0.18427043082175223]
	TIME [epoch: 11.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20436625395299257		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.20436625395299257 | validation: 0.19029160193683098]
	TIME [epoch: 11.6 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076956673972124		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.2076956673972124 | validation: 0.1975213884925951]
	TIME [epoch: 11.6 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20957284812584143		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.20957284812584143 | validation: 0.1956481708986241]
	TIME [epoch: 11.6 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21117593563701575		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.21117593563701575 | validation: 0.19960560295483365]
	TIME [epoch: 11.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22053330234669108		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.22053330234669108 | validation: 0.20085813002431152]
	TIME [epoch: 11.6 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126462499571489		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.2126462499571489 | validation: 0.20143886032450126]
	TIME [epoch: 11.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21107466647095		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.21107466647095 | validation: 0.1872380382319314]
	TIME [epoch: 11.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20957950587456237		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.20957950587456237 | validation: 0.1923942320024991]
	TIME [epoch: 11.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21272800938795156		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.21272800938795156 | validation: 0.19134779340596592]
	TIME [epoch: 11.6 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2158572164906376		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.2158572164906376 | validation: 0.1808343417354154]
	TIME [epoch: 11.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21118737714777655		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.21118737714777655 | validation: 0.18636495482121723]
	TIME [epoch: 11.5 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20709544530046925		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.20709544530046925 | validation: 0.19032453511688804]
	TIME [epoch: 11.6 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20779569053375538		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.20779569053375538 | validation: 0.18770391004283046]
	TIME [epoch: 11.6 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20743331723536124		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.20743331723536124 | validation: 0.1888621719346772]
	TIME [epoch: 11.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20443234855208842		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.20443234855208842 | validation: 0.179406661505994]
	TIME [epoch: 11.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046065591558723		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.2046065591558723 | validation: 0.1784169046352644]
	TIME [epoch: 11.5 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21039444944840213		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.21039444944840213 | validation: 0.18079764358173542]
	TIME [epoch: 11.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21160791239062568		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.21160791239062568 | validation: 0.18404968024305948]
	TIME [epoch: 11.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20632278883662636		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.20632278883662636 | validation: 0.1719559965577237]
	TIME [epoch: 11.5 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069507584658899		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.2069507584658899 | validation: 0.18210521240503505]
	TIME [epoch: 11.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047224098595372		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.2047224098595372 | validation: 0.1818222356473552]
	TIME [epoch: 11.6 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20659697952898298		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.20659697952898298 | validation: 0.17733302829714048]
	TIME [epoch: 11.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20730367165764066		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.20730367165764066 | validation: 0.17165113184807432]
	TIME [epoch: 11.5 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20616264633472184		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.20616264633472184 | validation: 0.17674651843633954]
	TIME [epoch: 11.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20836431549570783		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.20836431549570783 | validation: 0.1725383854922884]
	TIME [epoch: 11.6 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2032575913280264		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.2032575913280264 | validation: 0.18598583973525112]
	TIME [epoch: 11.5 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20497568457615722		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.20497568457615722 | validation: 0.1808614071251976]
	TIME [epoch: 11.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20444907470366575		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.20444907470366575 | validation: 0.18777335552210897]
	TIME [epoch: 11.6 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20648254531818894		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.20648254531818894 | validation: 0.1897646366735377]
	TIME [epoch: 11.5 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2116969226812756		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.2116969226812756 | validation: 0.19454190943102995]
	TIME [epoch: 11.5 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20935946417516443		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.20935946417516443 | validation: 0.18989200305729967]
	TIME [epoch: 11.6 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065364383580721		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.2065364383580721 | validation: 0.1793922599004443]
	TIME [epoch: 11.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21104641975616653		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.21104641975616653 | validation: 0.17959066331370743]
	TIME [epoch: 11.6 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20437861449499883		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.20437861449499883 | validation: 0.18750469793056046]
	TIME [epoch: 11.6 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20863149510088122		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.20863149510088122 | validation: 0.1890804674123253]
	TIME [epoch: 11.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191381670351857		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.20191381670351857 | validation: 0.18570494088582787]
	TIME [epoch: 11.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041863552625604		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.2041863552625604 | validation: 0.18208769897721855]
	TIME [epoch: 11.6 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20557544428919147		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.20557544428919147 | validation: 0.19364964817873323]
	TIME [epoch: 11.6 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20821956419117063		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.20821956419117063 | validation: 0.2062973148229638]
	TIME [epoch: 11.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142304184947275		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.21142304184947275 | validation: 0.2013288204552994]
	TIME [epoch: 11.5 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066653527530532		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.2066653527530532 | validation: 0.19695008164466554]
	TIME [epoch: 11.6 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20702656030151784		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.20702656030151784 | validation: 0.18837173265184926]
	TIME [epoch: 11.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20455017345529933		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.20455017345529933 | validation: 0.1971185600912476]
	TIME [epoch: 11.5 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2073948217006756		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.2073948217006756 | validation: 0.18967325780770933]
	TIME [epoch: 11.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20670795453242435		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.20670795453242435 | validation: 0.19406961409196236]
	TIME [epoch: 11.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20428837247161846		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.20428837247161846 | validation: 0.18350282816529973]
	TIME [epoch: 11.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20725577330057032		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.20725577330057032 | validation: 0.18380786536461305]
	TIME [epoch: 11.6 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20256829761955536		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.20256829761955536 | validation: 0.16940882179105093]
	TIME [epoch: 11.6 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20433439488387634		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.20433439488387634 | validation: 0.1840794615032297]
	TIME [epoch: 11.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21372146243705675		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.21372146243705675 | validation: 0.1998515801815117]
	TIME [epoch: 11.6 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21796144006069731		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.21796144006069731 | validation: 0.19688203960569245]
	TIME [epoch: 11.5 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21179823050737076		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.21179823050737076 | validation: 0.19124119465672718]
	TIME [epoch: 11.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21036475036001095		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.21036475036001095 | validation: 0.1890648681541469]
	TIME [epoch: 11.5 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096158991663879		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.2096158991663879 | validation: 0.18189700389832353]
	TIME [epoch: 11.6 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20322486663032555		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.20322486663032555 | validation: 0.17970627049494456]
	TIME [epoch: 11.6 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20873703920943215		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.20873703920943215 | validation: 0.18149104899673568]
	TIME [epoch: 11.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21376315049064987		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.21376315049064987 | validation: 0.18489202589733686]
	TIME [epoch: 11.6 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20995208344281335		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.20995208344281335 | validation: 0.19010248468873026]
	TIME [epoch: 11.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21037418512838943		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.21037418512838943 | validation: 0.18306629370222724]
	TIME [epoch: 11.6 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20855233031862164		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.20855233031862164 | validation: 0.1783324536969638]
	TIME [epoch: 11.6 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20609599605847967		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.20609599605847967 | validation: 0.18207267341917793]
	TIME [epoch: 11.6 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20589685894897397		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.20589685894897397 | validation: 0.18161984668861791]
	TIME [epoch: 11.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20345686105312344		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.20345686105312344 | validation: 0.17545555788267517]
	TIME [epoch: 11.6 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886549928504117		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.20886549928504117 | validation: 0.175646718368029]
	TIME [epoch: 11.5 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20728348886733333		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.20728348886733333 | validation: 0.1801947810685855]
	TIME [epoch: 11.6 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20648928134517486		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.20648928134517486 | validation: 0.19195361558194848]
	TIME [epoch: 11.6 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21548673952371944		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.21548673952371944 | validation: 0.18160833264591694]
	TIME [epoch: 11.6 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21144998116561203		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.21144998116561203 | validation: 0.19033813456010912]
	TIME [epoch: 11.5 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20934208176961905		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.20934208176961905 | validation: 0.1778443306833317]
	TIME [epoch: 11.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21062103459651563		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.21062103459651563 | validation: 0.17269232137077736]
	TIME [epoch: 11.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20108270104006556		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.20108270104006556 | validation: 0.18265744000409406]
	TIME [epoch: 11.6 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20742815236625806		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.20742815236625806 | validation: 0.1818337508027026]
	TIME [epoch: 11.5 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20589913229180112		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.20589913229180112 | validation: 0.1806464345549555]
	TIME [epoch: 11.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2109987000328871		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.2109987000328871 | validation: 0.18096321337541155]
	TIME [epoch: 11.6 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20366262568320237		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.20366262568320237 | validation: 0.17534591888645212]
	TIME [epoch: 11.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086140094390842		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.2086140094390842 | validation: 0.1792807653116016]
	TIME [epoch: 11.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20274916889453498		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.20274916889453498 | validation: 0.17192131537514402]
	TIME [epoch: 11.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21057240606411254		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.21057240606411254 | validation: 0.17233189702837]
	TIME [epoch: 11.6 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21211001236901		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.21211001236901 | validation: 0.16852071651697087]
	TIME [epoch: 11.6 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20778386680207378		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.20778386680207378 | validation: 0.17648481973269095]
	TIME [epoch: 11.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206746911791365		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.206746911791365 | validation: 0.17822214832974864]
	TIME [epoch: 11.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2062917845099327		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.2062917845099327 | validation: 0.17280298927274093]
	TIME [epoch: 11.5 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053423979352283		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.2053423979352283 | validation: 0.17792788450402497]
	TIME [epoch: 11.6 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20543602449438916		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.20543602449438916 | validation: 0.17684332317690418]
	TIME [epoch: 11.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20897769897331286		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.20897769897331286 | validation: 0.1717401528661071]
	TIME [epoch: 11.6 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096533138951802		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.2096533138951802 | validation: 0.17559328327281393]
	TIME [epoch: 11.6 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21144288616486318		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.21144288616486318 | validation: 0.16683726167899743]
	TIME [epoch: 11.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20277880164736442		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.20277880164736442 | validation: 0.1785973225393606]
	TIME [epoch: 11.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2071824695400749		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.2071824695400749 | validation: 0.1696035245961886]
	TIME [epoch: 11.6 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028137473866737		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.2028137473866737 | validation: 0.17528658211837736]
	TIME [epoch: 11.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21190126927702863		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.21190126927702863 | validation: 0.16758786920833682]
	TIME [epoch: 11.6 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20589135859048716		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.20589135859048716 | validation: 0.18031348328462735]
	TIME [epoch: 11.6 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20612700013435825		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.20612700013435825 | validation: 0.18323345501336172]
	TIME [epoch: 11.6 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20557588432491136		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.20557588432491136 | validation: 0.18076364405867387]
	TIME [epoch: 11.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20386706542201938		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.20386706542201938 | validation: 0.1749409183167427]
	TIME [epoch: 11.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337843595976074		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.20337843595976074 | validation: 0.18231984495140283]
	TIME [epoch: 11.6 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075582955981934		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.2075582955981934 | validation: 0.1896502798249404]
	TIME [epoch: 11.6 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2111980834078706		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.2111980834078706 | validation: 0.17678236467098565]
	TIME [epoch: 11.5 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20651141833989628		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.20651141833989628 | validation: 0.19036034612104538]
	TIME [epoch: 11.6 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20823062220343205		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.20823062220343205 | validation: 0.1865601961015117]
	TIME [epoch: 11.5 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20258236865587606		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.20258236865587606 | validation: 0.19190029919289608]
	TIME [epoch: 11.6 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20404844930297567		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.20404844930297567 | validation: 0.17819396865372597]
	TIME [epoch: 11.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19996100965494337		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.19996100965494337 | validation: 0.16880436322806447]
	TIME [epoch: 11.6 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20419846347280834		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.20419846347280834 | validation: 0.18101272689160844]
	TIME [epoch: 11.6 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20272758022591353		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.20272758022591353 | validation: 0.16869053943841303]
	TIME [epoch: 11.6 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19806603381223353		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.19806603381223353 | validation: 0.18465268389795417]
	TIME [epoch: 11.6 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20176781292895546		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.20176781292895546 | validation: 0.18289520383327104]
	TIME [epoch: 11.6 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20134397607787455		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.20134397607787455 | validation: 0.1854754225234316]
	TIME [epoch: 11.6 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079178448106313		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.20079178448106313 | validation: 0.17633560582205568]
	TIME [epoch: 11.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20010297930400417		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.20010297930400417 | validation: 0.1752247686073325]
	TIME [epoch: 11.6 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.202562282795756		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.202562282795756 | validation: 0.1846002084730284]
	TIME [epoch: 11.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2065600579033814		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.2065600579033814 | validation: 0.1853993262465846]
	TIME [epoch: 11.6 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20466616349664585		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.20466616349664585 | validation: 0.18988720588916935]
	TIME [epoch: 11.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20319431469930682		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.20319431469930682 | validation: 0.19109380879009188]
	TIME [epoch: 11.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20180449724767127		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.20180449724767127 | validation: 0.1818929715921614]
	TIME [epoch: 11.6 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20296270183951134		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.20296270183951134 | validation: 0.18233154110857178]
	TIME [epoch: 11.6 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20033499500934263		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.20033499500934263 | validation: 0.16936537075100425]
	TIME [epoch: 11.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011028744699388		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.2011028744699388 | validation: 0.17868547803551033]
	TIME [epoch: 11.6 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2080306036613702		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.2080306036613702 | validation: 0.17187225185153274]
	TIME [epoch: 11.6 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20683126621176276		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.20683126621176276 | validation: 0.17143493819018127]
	TIME [epoch: 11.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2043520506847845		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.2043520506847845 | validation: 0.17827058264826015]
	TIME [epoch: 11.6 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20571784418541997		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.20571784418541997 | validation: 0.18246661986581508]
	TIME [epoch: 11.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20386831493656757		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.20386831493656757 | validation: 0.17432763946339755]
	TIME [epoch: 11.6 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20126562286203908		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.20126562286203908 | validation: 0.1793488680766629]
	TIME [epoch: 11.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2013527222301861		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.2013527222301861 | validation: 0.17769954277393193]
	TIME [epoch: 11.6 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20308919887761798		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.20308919887761798 | validation: 0.17794424481259682]
	TIME [epoch: 11.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20480844774522758		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.20480844774522758 | validation: 0.1835287700171415]
	TIME [epoch: 11.6 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20450220061629326		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.20450220061629326 | validation: 0.17902337880986416]
	TIME [epoch: 11.6 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20268982962938017		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.20268982962938017 | validation: 0.19222122223780083]
	TIME [epoch: 11.6 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2086183170181757		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.2086183170181757 | validation: 0.18717261031381807]
	TIME [epoch: 11.6 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2087224987380294		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.2087224987380294 | validation: 0.1980622631356445]
	TIME [epoch: 11.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20780968042070974		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.20780968042070974 | validation: 0.19460022930161494]
	TIME [epoch: 11.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2115478681261962		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.2115478681261962 | validation: 0.18643740505613388]
	TIME [epoch: 11.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20818079335192327		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.20818079335192327 | validation: 0.18209873849193944]
	TIME [epoch: 11.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053499020804521		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.2053499020804521 | validation: 0.1820395392373115]
	TIME [epoch: 11.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2031768291267255		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.2031768291267255 | validation: 0.18205269468780208]
	TIME [epoch: 11.6 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2014960681242675		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.2014960681242675 | validation: 0.1748824178695694]
	TIME [epoch: 11.6 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025004637120345		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.2025004637120345 | validation: 0.18343936192868182]
	TIME [epoch: 11.6 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20447363523927145		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.20447363523927145 | validation: 0.17206985056303903]
	TIME [epoch: 11.6 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20488341930472437		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.20488341930472437 | validation: 0.16474525840073806]
	TIME [epoch: 11.6 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19733214801497848		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.19733214801497848 | validation: 0.16847342108087215]
	TIME [epoch: 11.6 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20207574821982682		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.20207574821982682 | validation: 0.17958531398307287]
	TIME [epoch: 11.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1972326280821334		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.1972326280821334 | validation: 0.16051883916850357]
	TIME [epoch: 11.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study3/model_tr_study3_r4_20240309_135637/states/model_tr_study3_1695.pth
	Model improved!!!
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20424118813385866		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.20424118813385866 | validation: 0.17446601421129365]
	TIME [epoch: 11.6 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20145440032366418		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.20145440032366418 | validation: 0.17469167102968705]
	TIME [epoch: 11.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045905913619607		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.2045905913619607 | validation: 0.17080806868342116]
	TIME [epoch: 11.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20397737976738367		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.20397737976738367 | validation: 0.17819081724991354]
	TIME [epoch: 11.6 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055392313972158		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.2055392313972158 | validation: 0.16973919320905195]
	TIME [epoch: 11.5 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20158464316770694		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.20158464316770694 | validation: 0.1889297476315015]
	TIME [epoch: 11.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20573848490220897		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.20573848490220897 | validation: 0.17562137972988665]
	TIME [epoch: 11.6 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20183392306002487		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.20183392306002487 | validation: 0.18300823998385482]
	TIME [epoch: 11.5 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20448388898937928		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.20448388898937928 | validation: 0.18048513562570712]
	TIME [epoch: 11.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20459726517652876		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.20459726517652876 | validation: 0.1761311643531187]
	TIME [epoch: 11.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023409101611466		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.2023409101611466 | validation: 0.17497099959067586]
	TIME [epoch: 11.6 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20695958760201996		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.20695958760201996 | validation: 0.17443002004686567]
	TIME [epoch: 11.6 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20944555120581004		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.20944555120581004 | validation: 0.1764964032920005]
	TIME [epoch: 11.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20633420761194707		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.20633420761194707 | validation: 0.1811233984719052]
	TIME [epoch: 11.6 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20209735689257952		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.20209735689257952 | validation: 0.1789754638005135]
	TIME [epoch: 11.6 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20414532398025143		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.20414532398025143 | validation: 0.17473467921861974]
	TIME [epoch: 11.5 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19999122196009794		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.19999122196009794 | validation: 0.17973254561219548]
	TIME [epoch: 11.6 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20627925239163636		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.20627925239163636 | validation: 0.17798158617886042]
	TIME [epoch: 11.6 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20406489314539733		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.20406489314539733 | validation: 0.18003970585328355]
	TIME [epoch: 11.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20311326980187489		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.20311326980187489 | validation: 0.17126623422578036]
	TIME [epoch: 11.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20135107526722507		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.20135107526722507 | validation: 0.16847670649855956]
	TIME [epoch: 11.5 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20267793679093762		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.20267793679093762 | validation: 0.18153011459938231]
	TIME [epoch: 11.5 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20236626873671926		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.20236626873671926 | validation: 0.17827433973730206]
	TIME [epoch: 11.6 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033510924733574		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.2033510924733574 | validation: 0.180050322604978]
	TIME [epoch: 11.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017884405094459		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.2017884405094459 | validation: 0.1858113259699176]
	TIME [epoch: 11.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20582729174630468		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.20582729174630468 | validation: 0.18452761669226356]
	TIME [epoch: 11.6 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20080267094894552		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.20080267094894552 | validation: 0.18331979967230694]
	TIME [epoch: 11.6 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20217408418208055		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.20217408418208055 | validation: 0.1880558159092947]
	TIME [epoch: 11.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20505919179829962		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.20505919179829962 | validation: 0.18898799189987844]
	TIME [epoch: 11.5 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20562094491865018		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.20562094491865018 | validation: 0.19890895136331707]
	TIME [epoch: 11.6 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20707566744800726		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.20707566744800726 | validation: 0.1962692679422362]
	TIME [epoch: 11.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20361247275471964		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.20361247275471964 | validation: 0.18768343502638962]
	TIME [epoch: 11.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20367384248649956		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.20367384248649956 | validation: 0.18843030196354463]
	TIME [epoch: 11.6 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20362559038162556		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.20362559038162556 | validation: 0.183581199657607]
	TIME [epoch: 11.6 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153342318324186		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.20153342318324186 | validation: 0.19217287866612204]
	TIME [epoch: 11.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19654744688600256		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.19654744688600256 | validation: 0.18826363690991754]
	TIME [epoch: 11.6 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20508415083971404		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.20508415083971404 | validation: 0.18060348638620255]
	TIME [epoch: 11.6 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20290650186395423		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.20290650186395423 | validation: 0.1837756928481869]
	TIME [epoch: 11.6 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20134914846123164		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.20134914846123164 | validation: 0.17672700306737063]
	TIME [epoch: 11.6 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018700358373418		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.2018700358373418 | validation: 0.1825982035213689]
	TIME [epoch: 11.5 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20047771395926434		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.20047771395926434 | validation: 0.17986628885845207]
	TIME [epoch: 11.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153958566784344		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.20153958566784344 | validation: 0.18054750537967643]
	TIME [epoch: 11.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20284563771468164		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.20284563771468164 | validation: 0.1822816878088248]
	TIME [epoch: 11.6 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042789676644138		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.2042789676644138 | validation: 0.16943835735765256]
	TIME [epoch: 11.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20490491091417282		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.20490491091417282 | validation: 0.17446297507557318]
	TIME [epoch: 11.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2013254610450964		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.2013254610450964 | validation: 0.17122101555717342]
	TIME [epoch: 11.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20093474068223405		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.20093474068223405 | validation: 0.1824771556510031]
	TIME [epoch: 11.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19838857396594808		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.19838857396594808 | validation: 0.1825145513703484]
	TIME [epoch: 11.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002188918964396		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.2002188918964396 | validation: 0.17192220315864787]
	TIME [epoch: 11.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1999146355506189		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.1999146355506189 | validation: 0.1796076836568733]
	TIME [epoch: 11.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266049971237948		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.20266049971237948 | validation: 0.17964731472551027]
	TIME [epoch: 11.6 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001478023845372		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.2001478023845372 | validation: 0.17383576770266757]
	TIME [epoch: 11.6 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20232596750324006		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.20232596750324006 | validation: 0.1812896910962806]
	TIME [epoch: 11.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456490160977234		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.20456490160977234 | validation: 0.18936153448073473]
	TIME [epoch: 11.5 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20441950202123182		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.20441950202123182 | validation: 0.19042803868304184]
	TIME [epoch: 11.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20715220256444838		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.20715220256444838 | validation: 0.1897983826572982]
	TIME [epoch: 11.6 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153612732688056		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.20153612732688056 | validation: 0.17796335801361463]
	TIME [epoch: 11.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20423724895732154		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.20423724895732154 | validation: 0.16893300157159138]
	TIME [epoch: 11.5 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20261769319525594		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.20261769319525594 | validation: 0.18474087281310975]
	TIME [epoch: 11.6 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20105799217309667		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.20105799217309667 | validation: 0.17895821114457036]
	TIME [epoch: 11.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20357547490611377		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.20357547490611377 | validation: 0.17024706639546736]
	TIME [epoch: 11.6 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015303922642588		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.2015303922642588 | validation: 0.18312807984624313]
	TIME [epoch: 11.6 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20606020886852527		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.20606020886852527 | validation: 0.18901751644009793]
	TIME [epoch: 11.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2057321392967276		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.2057321392967276 | validation: 0.1832373770683094]
	TIME [epoch: 11.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20381851663150924		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.20381851663150924 | validation: 0.1874382115597591]
	TIME [epoch: 11.6 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20175578995047488		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.20175578995047488 | validation: 0.1798386313726482]
	TIME [epoch: 11.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586049911757562		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.20586049911757562 | validation: 0.17973221757468583]
	TIME [epoch: 11.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20575284434401928		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.20575284434401928 | validation: 0.186907769538469]
	TIME [epoch: 11.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443744262414471		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.21443744262414471 | validation: 0.192414238519448]
	TIME [epoch: 11.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100614145538706		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.2100614145538706 | validation: 0.1888456985892821]
	TIME [epoch: 11.5 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20411418972933826		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.20411418972933826 | validation: 0.17701472660076945]
	TIME [epoch: 11.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20642619464352668		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.20642619464352668 | validation: 0.18777127075279867]
	TIME [epoch: 11.6 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2069067197952532		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.2069067197952532 | validation: 0.18101333233708683]
	TIME [epoch: 11.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20809217944701952		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.20809217944701952 | validation: 0.16947286069308307]
	TIME [epoch: 11.5 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076671569904631		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.2076671569904631 | validation: 0.17833591887846317]
	TIME [epoch: 11.6 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20083992125724034		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.20083992125724034 | validation: 0.18864810533622664]
	TIME [epoch: 11.6 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20564376287140645		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.20564376287140645 | validation: 0.18511117424375967]
	TIME [epoch: 11.5 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20605434062703365		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.20605434062703365 | validation: 0.1749639142762306]
	TIME [epoch: 11.6 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20264899531643532		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.20264899531643532 | validation: 0.1797330909688281]
	TIME [epoch: 11.6 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20648089050213267		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.20648089050213267 | validation: 0.173520163258032]
	TIME [epoch: 11.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20491554433264672		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.20491554433264672 | validation: 0.17867604305644114]
	TIME [epoch: 11.6 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20799766152893645		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.20799766152893645 | validation: 0.18301089699574044]
	TIME [epoch: 11.6 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20706049309646518		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.20706049309646518 | validation: 0.1782572688058097]
	TIME [epoch: 11.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20253494057222599		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.20253494057222599 | validation: 0.17774479305467367]
	TIME [epoch: 11.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20115087368783036		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.20115087368783036 | validation: 0.1868662592574254]
	TIME [epoch: 11.6 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20141289598385764		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.20141289598385764 | validation: 0.18082322254344632]
	TIME [epoch: 11.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20430692832944064		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.20430692832944064 | validation: 0.17472410405830346]
	TIME [epoch: 11.5 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20773899563415774		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.20773899563415774 | validation: 0.17997777331320294]
	TIME [epoch: 11.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20477674681814895		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.20477674681814895 | validation: 0.18041961604173956]
	TIME [epoch: 11.6 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045651285277374		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.2045651285277374 | validation: 0.1777812248459604]
	TIME [epoch: 11.6 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20198770299902666		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.20198770299902666 | validation: 0.18022229994466143]
	TIME [epoch: 11.6 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20234747493930078		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.20234747493930078 | validation: 0.18674100401593474]
	TIME [epoch: 11.6 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20371504442996768		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.20371504442996768 | validation: 0.18000108720497854]
	TIME [epoch: 11.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20318295874425635		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.20318295874425635 | validation: 0.1795331848266047]
	TIME [epoch: 11.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20745475991916917		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.20745475991916917 | validation: 0.17991779725065118]
	TIME [epoch: 11.5 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20362671786619824		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.20362671786619824 | validation: 0.18196696970709014]
	TIME [epoch: 11.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2058619582895601		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.2058619582895601 | validation: 0.1859830479822782]
	TIME [epoch: 11.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20190561433621412		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.20190561433621412 | validation: 0.17318112402123803]
	TIME [epoch: 11.5 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19942870883987052		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.19942870883987052 | validation: 0.17320635866894]
	TIME [epoch: 11.6 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19776401884034317		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.19776401884034317 | validation: 0.17531670845303096]
	TIME [epoch: 11.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20452191391785896		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.20452191391785896 | validation: 0.16553813998642675]
	TIME [epoch: 11.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2061082256030321		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.2061082256030321 | validation: 0.1744331583866795]
	TIME [epoch: 11.5 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20388979493578313		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.20388979493578313 | validation: 0.16551806600744823]
	TIME [epoch: 11.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19610391083314396		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.19610391083314396 | validation: 0.17414938301799268]
	TIME [epoch: 11.6 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20532397441563352		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.20532397441563352 | validation: 0.17907054426861627]
	TIME [epoch: 11.5 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19775473010026298		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.19775473010026298 | validation: 0.18549705849961945]
	TIME [epoch: 11.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196892136496446		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.196892136496446 | validation: 0.17276130527947764]
	TIME [epoch: 11.6 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19947069188562586		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.19947069188562586 | validation: 0.17750095166994484]
	TIME [epoch: 11.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20142941088129132		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.20142941088129132 | validation: 0.17778478240648085]
	TIME [epoch: 11.6 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19796090021941085		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.19796090021941085 | validation: 0.16842546281197407]
	TIME [epoch: 11.6 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20003337812667898		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.20003337812667898 | validation: 0.17602306804825976]
	TIME [epoch: 11.6 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.199227847811847		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.199227847811847 | validation: 0.17548033330633656]
	TIME [epoch: 11.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2019136342918253		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.2019136342918253 | validation: 0.17134850965990503]
	TIME [epoch: 11.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20519041904911248		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.20519041904911248 | validation: 0.17751854923813468]
	TIME [epoch: 11.6 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023829213108808		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.2023829213108808 | validation: 0.16814127909533272]
	TIME [epoch: 11.5 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042400959164561		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.2042400959164561 | validation: 0.17467205175167608]
	TIME [epoch: 11.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20259506807007216		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.20259506807007216 | validation: 0.1783321008791966]
	TIME [epoch: 11.6 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20013832701749787		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.20013832701749787 | validation: 0.17791656439909478]
	TIME [epoch: 11.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020297085591759		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.2020297085591759 | validation: 0.17115017598329008]
	TIME [epoch: 11.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20098902329394427		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.20098902329394427 | validation: 0.17690462733663295]
	TIME [epoch: 11.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2007663080519174		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.2007663080519174 | validation: 0.17525256408238693]
	TIME [epoch: 11.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20339239440393792		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.20339239440393792 | validation: 0.17571493262347926]
	TIME [epoch: 11.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20263472055632412		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.20263472055632412 | validation: 0.17739280555025821]
	TIME [epoch: 11.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19481463860043766		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.19481463860043766 | validation: 0.17435723695035826]
	TIME [epoch: 11.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20012171263928497		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.20012171263928497 | validation: 0.18371103985122575]
	TIME [epoch: 11.6 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20150687102501727		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.20150687102501727 | validation: 0.18704082481270398]
	TIME [epoch: 11.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20086940756928473		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.20086940756928473 | validation: 0.17654997719564922]
	TIME [epoch: 11.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20235849663246688		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.20235849663246688 | validation: 0.1832527433187336]
	TIME [epoch: 11.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20066471762376636		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.20066471762376636 | validation: 0.180572025105687]
	TIME [epoch: 11.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20291631650762298		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.20291631650762298 | validation: 0.1845527805124211]
	TIME [epoch: 11.6 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966098713172091		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.1966098713172091 | validation: 0.1729912285308022]
	TIME [epoch: 11.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20114345307127854		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.20114345307127854 | validation: 0.17584706091258276]
	TIME [epoch: 11.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19739154548877083		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.19739154548877083 | validation: 0.18114381871065618]
	TIME [epoch: 11.6 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20217545536959022		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.20217545536959022 | validation: 0.1739705653889601]
	TIME [epoch: 11.6 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496888549610776		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.20496888549610776 | validation: 0.17868791424728162]
	TIME [epoch: 11.6 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20286665156054945		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.20286665156054945 | validation: 0.17467426199116176]
	TIME [epoch: 11.6 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19701556466215706		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.19701556466215706 | validation: 0.1734052789101492]
	TIME [epoch: 11.5 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20329471643948344		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.20329471643948344 | validation: 0.17518974838356713]
	TIME [epoch: 11.6 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19450330379519826		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.19450330379519826 | validation: 0.17593836130066648]
	TIME [epoch: 11.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012080337079799		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.2012080337079799 | validation: 0.17398004804261452]
	TIME [epoch: 11.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20184466599971476		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.20184466599971476 | validation: 0.17863723917375066]
	TIME [epoch: 11.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20460677330398638		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.20460677330398638 | validation: 0.1752243474825924]
	TIME [epoch: 11.6 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20329368389293073		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.20329368389293073 | validation: 0.17593692146559647]
	TIME [epoch: 11.6 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2026263607859638		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.2026263607859638 | validation: 0.17682323638836828]
	TIME [epoch: 11.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19597760417925597		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.19597760417925597 | validation: 0.1723470571672266]
	TIME [epoch: 11.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19766558440144208		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.19766558440144208 | validation: 0.17877554233470613]
	TIME [epoch: 11.6 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055012819646112		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.20055012819646112 | validation: 0.1699255137131322]
	TIME [epoch: 11.5 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20153987723722458		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.20153987723722458 | validation: 0.16653202185275887]
	TIME [epoch: 11.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2003756095351873		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.2003756095351873 | validation: 0.1718321001497359]
	TIME [epoch: 11.6 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022877175080388		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.2022877175080388 | validation: 0.17153934010388416]
	TIME [epoch: 11.6 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20563865979953821		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.20563865979953821 | validation: 0.17392669514890358]
	TIME [epoch: 11.5 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20150489837967714		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.20150489837967714 | validation: 0.17224662974136415]
	TIME [epoch: 11.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049468839799316		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.2049468839799316 | validation: 0.17713679619004893]
	TIME [epoch: 11.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20370622597940313		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.20370622597940313 | validation: 0.16898016389061504]
	TIME [epoch: 11.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20336639469627166		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.20336639469627166 | validation: 0.17390537495466402]
	TIME [epoch: 11.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017482859235985		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.2017482859235985 | validation: 0.167298043627286]
	TIME [epoch: 11.5 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20185188483441088		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.20185188483441088 | validation: 0.17914330905540637]
	TIME [epoch: 11.5 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20276850598175042		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.20276850598175042 | validation: 0.17303868391481025]
	TIME [epoch: 11.6 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20175185308225327		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.20175185308225327 | validation: 0.16720392946279947]
	TIME [epoch: 11.6 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015502260453829		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.2015502260453829 | validation: 0.16935833351773005]
	TIME [epoch: 11.5 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055107151933408		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.2055107151933408 | validation: 0.16207825025189831]
	TIME [epoch: 11.5 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200391811794567		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.200391811794567 | validation: 0.16361506066093978]
	TIME [epoch: 11.6 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988332930891084		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.19988332930891084 | validation: 0.16993849528352167]
	TIME [epoch: 11.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20155266656349177		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.20155266656349177 | validation: 0.1774287074027099]
	TIME [epoch: 11.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20434925109409552		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.20434925109409552 | validation: 0.17147118424833377]
	TIME [epoch: 11.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2035929821539617		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.2035929821539617 | validation: 0.1713659279579408]
	TIME [epoch: 11.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1979743763653325		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.1979743763653325 | validation: 0.16549440663496476]
	TIME [epoch: 11.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19704672163114492		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.19704672163114492 | validation: 0.18314645124483345]
	TIME [epoch: 11.6 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19599292768088397		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.19599292768088397 | validation: 0.18595267736270493]
	TIME [epoch: 11.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20233195306138735		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.20233195306138735 | validation: 0.17865775715780394]
	TIME [epoch: 11.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20312807435248467		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.20312807435248467 | validation: 0.1729515759941282]
	TIME [epoch: 11.6 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2003488020582017		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.2003488020582017 | validation: 0.18972030276426474]
	TIME [epoch: 11.6 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19698860406485277		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.19698860406485277 | validation: 0.17133571548782572]
	TIME [epoch: 11.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20013166531546178		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.20013166531546178 | validation: 0.1807182707760559]
	TIME [epoch: 11.6 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984856485239924		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.1984856485239924 | validation: 0.182621532254377]
	TIME [epoch: 11.6 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19933562392151866		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.19933562392151866 | validation: 0.18459337730318154]
	TIME [epoch: 11.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2029197906955321		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.2029197906955321 | validation: 0.18404395851219177]
	TIME [epoch: 11.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19616631395885864		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.19616631395885864 | validation: 0.1757845268590966]
	TIME [epoch: 11.6 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2016068914668615		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.2016068914668615 | validation: 0.1743723543524257]
	TIME [epoch: 11.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20331536451243282		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.20331536451243282 | validation: 0.18601462389836212]
	TIME [epoch: 11.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20054474130429112		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.20054474130429112 | validation: 0.17951768652110223]
	TIME [epoch: 11.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2005188201587901		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.2005188201587901 | validation: 0.18912142449450975]
	TIME [epoch: 11.6 sec]
EPOCH 1878/2000:
	Training over batches...
