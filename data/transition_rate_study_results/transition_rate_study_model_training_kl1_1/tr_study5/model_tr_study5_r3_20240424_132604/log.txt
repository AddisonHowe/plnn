Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r3', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1563742210

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.44338483236385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.44338483236385 | validation: 10.25356741004094]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.521548595558018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.521548595558018 | validation: 8.700383806534608]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.495861314820516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.495861314820516 | validation: 7.952873333859531]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.730962447869395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.730962447869395 | validation: 7.169854012979603]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.119157763094949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.119157763094949 | validation: 7.100661816752643]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.798926596987709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.798926596987709 | validation: 6.453908483121168]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.556179972996718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.556179972996718 | validation: 6.322580042980328]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.380730933459512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.380730933459512 | validation: 6.476689580431632]
	TIME [epoch: 24.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.414641622132563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.414641622132563 | validation: 6.451576185181262]
	TIME [epoch: 25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.338042694526035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.338042694526035 | validation: 6.022803450419874]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.022985431002329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.022985431002329 | validation: 7.068837234040225]
	TIME [epoch: 25 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6174198949043035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6174198949043035 | validation: 5.963238611365148]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944404766167931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.944404766167931 | validation: 5.862248129582086]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.998737632768876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.998737632768876 | validation: 5.851034677680068]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.978736463504397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.978736463504397 | validation: 6.10289793018655]
	TIME [epoch: 25 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.075066734549003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.075066734549003 | validation: 5.957879405637518]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.886847485092899		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.886847485092899 | validation: 5.951440455011655]
	TIME [epoch: 25 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.113866951462222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.113866951462222 | validation: 6.1401358763561005]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.038021110052465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.038021110052465 | validation: 6.119205908097485]
	TIME [epoch: 25 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.906559155276545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.906559155276545 | validation: 5.946620060349428]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.008773266659301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.008773266659301 | validation: 5.986139360619776]
	TIME [epoch: 25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8127647196111365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8127647196111365 | validation: 6.852637924884327]
	TIME [epoch: 25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.089794765721649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.089794765721649 | validation: 5.845584877326156]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.723471228186184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.723471228186184 | validation: 5.576868296161161]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.825220255330759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.825220255330759 | validation: 5.674999730144785]
	TIME [epoch: 25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.760608356999732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.760608356999732 | validation: 5.807969348010824]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.873811590061266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.873811590061266 | validation: 5.6537145571548715]
	TIME [epoch: 24.9 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.705016753008684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.705016753008684 | validation: 5.580518294690828]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.739256023220002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.739256023220002 | validation: 6.9965123841988515]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.82173235744974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.82173235744974 | validation: 9.737823866123605]
	TIME [epoch: 24.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.806716504205328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.806716504205328 | validation: 6.031792169665502]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.072622245283176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.072622245283176 | validation: 5.868423942887427]
	TIME [epoch: 25 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.890104134321692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.890104134321692 | validation: 5.729414863942968]
	TIME [epoch: 25 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830207698151321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.830207698151321 | validation: 5.726241107685024]
	TIME [epoch: 24.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.820820535735038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.820820535735038 | validation: 5.8262266386184764]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.866579232259415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.866579232259415 | validation: 5.622951896137058]
	TIME [epoch: 25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829178784095125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.829178784095125 | validation: 5.870963503791876]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.858570204519292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.858570204519292 | validation: 5.7286214841081184]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.849351928372391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.849351928372391 | validation: 5.653416990247722]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.618080485137196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.618080485137196 | validation: 5.6769044587543975]
	TIME [epoch: 25 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.69815450943628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.69815450943628 | validation: 5.711749488877424]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.849758410911964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.849758410911964 | validation: 5.798721876701852]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7371628537997985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7371628537997985 | validation: 5.6400262666354255]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.675034117021675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.675034117021675 | validation: 5.6163449138653485]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.713465810893579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.713465810893579 | validation: 5.66165806463441]
	TIME [epoch: 25 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.537746325329193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.537746325329193 | validation: 5.7809083821005265]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7514457237412575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7514457237412575 | validation: 5.6035129408674855]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7576497209711635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7576497209711635 | validation: 5.472917458283474]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.473600737003023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.473600737003023 | validation: 5.417197568605508]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.342723744261987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.342723744261987 | validation: 5.3858669472994665]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.405417950889568		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.405417950889568 | validation: 5.030460683172795]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.270300475288867		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.270300475288867 | validation: 5.167041274083821]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.347957395492545		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.347957395492545 | validation: 6.237861391514959]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.703124127927594		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 6.703124127927594 | validation: 5.600288485713327]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.338526047203372		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.338526047203372 | validation: 5.077725835017051]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3364632137405295		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.3364632137405295 | validation: 5.758219043134791]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3647113091133765		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.3647113091133765 | validation: 4.938670017591149]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.96250271070632		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.96250271070632 | validation: 4.912146895913715]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.930921096913854		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.930921096913854 | validation: 5.675427414171947]
	TIME [epoch: 24.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.298109972934025		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.298109972934025 | validation: 5.126784247849098]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.078838141628413		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.078838141628413 | validation: 5.431889591678576]
	TIME [epoch: 25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.173692364584084		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.173692364584084 | validation: 5.198783358651733]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.003889757288234		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.003889757288234 | validation: 5.07895833782574]
	TIME [epoch: 24.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.842276894586259		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.842276894586259 | validation: 5.234135885834643]
	TIME [epoch: 25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.952506504170575		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.952506504170575 | validation: 4.869935483308154]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6966873457201554		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.6966873457201554 | validation: 4.993871470971722]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.575542682851332		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 7.575542682851332 | validation: 7.582698383171261]
	TIME [epoch: 25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.4177925965534275		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 7.4177925965534275 | validation: 8.961563988140506]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.983872555189451		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 6.983872555189451 | validation: 5.411753815522444]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.117867505846295		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 5.117867505846295 | validation: 4.985906951011006]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.00365376024963		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.00365376024963 | validation: 4.8737749862170245]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.866873630580591		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.866873630580591 | validation: 5.529374990026847]
	TIME [epoch: 25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.024476300520032		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 5.024476300520032 | validation: 4.551194643560762]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6249210694273035		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.6249210694273035 | validation: 4.771667116935508]
	TIME [epoch: 24.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.76472907003704		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.76472907003704 | validation: 4.921640388818753]
	TIME [epoch: 25 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.537094810627524		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.537094810627524 | validation: 4.470159385841378]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.317632933306244		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.317632933306244 | validation: 4.231002561691534]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.331559478795951		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.331559478795951 | validation: 4.162902758993308]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.027919693508936		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.027919693508936 | validation: 3.918809545978506]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6871950782278535		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.6871950782278535 | validation: 4.222588937354459]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8277539146334814		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.8277539146334814 | validation: 3.6452861014852354]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9058388534374586		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.9058388534374586 | validation: 3.5414681301433832]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7551650487537067		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.7551650487537067 | validation: 4.22071278774206]
	TIME [epoch: 24.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.640567138947089		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.640567138947089 | validation: 3.483851950240112]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.454248829266269		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.454248829266269 | validation: 3.3382976786777316]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.227178290068085		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.227178290068085 | validation: 2.945982145906314]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2896184577817364		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.2896184577817364 | validation: 2.9065837627382214]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.98618607310726		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.98618607310726 | validation: 3.0624938640919868]
	TIME [epoch: 24.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6102393908781596		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.6102393908781596 | validation: 3.3341874999786025]
	TIME [epoch: 24.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1231655524882362		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.1231655524882362 | validation: 2.7807930592903056]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9814784039689357		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.9814784039689357 | validation: 2.972441849208285]
	TIME [epoch: 24.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3810897304850713		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.3810897304850713 | validation: 2.447327021613254]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4665096077269535		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.4665096077269535 | validation: 3.1595778792183205]
	TIME [epoch: 24.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4925146107086764		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.4925146107086764 | validation: 2.039535465030148]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4037462895228794		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.4037462895228794 | validation: 2.3492130089363745]
	TIME [epoch: 24.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7935322819236603		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.7935322819236603 | validation: 2.2409556387649996]
	TIME [epoch: 24.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4363930562768803		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.4363930562768803 | validation: 3.348174594528596]
	TIME [epoch: 24.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.910171048049496		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.910171048049496 | validation: 2.4517759773996706]
	TIME [epoch: 24.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3552028782312973		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.3552028782312973 | validation: 2.4343230137676897]
	TIME [epoch: 24.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.330658593161779		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.330658593161779 | validation: 1.9068679920354572]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1935962046270046		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 6.1935962046270046 | validation: 7.473995907620259]
	TIME [epoch: 24.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6915229407561325		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 6.6915229407561325 | validation: 6.223856135061888]
	TIME [epoch: 24.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.108572606153116		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 6.108572606153116 | validation: 6.258930168059912]
	TIME [epoch: 24.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.125303486399369		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 6.125303486399369 | validation: 6.202410724090339]
	TIME [epoch: 24.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.10053414509695		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 6.10053414509695 | validation: 6.16138796171932]
	TIME [epoch: 24.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.068544568539793		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 6.068544568539793 | validation: 6.571344836301867]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.382250371742727		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 6.382250371742727 | validation: 6.429294847136268]
	TIME [epoch: 24.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.145934136597542		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 6.145934136597542 | validation: 6.563081382096007]
	TIME [epoch: 24.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.226331946692845		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 6.226331946692845 | validation: 6.493269047271594]
	TIME [epoch: 24.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1797299174275615		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 6.1797299174275615 | validation: 6.059249342655169]
	TIME [epoch: 24.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.095319285466373		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 6.095319285466373 | validation: 6.133473930964899]
	TIME [epoch: 24.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.105808572546597		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 6.105808572546597 | validation: 5.984733405534601]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9542698756053705		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 5.9542698756053705 | validation: 6.996494274281258]
	TIME [epoch: 24.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.425271451716843		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 6.425271451716843 | validation: 6.721601137443223]
	TIME [epoch: 24.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.273946369873364		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 6.273946369873364 | validation: 6.833599823815829]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.291516701441267		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 6.291516701441267 | validation: 6.639151680749567]
	TIME [epoch: 24.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.153163915733973		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 6.153163915733973 | validation: 5.99540253231153]
	TIME [epoch: 24.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.24040698813997		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 6.24040698813997 | validation: 6.153613805186374]
	TIME [epoch: 24.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.209990464932335		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 6.209990464932335 | validation: 6.329720097946515]
	TIME [epoch: 24.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.190562411922186		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 6.190562411922186 | validation: 6.563089714508541]
	TIME [epoch: 24.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.250860424033792		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 6.250860424033792 | validation: 6.145632890940322]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.103262014264188		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 6.103262014264188 | validation: 6.328809821434224]
	TIME [epoch: 24.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.21897438769607		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 6.21897438769607 | validation: 6.113144922213264]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.111114528848649		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 6.111114528848649 | validation: 6.023553126920842]
	TIME [epoch: 24.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.08252595308137		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 6.08252595308137 | validation: 5.9244033988756675]
	TIME [epoch: 24.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.016880105505694		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 6.016880105505694 | validation: 6.109688378670346]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1012618218837265		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 6.1012618218837265 | validation: 6.014428482709938]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044075399731377		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 6.044075399731377 | validation: 6.154213482033255]
	TIME [epoch: 24.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9497481731032025		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 5.9497481731032025 | validation: 5.912205215882834]
	TIME [epoch: 24.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1287257615707205		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 6.1287257615707205 | validation: 6.143170291068152]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.01856311546373		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 6.01856311546373 | validation: 6.080031803736192]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.971451259624827		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 5.971451259624827 | validation: 5.907847606771384]
	TIME [epoch: 24.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.957766468391012		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 5.957766468391012 | validation: 5.861667558377325]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944378076991349		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 5.944378076991349 | validation: 6.145364276022031]
	TIME [epoch: 24.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.997044234010934		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 5.997044234010934 | validation: 5.955587007733246]
	TIME [epoch: 24.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.973491162890194		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 5.973491162890194 | validation: 5.964581209389442]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9649649609200015		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 5.9649649609200015 | validation: 5.884857914586271]
	TIME [epoch: 24.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.032490040428518		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 6.032490040428518 | validation: 5.979893859520314]
	TIME [epoch: 24.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.000358651623729		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 6.000358651623729 | validation: 6.016827099373843]
	TIME [epoch: 24.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.071065156880598		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 6.071065156880598 | validation: 6.405118574788471]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.065202393468224		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 6.065202393468224 | validation: 6.374433742501631]
	TIME [epoch: 24.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.052186419164397		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 6.052186419164397 | validation: 5.869441443350663]
	TIME [epoch: 24.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.986019380146289		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 5.986019380146289 | validation: 6.04218305408395]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.979777002895231		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 5.979777002895231 | validation: 6.019429173363281]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.047705590359575		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 6.047705590359575 | validation: 6.023251683804058]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0027790256760625		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 6.0027790256760625 | validation: 6.059229586991169]
	TIME [epoch: 24.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.956746070299135		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 5.956746070299135 | validation: 5.8262905603288555]
	TIME [epoch: 24.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.955888506429399		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 5.955888506429399 | validation: 5.930008755954811]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.936372327380689		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 5.936372327380689 | validation: 6.131812692822154]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.930136922316079		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 5.930136922316079 | validation: 5.866246436623343]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.916597546425883		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 5.916597546425883 | validation: 5.914686876809919]
	TIME [epoch: 25 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.932445156480569		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 5.932445156480569 | validation: 5.814469090492691]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9146721332620515		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 5.9146721332620515 | validation: 5.887393147078106]
	TIME [epoch: 24.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834959608712321		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 5.834959608712321 | validation: 5.791128810153112]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8933517908988		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 5.8933517908988 | validation: 5.974651946266588]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.881899347395122		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 5.881899347395122 | validation: 5.859910660630957]
	TIME [epoch: 24.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.922460478030703		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 5.922460478030703 | validation: 5.841612975497799]
	TIME [epoch: 24.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.87224359908706		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 5.87224359908706 | validation: 6.088329979818791]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.917791567610079		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 5.917791567610079 | validation: 6.2249716202910115]
	TIME [epoch: 24.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.994277609225584		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 5.994277609225584 | validation: 5.809611277493133]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.08292110645871		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 6.08292110645871 | validation: 5.897713930517607]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.019325572329755		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 6.019325572329755 | validation: 5.821391504542065]
	TIME [epoch: 24.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830592583124341		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 5.830592583124341 | validation: 5.882814762623922]
	TIME [epoch: 24.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859417431956267		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 5.859417431956267 | validation: 6.001205067068571]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.938159899281648		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 5.938159899281648 | validation: 5.80358408653883]
	TIME [epoch: 24.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.849482248831171		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 5.849482248831171 | validation: 5.839940212905872]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.816765925552208		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 5.816765925552208 | validation: 5.873435309945722]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.918189681173364		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 5.918189681173364 | validation: 5.805616881191544]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8136273257262845		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 5.8136273257262845 | validation: 5.83849410968569]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.83831759306983		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 5.83831759306983 | validation: 5.820097032236498]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.907324960017033		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 5.907324960017033 | validation: 6.315029589932608]
	TIME [epoch: 24.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.120857748102635		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 6.120857748102635 | validation: 6.089745320881287]
	TIME [epoch: 24.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9953326499818465		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 5.9953326499818465 | validation: 5.921426291300988]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.944478079917139		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 5.944478079917139 | validation: 5.825767964043179]
	TIME [epoch: 24.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.829600614098865		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 5.829600614098865 | validation: 5.7820391673378255]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.937870705551251		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 5.937870705551251 | validation: 5.784891164614473]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9006369232023825		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 5.9006369232023825 | validation: 5.922890512867371]
	TIME [epoch: 24.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.854933216988008		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 5.854933216988008 | validation: 5.879604580633965]
	TIME [epoch: 25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.881306256336767		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 5.881306256336767 | validation: 5.856673079738442]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.797345506320877		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 5.797345506320877 | validation: 5.843438202666739]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8723649394713355		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 5.8723649394713355 | validation: 5.888732966038626]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.916902118372121		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 5.916902118372121 | validation: 5.81607171048116]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8087121997235425		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 5.8087121997235425 | validation: 5.961001099250855]
	TIME [epoch: 24.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.923367331268994		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 5.923367331268994 | validation: 5.917032809060641]
	TIME [epoch: 24.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.839959619515008		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 5.839959619515008 | validation: 6.391793859825886]
	TIME [epoch: 24.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.960606970449485		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 5.960606970449485 | validation: 5.851415867278996]
	TIME [epoch: 24.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.877294370943243		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 5.877294370943243 | validation: 5.868109050386592]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8404577933106285		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 5.8404577933106285 | validation: 5.821282559067513]
	TIME [epoch: 24.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.865802053245163		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 5.865802053245163 | validation: 5.804253645364042]
	TIME [epoch: 24.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.881039559763212		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 5.881039559763212 | validation: 5.910371300038232]
	TIME [epoch: 24.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.847080870818803		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 5.847080870818803 | validation: 5.767923124224633]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859208825303874		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 5.859208825303874 | validation: 6.19970570647324]
	TIME [epoch: 24.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.063168606733566		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 6.063168606733566 | validation: 5.970102165054849]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8877594644489015		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 5.8877594644489015 | validation: 5.879252884138161]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815899118945199		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 5.815899118945199 | validation: 5.975798302742009]
	TIME [epoch: 24.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8519480201554135		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 5.8519480201554135 | validation: 6.206090442295331]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.92154275455278		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 5.92154275455278 | validation: 6.148555218548231]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.924858940629221		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 5.924858940629221 | validation: 6.3936022497496285]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.035917789231054		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 6.035917789231054 | validation: 5.866475600096131]
	TIME [epoch: 24.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8717230196220225		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 5.8717230196220225 | validation: 5.900409469530472]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927232772831196		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 5.927232772831196 | validation: 5.894643601393166]
	TIME [epoch: 24.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838046371649664		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 5.838046371649664 | validation: 5.798193538683136]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.821141679994424		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 5.821141679994424 | validation: 5.829656121023294]
	TIME [epoch: 24.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.814377117210626		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 5.814377117210626 | validation: 6.773838079281502]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.115398632277664		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 6.115398632277664 | validation: 5.890628179700815]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.824047846547512		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 5.824047846547512 | validation: 5.798723101876867]
	TIME [epoch: 24.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.848205025335691		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 5.848205025335691 | validation: 6.019584892349187]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.889803359667226		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 5.889803359667226 | validation: 5.822980941321139]
	TIME [epoch: 25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815440312753626		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 5.815440312753626 | validation: 5.821085273181626]
	TIME [epoch: 24.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8659455081244065		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 5.8659455081244065 | validation: 5.823378986792773]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9710883380454485		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 5.9710883380454485 | validation: 5.929333778939617]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.93805719614296		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 5.93805719614296 | validation: 5.831132410780581]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852804064712824		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 5.852804064712824 | validation: 5.862783639736166]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.996238520799031		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 5.996238520799031 | validation: 5.875148843901894]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.796952413787908		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 5.796952413787908 | validation: 5.844944179160912]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.948074351565235		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 5.948074351565235 | validation: 5.814681173820134]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.822422194192915		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 5.822422194192915 | validation: 5.863673026860075]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.865690736834912		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 5.865690736834912 | validation: 6.153357324404074]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.915376965246075		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 5.915376965246075 | validation: 5.805684918684197]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7804416529384195		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 5.7804416529384195 | validation: 5.787697177878523]
	TIME [epoch: 25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.793434781034913		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 5.793434781034913 | validation: 5.9553496313042755]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.92123370821444		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 5.92123370821444 | validation: 5.813087893764296]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.92176822943114		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 5.92176822943114 | validation: 5.896640705640136]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.827443924567316		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 5.827443924567316 | validation: 6.028449229905309]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879494479844389		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 5.879494479844389 | validation: 5.785219250812412]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815925295213284		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 5.815925295213284 | validation: 5.773851284311048]
	TIME [epoch: 24.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750375928452844		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 5.750375928452844 | validation: 5.75707665277478]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.802466804519247		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 5.802466804519247 | validation: 6.305906446661972]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.044782859204558		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 6.044782859204558 | validation: 5.848340034847626]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.010413277873224		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 6.010413277873224 | validation: 5.797511553045584]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.826150297146535		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 5.826150297146535 | validation: 5.787498045300793]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.860633287068746		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 5.860633287068746 | validation: 5.795531232171505]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.872913803814156		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 5.872913803814156 | validation: 5.774065412009025]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.900029096297778		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 5.900029096297778 | validation: 5.757057288257895]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.806447700682475		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 5.806447700682475 | validation: 5.804146370386418]
	TIME [epoch: 24.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.895859660566072		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 5.895859660566072 | validation: 5.8345739800201635]
	TIME [epoch: 24.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.853112688664884		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 5.853112688664884 | validation: 5.846087859632319]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.83777712099806		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 5.83777712099806 | validation: 5.800288146182984]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782178300286151		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 5.782178300286151 | validation: 5.823561508855428]
	TIME [epoch: 24.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.806558053056735		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 5.806558053056735 | validation: 5.828639560945312]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.859155052933796		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 5.859155052933796 | validation: 5.9835125927462585]
	TIME [epoch: 24.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.116819623097833		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 6.116819623097833 | validation: 6.370107336013811]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.211528998874224		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 6.211528998874224 | validation: 6.520838095664029]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.374823208924624		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 6.374823208924624 | validation: 6.453875237688919]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.270176290631464		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 6.270176290631464 | validation: 6.422709259891923]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.469848646847038		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 6.469848646847038 | validation: 6.27989414354045]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.162577796425458		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 6.162577796425458 | validation: 6.272855992565187]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.26885584557294		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 6.26885584557294 | validation: 6.391167489804457]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.106399303962943		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 6.106399303962943 | validation: 5.925860364829784]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9285158308656865		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 5.9285158308656865 | validation: 5.9502638344984495]
	TIME [epoch: 25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.483333689735595		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 6.483333689735595 | validation: 6.517725027364559]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.667475488757498		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 6.667475488757498 | validation: 6.495950726676597]
	TIME [epoch: 25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.656342306173364		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 6.656342306173364 | validation: 6.510435517018471]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.640847316621224		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 6.640847316621224 | validation: 6.507842457145639]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.638798700164369		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 6.638798700164369 | validation: 6.650961104740998]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7724092362219075		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 6.7724092362219075 | validation: 6.5617364283249575]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.670491555135772		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 6.670491555135772 | validation: 6.508742763640409]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6830686106525405		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 6.6830686106525405 | validation: 6.605015548888517]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.670720868832349		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 6.670720868832349 | validation: 6.455703033315939]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.616219493383946		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 6.616219493383946 | validation: 6.614297076495385]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.985447844205968		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 6.985447844205968 | validation: 6.581895590505233]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.794395070824905		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 6.794395070824905 | validation: 6.617527114687698]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.75227603119937		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 6.75227603119937 | validation: 6.495392519506666]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.901350901036784		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 6.901350901036784 | validation: 6.631259264454159]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7745495937929885		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 6.7745495937929885 | validation: 6.64864456524994]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.799203961155789		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 6.799203961155789 | validation: 6.52387903217376]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.752229850794523		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 6.752229850794523 | validation: 6.662858213151515]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.752901282500739		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 6.752901282500739 | validation: 6.5815147603864625]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.71715839110553		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 6.71715839110553 | validation: 6.47056567980106]
	TIME [epoch: 24.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.684298557209145		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 6.684298557209145 | validation: 6.933576389324326]
	TIME [epoch: 25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.969587316226588		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 6.969587316226588 | validation: 6.598878560424407]
	TIME [epoch: 25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8287092611111735		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 6.8287092611111735 | validation: 6.640060831755143]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.020097968405909		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 7.020097968405909 | validation: 6.804790512165027]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.893800528112249		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 6.893800528112249 | validation: 6.596737326499603]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.768910281133247		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 6.768910281133247 | validation: 6.590701544249422]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.869674194597202		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 6.869674194597202 | validation: 7.569857427042603]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.068520771530029		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 7.068520771530029 | validation: 6.54308656869767]
	TIME [epoch: 25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.740872049372566		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 6.740872049372566 | validation: 6.747157475054819]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.760482112735571		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 6.760482112735571 | validation: 6.461491466069997]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.791927502517682		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 6.791927502517682 | validation: 6.455687652185876]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.735517100308321		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 6.735517100308321 | validation: 6.396845733974081]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.934422961511341		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 6.934422961511341 | validation: 6.578690460374153]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921616469316279		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 5.921616469316279 | validation: 4.670599108569104]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.52513580226205		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.52513580226205 | validation: 2.587755523765863]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6748292742378688		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.6748292742378688 | validation: 2.093311463136862]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6181056161373224		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.6181056161373224 | validation: 2.1131961298391335]
	TIME [epoch: 24.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.640495172772476		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.640495172772476 | validation: 2.093282781834022]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2936601091410687		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.2936601091410687 | validation: 2.403944089681506]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6096115471640617		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.6096115471640617 | validation: 2.401267780841172]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3682543480070715		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.3682543480070715 | validation: 1.8188327630584167]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9991187258774419		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.9991187258774419 | validation: 1.6181432085230365]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0783837161931205		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.0783837161931205 | validation: 1.6189576529225322]
	TIME [epoch: 25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0211876294356306		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.0211876294356306 | validation: 1.9586342576617057]
	TIME [epoch: 24.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9153974556388107		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.9153974556388107 | validation: 1.8133745289925223]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8663858073434252		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.8663858073434252 | validation: 1.8239619619099943]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036586711135649		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.036586711135649 | validation: 2.7774180110751714]
	TIME [epoch: 24.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5323278467324233		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.5323278467324233 | validation: 1.9217683231430784]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.798268708060205		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.798268708060205 | validation: 1.7135531266276254]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8375302667010742		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.8375302667010742 | validation: 1.487767327042651]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.964279625417094		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.964279625417094 | validation: 2.8501447720622934]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098167153172709		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.098167153172709 | validation: 1.9913869227802485]
	TIME [epoch: 24.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.936836336203919		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.936836336203919 | validation: 1.6139739848326278]
	TIME [epoch: 24.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5251810607721548		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.5251810607721548 | validation: 1.7374346157015834]
	TIME [epoch: 24.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.704063578841912		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.704063578841912 | validation: 1.7059944566440017]
	TIME [epoch: 25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5540342769039257		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.5540342769039257 | validation: 1.3228246182892809]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.39660837401753		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.39660837401753 | validation: 1.4325922044419628]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.872934550930749		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.872934550930749 | validation: 1.7654717152267745]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.533722865603828		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.533722865603828 | validation: 1.686615974515608]
	TIME [epoch: 24.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3647454037430014		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.3647454037430014 | validation: 4.019790932384758]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5674478337529796		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.5674478337529796 | validation: 1.8491526550104431]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5035265385858052		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.5035265385858052 | validation: 1.5502117900362107]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6746194190201913		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.6746194190201913 | validation: 1.8391183657561454]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4907451430130465		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.4907451430130465 | validation: 3.750690868456103]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4549686230624856		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.4549686230624856 | validation: 1.3618547329378796]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6216211889429588		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.6216211889429588 | validation: 1.6844783621067376]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4582725904351501		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.4582725904351501 | validation: 1.3346209315949198]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4645669328201014		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.4645669328201014 | validation: 1.1915109414020224]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6118072812314423		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.6118072812314423 | validation: 2.4179448104013543]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9458253120086917		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.9458253120086917 | validation: 1.6837838860836747]
	TIME [epoch: 24.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4807991903556206		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.4807991903556206 | validation: 1.5252831843306913]
	TIME [epoch: 24.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5714790014473596		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.5714790014473596 | validation: 1.7675461273694055]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4610077096408314		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.4610077096408314 | validation: 1.2953010531295073]
	TIME [epoch: 24.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5563036751381993		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.5563036751381993 | validation: 1.6684937476740476]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5990589664606945		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.5990589664606945 | validation: 1.4611440940935034]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6671136417187273		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.6671136417187273 | validation: 1.8621400395683743]
	TIME [epoch: 24.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5233886491112463		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.5233886491112463 | validation: 1.2421128912233905]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.446868986903391		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.446868986903391 | validation: 1.2944823480108645]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6770770104249186		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.6770770104249186 | validation: 1.4767501250510018]
	TIME [epoch: 24.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3621601992511474		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.3621601992511474 | validation: 1.1969452107634817]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3430776268609899		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.3430776268609899 | validation: 1.136793450349313]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3100896413576981		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.3100896413576981 | validation: 2.0787416750815546]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7644171026639062		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.7644171026639062 | validation: 1.3655922212762714]
	TIME [epoch: 24.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4343080544599252		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.4343080544599252 | validation: 2.0983174171340564]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9574166509030606		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.9574166509030606 | validation: 1.9815852239099234]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7674847235607756		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.7674847235607756 | validation: 1.5214674680258804]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5751660911094612		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.5751660911094612 | validation: 1.5535324966519728]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4515753305231462		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.4515753305231462 | validation: 1.408327960359199]
	TIME [epoch: 24.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.57642629357778		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.57642629357778 | validation: 1.462060444149018]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6718782000034125		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.6718782000034125 | validation: 1.316032616772278]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093207108956149		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 2.093207108956149 | validation: 2.2504440047205856]
	TIME [epoch: 24.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9652035700670862		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.9652035700670862 | validation: 2.6780453245262965]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3630975175162248		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 2.3630975175162248 | validation: 1.3348450850010232]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7115156832902874		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.7115156832902874 | validation: 1.791475287769668]
	TIME [epoch: 24.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7433675933049884		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.7433675933049884 | validation: 1.5961357022212246]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.537298931649118		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.537298931649118 | validation: 1.2159878261085262]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3220967555864758		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.3220967555864758 | validation: 1.303322929199209]
	TIME [epoch: 24.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4211522310015565		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.4211522310015565 | validation: 1.406097628216907]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5371513460116044		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.5371513460116044 | validation: 1.3996841965834506]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3474195042642383		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.3474195042642383 | validation: 1.1576360440786522]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7323508300615964		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.7323508300615964 | validation: 1.3590453759134014]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2496024146313462		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.2496024146313462 | validation: 2.781518832522993]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8370708498173067		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.8370708498173067 | validation: 1.227193165057745]
	TIME [epoch: 24.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3660157489700058		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.3660157489700058 | validation: 1.2495066808458604]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4812360085222749		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.4812360085222749 | validation: 1.882230874822215]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3589158531374423		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.3589158531374423 | validation: 1.9479926247737038]
	TIME [epoch: 24.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5658789870062686		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.5658789870062686 | validation: 1.5272852226842861]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6741361849204581		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.6741361849204581 | validation: 1.7330325496358063]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8185822119430588		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.8185822119430588 | validation: 2.879089340380215]
	TIME [epoch: 24.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2027324229334675		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.2027324229334675 | validation: 1.7324862199366409]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.876721459756527		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.876721459756527 | validation: 2.0672511005715646]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7320592015445677		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.7320592015445677 | validation: 1.70096705895897]
	TIME [epoch: 24.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.495264636087371		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.495264636087371 | validation: 1.665371523036351]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.276681344640655		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 2.276681344640655 | validation: 1.2306033253656856]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3931826479962286		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.3931826479962286 | validation: 1.3423890584299876]
	TIME [epoch: 24.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4517981471691788		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.4517981471691788 | validation: 1.3025126500424369]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5988997429382499		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.5988997429382499 | validation: 1.174997720811849]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.499070343539627		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.499070343539627 | validation: 1.579592176351324]
	TIME [epoch: 24.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2967394683160258		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.2967394683160258 | validation: 1.115124658442842]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4388216119176633		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.4388216119176633 | validation: 1.4817132302791851]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3529281607544394		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.3529281607544394 | validation: 1.2312741113789698]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2395247458926522		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.2395247458926522 | validation: 1.2958289760886579]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.528194599709593		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.528194599709593 | validation: 1.9661031518267162]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.504987013597287		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.504987013597287 | validation: 1.4525779214837047]
	TIME [epoch: 24.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.28959092288805		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.28959092288805 | validation: 1.0469472819516186]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1626072049588396		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.1626072049588396 | validation: 1.048795298280191]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2288230487697662		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.2288230487697662 | validation: 1.513850439264683]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.207049506337056		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.207049506337056 | validation: 1.097405620100203]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.717836401456523		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.717836401456523 | validation: 1.376655521153793]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.202036976763808		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.202036976763808 | validation: 1.2987138471570636]
	TIME [epoch: 24.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239589165808855		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.239589165808855 | validation: 1.127211178500766]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6432530929724285		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.6432530929724285 | validation: 1.3787380980799253]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3564986009495927		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.3564986009495927 | validation: 2.1661794700279446]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.587397349030341		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.587397349030341 | validation: 1.3296891061993639]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7937488808197428		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.7937488808197428 | validation: 1.6787789171134262]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5255297655329518		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.5255297655329518 | validation: 1.3314116439098915]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4633208429508755		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.4633208429508755 | validation: 1.358892542974526]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3117713146052772		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.3117713146052772 | validation: 1.3887850026011253]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2470748711948725		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.2470748711948725 | validation: 1.077279706181956]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1766744227163717		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.1766744227163717 | validation: 1.0697995800579814]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6222173858628253		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.6222173858628253 | validation: 2.1285137002576717]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8151794020760736		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.8151794020760736 | validation: 1.2125015434037116]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2875653280015202		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.2875653280015202 | validation: 1.2532763916527854]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.512298392633729		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.512298392633729 | validation: 1.1810694053542212]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4262907894544652		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.4262907894544652 | validation: 1.5044718369388057]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4286061149489067		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 2.4286061149489067 | validation: 1.1460108587636604]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5094051931562933		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.5094051931562933 | validation: 1.1625164291914347]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2612616330572162		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.2612616330572162 | validation: 1.0525679328925108]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2493017361757934		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.2493017361757934 | validation: 1.5499395334348005]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3891834491947341		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.3891834491947341 | validation: 1.8034795632460339]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7044221396223493		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.7044221396223493 | validation: 1.5341682518371664]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3421818287141634		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.3421818287141634 | validation: 1.5176669180396811]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3858221308368246		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.3858221308368246 | validation: 1.4281793472408846]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2932045237744871		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.2932045237744871 | validation: 1.5337680620070695]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3658847529520324		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.3658847529520324 | validation: 1.6307643147017807]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2809357335975273		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.2809357335975273 | validation: 1.7139579973145862]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4119245415346506		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.4119245415346506 | validation: 1.1894495741941997]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2198886813148893		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.2198886813148893 | validation: 1.130943533533787]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2868958364239953		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.2868958364239953 | validation: 1.211538413009446]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3059544177521247		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3059544177521247 | validation: 1.5861443440413387]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5302150493914533		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.5302150493914533 | validation: 1.1045623186143576]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1859049229895706		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.1859049229895706 | validation: 1.4002300848760965]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8710544254050865		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.8710544254050865 | validation: 1.3736928786472333]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2960397902805865		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.2960397902805865 | validation: 1.5862697579605287]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2929410016919032		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.2929410016919032 | validation: 1.3623891811610278]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4471811335135303		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.4471811335135303 | validation: 2.212515945738309]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5865717126282224		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.5865717126282224 | validation: 1.0792787929419028]
	TIME [epoch: 24.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161557798642935		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.161557798642935 | validation: 1.1587820347516558]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1496879339435098		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.1496879339435098 | validation: 1.257286993141967]
	TIME [epoch: 24.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.31201098070545		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.31201098070545 | validation: 1.6064175313550835]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3862862717164055		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.3862862717164055 | validation: 1.3161729594405336]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2529394813820907		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.2529394813820907 | validation: 1.1237526601678827]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.164102427239102		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.164102427239102 | validation: 1.3453593344339987]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.382021318091018		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.382021318091018 | validation: 1.445381054320697]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4027165153701704		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.4027165153701704 | validation: 1.1507836841265613]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.224056183558035		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.224056183558035 | validation: 1.6648118404567687]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2490435642877187		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.2490435642877187 | validation: 1.2724102846405516]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2371434790945233		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.2371434790945233 | validation: 1.0600308247152967]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1489425393363408		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.1489425393363408 | validation: 1.0717790436826076]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2223300759015525		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.2223300759015525 | validation: 1.2821150157376757]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1821899323099334		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.1821899323099334 | validation: 1.5856326346720948]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2129469490171558		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.2129469490171558 | validation: 1.3755127050808162]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2499313282910456		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.2499313282910456 | validation: 1.045536484344035]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1741522480678002		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.1741522480678002 | validation: 1.2287293749332897]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1744331514547632		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.1744331514547632 | validation: 1.725069846645407]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.458428991806553		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 2.458428991806553 | validation: 1.4548864571346163]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3304637975540108		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.3304637975540108 | validation: 1.382391508557096]
	TIME [epoch: 24.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8046222752614685		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.8046222752614685 | validation: 1.4062656873425405]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275025427771113		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.275025427771113 | validation: 1.0249935534777594]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1609513835955076		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.1609513835955076 | validation: 1.7071212447428323]
	TIME [epoch: 24.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6718989740102796		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.6718989740102796 | validation: 1.1440821136460118]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6724584326812533		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.6724584326812533 | validation: 1.1389801910597779]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3346312910971343		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.3346312910971343 | validation: 1.836847437680234]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.572425956846106		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.572425956846106 | validation: 1.2328439219213392]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2385771842573736		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.2385771842573736 | validation: 1.6457156259363135]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6728833445971694		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.6728833445971694 | validation: 1.906526578026054]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6457731375426141		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.6457731375426141 | validation: 1.192970725220417]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1699400413076335		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.1699400413076335 | validation: 1.216719073779823]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.618964723840367		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.618964723840367 | validation: 1.7189592947275483]
	TIME [epoch: 24.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3141761880640632		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.3141761880640632 | validation: 1.7413202209274459]
	TIME [epoch: 24.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3737915005151748		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.3737915005151748 | validation: 0.9931811441570025]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4329026080005887		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.4329026080005887 | validation: 1.0931478369341934]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1679314282366806		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.1679314282366806 | validation: 1.656279503740651]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3965384100891036		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.3965384100891036 | validation: 1.336298019910774]
	TIME [epoch: 24.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.463765177322509		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.463765177322509 | validation: 1.3324464765360136]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220075414597888		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.220075414597888 | validation: 1.0773084565917703]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2945016769254536		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.2945016769254536 | validation: 1.4916046064874287]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.747543101411917		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.747543101411917 | validation: 1.1036817140276887]
	TIME [epoch: 24.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2492127627066596		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.2492127627066596 | validation: 1.310472966450389]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.221880507734833		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 1.221880507734833 | validation: 1.073954858300114]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2889078392462492		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.2889078392462492 | validation: 1.2838805534981748]
	TIME [epoch: 24.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1486885714759683		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.1486885714759683 | validation: 1.0759228349586474]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823993799465091		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.1823993799465091 | validation: 1.0763376288254534]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2178763047857646		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.2178763047857646 | validation: 1.4753027427361232]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8057226933586754		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.8057226933586754 | validation: 1.3242944480306773]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420680301713821		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.1420680301713821 | validation: 1.137165021137227]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2396348831226331		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.2396348831226331 | validation: 1.2569443530511526]
	TIME [epoch: 24.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5140826920131119		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.5140826920131119 | validation: 1.084244365385148]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1984638899676177		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.1984638899676177 | validation: 1.0272490903836247]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0871823538007277		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.0871823538007277 | validation: 1.0630113167866844]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0153490499205486		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.0153490499205486 | validation: 1.0424320134758578]
	TIME [epoch: 24.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3426287737398594		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.3426287737398594 | validation: 0.9716428023207027]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2384606885990506		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.2384606885990506 | validation: 1.1746986981345533]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.190936844668316		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.190936844668316 | validation: 1.053175095619522]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1474889434171676		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.1474889434171676 | validation: 1.204243837874932]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1153844259900754		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.1153844259900754 | validation: 0.9323661801426313]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0483697461748183		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.0483697461748183 | validation: 0.9812764559138171]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1805037524636393		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.1805037524636393 | validation: 1.0858269701555843]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3731967899669328		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.3731967899669328 | validation: 1.1675427644929257]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1791863065678971		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.1791863065678971 | validation: 1.1947619172335604]
	TIME [epoch: 24.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3628570705589755		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3628570705589755 | validation: 1.3787009044219074]
	TIME [epoch: 24.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2002784572384426		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 1.2002784572384426 | validation: 1.483776302214277]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3856666124871628		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 1.3856666124871628 | validation: 0.9499533707170358]
	TIME [epoch: 24.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623253643238435		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.0623253643238435 | validation: 0.9609477270756841]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1743301041636285		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.1743301041636285 | validation: 1.3042837350071355]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1747880295503186		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.1747880295503186 | validation: 1.5602154359682257]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1669144588014841		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.1669144588014841 | validation: 1.0163521977457572]
	TIME [epoch: 24.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155630386483324		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.155630386483324 | validation: 1.0386163295176625]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1674263360173969		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.1674263360173969 | validation: 1.021289942043005]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1836589057005704		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.1836589057005704 | validation: 1.3051654886276722]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1894186018350872		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.1894186018350872 | validation: 0.940625442337563]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0874804888679719		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.0874804888679719 | validation: 1.2834509175293303]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.28785845866627		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.28785845866627 | validation: 1.2192317546608546]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152016773244637		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.152016773244637 | validation: 1.6755315193327125]
	TIME [epoch: 24.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5270101638327374		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.5270101638327374 | validation: 1.3109255808808495]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5291002256783508		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.5291002256783508 | validation: 2.493656808339018]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8564776457877552		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 1.8564776457877552 | validation: 1.1671318224823741]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0776625852174897		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.0776625852174897 | validation: 1.0160115988483633]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1545550178931712		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.1545550178931712 | validation: 1.1559150883908058]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1540748341835618		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.1540748341835618 | validation: 0.9682805359201128]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1134142837128496		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.1134142837128496 | validation: 0.9609288638957683]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.367963625955745		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.367963625955745 | validation: 1.7969202736467713]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2610742769571337		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.2610742769571337 | validation: 0.9999580180522583]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2172240508982142		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.2172240508982142 | validation: 1.3084081766863278]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1571944548266435		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 1.1571944548266435 | validation: 0.9932200153473718]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.338943210916203		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.338943210916203 | validation: 1.0738417682566763]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356172905427398		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.356172905427398 | validation: 1.4476611483412187]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174745397868071		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.174745397868071 | validation: 1.0289647883195838]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1895360668531145		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.1895360668531145 | validation: 1.763349029529565]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2680728002616335		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.2680728002616335 | validation: 1.4050990793442655]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3744464363653857		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.3744464363653857 | validation: 1.0470165679749257]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1333213159261626		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.1333213159261626 | validation: 1.0032103189832395]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0856546327560463		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.0856546327560463 | validation: 1.0225293967717786]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9963131130409013		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.9963131130409013 | validation: 0.9955318730777799]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2744389735622033		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.2744389735622033 | validation: 1.0522416685687441]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9940295753089728		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.9940295753089728 | validation: 1.0001811156323317]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0676338029011554		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 1.0676338029011554 | validation: 1.3229979254834996]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292099534424975		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.1292099534424975 | validation: 1.66718947388239]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2635387912825116		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 1.2635387912825116 | validation: 1.0678932984809217]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9845347278200379		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.9845347278200379 | validation: 1.3611755655771751]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1072076087431248		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.1072076087431248 | validation: 0.9076447422798747]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4651152385066646		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 1.4651152385066646 | validation: 1.403018857525092]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1553833425236608		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 1.1553833425236608 | validation: 1.2449513512012214]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1376353564922976		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 1.1376353564922976 | validation: 0.9236886245655282]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0920764858018792		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.0920764858018792 | validation: 0.9123439993886553]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430254715700266		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.9430254715700266 | validation: 1.0714958962591488]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9768856647681184		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.9768856647681184 | validation: 1.160148915127191]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3453153300066818		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.3453153300066818 | validation: 1.4939568917390427]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823281135315256		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.1823281135315256 | validation: 0.8964603982863782]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2482916669291575		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.2482916669291575 | validation: 0.8504316684274517]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0770293860220856		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 1.0770293860220856 | validation: 0.8746821318660469]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4306854918136707		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 1.4306854918136707 | validation: 1.141271355744705]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1807594197182087		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.1807594197182087 | validation: 1.1405847030925378]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0435177858927325		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 1.0435177858927325 | validation: 0.9723522038796597]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1439120587632599		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 1.1439120587632599 | validation: 1.2757800284813225]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3389075138250182		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.3389075138250182 | validation: 2.0580764941424703]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7140090776211392		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 1.7140090776211392 | validation: 0.9634824319560616]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2137476601241042		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 1.2137476601241042 | validation: 0.9334586782889378]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9929252443281227		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.9929252443281227 | validation: 0.9660512262334473]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9506642881174083		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.9506642881174083 | validation: 0.9510856967778878]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.025980904332469		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.025980904332469 | validation: 1.1452394923559848]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866930970882327		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.9866930970882327 | validation: 1.4231425391985766]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2263051314203413		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.2263051314203413 | validation: 0.9637380566621963]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5245290548412642		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.5245290548412642 | validation: 1.1046069354592598]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100036443848293		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 1.100036443848293 | validation: 1.0392582150720069]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.211106711756193		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.211106711756193 | validation: 1.253463953506262]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903321009718125		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.0903321009718125 | validation: 0.9555328882382652]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0294533846952854		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.0294533846952854 | validation: 1.0324085348336325]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9386906902543561		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.9386906902543561 | validation: 1.4684099350756707]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.127285064349762		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.127285064349762 | validation: 0.9722857728701416]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.292195565490098		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 1.292195565490098 | validation: 1.4896929263405554]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1867532406799217		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.1867532406799217 | validation: 0.9730112265543143]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9597161180615956		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.9597161180615956 | validation: 0.9735410954726078]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0113394173896624		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.0113394173896624 | validation: 0.9589130778590702]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9665939936927523		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.9665939936927523 | validation: 0.9321566507780498]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0081629612355076		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 1.0081629612355076 | validation: 1.2706601753149176]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2335656016673777		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 1.2335656016673777 | validation: 1.0046987873273465]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9941617810625514		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9941617810625514 | validation: 1.349104025369092]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.071195067407086		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.071195067407086 | validation: 1.0549678625025707]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0090322366424207		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.0090322366424207 | validation: 1.1566725582220496]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0574455864551704		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.0574455864551704 | validation: 0.9678415917378249]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0833990320951716		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 1.0833990320951716 | validation: 0.9039263916818865]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9397219273291655		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.9397219273291655 | validation: 1.4480835439267987]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4583341206202642		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 1.4583341206202642 | validation: 1.0255527915745548]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9635382572002257		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.9635382572002257 | validation: 0.9325580492235491]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01265886143922		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.01265886143922 | validation: 1.0764993878466016]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9735412849897556		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.9735412849897556 | validation: 1.2020169256995488]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0166640587163887		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.0166640587163887 | validation: 0.8432240768498264]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9323556087480769		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.9323556087480769 | validation: 1.050217730150613]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.224452432901225		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 1.224452432901225 | validation: 1.1109653883942352]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0354697954379848		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.0354697954379848 | validation: 0.9130885524058369]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9551220290366583		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.9551220290366583 | validation: 2.0663801975587734]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3666178668222848		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.3666178668222848 | validation: 0.8929101622853741]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8884575494597449		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.8884575494597449 | validation: 1.1862960009103005]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2149493156553488		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 1.2149493156553488 | validation: 0.9792522876907802]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9423520923932436		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.9423520923932436 | validation: 1.2091916131947533]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1379442319956272		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.1379442319956272 | validation: 0.9510882221622038]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0382541151113065		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 1.0382541151113065 | validation: 0.9882637395516707]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4152216170002736		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 1.4152216170002736 | validation: 0.9827988814313358]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0775043741907617		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 1.0775043741907617 | validation: 1.651260989532087]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0904659797585832		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.0904659797585832 | validation: 0.910182473307135]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0120173336257652		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 1.0120173336257652 | validation: 0.9844992529786291]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590193831504047		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.0590193831504047 | validation: 1.0531767898113513]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.061470303553224		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 1.061470303553224 | validation: 1.0338311013168004]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0517794020880253		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 1.0517794020880253 | validation: 0.9165978170701885]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0588771059472522		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 1.0588771059472522 | validation: 1.3525407861072782]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878178698660742		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.9878178698660742 | validation: 1.0697420403821192]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0627646297338598		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.0627646297338598 | validation: 1.5246517812243705]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.334446223158689		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.334446223158689 | validation: 1.401098255875139]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3557767211445246		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 1.3557767211445246 | validation: 1.7271637459903944]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1680675377580787		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.1680675377580787 | validation: 0.9223036480256102]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0811643887007225		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.0811643887007225 | validation: 1.1832276608397987]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.398002541057688		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 1.398002541057688 | validation: 0.8806315938836804]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8908371678391575		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.8908371678391575 | validation: 1.0264647526392678]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8830092557296119		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.8830092557296119 | validation: 1.0532710990977767]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8668640948008475		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.8668640948008475 | validation: 0.8036148145631498]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_595.pth
	Model improved!!!
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9308142908180264		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.9308142908180264 | validation: 0.7972195049504065]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9109172399808337		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.9109172399808337 | validation: 1.193750023487889]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265955857477154		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.0265955857477154 | validation: 1.5774436419026132]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0653256668940847		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.0653256668940847 | validation: 1.047362970074448]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9673594337186183		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.9673594337186183 | validation: 1.068349367007086]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0903662431326846		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.0903662431326846 | validation: 0.9612591021055247]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9532677879131074		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.9532677879131074 | validation: 0.9711589263915906]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9186914469036274		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.9186914469036274 | validation: 1.9164470664944078]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292515965773877		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 1.1292515965773877 | validation: 0.9145178415848186]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8998654125510761		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.8998654125510761 | validation: 0.9839076896342291]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054912930624673		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.054912930624673 | validation: 1.0554596505339793]
	TIME [epoch: 24.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9626653671713321		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.9626653671713321 | validation: 0.7714582405425279]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_607.pth
	Model improved!!!
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0917222083919758		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 1.0917222083919758 | validation: 0.9396836999551107]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8388711346792915		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.8388711346792915 | validation: 0.858529152832149]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705801131251058		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 1.0705801131251058 | validation: 0.8325221049520033]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9002272850474584		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.9002272850474584 | validation: 0.9412241379647354]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13838154117029		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 1.13838154117029 | validation: 1.3037979337445031]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.01989995337506		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 1.01989995337506 | validation: 1.0421406347625868]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9815118626023523		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.9815118626023523 | validation: 1.4107399657244828]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552070655721055		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.0552070655721055 | validation: 1.2894651389614515]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3229008766499688		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.3229008766499688 | validation: 0.8611994263417738]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9248338110561266		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.9248338110561266 | validation: 1.5470170276103523]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1753393866745232		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 1.1753393866745232 | validation: 0.8130726690098264]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9242767682707052		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.9242767682707052 | validation: 0.951829423735801]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9563023268417296		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.9563023268417296 | validation: 1.078595506648386]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.985652861330171		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.985652861330171 | validation: 0.8923527798276549]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8329381053434428		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.8329381053434428 | validation: 0.8757779695306457]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902610791690563		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 1.0902610791690563 | validation: 0.7564343277677243]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_623.pth
	Model improved!!!
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2205427722923603		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.2205427722923603 | validation: 0.924640245533964]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995852776695881		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.8995852776695881 | validation: 1.2432497865710859]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0106053393661483		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 1.0106053393661483 | validation: 0.89031537172894]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253966156495864		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.8253966156495864 | validation: 0.9054359937172132]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.144445496868595		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.144445496868595 | validation: 0.9686650098400383]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851395259773638		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.8851395259773638 | validation: 0.88854965935426]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0040844764577905		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.0040844764577905 | validation: 0.9369634659436031]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8314320070794035		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.8314320070794035 | validation: 0.871246831997405]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8853235548374767		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.8853235548374767 | validation: 0.9649618364465539]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.867953767072287		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.867953767072287 | validation: 1.0065587597102736]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8494676937651496		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.8494676937651496 | validation: 0.8039173568419508]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8769764632172334		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.8769764632172334 | validation: 0.8454179421342621]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9263221927933838		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.9263221927933838 | validation: 0.8263907721435778]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240378649097714		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.0240378649097714 | validation: 1.0957326601393473]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501866051623876		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 1.0501866051623876 | validation: 1.2354233742028347]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1960120519105417		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.1960120519105417 | validation: 1.059326511347193]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9086240436996363		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.9086240436996363 | validation: 0.8223489203907249]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8350668909894414		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.8350668909894414 | validation: 0.7899070874169631]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8916604463000726		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.8916604463000726 | validation: 0.8067838898620232]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532395906108221		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.8532395906108221 | validation: 0.8215018891813187]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9420557469541037		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.9420557469541037 | validation: 0.9450579728768557]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0270679116642452		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.0270679116642452 | validation: 0.7973200634359107]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8381077103528547		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.8381077103528547 | validation: 0.9637690368198963]
	TIME [epoch: 25 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0743357318851343		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 1.0743357318851343 | validation: 1.4508681011574374]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0905097887185127		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.0905097887185127 | validation: 0.8766959433601654]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0453308649439799		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.0453308649439799 | validation: 1.2325677964701987]
	TIME [epoch: 25 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9312497578011436		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.9312497578011436 | validation: 0.7903727258972952]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8372173996713507		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.8372173996713507 | validation: 1.0971334143849594]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9722753494235536		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.9722753494235536 | validation: 0.7576235432551027]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8046137784682794		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.8046137784682794 | validation: 1.0306466663849296]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609229084827557		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.8609229084827557 | validation: 0.8059324062303708]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8117564655880337		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.8117564655880337 | validation: 0.7536701515947246]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.817437383137595		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.817437383137595 | validation: 0.7987860936191248]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652634591358344		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.8652634591358344 | validation: 1.0930898086839642]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0450679607127147		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 1.0450679607127147 | validation: 0.8823180867767999]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8651875666012089		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.8651875666012089 | validation: 1.0175845531480878]
	TIME [epoch: 24.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8451421840155712		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.8451421840155712 | validation: 0.8027183896261484]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7591881930459757		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7591881930459757 | validation: 0.7895770706539931]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1129625597703108		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.1129625597703108 | validation: 1.1710277236413453]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9376327873931334		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.9376327873931334 | validation: 1.035610179939124]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1331571355143182		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.1331571355143182 | validation: 1.4966216737271543]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0659576993873607		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.0659576993873607 | validation: 0.7783216098979915]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034675266159148		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 1.0034675266159148 | validation: 1.0949400907581999]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9439110242171949		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.9439110242171949 | validation: 1.348096042753279]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0584658671422695		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 1.0584658671422695 | validation: 0.900912571001369]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8444770381064667		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.8444770381064667 | validation: 1.0396144437356827]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9174835173299863		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.9174835173299863 | validation: 1.1894161256364806]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.897364863695671		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.897364863695671 | validation: 0.8202368335992627]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8751960625406232		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.8751960625406232 | validation: 0.7659568469352973]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8312435050002638		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.8312435050002638 | validation: 0.8043671702143833]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0478006843743106		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 1.0478006843743106 | validation: 1.2196583321254713]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9221787800521273		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.9221787800521273 | validation: 1.190739678369331]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0797935681386184		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 1.0797935681386184 | validation: 0.7767532923265177]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8247997009778277		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.8247997009778277 | validation: 0.8650882390361762]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8450619728723535		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.8450619728723535 | validation: 0.8225613286233522]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.864157067197338		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.864157067197338 | validation: 1.0805870211939281]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8219298964010001		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.8219298964010001 | validation: 0.8116938356058075]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8775226539286611		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.8775226539286611 | validation: 1.0356031469257192]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8350933438940753		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.8350933438940753 | validation: 1.0266892573158883]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1768724805653026		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 1.1768724805653026 | validation: 0.7575968809365197]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9844065344916859		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.9844065344916859 | validation: 0.9100581771297873]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374122266657767		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.9374122266657767 | validation: 0.9109091968659854]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9610523549109107		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.9610523549109107 | validation: 1.3591746359455]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0114829403826469		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 1.0114829403826469 | validation: 0.7448638043413394]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_687.pth
	Model improved!!!
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.782831644679755		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.782831644679755 | validation: 0.795811923175188]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7939959122997455		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.7939959122997455 | validation: 0.8763198931353452]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8677364951701125		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.8677364951701125 | validation: 0.9442195848752762]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9100490435539035		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.9100490435539035 | validation: 0.8507652116909864]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0123229932828564		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 1.0123229932828564 | validation: 0.9255301587396172]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9246597747585253		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.9246597747585253 | validation: 0.7765069697563051]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152860097398322		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.8152860097398322 | validation: 0.8603209599152575]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8417032835662726		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.8417032835662726 | validation: 0.8070644125114607]
	TIME [epoch: 24.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7958796810157516		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.7958796810157516 | validation: 0.8211584910408783]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8305334265411657		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.8305334265411657 | validation: 0.7569535784235304]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8000619190271016		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.8000619190271016 | validation: 1.062410962583095]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9404843162144515		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.9404843162144515 | validation: 0.8033560488045118]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8834387719600586		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.8834387719600586 | validation: 0.8975682255480233]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818537423130588		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.818537423130588 | validation: 0.7528676586171875]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7772777498814107		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.7772777498814107 | validation: 0.7672517000820179]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295331696967952		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.8295331696967952 | validation: 0.7384347597760929]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085355961313693		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.8085355961313693 | validation: 0.8230102431688769]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.839990277599433		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.839990277599433 | validation: 0.9184970013525193]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755900070105807		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.8755900070105807 | validation: 1.0939151190485488]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.893810862069979		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.893810862069979 | validation: 1.046838526341698]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9144489924619488		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.9144489924619488 | validation: 0.9462076544547401]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182710423241478		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.8182710423241478 | validation: 0.8986964187080261]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708978761764029		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.7708978761764029 | validation: 0.8334692408245237]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8022226313989625		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.8022226313989625 | validation: 0.9460947040903557]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9524208392858612		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.9524208392858612 | validation: 1.0771848001017281]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8348386007889215		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.8348386007889215 | validation: 0.7576417961861475]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8590227542042288		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.8590227542042288 | validation: 0.7596902510718705]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8315565645392238		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.8315565645392238 | validation: 1.0333775760790715]
	TIME [epoch: 25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8727241406295064		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.8727241406295064 | validation: 0.87440263669889]
	TIME [epoch: 24.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9191331094919222		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.9191331094919222 | validation: 0.7372684525624891]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_717.pth
	Model improved!!!
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7789904134095538		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.7789904134095538 | validation: 0.8554832808496141]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8276408482887716		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.8276408482887716 | validation: 0.8510282181240658]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8116938096572713		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.8116938096572713 | validation: 0.8463942936735211]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8159864996073858		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.8159864996073858 | validation: 1.1709947750148566]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9459522241759384		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.9459522241759384 | validation: 0.7602567022478592]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8424356698471944		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.8424356698471944 | validation: 0.7472461541669557]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8004182250221566		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.8004182250221566 | validation: 0.6886571358344731]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_724.pth
	Model improved!!!
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336426031405789		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.7336426031405789 | validation: 0.8065307821279751]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837142484974975		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.7837142484974975 | validation: 0.754328004882845]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428134562740204		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.7428134562740204 | validation: 1.2047348232187265]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9583559700459453		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.9583559700459453 | validation: 0.8019859728907368]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8347230034261123		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.8347230034261123 | validation: 0.7901659061391442]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820424066706068		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.820424066706068 | validation: 0.7678812716246012]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9516005819854484		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.9516005819854484 | validation: 0.7219811657084643]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670202924909385		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.7670202924909385 | validation: 0.8516617739191636]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8190682078495612		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.8190682078495612 | validation: 0.7310508117787177]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105302899410894		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.8105302899410894 | validation: 0.6737521506851237]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577720300006252		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.7577720300006252 | validation: 0.7629004174536366]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7936074940384819		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.7936074940384819 | validation: 0.8666851194551669]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212396675148323		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.8212396675148323 | validation: 0.8464375791336985]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7536937501207098		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.7536937501207098 | validation: 1.0871213731082068]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790160865277072		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.8790160865277072 | validation: 0.7375332607919484]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7707620907249242		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.7707620907249242 | validation: 0.8579855206161275]
	TIME [epoch: 24.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9667481839580183		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.9667481839580183 | validation: 1.0593029859956797]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215342429334059		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.8215342429334059 | validation: 0.983876088882604]
	TIME [epoch: 24.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7859495890555199		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.7859495890555199 | validation: 0.7459780639002105]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8374741922372203		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.8374741922372203 | validation: 0.796007517227229]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218585978385074		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.7218585978385074 | validation: 0.7000806282739818]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7310617963868798		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.7310617963868798 | validation: 0.7768454410846707]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7663662194016356		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.7663662194016356 | validation: 0.6789934149059588]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7457104384452646		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.7457104384452646 | validation: 0.6679905907866825]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7288287063012611		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.7288287063012611 | validation: 0.7579759963434697]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564501858510129		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.7564501858510129 | validation: 0.6495751000268026]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7969540792556361		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.7969540792556361 | validation: 0.7821649441004584]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8338140382357867		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.8338140382357867 | validation: 0.9097899342524224]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8614490593028119		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.8614490593028119 | validation: 0.9406829763168695]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0518934501054935		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 1.0518934501054935 | validation: 1.378244520919416]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9463536663782822		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.9463536663782822 | validation: 0.7444226062335896]
	TIME [epoch: 24.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345237147096357		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.7345237147096357 | validation: 0.7018066752028768]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739987413139356		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.739987413139356 | validation: 0.8014655266763783]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8352376151101975		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.8352376151101975 | validation: 0.7664690092383636]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7621113438365925		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.7621113438365925 | validation: 0.8814276701224746]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881102963951736		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.7881102963951736 | validation: 0.8107513694598285]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324169119817349		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.7324169119817349 | validation: 0.8214070542211492]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953620779906243		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.8953620779906243 | validation: 1.2153120180644543]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215262857433676		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.8215262857433676 | validation: 0.8324633023786268]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128733171232162		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.8128733171232162 | validation: 0.9340999312237739]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.967353929172214		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.967353929172214 | validation: 0.9925726256078278]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8375534171503316		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.8375534171503316 | validation: 0.8733875252843649]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0639615583957618		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 1.0639615583957618 | validation: 1.5424185657109855]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606126428071334		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 1.0606126428071334 | validation: 2.018953964189643]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3940556702140217		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 1.3940556702140217 | validation: 0.7386826016229014]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7972835361766233		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.7972835361766233 | validation: 1.018942519145556]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7765331469232927		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.7765331469232927 | validation: 0.6560158018149254]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7318731237700704		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.7318731237700704 | validation: 0.7716525812064238]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282248643476561		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.7282248643476561 | validation: 0.8958384165881463]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7371032074378997		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.7371032074378997 | validation: 0.7070886322909792]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919696301003618		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.6919696301003618 | validation: 0.7093473772680511]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9731541541735045		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.9731541541735045 | validation: 0.7746782965797587]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.877352385457463		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.877352385457463 | validation: 0.7689014325169956]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7843676001822574		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.7843676001822574 | validation: 0.6307692266955038]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_778.pth
	Model improved!!!
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7088642637696522		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.7088642637696522 | validation: 0.6869022916284768]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120743458103214		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.7120743458103214 | validation: 0.6871895070207044]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947190669078441		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.6947190669078441 | validation: 1.175940938265494]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8584525546345471		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.8584525546345471 | validation: 0.655032756029543]
	TIME [epoch: 24.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6856764140733798		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.6856764140733798 | validation: 0.679706446239132]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876357530321547		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.876357530321547 | validation: 0.6512533847160186]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7807217093002279		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.7807217093002279 | validation: 0.8615873547575705]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8334378784871577		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.8334378784871577 | validation: 0.6615666171034666]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8654801908883145		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.8654801908883145 | validation: 0.6779389838057567]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7274004343404228		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.7274004343404228 | validation: 0.8425067853021722]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7639732271197109		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.7639732271197109 | validation: 0.7695712289631275]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8664637504087075		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.8664637504087075 | validation: 0.8756323254359384]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660705027091349		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.7660705027091349 | validation: 0.8037730900591644]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048388562467317		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.8048388562467317 | validation: 0.6402696580696884]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6921277948565584		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.6921277948565584 | validation: 0.6552993667644816]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576594886979972		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.7576594886979972 | validation: 0.6703420114371531]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8593802834120614		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.8593802834120614 | validation: 0.8591399905586456]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8110808495491901		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.8110808495491901 | validation: 0.6956551219598041]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7122444929021755		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.7122444929021755 | validation: 0.8424771747972993]
	TIME [epoch: 24.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7301907376264692		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.7301907376264692 | validation: 0.8294045690717363]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.734884207397771		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.734884207397771 | validation: 0.72487918866577]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7276852469270636		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.7276852469270636 | validation: 0.6584926546520161]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475957942024686		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.7475957942024686 | validation: 0.8984072206109872]
	TIME [epoch: 24.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7651034571862046		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.7651034571862046 | validation: 0.6674584153290598]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529552537981185		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.6529552537981185 | validation: 0.6994607434575976]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8631666277888078		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.8631666277888078 | validation: 0.9613212545232337]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8169065179327715		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.8169065179327715 | validation: 0.6297369331341047]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7181635970471254		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.7181635970471254 | validation: 0.7181632458930791]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8040399513146951		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.8040399513146951 | validation: 0.7580631614527229]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7502139180691968		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.7502139180691968 | validation: 0.8333625013302627]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7503818974872404		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.7503818974872404 | validation: 1.21847837214465]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9581942010555083		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.9581942010555083 | validation: 0.7112961970851535]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222258764054615		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.7222258764054615 | validation: 0.7152739184504411]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.747020476724677		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.747020476724677 | validation: 0.8228058476572945]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004667449805471		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.7004667449805471 | validation: 0.6531935505282382]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6854949910688677		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.6854949910688677 | validation: 0.7427571969288147]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109050531690962		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.7109050531690962 | validation: 1.212505574774252]
	TIME [epoch: 24.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8801724091642074		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.8801724091642074 | validation: 0.7157669976478503]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72198139152781		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.72198139152781 | validation: 0.6933106739856788]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.778216075253876		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.778216075253876 | validation: 0.6539947997196195]
	TIME [epoch: 24.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272155668384852		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.7272155668384852 | validation: 0.7895761137346696]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709296999116296		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.709296999116296 | validation: 0.6747345417626494]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909039697403547		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.6909039697403547 | validation: 0.8592099379145107]
	TIME [epoch: 24.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7638961357087138		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.7638961357087138 | validation: 0.6954987853663062]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6936291479629554		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.6936291479629554 | validation: 0.6446900120196984]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391097697396005		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.7391097697396005 | validation: 0.6801779880986935]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7519914108929511		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.7519914108929511 | validation: 0.6328919451725787]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8970594787351347		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.8970594787351347 | validation: 0.6341604677851248]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7327631873252922		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.7327631873252922 | validation: 0.8512939333887997]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120913357418986		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.7120913357418986 | validation: 0.6154929208383415]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7743982589327758		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.7743982589327758 | validation: 0.6929273227762949]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048084689995473		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.7048084689995473 | validation: 0.6377977512341786]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8566593499694724		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.8566593499694724 | validation: 0.7092351760666246]
	TIME [epoch: 24.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597031855423174		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.7597031855423174 | validation: 0.6563840068207994]
	TIME [epoch: 24.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730956002031538		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.6730956002031538 | validation: 0.7831532934206815]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7829392629606324		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.7829392629606324 | validation: 0.6846736019527702]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132914522281081		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.7132914522281081 | validation: 0.8711468301881452]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7465759743688178		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.7465759743688178 | validation: 0.6429738228069337]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164348818938862		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.7164348818938862 | validation: 0.7286537009571038]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8743057953011537		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.8743057953011537 | validation: 0.7587103379536404]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7095229924653467		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.7095229924653467 | validation: 0.7132241416452071]
	TIME [epoch: 24.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6558114150362906		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.6558114150362906 | validation: 0.7179116526990669]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485441850795214		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.7485441850795214 | validation: 0.6858376364419833]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791866365916557		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.6791866365916557 | validation: 0.7437507119126611]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497779091403625		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.6497779091403625 | validation: 0.8049311283564707]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585520913260107		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.6585520913260107 | validation: 0.7053645892399859]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160272282906879		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.7160272282906879 | validation: 0.7662629122604964]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7302202264425343		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.7302202264425343 | validation: 0.7732161282316831]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678785839582532		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.6678785839582532 | validation: 0.6198289440658514]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689994956970527		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.6689994956970527 | validation: 0.746709533712434]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6675915186987285		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.6675915186987285 | validation: 0.6557265236871507]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6748124152892304		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.6748124152892304 | validation: 0.6420588847375212]
	TIME [epoch: 24.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560691164627018		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.6560691164627018 | validation: 0.627388319538943]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6819446205273004		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.6819446205273004 | validation: 0.6695320425187555]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935260522541591		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.6935260522541591 | validation: 0.7126545050459653]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640507514334301		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.6640507514334301 | validation: 0.9411031649929511]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7247127727635063		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.7247127727635063 | validation: 0.6515266384983991]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543551879210309		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.6543551879210309 | validation: 0.6898225275922191]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700361427129953		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.700361427129953 | validation: 0.7487984129977224]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160303079238994		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.7160303079238994 | validation: 0.8026963733114486]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526492674560141		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.7526492674560141 | validation: 0.8422780400148918]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7032478616054186		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.7032478616054186 | validation: 0.7718042649474137]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608511891923374		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.6608511891923374 | validation: 0.6422663995551224]
	TIME [epoch: 25 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6525803454361832		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.6525803454361832 | validation: 0.633777141357751]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8267472716228116		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.8267472716228116 | validation: 0.6267504053761686]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722945284968397		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.722945284968397 | validation: 0.8274286407710446]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876484366550652		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.7876484366550652 | validation: 0.6301034833608942]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823972115927082		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.6823972115927082 | validation: 0.671629108427542]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7674336653200446		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.7674336653200446 | validation: 0.6040745952511388]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_867.pth
	Model improved!!!
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703029204355456		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.703029204355456 | validation: 0.6445397880418502]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986538081550004		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.6986538081550004 | validation: 0.6274812273824707]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.645510616473613		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.645510616473613 | validation: 0.5835706883902352]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7619393127859302		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.7619393127859302 | validation: 0.6397559689120014]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029869242080584		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.7029869242080584 | validation: 0.627951874677276]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002950506915898		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.7002950506915898 | validation: 0.5957916906406469]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558080776660435		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.7558080776660435 | validation: 0.6135019008098372]
	TIME [epoch: 24.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7409645843465704		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.7409645843465704 | validation: 0.6634531518684937]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647178533767379		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.6647178533767379 | validation: 0.6414279988361252]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7654262178011466		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.7654262178011466 | validation: 0.6625459089217401]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.706079840662723		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.706079840662723 | validation: 0.645720444588469]
	TIME [epoch: 24.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7067191991439066		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.7067191991439066 | validation: 0.7964359999041554]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7364334161529356		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.7364334161529356 | validation: 0.9682535645663152]
	TIME [epoch: 24.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7885049083862081		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.7885049083862081 | validation: 1.0240513170997365]
	TIME [epoch: 24.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594844289506825		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.7594844289506825 | validation: 0.6246553942769225]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796405521067093		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.6796405521067093 | validation: 0.7709120524846753]
	TIME [epoch: 24.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421517177127055		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.6421517177127055 | validation: 0.7121843288548179]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034005472594095		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.7034005472594095 | validation: 0.615428956518776]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.691907628593893		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.691907628593893 | validation: 0.6846811285137722]
	TIME [epoch: 24.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831970197564868		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.6831970197564868 | validation: 0.7865602364243072]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6707513813535977		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.6707513813535977 | validation: 0.6438200216141685]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064689064174343		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.7064689064174343 | validation: 0.6292859550718651]
	TIME [epoch: 24.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706965591707749		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.6706965591707749 | validation: 0.784989078095693]
	TIME [epoch: 24.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.698233967941917		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.698233967941917 | validation: 1.0578841391152072]
	TIME [epoch: 24.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382966096889672		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.8382966096889672 | validation: 0.8531089539439617]
	TIME [epoch: 24.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7455418066283396		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.7455418066283396 | validation: 0.7793129540754362]
	TIME [epoch: 24.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7033536798416196		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.7033536798416196 | validation: 0.8797264285802646]
	TIME [epoch: 24.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8260033641055828		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.8260033641055828 | validation: 0.7499831694672168]
	TIME [epoch: 24.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6604387895581351		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.6604387895581351 | validation: 0.6805938027243744]
	TIME [epoch: 24.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658868519537614		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.658868519537614 | validation: 0.6259566512735695]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6583257897546486		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.6583257897546486 | validation: 0.8181735680732091]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7002565741643886		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.7002565741643886 | validation: 0.8184394081942645]
	TIME [epoch: 24.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850459181313457		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.6850459181313457 | validation: 0.6122397963542868]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955991449865657		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.6955991449865657 | validation: 0.7827798678578114]
	TIME [epoch: 24.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542945395180176		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.7542945395180176 | validation: 0.6193117440358469]
	TIME [epoch: 24.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636144410796518		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.636144410796518 | validation: 0.8357256108691559]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564334517081564		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.6564334517081564 | validation: 0.5958114850162274]
	TIME [epoch: 24.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839695848620055		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.6839695848620055 | validation: 0.6140671247503834]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6294912323805673		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.6294912323805673 | validation: 0.699677126523919]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6195726579554023		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.6195726579554023 | validation: 0.6947017487290771]
	TIME [epoch: 24.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.700412407484061		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.700412407484061 | validation: 0.6784792181036886]
	TIME [epoch: 24.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6721836085709276		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.6721836085709276 | validation: 0.6677323043884078]
	TIME [epoch: 24.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272946578452772		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.7272946578452772 | validation: 0.8515367791460144]
	TIME [epoch: 24.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.651614423920505		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.651614423920505 | validation: 0.632151192937012]
	TIME [epoch: 24.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.705302313865058		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.705302313865058 | validation: 0.6157202349252097]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479022048773047		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.6479022048773047 | validation: 0.8507696851666277]
	TIME [epoch: 24.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039155278951944		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.7039155278951944 | validation: 0.798966897971219]
	TIME [epoch: 24.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6528557064101403		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.6528557064101403 | validation: 0.6728502585290038]
	TIME [epoch: 24.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688118738349796		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.688118738349796 | validation: 0.5717550398647739]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_916.pth
	Model improved!!!
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894868458112052		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.6894868458112052 | validation: 0.6247599456510874]
	TIME [epoch: 24.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6260252115693137		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.6260252115693137 | validation: 0.6593166487218528]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345380692746692		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.6345380692746692 | validation: 0.5874139916599715]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556758548807446		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.6556758548807446 | validation: 0.5718736116210302]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252060450260076		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.6252060450260076 | validation: 0.6449498539030302]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615703765873867		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.615703765873867 | validation: 0.634416258406705]
	TIME [epoch: 24.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295185535436332		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.6295185535436332 | validation: 0.6568787299069214]
	TIME [epoch: 24.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142577451603072		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.6142577451603072 | validation: 0.5858292948342191]
	TIME [epoch: 24.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784249457964603		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.6784249457964603 | validation: 0.645843608735734]
	TIME [epoch: 24.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366638083332238		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.6366638083332238 | validation: 0.6105263056852707]
	TIME [epoch: 24.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010131765993467		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.6010131765993467 | validation: 0.5809622787067913]
	TIME [epoch: 24.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6237619724372069		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.6237619724372069 | validation: 0.6574332024475049]
	TIME [epoch: 24.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642627238998631		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.6642627238998631 | validation: 0.7770346777070575]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299527399207974		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.6299527399207974 | validation: 0.5873736734738475]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994669112016775		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.5994669112016775 | validation: 0.6209029527532686]
	TIME [epoch: 24.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382534088615479		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.6382534088615479 | validation: 0.579065022861483]
	TIME [epoch: 24.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856712291312349		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.5856712291312349 | validation: 0.5965241953627204]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790946762373996		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.6790946762373996 | validation: 0.9087157207186188]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278633165348907		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.7278633165348907 | validation: 0.7011878585443632]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922899011572098		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.6922899011572098 | validation: 0.7059192672607044]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7521499691707614		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.7521499691707614 | validation: 0.6136081115638349]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6611136772120826		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.6611136772120826 | validation: 0.6755283301726656]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155419530189541		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.6155419530189541 | validation: 0.8633783143385191]
	TIME [epoch: 24.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7950603993425658		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.7950603993425658 | validation: 0.6404589527510168]
	TIME [epoch: 24.9 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6777175403236766		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.6777175403236766 | validation: 0.6012161078342844]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086263804336212		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.6086263804336212 | validation: 0.6999613847226729]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641834810103961		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.7641834810103961 | validation: 0.7151335177840327]
	TIME [epoch: 24.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014870403522165		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.6014870403522165 | validation: 0.613469532648072]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6403089911010289		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.6403089911010289 | validation: 0.7393694387421813]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579962250869124		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.6579962250869124 | validation: 0.7089793744538373]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083438642725499		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.6083438642725499 | validation: 0.782554080247504]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896167370666805		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.6896167370666805 | validation: 0.5854752600537247]
	TIME [epoch: 24.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5978028789165928		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.5978028789165928 | validation: 0.6257637607703279]
	TIME [epoch: 24.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859037525588338		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.6859037525588338 | validation: 0.6465622765864223]
	TIME [epoch: 24.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0167147091746094		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 1.0167147091746094 | validation: 0.9396427004071884]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722273424052446		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.7722273424052446 | validation: 0.6285123588998737]
	TIME [epoch: 24.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6166945625469447		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.6166945625469447 | validation: 0.6945608526785436]
	TIME [epoch: 25 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6367210518052553		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.6367210518052553 | validation: 0.5672486002114802]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_954.pth
	Model improved!!!
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6199728675636671		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.6199728675636671 | validation: 0.7367235075006642]
	TIME [epoch: 24.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711965975733418		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.6711965975733418 | validation: 0.6679526659931119]
	TIME [epoch: 24.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351139064069744		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.6351139064069744 | validation: 0.7181874287200296]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6154007862292868		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.6154007862292868 | validation: 0.5928484590557489]
	TIME [epoch: 24.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291581746603778		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.6291581746603778 | validation: 0.5936122440528593]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796027623546137		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.5796027623546137 | validation: 0.6177677103144577]
	TIME [epoch: 24.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6053699612261668		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.6053699612261668 | validation: 0.6988178808521495]
	TIME [epoch: 24.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821329230894173		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.5821329230894173 | validation: 0.7849825454104353]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6322124334463091		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.6322124334463091 | validation: 0.5780127354491954]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5826661193462281		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.5826661193462281 | validation: 0.6458359735332003]
	TIME [epoch: 24.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.589333779993297		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.589333779993297 | validation: 0.872984674754525]
	TIME [epoch: 24.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542705325229908		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.6542705325229908 | validation: 0.6028857730702736]
	TIME [epoch: 24.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6627356809336016		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.6627356809336016 | validation: 0.6663486486744724]
	TIME [epoch: 24.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063847011928918		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.6063847011928918 | validation: 0.677769573476761]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243658880613809		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.6243658880613809 | validation: 0.8720444801125775]
	TIME [epoch: 24.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392736585387276		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.6392736585387276 | validation: 0.6852626848666915]
	TIME [epoch: 24.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875188428332071		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.5875188428332071 | validation: 0.6096103795753492]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986458464727238		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.5986458464727238 | validation: 0.7641562427900626]
	TIME [epoch: 24.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6222985510839688		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.6222985510839688 | validation: 0.6274521165884022]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122467260949903		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.6122467260949903 | validation: 0.7090536490714519]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889788011400283		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.5889788011400283 | validation: 0.729278430064004]
	TIME [epoch: 24.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5885016204853691		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.5885016204853691 | validation: 0.5620873057180561]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987844640959545		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.5987844640959545 | validation: 0.5713576940360473]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8039644218035602		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.8039644218035602 | validation: 0.7451384673426327]
	TIME [epoch: 24.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6475241265264731		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.6475241265264731 | validation: 0.7413697266885556]
	TIME [epoch: 24.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239239831552204		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.6239239831552204 | validation: 0.6281771599517714]
	TIME [epoch: 24.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059077364046396		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.6059077364046396 | validation: 0.6947301312887629]
	TIME [epoch: 24.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597661213296552		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.6597661213296552 | validation: 0.6679627953390442]
	TIME [epoch: 24.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108567388306476		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.6108567388306476 | validation: 0.6323025847511221]
	TIME [epoch: 24.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683557541650273		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.683557541650273 | validation: 0.5978706615862125]
	TIME [epoch: 24.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890774212968823		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.5890774212968823 | validation: 0.6059627671490008]
	TIME [epoch: 24.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5869523500856583		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.5869523500856583 | validation: 0.7141347716416369]
	TIME [epoch: 24.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5888785925836082		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.5888785925836082 | validation: 0.6181078985474237]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5799103050148084		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.5799103050148084 | validation: 0.571613663852035]
	TIME [epoch: 24.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890571050978396		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.5890571050978396 | validation: 0.6379654052659981]
	TIME [epoch: 24.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6566321214597193		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.6566321214597193 | validation: 0.7119072021731063]
	TIME [epoch: 24.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811510033298547		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.6811510033298547 | validation: 0.7705143495359498]
	TIME [epoch: 24.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5953713881876666		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.5953713881876666 | validation: 0.6284970982999714]
	TIME [epoch: 24.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871489280979958		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.5871489280979958 | validation: 0.632954634950939]
	TIME [epoch: 24.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939133929793811		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.5939133929793811 | validation: 0.7771806692655365]
	TIME [epoch: 24.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393902848731092		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.6393902848731092 | validation: 0.8078836455179255]
	TIME [epoch: 24.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046456160510707		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.6046456160510707 | validation: 0.7303264863582568]
	TIME [epoch: 24.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6919842789354672		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.6919842789354672 | validation: 0.5988571639768405]
	TIME [epoch: 24.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270295327501881		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.6270295327501881 | validation: 0.65005424696907]
	TIME [epoch: 24.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6126229327580077		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.6126229327580077 | validation: 0.5944108283630258]
	TIME [epoch: 24.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7227117545659796		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.7227117545659796 | validation: 0.6619230054981843]
	TIME [epoch: 24.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6731506779683967		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.6731506779683967 | validation: 0.668065017527949]
	TIME [epoch: 24.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608641370169327		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.6608641370169327 | validation: 0.6056486666947175]
	TIME [epoch: 24.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900358796549922		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.5900358796549922 | validation: 0.9772836592090138]
	TIME [epoch: 24.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7436553899705802		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.7436553899705802 | validation: 0.7274196574237979]
	TIME [epoch: 24.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6807012322204083		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.6807012322204083 | validation: 0.7276639517749632]
	TIME [epoch: 24.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6004363682117182		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.6004363682117182 | validation: 0.5784764343696454]
	TIME [epoch: 24.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220830762740376		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.6220830762740376 | validation: 0.6653760703682164]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635917785130645		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.7635917785130645 | validation: 0.7626601248303865]
	TIME [epoch: 24.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053943427867002		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.7053943427867002 | validation: 0.6433268555201478]
	TIME [epoch: 24.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595499528055046		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.595499528055046 | validation: 0.536443954668938]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1010.pth
	Model improved!!!
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890520356061391		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.5890520356061391 | validation: 0.6405641302883502]
	TIME [epoch: 24.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030308601951961		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.6030308601951961 | validation: 0.5274473043126551]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1012.pth
	Model improved!!!
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993970363381026		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.5993970363381026 | validation: 0.5817985234096391]
	TIME [epoch: 24.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61833626562886		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.61833626562886 | validation: 0.6312193681645945]
	TIME [epoch: 24.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418577853901511		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.7418577853901511 | validation: 0.6078210512837481]
	TIME [epoch: 24.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139718251071465		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.6139718251071465 | validation: 0.5545569281617657]
	TIME [epoch: 24.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987186311598276		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.5987186311598276 | validation: 0.6934471453306585]
	TIME [epoch: 24.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6619906842191384		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.6619906842191384 | validation: 0.5713354609985375]
	TIME [epoch: 24.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5728452762280261		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.5728452762280261 | validation: 0.5435691692691155]
	TIME [epoch: 24.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764211478919413		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.5764211478919413 | validation: 0.5592433803683027]
	TIME [epoch: 24.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091917286303659		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.6091917286303659 | validation: 0.6114993987109112]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5754035591046186		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.5754035591046186 | validation: 0.5994058660871446]
	TIME [epoch: 24.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912315848090697		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.5912315848090697 | validation: 0.5972192095301659]
	TIME [epoch: 24.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6202990869908567		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.6202990869908567 | validation: 0.5651842959243116]
	TIME [epoch: 24.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950286113801038		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.5950286113801038 | validation: 0.5443075432915042]
	TIME [epoch: 24.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5741459127733444		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.5741459127733444 | validation: 0.556428601256849]
	TIME [epoch: 24.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7378157195157379		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.7378157195157379 | validation: 0.8638770733322582]
	TIME [epoch: 24.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902067148883124		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.6902067148883124 | validation: 0.6821573080821014]
	TIME [epoch: 24.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6153329738382995		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.6153329738382995 | validation: 0.6380078888015244]
	TIME [epoch: 25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942357515158067		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.5942357515158067 | validation: 0.5436599671578205]
	TIME [epoch: 24.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944106350276014		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.5944106350276014 | validation: 0.5760849247289478]
	TIME [epoch: 24.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5786019143802446		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.5786019143802446 | validation: 0.5891225915751136]
	TIME [epoch: 24.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217359051807706		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.6217359051807706 | validation: 0.6521051232563696]
	TIME [epoch: 24.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6133730970658849		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.6133730970658849 | validation: 0.5544715688659043]
	TIME [epoch: 25 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049527917429481		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.6049527917429481 | validation: 0.5753142604376399]
	TIME [epoch: 25 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576428974643031		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.5576428974643031 | validation: 0.565377950911198]
	TIME [epoch: 24.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6002277433884962		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.6002277433884962 | validation: 0.6240159164899642]
	TIME [epoch: 25 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230020445596219		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.6230020445596219 | validation: 0.6096269850648107]
	TIME [epoch: 24.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5811370542115125		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.5811370542115125 | validation: 0.586123911280338]
	TIME [epoch: 24.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819177493523204		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.5819177493523204 | validation: 0.7020541611818649]
	TIME [epoch: 24.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234133507097263		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.6234133507097263 | validation: 0.8144233947217926]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032787247781402		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.6032787247781402 | validation: 0.5552178331531411]
	TIME [epoch: 24.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5898325646377223		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.5898325646377223 | validation: 0.5901840971170534]
	TIME [epoch: 25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776097280784235		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.5776097280784235 | validation: 0.6381746976086802]
	TIME [epoch: 24.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383145827277902		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.6383145827277902 | validation: 0.6022715105619616]
	TIME [epoch: 24.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640213464852528		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.5640213464852528 | validation: 0.5422762405605528]
	TIME [epoch: 24.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517270174097979		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.5517270174097979 | validation: 0.5486635745664411]
	TIME [epoch: 24.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435818661018109		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.6435818661018109 | validation: 0.5745977203569629]
	TIME [epoch: 24.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021032094667094		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.6021032094667094 | validation: 0.5109755780833573]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1049.pth
	Model improved!!!
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548045970947338		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.548045970947338 | validation: 0.580346612892971]
	TIME [epoch: 24.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677265434962637		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.5677265434962637 | validation: 0.5797290881916725]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5460675495975497		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.5460675495975497 | validation: 0.5880094685751448]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359754880592317		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.6359754880592317 | validation: 0.58109900516046]
	TIME [epoch: 24.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663636850469819		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.663636850469819 | validation: 0.5824248295662369]
	TIME [epoch: 24.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6599375786430575		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.6599375786430575 | validation: 0.8410362061292801]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6858359375419105		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.6858359375419105 | validation: 0.5362880263240156]
	TIME [epoch: 24.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5550371530006063		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.5550371530006063 | validation: 0.5203085074279803]
	TIME [epoch: 24.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571326060595011		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.571326060595011 | validation: 0.5169131865020871]
	TIME [epoch: 24.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655795321404193		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.5655795321404193 | validation: 0.5841451652320239]
	TIME [epoch: 24.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771837657856452		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.5771837657856452 | validation: 0.732022208462397]
	TIME [epoch: 24.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7001378841425403		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.7001378841425403 | validation: 0.5006645154888181]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723582131114429		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.5723582131114429 | validation: 0.5403064677628917]
	TIME [epoch: 25 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596240671965897		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.5596240671965897 | validation: 0.537443335998378]
	TIME [epoch: 24.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5439470602484078		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.5439470602484078 | validation: 0.5328467047123079]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575129765957447		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.575129765957447 | validation: 0.5267241842903634]
	TIME [epoch: 24.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348085784685651		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.6348085784685651 | validation: 0.5346053245354625]
	TIME [epoch: 24.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876294487776396		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.5876294487776396 | validation: 0.5711164631525025]
	TIME [epoch: 25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5911523545966204		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.5911523545966204 | validation: 0.5967900232827384]
	TIME [epoch: 25 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568259913761298		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.568259913761298 | validation: 0.5332064566223659]
	TIME [epoch: 24.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031841422676325		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.6031841422676325 | validation: 0.6127170071633224]
	TIME [epoch: 24.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763359949939224		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.5763359949939224 | validation: 0.5023687645602215]
	TIME [epoch: 25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5545672389030842		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.5545672389030842 | validation: 0.5003223221234612]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1072.pth
	Model improved!!!
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5779928191127984		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.5779928191127984 | validation: 0.6160031199372424]
	TIME [epoch: 25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710666978384238		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.5710666978384238 | validation: 0.6042507089475672]
	TIME [epoch: 24.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550478438627483		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.550478438627483 | validation: 0.7437678861160046]
	TIME [epoch: 24.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.608252856864837		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.608252856864837 | validation: 0.5438340647829828]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5621152835864647		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.5621152835864647 | validation: 0.6504265551380783]
	TIME [epoch: 25 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563327449175768		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.563327449175768 | validation: 0.5539499333044702]
	TIME [epoch: 24.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733287926179774		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.5733287926179774 | validation: 0.6159124015710512]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584350888538347		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.5584350888538347 | validation: 0.5445173192188772]
	TIME [epoch: 24.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835741492760785		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.5835741492760785 | validation: 0.599466218252454]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6071753866244071		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.6071753866244071 | validation: 0.6313098639881045]
	TIME [epoch: 25 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5880901899910668		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.5880901899910668 | validation: 0.5940300734783316]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.594055604370302		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.594055604370302 | validation: 0.5887965017186676]
	TIME [epoch: 24.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5521660102627568		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.5521660102627568 | validation: 0.61345767340215]
	TIME [epoch: 24.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473481429947012		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.6473481429947012 | validation: 0.5741117230601169]
	TIME [epoch: 25 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5780648030478844		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.5780648030478844 | validation: 0.6597221865289744]
	TIME [epoch: 24.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5705141476554884		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.5705141476554884 | validation: 0.6441234259734588]
	TIME [epoch: 24.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6689564588973109		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.6689564588973109 | validation: 0.7146599389780376]
	TIME [epoch: 24.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626061669375013		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.5626061669375013 | validation: 0.6640757148493684]
	TIME [epoch: 24.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057064568049126		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.6057064568049126 | validation: 0.555934717412378]
	TIME [epoch: 24.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105605988075391		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.6105605988075391 | validation: 0.7240616797769616]
	TIME [epoch: 24.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.618692191106962		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.618692191106962 | validation: 0.699345060872685]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803288053597639		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.5803288053597639 | validation: 0.5402989227275313]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370091437974016		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.5370091437974016 | validation: 0.631395736900326]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542579785339588		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.542579785339588 | validation: 0.6127789985890616]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536687654664395		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.5536687654664395 | validation: 0.5926955389720658]
	TIME [epoch: 25 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532442889545579		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.5532442889545579 | validation: 0.6066767448316629]
	TIME [epoch: 24.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5670835894505323		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.5670835894505323 | validation: 0.7564784860467588]
	TIME [epoch: 24.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6984673869547734		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.6984673869547734 | validation: 0.5642410194924585]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569307904383771		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.5569307904383771 | validation: 0.657768470912506]
	TIME [epoch: 25 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692963747894731		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.5692963747894731 | validation: 0.7308537934157741]
	TIME [epoch: 24.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584280521525623		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.584280521525623 | validation: 0.6225989447057169]
	TIME [epoch: 24.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737519495096157		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.5737519495096157 | validation: 0.6149211184421188]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666432986205348		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.5666432986205348 | validation: 0.5564833707285336]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356351931807233		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.5356351931807233 | validation: 0.5530743672092382]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449910170521837		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.5449910170521837 | validation: 0.6038192274601915]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6113960827979164		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.6113960827979164 | validation: 0.5758408414694632]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549967837635998		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.5549967837635998 | validation: 0.550117729092744]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586386708566936		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.586386708566936 | validation: 0.5373362395048876]
	TIME [epoch: 24.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523948097913827		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.523948097913827 | validation: 0.5647590157271806]
	TIME [epoch: 24.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5626881779568065		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.5626881779568065 | validation: 0.5354549062013664]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556612930729617		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.556612930729617 | validation: 0.567351797637192]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851121061977596		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.5851121061977596 | validation: 0.5915086998142814]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5834167822252699		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.5834167822252699 | validation: 0.5496190910258537]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775460253076016		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.5775460253076016 | validation: 0.6993148917810952]
	TIME [epoch: 24.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291030952671139		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.6291030952671139 | validation: 0.4958956495832163]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1117.pth
	Model improved!!!
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724031429143082		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.6724031429143082 | validation: 0.8487905986111594]
	TIME [epoch: 25 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8272523617376442		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.8272523617376442 | validation: 0.5654246310147681]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742396174089864		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.6742396174089864 | validation: 0.6693820723172818]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.632817841439474		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.632817841439474 | validation: 0.614924716065956]
	TIME [epoch: 25 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097794579959519		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.6097794579959519 | validation: 0.57937962216161]
	TIME [epoch: 24.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5688555342502032		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.5688555342502032 | validation: 0.5774338774324754]
	TIME [epoch: 25 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5671937367532797		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.5671937367532797 | validation: 0.5304504035085057]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533224197230671		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.5533224197230671 | validation: 0.5134116336465249]
	TIME [epoch: 25 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001767343444202		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.6001767343444202 | validation: 0.577753648679294]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5511834257287614		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.5511834257287614 | validation: 0.5040967845051669]
	TIME [epoch: 25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5666548854718926		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.5666548854718926 | validation: 0.5664111542467987]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335363451730235		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.5335363451730235 | validation: 0.5255763766470628]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633837319194175		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.5633837319194175 | validation: 0.5080705424497035]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395401067026948		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.5395401067026948 | validation: 0.548887000580815]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380006931451664		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.5380006931451664 | validation: 0.525909551734607]
	TIME [epoch: 24.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213668813892234		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.5213668813892234 | validation: 0.5489715653268119]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5594681050283588		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.5594681050283588 | validation: 0.5803201234456874]
	TIME [epoch: 24.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5412543297769921		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.5412543297769921 | validation: 0.6320563631305712]
	TIME [epoch: 24.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333451724601224		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.5333451724601224 | validation: 0.5218880524629936]
	TIME [epoch: 25 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281909526560336		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.5281909526560336 | validation: 0.6474030646781753]
	TIME [epoch: 24.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188155124877941		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.6188155124877941 | validation: 0.8101571411300306]
	TIME [epoch: 24.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090268936784542		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.6090268936784542 | validation: 0.6084254330365164]
	TIME [epoch: 24.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5817701470468619		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.5817701470468619 | validation: 0.5605594731450443]
	TIME [epoch: 24.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470776080014377		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.5470776080014377 | validation: 0.5376652065090433]
	TIME [epoch: 24.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522279423130007		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.522279423130007 | validation: 0.6003329629445172]
	TIME [epoch: 25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5266232103448373		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.5266232103448373 | validation: 0.5489509015741382]
	TIME [epoch: 24.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530243851506281		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.530243851506281 | validation: 0.5703977194790888]
	TIME [epoch: 24.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5371801695726526		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.5371801695726526 | validation: 0.6118531295896861]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5260216049279298		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.5260216049279298 | validation: 0.5691553526446361]
	TIME [epoch: 25 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544978788076169		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.5544978788076169 | validation: 0.5197148200729987]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5690865281470997		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.5690865281470997 | validation: 0.6307999809078209]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470387910839409		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.5470387910839409 | validation: 0.5557122749146147]
	TIME [epoch: 25 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6530602802029581		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.6530602802029581 | validation: 0.8211087320030467]
	TIME [epoch: 24.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390058618131356		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.6390058618131356 | validation: 0.5810968347538187]
	TIME [epoch: 25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5318853390649667		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.5318853390649667 | validation: 0.5422399969826454]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306572765855198		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.5306572765855198 | validation: 0.6524020617851721]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604434374275926		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.5604434374275926 | validation: 0.6004276165170768]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357177417929253		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.5357177417929253 | validation: 0.5404585547674462]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5325424536224235		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.5325424536224235 | validation: 0.6879404747243062]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571646903106243		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.571646903106243 | validation: 0.5759142588572553]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238427494911598		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.5238427494911598 | validation: 0.5204854097603644]
	TIME [epoch: 24.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123711697139854		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.5123711697139854 | validation: 0.4959713804974018]
	TIME [epoch: 24.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071775160553038		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.5071775160553038 | validation: 0.5003814926774297]
	TIME [epoch: 24.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141337998481702		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.5141337998481702 | validation: 0.5125506893273049]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377519125117356		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.5377519125117356 | validation: 0.530633677007998]
	TIME [epoch: 24.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299791326923656		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.5299791326923656 | validation: 0.5163969188595025]
	TIME [epoch: 24.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515546068963993		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.515546068963993 | validation: 0.4968398684216013]
	TIME [epoch: 24.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5995416298844628		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.5995416298844628 | validation: 0.5656888737169629]
	TIME [epoch: 24.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553193535983957		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.553193535983957 | validation: 0.5386824198327326]
	TIME [epoch: 24.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800419371481766		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.5800419371481766 | validation: 0.5547977502340578]
	TIME [epoch: 24.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121964255464629		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.5121964255464629 | validation: 0.5174707486082797]
	TIME [epoch: 24.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251711159056238		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.5251711159056238 | validation: 0.4983975735760501]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509407083560916		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.509407083560916 | validation: 0.514387455973704]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202730240183976		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.5202730240183976 | validation: 0.5934852437561426]
	TIME [epoch: 24.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453427945199518		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.5453427945199518 | validation: 0.5790438980370067]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5793095196006904		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.5793095196006904 | validation: 0.613509505450056]
	TIME [epoch: 24.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699876368707242		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.5699876368707242 | validation: 0.7013185149045008]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6413620822032613		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.6413620822032613 | validation: 0.5892210055675424]
	TIME [epoch: 24.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531967598255588		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.531967598255588 | validation: 0.5776118505726001]
	TIME [epoch: 24.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5578560460180696		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.5578560460180696 | validation: 0.494509042443442]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1177.pth
	Model improved!!!
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5296796125115478		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.5296796125115478 | validation: 0.5174989570277504]
	TIME [epoch: 24.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383183956598288		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.5383183956598288 | validation: 0.5308691262855715]
	TIME [epoch: 24.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206178384342146		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.5206178384342146 | validation: 0.6071196449552236]
	TIME [epoch: 24.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323350412000727		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.5323350412000727 | validation: 0.5302204247894845]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332623815390377		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.5332623815390377 | validation: 0.5097654800806132]
	TIME [epoch: 24.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135913467723762		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.5135913467723762 | validation: 0.5185932597422375]
	TIME [epoch: 24.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617867011741159		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.5617867011741159 | validation: 0.6811963126150419]
	TIME [epoch: 24.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669637171053334		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.5669637171053334 | validation: 0.6314786952172803]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812361814740753		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.5812361814740753 | validation: 0.7371096972550035]
	TIME [epoch: 24.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5551260931678844		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.5551260931678844 | validation: 0.5550263308291525]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544167169291677		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.5544167169291677 | validation: 0.5672251639505733]
	TIME [epoch: 24.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278172433728655		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.5278172433728655 | validation: 0.5370587966759646]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5256996611348675		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.5256996611348675 | validation: 0.5132592171260558]
	TIME [epoch: 24.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5283842592686123		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.5283842592686123 | validation: 0.5119868723945813]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227714376463191		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.5227714376463191 | validation: 0.5510850548720445]
	TIME [epoch: 24.9 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271988780250341		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.5271988780250341 | validation: 0.5082799900148381]
	TIME [epoch: 24.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329193713382324		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.5329193713382324 | validation: 0.5475115052275418]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232928879288083		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.5232928879288083 | validation: 0.5248373385437664]
	TIME [epoch: 24.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293688588363128		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.5293688588363128 | validation: 0.5250302369789163]
	TIME [epoch: 25 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558580846555272		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.5558580846555272 | validation: 0.5243136727460481]
	TIME [epoch: 24.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172576520206853		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.5172576520206853 | validation: 0.596192432074518]
	TIME [epoch: 25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314743649263878		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.5314743649263878 | validation: 0.539771398907383]
	TIME [epoch: 25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451014944799428		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.5451014944799428 | validation: 0.5418584928827472]
	TIME [epoch: 25 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5670436594910178		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.5670436594910178 | validation: 0.6004095093814196]
	TIME [epoch: 25 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403152046290367		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.5403152046290367 | validation: 0.5197238533095342]
	TIME [epoch: 25 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206128699254666		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.5206128699254666 | validation: 0.498022394995681]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185756544202095		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.5185756544202095 | validation: 0.5103192729096891]
	TIME [epoch: 25 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122130494238214		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.5122130494238214 | validation: 0.5046840953918081]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258385960240894		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.5258385960240894 | validation: 0.49961817121121543]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067897051700061		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.5067897051700061 | validation: 0.518411324792976]
	TIME [epoch: 25 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145473361064532		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.5145473361064532 | validation: 0.5376056195961593]
	TIME [epoch: 25 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558297466214073		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.558297466214073 | validation: 0.8127816951783768]
	TIME [epoch: 24.9 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220408506479688		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.6220408506479688 | validation: 0.5680547706511597]
	TIME [epoch: 24.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612168576576283		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.5612168576576283 | validation: 0.6206191684112169]
	TIME [epoch: 25 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5206934017015312		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.5206934017015312 | validation: 0.5111369053322277]
	TIME [epoch: 24.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505679768168641		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.505679768168641 | validation: 0.5825988800125937]
	TIME [epoch: 25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5300883398823744		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.5300883398823744 | validation: 0.5579809398379717]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214890227953846		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.5214890227953846 | validation: 0.5706739685933614]
	TIME [epoch: 25 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101382383008776		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.5101382383008776 | validation: 0.5132103383223732]
	TIME [epoch: 24.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094802265436305		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.5094802265436305 | validation: 0.5079067872299288]
	TIME [epoch: 25 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143852438753935		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.5143852438753935 | validation: 0.5396729153680728]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243332516675138		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.5243332516675138 | validation: 0.4835704078218615]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1219.pth
	Model improved!!!
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5413107931134847		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.5413107931134847 | validation: 0.5526960239646068]
	TIME [epoch: 25 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528500499774627		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.528500499774627 | validation: 0.4887875750917994]
	TIME [epoch: 25 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142872832801249		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.5142872832801249 | validation: 0.5518033669744392]
	TIME [epoch: 25 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698325495104795		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.5698325495104795 | validation: 0.6406250888656593]
	TIME [epoch: 25 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656895751660825		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.5656895751660825 | validation: 0.4995788304980776]
	TIME [epoch: 25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050942804852188		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.5050942804852188 | validation: 0.48791267921577175]
	TIME [epoch: 25 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.520551661070334		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.520551661070334 | validation: 0.5803173814926201]
	TIME [epoch: 25 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587770658975062		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.5587770658975062 | validation: 0.4978823358171593]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299071812810918		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.5299071812810918 | validation: 0.4838017969070069]
	TIME [epoch: 25 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044623277988111		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.5044623277988111 | validation: 0.5069461746380116]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116842118690688		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.5116842118690688 | validation: 0.5063756665652461]
	TIME [epoch: 25 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077433773877951		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.5077433773877951 | validation: 0.5082333753543581]
	TIME [epoch: 24.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036069764432929		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.5036069764432929 | validation: 0.5070390465489394]
	TIME [epoch: 25 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075650422443208		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.5075650422443208 | validation: 0.512245611031955]
	TIME [epoch: 24.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033605514937912		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.5033605514937912 | validation: 0.48470592275879454]
	TIME [epoch: 25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928239973164515		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.4928239973164515 | validation: 0.49010846372272127]
	TIME [epoch: 24.9 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019530150369864		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.5019530150369864 | validation: 0.48531972328390205]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014585342427598		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.5014585342427598 | validation: 0.5504583771709952]
	TIME [epoch: 24.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5821406906582538		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.5821406906582538 | validation: 0.4695290525979465]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1238.pth
	Model improved!!!
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254123117452671		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.5254123117452671 | validation: 0.5116920230197097]
	TIME [epoch: 25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6055422137146309		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.6055422137146309 | validation: 0.49147461840932155]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387668691132639		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.5387668691132639 | validation: 0.5083514075233501]
	TIME [epoch: 25 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341179576992945		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.5341179576992945 | validation: 0.52617149062747]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302516764280865		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.5302516764280865 | validation: 0.464553461397678]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1243.pth
	Model improved!!!
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319528172338692		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.5319528172338692 | validation: 0.46685427384194]
	TIME [epoch: 24.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49847659278260137		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.49847659278260137 | validation: 0.49989864626705144]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4926302431717604		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.4926302431717604 | validation: 0.5017359907235261]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244320881702755		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.5244320881702755 | validation: 0.5715991228710999]
	TIME [epoch: 24.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49670483956771705		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.49670483956771705 | validation: 0.4979423207224197]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062317269862073		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.5062317269862073 | validation: 0.5173135676183844]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5056753778707771		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.5056753778707771 | validation: 0.5410217997003597]
	TIME [epoch: 24.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404734020348905		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.5404734020348905 | validation: 0.5211601340418186]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49342586586798004		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.49342586586798004 | validation: 0.502155887359446]
	TIME [epoch: 24.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340772845613784		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.5340772845613784 | validation: 0.5329181855020362]
	TIME [epoch: 24.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179587122494115		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.5179587122494115 | validation: 0.5374155201936094]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5773494977434002		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.5773494977434002 | validation: 0.508477048554975]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49585556005370823		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.49585556005370823 | validation: 0.5052131333542529]
	TIME [epoch: 25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016565490951164		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.5016565490951164 | validation: 0.5141836708247237]
	TIME [epoch: 24.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5031582881618413		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.5031582881618413 | validation: 0.6073985177145096]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5341024359279735		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.5341024359279735 | validation: 0.5167396357686999]
	TIME [epoch: 24.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48974422987280597		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.48974422987280597 | validation: 0.5023220260498295]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015457341783046		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.5015457341783046 | validation: 0.4731284234171953]
	TIME [epoch: 24.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5148831946657496		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.5148831946657496 | validation: 0.5269617242661802]
	TIME [epoch: 25 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5782228409988925		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.5782228409988925 | validation: 0.4949623597773731]
	TIME [epoch: 24.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446612232504836		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.5446612232504836 | validation: 0.46937445881410256]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088452839936815		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.5088452839936815 | validation: 0.48439723135725743]
	TIME [epoch: 24.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.540776138700509		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.540776138700509 | validation: 0.452335904971489]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1266.pth
	Model improved!!!
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155102542335359		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.5155102542335359 | validation: 0.4777637851169028]
	TIME [epoch: 24.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036987484123676		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.5036987484123676 | validation: 0.49111524771627396]
	TIME [epoch: 24.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065695918528462		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.5065695918528462 | validation: 0.47275697008785744]
	TIME [epoch: 24.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307706749960573		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.5307706749960573 | validation: 0.5257158363076138]
	TIME [epoch: 24.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478867407003056		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.5478867407003056 | validation: 0.461086840439118]
	TIME [epoch: 24.9 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166933657235222		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.5166933657235222 | validation: 0.5178409702832283]
	TIME [epoch: 24.8 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429031211519045		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.5429031211519045 | validation: 0.4531703205858168]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060181986878162		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.5060181986878162 | validation: 0.4727452633021261]
	TIME [epoch: 24.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48989313972475956		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.48989313972475956 | validation: 0.4821339279510113]
	TIME [epoch: 24.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4954996561842667		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.4954996561842667 | validation: 0.5779525293025901]
	TIME [epoch: 24.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5313939812695612		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.5313939812695612 | validation: 0.4839756267968028]
	TIME [epoch: 24.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4877377590332789		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.4877377590332789 | validation: 0.4793429640004204]
	TIME [epoch: 24.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054210640605579		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.5054210640605579 | validation: 0.4606067019235539]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914230003484795		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.4914230003484795 | validation: 0.510088880312014]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5080677251496608		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.5080677251496608 | validation: 0.5123948052864691]
	TIME [epoch: 24.9 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115616318404383		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.5115616318404383 | validation: 0.5579459450206852]
	TIME [epoch: 24.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.544893290134221		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.544893290134221 | validation: 0.5204728486097919]
	TIME [epoch: 24.9 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5090640581024646		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.5090640581024646 | validation: 0.519553432245895]
	TIME [epoch: 24.9 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5166890652082332		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.5166890652082332 | validation: 0.4640182602974109]
	TIME [epoch: 24.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123673877083257		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.5123673877083257 | validation: 0.477360802645436]
	TIME [epoch: 25 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5052964184913636		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.5052964184913636 | validation: 0.47282989776271367]
	TIME [epoch: 24.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088525595334193		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.5088525595334193 | validation: 0.4905938623805657]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035303217833768		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.5035303217833768 | validation: 0.4561806404223405]
	TIME [epoch: 24.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49884646337642086		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.49884646337642086 | validation: 0.4740399575991313]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5081497588475894		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.5081497588475894 | validation: 0.49583947135282397]
	TIME [epoch: 24.9 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969407701340569		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.4969407701340569 | validation: 0.5141138210627141]
	TIME [epoch: 24.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083577666233865		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.5083577666233865 | validation: 0.48021371190174167]
	TIME [epoch: 24.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5043160498951901		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.5043160498951901 | validation: 0.5120961239754233]
	TIME [epoch: 24.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5323136596962526		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.5323136596962526 | validation: 0.5479856037620222]
	TIME [epoch: 24.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931987940320742		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.5931987940320742 | validation: 0.4669531534050863]
	TIME [epoch: 24.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4958981146807052		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.4958981146807052 | validation: 0.5188684183744685]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4989252538233699		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.4989252538233699 | validation: 0.47930248514852725]
	TIME [epoch: 24.9 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4956687761801872		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.4956687761801872 | validation: 0.4762795210128472]
	TIME [epoch: 24.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000939567848004		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.5000939567848004 | validation: 0.5411922679883676]
	TIME [epoch: 24.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.50925290268312		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.50925290268312 | validation: 0.47457829633249604]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201811166091792		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.5201811166091792 | validation: 0.5021783591636915]
	TIME [epoch: 24.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328132336777035		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.5328132336777035 | validation: 0.4732907103057457]
	TIME [epoch: 24.9 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240738527720582		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.5240738527720582 | validation: 0.4554448477404995]
	TIME [epoch: 24.9 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5314734520780875		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.5314734520780875 | validation: 0.46772717378822415]
	TIME [epoch: 24.9 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140563218524752		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.5140563218524752 | validation: 0.4619762343176445]
	TIME [epoch: 24.9 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502281355270314		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.502281355270314 | validation: 0.47945904030849945]
	TIME [epoch: 24.9 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48851142968194017		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.48851142968194017 | validation: 0.4839365512747161]
	TIME [epoch: 24.9 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5008406483482691		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.5008406483482691 | validation: 0.49462584438417373]
	TIME [epoch: 24.9 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4958835739373288		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.4958835739373288 | validation: 0.5003855026867483]
	TIME [epoch: 24.9 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5038111680629402		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.5038111680629402 | validation: 0.49773591580058035]
	TIME [epoch: 24.9 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5029476960530168		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.5029476960530168 | validation: 0.5056919697794231]
	TIME [epoch: 24.9 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036166577973099		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.5036166577973099 | validation: 0.46994215514297727]
	TIME [epoch: 24.9 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852894708678172		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.4852894708678172 | validation: 0.4620742846531531]
	TIME [epoch: 24.8 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4882124738980893		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.4882124738980893 | validation: 0.4920822476957185]
	TIME [epoch: 24.9 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5170042187309936		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.5170042187309936 | validation: 0.46213823871471016]
	TIME [epoch: 24.9 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107574094266143		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.5107574094266143 | validation: 0.4617597221561853]
	TIME [epoch: 24.8 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4983515540729596		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.4983515540729596 | validation: 0.4838359765253192]
	TIME [epoch: 24.9 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5416204744794192		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.5416204744794192 | validation: 0.48012286889108835]
	TIME [epoch: 24.9 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49806099356717587		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.49806099356717587 | validation: 0.45625974113431844]
	TIME [epoch: 24.9 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015047976384678		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.5015047976384678 | validation: 0.4703389320203828]
	TIME [epoch: 24.9 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49225441544536425		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.49225441544536425 | validation: 0.4560273887178922]
	TIME [epoch: 24.9 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868674704358197		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.4868674704358197 | validation: 0.47450223316734647]
	TIME [epoch: 24.9 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4838274767399736		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.4838274767399736 | validation: 0.4827364014953232]
	TIME [epoch: 24.9 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4954296583454439		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.4954296583454439 | validation: 0.5290432616636557]
	TIME [epoch: 24.9 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048799326774976		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.5048799326774976 | validation: 0.5142323468760622]
	TIME [epoch: 24.9 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49347005532375426		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.49347005532375426 | validation: 0.507941875782191]
	TIME [epoch: 24.9 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293921018942251		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.5293921018942251 | validation: 0.48697706429026955]
	TIME [epoch: 24.9 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4972179805782161		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.4972179805782161 | validation: 0.4734436249907559]
	TIME [epoch: 24.9 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49053255423804387		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.49053255423804387 | validation: 0.46355216426070284]
	TIME [epoch: 24.9 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4954751296491594		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.4954751296491594 | validation: 0.47933037883246044]
	TIME [epoch: 24.9 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48676834144322195		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.48676834144322195 | validation: 0.4712106521615659]
	TIME [epoch: 24.8 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849718848320538		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.4849718848320538 | validation: 0.5053031219292307]
	TIME [epoch: 24.9 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065420376434326		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.5065420376434326 | validation: 0.5123185170963662]
	TIME [epoch: 24.9 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49273039664563517		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.49273039664563517 | validation: 0.526608445503459]
	TIME [epoch: 24.8 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876475484869971		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.4876475484869971 | validation: 0.5282905130344131]
	TIME [epoch: 24.9 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051636537914392		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.5051636537914392 | validation: 0.4977609666639821]
	TIME [epoch: 24.9 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4847524040770552		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.4847524040770552 | validation: 0.48468584575692436]
	TIME [epoch: 24.8 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48827492486102		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.48827492486102 | validation: 0.49585092911668865]
	TIME [epoch: 24.9 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4814684755786895		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.4814684755786895 | validation: 0.5009961518115387]
	TIME [epoch: 24.9 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48525931626747987		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.48525931626747987 | validation: 0.5219566686061534]
	TIME [epoch: 24.9 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509155645996332		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.509155645996332 | validation: 0.47688796911672404]
	TIME [epoch: 24.9 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49344803089456796		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.49344803089456796 | validation: 0.47688056528636863]
	TIME [epoch: 24.9 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4856671396273822		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.4856671396273822 | validation: 0.4846044360673673]
	TIME [epoch: 24.9 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47528011860398817		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.47528011860398817 | validation: 0.5052754016297525]
	TIME [epoch: 24.9 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050239023253571		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.5050239023253571 | validation: 0.5129049466196505]
	TIME [epoch: 24.9 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4924716188624436		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.4924716188624436 | validation: 0.4826367106147979]
	TIME [epoch: 24.9 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914368703218627		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.4914368703218627 | validation: 0.47908459498446915]
	TIME [epoch: 24.9 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178053859399783		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.5178053859399783 | validation: 0.4784856578846944]
	TIME [epoch: 24.9 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202395715180997		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.5202395715180997 | validation: 0.45518841990206066]
	TIME [epoch: 24.8 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4990181655190633		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.4990181655190633 | validation: 0.4593332754872263]
	TIME [epoch: 24.9 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501004669451166		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.501004669451166 | validation: 0.46610716641777616]
	TIME [epoch: 24.9 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975290963667637		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.4975290963667637 | validation: 0.4555643298549117]
	TIME [epoch: 24.9 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.498642331341008		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.498642331341008 | validation: 0.4643737412332154]
	TIME [epoch: 25 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124543229831374		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.5124543229831374 | validation: 0.4616219110328734]
	TIME [epoch: 24.8 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000399214714482		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.5000399214714482 | validation: 0.44885998495847534]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1356.pth
	Model improved!!!
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934875252200327		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.4934875252200327 | validation: 0.45838136105808674]
	TIME [epoch: 25 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48393787519568476		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.48393787519568476 | validation: 0.49729721086270445]
	TIME [epoch: 24.9 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605200398287068		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.5605200398287068 | validation: 0.6180434472008963]
	TIME [epoch: 24.9 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.562848626915051		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.562848626915051 | validation: 0.45491818753677393]
	TIME [epoch: 24.9 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47843314794578123		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.47843314794578123 | validation: 0.4480296371958902]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1361.pth
	Model improved!!!
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024073572556214		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.5024073572556214 | validation: 0.4590813456183666]
	TIME [epoch: 24.9 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4983853959633268		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.4983853959633268 | validation: 0.44704765787601164]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1363.pth
	Model improved!!!
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49845530763467905		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.49845530763467905 | validation: 0.4568669788767835]
	TIME [epoch: 24.9 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49936141041089765		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.49936141041089765 | validation: 0.46048081439062954]
	TIME [epoch: 24.9 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4847568103446529		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.4847568103446529 | validation: 0.45354887706911146]
	TIME [epoch: 24.9 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48636359904310145		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.48636359904310145 | validation: 0.4701076036263176]
	TIME [epoch: 24.9 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880050442367776		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.4880050442367776 | validation: 0.4872331094398875]
	TIME [epoch: 24.9 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48753996690019646		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.48753996690019646 | validation: 0.4891987391274389]
	TIME [epoch: 24.9 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48887746852026764		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.48887746852026764 | validation: 0.48786475188052786]
	TIME [epoch: 24.9 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4846156381308623		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.4846156381308623 | validation: 0.4799616428144707]
	TIME [epoch: 24.8 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826995442232819		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.4826995442232819 | validation: 0.5050813566832806]
	TIME [epoch: 24.9 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4880332081069396		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.4880332081069396 | validation: 0.47347819379610356]
	TIME [epoch: 24.9 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4767093020664336		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.4767093020664336 | validation: 0.4932582178166523]
	TIME [epoch: 24.9 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821757403989464		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.4821757403989464 | validation: 0.4892204634991316]
	TIME [epoch: 24.9 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48307106693607366		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.48307106693607366 | validation: 0.47268979906805625]
	TIME [epoch: 24.9 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47639900903119464		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.47639900903119464 | validation: 0.4725376107401913]
	TIME [epoch: 24.8 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025817660352462		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.5025817660352462 | validation: 0.5056735968041484]
	TIME [epoch: 24.9 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4942255821989803		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.4942255821989803 | validation: 0.4815858654862323]
	TIME [epoch: 24.9 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49626432514582747		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.49626432514582747 | validation: 0.5036885612377405]
	TIME [epoch: 24.8 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5040797249010528		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.5040797249010528 | validation: 0.4558917177144493]
	TIME [epoch: 24.9 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47310168736836156		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.47310168736836156 | validation: 0.4578689301932572]
	TIME [epoch: 24.9 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834152815071161		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.4834152815071161 | validation: 0.48033142466069606]
	TIME [epoch: 24.9 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108485939343433		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.5108485939343433 | validation: 0.46658813636603425]
	TIME [epoch: 24.9 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47189434288615917		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.47189434288615917 | validation: 0.46656736070235083]
	TIME [epoch: 24.9 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746636720231838		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.4746636720231838 | validation: 0.4489913385614597]
	TIME [epoch: 24.9 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473715488660016		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.473715488660016 | validation: 0.46297369774038677]
	TIME [epoch: 24.9 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826771226434344		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.4826771226434344 | validation: 0.4604919421275088]
	TIME [epoch: 24.9 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820068818461322		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.4820068818461322 | validation: 0.4638441546417309]
	TIME [epoch: 24.9 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4885394629768669		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.4885394629768669 | validation: 0.4803441036600532]
	TIME [epoch: 24.9 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4711577490058965		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.4711577490058965 | validation: 0.48829788765315274]
	TIME [epoch: 24.9 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4870073999894844		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.4870073999894844 | validation: 0.5121214372798787]
	TIME [epoch: 24.9 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772813435017479		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.4772813435017479 | validation: 0.47077338770287086]
	TIME [epoch: 24.9 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.480003488052289		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.480003488052289 | validation: 0.5107468459775811]
	TIME [epoch: 24.9 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289098359490426		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.5289098359490426 | validation: 0.5050358453612401]
	TIME [epoch: 24.9 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033296023145333		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.5033296023145333 | validation: 0.4713617444483228]
	TIME [epoch: 24.9 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900983263066907		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.4900983263066907 | validation: 0.46865554396895903]
	TIME [epoch: 24.9 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993182103903716		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.4993182103903716 | validation: 0.44526086703154055]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1398.pth
	Model improved!!!
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4684012437890266		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.4684012437890266 | validation: 0.48669225430420976]
	TIME [epoch: 24.9 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4799437434779441		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.4799437434779441 | validation: 0.5112233568062727]
	TIME [epoch: 24.9 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48681013581812915		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.48681013581812915 | validation: 0.46814149254033655]
	TIME [epoch: 24.9 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476690983550026		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.476690983550026 | validation: 0.48067029923069654]
	TIME [epoch: 24.9 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4769765218815738		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.4769765218815738 | validation: 0.4916535184725375]
	TIME [epoch: 24.9 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808250816732102		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.4808250816732102 | validation: 0.4730472006221113]
	TIME [epoch: 24.9 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4885470022219251		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.4885470022219251 | validation: 0.518304041707497]
	TIME [epoch: 24.9 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4877603766070913		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.4877603766070913 | validation: 0.4862796877019148]
	TIME [epoch: 24.8 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47644388083449507		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.47644388083449507 | validation: 0.5134459238603]
	TIME [epoch: 24.9 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028880203985436		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.5028880203985436 | validation: 0.5116776944470656]
	TIME [epoch: 24.9 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47849887510542966		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.47849887510542966 | validation: 0.45999765334174103]
	TIME [epoch: 24.9 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47339101132973055		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.47339101132973055 | validation: 0.47066384597418576]
	TIME [epoch: 24.9 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4794348558614749		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.4794348558614749 | validation: 0.4815008976698226]
	TIME [epoch: 24.9 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4811866246479605		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.4811866246479605 | validation: 0.4759092325418506]
	TIME [epoch: 24.8 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821139422849935		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.4821139422849935 | validation: 0.47634854670554205]
	TIME [epoch: 24.8 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49275940690849407		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.49275940690849407 | validation: 0.4576742395751538]
	TIME [epoch: 24.9 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4794924563694597		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.4794924563694597 | validation: 0.4349906594233681]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1415.pth
	Model improved!!!
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4803498520838837		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.4803498520838837 | validation: 0.4739497223843814]
	TIME [epoch: 24.8 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701636446245005		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.4701636446245005 | validation: 0.4914219508416282]
	TIME [epoch: 24.9 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4772948003422604		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.4772948003422604 | validation: 0.4724666032563084]
	TIME [epoch: 24.9 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47417031244607133		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.47417031244607133 | validation: 0.48468720894330114]
	TIME [epoch: 24.9 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47634015180494793		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.47634015180494793 | validation: 0.5200751134870061]
	TIME [epoch: 24.9 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48401175105733557		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.48401175105733557 | validation: 0.5290548433702972]
	TIME [epoch: 24.9 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5012473811161429		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.5012473811161429 | validation: 0.5299400124378052]
	TIME [epoch: 24.9 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49195567478290325		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.49195567478290325 | validation: 0.5431656245333136]
	TIME [epoch: 24.9 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955825735155256		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.4955825735155256 | validation: 0.5200646468098522]
	TIME [epoch: 24.9 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068851933941037		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.5068851933941037 | validation: 0.5292383607230937]
	TIME [epoch: 24.9 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48624791533700856		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.48624791533700856 | validation: 0.49454278980369476]
	TIME [epoch: 24.9 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921236660275042		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.4921236660275042 | validation: 0.46993372707966763]
	TIME [epoch: 24.9 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734328902586228		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.4734328902586228 | validation: 0.4746211005114313]
	TIME [epoch: 24.9 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47370201285520996		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.47370201285520996 | validation: 0.46959277403731875]
	TIME [epoch: 24.9 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47409549655854566		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.47409549655854566 | validation: 0.4615600070535502]
	TIME [epoch: 24.9 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690744771271981		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.4690744771271981 | validation: 0.4724493559102863]
	TIME [epoch: 24.9 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663186180667651		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.4663186180667651 | validation: 0.4804059867341798]
	TIME [epoch: 24.9 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740994774710869		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.4740994774710869 | validation: 0.47952143940007136]
	TIME [epoch: 24.9 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47946487699981444		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.47946487699981444 | validation: 0.46850851931715654]
	TIME [epoch: 24.9 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707018990154361		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.4707018990154361 | validation: 0.47268729312148894]
	TIME [epoch: 24.9 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47235814727181735		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.47235814727181735 | validation: 0.475748691080765]
	TIME [epoch: 24.9 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46704475829195646		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.46704475829195646 | validation: 0.5127398340345805]
	TIME [epoch: 24.9 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4851950954327212		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.4851950954327212 | validation: 0.5671419799603394]
	TIME [epoch: 24.9 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49930118193684614		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.49930118193684614 | validation: 0.46861226342493145]
	TIME [epoch: 24.8 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47013383220658433		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.47013383220658433 | validation: 0.47862801627801405]
	TIME [epoch: 24.9 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47854812483727405		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.47854812483727405 | validation: 0.4896054508559061]
	TIME [epoch: 24.9 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4965067801170089		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.4965067801170089 | validation: 0.4950978015872523]
	TIME [epoch: 24.9 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48930925324243624		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.48930925324243624 | validation: 0.5341581282932493]
	TIME [epoch: 24.9 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025337444920537		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.5025337444920537 | validation: 0.4916320850541007]
	TIME [epoch: 24.9 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47486583286318973		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.47486583286318973 | validation: 0.4791865171900598]
	TIME [epoch: 24.9 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46435078348174663		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.46435078348174663 | validation: 0.4800552821637405]
	TIME [epoch: 24.9 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47083059226999946		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.47083059226999946 | validation: 0.4687588567032795]
	TIME [epoch: 24.9 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748289124590455		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.4748289124590455 | validation: 0.47043385834862766]
	TIME [epoch: 24.9 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4879279457773912		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.4879279457773912 | validation: 0.5300741846026868]
	TIME [epoch: 24.9 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018374933136045		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.5018374933136045 | validation: 0.45473757709553403]
	TIME [epoch: 24.9 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47385712838274147		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.47385712838274147 | validation: 0.465746852646184]
	TIME [epoch: 24.9 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690948956091977		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.4690948956091977 | validation: 0.46987370710942217]
	TIME [epoch: 24.9 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4626375503222516		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.4626375503222516 | validation: 0.471419231585704]
	TIME [epoch: 24.9 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4982572175437655		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.4982572175437655 | validation: 0.5104116912857314]
	TIME [epoch: 24.8 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48857369032603337		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.48857369032603337 | validation: 0.5026901688187136]
	TIME [epoch: 24.9 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945539942450531		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.4945539942450531 | validation: 0.5747184171540164]
	TIME [epoch: 24.9 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4896489798149634		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.4896489798149634 | validation: 0.4913788180620248]
	TIME [epoch: 24.9 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47523772099089173		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.47523772099089173 | validation: 0.5494346202246824]
	TIME [epoch: 24.9 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050495879150995		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.5050495879150995 | validation: 0.5144527651394052]
	TIME [epoch: 24.9 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47689447424414944		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.47689447424414944 | validation: 0.46636531613432747]
	TIME [epoch: 24.8 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46959545390963586		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.46959545390963586 | validation: 0.4704178123916762]
	TIME [epoch: 24.9 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745697249176457		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.4745697249176457 | validation: 0.4793130159959662]
	TIME [epoch: 24.9 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46973650416702284		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.46973650416702284 | validation: 0.4973651981663628]
	TIME [epoch: 24.9 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834926374895771		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.4834926374895771 | validation: 0.5096178364533186]
	TIME [epoch: 24.9 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48044928645545665		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.48044928645545665 | validation: 0.48488525151616513]
	TIME [epoch: 24.9 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746488871489265		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.4746488871489265 | validation: 0.4936170998681352]
	TIME [epoch: 24.9 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46988970550455317		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.46988970550455317 | validation: 0.47889005963019826]
	TIME [epoch: 24.9 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46917183526456196		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.46917183526456196 | validation: 0.4741207886844896]
	TIME [epoch: 24.9 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46427939395789697		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.46427939395789697 | validation: 0.48764926473471454]
	TIME [epoch: 24.8 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761127225365921		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.4761127225365921 | validation: 0.4664266692438955]
	TIME [epoch: 24.9 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4731014656871352		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.4731014656871352 | validation: 0.4571112650211498]
	TIME [epoch: 24.9 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688754813323041		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.4688754813323041 | validation: 0.48533222858974273]
	TIME [epoch: 24.8 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4972196774992889		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.4972196774992889 | validation: 0.4933215142127486]
	TIME [epoch: 24.9 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48696430073850855		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.48696430073850855 | validation: 0.46934009720279085]
	TIME [epoch: 24.9 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47245450041760517		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.47245450041760517 | validation: 0.4953371901796855]
	TIME [epoch: 24.8 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47415777422941285		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.47415777422941285 | validation: 0.4886473677780044]
	TIME [epoch: 24.9 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4696596823528904		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.4696596823528904 | validation: 0.47095769577586866]
	TIME [epoch: 24.9 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656850295694519		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.4656850295694519 | validation: 0.4665855392634029]
	TIME [epoch: 24.8 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4767248485928756		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.4767248485928756 | validation: 0.4692999615469084]
	TIME [epoch: 24.9 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4792473133773311		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.4792473133773311 | validation: 0.48232042609089093]
	TIME [epoch: 24.9 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47321560776122856		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.47321560776122856 | validation: 0.486950813241835]
	TIME [epoch: 24.8 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4619180928138311		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.4619180928138311 | validation: 0.47414973185436693]
	TIME [epoch: 24.9 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47062645879633636		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.47062645879633636 | validation: 0.48174350091015355]
	TIME [epoch: 24.9 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4624086465148		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.4624086465148 | validation: 0.4984141816217085]
	TIME [epoch: 24.9 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47385274368241426		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.47385274368241426 | validation: 0.510415722422298]
	TIME [epoch: 24.9 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727055766359076		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.4727055766359076 | validation: 0.514403784150711]
	TIME [epoch: 24.9 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48228524605181444		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.48228524605181444 | validation: 0.5008454383081183]
	TIME [epoch: 24.9 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46974987640321375		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.46974987640321375 | validation: 0.537200150392926]
	TIME [epoch: 24.9 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49099396164098597		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.49099396164098597 | validation: 0.4945262383816316]
	TIME [epoch: 24.9 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4800536219369394		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.4800536219369394 | validation: 0.4578423613440033]
	TIME [epoch: 24.8 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642324180781503		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.4642324180781503 | validation: 0.45988794690069756]
	TIME [epoch: 24.8 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47323417880511565		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.47323417880511565 | validation: 0.46028177884756616]
	TIME [epoch: 24.9 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638620064114347		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.4638620064114347 | validation: 0.4576339185730048]
	TIME [epoch: 24.9 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732798882578707		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.4732798882578707 | validation: 0.4528128493032958]
	TIME [epoch: 24.9 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46523938475957516		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.46523938475957516 | validation: 0.46369897388330594]
	TIME [epoch: 24.9 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662930566122444		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.4662930566122444 | validation: 0.4687030863221528]
	TIME [epoch: 24.8 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46434687185502055		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.46434687185502055 | validation: 0.46071744575877904]
	TIME [epoch: 24.9 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46772260733200344		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.46772260733200344 | validation: 0.4873249681221357]
	TIME [epoch: 24.9 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686991929504737		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.4686991929504737 | validation: 0.4601196817786026]
	TIME [epoch: 24.9 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47590570682008987		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.47590570682008987 | validation: 0.4750892052159628]
	TIME [epoch: 24.9 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47641425437183216		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.47641425437183216 | validation: 0.4722235980601118]
	TIME [epoch: 24.9 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.467870161346023		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.467870161346023 | validation: 0.46130796977321537]
	TIME [epoch: 24.8 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705433568609675		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.4705433568609675 | validation: 0.46660507067622875]
	TIME [epoch: 24.9 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46277242797216633		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.46277242797216633 | validation: 0.4409682688713157]
	TIME [epoch: 24.9 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4610844023910673		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.4610844023910673 | validation: 0.46981139185672155]
	TIME [epoch: 24.8 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46030681769682213		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.46030681769682213 | validation: 0.46957052276636996]
	TIME [epoch: 24.9 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662523857930182		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.4662523857930182 | validation: 0.46046367076687844]
	TIME [epoch: 24.9 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716665114622938		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.4716665114622938 | validation: 0.44039654267529244]
	TIME [epoch: 24.8 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743985753988045		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.4743985753988045 | validation: 0.44858430560619994]
	TIME [epoch: 24.9 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4768715968489335		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.4768715968489335 | validation: 0.48713025056992515]
	TIME [epoch: 24.9 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4907111114637532		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.4907111114637532 | validation: 0.45184598873458326]
	TIME [epoch: 24.8 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46605453627010185		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.46605453627010185 | validation: 0.45004699329753123]
	TIME [epoch: 24.9 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47076740394116573		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.47076740394116573 | validation: 0.4313156016304787]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1513.pth
	Model improved!!!
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46405187658714403		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.46405187658714403 | validation: 0.4472286610911908]
	TIME [epoch: 24.9 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46774100888384673		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.46774100888384673 | validation: 0.45483237397768317]
	TIME [epoch: 24.9 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677250517917238		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.4677250517917238 | validation: 0.4614965593132017]
	TIME [epoch: 24.9 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602210410265089		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.4602210410265089 | validation: 0.4657627591903862]
	TIME [epoch: 24.9 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677294393507887		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.4677294393507887 | validation: 0.4630261040005037]
	TIME [epoch: 24.9 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4749203958477111		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.4749203958477111 | validation: 0.4635227549845225]
	TIME [epoch: 24.9 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631050022354768		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.4631050022354768 | validation: 0.46263418259750255]
	TIME [epoch: 24.8 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45649534286893134		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.45649534286893134 | validation: 0.45516163890787525]
	TIME [epoch: 24.9 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46432531472321276		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.46432531472321276 | validation: 0.46967995108894933]
	TIME [epoch: 24.9 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4957170753603203		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.4957170753603203 | validation: 0.4842375391400699]
	TIME [epoch: 24.9 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857539544453		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.4857539544453 | validation: 0.44774960749569837]
	TIME [epoch: 24.9 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46558900675425885		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.46558900675425885 | validation: 0.4727700812168895]
	TIME [epoch: 24.9 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594624767160085		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.4594624767160085 | validation: 0.4727707381742643]
	TIME [epoch: 24.8 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47080443044519277		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.47080443044519277 | validation: 0.45728979714523915]
	TIME [epoch: 24.9 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46474751366908984		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.46474751366908984 | validation: 0.45368858226131864]
	TIME [epoch: 24.9 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676590769591904		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.4676590769591904 | validation: 0.48205738414043486]
	TIME [epoch: 24.9 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47733828116468624		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.47733828116468624 | validation: 0.4889116348035829]
	TIME [epoch: 24.9 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48278606810348856		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.48278606810348856 | validation: 0.47396480610005287]
	TIME [epoch: 24.9 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642284837413819		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.4642284837413819 | validation: 0.45684132119573717]
	TIME [epoch: 24.9 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4774985736292717		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.4774985736292717 | validation: 0.46369885833695945]
	TIME [epoch: 24.9 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46698919688623775		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.46698919688623775 | validation: 0.43264212733081026]
	TIME [epoch: 24.9 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4713801258805931		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.4713801258805931 | validation: 0.4321642581442876]
	TIME [epoch: 24.9 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46823817419045666		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.46823817419045666 | validation: 0.46080891350896097]
	TIME [epoch: 24.9 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679421132343511		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.4679421132343511 | validation: 0.42922281892902925]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1537.pth
	Model improved!!!
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46932988717755675		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.46932988717755675 | validation: 0.4395343367065584]
	TIME [epoch: 24.9 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651330108730556		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.4651330108730556 | validation: 0.43390370756266583]
	TIME [epoch: 24.9 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46491817261108803		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.46491817261108803 | validation: 0.45001134548007893]
	TIME [epoch: 24.9 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4752472469978739		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.4752472469978739 | validation: 0.43931908070628495]
	TIME [epoch: 24.9 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46313778767545194		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.46313778767545194 | validation: 0.4544348502121134]
	TIME [epoch: 24.9 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.467964348553176		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.467964348553176 | validation: 0.44742191409488463]
	TIME [epoch: 24.9 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4720883661778533		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.4720883661778533 | validation: 0.4648399966521079]
	TIME [epoch: 24.9 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674270285192028		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.4674270285192028 | validation: 0.4328302691035688]
	TIME [epoch: 24.9 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473189314525266		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.473189314525266 | validation: 0.47837794467423606]
	TIME [epoch: 24.9 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48071163151130714		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.48071163151130714 | validation: 0.4425417457874682]
	TIME [epoch: 24.8 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4648016334535708		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.4648016334535708 | validation: 0.4444019943775326]
	TIME [epoch: 24.9 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46281955830002763		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.46281955830002763 | validation: 0.4241804512420436]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1549.pth
	Model improved!!!
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707107200246684		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.4707107200246684 | validation: 0.4232144355092946]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1550.pth
	Model improved!!!
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679712913156467		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.4679712913156467 | validation: 0.44454924036992793]
	TIME [epoch: 24.9 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47319939822724955		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.47319939822724955 | validation: 0.43780876627659804]
	TIME [epoch: 24.9 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4661604506171895		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.4661604506171895 | validation: 0.44204063369713253]
	TIME [epoch: 24.9 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46008832441688485		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.46008832441688485 | validation: 0.4589147001713147]
	TIME [epoch: 24.9 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46332753195069054		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.46332753195069054 | validation: 0.47029399259981575]
	TIME [epoch: 24.9 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47429491267776686		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.47429491267776686 | validation: 0.48317340003555204]
	TIME [epoch: 24.9 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903243560372458		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.4903243560372458 | validation: 0.48089432703648277]
	TIME [epoch: 24.9 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4957459872143239		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.4957459872143239 | validation: 0.45541623761753913]
	TIME [epoch: 24.9 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631583491206235		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.4631583491206235 | validation: 0.4667416793959488]
	TIME [epoch: 24.8 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46046906678435745		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.46046906678435745 | validation: 0.47025022357906215]
	TIME [epoch: 24.9 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4646259129922323		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.4646259129922323 | validation: 0.47125686825735275]
	TIME [epoch: 24.9 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4572807115197476		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.4572807115197476 | validation: 0.47525348124945865]
	TIME [epoch: 24.8 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46979462025817215		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.46979462025817215 | validation: 0.4825570662223013]
	TIME [epoch: 24.9 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636238725518772		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.4636238725518772 | validation: 0.45576795409615595]
	TIME [epoch: 24.9 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45898487341066385		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.45898487341066385 | validation: 0.45831357923433647]
	TIME [epoch: 24.8 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643236536493414		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.4643236536493414 | validation: 0.45116478496137774]
	TIME [epoch: 24.9 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4782658128470029		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.4782658128470029 | validation: 0.4327562348990601]
	TIME [epoch: 24.9 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46473230355890627		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.46473230355890627 | validation: 0.455523150558806]
	TIME [epoch: 24.8 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651734074347353		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.4651734074347353 | validation: 0.45152384298702]
	TIME [epoch: 24.9 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4667118945789762		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.4667118945789762 | validation: 0.4666041267084009]
	TIME [epoch: 24.9 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756273092484461		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.4756273092484461 | validation: 0.45603972744891985]
	TIME [epoch: 24.8 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760725516504155		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.4760725516504155 | validation: 0.45172827926844633]
	TIME [epoch: 24.9 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46324419023880625		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.46324419023880625 | validation: 0.4632599956160653]
	TIME [epoch: 24.9 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698722229741582		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.4698722229741582 | validation: 0.4685987591734268]
	TIME [epoch: 24.8 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631857503841414		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.4631857503841414 | validation: 0.454702253029615]
	TIME [epoch: 24.9 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46850409507566426		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.46850409507566426 | validation: 0.45223942562012637]
	TIME [epoch: 24.9 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45651567148459593		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.45651567148459593 | validation: 0.440091919254231]
	TIME [epoch: 24.9 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632383093859909		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.4632383093859909 | validation: 0.4447198518913622]
	TIME [epoch: 24.9 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45602373291154963		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.45602373291154963 | validation: 0.44009054331237807]
	TIME [epoch: 24.9 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46338650755973065		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.46338650755973065 | validation: 0.4330717040686551]
	TIME [epoch: 24.8 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4649529859640862		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.4649529859640862 | validation: 0.4456906219353857]
	TIME [epoch: 24.9 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46234429793500964		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.46234429793500964 | validation: 0.4460904784741648]
	TIME [epoch: 24.9 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4613084930705829		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.4613084930705829 | validation: 0.43679627951547645]
	TIME [epoch: 24.9 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.470188647324136		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.470188647324136 | validation: 0.4426192408592487]
	TIME [epoch: 24.9 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46752881988524003		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.46752881988524003 | validation: 0.45163314661705456]
	TIME [epoch: 24.9 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46038544974235873		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.46038544974235873 | validation: 0.45430194416225805]
	TIME [epoch: 24.8 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47750451399920096		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.47750451399920096 | validation: 0.5022458661549847]
	TIME [epoch: 24.9 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4849427329100392		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.4849427329100392 | validation: 0.4980938059740583]
	TIME [epoch: 24.9 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747839485937767		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.4747839485937767 | validation: 0.4809109023496261]
	TIME [epoch: 24.8 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46420534414227366		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.46420534414227366 | validation: 0.45610062177401495]
	TIME [epoch: 24.9 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46176506481593815		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.46176506481593815 | validation: 0.44818898966865983]
	TIME [epoch: 24.9 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46117163028853736		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.46117163028853736 | validation: 0.4535015843293414]
	TIME [epoch: 24.9 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4584150452241594		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.4584150452241594 | validation: 0.4627631050038275]
	TIME [epoch: 25 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568965316865389		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.4568965316865389 | validation: 0.47331954918658525]
	TIME [epoch: 24.9 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771864096932579		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.4771864096932579 | validation: 0.47364377779093403]
	TIME [epoch: 24.8 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822874467644818		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.4822874467644818 | validation: 0.4598337428429133]
	TIME [epoch: 24.9 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668132286116795		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.4668132286116795 | validation: 0.46734030310157665]
	TIME [epoch: 24.9 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45041889072767477		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.45041889072767477 | validation: 0.4827208937292472]
	TIME [epoch: 24.9 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45469749287835226		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.45469749287835226 | validation: 0.454187460064759]
	TIME [epoch: 24.9 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561901970607519		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.4561901970607519 | validation: 0.4686903566557957]
	TIME [epoch: 24.9 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45579982098415195		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.45579982098415195 | validation: 0.46393366632242505]
	TIME [epoch: 24.8 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46473707016278226		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.46473707016278226 | validation: 0.4519086344933231]
	TIME [epoch: 24.9 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4649022746086421		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.4649022746086421 | validation: 0.4389772870990089]
	TIME [epoch: 24.9 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686383483850929		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.4686383483850929 | validation: 0.44237472015947343]
	TIME [epoch: 24.8 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45969462431421		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.45969462431421 | validation: 0.4377483180281696]
	TIME [epoch: 24.9 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46428101201745686		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.46428101201745686 | validation: 0.44784192378730775]
	TIME [epoch: 24.9 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617404773654583		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.4617404773654583 | validation: 0.44615548894843426]
	TIME [epoch: 24.8 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46353719268081467		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.46353719268081467 | validation: 0.450354934170164]
	TIME [epoch: 24.9 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643237798250168		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.4643237798250168 | validation: 0.46694868103806464]
	TIME [epoch: 24.9 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671391570149698		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.4671391570149698 | validation: 0.4616909196824894]
	TIME [epoch: 24.8 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46120458886088234		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.46120458886088234 | validation: 0.44510901889895793]
	TIME [epoch: 24.9 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4619604292004673		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.4619604292004673 | validation: 0.44124486666057733]
	TIME [epoch: 24.9 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4557193591461587		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.4557193591461587 | validation: 0.4540049314618059]
	TIME [epoch: 24.8 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599894780107295		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.4599894780107295 | validation: 0.4588763506461879]
	TIME [epoch: 24.9 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748799475102759		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.4748799475102759 | validation: 0.4310816433803249]
	TIME [epoch: 24.9 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709041473045251		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.4709041473045251 | validation: 0.43868781057899525]
	TIME [epoch: 24.8 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744875272068207		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.4744875272068207 | validation: 0.44810562404936854]
	TIME [epoch: 24.9 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46271662157048166		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.46271662157048166 | validation: 0.4415332078886594]
	TIME [epoch: 24.9 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466926566621322		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.466926566621322 | validation: 0.4394053906619519]
	TIME [epoch: 24.9 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46534087087333265		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.46534087087333265 | validation: 0.4381536620827573]
	TIME [epoch: 24.9 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625699213464462		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.4625699213464462 | validation: 0.4474055955936902]
	TIME [epoch: 24.9 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46778337090743805		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.46778337090743805 | validation: 0.45132080964455]
	TIME [epoch: 24.9 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673034178224791		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.4673034178224791 | validation: 0.43616114591740307]
	TIME [epoch: 24.9 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4796991051730149		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.4796991051730149 | validation: 0.4326971943454746]
	TIME [epoch: 24.9 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47506774283993985		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.47506774283993985 | validation: 0.4307261579276015]
	TIME [epoch: 24.8 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745600594840601		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.4745600594840601 | validation: 0.4349475785949617]
	TIME [epoch: 24.9 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707233585312233		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.4707233585312233 | validation: 0.4296733024838774]
	TIME [epoch: 24.9 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47414288041163893		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.47414288041163893 | validation: 0.4421492656751586]
	TIME [epoch: 24.9 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47033107491951043		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.47033107491951043 | validation: 0.44676316332351584]
	TIME [epoch: 24.9 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676934947993736		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.4676934947993736 | validation: 0.4331454882472596]
	TIME [epoch: 24.9 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46644231122645874		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.46644231122645874 | validation: 0.43580495771831895]
	TIME [epoch: 24.8 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46364117876008104		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.46364117876008104 | validation: 0.43766145849295285]
	TIME [epoch: 24.9 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569713928798917		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.4569713928798917 | validation: 0.4721894852795683]
	TIME [epoch: 24.9 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657613189201634		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.4657613189201634 | validation: 0.47046602716818386]
	TIME [epoch: 24.8 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.461817402283322		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.461817402283322 | validation: 0.4550499066560788]
	TIME [epoch: 24.9 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45921463927357736		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.45921463927357736 | validation: 0.45897120918550527]
	TIME [epoch: 24.9 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647704891406999		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.4647704891406999 | validation: 0.4589600592071299]
	TIME [epoch: 24.8 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48165091790837133		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.48165091790837133 | validation: 0.47306108569831423]
	TIME [epoch: 24.9 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4666069401167475		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.4666069401167475 | validation: 0.4439624519910092]
	TIME [epoch: 24.9 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45481965853792555		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.45481965853792555 | validation: 0.43365124201044425]
	TIME [epoch: 24.8 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45977656893922914		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.45977656893922914 | validation: 0.44445694306529904]
	TIME [epoch: 24.9 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45000984532349625		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.45000984532349625 | validation: 0.42898417715955456]
	TIME [epoch: 24.9 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45990648602019213		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.45990648602019213 | validation: 0.44700537870737195]
	TIME [epoch: 24.8 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46428566895022244		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.46428566895022244 | validation: 0.457034892496758]
	TIME [epoch: 24.9 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549145138021868		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.4549145138021868 | validation: 0.4392609576352192]
	TIME [epoch: 24.9 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45836183176088224		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.45836183176088224 | validation: 0.46329652771944924]
	TIME [epoch: 24.8 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702350803626276		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.4702350803626276 | validation: 0.4333723721596839]
	TIME [epoch: 24.9 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616569572301294		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.4616569572301294 | validation: 0.4582371096514878]
	TIME [epoch: 24.9 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45542521387155327		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.45542521387155327 | validation: 0.44653333701866116]
	TIME [epoch: 24.8 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4541618448419257		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.4541618448419257 | validation: 0.45470211152807133]
	TIME [epoch: 24.9 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609646048847037		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.4609646048847037 | validation: 0.4688661322757571]
	TIME [epoch: 24.9 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46767882144955		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.46767882144955 | validation: 0.45390242558101707]
	TIME [epoch: 24.8 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46611879537701667		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.46611879537701667 | validation: 0.4738816391478888]
	TIME [epoch: 24.9 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689543934965039		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.4689543934965039 | validation: 0.4548936311064438]
	TIME [epoch: 24.9 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688126842390369		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.4688126842390369 | validation: 0.4585204136216547]
	TIME [epoch: 24.9 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681101368200533		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.4681101368200533 | validation: 0.46386760909615027]
	TIME [epoch: 24.9 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46695408200481864		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.46695408200481864 | validation: 0.45516875733165635]
	TIME [epoch: 24.9 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46493004205857696		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.46493004205857696 | validation: 0.4727467735999109]
	TIME [epoch: 24.8 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634474639147058		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.4634474639147058 | validation: 0.4702082563462224]
	TIME [epoch: 24.9 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777442362182259		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.4777442362182259 | validation: 0.47317559682211047]
	TIME [epoch: 24.9 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709601058438776		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.4709601058438776 | validation: 0.5123111033698121]
	TIME [epoch: 24.9 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827162852379457		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.4827162852379457 | validation: 0.49285657982451525]
	TIME [epoch: 24.9 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47118636971599415		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.47118636971599415 | validation: 0.464073632797526]
	TIME [epoch: 24.9 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46047693507603704		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.46047693507603704 | validation: 0.45079183008439855]
	TIME [epoch: 24.9 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594019893414105		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.4594019893414105 | validation: 0.445959658204323]
	TIME [epoch: 24.9 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45889511059960175		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.45889511059960175 | validation: 0.4280850537266286]
	TIME [epoch: 24.9 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621455663858183		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.4621455663858183 | validation: 0.4517155338604055]
	TIME [epoch: 24.9 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4606982033548483		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.4606982033548483 | validation: 0.4342106125840245]
	TIME [epoch: 24.9 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45261682531509995		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.45261682531509995 | validation: 0.4514676911976196]
	TIME [epoch: 24.9 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.463622044022323		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.463622044022323 | validation: 0.43827673126066474]
	TIME [epoch: 24.9 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45918600712234503		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.45918600712234503 | validation: 0.4445254088285964]
	TIME [epoch: 24.9 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604086803330271		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.4604086803330271 | validation: 0.44385789779586093]
	TIME [epoch: 24.9 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4622040953406874		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.4622040953406874 | validation: 0.43646325392457014]
	TIME [epoch: 24.9 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46136364229257776		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.46136364229257776 | validation: 0.4411190510124003]
	TIME [epoch: 24.9 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46210686158954944		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.46210686158954944 | validation: 0.44567690844468544]
	TIME [epoch: 24.9 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608013862617838		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.4608013862617838 | validation: 0.4443237279221038]
	TIME [epoch: 24.9 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528645320595391		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.4528645320595391 | validation: 0.44427506025505437]
	TIME [epoch: 24.9 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525294668121332		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.4525294668121332 | validation: 0.4616193603634712]
	TIME [epoch: 24.9 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536634072329503		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.4536634072329503 | validation: 0.49981424457743856]
	TIME [epoch: 24.9 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632969493593127		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.4632969493593127 | validation: 0.44933347477624735]
	TIME [epoch: 24.9 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573113825973452		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.4573113825973452 | validation: 0.4439743475857047]
	TIME [epoch: 24.9 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4542640025261426		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.4542640025261426 | validation: 0.4532588430231273]
	TIME [epoch: 24.9 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608307253010139		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.4608307253010139 | validation: 0.4614264294196168]
	TIME [epoch: 24.9 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582507720608179		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.4582507720608179 | validation: 0.4611546060079654]
	TIME [epoch: 24.9 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537234288674529		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.4537234288674529 | validation: 0.4356732921738366]
	TIME [epoch: 24.9 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457823680624769		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.457823680624769 | validation: 0.4540004065284271]
	TIME [epoch: 24.9 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45348102032689197		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.45348102032689197 | validation: 0.44834706198595814]
	TIME [epoch: 24.9 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45881136124639155		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.45881136124639155 | validation: 0.45020445964680045]
	TIME [epoch: 24.9 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553288592629647		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.4553288592629647 | validation: 0.4478901720601304]
	TIME [epoch: 24.9 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44769470336092254		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.44769470336092254 | validation: 0.4584532502780478]
	TIME [epoch: 24.9 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45686871668157336		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.45686871668157336 | validation: 0.45109846008780635]
	TIME [epoch: 24.9 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524381162423846		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.4524381162423846 | validation: 0.45300375132323645]
	TIME [epoch: 24.9 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45362930428401216		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.45362930428401216 | validation: 0.4386411940393502]
	TIME [epoch: 24.9 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453506683861748		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.453506683861748 | validation: 0.4574402470883521]
	TIME [epoch: 24.9 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608873852191084		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.4608873852191084 | validation: 0.4538235830817617]
	TIME [epoch: 24.9 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45218806607012724		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.45218806607012724 | validation: 0.4482363583152694]
	TIME [epoch: 24.9 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504135119227206		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.4504135119227206 | validation: 0.44504576404197255]
	TIME [epoch: 24.9 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498826002137227		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.4498826002137227 | validation: 0.4388142425249644]
	TIME [epoch: 24.9 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514588129244838		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.4514588129244838 | validation: 0.44866686010345136]
	TIME [epoch: 24.9 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45288950135384753		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.45288950135384753 | validation: 0.44210450191302886]
	TIME [epoch: 24.9 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45120394901307476		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.45120394901307476 | validation: 0.44136937702129003]
	TIME [epoch: 24.9 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480978959390628		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.4480978959390628 | validation: 0.45178086253880906]
	TIME [epoch: 24.9 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4507006660900761		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.4507006660900761 | validation: 0.45342275122591064]
	TIME [epoch: 24.9 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537565134483634		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.4537565134483634 | validation: 0.4522185506782064]
	TIME [epoch: 24.9 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45655504205994296		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.45655504205994296 | validation: 0.4488577583116677]
	TIME [epoch: 24.9 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551691304674981		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.4551691304674981 | validation: 0.4482028849674218]
	TIME [epoch: 24.9 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599433892008835		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.4599433892008835 | validation: 0.4338612902337005]
	TIME [epoch: 24.9 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46201014033009236		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.46201014033009236 | validation: 0.43592682269115585]
	TIME [epoch: 24.9 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549861180061722		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.4549861180061722 | validation: 0.4291343519854638]
	TIME [epoch: 24.9 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540276618891934		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.4540276618891934 | validation: 0.4321285443558043]
	TIME [epoch: 24.9 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673324792009983		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.4673324792009983 | validation: 0.42278686678385397]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1711.pth
	Model improved!!!
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45541431927580195		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.45541431927580195 | validation: 0.42719101388256436]
	TIME [epoch: 24.9 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457077899620402		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.457077899620402 | validation: 0.4314696700150728]
	TIME [epoch: 24.9 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452738736805893		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.452738736805893 | validation: 0.45008173980006255]
	TIME [epoch: 24.9 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553347822790606		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.4553347822790606 | validation: 0.4421035603248967]
	TIME [epoch: 24.9 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514463248922314		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.4514463248922314 | validation: 0.4504911795875383]
	TIME [epoch: 24.9 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45014473358375484		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.45014473358375484 | validation: 0.45108782123321756]
	TIME [epoch: 24.9 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45052945228661884		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.45052945228661884 | validation: 0.456252535584191]
	TIME [epoch: 24.9 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4519060428091405		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.4519060428091405 | validation: 0.43675957885644123]
	TIME [epoch: 24.9 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45521352642167895		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.45521352642167895 | validation: 0.4498678009383989]
	TIME [epoch: 24.9 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4443804804621696		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.4443804804621696 | validation: 0.4345584104829851]
	TIME [epoch: 24.9 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4541851779271151		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.4541851779271151 | validation: 0.4398457510961734]
	TIME [epoch: 24.9 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600397865611281		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.4600397865611281 | validation: 0.45010981400322236]
	TIME [epoch: 24.9 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45442516981925135		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.45442516981925135 | validation: 0.44858652316113484]
	TIME [epoch: 24.9 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45730436452775564		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.45730436452775564 | validation: 0.44138365083815684]
	TIME [epoch: 24.9 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525273961323494		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.4525273961323494 | validation: 0.45666229837335165]
	TIME [epoch: 24.9 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4566791638564146		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.4566791638564146 | validation: 0.4584408664737228]
	TIME [epoch: 24.9 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45414440482069196		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.45414440482069196 | validation: 0.47402862089696257]
	TIME [epoch: 24.9 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4611123419631909		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.4611123419631909 | validation: 0.4462824203295952]
	TIME [epoch: 24.9 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45104960207675193		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.45104960207675193 | validation: 0.446048800118014]
	TIME [epoch: 24.9 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4462147299418268		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.4462147299418268 | validation: 0.43073257811312443]
	TIME [epoch: 24.9 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536883166427277		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.4536883166427277 | validation: 0.4473479324216455]
	TIME [epoch: 24.9 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46141993171131723		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.46141993171131723 | validation: 0.43101750463816585]
	TIME [epoch: 24.9 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45473036520645427		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.45473036520645427 | validation: 0.45226744745096326]
	TIME [epoch: 24.9 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4471303019845512		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.4471303019845512 | validation: 0.4508039858832356]
	TIME [epoch: 24.9 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4519554979911422		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.4519554979911422 | validation: 0.44277444785073455]
	TIME [epoch: 24.9 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44485021868514146		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.44485021868514146 | validation: 0.44331413018459276]
	TIME [epoch: 24.9 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504589437140923		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.4504589437140923 | validation: 0.44655332232357525]
	TIME [epoch: 24.9 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45036430105492		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.45036430105492 | validation: 0.4339108739290448]
	TIME [epoch: 24.9 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533504119188953		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.4533504119188953 | validation: 0.4417366453394933]
	TIME [epoch: 24.9 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496270951001967		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.4496270951001967 | validation: 0.45146205884091006]
	TIME [epoch: 24.9 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45822817846572883		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.45822817846572883 | validation: 0.4538447198199391]
	TIME [epoch: 24.9 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4610652494146796		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.4610652494146796 | validation: 0.46337229735141977]
	TIME [epoch: 24.9 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45998464177836546		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.45998464177836546 | validation: 0.458916549571833]
	TIME [epoch: 24.9 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536258717617029		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.4536258717617029 | validation: 0.46155093607780223]
	TIME [epoch: 24.9 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45995584081758534		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.45995584081758534 | validation: 0.46310992228193665]
	TIME [epoch: 24.9 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45401323911029867		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.45401323911029867 | validation: 0.47121297240488236]
	TIME [epoch: 24.9 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523600680049054		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.4523600680049054 | validation: 0.43992760875855735]
	TIME [epoch: 24.9 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500385270887706		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.4500385270887706 | validation: 0.463543435081361]
	TIME [epoch: 24.9 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550280365570567		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.4550280365570567 | validation: 0.4451976037035587]
	TIME [epoch: 24.9 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551004920461145		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.4551004920461145 | validation: 0.43821266701721817]
	TIME [epoch: 24.9 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513953587586176		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.4513953587586176 | validation: 0.4354229319144831]
	TIME [epoch: 24.9 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45271570215375084		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.45271570215375084 | validation: 0.4347413149948007]
	TIME [epoch: 24.9 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45955272352568916		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.45955272352568916 | validation: 0.46371554946276766]
	TIME [epoch: 24.9 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585249704614694		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.4585249704614694 | validation: 0.4722974903409677]
	TIME [epoch: 24.9 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603637390781237		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.4603637390781237 | validation: 0.4358360699989979]
	TIME [epoch: 24.9 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44741097607194025		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.44741097607194025 | validation: 0.43665695286107176]
	TIME [epoch: 24.9 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45693077526446724		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.45693077526446724 | validation: 0.4526204504220928]
	TIME [epoch: 24.9 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596688383707523		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.4596688383707523 | validation: 0.44876450817050945]
	TIME [epoch: 24.9 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532220338591331		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.4532220338591331 | validation: 0.4568609376272695]
	TIME [epoch: 24.9 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44753905623724155		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.44753905623724155 | validation: 0.46003869184665064]
	TIME [epoch: 24.9 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.460519946145681		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.460519946145681 | validation: 0.46633014782504334]
	TIME [epoch: 24.9 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45875957772852477		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.45875957772852477 | validation: 0.4661021642569513]
	TIME [epoch: 24.9 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524979798010896		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.4524979798010896 | validation: 0.45657328812232584]
	TIME [epoch: 24.9 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46382762600107874		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.46382762600107874 | validation: 0.4800150044247992]
	TIME [epoch: 24.9 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528867353283764		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.4528867353283764 | validation: 0.4567110012580524]
	TIME [epoch: 24.9 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45012226321983734		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.45012226321983734 | validation: 0.4349045067986007]
	TIME [epoch: 24.9 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45222126626339026		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.45222126626339026 | validation: 0.46682998771689094]
	TIME [epoch: 24.9 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44893952035671053		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.44893952035671053 | validation: 0.45029267965127984]
	TIME [epoch: 24.9 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511984800514731		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.4511984800514731 | validation: 0.45380652461311416]
	TIME [epoch: 24.9 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44979760706264227		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.44979760706264227 | validation: 0.4382200456811603]
	TIME [epoch: 24.9 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45507814213679343		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.45507814213679343 | validation: 0.45270033488262423]
	TIME [epoch: 24.9 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492167312288248		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.4492167312288248 | validation: 0.4323851834006051]
	TIME [epoch: 24.9 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44728999500510996		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.44728999500510996 | validation: 0.4403425896431292]
	TIME [epoch: 24.9 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4516029676327078		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.4516029676327078 | validation: 0.453400982824125]
	TIME [epoch: 24.9 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45553332443235284		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.45553332443235284 | validation: 0.4565306067618869]
	TIME [epoch: 24.9 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.450017364424794		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.450017364424794 | validation: 0.46407710776032607]
	TIME [epoch: 24.9 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598393510633042		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.4598393510633042 | validation: 0.44436950760955335]
	TIME [epoch: 24.9 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45221004194850634		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.45221004194850634 | validation: 0.43733441823944963]
	TIME [epoch: 24.9 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45075890764225146		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.45075890764225146 | validation: 0.4340886395416771]
	TIME [epoch: 24.9 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45777377646928713		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.45777377646928713 | validation: 0.44472719799382165]
	TIME [epoch: 24.9 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45537025082629706		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.45537025082629706 | validation: 0.4416269454927712]
	TIME [epoch: 24.9 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4478487110791521		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.4478487110791521 | validation: 0.44736685120259256]
	TIME [epoch: 24.9 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44459188195905264		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.44459188195905264 | validation: 0.4501110598230669]
	TIME [epoch: 24.9 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45268292905492663		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.45268292905492663 | validation: 0.45245557903685785]
	TIME [epoch: 24.9 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4455074513525858		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.4455074513525858 | validation: 0.42868005386518304]
	TIME [epoch: 24.8 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4539900937541631		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.4539900937541631 | validation: 0.4480306262179968]
	TIME [epoch: 24.9 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547922104504664		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.4547922104504664 | validation: 0.44777498262979654]
	TIME [epoch: 24.9 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536044028597722		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.4536044028597722 | validation: 0.45161759146684205]
	TIME [epoch: 24.8 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656428457759064		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.4656428457759064 | validation: 0.46559832463799083]
	TIME [epoch: 24.9 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608713164052173		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.4608713164052173 | validation: 0.44084759523779865]
	TIME [epoch: 24.9 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45088829943158326		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.45088829943158326 | validation: 0.43640778871420666]
	TIME [epoch: 24.8 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528230545520269		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.4528230545520269 | validation: 0.44090104954664994]
	TIME [epoch: 24.9 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45136671039212717		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.45136671039212717 | validation: 0.43862072881320885]
	TIME [epoch: 24.9 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573856251395693		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.4573856251395693 | validation: 0.4293432840873898]
	TIME [epoch: 24.9 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532355858733351		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.4532355858733351 | validation: 0.4345281956896514]
	TIME [epoch: 24.9 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562897903421318		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.4562897903421318 | validation: 0.42562002577987945]
	TIME [epoch: 24.9 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565301046800798		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.4565301046800798 | validation: 0.4465376189383582]
	TIME [epoch: 24.9 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45251267131171025		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.45251267131171025 | validation: 0.447012733578666]
	TIME [epoch: 24.9 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45481687979860963		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.45481687979860963 | validation: 0.4510494922427185]
	TIME [epoch: 24.9 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617871338525908		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.4617871338525908 | validation: 0.45039970487004005]
	TIME [epoch: 24.8 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45694826950515716		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.45694826950515716 | validation: 0.4469083170715197]
	TIME [epoch: 24.9 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45314247081119474		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.45314247081119474 | validation: 0.44796341598023626]
	TIME [epoch: 24.9 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536207526660415		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.4536207526660415 | validation: 0.44012113877197523]
	TIME [epoch: 24.8 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583829350118911		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.4583829350118911 | validation: 0.4362742654471591]
	TIME [epoch: 24.9 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45437043051474346		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.45437043051474346 | validation: 0.4414644520839752]
	TIME [epoch: 24.9 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4605915445164743		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.4605915445164743 | validation: 0.43555470248082984]
	TIME [epoch: 24.8 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512682591239078		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.4512682591239078 | validation: 0.4302325560917216]
	TIME [epoch: 24.9 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44572214965003437		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.44572214965003437 | validation: 0.4385644884113838]
	TIME [epoch: 24.9 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473792810560486		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.4473792810560486 | validation: 0.4371432340102645]
	TIME [epoch: 24.8 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497553315633451		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.4497553315633451 | validation: 0.4492675671557014]
	TIME [epoch: 24.9 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4482140823247632		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.4482140823247632 | validation: 0.4221245220947564]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1812.pth
	Model improved!!!
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518090887701344		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.4518090887701344 | validation: 0.44376968350307394]
	TIME [epoch: 24.8 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45399582570289615		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.45399582570289615 | validation: 0.43892301658775906]
	TIME [epoch: 24.9 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44805333989662427		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.44805333989662427 | validation: 0.4408623805528092]
	TIME [epoch: 24.9 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45996384738830565		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.45996384738830565 | validation: 0.4661829482286598]
	TIME [epoch: 24.8 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46194730928811106		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.46194730928811106 | validation: 0.4638292961516154]
	TIME [epoch: 24.9 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449950253554669		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.449950253554669 | validation: 0.45042454034024915]
	TIME [epoch: 24.9 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548288770858296		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.4548288770858296 | validation: 0.43804510371514205]
	TIME [epoch: 24.8 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526981764105275		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.4526981764105275 | validation: 0.43559097218111237]
	TIME [epoch: 24.9 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44889738921483985		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.44889738921483985 | validation: 0.46461221418677534]
	TIME [epoch: 24.9 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565019849923285		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.4565019849923285 | validation: 0.4517879934387955]
	TIME [epoch: 24.8 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531502144656483		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.4531502144656483 | validation: 0.45443665188060933]
	TIME [epoch: 24.9 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45931870585274404		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.45931870585274404 | validation: 0.4550131810621693]
	TIME [epoch: 24.9 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45075788285651164		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.45075788285651164 | validation: 0.4634008388296577]
	TIME [epoch: 24.8 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45890981362472705		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.45890981362472705 | validation: 0.45933480912212865]
	TIME [epoch: 24.9 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4485467110613454		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.4485467110613454 | validation: 0.44897457824054626]
	TIME [epoch: 24.9 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45360551663123916		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.45360551663123916 | validation: 0.45983037888645706]
	TIME [epoch: 24.9 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4558747268601172		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.4558747268601172 | validation: 0.4624698273052603]
	TIME [epoch: 24.9 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45261650068668213		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.45261650068668213 | validation: 0.4658540419714669]
	TIME [epoch: 24.9 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.451943396126005		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.451943396126005 | validation: 0.45418536307277124]
	TIME [epoch: 24.9 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45097124804961164		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.45097124804961164 | validation: 0.4454279863973776]
	TIME [epoch: 24.9 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483672818763898		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.4483672818763898 | validation: 0.44608995605216]
	TIME [epoch: 24.9 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45512880400663913		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.45512880400663913 | validation: 0.4405585487762851]
	TIME [epoch: 24.9 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45631000158537127		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.45631000158537127 | validation: 0.43669173020930785]
	TIME [epoch: 24.9 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45103512783288646		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.45103512783288646 | validation: 0.42053991242755007]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r3_20240424_132604/states/model_tr_study5_1836.pth
	Model improved!!!
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44537093663455646		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.44537093663455646 | validation: 0.4345041388098617]
	TIME [epoch: 24.9 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4502754271801604		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.4502754271801604 | validation: 0.44194813220249146]
	TIME [epoch: 24.9 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458335590266092		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.458335590266092 | validation: 0.43130252801470625]
	TIME [epoch: 24.9 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45414331171328604		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.45414331171328604 | validation: 0.4405102910274315]
	TIME [epoch: 24.8 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4527298660944475		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.4527298660944475 | validation: 0.43767015127849435]
	TIME [epoch: 24.9 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4539925571799073		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.4539925571799073 | validation: 0.4422164254084542]
	TIME [epoch: 24.9 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510373822985735		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.4510373822985735 | validation: 0.4317236971143921]
	TIME [epoch: 24.8 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4546344244758458		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.4546344244758458 | validation: 0.43695503410536324]
	TIME [epoch: 24.9 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4484076393183092		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.4484076393183092 | validation: 0.4420595484513816]
	TIME [epoch: 24.9 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45712971074277603		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.45712971074277603 | validation: 0.4391310958040953]
	TIME [epoch: 24.8 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45263058033211434		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.45263058033211434 | validation: 0.4309716024805947]
	TIME [epoch: 24.9 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45422994078974754		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.45422994078974754 | validation: 0.4364164485830429]
	TIME [epoch: 24.9 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45772957874519643		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.45772957874519643 | validation: 0.4364503094859715]
	TIME [epoch: 24.8 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45365555271460606		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.45365555271460606 | validation: 0.43796077097525876]
	TIME [epoch: 24.9 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514506278158837		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.4514506278158837 | validation: 0.4543229643017908]
	TIME [epoch: 24.9 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4567112862153273		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.4567112862153273 | validation: 0.46855851962672773]
	TIME [epoch: 24.8 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46053568618290586		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.46053568618290586 | validation: 0.45093815036012286]
	TIME [epoch: 24.9 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45426913203047614		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.45426913203047614 | validation: 0.44781148634130996]
	TIME [epoch: 24.9 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582632977885287		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.4582632977885287 | validation: 0.46263725556964974]
	TIME [epoch: 24.8 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44644189970930814		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.44644189970930814 | validation: 0.44200816753435396]
	TIME [epoch: 24.9 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45874615237422		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.45874615237422 | validation: 0.4526238531850219]
	TIME [epoch: 24.9 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4494992447356808		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.4494992447356808 | validation: 0.43929293214059734]
	TIME [epoch: 24.8 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4510253053669526		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.4510253053669526 | validation: 0.4434019894374853]
	TIME [epoch: 24.9 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44543346111323295		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.44543346111323295 | validation: 0.44360641926369276]
	TIME [epoch: 24.9 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45094049555184995		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.45094049555184995 | validation: 0.4336699023287628]
	TIME [epoch: 24.8 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44870410541956196		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.44870410541956196 | validation: 0.4272881735554597]
	TIME [epoch: 24.9 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45208194646921757		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.45208194646921757 | validation: 0.4420372246906239]
	TIME [epoch: 24.9 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492797074662958		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.4492797074662958 | validation: 0.44235555864541865]
	TIME [epoch: 24.8 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45170441469383005		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.45170441469383005 | validation: 0.4503398682314007]
	TIME [epoch: 24.9 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4529046297481684		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.4529046297481684 | validation: 0.4477671228043236]
	TIME [epoch: 24.9 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44913204372663645		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.44913204372663645 | validation: 0.43799766087603414]
	TIME [epoch: 24.8 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489916070124043		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.4489916070124043 | validation: 0.43752086467272455]
	TIME [epoch: 24.9 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453535300140412		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.4453535300140412 | validation: 0.443257520841155]
	TIME [epoch: 24.9 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45461148000520335		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.45461148000520335 | validation: 0.43151322785357005]
	TIME [epoch: 24.8 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4536217166023734		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.4536217166023734 | validation: 0.44525977783733456]
	TIME [epoch: 24.9 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4508853627744236		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.4508853627744236 | validation: 0.449838575710846]
	TIME [epoch: 24.9 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45065233849262454		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.45065233849262454 | validation: 0.44876183928954405]
	TIME [epoch: 24.8 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4508206253600665		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.4508206253600665 | validation: 0.45822003144931195]
	TIME [epoch: 24.9 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504846785838025		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.4504846785838025 | validation: 0.4513968584378094]
	TIME [epoch: 24.9 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479905537864483		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.4479905537864483 | validation: 0.46444007310674623]
	TIME [epoch: 24.8 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45509523513065564		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.45509523513065564 | validation: 0.45326515421143426]
	TIME [epoch: 24.9 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560343823066588		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.4560343823066588 | validation: 0.4475060403642685]
	TIME [epoch: 24.9 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582173282090045		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.4582173282090045 | validation: 0.46185980339089117]
	TIME [epoch: 24.8 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45504457150228406		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.45504457150228406 | validation: 0.46005693171281997]
	TIME [epoch: 24.9 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554573396552229		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.4554573396552229 | validation: 0.45819497729511754]
	TIME [epoch: 24.9 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44652235340781743		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.44652235340781743 | validation: 0.46133026117325593]
	TIME [epoch: 24.9 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44957745533097937		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.44957745533097937 | validation: 0.4554259999523992]
	TIME [epoch: 24.9 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4540006320366866		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.4540006320366866 | validation: 0.4589457650166914]
	TIME [epoch: 24.9 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511613668189241		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.4511613668189241 | validation: 0.46099748637140353]
	TIME [epoch: 24.9 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44901661476868115		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.44901661476868115 | validation: 0.46650386964942864]
	TIME [epoch: 24.9 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45140767005217347		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.45140767005217347 | validation: 0.46670610088808395]
	TIME [epoch: 24.9 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4564645437575532		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.4564645437575532 | validation: 0.46898931836255003]
	TIME [epoch: 24.8 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495910629823958		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.4495910629823958 | validation: 0.47360793555674785]
	TIME [epoch: 24.9 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4495076549271859		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.4495076549271859 | validation: 0.46182967539905007]
	TIME [epoch: 24.9 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44981176972310327		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.44981176972310327 | validation: 0.4583327912592432]
	TIME [epoch: 24.9 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511314081404667		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.4511314081404667 | validation: 0.45491630918816117]
	TIME [epoch: 24.9 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442887630735604		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.442887630735604 | validation: 0.45478875084178977]
	TIME [epoch: 24.9 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4537723288254362		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.4537723288254362 | validation: 0.4518886995737015]
	TIME [epoch: 24.8 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454213353252779		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.454213353252779 | validation: 0.45684322328505766]
	TIME [epoch: 24.9 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488647098104947		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.4488647098104947 | validation: 0.440087483131706]
	TIME [epoch: 24.9 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45122704772403255		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.45122704772403255 | validation: 0.4601262783779045]
	TIME [epoch: 24.9 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488855111157691		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.4488855111157691 | validation: 0.4365504559496416]
	TIME [epoch: 24.9 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44385129210323526		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.44385129210323526 | validation: 0.4478778189222725]
	TIME [epoch: 24.9 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452001144438956		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.4452001144438956 | validation: 0.4578924213787963]
	TIME [epoch: 24.8 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4486841573044072		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.4486841573044072 | validation: 0.4537869396311842]
	TIME [epoch: 24.9 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447963658622928		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.4447963658622928 | validation: 0.45097586620809]
	TIME [epoch: 24.9 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44515709176021834		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.44515709176021834 | validation: 0.44797952728627466]
	TIME [epoch: 24.9 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472019480320303		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.4472019480320303 | validation: 0.4461364270818271]
	TIME [epoch: 24.9 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44484558242260464		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.44484558242260464 | validation: 0.4514264444370976]
	TIME [epoch: 24.9 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44652737307533275		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.44652737307533275 | validation: 0.4375498990995672]
	TIME [epoch: 24.8 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500107343792592		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.4500107343792592 | validation: 0.4379776353431663]
	TIME [epoch: 24.9 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44821881549926607		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.44821881549926607 | validation: 0.46547067504035505]
	TIME [epoch: 24.9 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44718379789598295		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.44718379789598295 | validation: 0.45042042607322674]
	TIME [epoch: 24.9 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45028884367097566		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.45028884367097566 | validation: 0.4636280211997976]
	TIME [epoch: 24.9 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44619229265298976		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.44619229265298976 | validation: 0.46313928106211655]
	TIME [epoch: 24.9 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.454629709899727		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.454629709899727 | validation: 0.46208416515076606]
	TIME [epoch: 24.8 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44544174594356706		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.44544174594356706 | validation: 0.449020320294346]
	TIME [epoch: 24.9 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.455280450491495		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.455280450491495 | validation: 0.4523906362644742]
	TIME [epoch: 24.9 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45059548185764553		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.45059548185764553 | validation: 0.44683938613836577]
	TIME [epoch: 24.8 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444742223594652		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.4444742223594652 | validation: 0.4511576313460319]
	TIME [epoch: 24.9 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488800786473348		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.4488800786473348 | validation: 0.4355036537918629]
	TIME [epoch: 24.9 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549265317284492		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.4549265317284492 | validation: 0.4370184946729876]
	TIME [epoch: 24.9 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490232791869437		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.4490232791869437 | validation: 0.45453991803223404]
	TIME [epoch: 24.9 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4455384715489795		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.4455384715489795 | validation: 0.45613064356676475]
	TIME [epoch: 24.9 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44447894735573784		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.44447894735573784 | validation: 0.45806048201336586]
	TIME [epoch: 24.9 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.447031325578239		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.447031325578239 | validation: 0.4447686356848724]
	TIME [epoch: 24.9 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449282372690332		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.4449282372690332 | validation: 0.44850692132451586]
	TIME [epoch: 24.9 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45192742718393253		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.45192742718393253 | validation: 0.45021146514148674]
	TIME [epoch: 24.9 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4475185416196711		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.4475185416196711 | validation: 0.44612519728724737]
	TIME [epoch: 24.9 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506149005366186		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.4506149005366186 | validation: 0.44758501756876085]
	TIME [epoch: 24.9 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4453295645458067		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.4453295645458067 | validation: 0.4463039573327379]
	TIME [epoch: 24.8 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44853966782053556		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.44853966782053556 | validation: 0.4521031108791528]
	TIME [epoch: 24.9 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44860470784063516		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.44860470784063516 | validation: 0.43886923869185274]
	TIME [epoch: 24.9 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45268186146034134		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.45268186146034134 | validation: 0.44461799439019745]
	TIME [epoch: 24.9 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4457118041087892		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.4457118041087892 | validation: 0.45054567385910915]
	TIME [epoch: 24.9 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489109071416869		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.4489109071416869 | validation: 0.44392740605100245]
	TIME [epoch: 24.9 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509539950572184		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.4509539950572184 | validation: 0.4284150126201052]
	TIME [epoch: 24.9 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.443519893995016		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.443519893995016 | validation: 0.4454953104614828]
	TIME [epoch: 24.9 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43999359493363527		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.43999359493363527 | validation: 0.439520625908481]
	TIME [epoch: 24.9 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44393463564800056		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.44393463564800056 | validation: 0.4442176163077675]
	TIME [epoch: 24.9 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441110064568881		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.441110064568881 | validation: 0.4474149166132507]
	TIME [epoch: 24.9 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44546914518976827		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.44546914518976827 | validation: 0.45785263998901715]
	TIME [epoch: 24.9 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45134454612154734		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.45134454612154734 | validation: 0.4417345888198581]
	TIME [epoch: 24.9 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480303660052732		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.4480303660052732 | validation: 0.4484705893533113]
	TIME [epoch: 24.9 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4505814949423099		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.4505814949423099 | validation: 0.45654732794758596]
	TIME [epoch: 24.9 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44092473370234014		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.44092473370234014 | validation: 0.4598925493055643]
	TIME [epoch: 24.9 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4527663008211092		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.4527663008211092 | validation: 0.46289310445250864]
	TIME [epoch: 24.9 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44168608885982263		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.44168608885982263 | validation: 0.43815080038203363]
	TIME [epoch: 24.9 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511097345475257		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.4511097345475257 | validation: 0.4441354964850166]
	TIME [epoch: 24.9 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4462605539933073		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.4462605539933073 | validation: 0.45486020811587835]
	TIME [epoch: 24.9 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523535840722972		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.4523535840722972 | validation: 0.443974173319206]
	TIME [epoch: 24.9 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4456870464155333		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.4456870464155333 | validation: 0.45556522619061507]
	TIME [epoch: 24.9 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44693725025370673		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.44693725025370673 | validation: 0.4469353106006141]
	TIME [epoch: 24.9 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44397753850035504		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.44397753850035504 | validation: 0.45709765487472]
	TIME [epoch: 24.9 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44688395471623016		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.44688395471623016 | validation: 0.45899963281744816]
	TIME [epoch: 24.9 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481040402514394		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.4481040402514394 | validation: 0.4403396139684432]
	TIME [epoch: 24.9 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44394525962076753		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.44394525962076753 | validation: 0.45794049359726724]
	TIME [epoch: 24.9 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44452923216696216		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.44452923216696216 | validation: 0.4459327632659198]
	TIME [epoch: 24.9 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44117565590453933		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.44117565590453933 | validation: 0.43745758762160253]
	TIME [epoch: 24.9 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480173123525845		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.4480173123525845 | validation: 0.4478495967116491]
	TIME [epoch: 24.9 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449456826126425		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.449456826126425 | validation: 0.45702025829253373]
	TIME [epoch: 24.9 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472241946712824		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.4472241946712824 | validation: 0.4539273496501257]
	TIME [epoch: 24.9 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4484240316968938		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.4484240316968938 | validation: 0.4673389457769711]
	TIME [epoch: 24.9 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44715554513466643		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.44715554513466643 | validation: 0.44685193850607785]
	TIME [epoch: 24.9 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44878890366689217		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.44878890366689217 | validation: 0.44781131922929696]
	TIME [epoch: 24.9 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44886012731317615		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.44886012731317615 | validation: 0.45230957344638967]
	TIME [epoch: 24.9 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44808191653801865		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.44808191653801865 | validation: 0.45396090362127867]
	TIME [epoch: 24.9 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45001288174251175		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.45001288174251175 | validation: 0.4559056690733537]
	TIME [epoch: 24.9 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506868307978656		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.4506868307978656 | validation: 0.4515087393674025]
	TIME [epoch: 24.9 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569878592274764		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.4569878592274764 | validation: 0.4577911424175558]
	TIME [epoch: 24.9 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513924664066417		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.4513924664066417 | validation: 0.443665501947428]
	TIME [epoch: 24.9 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548086031011582		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.4548086031011582 | validation: 0.4425703664221007]
	TIME [epoch: 24.9 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45047050197633076		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.45047050197633076 | validation: 0.4349507496149036]
	TIME [epoch: 24.9 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448412320257064		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.4448412320257064 | validation: 0.45345078674838596]
	TIME [epoch: 24.9 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4463820955823629		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.4463820955823629 | validation: 0.4416937445545767]
	TIME [epoch: 24.9 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44913410791596287		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.44913410791596287 | validation: 0.4392773784888565]
	TIME [epoch: 24.9 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4457253278483611		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.4457253278483611 | validation: 0.44206249460542574]
	TIME [epoch: 24.9 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44592000003550847		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.44592000003550847 | validation: 0.4264963560013467]
	TIME [epoch: 24.9 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44999807118265817		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.44999807118265817 | validation: 0.4335712744655507]
	TIME [epoch: 24.9 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4461271944202352		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.4461271944202352 | validation: 0.45814201484549855]
	TIME [epoch: 24.9 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451720766195311		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.4451720766195311 | validation: 0.44687878114957685]
	TIME [epoch: 24.9 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44265132366074633		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.44265132366074633 | validation: 0.45612695093629174]
	TIME [epoch: 24.9 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492745061236363		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.4492745061236363 | validation: 0.44836074874416354]
	TIME [epoch: 24.9 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4475474188814552		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.4475474188814552 | validation: 0.4614645011436984]
	TIME [epoch: 24.8 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45012681013519684		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.45012681013519684 | validation: 0.46243849802916137]
	TIME [epoch: 24.9 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44526394629463284		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.44526394629463284 | validation: 0.46445599130784276]
	TIME [epoch: 24.9 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45348639076184516		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.45348639076184516 | validation: 0.4701168783013071]
	TIME [epoch: 24.9 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44417309920785053		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.44417309920785053 | validation: 0.4718433147857911]
	TIME [epoch: 24.9 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4494306699206944		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.4494306699206944 | validation: 0.45011476132001277]
	TIME [epoch: 24.9 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496151109036104		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.4496151109036104 | validation: 0.4499662699167886]
	TIME [epoch: 24.8 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4514609498305753		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.4514609498305753 | validation: 0.445736773725327]
	TIME [epoch: 24.9 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44246612278431974		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.44246612278431974 | validation: 0.45114253476738575]
	TIME [epoch: 24.9 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44616619336467533		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.44616619336467533 | validation: 0.4508121241679629]
	TIME [epoch: 24.8 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44494449036031214		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.44494449036031214 | validation: 0.4578815401364289]
	TIME [epoch: 24.9 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44534099964633067		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.44534099964633067 | validation: 0.4416346539262448]
	TIME [epoch: 24.9 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44433054346495116		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.44433054346495116 | validation: 0.43806064181901355]
	TIME [epoch: 24.8 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4443840481817429		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.4443840481817429 | validation: 0.4489775640238727]
	TIME [epoch: 24.9 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44424057905875225		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.44424057905875225 | validation: 0.4471668552102939]
	TIME [epoch: 24.9 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44688071954012126		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.44688071954012126 | validation: 0.4448437900796507]
	TIME [epoch: 24.8 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44083277275354715		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.44083277275354715 | validation: 0.4338755961046104]
	TIME [epoch: 24.9 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.444454833038985		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.444454833038985 | validation: 0.4483216325437968]
	TIME [epoch: 24.9 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4438285955909701		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.4438285955909701 | validation: 0.43483580183693954]
	TIME [epoch: 24.8 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448166145459282		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.4448166145459282 | validation: 0.4410529377674699]
	TIME [epoch: 24.9 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4447954623635162		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.4447954623635162 | validation: 0.45068560912408195]
	TIME [epoch: 24.9 sec]
Finished training in 50012.824 seconds.
