Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r4', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r4', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4044715548

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.65527863835623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.65527863835623 | validation: 11.069761801212561]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.511629804043519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.511629804043519 | validation: 9.619674236574149]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.031862199230744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.031862199230744 | validation: 9.251962443805983]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.184842673841706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.184842673841706 | validation: 8.143565113109732]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.600993019275309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.600993019275309 | validation: 8.049442499161806]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.362485441227703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.362485441227703 | validation: 7.683048029507195]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.122418885664685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.122418885664685 | validation: 7.396361270650133]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.818115537341242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.818115537341242 | validation: 7.025875123325597]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5972018201282365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5972018201282365 | validation: 7.153337942365693]
	TIME [epoch: 25 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.658550182199873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.658550182199873 | validation: 6.778492789538314]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.481678692479566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.481678692479566 | validation: 6.690305220751725]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.318644401254469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.318644401254469 | validation: 6.4097923666554975]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.181889775489559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.181889775489559 | validation: 6.4326952386274865]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.133622167880352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.133622167880352 | validation: 6.381553661551874]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.153191701972194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153191701972194 | validation: 6.4461261731223365]
	TIME [epoch: 25.1 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.171660766341778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.171660766341778 | validation: 6.3425488498328]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.133363175553692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.133363175553692 | validation: 5.997586788053627]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.011197049784417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.011197049784417 | validation: 6.272197470941708]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.048046271134208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.048046271134208 | validation: 6.140516394766191]
	TIME [epoch: 24.9 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.962407311216867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.962407311216867 | validation: 6.183646239780708]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.92678003735636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.92678003735636 | validation: 6.016281215414031]
	TIME [epoch: 25.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002855572287959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002855572287959 | validation: 6.286165230300307]
	TIME [epoch: 25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.966025564615526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966025564615526 | validation: 6.078385607812094]
	TIME [epoch: 25.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.942191230203545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.942191230203545 | validation: 6.068034180773859]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.892172558470841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.892172558470841 | validation: 6.080808235231935]
	TIME [epoch: 25 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.921867885155871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.921867885155871 | validation: 6.0129326643225385]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.815337668797603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.815337668797603 | validation: 6.029392634792181]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9293258131938975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9293258131938975 | validation: 6.102588283293545]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.879283954085544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.879283954085544 | validation: 5.958044128157817]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.744396948182801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.744396948182801 | validation: 5.932709873142112]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834115177981999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834115177981999 | validation: 5.907007025567898]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.801663122268863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.801663122268863 | validation: 5.897219704425124]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.783489446644895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.783489446644895 | validation: 5.841223559082826]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.755354682853036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.755354682853036 | validation: 6.019725953230343]
	TIME [epoch: 25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1573479145333385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1573479145333385 | validation: 6.350837830916894]
	TIME [epoch: 25.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8898724477674005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8898724477674005 | validation: 6.064253869657957]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.134250500660272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.134250500660272 | validation: 5.964667901170948]
	TIME [epoch: 25.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.614728284662571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.614728284662571 | validation: 5.831336281508393]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.701365691409614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.701365691409614 | validation: 5.80274137039228]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.62684375239509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.62684375239509 | validation: 5.621709907506248]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.567121036789029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.567121036789029 | validation: 5.6465864947286795]
	TIME [epoch: 25.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.630196291417101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.630196291417101 | validation: 5.615398200475012]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.541934053317565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.541934053317565 | validation: 5.690386941569766]
	TIME [epoch: 25.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.496965199910955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.496965199910955 | validation: 5.725018862187501]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.61374151032218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.61374151032218 | validation: 5.596079187676995]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.542173160248506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.542173160248506 | validation: 5.53718905286152]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.398329860334284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.398329860334284 | validation: 5.641701706608176]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.524425296656713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.524425296656713 | validation: 5.188780736734052]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7826806065931295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7826806065931295 | validation: 5.792544413182096]
	TIME [epoch: 25 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.584351808510409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.584351808510409 | validation: 5.314848006417017]
	TIME [epoch: 25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.293057582705184		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.293057582705184 | validation: 5.362794365464679]
	TIME [epoch: 25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.084638102193723		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.084638102193723 | validation: 6.058641557973888]
	TIME [epoch: 25.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.638330537392699		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.638330537392699 | validation: 5.412736382046752]
	TIME [epoch: 25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.368742445101984		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.368742445101984 | validation: 5.326546810098334]
	TIME [epoch: 25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.07369776801405		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.07369776801405 | validation: 5.178600476210083]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.007487011970861		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.007487011970861 | validation: 4.625916552440917]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.656482024016478		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.656482024016478 | validation: 5.399786555666674]
	TIME [epoch: 25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2169885978323585		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.2169885978323585 | validation: 4.820594000511397]
	TIME [epoch: 25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535467306931041		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 4.535467306931041 | validation: 5.271242096298882]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.093812881312778		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.093812881312778 | validation: 4.45964424770935]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6323942657379185		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 4.6323942657379185 | validation: 4.801365008563534]
	TIME [epoch: 25 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.408876591100184		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.408876591100184 | validation: 5.864792282603035]
	TIME [epoch: 24.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9029456683044454		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.9029456683044454 | validation: 5.075547729073088]
	TIME [epoch: 25 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.998158195498178		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.998158195498178 | validation: 6.990894500475966]
	TIME [epoch: 25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.324610097154599		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 8.324610097154599 | validation: 7.126764739728315]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.357069492130622		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.357069492130622 | validation: 4.350472759492809]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.351434120028834		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.351434120028834 | validation: 4.257851718424355]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.631481450111641		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 6.631481450111641 | validation: 4.622608837729741]
	TIME [epoch: 24.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566501452070156		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.566501452070156 | validation: 4.75940098221621]
	TIME [epoch: 25 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.921768059715304		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.921768059715304 | validation: 5.069136600396576]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.687709269923538		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 4.687709269923538 | validation: 4.700227465058851]
	TIME [epoch: 24.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.580714628250678		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 4.580714628250678 | validation: 4.765911229377641]
	TIME [epoch: 25.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.624523862233515		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.624523862233515 | validation: 4.5600009817420775]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.384628864634916		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.384628864634916 | validation: 4.339586395728346]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7417723050189124		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 4.7417723050189124 | validation: 4.226176992364187]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.298630331202011		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.298630331202011 | validation: 4.171059368939352]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.712965553993623		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.712965553993623 | validation: 4.1826849313278105]
	TIME [epoch: 25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.454940614043924		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.454940614043924 | validation: 4.480215854630444]
	TIME [epoch: 25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.975447778897412		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.975447778897412 | validation: 4.472964861140203]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.242994602121611		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.242994602121611 | validation: 4.48981685770743]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4281115204341335		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 5.4281115204341335 | validation: 4.83383554923234]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.490925291696199		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.490925291696199 | validation: 4.263348820701396]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.296642106210026		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.296642106210026 | validation: 4.898601518230492]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6574375379683115		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 4.6574375379683115 | validation: 4.123902345323847]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.13144370002783		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 4.13144370002783 | validation: 4.503843416900696]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.168265112097766		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 4.168265112097766 | validation: 3.7843524080999784]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9770686171006533		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.9770686171006533 | validation: 4.95906773569789]
	TIME [epoch: 25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475910670857925		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 4.475910670857925 | validation: 4.055811812733325]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.457186312720441		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.457186312720441 | validation: 4.190418354039563]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.119291131592762		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.119291131592762 | validation: 3.8785497647606633]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.333034493509935		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.333034493509935 | validation: 6.67238256353435]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.686353823730559		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 5.686353823730559 | validation: 4.795298574407262]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.322302745815345		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 4.322302745815345 | validation: 4.195134371213656]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.031340564668251		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.031340564668251 | validation: 5.4547277196154775]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.295012693186468		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 5.295012693186468 | validation: 4.400919514565657]
	TIME [epoch: 25.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.550021055725676		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.550021055725676 | validation: 4.803858827325847]
	TIME [epoch: 25 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4328961005751015		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.4328961005751015 | validation: 4.542706477494669]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365753222800261		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 4.365753222800261 | validation: 4.511490651675768]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.163860948396587		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.163860948396587 | validation: 4.004370304327934]
	TIME [epoch: 25.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.690806457481625		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 4.690806457481625 | validation: 4.578076112514976]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.81297174919389		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 4.81297174919389 | validation: 4.8018573395576105]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.658466736882032		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.658466736882032 | validation: 4.082487847180625]
	TIME [epoch: 25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.195790505719858		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.195790505719858 | validation: 4.009546544632888]
	TIME [epoch: 25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9142071281185657		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.9142071281185657 | validation: 3.8213080973959155]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9680333502077243		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.9680333502077243 | validation: 3.87473894052582]
	TIME [epoch: 25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.453552452046556		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.453552452046556 | validation: 6.112012271043495]
	TIME [epoch: 25 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.481044105338316		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 5.481044105338316 | validation: 5.519590528460087]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.570436092072085		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.570436092072085 | validation: 4.001990034307554]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.206014267495257		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.206014267495257 | validation: 3.6958586784689347]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.467243412381199		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.467243412381199 | validation: 3.971665754901868]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.571470410936207		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 4.571470410936207 | validation: 4.367895110259952]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097170078094125		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.097170078094125 | validation: 3.755077941775011]
	TIME [epoch: 25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8005566466798015		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.8005566466798015 | validation: 3.8165476870060675]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1447928440899195		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.1447928440899195 | validation: 4.021511449400321]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.084342331335038		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.084342331335038 | validation: 4.615107922791834]
	TIME [epoch: 25 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.303737851079671		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 4.303737851079671 | validation: 3.852933973143354]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.940147341826316		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.940147341826316 | validation: 3.9777314747720345]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6662140339348745		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 4.6662140339348745 | validation: 4.5293570930280955]
	TIME [epoch: 25 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.272715544649953		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.272715544649953 | validation: 3.9972179908794843]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.149903800099377		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 4.149903800099377 | validation: 4.068972823791078]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.958550755468875		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.958550755468875 | validation: 5.136098578343499]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.587439364069153		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.587439364069153 | validation: 3.9081087386300055]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.820940458132209		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.820940458132209 | validation: 3.767324850238946]
	TIME [epoch: 24.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9727267311500176		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.9727267311500176 | validation: 3.673020501318547]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.904503522777077		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.904503522777077 | validation: 4.467250903930602]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.908421899931286		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.908421899931286 | validation: 4.751541218333699]
	TIME [epoch: 24.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.463607439521711		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.463607439521711 | validation: 4.694819948267188]
	TIME [epoch: 24.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.98054263664506		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 5.98054263664506 | validation: 8.561771854840952]
	TIME [epoch: 25 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.605146092817618		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 7.605146092817618 | validation: 5.088419670117278]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.559705219483742		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 4.559705219483742 | validation: 4.31721014480973]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.345465098724704		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.345465098724704 | validation: 4.319749930358037]
	TIME [epoch: 25 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.143028986026803		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 4.143028986026803 | validation: 3.801855603136228]
	TIME [epoch: 25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.055269787617345		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 4.055269787617345 | validation: 3.904791241349139]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.291383687691352		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.291383687691352 | validation: 3.977933059288807]
	TIME [epoch: 25 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.480180496143761		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 4.480180496143761 | validation: 3.751403276869123]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.901049006971408		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.901049006971408 | validation: 3.833687911934349]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1199958338375335		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 4.1199958338375335 | validation: 5.0067960055569465]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.452790123245985		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.452790123245985 | validation: 3.7876372623069154]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8524589623081402		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.8524589623081402 | validation: 3.6081907890348077]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.410340002639925		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 4.410340002639925 | validation: 3.9303550555923157]
	TIME [epoch: 25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8302832589538083		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.8302832589538083 | validation: 3.833600329848274]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7573206283169034		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.7573206283169034 | validation: 3.7767957331483193]
	TIME [epoch: 25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.782372160060267		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 3.782372160060267 | validation: 3.808471673142593]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7236612335879795		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.7236612335879795 | validation: 3.804633159235447]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9867306930019755		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.9867306930019755 | validation: 3.7883831555391674]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.801067096043195		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 3.801067096043195 | validation: 3.681295292945789]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.714562867663848		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 3.714562867663848 | validation: 3.8073759832553926]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.062748378551066		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 5.062748378551066 | validation: 5.26107502677643]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.343488589751066		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 5.343488589751066 | validation: 3.6816933731249106]
	TIME [epoch: 25 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9799918968359753		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 3.9799918968359753 | validation: 3.7203601934266617]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.848273721390346		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 3.848273721390346 | validation: 3.4990401183930238]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0109922823509345		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 4.0109922823509345 | validation: 6.118624464873467]
	TIME [epoch: 25 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.170391321484221		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 5.170391321484221 | validation: 4.315291105937484]
	TIME [epoch: 25 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.946707492842364		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.946707492842364 | validation: 4.022960815696498]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7786286968323806		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.7786286968323806 | validation: 3.5293348333262897]
	TIME [epoch: 25.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9714603305304013		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.9714603305304013 | validation: 4.0595121525722755]
	TIME [epoch: 25 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.046695722295955		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.046695722295955 | validation: 3.4671644745325514]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.023767180310487		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.023767180310487 | validation: 3.9405363795443873]
	TIME [epoch: 25 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9068839272339986		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.9068839272339986 | validation: 3.4705931346594117]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0676387671789564		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 4.0676387671789564 | validation: 5.25407809162132]
	TIME [epoch: 24.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.20579623239483		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 4.20579623239483 | validation: 3.719141912582181]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.236466266682796		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.236466266682796 | validation: 3.9643193074746104]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9308092544199584		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.9308092544199584 | validation: 3.534196103054278]
	TIME [epoch: 25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.669051721108231		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.669051721108231 | validation: 4.00405272863582]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.831957095213839		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.831957095213839 | validation: 3.2743254998310483]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4594018650503724		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.4594018650503724 | validation: 3.346372679447725]
	TIME [epoch: 24.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4088755900161547		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.4088755900161547 | validation: 3.421207401845962]
	TIME [epoch: 25 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7839401668745682		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.7839401668745682 | validation: 3.6272397486331]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6116765592994646		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.6116765592994646 | validation: 3.4177655418991266]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8844813913166085		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.8844813913166085 | validation: 3.6343447895372027]
	TIME [epoch: 25 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.277147620795228		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 4.277147620795228 | validation: 3.50765545445742]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6426942948408207		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.6426942948408207 | validation: 3.2400930519826887]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6421156980752616		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.6421156980752616 | validation: 3.315549124536861]
	TIME [epoch: 25 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4165989587916386		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.4165989587916386 | validation: 3.2913508596812733]
	TIME [epoch: 25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.554567362640417		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 3.554567362640417 | validation: 3.311038689477723]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9561844986603343		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 3.9561844986603343 | validation: 4.812464938147547]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.333568323211253		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.333568323211253 | validation: 4.080198601234725]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.992435079401416		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.992435079401416 | validation: 3.486098477793804]
	TIME [epoch: 25.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5173913707827205		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.5173913707827205 | validation: 3.610059262255188]
	TIME [epoch: 25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7163629805009686		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.7163629805009686 | validation: 3.5081358815833155]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380036994625854		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.380036994625854 | validation: 3.3870938431795414]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.058953593047358		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 4.058953593047358 | validation: 3.6088440480030064]
	TIME [epoch: 25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4812093284420618		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.4812093284420618 | validation: 3.165762900495463]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3329889666709613		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.3329889666709613 | validation: 3.8821889655953816]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9958143273758333		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.9958143273758333 | validation: 3.7377928347363776]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6080119805266557		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.6080119805266557 | validation: 3.207580697652693]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3930513012403973		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.3930513012403973 | validation: 3.5249809292123047]
	TIME [epoch: 24.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.033029286361661		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 4.033029286361661 | validation: 4.514123467540298]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8356037428987797		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.8356037428987797 | validation: 3.339018087522009]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.704538161917801		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.704538161917801 | validation: 4.436518952410297]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8248878012309575		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 4.8248878012309575 | validation: 4.883980752694161]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786038296704281		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 5.786038296704281 | validation: 4.798951813122906]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8971738274890733		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.8971738274890733 | validation: 3.6547990384741764]
	TIME [epoch: 24.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393137377119687		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.393137377119687 | validation: 3.3106354329087155]
	TIME [epoch: 25 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3881028536665054		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.3881028536665054 | validation: 3.1954666250048662]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258547283417439		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.258547283417439 | validation: 3.4825360052831162]
	TIME [epoch: 24.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4475921563491427		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.4475921563491427 | validation: 3.062883359142534]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0357205467377497		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.0357205467377497 | validation: 3.3248362840131156]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3267916361699017		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.3267916361699017 | validation: 3.177601692533159]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0629451483818957		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.0629451483818957 | validation: 2.8849442649168884]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.572775223972474		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 4.572775223972474 | validation: 6.494614289072236]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.684828782670547		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 5.684828782670547 | validation: 4.050155144591303]
	TIME [epoch: 24.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.634002315742582		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.634002315742582 | validation: 3.7532537889918185]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3803083436462384		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.3803083436462384 | validation: 3.041820380610967]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0872362063407746		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.0872362063407746 | validation: 3.1115615454951446]
	TIME [epoch: 24.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135834599664416		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.135834599664416 | validation: 2.9142879521124603]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9633453761368225		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.9633453761368225 | validation: 2.7189081948038916]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.993159213050321		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.993159213050321 | validation: 3.6439135084174263]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.85183703099648		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.85183703099648 | validation: 6.546139943779989]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.917606059814704		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 4.917606059814704 | validation: 4.106555193107767]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.522360765124465		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.522360765124465 | validation: 2.9147407980635625]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.281374628535954		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.281374628535954 | validation: 3.134628496252856]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.477793237861869		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.477793237861869 | validation: 3.1877442258429696]
	TIME [epoch: 25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1648615096635435		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.1648615096635435 | validation: 3.107747123069944]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2473567291128753		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.2473567291128753 | validation: 3.2582938157291443]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.375592777398867		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.375592777398867 | validation: 3.4585115589429063]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.954028567552572		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.954028567552572 | validation: 4.2060887144367065]
	TIME [epoch: 24.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.583128097464056		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.583128097464056 | validation: 2.975259613875348]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0515044323750873		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.0515044323750873 | validation: 2.8458256185550077]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0672672456654926		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.0672672456654926 | validation: 2.9314899010967457]
	TIME [epoch: 25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.09278072077394		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.09278072077394 | validation: 2.910316945538951]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1166700114467543		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.1166700114467543 | validation: 2.846116419431218]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.88490614871055		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.88490614871055 | validation: 3.6798284103713685]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1525285351484795		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.1525285351484795 | validation: 2.8810235635656887]
	TIME [epoch: 24.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.086715354331312		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.086715354331312 | validation: 3.045539436955711]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0874751712021014		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.0874751712021014 | validation: 2.737105745588246]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2710255076532064		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.2710255076532064 | validation: 3.3457100994077438]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.959710466229821		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 2.959710466229821 | validation: 2.89142030015876]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.033349665834722		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.033349665834722 | validation: 3.115921682063508]
	TIME [epoch: 25 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8747951122655637		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.8747951122655637 | validation: 2.6567187998381523]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0698441516203996		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.0698441516203996 | validation: 3.312344531138303]
	TIME [epoch: 25 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.197425269231784		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 4.197425269231784 | validation: 3.2059602955412565]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393418631787599		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.393418631787599 | validation: 2.7281803659607182]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0908455762657834		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.0908455762657834 | validation: 3.152641736362276]
	TIME [epoch: 25 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2383059889532637		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.2383059889532637 | validation: 3.85034890719218]
	TIME [epoch: 25 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4117648525079964		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 3.4117648525079964 | validation: 2.779786788221524]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9217447586390555		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 2.9217447586390555 | validation: 2.623025443848574]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.713047471241704		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 2.713047471241704 | validation: 3.4912265891847554]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9948144080644523		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 2.9948144080644523 | validation: 2.514384843845655]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7711570021424086		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.7711570021424086 | validation: 2.7896715839436554]
	TIME [epoch: 25 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3746470788839757		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.3746470788839757 | validation: 2.8834733802915524]
	TIME [epoch: 25 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.752007347436738		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 2.752007347436738 | validation: 3.1679560813961563]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.805390044309388		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 2.805390044309388 | validation: 2.645776996735937]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7602197814610947		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 2.7602197814610947 | validation: 2.75176087533357]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8727937538347605		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 2.8727937538347605 | validation: 2.8665213776734504]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.238211405206072		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.238211405206072 | validation: 2.7477032458839363]
	TIME [epoch: 25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9227726199024646		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 2.9227726199024646 | validation: 2.831610133265707]
	TIME [epoch: 25 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9448552814273494		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.9448552814273494 | validation: 2.93430904784392]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5800106934337244		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 3.5800106934337244 | validation: 4.936623449693591]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.521812695313531		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 3.521812695313531 | validation: 2.647204693962734]
	TIME [epoch: 25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6824603609404636		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 2.6824603609404636 | validation: 2.400597351709123]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3026788520280745		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.3026788520280745 | validation: 2.6033568466345742]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7953399794106675		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 2.7953399794106675 | validation: 2.7329052637180222]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.65359549593705		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 2.65359549593705 | validation: 2.4336598034535992]
	TIME [epoch: 25.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.466955989080918		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.466955989080918 | validation: 2.3790669525664927]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.738294861222446		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 2.738294861222446 | validation: 2.552881380685042]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.203302686208673		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.203302686208673 | validation: 2.683353932879884]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8264653221250633		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 2.8264653221250633 | validation: 2.7893058937556505]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.786862263447384		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 2.786862263447384 | validation: 2.4897708359777018]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4786453657229806		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 2.4786453657229806 | validation: 2.5907573619221442]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6732780120592707		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 2.6732780120592707 | validation: 2.430697502167893]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126143546137299		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.126143546137299 | validation: 2.8059185612140487]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0177161955217073		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.0177161955217073 | validation: 3.7642402088386633]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.914821111271786		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.914821111271786 | validation: 3.002448166481997]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.879711671174001		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 2.879711671174001 | validation: 3.0691782629546607]
	TIME [epoch: 25 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0909904087314315		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.0909904087314315 | validation: 3.1405138179665903]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6933597912978473		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 2.6933597912978473 | validation: 4.061992420108754]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515425561571546		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.515425561571546 | validation: 2.808991186738501]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.759353220032777		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 2.759353220032777 | validation: 2.6221093752930016]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.544500937051571		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.544500937051571 | validation: 2.572818250883677]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5309387881531706		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.5309387881531706 | validation: 2.4522275711489976]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.596395550468002		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 2.596395550468002 | validation: 2.607582075877397]
	TIME [epoch: 25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7564761399865723		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 2.7564761399865723 | validation: 2.6877027073569093]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5486808521815445		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 2.5486808521815445 | validation: 2.431361866416113]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.420086161204844		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 2.420086161204844 | validation: 2.327088829814648]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.626252968206605		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 2.626252968206605 | validation: 2.334623229420511]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.71407543973752		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 2.71407543973752 | validation: 2.3009323411721185]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.545226358297274		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.545226358297274 | validation: 2.3720719590811776]
	TIME [epoch: 25 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5342094384000013		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 2.5342094384000013 | validation: 2.6840939053492514]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.760037803335739		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 2.760037803335739 | validation: 2.3123537675569596]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4605193249072634		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 2.4605193249072634 | validation: 2.2189873682229657]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2067718977337227		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.2067718977337227 | validation: 2.7219326560307504]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6274687940840957		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 2.6274687940840957 | validation: 3.109226757108203]
	TIME [epoch: 24.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4192908792033774		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 2.4192908792033774 | validation: 3.46331002820009]
	TIME [epoch: 25 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.762688342221265		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 2.762688342221265 | validation: 2.505483151820923]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.404040017586702		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 2.404040017586702 | validation: 2.14251848778818]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31808426952237		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 2.31808426952237 | validation: 2.4177341937896553]
	TIME [epoch: 25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7161566348299315		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 2.7161566348299315 | validation: 2.429600041377686]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.645223825114965		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 2.645223825114965 | validation: 3.060371652795484]
	TIME [epoch: 24.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.815907186695511		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.815907186695511 | validation: 5.5643568828928665]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9087482351303953		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.9087482351303953 | validation: 2.6287518556494325]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4424167866614717		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.4424167866614717 | validation: 2.0864300077712]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2481503263515505		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.2481503263515505 | validation: 2.189900720156324]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3916482902510277		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.3916482902510277 | validation: 2.1722685501788557]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2693234187488835		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 2.2693234187488835 | validation: 1.9671972258669632]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0054648477501944		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 2.0054648477501944 | validation: 2.9070466116928437]
	TIME [epoch: 24.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.21531704333825		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 2.21531704333825 | validation: 3.7670509693030985]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5125094588135		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 2.5125094588135 | validation: 2.6229809025742363]
	TIME [epoch: 24.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.226460906173709		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.226460906173709 | validation: 3.4958057079652662]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5093592962800733		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 2.5093592962800733 | validation: 2.189265048941594]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1203489945994702		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 2.1203489945994702 | validation: 1.9190812293060606]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.156959597281264		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 2.156959597281264 | validation: 1.8394008966274344]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2439190203600656		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 2.2439190203600656 | validation: 1.9060915570019716]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.396538876410544		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.396538876410544 | validation: 4.055292330037632]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.29335032021334		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 3.29335032021334 | validation: 2.072827881102968]
	TIME [epoch: 24.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.051463478024401		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.051463478024401 | validation: 2.0752728338759034]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0282841113545818		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 2.0282841113545818 | validation: 1.8097908454313756]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30023754986665		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.30023754986665 | validation: 1.9803153032295193]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0237908129867237		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.0237908129867237 | validation: 4.470469211526593]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9877923134471853		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.9877923134471853 | validation: 1.6849182215563798]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1071907782527504		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 2.1071907782527504 | validation: 1.8560783942773764]
	TIME [epoch: 24.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7694702170915682		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.7694702170915682 | validation: 1.844050975978513]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9581943402943918		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.9581943402943918 | validation: 2.137682797720726]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0470065077596935		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 2.0470065077596935 | validation: 1.893057693902859]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0507792997265666		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.0507792997265666 | validation: 2.177915106075449]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.07983472321917		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.07983472321917 | validation: 3.131740582240453]
	TIME [epoch: 24.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.437524948282146		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 2.437524948282146 | validation: 2.620537960735699]
	TIME [epoch: 24.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.154564686325378		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 2.154564686325378 | validation: 2.09011995502722]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8427106596241676		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.8427106596241676 | validation: 1.8258780574348723]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.04255923970434		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 2.04255923970434 | validation: 1.9608157132712876]
	TIME [epoch: 25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8857423250360816		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.8857423250360816 | validation: 2.0950320424504176]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0460197835542124		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.0460197835542124 | validation: 1.8998577332410984]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752998214713521		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.752998214713521 | validation: 1.9819065206572846]
	TIME [epoch: 24.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.089103256001677		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.089103256001677 | validation: 2.15546799920533]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8100012239389782		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.8100012239389782 | validation: 1.644248133204173]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.214616302967269		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.214616302967269 | validation: 2.173882976038973]
	TIME [epoch: 24.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0739941922213325		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.0739941922213325 | validation: 1.7216409731849904]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2229938343184577		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.2229938343184577 | validation: 1.817034268549274]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9601975415629653		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.9601975415629653 | validation: 2.2358376068138845]
	TIME [epoch: 24.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7897552024639156		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.7897552024639156 | validation: 1.6385079325081975]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.768814372975283		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.768814372975283 | validation: 1.9751390629368053]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7349997023837778		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.7349997023837778 | validation: 1.9471222310572476]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7451207187861077		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.7451207187861077 | validation: 1.9931044085472907]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8006095611314459		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.8006095611314459 | validation: 2.048715346451148]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0049923348503356		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 2.0049923348503356 | validation: 1.9348594504769199]
	TIME [epoch: 24.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3737145140691807		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 2.3737145140691807 | validation: 1.870342313347267]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.792458650699202		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.792458650699202 | validation: 1.5621774581020191]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8311858409212949		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.8311858409212949 | validation: 1.7576643653675625]
	TIME [epoch: 24.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6466951536041494		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.6466951536041494 | validation: 2.166348199383019]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8047741877381807		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.8047741877381807 | validation: 1.636691570464199]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6337697300488112		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.6337697300488112 | validation: 1.692860932449811]
	TIME [epoch: 24.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6088379281886374		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.6088379281886374 | validation: 1.848487183175422]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6121639014626177		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.6121639014626177 | validation: 1.524276539988542]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7637615345261053		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.7637615345261053 | validation: 1.5948264903168041]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5712682875584774		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.5712682875584774 | validation: 1.432157630223294]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4307318099545432		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.4307318099545432 | validation: 1.5871908970696031]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3828376146018981		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.3828376146018981 | validation: 1.5577192628883634]
	TIME [epoch: 24.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5236686257789835		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.5236686257789835 | validation: 1.5410040169650967]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.504749897548459		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.504749897548459 | validation: 1.3825383028368265]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6241271908395625		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.6241271908395625 | validation: 1.4648163346522227]
	TIME [epoch: 24.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4389988194293872		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.4389988194293872 | validation: 1.6316853333932537]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4458362494839072		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.4458362494839072 | validation: 1.3412267818337058]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4046235746762044		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.4046235746762044 | validation: 1.4754281630864454]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.47714668460012		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.47714668460012 | validation: 1.523810662255352]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4008065175303184		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.4008065175303184 | validation: 1.570823404732461]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9409366489472566		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.9409366489472566 | validation: 1.5505233772441351]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.486089113683279		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.486089113683279 | validation: 1.5418362318332417]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.34688068174558		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 4.34688068174558 | validation: 4.965990353676305]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9960583463208312		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 2.9960583463208312 | validation: 1.9659752406199267]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.553479205428641		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.553479205428641 | validation: 1.2742342259064912]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274426586226545		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.274426586226545 | validation: 1.6184393686908496]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4585695885465364		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.4585695885465364 | validation: 1.2980389156102963]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3316350862598196		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.3316350862598196 | validation: 1.6649778862329327]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.282857046445676		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 2.282857046445676 | validation: 1.8736860007419063]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6041146081803428		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.6041146081803428 | validation: 1.3621889298670953]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5312280773381357		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.5312280773381357 | validation: 1.4685799141232878]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.428631599491586		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.428631599491586 | validation: 1.4851357076070304]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3560707407670933		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.3560707407670933 | validation: 1.2379935282294074]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3904702625315457		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.3904702625315457 | validation: 2.090079740240575]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5664890338210586		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.5664890338210586 | validation: 1.3037663194189295]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.670349022980768		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.670349022980768 | validation: 2.6168320282607445]
	TIME [epoch: 25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9894088803258014		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.9894088803258014 | validation: 1.772791569994928]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8028178730661377		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.8028178730661377 | validation: 1.3851820416582104]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6266915258305015		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.6266915258305015 | validation: 1.7388826839352354]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4037171395375059		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.4037171395375059 | validation: 1.346513410662699]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.464172423013682		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.464172423013682 | validation: 1.2028534519865246]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2205247430186812		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.2205247430186812 | validation: 1.3157117039778963]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3082423994782484		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.3082423994782484 | validation: 1.3852685937914435]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3713696464269085		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.3713696464269085 | validation: 1.2261456878223636]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6013772330802096		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.6013772330802096 | validation: 1.2186848175873737]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5195386179520174		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.5195386179520174 | validation: 1.2985011385545489]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.460008428086855		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.460008428086855 | validation: 1.5288755349810967]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9315657892394276		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 2.9315657892394276 | validation: 1.6754641313947907]
	TIME [epoch: 24.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5288644344398088		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.5288644344398088 | validation: 1.858033571600865]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3483383084732419		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.3483383084732419 | validation: 1.2658495266443737]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.319399041407605		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.319399041407605 | validation: 1.4421177363966744]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3347559391056518		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.3347559391056518 | validation: 1.7201835235474199]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384440264053305		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.384440264053305 | validation: 1.2781554578431218]
	TIME [epoch: 25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436952426379032		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.436952426379032 | validation: 1.770749187550178]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5267987112316597		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.5267987112316597 | validation: 1.3214188038612822]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5590683377040877		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.5590683377040877 | validation: 1.6092494919093294]
	TIME [epoch: 25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2630904479682723		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.2630904479682723 | validation: 1.2029347140760942]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3533070269958254		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.3533070269958254 | validation: 1.5087085763725918]
	TIME [epoch: 24.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.462935570816275		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.462935570816275 | validation: 2.054695994167761]
	TIME [epoch: 25 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4502712463666425		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.4502712463666425 | validation: 1.3486501389738306]
	TIME [epoch: 25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2845782679987496		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.2845782679987496 | validation: 1.2425709941742842]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2032062964013428		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.2032062964013428 | validation: 1.2476576638898482]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3362265830244124		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.3362265830244124 | validation: 1.0692765297669535]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1828436076662312		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.1828436076662312 | validation: 2.3194879664655357]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.691165761772788		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.691165761772788 | validation: 1.4848954145905418]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.291491267142061		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.291491267142061 | validation: 1.3264662249440886]
	TIME [epoch: 25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.318040747467629		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.318040747467629 | validation: 1.8365473351492045]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3991849215272434		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.3991849215272434 | validation: 1.3965864941580748]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.12677750140798		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.12677750140798 | validation: 1.2380386607744722]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154822786705987		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.154822786705987 | validation: 1.5582074351595054]
	TIME [epoch: 25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1719764738225538		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.1719764738225538 | validation: 1.3920959875959416]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3330254792112737		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.3330254792112737 | validation: 1.3795345649472788]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4537761516377228		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.4537761516377228 | validation: 1.988573147215495]
	TIME [epoch: 25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6476751026067393		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.6476751026067393 | validation: 1.4344917539679376]
	TIME [epoch: 24.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2293979470917944		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.2293979470917944 | validation: 1.1162206625102278]
	TIME [epoch: 24.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1129241794659477		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.1129241794659477 | validation: 1.1912491747548555]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3943486051300686		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3943486051300686 | validation: 2.187261225771928]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4776825912377078		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.4776825912377078 | validation: 1.3506481153102994]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3491282226720716		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.3491282226720716 | validation: 1.459489638941746]
	TIME [epoch: 25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1480408357025382		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.1480408357025382 | validation: 1.0940460053174081]
	TIME [epoch: 24.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0467731645803577		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.0467731645803577 | validation: 1.0643934863586495]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0665937355325086		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.0665937355325086 | validation: 1.0877828202747486]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3866171603335222		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.3866171603335222 | validation: 1.39059500418331]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1075005559323892		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.1075005559323892 | validation: 1.0753662530960204]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1080998676455187		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.1080998676455187 | validation: 1.4722041426451447]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.177814448221079		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.177814448221079 | validation: 1.3272262981541334]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1948820827319704		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.1948820827319704 | validation: 1.4160415886480962]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.195008293338298		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.195008293338298 | validation: 1.474302848180505]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2713701675237277		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.2713701675237277 | validation: 1.7560087658099843]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1059506868196336		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.1059506868196336 | validation: 1.282104534008405]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0555843532729496		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.0555843532729496 | validation: 0.920978697928218]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0287036301795773		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.0287036301795773 | validation: 1.04734147843201]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.442800992504556		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.442800992504556 | validation: 0.9609070114511481]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9922251942436734		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.9922251942436734 | validation: 1.1021623710992512]
	TIME [epoch: 25.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0437078708785472		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.0437078708785472 | validation: 1.3406249032406492]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0303519327861708		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.0303519327861708 | validation: 0.9516356294841309]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0195567447464189		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 1.0195567447464189 | validation: 1.3095877051763307]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.085311289885309		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.085311289885309 | validation: 0.8596140398635131]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.099928940962912		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.099928940962912 | validation: 0.8170905941816566]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189647286763087		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.9189647286763087 | validation: 1.00121653202164]
	TIME [epoch: 25.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1259482139577441		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.1259482139577441 | validation: 1.2553436713086654]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1004858497842707		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.1004858497842707 | validation: 0.9945971603566676]
	TIME [epoch: 25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9922223926992271		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.9922223926992271 | validation: 1.3340702681473602]
	TIME [epoch: 25.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066786366862068		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.066786366862068 | validation: 1.1716943155507773]
	TIME [epoch: 25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2223253201373891		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.2223253201373891 | validation: 1.276359338956711]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9606152317297567		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.9606152317297567 | validation: 1.0271723029402682]
	TIME [epoch: 25.1 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176683911863243		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.9176683911863243 | validation: 1.892292669121998]
	TIME [epoch: 25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146971245765178		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.146971245765178 | validation: 0.8847708518360835]
	TIME [epoch: 25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0997877035500019		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 1.0997877035500019 | validation: 1.1855028836551964]
	TIME [epoch: 25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.710764602329521		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.710764602329521 | validation: 1.9306887526026089]
	TIME [epoch: 25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2517918111008486		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.2517918111008486 | validation: 0.9813858024856643]
	TIME [epoch: 25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.895624699074196		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.895624699074196 | validation: 1.0514965322681937]
	TIME [epoch: 25.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9357990142587067		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.9357990142587067 | validation: 0.9338603731467408]
	TIME [epoch: 25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0484523877571443		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.0484523877571443 | validation: 0.9374515826872447]
	TIME [epoch: 25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891069562656736		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.9891069562656736 | validation: 0.8773504811984507]
	TIME [epoch: 25.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1103187236864343		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.1103187236864343 | validation: 1.081803883570079]
	TIME [epoch: 25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8606922295406911		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.8606922295406911 | validation: 0.9434673319591639]
	TIME [epoch: 25 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8744155271544196		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8744155271544196 | validation: 1.121785046129669]
	TIME [epoch: 25.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9813829682775191		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.9813829682775191 | validation: 0.8325822619168406]
	TIME [epoch: 25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9081376618394257		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.9081376618394257 | validation: 1.0883130156959]
	TIME [epoch: 25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258893422357083		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.0258893422357083 | validation: 0.9431996057702564]
	TIME [epoch: 25.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9008624289642557		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.9008624289642557 | validation: 1.2448187442154686]
	TIME [epoch: 25 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8996787500583563		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.8996787500583563 | validation: 0.9935677600204512]
	TIME [epoch: 25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8293229497632599		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.8293229497632599 | validation: 0.8009834489697261]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7931537628484908		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.7931537628484908 | validation: 1.0688855190399948]
	TIME [epoch: 25 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034985256002888		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 1.034985256002888 | validation: 0.8004102121773113]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4912313018255008		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.4912313018255008 | validation: 1.2792538489918135]
	TIME [epoch: 25.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9602021139925271		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.9602021139925271 | validation: 1.4518671727323105]
	TIME [epoch: 25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1029582721860718		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.1029582721860718 | validation: 0.9299987185797746]
	TIME [epoch: 25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9321201454107446		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.9321201454107446 | validation: 1.2099521927321895]
	TIME [epoch: 25.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.95044761420445		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.95044761420445 | validation: 1.0231694876271344]
	TIME [epoch: 25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2794555428462422		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.2794555428462422 | validation: 1.605667865493515]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.258906635058021		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.258906635058021 | validation: 1.4444519870121242]
	TIME [epoch: 25.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1572248540630334		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.1572248540630334 | validation: 1.1296054281181045]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6202316699116701		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.6202316699116701 | validation: 1.4913288653097934]
	TIME [epoch: 25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705666363001998		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.0705666363001998 | validation: 1.0505128203517913]
	TIME [epoch: 25.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336638317720152		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.9336638317720152 | validation: 1.2606449448160706]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9183450372079274		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.9183450372079274 | validation: 1.3158297780555983]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.990027579090198		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.990027579090198 | validation: 0.9569686619321207]
	TIME [epoch: 25.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8549237590363467		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.8549237590363467 | validation: 0.8436189935288587]
	TIME [epoch: 25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8885331976778925		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.8885331976778925 | validation: 1.0101221886708684]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3667560673440227		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.3667560673440227 | validation: 1.6394770601962096]
	TIME [epoch: 25.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1396005078102436		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.1396005078102436 | validation: 1.315527199978839]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0302248814129986		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.0302248814129986 | validation: 1.3679792991079627]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9389026353149841		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.9389026353149841 | validation: 1.0262981096708246]
	TIME [epoch: 25.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8822990750897347		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.8822990750897347 | validation: 0.9202272568157511]
	TIME [epoch: 25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9679314736578142		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.9679314736578142 | validation: 1.4440833292431006]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0212121718650788		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.0212121718650788 | validation: 0.9417365195984116]
	TIME [epoch: 25.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.87246477999528		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.87246477999528 | validation: 0.7946047679062344]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8133064395816975		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.8133064395816975 | validation: 0.9207033987774881]
	TIME [epoch: 25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0727011064978151		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.0727011064978151 | validation: 0.8580226255185861]
	TIME [epoch: 25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.062758137007176		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.062758137007176 | validation: 0.7897932067421561]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1549766997042172		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.1549766997042172 | validation: 1.9290473139573907]
	TIME [epoch: 25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0741388053194496		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.0741388053194496 | validation: 1.1483461305320986]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8410687425333667		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.8410687425333667 | validation: 1.0960293685901508]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1820113852756768		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.1820113852756768 | validation: 1.2031008551852476]
	TIME [epoch: 25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9536593584131122		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.9536593584131122 | validation: 0.8664505100951715]
	TIME [epoch: 25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832758662441609		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.832758662441609 | validation: 0.8069947204869931]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0283108559059357		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.0283108559059357 | validation: 0.8721105187110891]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0621842731195321		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.0621842731195321 | validation: 1.1860755812919141]
	TIME [epoch: 25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8222088890122501		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.8222088890122501 | validation: 1.6838395668942985]
	TIME [epoch: 25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244529875607626		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.0244529875607626 | validation: 1.0973784634749555]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.020054281777551		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 1.020054281777551 | validation: 1.4979325454334729]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2944988622719928		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.2944988622719928 | validation: 1.8597711326605515]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2882825173949999		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.2882825173949999 | validation: 1.883210775188029]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1606076129851661		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.1606076129851661 | validation: 0.9006336196413932]
	TIME [epoch: 25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8362940649366075		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.8362940649366075 | validation: 1.0655886435635593]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.111071808740286		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.111071808740286 | validation: 1.04141548025391]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8439838567218307		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.8439838567218307 | validation: 0.8627687059031159]
	TIME [epoch: 25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8935524706182022		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8935524706182022 | validation: 1.1844186533431023]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.076655176710039		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.076655176710039 | validation: 1.9639106589798259]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268945268412413		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.268945268412413 | validation: 2.1178272735300916]
	TIME [epoch: 25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3274557852942634		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 3.3274557852942634 | validation: 3.2539416882062246]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1855558990782495		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 2.1855558990782495 | validation: 1.281969362971436]
	TIME [epoch: 25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5132522952167515		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.5132522952167515 | validation: 1.2664451924429312]
	TIME [epoch: 25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8241641979967097		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.8241641979967097 | validation: 0.8206360694288675]
	TIME [epoch: 25 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2181356389114744		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.2181356389114744 | validation: 1.62602543371641]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1828028583577912		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 1.1828028583577912 | validation: 0.9820465503831132]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8726143299731255		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.8726143299731255 | validation: 0.7981037609221963]
	TIME [epoch: 25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8242181968753116		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.8242181968753116 | validation: 0.9259974664142625]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7618525854091119		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.7618525854091119 | validation: 0.8701751998667498]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.756238164970035		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.756238164970035 | validation: 0.8099067023474984]
	TIME [epoch: 25 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186843492183905		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.8186843492183905 | validation: 0.8065572673511133]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8768679812062299		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.8768679812062299 | validation: 1.7689180150049988]
	TIME [epoch: 25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2131660756502514		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.2131660756502514 | validation: 0.9036911143901393]
	TIME [epoch: 25 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7572850384846601		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.7572850384846601 | validation: 0.9037266494243662]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8654614786192948		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.8654614786192948 | validation: 0.9872078093639033]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8939672256591917		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.8939672256591917 | validation: 1.3190300031230817]
	TIME [epoch: 25 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.091042469994623		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 1.091042469994623 | validation: 1.4047410741609623]
	TIME [epoch: 25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9965740289600683		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.9965740289600683 | validation: 1.087646626349985]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9015138513080418		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.9015138513080418 | validation: 1.5911911730230837]
	TIME [epoch: 25 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1811582105066423		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.1811582105066423 | validation: 0.8889549329470978]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8418925201343239		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.8418925201343239 | validation: 0.8126167582112642]
	TIME [epoch: 25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014645468848062		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 1.014645468848062 | validation: 1.0460412625616176]
	TIME [epoch: 25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8698468761196472		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8698468761196472 | validation: 0.9380755423132405]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.78797670080563		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.78797670080563 | validation: 1.16052275700091]
	TIME [epoch: 25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.02771733362206		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.02771733362206 | validation: 0.8570343748039696]
	TIME [epoch: 25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708201446154859		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.7708201446154859 | validation: 0.853298243123204]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7673481258311607		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7673481258311607 | validation: 1.0021774160333288]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00622313156143		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 1.00622313156143 | validation: 0.9471061750270342]
	TIME [epoch: 25 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9245286193634321		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.9245286193634321 | validation: 0.8724588052211177]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240812032092105		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8240812032092105 | validation: 1.1150678163488796]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8783313645629499		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.8783313645629499 | validation: 0.9060597536674037]
	TIME [epoch: 25 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2477185412730118		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 1.2477185412730118 | validation: 1.7234398950905825]
	TIME [epoch: 25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3455500957790707		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.3455500957790707 | validation: 2.040337148498082]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2528635313304117		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 1.2528635313304117 | validation: 0.9158555632949714]
	TIME [epoch: 25 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9410887675360567		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.9410887675360567 | validation: 0.8848885763354468]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9489518772258597		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.9489518772258597 | validation: 0.990265898568083]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7614619488725601		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.7614619488725601 | validation: 0.843297019122482]
	TIME [epoch: 25 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816097164256133		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.8816097164256133 | validation: 1.2535272075113224]
	TIME [epoch: 25 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0261018911019262		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 1.0261018911019262 | validation: 1.444554474101488]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5612419520187892		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 1.5612419520187892 | validation: 1.3540973363292506]
	TIME [epoch: 25 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8942098496861696		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.8942098496861696 | validation: 1.3251936510211904]
	TIME [epoch: 25 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9207511324822997		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.9207511324822997 | validation: 1.0394305046007926]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8285752423540351		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.8285752423540351 | validation: 1.0048865713008746]
	TIME [epoch: 25 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8182578584871065		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.8182578584871065 | validation: 1.103154399043732]
	TIME [epoch: 25 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8043373117590468		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8043373117590468 | validation: 0.9870021560511772]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8611003311833287		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.8611003311833287 | validation: 1.1493176699220076]
	TIME [epoch: 25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8356621718085782		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.8356621718085782 | validation: 0.8114001516859269]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7489761761883335		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.7489761761883335 | validation: 0.9949873492631371]
	TIME [epoch: 25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8679470624326727		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.8679470624326727 | validation: 0.9532483323809697]
	TIME [epoch: 25 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8346661333109435		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.8346661333109435 | validation: 0.8454189272347926]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692527004228202		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.7692527004228202 | validation: 0.9455586202051808]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8821216137035812		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.8821216137035812 | validation: 0.9838046303645394]
	TIME [epoch: 25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.087307760446472		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 1.087307760446472 | validation: 3.8105140297881857]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4883253247592623		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 2.4883253247592623 | validation: 1.853893486468665]
	TIME [epoch: 25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1408819283869633		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 1.1408819283869633 | validation: 0.9002912316853824]
	TIME [epoch: 25 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9213636925191941		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.9213636925191941 | validation: 1.2786740551163436]
	TIME [epoch: 25 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8789175945198799		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.8789175945198799 | validation: 0.9475228508331104]
	TIME [epoch: 25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.827869128991776		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.827869128991776 | validation: 0.9903520615428419]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0906659388163302		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 1.0906659388163302 | validation: 1.444184860649026]
	TIME [epoch: 25 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.007309370818687		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.007309370818687 | validation: 1.131541415633793]
	TIME [epoch: 25 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1668772947087978		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.1668772947087978 | validation: 1.0102002770053093]
	TIME [epoch: 25 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8394957184508004		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.8394957184508004 | validation: 0.8996457264672415]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0516989710059375		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.0516989710059375 | validation: 1.1488066309750038]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4038902897502885		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.4038902897502885 | validation: 1.917698279820848]
	TIME [epoch: 25 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3483209542513261		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 1.3483209542513261 | validation: 1.7759087358192653]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2417108582511496		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.2417108582511496 | validation: 0.9166290792649707]
	TIME [epoch: 25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8610424903375021		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.8610424903375021 | validation: 1.6774108411626583]
	TIME [epoch: 25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.128322763338211		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 1.128322763338211 | validation: 2.005347723118113]
	TIME [epoch: 25 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5312308349735295		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 1.5312308349735295 | validation: 0.9968760327029824]
	TIME [epoch: 25 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9769016422147967		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.9769016422147967 | validation: 1.0586136809242366]
	TIME [epoch: 25 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794884888517752		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.9794884888517752 | validation: 1.0039741567264446]
	TIME [epoch: 25 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8510852483900551		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.8510852483900551 | validation: 1.000528731449912]
	TIME [epoch: 25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9363351781655274		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.9363351781655274 | validation: 1.4160951089826315]
	TIME [epoch: 25 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9339221663741982		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.9339221663741982 | validation: 1.7194884716091945]
	TIME [epoch: 25 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1469674575154187		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 1.1469674575154187 | validation: 0.9941944737131272]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816415694963062		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.8816415694963062 | validation: 1.0458563250997386]
	TIME [epoch: 25 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8972786085304496		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.8972786085304496 | validation: 0.9507299498354408]
	TIME [epoch: 25 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8453292663502303		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.8453292663502303 | validation: 1.1631879046086655]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486217780515499		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.8486217780515499 | validation: 2.345807484488954]
	TIME [epoch: 25 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.698448756411731		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 2.698448756411731 | validation: 1.1183235680180936]
	TIME [epoch: 25 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0030049087806199		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 1.0030049087806199 | validation: 1.5045492758875716]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9769787472584651		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.9769787472584651 | validation: 0.9256414504238734]
	TIME [epoch: 25 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419627625189545		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.8419627625189545 | validation: 2.161321509738162]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5193517649076054		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.5193517649076054 | validation: 1.036863225508648]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8079283592333555		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.8079283592333555 | validation: 0.8644841970187863]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.583020687925063		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 1.583020687925063 | validation: 2.141578437372154]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2698078663073002		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 1.2698078663073002 | validation: 1.0890913776496922]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8296873652778953		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.8296873652778953 | validation: 0.973077667041036]
	TIME [epoch: 25 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7271207377169757		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.7271207377169757 | validation: 0.8364753428983441]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9735326468351806		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.9735326468351806 | validation: 0.9150234695762831]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9809091822570893		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.9809091822570893 | validation: 0.8342497461509532]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9687809896906519		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.9687809896906519 | validation: 0.9825762389723249]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.816500484374117		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.816500484374117 | validation: 1.206224054426694]
	TIME [epoch: 25 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.564555984899166		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 1.564555984899166 | validation: 0.8282392954069482]
	TIME [epoch: 25 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351625950523831		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.8351625950523831 | validation: 1.2129909702917214]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8975988319175657		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.8975988319175657 | validation: 0.9811450256925067]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8740892878031796		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.8740892878031796 | validation: 1.0415061112942954]
	TIME [epoch: 25 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9713015166835545		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.9713015166835545 | validation: 0.9229025226113495]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0359680093346781		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.0359680093346781 | validation: 1.7347286515441638]
	TIME [epoch: 25 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5750095744698873		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 1.5750095744698873 | validation: 1.4506942807435455]
	TIME [epoch: 25 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9510455180393593		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.9510455180393593 | validation: 1.3347645672744104]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9402408519944316		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.9402408519944316 | validation: 0.8904588403273641]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733812897431885		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.733812897431885 | validation: 0.9604796251782692]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7882872503749367		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.7882872503749367 | validation: 1.0432427757813392]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7834305977215106		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.7834305977215106 | validation: 0.9572977086767235]
	TIME [epoch: 25 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8355597587799235		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.8355597587799235 | validation: 0.9447404921835724]
	TIME [epoch: 25 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8657536517663621		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.8657536517663621 | validation: 1.4229688794842243]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.830953171882864		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.830953171882864 | validation: 0.7883388327027697]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.748939407402467		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 1.748939407402467 | validation: 1.3851019778804778]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9461186707065439		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.9461186707065439 | validation: 0.8521512281100102]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7913208633441385		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.7913208633441385 | validation: 0.8458302782014876]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322101463897079		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.7322101463897079 | validation: 0.8532223105846037]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8211776521920113		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.8211776521920113 | validation: 1.0869735767112536]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805566624290274		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.805566624290274 | validation: 0.968622499538501]
	TIME [epoch: 25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8113961045595508		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.8113961045595508 | validation: 0.9207662369386259]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7967003949816025		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.7967003949816025 | validation: 1.3031820079698115]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7998269374077966		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.7998269374077966 | validation: 1.4008488385460165]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0926711200804047		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.0926711200804047 | validation: 0.8677464360846631]
	TIME [epoch: 25 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821545061981035		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.821545061981035 | validation: 1.007296787163944]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8249195656127303		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.8249195656127303 | validation: 0.9392876891874927]
	TIME [epoch: 25 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1514871495710566		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 1.1514871495710566 | validation: 1.4782743974606434]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347926131320821		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.9347926131320821 | validation: 1.5442991853471393]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1463117601453572		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 1.1463117601453572 | validation: 1.699228343202118]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0340069118045998		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 1.0340069118045998 | validation: 0.9771213156480067]
	TIME [epoch: 25 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0160648289959582		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 1.0160648289959582 | validation: 0.9815173515887609]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090081331512936		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.8090081331512936 | validation: 0.8417050457447802]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216734546840538		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.7216734546840538 | validation: 0.9550927668475031]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8016124573761781		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.8016124573761781 | validation: 0.8552725939764596]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557820664216872		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 1.2557820664216872 | validation: 1.7617033875820198]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2129185913652203		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 1.2129185913652203 | validation: 0.8531984551615662]
	TIME [epoch: 25 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8273154526403479		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.8273154526403479 | validation: 0.913998171158556]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380011430447606		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.7380011430447606 | validation: 1.4097260278628698]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1680058135368478		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.1680058135368478 | validation: 2.3669030246963563]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4832502551403055		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 1.4832502551403055 | validation: 0.8571836716494343]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8184054048634988		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.8184054048634988 | validation: 1.0931025865966666]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8988799563987316		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.8988799563987316 | validation: 1.4991312794026879]
	TIME [epoch: 25 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0781357211804892		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.0781357211804892 | validation: 1.306255320387336]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9793744702598735		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.9793744702598735 | validation: 1.0281782789033664]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7697545334646021		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.7697545334646021 | validation: 1.026786194099745]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8468201436117776		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.8468201436117776 | validation: 1.2935346456460295]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0487097112618227		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 1.0487097112618227 | validation: 1.3882227811256065]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0262073311776287		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 1.0262073311776287 | validation: 1.5356453325871382]
	TIME [epoch: 25 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9484442257029224		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.9484442257029224 | validation: 1.0379009281413953]
	TIME [epoch: 25 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716325018176976		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.716325018176976 | validation: 0.9973470919470845]
	TIME [epoch: 25 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8404852609407225		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.8404852609407225 | validation: 1.2031905797368883]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0221641743649208		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 1.0221641743649208 | validation: 1.4466210565973112]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9124361367443938		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.9124361367443938 | validation: 0.9448161569518726]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8120206569373117		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.8120206569373117 | validation: 0.8221639887267159]
	TIME [epoch: 25 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8851875428474634		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.8851875428474634 | validation: 0.9772121834234611]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7442809085682089		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.7442809085682089 | validation: 1.0833190297574833]
	TIME [epoch: 25 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7653774951469062		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.7653774951469062 | validation: 1.087241726052852]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7513423825684975		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.7513423825684975 | validation: 0.8880895247158614]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693301162020988		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.7693301162020988 | validation: 1.1364774040816277]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7194102584157006		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7194102584157006 | validation: 0.7781334362457514]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_661.pth
	Model improved!!!
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6400937756273387		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.6400937756273387 | validation: 1.0123196052246184]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4387002387159031		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 1.4387002387159031 | validation: 1.782209666907902]
	TIME [epoch: 25 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003421595415362		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.003421595415362 | validation: 0.8724926839877923]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7137413995815267		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.7137413995815267 | validation: 0.8713141715679489]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708801876683189		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.7708801876683189 | validation: 0.873781959947856]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7008795774339427		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.7008795774339427 | validation: 0.8106314695627941]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616123414527133		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.6616123414527133 | validation: 0.7773798645694258]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_668.pth
	Model improved!!!
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6665781238982587		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.6665781238982587 | validation: 0.8418789381669137]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6823458153805713		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.6823458153805713 | validation: 0.8224116805459306]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8191002966370412		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.8191002966370412 | validation: 0.7728888354086848]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_671.pth
	Model improved!!!
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6779404681061045		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6779404681061045 | validation: 0.9249672485956403]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6872110767626046		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.6872110767626046 | validation: 0.7371280812783775]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163763534826213		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.7163763534826213 | validation: 0.8236493727361832]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662010172920628		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.662010172920628 | validation: 0.8026655076820487]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653508951113015		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.653508951113015 | validation: 0.9388371348016059]
	TIME [epoch: 25 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8314668829702571		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.8314668829702571 | validation: 0.8165104671238063]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990935435057903		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6990935435057903 | validation: 0.9532392566502033]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7974111544358164		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.7974111544358164 | validation: 0.8328714132883854]
	TIME [epoch: 25 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801448791367386		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6801448791367386 | validation: 0.8781202758382952]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789312714958058		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.6789312714958058 | validation: 0.7995979026431388]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799392854798282		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.6799392854798282 | validation: 0.782994376775345]
	TIME [epoch: 25 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504639819685984		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.6504639819685984 | validation: 0.7315738709750701]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7703408184772104		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.7703408184772104 | validation: 1.1845271984590353]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7175520502390568		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.7175520502390568 | validation: 0.9494200899771823]
	TIME [epoch: 25 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116892796233177		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.7116892796233177 | validation: 0.8379657001922906]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777888391501317		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.777888391501317 | validation: 0.757576022747945]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143905383769622		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.7143905383769622 | validation: 0.753467353703346]
	TIME [epoch: 25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7789549015740777		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.7789549015740777 | validation: 0.7763803441798635]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6510041776650809		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.6510041776650809 | validation: 0.9690279751218591]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8715097980000794		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.8715097980000794 | validation: 1.3714609366406092]
	TIME [epoch: 25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9035079107472521		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.9035079107472521 | validation: 0.841701654640413]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057588436634353		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.7057588436634353 | validation: 0.7635524331690212]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692032199253803		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6692032199253803 | validation: 0.7697923699068746]
	TIME [epoch: 25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6071014575890068		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6071014575890068 | validation: 0.892801670901491]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6578587922844115		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.6578587922844115 | validation: 0.8205243299061706]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624476648624041		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.624476648624041 | validation: 0.8209364978358137]
	TIME [epoch: 25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669869754612808		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.6669869754612808 | validation: 0.9732361265863869]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8236772474451611		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.8236772474451611 | validation: 0.9596555658770859]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842235802358311		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.6842235802358311 | validation: 0.9242839489298519]
	TIME [epoch: 25 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761226501388403		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.6761226501388403 | validation: 0.9436725265558402]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850417611414255		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6850417611414255 | validation: 0.8757581006400982]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6721675942754666		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.6721675942754666 | validation: 0.8920013211693827]
	TIME [epoch: 25 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7932484916904023		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7932484916904023 | validation: 1.1602399001204249]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7682107248222654		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.7682107248222654 | validation: 0.8028724272400851]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467227659789098		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.6467227659789098 | validation: 0.7713530564037884]
	TIME [epoch: 25 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458705226007735		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.6458705226007735 | validation: 1.0333973972312447]
	TIME [epoch: 24.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70552030799647		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.70552030799647 | validation: 0.8114381436728707]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536353512896041		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.6536353512896041 | validation: 0.7201559753451697]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860309611639037		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.6860309611639037 | validation: 0.9057105114398688]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485233627320443		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.7485233627320443 | validation: 1.0152434039584817]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7235458440860819		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.7235458440860819 | validation: 1.1227683406097848]
	TIME [epoch: 25 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7913859151178392		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.7913859151178392 | validation: 1.0177932695188097]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8747226348172825		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.8747226348172825 | validation: 1.290489068975314]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9575081912099159		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.9575081912099159 | validation: 0.7930514892833576]
	TIME [epoch: 25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481149863418268		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.7481149863418268 | validation: 0.8538257130627658]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7439591810325127		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.7439591810325127 | validation: 1.2307307418015085]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9348887126664679		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.9348887126664679 | validation: 1.0340627046578064]
	TIME [epoch: 25 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9229430312038102		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.9229430312038102 | validation: 1.1779004706325453]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821460390087422		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.821460390087422 | validation: 0.8069597879902313]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.675783113776757		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.675783113776757 | validation: 0.8131682288495858]
	TIME [epoch: 25 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217505750118161		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.6217505750118161 | validation: 0.9387917251264262]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6885823957073414		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.6885823957073414 | validation: 0.973348614000721]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044850182277201		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.7044850182277201 | validation: 0.8792706117173255]
	TIME [epoch: 25 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834068849284423		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6834068849284423 | validation: 0.8011894517656277]
	TIME [epoch: 24.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.635819794188569		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.635819794188569 | validation: 0.762959920754257]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6626908390466076		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.6626908390466076 | validation: 0.795413855003298]
	TIME [epoch: 25 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131021464493776		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.7131021464493776 | validation: 1.1189685188331435]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.765219039001001		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.765219039001001 | validation: 0.9535137163960167]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6871843436425263		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.6871843436425263 | validation: 0.9682326877922444]
	TIME [epoch: 25 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7762925914588695		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.7762925914588695 | validation: 1.078032660135227]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6981705994574009		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.6981705994574009 | validation: 1.0647698851123923]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8423029387607273		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.8423029387607273 | validation: 1.078552186816166]
	TIME [epoch: 25 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696973684317938		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.6696973684317938 | validation: 1.0115182779115819]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6439655425658931		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.6439655425658931 | validation: 0.9870838037779394]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7552467839318091		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.7552467839318091 | validation: 0.8747629417880475]
	TIME [epoch: 25 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6596807632714528		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.6596807632714528 | validation: 1.0284517187246305]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757992661042076		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.6757992661042076 | validation: 1.0113699692603357]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799371484114821		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.6799371484114821 | validation: 1.0579466089834626]
	TIME [epoch: 25 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7516670957773399		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.7516670957773399 | validation: 0.9144325297483369]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585816167832429		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.6585816167832429 | validation: 0.7643692696022428]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536630347872787		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.6536630347872787 | validation: 0.9426256056463114]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6550432707436048		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.6550432707436048 | validation: 0.8858566097151421]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545965022472354		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.8545965022472354 | validation: 1.2380858986715981]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.751808755572151		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.751808755572151 | validation: 0.9171790276572273]
	TIME [epoch: 25 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.616501360433981		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.616501360433981 | validation: 1.022936262971265]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2698333261676913		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 1.2698333261676913 | validation: 1.315974189947048]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644390314467845		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.7644390314467845 | validation: 0.7247853242760418]
	TIME [epoch: 25 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593510022844994		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.6593510022844994 | validation: 0.828901597234231]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650272951547576		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.6650272951547576 | validation: 0.6796202061847781]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076988658984921		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.6076988658984921 | validation: 1.1186151546333825]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7848157084263516		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.7848157084263516 | validation: 0.8173552391005455]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011625622201814		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.7011625622201814 | validation: 0.683667091059726]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544127881544686		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6544127881544686 | validation: 0.8273857208038766]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834980285386569		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.6834980285386569 | validation: 0.7670447354233523]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6408767348764028		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.6408767348764028 | validation: 0.749802483509642]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127349176105941		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6127349176105941 | validation: 0.7668391881609603]
	TIME [epoch: 25 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472811348634789		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.6472811348634789 | validation: 0.899683745958348]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6781124852272892		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.6781124852272892 | validation: 0.7916007579409404]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974618908854337		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5974618908854337 | validation: 0.7245277031204007]
	TIME [epoch: 25 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5717880951172526		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5717880951172526 | validation: 0.8010778334651854]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061614017212253		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.6061614017212253 | validation: 0.7249037806151956]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958974223342222		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.5958974223342222 | validation: 0.7749254019089807]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5725571819961405		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5725571819961405 | validation: 0.740844226195078]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730295044639899		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5730295044639899 | validation: 0.6963532046749044]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5911492145226738		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5911492145226738 | validation: 0.8009137906057248]
	TIME [epoch: 25 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608910063974938		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.6608910063974938 | validation: 0.8148530718659154]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876879250495468		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5876879250495468 | validation: 0.8339388910536792]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123445669204023		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.6123445669204023 | validation: 0.8996140634867104]
	TIME [epoch: 25 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409732739322271		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.6409732739322271 | validation: 0.9092317340494546]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543197047286283		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.6543197047286283 | validation: 0.9199985137339861]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925139498519468		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.5925139498519468 | validation: 0.9267470889671862]
	TIME [epoch: 25 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085835030527091		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.6085835030527091 | validation: 1.0902293061006656]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6744405579906027		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.6744405579906027 | validation: 1.0225955023729028]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7717399042699559		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.7717399042699559 | validation: 1.0209792875415635]
	TIME [epoch: 25 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556792968739737		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.6556792968739737 | validation: 1.1140435217820337]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6653385326036777		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.6653385326036777 | validation: 0.9038848187795779]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422911664694769		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.6422911664694769 | validation: 1.2053654054268168]
	TIME [epoch: 25 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8084277370373231		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.8084277370373231 | validation: 1.0875130662439167]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7381463766643345		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.7381463766643345 | validation: 0.9675937209729725]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6140075870524626		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.6140075870524626 | validation: 1.0320595054564483]
	TIME [epoch: 25 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6339683860872053		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.6339683860872053 | validation: 0.9064977663689676]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254169141343466		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.6254169141343466 | validation: 0.9401880929201165]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147938420207901		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.6147938420207901 | validation: 1.0066558731009547]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8492761713987961		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.8492761713987961 | validation: 1.0527550749908305]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712393890734639		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.7712393890734639 | validation: 1.0361924505570927]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0984067633603838		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 1.0984067633603838 | validation: 1.090861981783735]
	TIME [epoch: 25 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0496843837934655		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 1.0496843837934655 | validation: 1.1027657492621283]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7336388387652315		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.7336388387652315 | validation: 0.9705167757958804]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6751960497516928		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.6751960497516928 | validation: 1.0087659750102387]
	TIME [epoch: 25 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344219189642942		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.6344219189642942 | validation: 0.8779514125281818]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206795521228		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.6206795521228 | validation: 0.9771870342797976]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6331419125138266		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.6331419125138266 | validation: 0.8524046335099741]
	TIME [epoch: 25 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579091624075915		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.6579091624075915 | validation: 0.8594779708836419]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946210647990215		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.5946210647990215 | validation: 0.9029939590711143]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201566186644019		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.6201566186644019 | validation: 0.9562991277476596]
	TIME [epoch: 25 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.683505928030629		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.683505928030629 | validation: 1.1301564943701599]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694999854676179		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.6694999854676179 | validation: 0.930590189825675]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697078238532872		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.697078238532872 | validation: 0.8727202505720982]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7053975850294949		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.7053975850294949 | validation: 1.0334331339926859]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708140722559084		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.6708140722559084 | validation: 0.907388352699293]
	TIME [epoch: 24.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635133835838207		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.7635133835838207 | validation: 0.857618815604668]
	TIME [epoch: 25 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7083794082612572		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.7083794082612572 | validation: 0.8263935262815519]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033829129079761		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.6033829129079761 | validation: 0.7594318434192744]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6006821348852998		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.6006821348852998 | validation: 0.8556423791111807]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939206240598925		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.6939206240598925 | validation: 0.9636800237340718]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7401145952557544		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.7401145952557544 | validation: 0.9653758244476423]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5811398687622029		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.5811398687622029 | validation: 0.8710855340958835]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962550318472647		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5962550318472647 | validation: 0.8340484239123825]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096330403217234		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.6096330403217234 | validation: 1.2172354668224465]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732363961488634		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.8732363961488634 | validation: 1.0570519579172477]
	TIME [epoch: 25 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6349003193986048		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6349003193986048 | validation: 0.9405005854844823]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808915054767886		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.8808915054767886 | validation: 0.9460959265006935]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6416930214011666		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.6416930214011666 | validation: 0.7617243135812934]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5982697040461981		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5982697040461981 | validation: 0.8269504510349946]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6666638960671343		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.6666638960671343 | validation: 0.9040448861007346]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5992475874692962		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5992475874692962 | validation: 0.8046056718889198]
	TIME [epoch: 25 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594647081381922		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.6594647081381922 | validation: 0.880154600506587]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480262353174535		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.6480262353174535 | validation: 0.8153440596512881]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041256214634484		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.6041256214634484 | validation: 0.8459037776721943]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5864034335251818		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5864034335251818 | validation: 0.8161560920026939]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7559118451525504		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.7559118451525504 | validation: 0.7485225440862122]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6564483312123465		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.6564483312123465 | validation: 0.7515139851730834]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6529128081888702		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.6529128081888702 | validation: 0.7770345909145714]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610483200921208		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.610483200921208 | validation: 0.8223337629010418]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5824770208255362		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.5824770208255362 | validation: 0.7649910392752943]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.645559443258211		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.645559443258211 | validation: 0.8380774103938662]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624201458268479		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.624201458268479 | validation: 0.8916960448979863]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020718427925635		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.6020718427925635 | validation: 0.727641055228305]
	TIME [epoch: 25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6060710011634031		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.6060710011634031 | validation: 0.7554375963375628]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942998192571035		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.5942998192571035 | validation: 0.6784831217605446]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678527677141659		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.5678527677141659 | validation: 0.7738855854959786]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6240579783818728		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.6240579783818728 | validation: 0.8643270874953396]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865660372548236		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.6865660372548236 | validation: 0.7718340011095002]
	TIME [epoch: 25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458381734818255		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.6458381734818255 | validation: 0.8529887312918083]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.599349407986306		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.599349407986306 | validation: 0.7340679606767541]
	TIME [epoch: 25 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649915086717305		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.5649915086717305 | validation: 0.8138872194399679]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986735504477027		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5986735504477027 | validation: 0.735377311685676]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5805648763877368		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.5805648763877368 | validation: 0.8358464889266464]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6078058233865188		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.6078058233865188 | validation: 0.8410342212960142]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5986178496697091		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.5986178496697091 | validation: 0.8266501478189352]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6557614494738654		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.6557614494738654 | validation: 0.7761514771140519]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451311347091551		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.6451311347091551 | validation: 0.939138070615365]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585028070998871		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.6585028070998871 | validation: 0.7801430721739047]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7396054044856245		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.7396054044856245 | validation: 0.7352914614802722]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5719633784812717		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.5719633784812717 | validation: 0.8016541781560125]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733202870007037		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.733202870007037 | validation: 0.9496088312817175]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589530983917304		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.6589530983917304 | validation: 0.8015644128438847]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6501044991757243		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.6501044991757243 | validation: 0.7685740716424222]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5849150453707479		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.5849150453707479 | validation: 0.7632608380403016]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139387524099109		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.6139387524099109 | validation: 0.7587986416233193]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6103077027747611		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.6103077027747611 | validation: 0.7332192020367484]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5972435173652534		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.5972435173652534 | validation: 0.9531272166093604]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304863905631853		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.7304863905631853 | validation: 0.7203572618934841]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6363798102061986		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.6363798102061986 | validation: 0.8481810216571145]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074371881348456		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.6074371881348456 | validation: 1.0351757432891404]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874093724592467		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.6874093724592467 | validation: 0.8517866974310185]
	TIME [epoch: 25 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6632186235900854		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.6632186235900854 | validation: 0.7479069266115548]
	TIME [epoch: 25 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696121772321587		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5696121772321587 | validation: 0.7466832809544331]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5727962330797643		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.5727962330797643 | validation: 0.7215468843952921]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5729636887032107		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.5729636887032107 | validation: 0.8356981285971944]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335577132516065		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.6335577132516065 | validation: 0.852942300339665]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6002278619288234		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.6002278619288234 | validation: 0.8705968917939977]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806621679346711		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.5806621679346711 | validation: 0.8232298257813281]
	TIME [epoch: 25 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5558406056067896		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.5558406056067896 | validation: 0.8520166678917184]
	TIME [epoch: 25 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517009451991939		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.5517009451991939 | validation: 0.9021087475472459]
	TIME [epoch: 25 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955751162580172		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.5955751162580172 | validation: 0.7407781701609997]
	TIME [epoch: 25 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023281320545314		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.6023281320545314 | validation: 1.0852206636542354]
	TIME [epoch: 25 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744765226692723		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.744765226692723 | validation: 1.0339333966706599]
	TIME [epoch: 25 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8232771562441161		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.8232771562441161 | validation: 0.9651458586370762]
	TIME [epoch: 25 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282254466306965		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.6282254466306965 | validation: 1.00965416853194]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598025768664095		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.6598025768664095 | validation: 0.8465034110036931]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840159690106322		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.5840159690106322 | validation: 0.8034170482797073]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122005445888624		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.6122005445888624 | validation: 1.1511570149879802]
	TIME [epoch: 24.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0852740989132106		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 1.0852740989132106 | validation: 1.0012289685982274]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6450956816177962		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.6450956816177962 | validation: 0.8414689102333535]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5751413444169985		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.5751413444169985 | validation: 0.9225810206197107]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842181154895347		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.5842181154895347 | validation: 0.8602887053563987]
	TIME [epoch: 25 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600602788921478		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.5600602788921478 | validation: 0.8305797563567255]
	TIME [epoch: 25 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733202731236958		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.5733202731236958 | validation: 0.858510090884692]
	TIME [epoch: 25 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6087521836064009		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.6087521836064009 | validation: 0.9014592700555611]
	TIME [epoch: 25 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685273932643516		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.5685273932643516 | validation: 0.9192665729250863]
	TIME [epoch: 25 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6990962290752725		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.6990962290752725 | validation: 1.115341001047979]
	TIME [epoch: 25 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8222308995302017		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.8222308995302017 | validation: 1.2996111900943736]
	TIME [epoch: 25 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760647700076598		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.8760647700076598 | validation: 0.9660872498541128]
	TIME [epoch: 25 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6035932127403318		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.6035932127403318 | validation: 0.8947154471899412]
	TIME [epoch: 25 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490328755164012		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.5490328755164012 | validation: 0.8966753858864269]
	TIME [epoch: 25 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631096979460666		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.5631096979460666 | validation: 0.954229645342947]
	TIME [epoch: 25 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6015850234042339		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.6015850234042339 | validation: 0.8889802324246918]
	TIME [epoch: 25 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5869332999300132		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.5869332999300132 | validation: 0.9913301787889066]
	TIME [epoch: 25 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730547016726247		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.6730547016726247 | validation: 0.9484542556979786]
	TIME [epoch: 25 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5787077206842487		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.5787077206842487 | validation: 0.8578726834051494]
	TIME [epoch: 25 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819743830631063		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.5819743830631063 | validation: 0.906852897029125]
	TIME [epoch: 25 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139295703415064		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.6139295703415064 | validation: 0.8556911626707183]
	TIME [epoch: 25 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757849051369451		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.5757849051369451 | validation: 0.839805107246657]
	TIME [epoch: 25 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605191521425517		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.5605191521425517 | validation: 0.8245517161310849]
	TIME [epoch: 25 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5623959979648375		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.5623959979648375 | validation: 0.8744813707414864]
	TIME [epoch: 25 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5640931556438842		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.5640931556438842 | validation: 0.8395906595452965]
	TIME [epoch: 25 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5882995557250843		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.5882995557250843 | validation: 0.945985066606405]
	TIME [epoch: 25 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809495939749514		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.5809495939749514 | validation: 0.8741641231387525]
	TIME [epoch: 25 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8813887952701862		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.8813887952701862 | validation: 1.2254069823206848]
	TIME [epoch: 25 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0408423888353062		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 1.0408423888353062 | validation: 1.110373312523694]
	TIME [epoch: 25 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.730817932981934		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.730817932981934 | validation: 0.8405661467578293]
	TIME [epoch: 25 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5681307749159716		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.5681307749159716 | validation: 0.8206108726840141]
	TIME [epoch: 25 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5679732372611781		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.5679732372611781 | validation: 0.8378186381135592]
	TIME [epoch: 25 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023622230313523		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.6023622230313523 | validation: 1.0345146752282863]
	TIME [epoch: 25 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7183737824959964		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.7183737824959964 | validation: 0.8383172935395566]
	TIME [epoch: 25 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958128046419898		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.5958128046419898 | validation: 0.8160744544801526]
	TIME [epoch: 25 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5375258027833608		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.5375258027833608 | validation: 0.807380438199041]
	TIME [epoch: 25 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461235040960933		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.5461235040960933 | validation: 0.8137991562395778]
	TIME [epoch: 25 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806744368730763		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.5806744368730763 | validation: 1.0389865319861908]
	TIME [epoch: 25 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7131319488600021		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.7131319488600021 | validation: 0.7778110868117243]
	TIME [epoch: 25 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789118021455121		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.5789118021455121 | validation: 0.8290459500255656]
	TIME [epoch: 25 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507526823935901		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.5507526823935901 | validation: 0.7971718225772096]
	TIME [epoch: 25 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364671241336136		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.5364671241336136 | validation: 0.8069783664207401]
	TIME [epoch: 25 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5379092961336227		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.5379092961336227 | validation: 0.8459246845905708]
	TIME [epoch: 25 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5459923142109926		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.5459923142109926 | validation: 0.8281548498764982]
	TIME [epoch: 25 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560972765200372		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.560972765200372 | validation: 0.7490136110473526]
	TIME [epoch: 25 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354009518821679		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.5354009518821679 | validation: 0.7054700002393116]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929194822719269		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.5929194822719269 | validation: 0.9434719927723557]
	TIME [epoch: 25 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7287884832257079		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.7287884832257079 | validation: 0.7840493794470951]
	TIME [epoch: 25 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939198624843738		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.5939198624843738 | validation: 0.6639105018551459]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5292765264869226		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.5292765264869226 | validation: 0.7177236855713427]
	TIME [epoch: 25 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.605526904436325		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.605526904436325 | validation: 0.9130257975757559]
	TIME [epoch: 25 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6029034567936506		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.6029034567936506 | validation: 0.749839306501228]
	TIME [epoch: 25 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7005829749095682		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.7005829749095682 | validation: 1.0144678494931934]
	TIME [epoch: 25 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282720349265333		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.7282720349265333 | validation: 0.897622494877662]
	TIME [epoch: 25 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7341310969082782		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.7341310969082782 | validation: 0.8968789657900789]
	TIME [epoch: 25 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6341458726403106		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.6341458726403106 | validation: 0.7208025852791099]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467077041401356		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.5467077041401356 | validation: 0.731456145485624]
	TIME [epoch: 25 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361943059885755		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.5361943059885755 | validation: 0.7060664261825353]
	TIME [epoch: 24.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355977361313459		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.5355977361313459 | validation: 0.7074275875492134]
	TIME [epoch: 25 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550795457225852		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.550795457225852 | validation: 0.8608310668361339]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5810698033525316		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.5810698033525316 | validation: 0.7049247276845683]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179024121617061		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.5179024121617061 | validation: 0.7413469403281668]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5815959720174247		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.5815959720174247 | validation: 0.8243692530379205]
	TIME [epoch: 25 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5702055283198427		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.5702055283198427 | validation: 0.7775127813690672]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5502486334023092		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.5502486334023092 | validation: 0.8338588166399847]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396618200850407		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.5396618200850407 | validation: 0.893576033111901]
	TIME [epoch: 25 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141245560054314		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.6141245560054314 | validation: 0.9196028622355479]
	TIME [epoch: 25 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6038317470830259		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.6038317470830259 | validation: 0.8761280352814065]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575388898884432		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.575388898884432 | validation: 0.8966238413115681]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606731510018759		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.5606731510018759 | validation: 0.8741143693163165]
	TIME [epoch: 25 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749146733418904		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.5749146733418904 | validation: 0.8556462008059984]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438507423682962		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.5438507423682962 | validation: 0.8177008093664111]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544335741472768		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.5544335741472768 | validation: 0.8990667072688926]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5887916629344471		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.5887916629344471 | validation: 0.879262844800064]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565242398001274		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.5565242398001274 | validation: 0.8674320690536911]
	TIME [epoch: 25 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819870464122108		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.5819870464122108 | validation: 0.841393551259186]
	TIME [epoch: 25 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473558598625596		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.5473558598625596 | validation: 0.8360294649689665]
	TIME [epoch: 25 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6318601829579148		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.6318601829579148 | validation: 0.9428101735741834]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254381897893324		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.6254381897893324 | validation: 0.8129618873215406]
	TIME [epoch: 25 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5583126816018583		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.5583126816018583 | validation: 0.8081300632846674]
	TIME [epoch: 24.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5776222783559288		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.5776222783559288 | validation: 0.7499681927091075]
	TIME [epoch: 25 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507720038573114		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.5507720038573114 | validation: 0.8270429318038182]
	TIME [epoch: 25 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5832699904546811		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.5832699904546811 | validation: 0.7880949307736687]
	TIME [epoch: 24.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355471541837182		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.5355471541837182 | validation: 0.8653666318761105]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657141571303256		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.5657141571303256 | validation: 0.8469720140432787]
	TIME [epoch: 25 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5391631089227225		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.5391631089227225 | validation: 0.8276615738371282]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.553953577583486		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.553953577583486 | validation: 0.8069449828668398]
	TIME [epoch: 25 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293007792343724		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.5293007792343724 | validation: 0.8103100168965003]
	TIME [epoch: 24.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082865431884854		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.6082865431884854 | validation: 1.0457637841583718]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526963403807452		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.6526963403807452 | validation: 0.8852375175720557]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534344304368402		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.5534344304368402 | validation: 0.8320383236547233]
	TIME [epoch: 25 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403422626773401		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.5403422626773401 | validation: 0.8386645766694034]
	TIME [epoch: 24.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930391569599748		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.6930391569599748 | validation: 0.8902984005416937]
	TIME [epoch: 24.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301093535560796		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.6301093535560796 | validation: 0.9210860930922792]
	TIME [epoch: 24.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5663973169515447		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.5663973169515447 | validation: 0.6883513862730921]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52797047591702		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.52797047591702 | validation: 0.73789908216448]
	TIME [epoch: 25 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293214132607418		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.5293214132607418 | validation: 0.7877764349061559]
	TIME [epoch: 24.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096780966323074		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.6096780966323074 | validation: 0.9232032559149292]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5902985397921241		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.5902985397921241 | validation: 0.7939636895314678]
	TIME [epoch: 25 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5646808230425373		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.5646808230425373 | validation: 0.8746558382851172]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6658478982226275		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.6658478982226275 | validation: 0.8611309923670467]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556759788340342		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.556759788340342 | validation: 0.8718111760755932]
	TIME [epoch: 25 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6210991694610557		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.6210991694610557 | validation: 0.8316222722700342]
	TIME [epoch: 24.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454452390578399		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.5454452390578399 | validation: 0.8600387700996379]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5498559414711413		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.5498559414711413 | validation: 0.8226920909210428]
	TIME [epoch: 25 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527796606944261		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.527796606944261 | validation: 0.841258157991835]
	TIME [epoch: 24.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290891009100983		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.5290891009100983 | validation: 0.79479115375391]
	TIME [epoch: 25 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551564720734605		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.551564720734605 | validation: 0.8889096336398495]
	TIME [epoch: 25 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842437915445899		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.5842437915445899 | validation: 0.7931157774059762]
	TIME [epoch: 24.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567943975202877		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.567943975202877 | validation: 0.7840168132329205]
	TIME [epoch: 24.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484296767737546		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.5484296767737546 | validation: 0.8255053751852597]
	TIME [epoch: 24.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387421721661569		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.5387421721661569 | validation: 0.8547063034830181]
	TIME [epoch: 25 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593199780453383		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.5593199780453383 | validation: 0.8437349476908976]
	TIME [epoch: 25 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5308699711495402		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.5308699711495402 | validation: 0.8526322226709615]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5737052558212267		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.5737052558212267 | validation: 0.8343701991715976]
	TIME [epoch: 24.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5331373385066415		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.5331373385066415 | validation: 0.814394816999081]
	TIME [epoch: 24.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376219452526648		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.5376219452526648 | validation: 0.8569588232341887]
	TIME [epoch: 25 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664898733246221		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.5664898733246221 | validation: 0.8419920759092401]
	TIME [epoch: 25 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539810045468748		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.539810045468748 | validation: 0.8406383135005896]
	TIME [epoch: 25 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.551742922141403		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.551742922141403 | validation: 0.813317334072405]
	TIME [epoch: 25 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451677668154143		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.5451677668154143 | validation: 0.8581579900172134]
	TIME [epoch: 25 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5956111566358706		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.5956111566358706 | validation: 0.8085192549512553]
	TIME [epoch: 24.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5570316553015208		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.5570316553015208 | validation: 0.8372461730731894]
	TIME [epoch: 25 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183425145657596		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.6183425145657596 | validation: 0.8263820242129282]
	TIME [epoch: 25 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156325628605507		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.6156325628605507 | validation: 0.7927800607171482]
	TIME [epoch: 25 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384144866751724		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.5384144866751724 | validation: 0.7665298407427426]
	TIME [epoch: 25 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515678697494613		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.5515678697494613 | validation: 0.8900037471440486]
	TIME [epoch: 25 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109707191568262		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.6109707191568262 | validation: 0.8361091893886408]
	TIME [epoch: 25 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761800192401824		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.5761800192401824 | validation: 0.7803689979453263]
	TIME [epoch: 25 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077275454486412		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.5077275454486412 | validation: 0.7429176634343042]
	TIME [epoch: 25.1 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346096822986395		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.5346096822986395 | validation: 0.9093188477980292]
	TIME [epoch: 24.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7004337740355466		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.7004337740355466 | validation: 0.9294144750927407]
	TIME [epoch: 24.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6057723833222657		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.6057723833222657 | validation: 0.7891017249436356]
	TIME [epoch: 24.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5745300217528738		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.5745300217528738 | validation: 0.8721894640403542]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663404417248316		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.663404417248316 | validation: 0.9734740197558276]
	TIME [epoch: 24.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635030043751504		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.6635030043751504 | validation: 0.8316426626127731]
	TIME [epoch: 24.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621442719676095		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.621442719676095 | validation: 0.9001624097842071]
	TIME [epoch: 25 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7560429882652128		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.7560429882652128 | validation: 0.8981359312646008]
	TIME [epoch: 25 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156133122627341		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.6156133122627341 | validation: 0.7806291435982954]
	TIME [epoch: 25.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5621932048299498		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.5621932048299498 | validation: 0.7959963837861783]
	TIME [epoch: 25 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.596165739270532		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.596165739270532 | validation: 0.6911793897163208]
	TIME [epoch: 25 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5327611582859084		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.5327611582859084 | validation: 0.6720415933080307]
	TIME [epoch: 25.1 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231767791188099		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.5231767791188099 | validation: 0.7631777906684281]
	TIME [epoch: 25.1 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5444102310838265		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.5444102310838265 | validation: 0.7434520898103767]
	TIME [epoch: 25 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5279114073873273		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.5279114073873273 | validation: 0.73292524207682]
	TIME [epoch: 25.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5256800718760346		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.5256800718760346 | validation: 0.7101195552924044]
	TIME [epoch: 25 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915943596779412		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.5915943596779412 | validation: 0.8657132328522675]
	TIME [epoch: 25 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975218712147824		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.5975218712147824 | validation: 0.7576817069051589]
	TIME [epoch: 25 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5829120584683025		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.5829120584683025 | validation: 0.8261089134498595]
	TIME [epoch: 25 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470050577400669		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.6470050577400669 | validation: 0.6746184118136855]
	TIME [epoch: 25 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293658611680768		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.5293658611680768 | validation: 0.6554101978034567]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_1024.pth
	Model improved!!!
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.555866867661873		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.555866867661873 | validation: 0.6765341302835128]
	TIME [epoch: 25 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5915930032591832		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.5915930032591832 | validation: 0.6559168976976705]
	TIME [epoch: 25 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384827376087188		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.5384827376087188 | validation: 0.6731813376947006]
	TIME [epoch: 25 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359900305299906		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.5359900305299906 | validation: 0.6860868841821959]
	TIME [epoch: 25 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5372554339091962		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.5372554339091962 | validation: 0.7330767935439144]
	TIME [epoch: 25 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55500646039554		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.55500646039554 | validation: 0.6820093794436649]
	TIME [epoch: 25.1 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364860886531833		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.5364860886531833 | validation: 0.8813536416448676]
	TIME [epoch: 25 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313240293809887		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.6313240293809887 | validation: 0.7794542837987691]
	TIME [epoch: 25 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5789248649974416		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.5789248649974416 | validation: 0.6806496889328775]
	TIME [epoch: 25.1 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442392405634376		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.5442392405634376 | validation: 0.7519528609970046]
	TIME [epoch: 25 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364477715621517		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.5364477715621517 | validation: 0.6787572834290455]
	TIME [epoch: 24.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143590285544845		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.5143590285544845 | validation: 0.6370910747449451]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_1036.pth
	Model improved!!!
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5267876223588696		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.5267876223588696 | validation: 0.626428915976969]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r4_20240424_132604/states/model_tr_study5_1037.pth
	Model improved!!!
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5126232133857247		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.5126232133857247 | validation: 0.7314470657054369]
	TIME [epoch: 25.1 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529780291682864		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.529780291682864 | validation: 0.7313546877117588]
	TIME [epoch: 25 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5706122377584664		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.5706122377584664 | validation: 0.6803679504355217]
	TIME [epoch: 24.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261687024601952		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.5261687024601952 | validation: 0.6644357302811283]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196116181771249		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.5196116181771249 | validation: 0.6703344379760301]
	TIME [epoch: 25.1 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5571228146504429		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.5571228146504429 | validation: 0.7471517849076801]
	TIME [epoch: 25 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747830212223664		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.5747830212223664 | validation: 0.7142771065088367]
	TIME [epoch: 25 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604396142713952		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.604396142713952 | validation: 0.6587432984438316]
	TIME [epoch: 25.1 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458981071777834		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.5458981071777834 | validation: 0.6373800552792024]
	TIME [epoch: 25 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199064648035128		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.5199064648035128 | validation: 0.6467257141190598]
	TIME [epoch: 25 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5998364659387583		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.5998364659387583 | validation: 0.6811900248744626]
	TIME [epoch: 25 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942832062524557		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.5942832062524557 | validation: 0.8218612814157052]
	TIME [epoch: 25 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328780906121929		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.6328780906121929 | validation: 0.690553193003417]
	TIME [epoch: 24.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5744956269400006		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.5744956269400006 | validation: 0.6868667974071551]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794576070132234		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.5794576070132234 | validation: 0.6481569962579306]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554282909175124		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.554282909175124 | validation: 0.7018267358073874]
	TIME [epoch: 25 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905347128961614		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.5905347128961614 | validation: 0.6719546005702045]
	TIME [epoch: 25 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5412949246222427		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.5412949246222427 | validation: 0.659749973055448]
	TIME [epoch: 25 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5219573173974004		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.5219573173974004 | validation: 0.6646929796250381]
	TIME [epoch: 25 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5273076937266101		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.5273076937266101 | validation: 0.7256476211521004]
	TIME [epoch: 25 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354682587831749		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.5354682587831749 | validation: 0.694372803723775]
	TIME [epoch: 25 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5752195809088774		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.5752195809088774 | validation: 0.6821958038887115]
	TIME [epoch: 25 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213469005498736		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.5213469005498736 | validation: 0.7007815691319558]
	TIME [epoch: 24.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118796487636177		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.5118796487636177 | validation: 0.723288794553766]
	TIME [epoch: 24.9 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5078672571361139		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.5078672571361139 | validation: 0.7837015975403937]
	TIME [epoch: 24.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387747165883062		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.5387747165883062 | validation: 0.8716414960428597]
	TIME [epoch: 25 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5479496266052379		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.5479496266052379 | validation: 0.7120213804762835]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.524118944673456		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.524118944673456 | validation: 0.6953654471992913]
	TIME [epoch: 25 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49700174539905484		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.49700174539905484 | validation: 0.6755834617857174]
	TIME [epoch: 25 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077699359177279		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.5077699359177279 | validation: 0.7186248260036799]
	TIME [epoch: 25 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526664813789877		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.526664813789877 | validation: 0.7730875630281906]
	TIME [epoch: 24.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6198074297993824		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.6198074297993824 | validation: 0.7890051543972676]
	TIME [epoch: 25 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668214443432863		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.5668214443432863 | validation: 0.7028019822679833]
	TIME [epoch: 24.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199747690774374		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.5199747690774374 | validation: 0.8167307515704773]
	TIME [epoch: 25 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764020749521636		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.5764020749521636 | validation: 0.7872925094692778]
	TIME [epoch: 24.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214786337476406		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.5214786337476406 | validation: 0.7392535944513966]
	TIME [epoch: 25 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213529392922993		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.5213529392922993 | validation: 0.7112105827585434]
	TIME [epoch: 24.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280632147057274		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.5280632147057274 | validation: 0.6933491492756807]
	TIME [epoch: 25 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145353174474275		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.5145353174474275 | validation: 0.6666951368966931]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103484591620202		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.5103484591620202 | validation: 0.6585060245930251]
	TIME [epoch: 24.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087062984926648		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.5087062984926648 | validation: 0.6607618649080708]
	TIME [epoch: 25 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4957339601713874		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.4957339601713874 | validation: 0.6336347226582235]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526579489314855		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.526579489314855 | validation: 0.7866940406693509]
	TIME [epoch: 25 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549878691752533		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.549878691752533 | validation: 0.7087580339438134]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094247682222703		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.5094247682222703 | validation: 0.6835842462953374]
	TIME [epoch: 25 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5212858572369312		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.5212858572369312 | validation: 0.6612967363016486]
	TIME [epoch: 25 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158815871141393		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.5158815871141393 | validation: 0.6978499635200309]
	TIME [epoch: 25 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732264319653136		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.5732264319653136 | validation: 0.8339185867704362]
	TIME [epoch: 25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5807647731368316		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.5807647731368316 | validation: 0.66293474688254]
	TIME [epoch: 25 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127343606486753		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.5127343606486753 | validation: 0.6833271227547587]
	TIME [epoch: 25.1 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5148056059967678		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.5148056059967678 | validation: 0.6950632080612448]
	TIME [epoch: 25 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5124674292493248		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.5124674292493248 | validation: 0.6899646080777774]
	TIME [epoch: 25 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501316547704898		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.5501316547704898 | validation: 0.8070941706899397]
	TIME [epoch: 25 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5979170498063373		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.5979170498063373 | validation: 0.7179741821967308]
	TIME [epoch: 25 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5491570243860048		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.5491570243860048 | validation: 0.7985422625621372]
	TIME [epoch: 25 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527590078616037		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.5527590078616037 | validation: 0.7607477962184548]
	TIME [epoch: 25.1 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522266195845214		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.522266195845214 | validation: 0.7004767058411875]
	TIME [epoch: 25 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149143643683439		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.5149143643683439 | validation: 0.7533066302701207]
	TIME [epoch: 25 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5480678979508413		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.5480678979508413 | validation: 0.8013142983472433]
	TIME [epoch: 25 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528484853048768		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.528484853048768 | validation: 0.7043557734860543]
	TIME [epoch: 25 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.512238957732859		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.512238957732859 | validation: 0.659535954404356]
	TIME [epoch: 25 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49699194779654693		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.49699194779654693 | validation: 0.6560353158406137]
	TIME [epoch: 25 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082240190125726		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.5082240190125726 | validation: 0.7336182463539135]
	TIME [epoch: 25 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138250017018675		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.5138250017018675 | validation: 0.7172171775507269]
	TIME [epoch: 25 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072762024607566		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.5072762024607566 | validation: 0.6652045928310736]
	TIME [epoch: 25.1 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130935714164016		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.5130935714164016 | validation: 0.7796092902094095]
	TIME [epoch: 25 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6263599436873287		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.6263599436873287 | validation: 0.883429667075418]
	TIME [epoch: 25 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607093454598822		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.607093454598822 | validation: 0.6931595304028947]
	TIME [epoch: 25 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317188061710755		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.5317188061710755 | validation: 0.6975182211825814]
	TIME [epoch: 25 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083008271505816		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.5083008271505816 | validation: 0.7013958275567213]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107922909103342		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.5107922909103342 | validation: 0.7786907263854767]
	TIME [epoch: 25.1 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382543366620671		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.5382543366620671 | validation: 0.6965810707492597]
	TIME [epoch: 25 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4969624103476155		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.4969624103476155 | validation: 0.6455442979898388]
	TIME [epoch: 25 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48849528802898623		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.48849528802898623 | validation: 0.6629697863371204]
	TIME [epoch: 25 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5034592624196148		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.5034592624196148 | validation: 0.70646348657331]
	TIME [epoch: 25 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713399887551405		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.5713399887551405 | validation: 0.744082572408664]
	TIME [epoch: 25 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409596470101782		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.5409596470101782 | validation: 0.7068324472210622]
	TIME [epoch: 25 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5661289953408317		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.5661289953408317 | validation: 0.8462340950109791]
	TIME [epoch: 25.1 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046943452787786		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.6046943452787786 | validation: 0.752477353926578]
	TIME [epoch: 25 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049756498609715		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.5049756498609715 | validation: 0.7116195920402976]
	TIME [epoch: 25.1 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49564920927397077		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.49564920927397077 | validation: 0.6989440777530292]
	TIME [epoch: 25 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5545573353303134		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.5545573353303134 | validation: 0.7720776076584707]
	TIME [epoch: 25 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5566225303951416		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.5566225303951416 | validation: 0.7855802761932781]
	TIME [epoch: 25 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49077303310846826		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.49077303310846826 | validation: 0.7613863734599986]
	TIME [epoch: 25 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5388675633616611		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.5388675633616611 | validation: 0.7986559424754794]
	TIME [epoch: 25 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137499200935718		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.5137499200935718 | validation: 0.7243973226265191]
	TIME [epoch: 25.1 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4996338063085638		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.4996338063085638 | validation: 0.7670575627937426]
	TIME [epoch: 25 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068429751905129		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.5068429751905129 | validation: 0.7890288828149032]
	TIME [epoch: 25 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664201607980719		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.5664201607980719 | validation: 0.8062525226361532]
	TIME [epoch: 25 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224138537087079		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.5224138537087079 | validation: 0.7679262081386338]
	TIME [epoch: 25 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.519840389170902		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.519840389170902 | validation: 0.7831678429860607]
	TIME [epoch: 25 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135782832683216		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.5135782832683216 | validation: 0.7426592768821715]
	TIME [epoch: 25 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051910316182037		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.5051910316182037 | validation: 0.7323410252650154]
	TIME [epoch: 25 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013978690852142		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.5013978690852142 | validation: 0.7221986826789075]
	TIME [epoch: 25 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501047890328871		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.501047890328871 | validation: 0.7314818213816981]
	TIME [epoch: 25.1 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5368925482845381		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.5368925482845381 | validation: 0.7347284167258903]
	TIME [epoch: 25 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227541864540793		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.5227541864540793 | validation: 0.7307182049432882]
	TIME [epoch: 25 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564593665415069		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.5564593665415069 | validation: 0.7985256940151294]
	TIME [epoch: 25 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5957331745473015		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.5957331745473015 | validation: 0.8666015033647537]
	TIME [epoch: 25 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926806903989723		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.5926806903989723 | validation: 0.7267292624469969]
	TIME [epoch: 25 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5784271004246092		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.5784271004246092 | validation: 0.7705286551585198]
	TIME [epoch: 25 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639921128689446		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.5639921128689446 | validation: 0.7262299730054323]
	TIME [epoch: 25 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5321646032429057		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.5321646032429057 | validation: 0.7190803256694192]
	TIME [epoch: 25 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5146203871485048		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.5146203871485048 | validation: 0.7473129183493988]
	TIME [epoch: 25 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509865648708516		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.509865648708516 | validation: 0.7659887987441352]
	TIME [epoch: 25 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975599921062863		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.4975599921062863 | validation: 0.7041798785079361]
	TIME [epoch: 25 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49891169518348355		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.49891169518348355 | validation: 0.7520667386230798]
	TIME [epoch: 25 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163831542618025		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.5163831542618025 | validation: 0.7393830439635941]
	TIME [epoch: 25 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176795827295193		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.5176795827295193 | validation: 0.7317125808012984]
	TIME [epoch: 25 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51040855084146		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.51040855084146 | validation: 0.7089178632054633]
	TIME [epoch: 25.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4917003432904976		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.4917003432904976 | validation: 0.6934984916090151]
	TIME [epoch: 25 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49798671037341635		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.49798671037341635 | validation: 0.6635570528037473]
	TIME [epoch: 25 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4991765426027385		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.4991765426027385 | validation: 0.7411421849097752]
	TIME [epoch: 25 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938076738130548		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.4938076738130548 | validation: 0.678045854078473]
	TIME [epoch: 25 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49442196532644184		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.49442196532644184 | validation: 0.6872879430251021]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069935983858158		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.5069935983858158 | validation: 0.6874166841342327]
	TIME [epoch: 25.1 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141212371534457		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.5141212371534457 | validation: 0.6982561570206763]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039601654269348		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.5039601654269348 | validation: 0.7380970798367935]
	TIME [epoch: 25 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069936386523658		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.5069936386523658 | validation: 0.6861314449912266]
	TIME [epoch: 25 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49600406061463453		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.49600406061463453 | validation: 0.7309430286721349]
	TIME [epoch: 25 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243969922656491		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.5243969922656491 | validation: 0.741852154563807]
	TIME [epoch: 25 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508914915554672		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.5508914915554672 | validation: 0.8659675217166367]
	TIME [epoch: 25 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6552376393060264		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.6552376393060264 | validation: 0.9033517224046236]
	TIME [epoch: 25 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955246289818129		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.6955246289818129 | validation: 0.8878326452112154]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948615527699831		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.6948615527699831 | validation: 0.9362764588638686]
	TIME [epoch: 25 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626987786481223		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.626987786481223 | validation: 0.892084599158728]
	TIME [epoch: 24.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048087364827874		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.6048087364827874 | validation: 0.9249891255778667]
	TIME [epoch: 25 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6184582148760044		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.6184582148760044 | validation: 0.9244981671013451]
	TIME [epoch: 25 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540051584844449		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.5540051584844449 | validation: 0.8293550868034248]
	TIME [epoch: 25 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272960295493518		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.5272960295493518 | validation: 0.7349148857930863]
	TIME [epoch: 25 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5327075651898667		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.5327075651898667 | validation: 0.8044614861569835]
	TIME [epoch: 25 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107922353981803		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.5107922353981803 | validation: 0.7463161671840696]
	TIME [epoch: 25 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204936562724979		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.5204936562724979 | validation: 0.7561834526581231]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4948059623754114		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.4948059623754114 | validation: 0.7131025193383382]
	TIME [epoch: 25 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001931594101364		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.5001931594101364 | validation: 0.8504864686381014]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5278839573002984		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.5278839573002984 | validation: 0.8029926893256462]
	TIME [epoch: 25 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324485851371833		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.5324485851371833 | validation: 0.8541224458916545]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5194773012058448		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.5194773012058448 | validation: 0.8224721532516759]
	TIME [epoch: 25 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003010213478147		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.5003010213478147 | validation: 0.8048927421159187]
	TIME [epoch: 25 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.496331346809436		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.496331346809436 | validation: 0.7954051020616268]
	TIME [epoch: 25 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.521686141429621		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.521686141429621 | validation: 0.796393836243099]
	TIME [epoch: 24.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52610506861464		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.52610506861464 | validation: 0.8006167850141512]
	TIME [epoch: 25 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108897102856982		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.5108897102856982 | validation: 0.8178928131838452]
	TIME [epoch: 25 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473008031828295		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.5473008031828295 | validation: 0.8024500494107568]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5439873760261417		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.5439873760261417 | validation: 0.7849019700221095]
	TIME [epoch: 25 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037857131038671		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.5037857131038671 | validation: 0.8133694667404868]
	TIME [epoch: 25 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023912405081661		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.5023912405081661 | validation: 0.8124680320519799]
	TIME [epoch: 25 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050486720643762		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.5050486720643762 | validation: 0.7862630781639464]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4942919360180314		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.4942919360180314 | validation: 0.7877340036662588]
	TIME [epoch: 25.1 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4991870256577615		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.4991870256577615 | validation: 0.7718645497203884]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4994769472786531		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.4994769472786531 | validation: 0.818217380794512]
	TIME [epoch: 25 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016672288033152		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.5016672288033152 | validation: 0.7869969043900088]
	TIME [epoch: 25 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501219639111089		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.501219639111089 | validation: 0.7831392687070118]
	TIME [epoch: 25 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5061188499503195		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.5061188499503195 | validation: 0.7709346162152749]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000731761755914		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.5000731761755914 | validation: 0.7492391581785407]
	TIME [epoch: 25 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026809064975536		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.5026809064975536 | validation: 0.8024354707113281]
	TIME [epoch: 24.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4976562057436858		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.4976562057436858 | validation: 0.7867896234968558]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5062334694239553		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.5062334694239553 | validation: 0.8411823351081604]
	TIME [epoch: 25 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140467349446604		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.5140467349446604 | validation: 0.8137743944978891]
	TIME [epoch: 25 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197539922075859		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.5197539922075859 | validation: 0.8247592334970663]
	TIME [epoch: 25 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411278659749741		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.5411278659749741 | validation: 0.8126970147974446]
	TIME [epoch: 25 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230119564126482		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.5230119564126482 | validation: 0.7930779421041055]
	TIME [epoch: 25 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142545829001814		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.5142545829001814 | validation: 0.7886724699230445]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5031868275431433		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.5031868275431433 | validation: 0.8245281742717429]
	TIME [epoch: 25 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075939948986034		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.5075939948986034 | validation: 0.8159388127722019]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088347455859287		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.5088347455859287 | validation: 0.8055222007568895]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049457925588521		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.5049457925588521 | validation: 0.8078047255948928]
	TIME [epoch: 24.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224340885180504		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.5224340885180504 | validation: 0.8097551121781205]
	TIME [epoch: 25 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5280851569545382		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.5280851569545382 | validation: 0.8008659322605745]
	TIME [epoch: 25 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49827032520597936		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.49827032520597936 | validation: 0.7581731650954467]
	TIME [epoch: 25 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5088546051892477		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.5088546051892477 | validation: 0.7668360173953017]
	TIME [epoch: 24.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4915582767072369		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.4915582767072369 | validation: 0.8027424801769718]
	TIME [epoch: 25 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502538159488631		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.502538159488631 | validation: 0.8004691877249508]
	TIME [epoch: 25 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49711619052590705		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.49711619052590705 | validation: 0.7527396932372533]
	TIME [epoch: 24.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49831754080618135		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.49831754080618135 | validation: 0.7829247761311297]
	TIME [epoch: 24.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4842848405493089		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.4842848405493089 | validation: 0.8011512882430415]
	TIME [epoch: 25 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5324496588514459		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.5324496588514459 | validation: 0.7937943230199966]
	TIME [epoch: 25 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5079698535792956		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.5079698535792956 | validation: 0.8189638242065135]
	TIME [epoch: 24.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5023948986787754		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.5023948986787754 | validation: 0.8086675143258164]
	TIME [epoch: 25 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49115817679250073		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.49115817679250073 | validation: 0.8090910847488948]
	TIME [epoch: 25 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.50139662751006		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.50139662751006 | validation: 0.799434227884946]
	TIME [epoch: 25 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189677940534513		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.5189677940534513 | validation: 0.8279277519879407]
	TIME [epoch: 24.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5703332034894694		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.5703332034894694 | validation: 0.891333179433522]
	TIME [epoch: 25 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337876088717054		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.6337876088717054 | validation: 0.8934958509043925]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598336173641207		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.6598336173641207 | validation: 0.8131496881433763]
	TIME [epoch: 25 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5833261510168269		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.5833261510168269 | validation: 0.7805485091080135]
	TIME [epoch: 24.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113321936361996		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.5113321936361996 | validation: 0.7809004114758052]
	TIME [epoch: 25 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49916492843539595		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.49916492843539595 | validation: 0.7923351160224481]
	TIME [epoch: 25 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49695530428818524		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.49695530428818524 | validation: 0.7907718679110962]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4981129944169084		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.4981129944169084 | validation: 0.7801987763808836]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4816852357641983		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.4816852357641983 | validation: 0.7951351742152001]
	TIME [epoch: 25 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227131698518418		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.5227131698518418 | validation: 0.7900038755840484]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5074017159153726		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.5074017159153726 | validation: 0.7851620120859896]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000163551603753		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.5000163551603753 | validation: 0.7754558712289832]
	TIME [epoch: 25.1 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4942170599833969		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.4942170599833969 | validation: 0.7782153734501038]
	TIME [epoch: 25 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5024440954879335		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.5024440954879335 | validation: 0.775462663699945]
	TIME [epoch: 25 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937213828779665		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.4937213828779665 | validation: 0.7674051361856692]
	TIME [epoch: 25 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4936229816159775		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.4936229816159775 | validation: 0.7627918597841108]
	TIME [epoch: 25 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4974727316200175		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.4974727316200175 | validation: 0.7352792505654528]
	TIME [epoch: 25 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4902542536005676		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.4902542536005676 | validation: 0.7420727616748559]
	TIME [epoch: 25.1 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011440735850063		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.5011440735850063 | validation: 0.7549505326723133]
	TIME [epoch: 24.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48408078429692153		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.48408078429692153 | validation: 0.7712972707335664]
	TIME [epoch: 25 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48298693708535956		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.48298693708535956 | validation: 0.727132959833519]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48482620839795937		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.48482620839795937 | validation: 0.7562366221957538]
	TIME [epoch: 24.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832827737217479		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.4832827737217479 | validation: 0.7674172501136143]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49139894038858184		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.49139894038858184 | validation: 0.7718410282946252]
	TIME [epoch: 25 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484497467984893		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.484497467984893 | validation: 0.7492772064443082]
	TIME [epoch: 25 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49906089053158986		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.49906089053158986 | validation: 0.7725404307031558]
	TIME [epoch: 25 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49339542073018733		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.49339542073018733 | validation: 0.778329347205653]
	TIME [epoch: 25 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4960069210044954		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.4960069210044954 | validation: 0.7549016106656423]
	TIME [epoch: 25 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845830704497547		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.4845830704497547 | validation: 0.7761014560263518]
	TIME [epoch: 25 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47947333079626686		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.47947333079626686 | validation: 0.7478323970778813]
	TIME [epoch: 25 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49328872642861654		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.49328872642861654 | validation: 0.7425251239551426]
	TIME [epoch: 25 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852045103432244		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.4852045103432244 | validation: 0.7147277923474552]
	TIME [epoch: 25 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4804798142743334		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.4804798142743334 | validation: 0.7410803647625868]
	TIME [epoch: 25 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045393663193742		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.5045393663193742 | validation: 0.7932241215059037]
	TIME [epoch: 25 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639932502799556		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.5639932502799556 | validation: 0.788277708402572]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121842004425379		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.5121842004425379 | validation: 0.7302933870350213]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4978482372388928		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.4978482372388928 | validation: 0.7391645470094089]
	TIME [epoch: 25 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4844665075997817		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.4844665075997817 | validation: 0.7439849717481744]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845059466557884		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.4845059466557884 | validation: 0.7470361198116404]
	TIME [epoch: 25 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4817991316781988		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.4817991316781988 | validation: 0.7161268306345656]
	TIME [epoch: 24.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753856906687271		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.4753856906687271 | validation: 0.6880881933283728]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820170618594044		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.4820170618594044 | validation: 0.692463490439938]
	TIME [epoch: 25 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744262780460557		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.4744262780460557 | validation: 0.6737085168865352]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48937824963375687		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.48937824963375687 | validation: 0.6697050132052687]
	TIME [epoch: 25 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762783851921051		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.4762783851921051 | validation: 0.6964337775407864]
	TIME [epoch: 25 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839847249998498		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.4839847249998498 | validation: 0.7397204233807864]
	TIME [epoch: 25 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47682069576068276		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.47682069576068276 | validation: 0.7087350637192503]
	TIME [epoch: 24.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48011862778527614		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.48011862778527614 | validation: 0.7564010090035315]
	TIME [epoch: 25.1 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47942179177555855		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.47942179177555855 | validation: 0.7882656335297739]
	TIME [epoch: 25 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48357609843238325		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.48357609843238325 | validation: 0.6929237246986051]
	TIME [epoch: 25 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46978040673180804		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.46978040673180804 | validation: 0.7484236929475264]
	TIME [epoch: 25 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509383754629061		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.509383754629061 | validation: 0.7570964620081536]
	TIME [epoch: 25 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251965160769846		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.5251965160769846 | validation: 0.7894608174508466]
	TIME [epoch: 25 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5286735212195919		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.5286735212195919 | validation: 0.750646522637312]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182822729286737		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.5182822729286737 | validation: 0.714117595868737]
	TIME [epoch: 25 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5070789955679633		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.5070789955679633 | validation: 0.7799225369737949]
	TIME [epoch: 24.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48469918320832184		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.48469918320832184 | validation: 0.7893898473091564]
	TIME [epoch: 25.1 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4848066411232085		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.4848066411232085 | validation: 0.7592697607206392]
	TIME [epoch: 25 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4829459469054008		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.4829459469054008 | validation: 0.7378641155572803]
	TIME [epoch: 25 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747767944459479		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.4747767944459479 | validation: 0.7457977012689259]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703815162975284		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.4703815162975284 | validation: 0.7626807024405069]
	TIME [epoch: 25 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4941149990660547		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.4941149990660547 | validation: 0.7444702896901493]
	TIME [epoch: 25 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49022642088117396		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.49022642088117396 | validation: 0.6971259072925406]
	TIME [epoch: 25 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833957092913054		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.4833957092913054 | validation: 0.725761459537791]
	TIME [epoch: 25 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47907239682531605		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.47907239682531605 | validation: 0.6967791103425907]
	TIME [epoch: 25 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4862597450666897		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.4862597450666897 | validation: 0.7712092469497793]
	TIME [epoch: 25 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5374580330438736		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.5374580330438736 | validation: 0.7760495235111359]
	TIME [epoch: 24.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178294932761749		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.5178294932761749 | validation: 0.7512995220545463]
	TIME [epoch: 25 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214165256028261		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.5214165256028261 | validation: 0.7391845110341413]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153549136926113		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.5153549136926113 | validation: 0.7478159463990756]
	TIME [epoch: 25 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4806638603604955		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.4806638603604955 | validation: 0.756516013410247]
	TIME [epoch: 25 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48456159587470005		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.48456159587470005 | validation: 0.704781827063225]
	TIME [epoch: 25 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4746229482760396		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.4746229482760396 | validation: 0.7167112588942447]
	TIME [epoch: 25 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48403961755349206		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.48403961755349206 | validation: 0.7485478229757212]
	TIME [epoch: 25 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4947949680782804		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.4947949680782804 | validation: 0.7055317154500597]
	TIME [epoch: 25 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780187919455732		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.4780187919455732 | validation: 0.7331143918113765]
	TIME [epoch: 24.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49607567205101205		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.49607567205101205 | validation: 0.7627502782052074]
	TIME [epoch: 24.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186675640813092		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.5186675640813092 | validation: 0.7287466903688883]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246364344039443		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.5246364344039443 | validation: 0.7184515941388836]
	TIME [epoch: 25 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48373228006004443		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.48373228006004443 | validation: 0.7449387743957856]
	TIME [epoch: 25 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766661055150084		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.4766661055150084 | validation: 0.736001145887418]
	TIME [epoch: 25 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47574666236082164		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.47574666236082164 | validation: 0.7216071034385023]
	TIME [epoch: 25 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4682756642191267		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.4682756642191267 | validation: 0.7427551387648802]
	TIME [epoch: 24.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747258521976677		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.4747258521976677 | validation: 0.6793596450116002]
	TIME [epoch: 25 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734163831900505		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.4734163831900505 | validation: 0.7540329655049484]
	TIME [epoch: 25 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48815965662139754		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.48815965662139754 | validation: 0.7408626558148975]
	TIME [epoch: 24.9 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49745585971656775		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.49745585971656775 | validation: 0.7728053282791456]
	TIME [epoch: 25 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993645360284361		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.4993645360284361 | validation: 0.7601274481580694]
	TIME [epoch: 24.9 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4802542810274184		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.4802542810274184 | validation: 0.7647233596680204]
	TIME [epoch: 25 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702060380068519		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.4702060380068519 | validation: 0.7879189255430886]
	TIME [epoch: 25 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4825483143785499		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.4825483143785499 | validation: 0.7926407503415587]
	TIME [epoch: 25 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497116518537962		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.497116518537962 | validation: 0.7596140867141685]
	TIME [epoch: 24.9 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899432444239513		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.4899432444239513 | validation: 0.7832157977253331]
	TIME [epoch: 25 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478642416435812		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.478642416435812 | validation: 0.7505846027677154]
	TIME [epoch: 25 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4842483878674933		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.4842483878674933 | validation: 0.7432466264990495]
	TIME [epoch: 25 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914489361057175		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.4914489361057175 | validation: 0.7171572714594986]
	TIME [epoch: 25 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48808717217260367		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.48808717217260367 | validation: 0.7321454124605736]
	TIME [epoch: 25 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4782136123861507		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.4782136123861507 | validation: 0.7515491486921018]
	TIME [epoch: 25 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891181984887587		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.4891181984887587 | validation: 0.750491694623817]
	TIME [epoch: 25 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478524365043831		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.478524365043831 | validation: 0.7596868409645222]
	TIME [epoch: 25 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48936958243722006		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.48936958243722006 | validation: 0.7573460650021886]
	TIME [epoch: 25 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.479893934600079		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.479893934600079 | validation: 0.7368340557051016]
	TIME [epoch: 25 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4814742532941614		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.4814742532941614 | validation: 0.7524882129467066]
	TIME [epoch: 25 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4751442336323856		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.4751442336323856 | validation: 0.7224117692311184]
	TIME [epoch: 24.9 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707479392847305		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.4707479392847305 | validation: 0.7548982486722474]
	TIME [epoch: 25 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839312115683353		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.4839312115683353 | validation: 0.7633284245613067]
	TIME [epoch: 24.9 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46571923556458494		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.46571923556458494 | validation: 0.7394949650153941]
	TIME [epoch: 25 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47583916209986443		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.47583916209986443 | validation: 0.731048511322995]
	TIME [epoch: 25 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852961600991339		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.4852961600991339 | validation: 0.7481939915096435]
	TIME [epoch: 24.9 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087892323669135		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.5087892323669135 | validation: 0.7630602917359471]
	TIME [epoch: 25 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5042053029241409		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.5042053029241409 | validation: 0.7313148840365825]
	TIME [epoch: 25 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476641439567748		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.476641439567748 | validation: 0.7353981469343475]
	TIME [epoch: 24.9 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4866713926232591		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.4866713926232591 | validation: 0.7431650625174385]
	TIME [epoch: 24.9 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48852842446998124		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.48852842446998124 | validation: 0.7358874187158452]
	TIME [epoch: 24.9 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46231900569792783		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.46231900569792783 | validation: 0.7670151629318225]
	TIME [epoch: 25 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47943160537244034		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.47943160537244034 | validation: 0.758235183714177]
	TIME [epoch: 25 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903491688775332		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.4903491688775332 | validation: 0.7602472000070136]
	TIME [epoch: 24.9 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48753058173633346		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.48753058173633346 | validation: 0.7389326385117382]
	TIME [epoch: 25 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47770350545897966		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.47770350545897966 | validation: 0.7358075919794902]
	TIME [epoch: 25 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4795948806784417		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.4795948806784417 | validation: 0.743393477607655]
	TIME [epoch: 25 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821377387395911		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.4821377387395911 | validation: 0.7396353023040914]
	TIME [epoch: 24.9 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49587320148823943		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.49587320148823943 | validation: 0.6916380390763448]
	TIME [epoch: 24.9 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638006399252653		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.4638006399252653 | validation: 0.6840130026923389]
	TIME [epoch: 25 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677877025872138		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.4677877025872138 | validation: 0.7551798720504177]
	TIME [epoch: 25 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693876248834884		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.4693876248834884 | validation: 0.7381095345899013]
	TIME [epoch: 25 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4765669945609232		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.4765669945609232 | validation: 0.7368204620892256]
	TIME [epoch: 25 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46694912162907587		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.46694912162907587 | validation: 0.7438256029355012]
	TIME [epoch: 24.9 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4768828594047976		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.4768828594047976 | validation: 0.7395376653307604]
	TIME [epoch: 24.9 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.463008781357545		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.463008781357545 | validation: 0.7121724837008282]
	TIME [epoch: 25 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675660134217552		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.4675660134217552 | validation: 0.7200703204405275]
	TIME [epoch: 25 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47818134047916444		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.47818134047916444 | validation: 0.7437302697727207]
	TIME [epoch: 24.9 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47837730968779635		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.47837730968779635 | validation: 0.7240441409912325]
	TIME [epoch: 25 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47315927293262217		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.47315927293262217 | validation: 0.7427864118920283]
	TIME [epoch: 25 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47827924624680945		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.47827924624680945 | validation: 0.761686419887867]
	TIME [epoch: 25 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4893869736545483		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.4893869736545483 | validation: 0.753044922145829]
	TIME [epoch: 25 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48380885444420624		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.48380885444420624 | validation: 0.7635327967705741]
	TIME [epoch: 25 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4901599110860475		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.4901599110860475 | validation: 0.7001359396795427]
	TIME [epoch: 24.9 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741960283505876		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.4741960283505876 | validation: 0.7667642232945402]
	TIME [epoch: 24.9 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46456474068564224		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.46456474068564224 | validation: 0.737722473514997]
	TIME [epoch: 25 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476516363630891		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.476516363630891 | validation: 0.7632831358093194]
	TIME [epoch: 24.9 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727517840971099		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.4727517840971099 | validation: 0.7313496712714974]
	TIME [epoch: 25 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687760105503033		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.4687760105503033 | validation: 0.6715588190930367]
	TIME [epoch: 24.9 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4805927232374359		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.4805927232374359 | validation: 0.7310151849247163]
	TIME [epoch: 24.9 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820001221513219		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.4820001221513219 | validation: 0.6812581268501502]
	TIME [epoch: 24.9 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46858054893979106		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.46858054893979106 | validation: 0.7139538651842439]
	TIME [epoch: 24.9 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46952422772397095		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.46952422772397095 | validation: 0.7364738832531782]
	TIME [epoch: 24.9 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478276767074607		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.478276767074607 | validation: 0.7456488169614636]
	TIME [epoch: 24.9 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47116831670032217		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.47116831670032217 | validation: 0.7180623062360203]
	TIME [epoch: 24.9 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732596469331106		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.4732596469331106 | validation: 0.7438108219785527]
	TIME [epoch: 24.9 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47938282272826616		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.47938282272826616 | validation: 0.7292528939270199]
	TIME [epoch: 24.9 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47912911790871615		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.47912911790871615 | validation: 0.7351924451157619]
	TIME [epoch: 24.9 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46850617355271973		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.46850617355271973 | validation: 0.7180749037215044]
	TIME [epoch: 24.9 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662602391680087		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.4662602391680087 | validation: 0.7107918939470329]
	TIME [epoch: 24.9 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46792644802658456		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.46792644802658456 | validation: 0.724189364736182]
	TIME [epoch: 24.9 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773535951395277		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.4773535951395277 | validation: 0.719391308260103]
	TIME [epoch: 24.9 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46415288502623053		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.46415288502623053 | validation: 0.7483358130622142]
	TIME [epoch: 24.9 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4769022895892131		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.4769022895892131 | validation: 0.7380447192998923]
	TIME [epoch: 24.9 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4731215088920045		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.4731215088920045 | validation: 0.7446986828798697]
	TIME [epoch: 24.9 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4832689614670345		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.4832689614670345 | validation: 0.7573708103833358]
	TIME [epoch: 24.9 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975511250085905		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.4975511250085905 | validation: 0.7454239142805087]
	TIME [epoch: 24.9 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881563451638131		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.4881563451638131 | validation: 0.7483516730495683]
	TIME [epoch: 25 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764904156046737		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.4764904156046737 | validation: 0.7187425100783505]
	TIME [epoch: 25 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4670004635734296		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.4670004635734296 | validation: 0.76324100404658]
	TIME [epoch: 25 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46767729236067257		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.46767729236067257 | validation: 0.7065364390482034]
	TIME [epoch: 25 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876175132945485		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.4876175132945485 | validation: 0.7414932385701181]
	TIME [epoch: 24.9 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4868599604369348		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.4868599604369348 | validation: 0.7491375747091366]
	TIME [epoch: 24.9 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4694042576019309		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.4694042576019309 | validation: 0.7223855816502814]
	TIME [epoch: 25 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.471939952115014		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.471939952115014 | validation: 0.7365507852164975]
	TIME [epoch: 25 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48949591117342595		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.48949591117342595 | validation: 0.7269735026784465]
	TIME [epoch: 24.9 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659567254963816		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.4659567254963816 | validation: 0.6955257708162068]
	TIME [epoch: 24.9 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45739149346062635		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.45739149346062635 | validation: 0.7192188917126906]
	TIME [epoch: 24.9 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674481064827877		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.4674481064827877 | validation: 0.6963622901011229]
	TIME [epoch: 24.9 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763971239969097		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.4763971239969097 | validation: 0.7037350026033847]
	TIME [epoch: 24.9 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4786589679749088		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.4786589679749088 | validation: 0.7255911570709742]
	TIME [epoch: 24.9 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48113598298725435		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.48113598298725435 | validation: 0.7442712004062068]
	TIME [epoch: 24.9 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030337696175802		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.5030337696175802 | validation: 0.7725709890302288]
	TIME [epoch: 25 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165270517471575		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.5165270517471575 | validation: 0.7868469252759226]
	TIME [epoch: 24.9 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5451322469500424		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.5451322469500424 | validation: 0.7862548412084963]
	TIME [epoch: 24.9 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355972623149081		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.5355972623149081 | validation: 0.8046537143063338]
	TIME [epoch: 24.9 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48530780823394304		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.48530780823394304 | validation: 0.7653215031744705]
	TIME [epoch: 24.9 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47500156912975655		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.47500156912975655 | validation: 0.7470506416568184]
	TIME [epoch: 24.9 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47939999295381386		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.47939999295381386 | validation: 0.7608991115185706]
	TIME [epoch: 24.9 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47633787089050483		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.47633787089050483 | validation: 0.7414574983800688]
	TIME [epoch: 24.9 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47626758910367917		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.47626758910367917 | validation: 0.7254110373762629]
	TIME [epoch: 24.9 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771202209090528		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.4771202209090528 | validation: 0.7552975849757237]
	TIME [epoch: 24.9 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747174047574453		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.4747174047574453 | validation: 0.7297631768865007]
	TIME [epoch: 24.9 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47309036268658405		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.47309036268658405 | validation: 0.7184217213755659]
	TIME [epoch: 24.9 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47567354656268035		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.47567354656268035 | validation: 0.7159086960234728]
	TIME [epoch: 24.9 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4784324078789272		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.4784324078789272 | validation: 0.7497914360694777]
	TIME [epoch: 24.9 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47744111661906574		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.47744111661906574 | validation: 0.744318548064933]
	TIME [epoch: 24.9 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47530268536040315		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.47530268536040315 | validation: 0.7248964125306219]
	TIME [epoch: 24.9 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46932545458864827		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.46932545458864827 | validation: 0.7166816077641386]
	TIME [epoch: 24.9 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687545556724393		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.4687545556724393 | validation: 0.7660565527484969]
	TIME [epoch: 24.9 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47539311812012097		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.47539311812012097 | validation: 0.7599027055624913]
	TIME [epoch: 24.9 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654530167794635		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.4654530167794635 | validation: 0.7611959857899478]
	TIME [epoch: 24.9 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47554602972124277		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.47554602972124277 | validation: 0.7497868646379644]
	TIME [epoch: 24.9 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617829472240053		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.4617829472240053 | validation: 0.7485137280803349]
	TIME [epoch: 24.9 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764631403345639		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.4764631403345639 | validation: 0.7422494135094437]
	TIME [epoch: 24.9 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46449278194965643		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.46449278194965643 | validation: 0.733800506057844]
	TIME [epoch: 24.9 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4675281010875401		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.4675281010875401 | validation: 0.6698259080397432]
	TIME [epoch: 24.9 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46995113779240943		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.46995113779240943 | validation: 0.7609417840236844]
	TIME [epoch: 24.9 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47414286899530234		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.47414286899530234 | validation: 0.7534224896567442]
	TIME [epoch: 24.9 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621937733961775		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.4621937733961775 | validation: 0.748548664771038]
	TIME [epoch: 24.9 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669907301873123		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.4669907301873123 | validation: 0.7492795601186438]
	TIME [epoch: 24.9 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48632559618098753		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.48632559618098753 | validation: 0.753513326172687]
	TIME [epoch: 24.9 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48393103013506955		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.48393103013506955 | validation: 0.7715869464696071]
	TIME [epoch: 24.9 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468208361005918		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.468208361005918 | validation: 0.7685080432702356]
	TIME [epoch: 24.9 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704928704535972		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.4704928704535972 | validation: 0.7783894470157463]
	TIME [epoch: 24.9 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736924086694822		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.4736924086694822 | validation: 0.7627253650591774]
	TIME [epoch: 24.9 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789330287634741		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.4789330287634741 | validation: 0.7937430811209132]
	TIME [epoch: 25 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.467569621077363		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.467569621077363 | validation: 0.748921044586308]
	TIME [epoch: 24.9 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4737201062012675		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.4737201062012675 | validation: 0.7651238628763801]
	TIME [epoch: 24.9 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744817213985888		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.4744817213985888 | validation: 0.7335113675641375]
	TIME [epoch: 25 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4822010113850135		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.4822010113850135 | validation: 0.736630686711198]
	TIME [epoch: 24.9 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830986113694532		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.4830986113694532 | validation: 0.7520412076456467]
	TIME [epoch: 25 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46921067868013394		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.46921067868013394 | validation: 0.7692897551761015]
	TIME [epoch: 24.9 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637332352943498		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.4637332352943498 | validation: 0.7588685338496026]
	TIME [epoch: 25 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669237988175895		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.4669237988175895 | validation: 0.7239070619052113]
	TIME [epoch: 25 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650772940247872		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.4650772940247872 | validation: 0.7362291386582364]
	TIME [epoch: 25 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602106727145757		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.4602106727145757 | validation: 0.7503342062852578]
	TIME [epoch: 25 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47221735639267604		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.47221735639267604 | validation: 0.7367527045725979]
	TIME [epoch: 24.9 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821171017057999		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.4821171017057999 | validation: 0.7511846456852712]
	TIME [epoch: 25 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46973135684359685		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.46973135684359685 | validation: 0.721906518595231]
	TIME [epoch: 25 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4738495801828363		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.4738495801828363 | validation: 0.7314430557987607]
	TIME [epoch: 25 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47046233831319845		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.47046233831319845 | validation: 0.7263145159823291]
	TIME [epoch: 24.9 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47943529494097664		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.47943529494097664 | validation: 0.7478910969551308]
	TIME [epoch: 24.9 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48092143374764673		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.48092143374764673 | validation: 0.7194022090518485]
	TIME [epoch: 25 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4817160146708315		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.4817160146708315 | validation: 0.7238108079155563]
	TIME [epoch: 25 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49786892840136904		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.49786892840136904 | validation: 0.7532769987170668]
	TIME [epoch: 25 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834854635736363		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.4834854635736363 | validation: 0.7356249592684939]
	TIME [epoch: 24.9 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47597041555435543		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.47597041555435543 | validation: 0.7259634580401163]
	TIME [epoch: 24.9 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46081078959551075		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.46081078959551075 | validation: 0.7125086954462267]
	TIME [epoch: 24.9 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707674054092752		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.4707674054092752 | validation: 0.7417576983264]
	TIME [epoch: 24.9 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47270494379057804		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.47270494379057804 | validation: 0.6900949946171631]
	TIME [epoch: 24.9 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46357225068317276		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.46357225068317276 | validation: 0.7440001413399209]
	TIME [epoch: 24.9 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654726883632997		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.4654726883632997 | validation: 0.747863805780344]
	TIME [epoch: 24.9 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46130680929133994		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.46130680929133994 | validation: 0.7354150473113679]
	TIME [epoch: 24.9 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596825247188854		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.4596825247188854 | validation: 0.7355972305622361]
	TIME [epoch: 24.9 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719462589414459		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.4719462589414459 | validation: 0.7354612476945609]
	TIME [epoch: 24.9 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4797395078727318		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.4797395078727318 | validation: 0.7222758139481766]
	TIME [epoch: 25 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740699195603071		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.4740699195603071 | validation: 0.7330383045481637]
	TIME [epoch: 24.9 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47092797712498646		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.47092797712498646 | validation: 0.7391629084300159]
	TIME [epoch: 24.9 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656889798291076		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.4656889798291076 | validation: 0.7371893866455246]
	TIME [epoch: 25 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47278981591525227		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.47278981591525227 | validation: 0.7464643115219525]
	TIME [epoch: 25 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4685438351113773		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.4685438351113773 | validation: 0.7431323392235004]
	TIME [epoch: 25 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4757972021971093		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.4757972021971093 | validation: 0.7363976017787153]
	TIME [epoch: 25 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47744626714089217		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.47744626714089217 | validation: 0.7474842511715224]
	TIME [epoch: 25 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686388309435421		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.4686388309435421 | validation: 0.7512127805795428]
	TIME [epoch: 24.9 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607084262853251		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.4607084262853251 | validation: 0.7616816435493782]
	TIME [epoch: 24.9 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734469034713069		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.4734469034713069 | validation: 0.7421586840315842]
	TIME [epoch: 24.9 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47605149506238065		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.47605149506238065 | validation: 0.7738225592279594]
	TIME [epoch: 25 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780798997372465		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.4780798997372465 | validation: 0.7499564776049704]
	TIME [epoch: 25 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47676167768408656		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.47676167768408656 | validation: 0.7523397414529683]
	TIME [epoch: 25 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722547676816866		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.4722547676816866 | validation: 0.7578334248399113]
	TIME [epoch: 25 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.467953890406709		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.467953890406709 | validation: 0.7568266944342454]
	TIME [epoch: 25 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46952534822920744		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.46952534822920744 | validation: 0.7451825746303247]
	TIME [epoch: 25 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46582517537596224		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.46582517537596224 | validation: 0.7459601226902465]
	TIME [epoch: 25 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4593291212356643		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.4593291212356643 | validation: 0.7463920440466242]
	TIME [epoch: 25 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46750197734696786		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.46750197734696786 | validation: 0.7570809123051742]
	TIME [epoch: 25 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46803394178009494		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.46803394178009494 | validation: 0.7615671954902377]
	TIME [epoch: 25 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663793537778414		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.4663793537778414 | validation: 0.7503482882922103]
	TIME [epoch: 25 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4611814359436684		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.4611814359436684 | validation: 0.7443191548554091]
	TIME [epoch: 25 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46812760830910977		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.46812760830910977 | validation: 0.7312722464042307]
	TIME [epoch: 25 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47126277086982304		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.47126277086982304 | validation: 0.7514751274903627]
	TIME [epoch: 25 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4809574822414465		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.4809574822414465 | validation: 0.7472339884939615]
	TIME [epoch: 25 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47349135471316195		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.47349135471316195 | validation: 0.7511661294447007]
	TIME [epoch: 25 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46557669943686264		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.46557669943686264 | validation: 0.7255060111124425]
	TIME [epoch: 25 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4719555476441782		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.4719555476441782 | validation: 0.752163873395735]
	TIME [epoch: 25 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4928963995623242		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.4928963995623242 | validation: 0.7738255839084517]
	TIME [epoch: 25 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5207067496474707		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.5207067496474707 | validation: 0.7817164864811305]
	TIME [epoch: 24.9 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317270399271112		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.5317270399271112 | validation: 0.7610445477603617]
	TIME [epoch: 24.9 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.486716902249003		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.486716902249003 | validation: 0.7525231814998068]
	TIME [epoch: 25 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.475624530094351		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.475624530094351 | validation: 0.7539930290382887]
	TIME [epoch: 24.9 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773098656760061		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.4773098656760061 | validation: 0.7641309502458673]
	TIME [epoch: 24.9 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739076782397639		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.4739076782397639 | validation: 0.7684210031279449]
	TIME [epoch: 24.9 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659496224552764		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.4659496224552764 | validation: 0.7673443197923834]
	TIME [epoch: 24.9 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45767989589645725		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.45767989589645725 | validation: 0.7485874875438141]
	TIME [epoch: 24.9 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47190679411266584		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.47190679411266584 | validation: 0.7642424754071859]
	TIME [epoch: 24.9 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46086421977778047		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.46086421977778047 | validation: 0.7750770514688453]
	TIME [epoch: 24.9 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4752814858210832		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.4752814858210832 | validation: 0.764211877780891]
	TIME [epoch: 25 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46613325644797343		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.46613325644797343 | validation: 0.7659939092946505]
	TIME [epoch: 24.9 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47309891804343457		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.47309891804343457 | validation: 0.7641894925161193]
	TIME [epoch: 25 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4725173121616014		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.4725173121616014 | validation: 0.7726088686505258]
	TIME [epoch: 24.9 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47167512622828844		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.47167512622828844 | validation: 0.7645308552718033]
	TIME [epoch: 25 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47363553361106486		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.47363553361106486 | validation: 0.769331347753278]
	TIME [epoch: 24.9 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46532674660168594		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.46532674660168594 | validation: 0.7745575634342644]
	TIME [epoch: 25 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47318841942513246		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.47318841942513246 | validation: 0.7798977280417759]
	TIME [epoch: 24.9 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47606937230298		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.47606937230298 | validation: 0.7775251603097606]
	TIME [epoch: 25 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4842108912302387		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.4842108912302387 | validation: 0.7774858462936007]
	TIME [epoch: 25 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906823746844138		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.4906823746844138 | validation: 0.7916104499158655]
	TIME [epoch: 25 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49040912251288715		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.49040912251288715 | validation: 0.7969674706298937]
	TIME [epoch: 24.9 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49404625224677423		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.49404625224677423 | validation: 0.8012934742533506]
	TIME [epoch: 25 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821310312617919		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.4821310312617919 | validation: 0.7994596925790609]
	TIME [epoch: 24.9 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4754654999188863		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.4754654999188863 | validation: 0.7532369706871685]
	TIME [epoch: 25 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46951512671401646		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.46951512671401646 | validation: 0.7636153918383096]
	TIME [epoch: 24.9 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698993621369265		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.4698993621369265 | validation: 0.7603080531954457]
	TIME [epoch: 24.9 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46596560009251575		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.46596560009251575 | validation: 0.7735395124793242]
	TIME [epoch: 25 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46356114568954004		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.46356114568954004 | validation: 0.7513010697371908]
	TIME [epoch: 24.9 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704395117783704		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.4704395117783704 | validation: 0.7639005798568641]
	TIME [epoch: 24.9 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4740083324974423		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.4740083324974423 | validation: 0.7705120804402691]
	TIME [epoch: 24.9 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47765054484827235		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.47765054484827235 | validation: 0.7478901384199561]
	TIME [epoch: 24.9 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47612174070540814		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.47612174070540814 | validation: 0.8102617734723003]
	TIME [epoch: 25 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47613059832678345		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.47613059832678345 | validation: 0.7976173749141612]
	TIME [epoch: 24.9 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.480497232899144		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.480497232899144 | validation: 0.7924297268506948]
	TIME [epoch: 24.9 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47490156133834033		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.47490156133834033 | validation: 0.7485760897329419]
	TIME [epoch: 24.9 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808445419679537		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.4808445419679537 | validation: 0.7385852959853269]
	TIME [epoch: 25 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869613856089232		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.4869613856089232 | validation: 0.7888868746939874]
	TIME [epoch: 24.9 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47291403492653716		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.47291403492653716 | validation: 0.781552700827472]
	TIME [epoch: 25 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4864119682116693		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.4864119682116693 | validation: 0.7893316209408585]
	TIME [epoch: 24.9 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48397656352521723		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.48397656352521723 | validation: 0.7736436313396672]
	TIME [epoch: 24.9 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46477386146768856		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.46477386146768856 | validation: 0.7695998391083374]
	TIME [epoch: 25 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46441100204592556		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.46441100204592556 | validation: 0.7858341292284043]
	TIME [epoch: 25 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668029282641635		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.4668029282641635 | validation: 0.7590266588198702]
	TIME [epoch: 25 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47302074425817187		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.47302074425817187 | validation: 0.7807371833358161]
	TIME [epoch: 25 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47439337655775515		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.47439337655775515 | validation: 0.789557571055951]
	TIME [epoch: 24.9 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.470053228833818		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.470053228833818 | validation: 0.790342641020172]
	TIME [epoch: 24.9 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4948881794585742		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.4948881794585742 | validation: 0.8086701618653811]
	TIME [epoch: 24.9 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4993966744920446		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.4993966744920446 | validation: 0.804118008664852]
	TIME [epoch: 24.9 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939336235126648		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.4939336235126648 | validation: 0.8134862221625982]
	TIME [epoch: 24.9 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48577081145956397		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.48577081145956397 | validation: 0.7979267465783122]
	TIME [epoch: 25 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48824014504718855		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.48824014504718855 | validation: 0.7891844663613093]
	TIME [epoch: 25 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48009160722254374		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.48009160722254374 | validation: 0.7952131095988116]
	TIME [epoch: 24.9 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914215383321002		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.4914215383321002 | validation: 0.8026073924143211]
	TIME [epoch: 25 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823914445758829		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.4823914445758829 | validation: 0.7861956276298827]
	TIME [epoch: 24.9 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4726349798573816		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.4726349798573816 | validation: 0.7702148474879031]
	TIME [epoch: 24.9 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681304593745581		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.4681304593745581 | validation: 0.7754396825724567]
	TIME [epoch: 24.9 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4742278575156474		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.4742278575156474 | validation: 0.7682847503593361]
	TIME [epoch: 24.9 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47337356702607963		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.47337356702607963 | validation: 0.7869110810551146]
	TIME [epoch: 24.9 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47302261810903135		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.47302261810903135 | validation: 0.7826193156476586]
	TIME [epoch: 24.9 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739170151218811		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.4739170151218811 | validation: 0.7917164533008889]
	TIME [epoch: 25 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46924995842853084		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.46924995842853084 | validation: 0.7784975966253661]
	TIME [epoch: 24.9 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47237581243514326		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.47237581243514326 | validation: 0.7860263291790535]
	TIME [epoch: 25 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674633307227205		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.4674633307227205 | validation: 0.7734299197367236]
	TIME [epoch: 25 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695971294053197		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.4695971294053197 | validation: 0.777187559888739]
	TIME [epoch: 24.9 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47105659175967657		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.47105659175967657 | validation: 0.765542773950423]
	TIME [epoch: 24.9 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47039553629336606		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.47039553629336606 | validation: 0.7658002683728309]
	TIME [epoch: 24.9 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47621813841286		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.47621813841286 | validation: 0.7720513256790928]
	TIME [epoch: 24.9 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47076734144998134		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.47076734144998134 | validation: 0.7699506830088285]
	TIME [epoch: 24.9 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4796723197282652		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.4796723197282652 | validation: 0.7694939095678465]
	TIME [epoch: 25 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46613368953380074		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.46613368953380074 | validation: 0.7775043137520943]
	TIME [epoch: 24.9 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721287497788556		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.4721287497788556 | validation: 0.748350906445799]
	TIME [epoch: 25 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47231505700574883		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.47231505700574883 | validation: 0.7700842975273625]
	TIME [epoch: 24.9 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47007994228462513		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.47007994228462513 | validation: 0.7730826846248947]
	TIME [epoch: 25 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47289936546970734		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.47289936546970734 | validation: 0.7762324393281429]
	TIME [epoch: 24.9 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47386957949855263		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.47386957949855263 | validation: 0.7750661060548353]
	TIME [epoch: 25 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4715913241350218		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.4715913241350218 | validation: 0.7604702698732522]
	TIME [epoch: 24.9 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46838503405254683		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.46838503405254683 | validation: 0.7695785061261049]
	TIME [epoch: 25 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46684743031377307		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.46684743031377307 | validation: 0.7755576265920614]
	TIME [epoch: 24.9 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46812260613361323		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.46812260613361323 | validation: 0.7771670019362731]
	TIME [epoch: 24.9 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4757375053534013		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.4757375053534013 | validation: 0.8003405834005087]
	TIME [epoch: 24.9 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763321477625765		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.4763321477625765 | validation: 0.7724436183885044]
	TIME [epoch: 25 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771171471228185		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.4771171471228185 | validation: 0.7770187084914983]
	TIME [epoch: 24.9 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763172677818501		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.4763172677818501 | validation: 0.8020991999275484]
	TIME [epoch: 24.9 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47190439889480307		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.47190439889480307 | validation: 0.802570446553423]
	TIME [epoch: 24.9 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.481062688475657		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.481062688475657 | validation: 0.7770395448201728]
	TIME [epoch: 24.9 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47313168472999617		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.47313168472999617 | validation: 0.7931072536231603]
	TIME [epoch: 24.9 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47396801583880416		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.47396801583880416 | validation: 0.794634028301]
	TIME [epoch: 25 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48416690326143497		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.48416690326143497 | validation: 0.8153410015935583]
	TIME [epoch: 24.9 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49376185246426474		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.49376185246426474 | validation: 0.8056253159989922]
	TIME [epoch: 24.9 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845040356617537		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.4845040356617537 | validation: 0.7998601473393246]
	TIME [epoch: 25 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47262740649418195		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.47262740649418195 | validation: 0.8025008906483632]
	TIME [epoch: 24.9 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47498494777614886		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.47498494777614886 | validation: 0.7861362371347707]
	TIME [epoch: 25 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46628336586576224		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.46628336586576224 | validation: 0.7661352703830037]
	TIME [epoch: 24.9 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47547498725844706		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.47547498725844706 | validation: 0.7678014322913549]
	TIME [epoch: 24.9 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47274269439981015		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.47274269439981015 | validation: 0.7761948639988164]
	TIME [epoch: 24.9 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4730869986098143		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.4730869986098143 | validation: 0.7940463497418283]
	TIME [epoch: 24.9 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750249910628989		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.4750249910628989 | validation: 0.7860481626495721]
	TIME [epoch: 24.9 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4763092758811356		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.4763092758811356 | validation: 0.7983667570056284]
	TIME [epoch: 24.9 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466749282960531		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.466749282960531 | validation: 0.7742666735640995]
	TIME [epoch: 24.9 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4645732739207249		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.4645732739207249 | validation: 0.7626570759942491]
	TIME [epoch: 24.9 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4617258448835243		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.4617258448835243 | validation: 0.7711828443883897]
	TIME [epoch: 24.9 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671758088256926		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.4671758088256926 | validation: 0.7786374388854153]
	TIME [epoch: 25 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683901768643193		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.4683901768643193 | validation: 0.8092769271426997]
	TIME [epoch: 24.9 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4825558297289115		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.4825558297289115 | validation: 0.7969827007687701]
	TIME [epoch: 25 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47289857474456287		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.47289857474456287 | validation: 0.7949487041501838]
	TIME [epoch: 24.9 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47308775467542663		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.47308775467542663 | validation: 0.7963971500175747]
	TIME [epoch: 24.9 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47762622068718585		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.47762622068718585 | validation: 0.8020210214135932]
	TIME [epoch: 24.9 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762665549638828		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.4762665549638828 | validation: 0.7946512391670513]
	TIME [epoch: 24.9 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4686226063747339		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.4686226063747339 | validation: 0.7578881342982708]
	TIME [epoch: 24.9 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4734879690495651		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.4734879690495651 | validation: 0.766837725738875]
	TIME [epoch: 25 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697179113640847		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.4697179113640847 | validation: 0.779321051345529]
	TIME [epoch: 25 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47054006132499443		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.47054006132499443 | validation: 0.8001805844965734]
	TIME [epoch: 24.9 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47619309466965043		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.47619309466965043 | validation: 0.8015153789755052]
	TIME [epoch: 25 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4735594180743121		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.4735594180743121 | validation: 0.7789874609193251]
	TIME [epoch: 24.9 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748640773332899		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.4748640773332899 | validation: 0.7834013349393183]
	TIME [epoch: 24.9 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47221453894169696		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.47221453894169696 | validation: 0.7786843678520841]
	TIME [epoch: 24.9 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823686164817931		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.4823686164817931 | validation: 0.7882435477091028]
	TIME [epoch: 24.9 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47117686133673387		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.47117686133673387 | validation: 0.7623549040719491]
	TIME [epoch: 24.9 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46930443103510516		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.46930443103510516 | validation: 0.757578517963091]
	TIME [epoch: 24.9 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635682172377368		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.4635682172377368 | validation: 0.7731085454637031]
	TIME [epoch: 25 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46828390672643866		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.46828390672643866 | validation: 0.763529505361252]
	TIME [epoch: 24.9 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4779953433608645		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.4779953433608645 | validation: 0.767052726207366]
	TIME [epoch: 24.9 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709011299663364		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.4709011299663364 | validation: 0.7712715672727205]
	TIME [epoch: 24.9 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4637109976422081		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.4637109976422081 | validation: 0.7615017255218026]
	TIME [epoch: 24.9 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4653114418373421		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.4653114418373421 | validation: 0.7408005355871439]
	TIME [epoch: 24.9 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4644330940418568		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.4644330940418568 | validation: 0.760688945416257]
	TIME [epoch: 24.9 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732040872998127		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.4732040872998127 | validation: 0.7612944354489506]
	TIME [epoch: 24.9 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47267377542018		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.47267377542018 | validation: 0.7655078778651528]
	TIME [epoch: 24.9 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672365767673736		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.4672365767673736 | validation: 0.7677618791273833]
	TIME [epoch: 25 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608955840044188		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.4608955840044188 | validation: 0.7578564217720838]
	TIME [epoch: 24.9 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47697954835333073		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.47697954835333073 | validation: 0.7694648485278828]
	TIME [epoch: 25 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650591241141251		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.4650591241141251 | validation: 0.7592812896137892]
	TIME [epoch: 24.9 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599501882566336		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.4599501882566336 | validation: 0.758241934705535]
	TIME [epoch: 25 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46735662095666436		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.46735662095666436 | validation: 0.7609273390116209]
	TIME [epoch: 24.9 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760572067558044		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.4760572067558044 | validation: 0.7539993361164699]
	TIME [epoch: 24.9 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47021156592249574		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.47021156592249574 | validation: 0.7754430230446516]
	TIME [epoch: 24.9 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46918299174544525		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.46918299174544525 | validation: 0.7495800957716017]
	TIME [epoch: 24.9 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671917614190363		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.4671917614190363 | validation: 0.7613312401299066]
	TIME [epoch: 24.9 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594365033882479		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.4594365033882479 | validation: 0.771574375748672]
	TIME [epoch: 24.9 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654763633680208		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.4654763633680208 | validation: 0.7535392408962511]
	TIME [epoch: 24.9 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638985017003556		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.4638985017003556 | validation: 0.7571698194928337]
	TIME [epoch: 25 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701380543313639		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.4701380543313639 | validation: 0.7566347329391502]
	TIME [epoch: 24.9 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47565160648411126		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.47565160648411126 | validation: 0.7528085100048242]
	TIME [epoch: 24.9 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560379220962624		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.4560379220962624 | validation: 0.7538096296543482]
	TIME [epoch: 24.9 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46029412642211304		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.46029412642211304 | validation: 0.7593129557250679]
	TIME [epoch: 24.9 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677524292770705		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.4677524292770705 | validation: 0.7592226996783478]
	TIME [epoch: 24.9 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753024092414369		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.4753024092414369 | validation: 0.76265932955571]
	TIME [epoch: 25 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4760990535880684		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.4760990535880684 | validation: 0.7404309071468069]
	TIME [epoch: 24.9 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787254938256238		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.4787254938256238 | validation: 0.7678446456991692]
	TIME [epoch: 24.9 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827450531744731		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.4827450531744731 | validation: 0.7604655930390396]
	TIME [epoch: 24.9 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47706727859439146		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.47706727859439146 | validation: 0.7598677181009387]
	TIME [epoch: 24.9 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48882868443448757		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.48882868443448757 | validation: 0.7608647818238472]
	TIME [epoch: 24.9 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4996306472365636		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.4996306472365636 | validation: 0.7720705631963821]
	TIME [epoch: 24.9 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49383706589278		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.49383706589278 | validation: 0.7667775435339741]
	TIME [epoch: 24.9 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49847835777617444		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.49847835777617444 | validation: 0.7699640549944359]
	TIME [epoch: 24.9 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48875212317397787		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.48875212317397787 | validation: 0.7718648362162001]
	TIME [epoch: 25 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49682125586577675		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.49682125586577675 | validation: 0.7568193506567928]
	TIME [epoch: 24.9 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4927911645397167		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.4927911645397167 | validation: 0.7507268586085346]
	TIME [epoch: 24.9 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4979542618239623		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.4979542618239623 | validation: 0.7762639051656922]
	TIME [epoch: 24.9 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118191000319878		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.5118191000319878 | validation: 0.7755386125890266]
	TIME [epoch: 24.9 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005401389392427		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.5005401389392427 | validation: 0.7684129598763925]
	TIME [epoch: 24.9 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4974534491479572		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.4974534491479572 | validation: 0.7582639311342905]
	TIME [epoch: 25 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48384415357755817		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.48384415357755817 | validation: 0.7561902767014644]
	TIME [epoch: 24.9 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4724166065781257		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.4724166065781257 | validation: 0.7407952397140926]
	TIME [epoch: 24.9 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656250471541996		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.4656250471541996 | validation: 0.7647030991033187]
	TIME [epoch: 24.9 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808582882590972		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.4808582882590972 | validation: 0.7425547404785751]
	TIME [epoch: 24.9 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681118736140391		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.4681118736140391 | validation: 0.7516000925700795]
	TIME [epoch: 24.9 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4614832574900735		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.4614832574900735 | validation: 0.7541319115474835]
	TIME [epoch: 24.9 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47181617409897936		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.47181617409897936 | validation: 0.7483222000205053]
	TIME [epoch: 24.9 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46433935028509804		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.46433935028509804 | validation: 0.7468013510650152]
	TIME [epoch: 24.9 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647204350854618		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.4647204350854618 | validation: 0.7441075776872327]
	TIME [epoch: 24.9 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618252089325597		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.4618252089325597 | validation: 0.7511012406978325]
	TIME [epoch: 24.9 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.465283565160402		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.465283565160402 | validation: 0.7625614206495513]
	TIME [epoch: 24.9 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707174675923753		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.4707174675923753 | validation: 0.7686832672092797]
	TIME [epoch: 24.9 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45772556028437417		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.45772556028437417 | validation: 0.7517438921848151]
	TIME [epoch: 24.9 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46394223246789557		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.46394223246789557 | validation: 0.7610186936229261]
	TIME [epoch: 24.9 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46131083350466856		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.46131083350466856 | validation: 0.7573712457445392]
	TIME [epoch: 24.9 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4627260721579388		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.4627260721579388 | validation: 0.7672877846308057]
	TIME [epoch: 24.9 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46670193884915134		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.46670193884915134 | validation: 0.7227989945405244]
	TIME [epoch: 25 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46456233422505894		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.46456233422505894 | validation: 0.7537517449510824]
	TIME [epoch: 24.9 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45424171953120973		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.45424171953120973 | validation: 0.7406416686538608]
	TIME [epoch: 24.9 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4567595303608799		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.4567595303608799 | validation: 0.761076723923102]
	TIME [epoch: 24.9 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46015217937694985		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.46015217937694985 | validation: 0.7549688985917112]
	TIME [epoch: 24.9 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4575896884744609		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.4575896884744609 | validation: 0.7574370052875259]
	TIME [epoch: 24.9 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669733454637054		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.4669733454637054 | validation: 0.7639631000662979]
	TIME [epoch: 25 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46076500318159175		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.46076500318159175 | validation: 0.7710936397906906]
	TIME [epoch: 24.9 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45726252107714055		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.45726252107714055 | validation: 0.7496275644430429]
	TIME [epoch: 24.9 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612703652541799		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.4612703652541799 | validation: 0.764474301726986]
	TIME [epoch: 24.9 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46418323052017324		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.46418323052017324 | validation: 0.7614834881163884]
	TIME [epoch: 25 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46517070650790493		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.46517070650790493 | validation: 0.768293015416614]
	TIME [epoch: 24.9 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700721771520696		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.4700721771520696 | validation: 0.7650015020683929]
	TIME [epoch: 24.9 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46702390373818353		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.46702390373818353 | validation: 0.7885625627412258]
	TIME [epoch: 24.9 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46494310459055227		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.46494310459055227 | validation: 0.7450456218145658]
	TIME [epoch: 24.9 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46027755868094655		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.46027755868094655 | validation: 0.7658004235349268]
	TIME [epoch: 24.9 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46329085569153317		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.46329085569153317 | validation: 0.766809839824906]
	TIME [epoch: 24.9 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4624059751759184		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.4624059751759184 | validation: 0.7521108848410156]
	TIME [epoch: 24.9 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46198588896701476		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.46198588896701476 | validation: 0.7520957468624971]
	TIME [epoch: 25 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4610921111022087		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.4610921111022087 | validation: 0.7578229231862491]
	TIME [epoch: 25 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47108766802640273		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.47108766802640273 | validation: 0.7462426837743251]
	TIME [epoch: 25 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676836383483498		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.4676836383483498 | validation: 0.7779628568737124]
	TIME [epoch: 24.9 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47761555806056927		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.47761555806056927 | validation: 0.7529323457177333]
	TIME [epoch: 24.9 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739133505268946		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.4739133505268946 | validation: 0.7559487451350083]
	TIME [epoch: 24.9 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4799436069755465		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.4799436069755465 | validation: 0.7571770216569709]
	TIME [epoch: 24.9 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47670696386953176		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.47670696386953176 | validation: 0.7607760254611542]
	TIME [epoch: 24.9 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46968220546814454		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.46968220546814454 | validation: 0.7444185284331257]
	TIME [epoch: 25 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4831163084426412		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.4831163084426412 | validation: 0.7651111118286216]
	TIME [epoch: 25 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845427186419928		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.4845427186419928 | validation: 0.7653773263496515]
	TIME [epoch: 24.9 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48132268267507794		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.48132268267507794 | validation: 0.7563999656773698]
	TIME [epoch: 24.9 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766068534965798		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.4766068534965798 | validation: 0.7540028037415596]
	TIME [epoch: 24.9 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4758174404855372		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.4758174404855372 | validation: 0.7448049451605471]
	TIME [epoch: 24.9 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748706914635388		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.4748706914635388 | validation: 0.7676973952201058]
	TIME [epoch: 24.9 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4913656824615784		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.4913656824615784 | validation: 0.7606490609297727]
	TIME [epoch: 24.9 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49582908269517467		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.49582908269517467 | validation: 0.7532272760771186]
	TIME [epoch: 25 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075492179863028		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.5075492179863028 | validation: 0.7645723291899122]
	TIME [epoch: 24.9 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49026791115413665		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.49026791115413665 | validation: 0.7686970357341592]
	TIME [epoch: 25 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48608676286911645		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.48608676286911645 | validation: 0.735456861293129]
	TIME [epoch: 24.9 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4836194479486271		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.4836194479486271 | validation: 0.7516197863734257]
	TIME [epoch: 25 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830252722725863		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.4830252722725863 | validation: 0.7613671268182028]
	TIME [epoch: 24.9 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47532147001823644		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.47532147001823644 | validation: 0.7561193099912091]
	TIME [epoch: 24.9 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47939557360475266		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.47939557360475266 | validation: 0.7599498928975476]
	TIME [epoch: 24.9 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48782439476610107		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.48782439476610107 | validation: 0.7615253195940137]
	TIME [epoch: 24.9 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49107556595911567		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.49107556595911567 | validation: 0.7457560876648874]
	TIME [epoch: 24.9 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47784872379998256		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.47784872379998256 | validation: 0.7572877300348319]
	TIME [epoch: 24.9 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4909911758955832		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.4909911758955832 | validation: 0.759951179846004]
	TIME [epoch: 24.9 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789718214105519		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.4789718214105519 | validation: 0.7496464104172111]
	TIME [epoch: 24.9 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4733986582472806		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.4733986582472806 | validation: 0.7556910881593605]
	TIME [epoch: 24.9 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47537123297405154		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.47537123297405154 | validation: 0.7455453628582066]
	TIME [epoch: 24.9 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4770665431405654		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.4770665431405654 | validation: 0.7528978167791209]
	TIME [epoch: 24.9 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47761985593768014		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.47761985593768014 | validation: 0.7621176934030173]
	TIME [epoch: 24.9 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4861252427128836		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.4861252427128836 | validation: 0.7600891052045782]
	TIME [epoch: 25 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001102416269331		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.5001102416269331 | validation: 0.7781109241001355]
	TIME [epoch: 25 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049483508629311		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.5049483508629311 | validation: 0.7665995840310782]
	TIME [epoch: 24.9 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4984705119050498		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.4984705119050498 | validation: 0.7473776356434206]
	TIME [epoch: 24.9 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48981432535581415		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.48981432535581415 | validation: 0.754102937722367]
	TIME [epoch: 25 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49251939332264116		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.49251939332264116 | validation: 0.7626660333185048]
	TIME [epoch: 24.9 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789537183672897		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.4789537183672897 | validation: 0.7536379605074864]
	TIME [epoch: 24.9 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4768167204579017		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.4768167204579017 | validation: 0.7502469856507099]
	TIME [epoch: 24.9 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48108159060847344		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.48108159060847344 | validation: 0.752579532370987]
	TIME [epoch: 24.9 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47445752534250507		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.47445752534250507 | validation: 0.7568300405774668]
	TIME [epoch: 24.9 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821716097923823		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.4821716097923823 | validation: 0.7598923541011867]
	TIME [epoch: 24.9 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47925450000535813		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.47925450000535813 | validation: 0.742252091359772]
	TIME [epoch: 24.9 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46417696067046776		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.46417696067046776 | validation: 0.7504064783950554]
	TIME [epoch: 25 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736414874941552		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.4736414874941552 | validation: 0.7606379874153082]
	TIME [epoch: 25 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697285190871856		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.4697285190871856 | validation: 0.7488792655362948]
	TIME [epoch: 25 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824425675675913		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.4824425675675913 | validation: 0.748242439758144]
	TIME [epoch: 24.9 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48094736749454187		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.48094736749454187 | validation: 0.749537250356982]
	TIME [epoch: 25 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46558675551877104		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.46558675551877104 | validation: 0.7513549808291191]
	TIME [epoch: 24.9 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46449963965579644		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.46449963965579644 | validation: 0.7499533820306882]
	TIME [epoch: 25 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739139194272226		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.4739139194272226 | validation: 0.7564711588328615]
	TIME [epoch: 24.9 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663449093514264		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.4663449093514264 | validation: 0.7741412024845025]
	TIME [epoch: 25 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47068750076994137		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.47068750076994137 | validation: 0.7523308147997804]
	TIME [epoch: 24.9 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780329469232524		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.4780329469232524 | validation: 0.7453546842122615]
	TIME [epoch: 25 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46096994917618406		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.46096994917618406 | validation: 0.7362528325432834]
	TIME [epoch: 24.9 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45830839117370187		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.45830839117370187 | validation: 0.7473855504079988]
	TIME [epoch: 25 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47162717460333853		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.47162717460333853 | validation: 0.7513590626232838]
	TIME [epoch: 24.9 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46565056999092086		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.46565056999092086 | validation: 0.7462031604636302]
	TIME [epoch: 24.9 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46548697640047104		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.46548697640047104 | validation: 0.7569003967673852]
	TIME [epoch: 25 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47136604003127447		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.47136604003127447 | validation: 0.7705888216457646]
	TIME [epoch: 24.9 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635646298287989		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.4635646298287989 | validation: 0.7514610797560783]
	TIME [epoch: 24.9 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4680320715002143		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.4680320715002143 | validation: 0.7639383241674742]
	TIME [epoch: 25 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4671502811300734		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.4671502811300734 | validation: 0.7752550809711133]
	TIME [epoch: 24.9 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47028792035340994		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.47028792035340994 | validation: 0.8029981503559027]
	TIME [epoch: 25 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4811518238413811		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.4811518238413811 | validation: 0.7931387975821366]
	TIME [epoch: 24.9 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473176371553263		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.473176371553263 | validation: 0.7790003241081221]
	TIME [epoch: 25 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.477613884913134		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.477613884913134 | validation: 0.7987879330177661]
	TIME [epoch: 24.9 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4824160537651965		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.4824160537651965 | validation: 0.7911267923014785]
	TIME [epoch: 25 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4825277852823104		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.4825277852823104 | validation: 0.7615747271133313]
	TIME [epoch: 24.9 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47805980218703464		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.47805980218703464 | validation: 0.7821723887869044]
	TIME [epoch: 24.9 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47199253339389646		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.47199253339389646 | validation: 0.7867991815022396]
	TIME [epoch: 24.9 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46585429973211656		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.46585429973211656 | validation: 0.7690837639189998]
	TIME [epoch: 24.9 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46716111501701113		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.46716111501701113 | validation: 0.7850593443997391]
	TIME [epoch: 24.9 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750386424082631		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.4750386424082631 | validation: 0.7661384941921593]
	TIME [epoch: 25 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698476026410625		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.4698476026410625 | validation: 0.7933286597331669]
	TIME [epoch: 24.9 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473758962227623		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.473758962227623 | validation: 0.7837715295319738]
	TIME [epoch: 24.9 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4668904736108076		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.4668904736108076 | validation: 0.743527639638414]
	TIME [epoch: 24.9 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47021609822495525		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.47021609822495525 | validation: 0.7825249109940495]
	TIME [epoch: 25 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47131615994742787		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.47131615994742787 | validation: 0.7823255211647941]
	TIME [epoch: 24.9 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700893868708165		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.4700893868708165 | validation: 0.7789806273859634]
	TIME [epoch: 25 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47005133718422926		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.47005133718422926 | validation: 0.7712422985410463]
	TIME [epoch: 24.9 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48049169595030305		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.48049169595030305 | validation: 0.8047820743003046]
	TIME [epoch: 24.9 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47458605957774097		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.47458605957774097 | validation: 0.7957363207240945]
	TIME [epoch: 25 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47025424757436823		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.47025424757436823 | validation: 0.7721556087121343]
	TIME [epoch: 25 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4663841469509159		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.4663841469509159 | validation: 0.7844608612232266]
	TIME [epoch: 24.9 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47075129520905995		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.47075129520905995 | validation: 0.7594332273736746]
	TIME [epoch: 25 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47887524002215237		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.47887524002215237 | validation: 0.773059414883381]
	TIME [epoch: 25 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46550685713162354		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.46550685713162354 | validation: 0.785931869267541]
	TIME [epoch: 24.9 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705171203370421		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.4705171203370421 | validation: 0.767862662459325]
	TIME [epoch: 25 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46592375945692843		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.46592375945692843 | validation: 0.7759158877092063]
	TIME [epoch: 24.9 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4646094595080863		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.4646094595080863 | validation: 0.7500072668535926]
	TIME [epoch: 24.8 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46128117564301574		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.46128117564301574 | validation: 0.7537649089731013]
	TIME [epoch: 25 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45414196982299465		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.45414196982299465 | validation: 0.7707650926189249]
	TIME [epoch: 25 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631689105977538		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.4631689105977538 | validation: 0.7711241437370402]
	TIME [epoch: 24.9 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638999997943891		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.4638999997943891 | validation: 0.7800836009578858]
	TIME [epoch: 24.9 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46882838599702514		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.46882838599702514 | validation: 0.7663918640683877]
	TIME [epoch: 24.9 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46059503677117397		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.46059503677117397 | validation: 0.7708667424753433]
	TIME [epoch: 24.9 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657850033258315		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.4657850033258315 | validation: 0.7848958673470999]
	TIME [epoch: 24.9 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4718012740624175		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.4718012740624175 | validation: 0.7680089700553216]
	TIME [epoch: 24.9 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46354778890018594		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.46354778890018594 | validation: 0.7722978513776062]
	TIME [epoch: 24.9 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638924410852857		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.4638924410852857 | validation: 0.7623670053789962]
	TIME [epoch: 24.9 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468497850295723		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.468497850295723 | validation: 0.7748550648484556]
	TIME [epoch: 25 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625260713278806		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.4625260713278806 | validation: 0.7639543933398598]
	TIME [epoch: 24.9 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45961107021997544		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.45961107021997544 | validation: 0.7649388728368055]
	TIME [epoch: 24.9 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46934765221698177		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.46934765221698177 | validation: 0.7968692127778985]
	TIME [epoch: 24.9 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47057688459305336		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.47057688459305336 | validation: 0.7711801195790465]
	TIME [epoch: 24.8 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4630632110328999		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.4630632110328999 | validation: 0.7681577725855634]
	TIME [epoch: 24.9 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628425194334096		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.4628425194334096 | validation: 0.7663612293756282]
	TIME [epoch: 25 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635684759027176		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.4635684759027176 | validation: 0.7822999290820318]
	TIME [epoch: 24.9 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46963718824911505		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.46963718824911505 | validation: 0.7463937785660875]
	TIME [epoch: 24.9 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46697419312940275		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.46697419312940275 | validation: 0.7860061760899282]
	TIME [epoch: 24.9 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46287727476635093		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.46287727476635093 | validation: 0.763301020737993]
	TIME [epoch: 24.9 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46250420150425847		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.46250420150425847 | validation: 0.762020415984974]
	TIME [epoch: 24.9 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45235947239201313		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.45235947239201313 | validation: 0.7573736664948123]
	TIME [epoch: 24.9 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4651726940080032		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.4651726940080032 | validation: 0.7620635207841342]
	TIME [epoch: 24.9 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46340477225057175		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.46340477225057175 | validation: 0.7669039667009031]
	TIME [epoch: 24.9 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45475448110038247		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.45475448110038247 | validation: 0.7644461415030719]
	TIME [epoch: 25 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4665535528357238		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.4665535528357238 | validation: 0.7468135644012993]
	TIME [epoch: 24.9 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.463585396002406		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.463585396002406 | validation: 0.7545557338425195]
	TIME [epoch: 25 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656230262601524		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.4656230262601524 | validation: 0.7556473714600831]
	TIME [epoch: 25 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641330491159627		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.4641330491159627 | validation: 0.7517422495915058]
	TIME [epoch: 24.9 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687173374098128		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.4687173374098128 | validation: 0.7304464190590829]
	TIME [epoch: 25 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673494875987004		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.4673494875987004 | validation: 0.755758046309401]
	TIME [epoch: 25 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46319115970548685		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.46319115970548685 | validation: 0.7515813112760733]
	TIME [epoch: 24.9 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45933324185434743		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.45933324185434743 | validation: 0.7524004398137802]
	TIME [epoch: 25 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4597789608735052		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.4597789608735052 | validation: 0.7567433763611316]
	TIME [epoch: 25 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4609739435471195		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.4609739435471195 | validation: 0.7363637868617745]
	TIME [epoch: 24.9 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45380619088169594		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.45380619088169594 | validation: 0.7568481740493194]
	TIME [epoch: 25 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46240176538611766		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.46240176538611766 | validation: 0.7616303541672684]
	TIME [epoch: 24.9 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628886530515776		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.4628886530515776 | validation: 0.7615921395141997]
	TIME [epoch: 24.9 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46195472660164577		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.46195472660164577 | validation: 0.7449566498641991]
	TIME [epoch: 25 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45894583290698476		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.45894583290698476 | validation: 0.7655477555169966]
	TIME [epoch: 25 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45876599367196896		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.45876599367196896 | validation: 0.7539262536295628]
	TIME [epoch: 24.9 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548108461572622		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.4548108461572622 | validation: 0.7300818395810785]
	TIME [epoch: 24.9 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46032240691494397		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.46032240691494397 | validation: 0.757542967283365]
	TIME [epoch: 24.9 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46917968014607364		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.46917968014607364 | validation: 0.7622976343227659]
	TIME [epoch: 24.9 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652409749536762		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.4652409749536762 | validation: 0.7527353955357264]
	TIME [epoch: 24.9 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46168315054376236		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.46168315054376236 | validation: 0.7641005106265619]
	TIME [epoch: 24.9 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46414617475913433		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.46414617475913433 | validation: 0.7556343432963604]
	TIME [epoch: 24.9 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46165576768147676		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.46165576768147676 | validation: 0.7549500810458055]
	TIME [epoch: 24.9 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743036766413591		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.4743036766413591 | validation: 0.7466982009332899]
	TIME [epoch: 24.9 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532921431210704		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.4532921431210704 | validation: 0.7554535881705613]
	TIME [epoch: 24.9 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46433748592227575		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.46433748592227575 | validation: 0.7548264648808699]
	TIME [epoch: 24.9 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45971873288837245		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.45971873288837245 | validation: 0.7627486254824979]
	TIME [epoch: 24.9 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660034124350076		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.4660034124350076 | validation: 0.7599594243689708]
	TIME [epoch: 24.9 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547153666823156		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.4547153666823156 | validation: 0.7545453941390496]
	TIME [epoch: 24.9 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46186072533769024		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.46186072533769024 | validation: 0.7413410642160773]
	TIME [epoch: 24.9 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46598768803898194		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.46598768803898194 | validation: 0.7552222626563247]
	TIME [epoch: 24.9 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46404897693277763		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.46404897693277763 | validation: 0.7677647069886224]
	TIME [epoch: 24.9 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4661969675585852		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.4661969675585852 | validation: 0.753654381660755]
	TIME [epoch: 24.9 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46234378642430574		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.46234378642430574 | validation: 0.7671280556766209]
	TIME [epoch: 24.9 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621888181644978		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.4621888181644978 | validation: 0.7511855562476285]
	TIME [epoch: 24.9 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728395244075323		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.4728395244075323 | validation: 0.7693617324744513]
	TIME [epoch: 24.9 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4595545850727106		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.4595545850727106 | validation: 0.7626041922182841]
	TIME [epoch: 24.9 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4601849420724597		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.4601849420724597 | validation: 0.7728668687968557]
	TIME [epoch: 24.9 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4646429697876072		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.4646429697876072 | validation: 0.7756823831648184]
	TIME [epoch: 24.9 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464919586216645		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.464919586216645 | validation: 0.7612219659238919]
	TIME [epoch: 24.9 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4653972101073666		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.4653972101073666 | validation: 0.7350823089273979]
	TIME [epoch: 24.9 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530479984041742		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.4530479984041742 | validation: 0.7645170415802693]
	TIME [epoch: 25 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45263096176110373		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.45263096176110373 | validation: 0.7545722248756904]
	TIME [epoch: 24.9 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45937166622421644		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.45937166622421644 | validation: 0.752294032167302]
	TIME [epoch: 24.9 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4660293681520156		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.4660293681520156 | validation: 0.7467433379259232]
	TIME [epoch: 25 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46131845579433683		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.46131845579433683 | validation: 0.7698275195004861]
	TIME [epoch: 24.9 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46883404208267515		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.46883404208267515 | validation: 0.7655121474382192]
	TIME [epoch: 24.9 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46520079377758095		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.46520079377758095 | validation: 0.7667974895898059]
	TIME [epoch: 24.9 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46146069712300103		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.46146069712300103 | validation: 0.7613246619850712]
	TIME [epoch: 24.9 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585833852252213		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.4585833852252213 | validation: 0.7631678559388405]
	TIME [epoch: 24.9 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4643750499454615		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.4643750499454615 | validation: 0.740923547628152]
	TIME [epoch: 25 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4562877010549996		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.4562877010549996 | validation: 0.7461522364237908]
	TIME [epoch: 24.9 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45935324203136263		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.45935324203136263 | validation: 0.7465187520885245]
	TIME [epoch: 24.9 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46761367160619993		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.46761367160619993 | validation: 0.7409192029259458]
	TIME [epoch: 24.9 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45532397543792197		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.45532397543792197 | validation: 0.7488564146745169]
	TIME [epoch: 24.9 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633718887326146		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.4633718887326146 | validation: 0.741292719639976]
	TIME [epoch: 24.9 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46369547387742227		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.46369547387742227 | validation: 0.7406728556599969]
	TIME [epoch: 24.9 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596101917925016		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.4596101917925016 | validation: 0.7550013447302747]
	TIME [epoch: 24.9 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573983937517291		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.4573983937517291 | validation: 0.742243920985605]
	TIME [epoch: 24.9 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46040808986671017		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.46040808986671017 | validation: 0.7421103668483595]
	TIME [epoch: 24.9 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4610410001143516		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.4610410001143516 | validation: 0.7528385791492989]
	TIME [epoch: 24.9 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46401174642502685		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.46401174642502685 | validation: 0.740690928716943]
	TIME [epoch: 24.9 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580197128970503		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.4580197128970503 | validation: 0.747992495728029]
	TIME [epoch: 24.9 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4576946275916068		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.4576946275916068 | validation: 0.7576226499248239]
	TIME [epoch: 24.9 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634341265075196		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.4634341265075196 | validation: 0.7444390553530795]
	TIME [epoch: 24.9 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4615132942180731		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.4615132942180731 | validation: 0.7106946667480104]
	TIME [epoch: 24.9 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45535938020899336		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.45535938020899336 | validation: 0.751311642159438]
	TIME [epoch: 24.9 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45247738496305767		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.45247738496305767 | validation: 0.7541277286447857]
	TIME [epoch: 24.9 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512028911113434		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.4512028911113434 | validation: 0.7433090376980954]
	TIME [epoch: 24.9 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46433893144843846		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.46433893144843846 | validation: 0.7418826876001043]
	TIME [epoch: 24.9 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46049928337330437		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.46049928337330437 | validation: 0.7519780031218638]
	TIME [epoch: 24.9 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625928343715152		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.4625928343715152 | validation: 0.7478939004176597]
	TIME [epoch: 24.9 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4712424491737102		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.4712424491737102 | validation: 0.7432997212879329]
	TIME [epoch: 24.9 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45754645956427065		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.45754645956427065 | validation: 0.7119247426434459]
	TIME [epoch: 24.9 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46562453576416507		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.46562453576416507 | validation: 0.7290266366970406]
	TIME [epoch: 24.9 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549004323936725		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.4549004323936725 | validation: 0.7062720856196261]
	TIME [epoch: 24.9 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46035896773588414		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.46035896773588414 | validation: 0.7344735524669892]
	TIME [epoch: 25 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458957267454706		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.458957267454706 | validation: 0.7410822460763805]
	TIME [epoch: 24.9 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46776401708763055		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.46776401708763055 | validation: 0.7258330319326965]
	TIME [epoch: 24.9 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565537167451952		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.4565537167451952 | validation: 0.7456333289624132]
	TIME [epoch: 24.9 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45501985531468214		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.45501985531468214 | validation: 0.7374075040927286]
	TIME [epoch: 24.9 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45287128471798943		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.45287128471798943 | validation: 0.7567547921015988]
	TIME [epoch: 24.9 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647068174212444		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.4647068174212444 | validation: 0.7295542807594905]
	TIME [epoch: 24.9 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581383509890019		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.4581383509890019 | validation: 0.7416379632995279]
	TIME [epoch: 24.9 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633489601258688		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.4633489601258688 | validation: 0.7503288412081907]
	TIME [epoch: 24.9 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46573894694097734		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.46573894694097734 | validation: 0.7449056472323994]
	TIME [epoch: 24.9 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598039261415111		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.4598039261415111 | validation: 0.741921877200933]
	TIME [epoch: 24.9 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600421708189758		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.4600421708189758 | validation: 0.7401498888345913]
	TIME [epoch: 24.9 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4649592426935762		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.4649592426935762 | validation: 0.7477537842470698]
	TIME [epoch: 25 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45039910672614464		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.45039910672614464 | validation: 0.7250042919940541]
	TIME [epoch: 24.9 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453224394697443		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.453224394697443 | validation: 0.7458041045925146]
	TIME [epoch: 24.9 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4559577965160828		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.4559577965160828 | validation: 0.7502445778510562]
	TIME [epoch: 24.9 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538602351336197		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.4538602351336197 | validation: 0.7373417688975047]
	TIME [epoch: 24.9 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600956879689753		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.4600956879689753 | validation: 0.7415012264192756]
	TIME [epoch: 24.9 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641909107163971		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.4641909107163971 | validation: 0.7465219291968146]
	TIME [epoch: 24.9 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45680575902053766		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.45680575902053766 | validation: 0.7476802027860877]
	TIME [epoch: 24.9 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45758468528425045		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.45758468528425045 | validation: 0.7614926924206146]
	TIME [epoch: 24.9 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45733616461129734		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.45733616461129734 | validation: 0.75356818463697]
	TIME [epoch: 24.9 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612310555379656		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.4612310555379656 | validation: 0.7388138298702512]
	TIME [epoch: 24.9 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45752433955690985		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.45752433955690985 | validation: 0.7474779362039763]
	TIME [epoch: 24.9 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4631009434504164		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.4631009434504164 | validation: 0.7706948486139708]
	TIME [epoch: 24.9 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550005621325706		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.4550005621325706 | validation: 0.7457177493814032]
	TIME [epoch: 24.9 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46619651653731997		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.46619651653731997 | validation: 0.7552878927793721]
	TIME [epoch: 24.9 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45321156321648537		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.45321156321648537 | validation: 0.747839618868808]
	TIME [epoch: 24.9 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45880746253613847		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.45880746253613847 | validation: 0.7403636971838061]
	TIME [epoch: 25 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599369249577326		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.4599369249577326 | validation: 0.7520804022746139]
	TIME [epoch: 24.9 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4619680245729444		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.4619680245729444 | validation: 0.733953920311118]
	TIME [epoch: 24.9 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45874676965897226		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.45874676965897226 | validation: 0.7320723573592648]
	TIME [epoch: 25 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4652033762938139		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.4652033762938139 | validation: 0.7551032658864739]
	TIME [epoch: 24.9 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45656678503816567		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.45656678503816567 | validation: 0.7443151389281831]
	TIME [epoch: 25 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4582862019356056		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.4582862019356056 | validation: 0.7589087116913464]
	TIME [epoch: 24.9 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4613464008468749		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.4613464008468749 | validation: 0.73932862911493]
	TIME [epoch: 24.9 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46070317762279195		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.46070317762279195 | validation: 0.7413127611152953]
	TIME [epoch: 24.9 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4647726133115225		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.4647726133115225 | validation: 0.7342727193644997]
	TIME [epoch: 24.9 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525281907870661		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.4525281907870661 | validation: 0.729724389435018]
	TIME [epoch: 24.9 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45506881511061564		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.45506881511061564 | validation: 0.7405805441798026]
	TIME [epoch: 25 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4469867607796857		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.4469867607796857 | validation: 0.7328094058092196]
	TIME [epoch: 24.9 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603014033264761		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.4603014033264761 | validation: 0.7469126052715954]
	TIME [epoch: 24.9 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46418923015069713		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.46418923015069713 | validation: 0.7270976333569231]
	TIME [epoch: 24.9 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550720577412798		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.4550720577412798 | validation: 0.7246189855382776]
	TIME [epoch: 25 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45590495757400923		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.45590495757400923 | validation: 0.7476127081748898]
	TIME [epoch: 24.9 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687385695276407		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.4687385695276407 | validation: 0.7355568574231605]
	TIME [epoch: 24.9 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492774468902709		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.4492774468902709 | validation: 0.7409176813652806]
	TIME [epoch: 25 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46415941281572926		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.46415941281572926 | validation: 0.735563388721676]
	TIME [epoch: 24.9 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.459722468756923		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.459722468756923 | validation: 0.7477847928427249]
	TIME [epoch: 25 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625069090426946		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.4625069090426946 | validation: 0.7329049883420357]
	TIME [epoch: 24.9 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4604720953418689		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.4604720953418689 | validation: 0.7384215609268648]
	TIME [epoch: 24.9 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46741297106176505		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.46741297106176505 | validation: 0.7441430729243015]
	TIME [epoch: 24.9 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4588124780138874		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.4588124780138874 | validation: 0.7261648039467343]
	TIME [epoch: 24.9 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45470057033813466		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.45470057033813466 | validation: 0.7416907667620695]
	TIME [epoch: 24.9 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598850218254288		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.4598850218254288 | validation: 0.7364260274198433]
	TIME [epoch: 24.9 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45371544038577105		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.45371544038577105 | validation: 0.7436368143577974]
	TIME [epoch: 24.9 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4508862921004937		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.4508862921004937 | validation: 0.7395547848997492]
	TIME [epoch: 24.9 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45557048853805926		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.45557048853805926 | validation: 0.7513490573182204]
	TIME [epoch: 25 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4534337626210386		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.4534337626210386 | validation: 0.7456313653297068]
	TIME [epoch: 25 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608867230842501		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.4608867230842501 | validation: 0.7387055509680818]
	TIME [epoch: 24.9 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549784257369738		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.4549784257369738 | validation: 0.7389237991905983]
	TIME [epoch: 25 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551197849329625		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.4551197849329625 | validation: 0.7458263563375]
	TIME [epoch: 25 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531408332227614		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.4531408332227614 | validation: 0.7396105370828628]
	TIME [epoch: 24.9 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4572099462452506		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.4572099462452506 | validation: 0.7311358540831694]
	TIME [epoch: 25 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45941820546612344		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.45941820546612344 | validation: 0.7626911440386541]
	TIME [epoch: 25 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45438748981454746		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.45438748981454746 | validation: 0.7534085825417733]
	TIME [epoch: 24.9 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517211886240966		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.4517211886240966 | validation: 0.7298942336069633]
	TIME [epoch: 25 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45733901587457126		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.45733901587457126 | validation: 0.7631755873176875]
	TIME [epoch: 25 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4525789395574297		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.4525789395574297 | validation: 0.7360782369963824]
	TIME [epoch: 24.9 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45510476942818007		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.45510476942818007 | validation: 0.7295263465729402]
	TIME [epoch: 25 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4621271504507841		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.4621271504507841 | validation: 0.7517737274427763]
	TIME [epoch: 24.9 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4499962800835701		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.4499962800835701 | validation: 0.740522708372639]
	TIME [epoch: 24.9 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46287779749851043		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.46287779749851043 | validation: 0.735796486661259]
	TIME [epoch: 25 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44933041732220114		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.44933041732220114 | validation: 0.7494756750866433]
	TIME [epoch: 25 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602466273364666		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.4602466273364666 | validation: 0.7254704117535894]
	TIME [epoch: 24.8 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4544395760609996		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.4544395760609996 | validation: 0.725437927855805]
	TIME [epoch: 24.9 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45087724110125427		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.45087724110125427 | validation: 0.73369980223988]
	TIME [epoch: 24.9 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45541468094805093		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.45541468094805093 | validation: 0.7402859568744561]
	TIME [epoch: 24.9 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553696811535976		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.4553696811535976 | validation: 0.7306940757945384]
	TIME [epoch: 24.9 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45363404112653893		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.45363404112653893 | validation: 0.7510069833039144]
	TIME [epoch: 25 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531455657674901		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.4531455657674901 | validation: 0.7619294769713806]
	TIME [epoch: 24.9 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554306032773715		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.4554306032773715 | validation: 0.7426099836760728]
	TIME [epoch: 24.9 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4625876527896541		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.4625876527896541 | validation: 0.742131161869246]
	TIME [epoch: 24.9 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45196893626242685		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.45196893626242685 | validation: 0.7442035794303851]
	TIME [epoch: 24.8 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45806259052725934		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.45806259052725934 | validation: 0.752605316416122]
	TIME [epoch: 24.9 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46135235204954833		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.46135235204954833 | validation: 0.7504975443934351]
	TIME [epoch: 24.9 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4547430060438444		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.4547430060438444 | validation: 0.7262669574044713]
	TIME [epoch: 24.9 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458491827768729		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.458491827768729 | validation: 0.7303703311548984]
	TIME [epoch: 24.9 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490995207096986		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.4490995207096986 | validation: 0.7199537048363565]
	TIME [epoch: 24.9 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569163609113147		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.4569163609113147 | validation: 0.7261957825485443]
	TIME [epoch: 24.9 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4531066784024414		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.4531066784024414 | validation: 0.7289957094632442]
	TIME [epoch: 25 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4524257353345874		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.4524257353345874 | validation: 0.747440998271139]
	TIME [epoch: 25 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4578609481067319		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.4578609481067319 | validation: 0.7245139501297763]
	TIME [epoch: 24.9 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45819840508324605		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.45819840508324605 | validation: 0.7364089230909658]
	TIME [epoch: 24.9 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580399267708766		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.4580399267708766 | validation: 0.7065144067311898]
	TIME [epoch: 24.9 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4608490167679439		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.4608490167679439 | validation: 0.7473298222963518]
	TIME [epoch: 24.9 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45764390063864946		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.45764390063864946 | validation: 0.7650375357732898]
	TIME [epoch: 25 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45799574993958686		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.45799574993958686 | validation: 0.7388832431610655]
	TIME [epoch: 25 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45541050599936994		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.45541050599936994 | validation: 0.7414531533198502]
	TIME [epoch: 24.9 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618202771655078		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.4618202771655078 | validation: 0.7310740645427285]
	TIME [epoch: 25 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530518017438906		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.4530518017438906 | validation: 0.7496185732267213]
	TIME [epoch: 24.9 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45989638473203576		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.45989638473203576 | validation: 0.7552510462269844]
	TIME [epoch: 24.9 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512614058452574		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.4512614058452574 | validation: 0.7542518706585497]
	TIME [epoch: 25 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585724327845038		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.4585724327845038 | validation: 0.7468664022896914]
	TIME [epoch: 25 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4596504281736248		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.4596504281736248 | validation: 0.7160148293397467]
	TIME [epoch: 24.9 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560614269853256		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.4560614269853256 | validation: 0.7337206243871048]
	TIME [epoch: 25 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590906154032559		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.4590906154032559 | validation: 0.7253688890464173]
	TIME [epoch: 24.9 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550194905425098		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.4550194905425098 | validation: 0.7463618735400595]
	TIME [epoch: 24.9 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45482516089654434		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.45482516089654434 | validation: 0.7554269330642835]
	TIME [epoch: 24.9 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551757803132669		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.4551757803132669 | validation: 0.7328167749932682]
	TIME [epoch: 24.9 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580069058140314		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.4580069058140314 | validation: 0.7267343853321748]
	TIME [epoch: 24.9 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4532662421479577		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.4532662421479577 | validation: 0.7287207459206875]
	TIME [epoch: 24.9 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555906721927401		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.4555906721927401 | validation: 0.7415477427684704]
	TIME [epoch: 24.9 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4553659892810184		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.4553659892810184 | validation: 0.756034884692208]
	TIME [epoch: 24.9 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4606717657200028		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.4606717657200028 | validation: 0.7390654289373946]
	TIME [epoch: 25 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4572568614110624		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.4572568614110624 | validation: 0.748203361588076]
	TIME [epoch: 25 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.459503698715651		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.459503698715651 | validation: 0.7558301763936655]
	TIME [epoch: 24.8 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45685963644569555		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.45685963644569555 | validation: 0.7414415369206121]
	TIME [epoch: 24.9 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4565662401841768		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.4565662401841768 | validation: 0.7250647685378655]
	TIME [epoch: 24.9 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45933239748473986		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.45933239748473986 | validation: 0.7376652833944414]
	TIME [epoch: 24.9 sec]
Finished training in 50160.221 seconds.
